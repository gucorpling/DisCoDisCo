/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/por.rst.cstn/
2021-07-22 22:57:19,620 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/por.rst.cstn
2021-07-22 22:57:19,620 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/por.rst.cstn/sent_train.txt
2021-07-22 22:57:19,620 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/por.rst.cstn/sent_dev.txt
2021-07-22 22:57:19,620 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/por.rst.cstn/sent_test.txt
Corpus: 4496 train + 859 dev + 1851 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 22:57:38,176 ----------------------------------------------------------------------------------------------------
2021-07-22 22:57:38,177 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 22:57:38,177 ----------------------------------------------------------------------------------------------------
2021-07-22 22:57:38,177 Corpus: "Corpus: 4496 train + 859 dev + 1851 test sentences"
2021-07-22 22:57:38,178 ----------------------------------------------------------------------------------------------------
2021-07-22 22:57:38,178 Parameters:
2021-07-22 22:57:38,178  - learning_rate: "3e-05"
2021-07-22 22:57:38,178  - mini_batch_size: "32"
2021-07-22 22:57:38,178  - patience: "3"
2021-07-22 22:57:38,178  - anneal_factor: "0.5"
2021-07-22 22:57:38,178  - max_epochs: "40"
2021-07-22 22:57:38,178  - shuffle: "True"
2021-07-22 22:57:38,178  - train_with_dev: "False"
2021-07-22 22:57:38,178  - batch_growth_annealing: "False"
2021-07-22 22:57:38,178 ----------------------------------------------------------------------------------------------------
2021-07-22 22:57:38,178 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/por.rst.cstn"
2021-07-22 22:57:38,178 ----------------------------------------------------------------------------------------------------
2021-07-22 22:57:38,178 Device: cuda:0
2021-07-22 22:57:38,178 ----------------------------------------------------------------------------------------------------
2021-07-22 22:57:38,178 Embeddings storage mode: cpu
2021-07-22 22:57:38,181 ----------------------------------------------------------------------------------------------------
2021-07-22 22:57:46,049 epoch 1 - iter 14/141 - loss 23.81192684 - samples/sec: 56.95 - lr: 0.000030
2021-07-22 22:57:54,075 epoch 1 - iter 28/141 - loss 21.48641522 - samples/sec: 55.82 - lr: 0.000030
2021-07-22 22:58:02,111 epoch 1 - iter 42/141 - loss 19.03197620 - samples/sec: 55.75 - lr: 0.000030
2021-07-22 22:58:10,317 epoch 1 - iter 56/141 - loss 16.49281462 - samples/sec: 54.60 - lr: 0.000030
2021-07-22 22:58:18,401 epoch 1 - iter 70/141 - loss 14.32841878 - samples/sec: 55.42 - lr: 0.000030
2021-07-22 22:58:26,523 epoch 1 - iter 84/141 - loss 12.41711532 - samples/sec: 55.17 - lr: 0.000030
2021-07-22 22:58:34,905 epoch 1 - iter 98/141 - loss 10.89233778 - samples/sec: 53.45 - lr: 0.000030
2021-07-22 22:58:42,949 epoch 1 - iter 112/141 - loss 9.70192600 - samples/sec: 55.70 - lr: 0.000030
2021-07-22 22:58:51,197 epoch 1 - iter 126/141 - loss 8.74705801 - samples/sec: 54.32 - lr: 0.000030
2021-07-22 22:58:59,388 epoch 1 - iter 140/141 - loss 7.96271024 - samples/sec: 54.70 - lr: 0.000030
2021-07-22 22:58:59,702 ----------------------------------------------------------------------------------------------------
2021-07-22 22:58:59,702 EPOCH 1 done: loss 7.9121 - lr 0.0000300
2021-07-22 22:59:10,955 DEV : loss 0.7179341316223145 - score 0.7093
2021-07-22 22:59:10,980 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 22:59:12,201 ----------------------------------------------------------------------------------------------------
2021-07-22 22:59:15,442 epoch 2 - iter 14/141 - loss 0.76801610 - samples/sec: 138.35 - lr: 0.000030
2021-07-22 22:59:18,644 epoch 2 - iter 28/141 - loss 0.72606506 - samples/sec: 139.95 - lr: 0.000030
2021-07-22 22:59:22,020 epoch 2 - iter 42/141 - loss 0.70214391 - samples/sec: 132.75 - lr: 0.000030
2021-07-22 22:59:25,224 epoch 2 - iter 56/141 - loss 0.66157324 - samples/sec: 139.84 - lr: 0.000030
2021-07-22 22:59:28,472 epoch 2 - iter 70/141 - loss 0.64336677 - samples/sec: 138.01 - lr: 0.000030
2021-07-22 22:59:31,626 epoch 2 - iter 84/141 - loss 0.62162981 - samples/sec: 142.08 - lr: 0.000030
2021-07-22 22:59:35,087 epoch 2 - iter 98/141 - loss 0.59351177 - samples/sec: 129.48 - lr: 0.000030
2021-07-22 22:59:38,380 epoch 2 - iter 112/141 - loss 0.56501240 - samples/sec: 136.06 - lr: 0.000030
2021-07-22 22:59:41,853 epoch 2 - iter 126/141 - loss 0.54602389 - samples/sec: 129.03 - lr: 0.000030
2021-07-22 22:59:45,226 epoch 2 - iter 140/141 - loss 0.52819078 - samples/sec: 132.86 - lr: 0.000030
2021-07-22 22:59:45,376 ----------------------------------------------------------------------------------------------------
2021-07-22 22:59:45,376 EPOCH 2 done: loss 0.5274 - lr 0.0000300
2021-07-22 22:59:47,427 DEV : loss 0.243671715259552 - score 0.9452
2021-07-22 22:59:47,451 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 22:59:51,643 ----------------------------------------------------------------------------------------------------
2021-07-22 22:59:55,000 epoch 3 - iter 14/141 - loss 0.36230878 - samples/sec: 133.56 - lr: 0.000030
2021-07-22 22:59:58,163 epoch 3 - iter 28/141 - loss 0.32694893 - samples/sec: 141.67 - lr: 0.000030
2021-07-22 23:00:01,475 epoch 3 - iter 42/141 - loss 0.31001149 - samples/sec: 135.30 - lr: 0.000030
2021-07-22 23:00:04,779 epoch 3 - iter 56/141 - loss 0.30614002 - samples/sec: 135.62 - lr: 0.000030
2021-07-22 23:00:08,103 epoch 3 - iter 70/141 - loss 0.30166599 - samples/sec: 134.82 - lr: 0.000030
2021-07-22 23:00:11,427 epoch 3 - iter 84/141 - loss 0.28918036 - samples/sec: 134.82 - lr: 0.000030
2021-07-22 23:00:14,799 epoch 3 - iter 98/141 - loss 0.28271215 - samples/sec: 132.90 - lr: 0.000030
2021-07-22 23:00:17,994 epoch 3 - iter 112/141 - loss 0.27868152 - samples/sec: 140.26 - lr: 0.000030
2021-07-22 23:00:21,328 epoch 3 - iter 126/141 - loss 0.27433035 - samples/sec: 134.42 - lr: 0.000030
2021-07-22 23:00:24,784 epoch 3 - iter 140/141 - loss 0.27303018 - samples/sec: 129.65 - lr: 0.000030
2021-07-22 23:00:24,939 ----------------------------------------------------------------------------------------------------
2021-07-22 23:00:24,939 EPOCH 3 done: loss 0.2721 - lr 0.0000300
2021-07-22 23:00:26,997 DEV : loss 0.11413154006004333 - score 0.9815
2021-07-22 23:00:27,021 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:00:33,583 ----------------------------------------------------------------------------------------------------
2021-07-22 23:00:37,476 epoch 4 - iter 14/141 - loss 0.22441830 - samples/sec: 135.06 - lr: 0.000030
2021-07-22 23:00:41,007 epoch 4 - iter 28/141 - loss 0.22649582 - samples/sec: 126.88 - lr: 0.000030
2021-07-22 23:00:44,219 epoch 4 - iter 42/141 - loss 0.21852930 - samples/sec: 139.53 - lr: 0.000030
2021-07-22 23:00:47,562 epoch 4 - iter 56/141 - loss 0.21768812 - samples/sec: 134.04 - lr: 0.000030
2021-07-22 23:00:50,959 epoch 4 - iter 70/141 - loss 0.21044721 - samples/sec: 131.91 - lr: 0.000030
2021-07-22 23:00:54,208 epoch 4 - iter 84/141 - loss 0.20378658 - samples/sec: 137.96 - lr: 0.000030
2021-07-22 23:00:57,684 epoch 4 - iter 98/141 - loss 0.20278225 - samples/sec: 128.91 - lr: 0.000030
2021-07-22 23:01:01,011 epoch 4 - iter 112/141 - loss 0.20184608 - samples/sec: 134.69 - lr: 0.000030
2021-07-22 23:01:04,284 epoch 4 - iter 126/141 - loss 0.20118928 - samples/sec: 136.90 - lr: 0.000030
2021-07-22 23:01:07,600 epoch 4 - iter 140/141 - loss 0.19890312 - samples/sec: 135.16 - lr: 0.000030
2021-07-22 23:01:07,750 ----------------------------------------------------------------------------------------------------
2021-07-22 23:01:07,751 EPOCH 4 done: loss 0.1979 - lr 0.0000300
2021-07-22 23:01:09,814 DEV : loss 0.07519964128732681 - score 0.985
2021-07-22 23:01:09,839 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:01:13,839 ----------------------------------------------------------------------------------------------------
2021-07-22 23:01:17,011 epoch 5 - iter 14/141 - loss 0.17500049 - samples/sec: 141.36 - lr: 0.000030
2021-07-22 23:01:20,308 epoch 5 - iter 28/141 - loss 0.17841524 - samples/sec: 135.94 - lr: 0.000030
2021-07-22 23:01:23,619 epoch 5 - iter 42/141 - loss 0.16708015 - samples/sec: 135.33 - lr: 0.000030
2021-07-22 23:01:27,058 epoch 5 - iter 56/141 - loss 0.16313277 - samples/sec: 130.29 - lr: 0.000030
2021-07-22 23:01:30,452 epoch 5 - iter 70/141 - loss 0.16663420 - samples/sec: 132.07 - lr: 0.000030
2021-07-22 23:01:33,804 epoch 5 - iter 84/141 - loss 0.16311759 - samples/sec: 133.66 - lr: 0.000030
2021-07-22 23:01:37,210 epoch 5 - iter 98/141 - loss 0.16407490 - samples/sec: 131.59 - lr: 0.000030
2021-07-22 23:01:40,604 epoch 5 - iter 112/141 - loss 0.16508991 - samples/sec: 132.02 - lr: 0.000030
2021-07-22 23:01:43,931 epoch 5 - iter 126/141 - loss 0.16261378 - samples/sec: 134.69 - lr: 0.000030
2021-07-22 23:01:47,263 epoch 5 - iter 140/141 - loss 0.16208944 - samples/sec: 134.51 - lr: 0.000030
2021-07-22 23:01:47,411 ----------------------------------------------------------------------------------------------------
2021-07-22 23:01:47,411 EPOCH 5 done: loss 0.1623 - lr 0.0000300
2021-07-22 23:01:49,476 DEV : loss 0.05744367837905884 - score 0.9886
2021-07-22 23:01:49,501 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:01:53,534 ----------------------------------------------------------------------------------------------------
2021-07-22 23:01:56,764 epoch 6 - iter 14/141 - loss 0.15682937 - samples/sec: 138.80 - lr: 0.000030
2021-07-22 23:02:00,079 epoch 6 - iter 28/141 - loss 0.14805539 - samples/sec: 135.20 - lr: 0.000030
2021-07-22 23:02:03,343 epoch 6 - iter 42/141 - loss 0.13997844 - samples/sec: 137.27 - lr: 0.000030
2021-07-22 23:02:06,755 epoch 6 - iter 56/141 - loss 0.13916445 - samples/sec: 131.32 - lr: 0.000030
2021-07-22 23:02:10,235 epoch 6 - iter 70/141 - loss 0.13658951 - samples/sec: 128.80 - lr: 0.000030
2021-07-22 23:02:13,560 epoch 6 - iter 84/141 - loss 0.13589003 - samples/sec: 134.75 - lr: 0.000030
2021-07-22 23:02:16,931 epoch 6 - iter 98/141 - loss 0.13763480 - samples/sec: 132.95 - lr: 0.000030
2021-07-22 23:02:20,304 epoch 6 - iter 112/141 - loss 0.13784457 - samples/sec: 132.86 - lr: 0.000030
2021-07-22 23:02:23,603 epoch 6 - iter 126/141 - loss 0.14029717 - samples/sec: 135.82 - lr: 0.000030
2021-07-22 23:02:26,954 epoch 6 - iter 140/141 - loss 0.14106798 - samples/sec: 133.71 - lr: 0.000030
2021-07-22 23:02:27,115 ----------------------------------------------------------------------------------------------------
2021-07-22 23:02:27,115 EPOCH 6 done: loss 0.1415 - lr 0.0000300
2021-07-22 23:02:29,186 DEV : loss 0.04784965515136719 - score 0.9886
2021-07-22 23:02:29,211 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:02:33,366 ----------------------------------------------------------------------------------------------------
2021-07-22 23:02:36,776 epoch 7 - iter 14/141 - loss 0.11647839 - samples/sec: 131.51 - lr: 0.000030
2021-07-22 23:02:40,134 epoch 7 - iter 28/141 - loss 0.11173207 - samples/sec: 133.43 - lr: 0.000030
2021-07-22 23:02:43,347 epoch 7 - iter 42/141 - loss 0.11805077 - samples/sec: 139.49 - lr: 0.000030
2021-07-22 23:02:46,644 epoch 7 - iter 56/141 - loss 0.11745130 - samples/sec: 135.90 - lr: 0.000030
2021-07-22 23:02:50,094 epoch 7 - iter 70/141 - loss 0.11748710 - samples/sec: 129.91 - lr: 0.000030
2021-07-22 23:02:53,538 epoch 7 - iter 84/141 - loss 0.12375260 - samples/sec: 130.09 - lr: 0.000030
2021-07-22 23:02:56,932 epoch 7 - iter 98/141 - loss 0.12733914 - samples/sec: 132.06 - lr: 0.000030
2021-07-22 23:03:00,289 epoch 7 - iter 112/141 - loss 0.12585338 - samples/sec: 133.46 - lr: 0.000030
2021-07-22 23:03:03,570 epoch 7 - iter 126/141 - loss 0.12393721 - samples/sec: 136.60 - lr: 0.000030
2021-07-22 23:03:06,850 epoch 7 - iter 140/141 - loss 0.12566781 - samples/sec: 136.60 - lr: 0.000030
2021-07-22 23:03:07,015 ----------------------------------------------------------------------------------------------------
2021-07-22 23:03:07,015 EPOCH 7 done: loss 0.1257 - lr 0.0000300
2021-07-22 23:03:09,092 DEV : loss 0.04572291299700737 - score 0.9903
2021-07-22 23:03:09,117 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:03:13,184 ----------------------------------------------------------------------------------------------------
2021-07-22 23:03:16,526 epoch 8 - iter 14/141 - loss 0.11549814 - samples/sec: 134.16 - lr: 0.000030
2021-07-22 23:03:19,894 epoch 8 - iter 28/141 - loss 0.11683500 - samples/sec: 133.05 - lr: 0.000030
2021-07-22 23:03:23,150 epoch 8 - iter 42/141 - loss 0.12363614 - samples/sec: 137.63 - lr: 0.000030
2021-07-22 23:03:26,586 epoch 8 - iter 56/141 - loss 0.12111173 - samples/sec: 130.44 - lr: 0.000030
2021-07-22 23:03:30,061 epoch 8 - iter 70/141 - loss 0.11982312 - samples/sec: 128.92 - lr: 0.000030
2021-07-22 23:03:33,424 epoch 8 - iter 84/141 - loss 0.11972690 - samples/sec: 133.27 - lr: 0.000030
2021-07-22 23:03:36,758 epoch 8 - iter 98/141 - loss 0.12097142 - samples/sec: 134.39 - lr: 0.000030
2021-07-22 23:03:39,984 epoch 8 - iter 112/141 - loss 0.12052681 - samples/sec: 138.92 - lr: 0.000030
2021-07-22 23:03:43,296 epoch 8 - iter 126/141 - loss 0.12131214 - samples/sec: 135.31 - lr: 0.000030
2021-07-22 23:03:46,637 epoch 8 - iter 140/141 - loss 0.11768648 - samples/sec: 134.14 - lr: 0.000030
2021-07-22 23:03:46,810 ----------------------------------------------------------------------------------------------------
2021-07-22 23:03:46,810 EPOCH 8 done: loss 0.1170 - lr 0.0000300
2021-07-22 23:03:48,883 DEV : loss 0.03736470267176628 - score 0.993
2021-07-22 23:03:48,908 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:03:52,913 ----------------------------------------------------------------------------------------------------
2021-07-22 23:03:56,527 epoch 9 - iter 14/141 - loss 0.12715438 - samples/sec: 124.03 - lr: 0.000030
2021-07-22 23:03:59,712 epoch 9 - iter 28/141 - loss 0.13241454 - samples/sec: 140.74 - lr: 0.000030
2021-07-22 23:04:03,109 epoch 9 - iter 42/141 - loss 0.12935977 - samples/sec: 131.91 - lr: 0.000030
2021-07-22 23:04:06,511 epoch 9 - iter 56/141 - loss 0.12631618 - samples/sec: 131.74 - lr: 0.000030
2021-07-22 23:04:09,748 epoch 9 - iter 70/141 - loss 0.12369421 - samples/sec: 138.43 - lr: 0.000030
2021-07-22 23:04:12,926 epoch 9 - iter 84/141 - loss 0.12715692 - samples/sec: 140.99 - lr: 0.000030
2021-07-22 23:04:16,316 epoch 9 - iter 98/141 - loss 0.12278164 - samples/sec: 132.21 - lr: 0.000030
2021-07-22 23:04:19,716 epoch 9 - iter 112/141 - loss 0.12222534 - samples/sec: 131.77 - lr: 0.000030
2021-07-22 23:04:23,172 epoch 9 - iter 126/141 - loss 0.12065335 - samples/sec: 129.67 - lr: 0.000030
2021-07-22 23:04:26,537 epoch 9 - iter 140/141 - loss 0.11850239 - samples/sec: 133.19 - lr: 0.000030
2021-07-22 23:04:26,676 ----------------------------------------------------------------------------------------------------
2021-07-22 23:04:26,677 EPOCH 9 done: loss 0.1178 - lr 0.0000300
2021-07-22 23:04:28,766 DEV : loss 0.03768330439925194 - score 0.993
2021-07-22 23:04:28,791 BAD EPOCHS (no improvement): 1
2021-07-22 23:04:28,791 ----------------------------------------------------------------------------------------------------
2021-07-22 23:04:32,110 epoch 10 - iter 14/141 - loss 0.09979660 - samples/sec: 135.06 - lr: 0.000030
2021-07-22 23:04:35,518 epoch 10 - iter 28/141 - loss 0.10630957 - samples/sec: 131.48 - lr: 0.000030
2021-07-22 23:04:38,802 epoch 10 - iter 42/141 - loss 0.10236163 - samples/sec: 136.46 - lr: 0.000030
2021-07-22 23:04:42,228 epoch 10 - iter 56/141 - loss 0.10638233 - samples/sec: 130.81 - lr: 0.000030
2021-07-22 23:04:45,648 epoch 10 - iter 70/141 - loss 0.10822124 - samples/sec: 131.04 - lr: 0.000030
2021-07-22 23:04:48,990 epoch 10 - iter 84/141 - loss 0.10330580 - samples/sec: 134.08 - lr: 0.000030
2021-07-22 23:04:52,379 epoch 10 - iter 98/141 - loss 0.10428167 - samples/sec: 132.22 - lr: 0.000030
2021-07-22 23:04:55,798 epoch 10 - iter 112/141 - loss 0.10539984 - samples/sec: 131.06 - lr: 0.000030
2021-07-22 23:04:59,051 epoch 10 - iter 126/141 - loss 0.10547617 - samples/sec: 137.74 - lr: 0.000030
2021-07-22 23:05:02,283 epoch 10 - iter 140/141 - loss 0.10782839 - samples/sec: 138.66 - lr: 0.000030
2021-07-22 23:05:02,440 ----------------------------------------------------------------------------------------------------
2021-07-22 23:05:02,440 EPOCH 10 done: loss 0.1071 - lr 0.0000300
2021-07-22 23:05:04,511 DEV : loss 0.034339819103479385 - score 0.993
2021-07-22 23:05:04,536 BAD EPOCHS (no improvement): 2
2021-07-22 23:05:04,536 ----------------------------------------------------------------------------------------------------
2021-07-22 23:05:07,873 epoch 11 - iter 14/141 - loss 0.09999130 - samples/sec: 134.33 - lr: 0.000030
2021-07-22 23:05:11,272 epoch 11 - iter 28/141 - loss 0.10337540 - samples/sec: 131.87 - lr: 0.000030
2021-07-22 23:05:14,592 epoch 11 - iter 42/141 - loss 0.10181450 - samples/sec: 134.98 - lr: 0.000030
2021-07-22 23:05:17,907 epoch 11 - iter 56/141 - loss 0.09948430 - samples/sec: 135.18 - lr: 0.000030
2021-07-22 23:05:21,269 epoch 11 - iter 70/141 - loss 0.10314962 - samples/sec: 133.27 - lr: 0.000030
2021-07-22 23:05:24,560 epoch 11 - iter 84/141 - loss 0.09920211 - samples/sec: 136.18 - lr: 0.000030
2021-07-22 23:05:27,876 epoch 11 - iter 98/141 - loss 0.09859058 - samples/sec: 135.13 - lr: 0.000030
2021-07-22 23:05:31,355 epoch 11 - iter 112/141 - loss 0.09810218 - samples/sec: 128.78 - lr: 0.000030
2021-07-22 23:05:34,675 epoch 11 - iter 126/141 - loss 0.09820941 - samples/sec: 134.98 - lr: 0.000030
2021-07-22 23:05:37,975 epoch 11 - iter 140/141 - loss 0.09809931 - samples/sec: 135.78 - lr: 0.000030
2021-07-22 23:05:38,107 ----------------------------------------------------------------------------------------------------
2021-07-22 23:05:38,108 EPOCH 11 done: loss 0.0995 - lr 0.0000300
2021-07-22 23:05:40,184 DEV : loss 0.036232225596904755 - score 0.993
2021-07-22 23:05:40,209 BAD EPOCHS (no improvement): 3
2021-07-22 23:05:40,209 ----------------------------------------------------------------------------------------------------
2021-07-22 23:05:43,548 epoch 12 - iter 14/141 - loss 0.08445882 - samples/sec: 134.24 - lr: 0.000030
2021-07-22 23:05:46,884 epoch 12 - iter 28/141 - loss 0.09849820 - samples/sec: 134.34 - lr: 0.000030
2021-07-22 23:05:50,308 epoch 12 - iter 42/141 - loss 0.09819894 - samples/sec: 130.88 - lr: 0.000030
2021-07-22 23:05:53,583 epoch 12 - iter 56/141 - loss 0.09900408 - samples/sec: 136.80 - lr: 0.000030
2021-07-22 23:05:56,853 epoch 12 - iter 70/141 - loss 0.09763677 - samples/sec: 137.05 - lr: 0.000030
2021-07-22 23:06:00,219 epoch 12 - iter 84/141 - loss 0.09702745 - samples/sec: 133.14 - lr: 0.000030
2021-07-22 23:06:03,500 epoch 12 - iter 98/141 - loss 0.09624809 - samples/sec: 136.59 - lr: 0.000030
2021-07-22 23:06:06,937 epoch 12 - iter 112/141 - loss 0.09411247 - samples/sec: 130.39 - lr: 0.000030
2021-07-22 23:06:10,424 epoch 12 - iter 126/141 - loss 0.09505809 - samples/sec: 128.48 - lr: 0.000030
2021-07-22 23:06:13,747 epoch 12 - iter 140/141 - loss 0.09548989 - samples/sec: 134.87 - lr: 0.000030
2021-07-22 23:06:13,888 ----------------------------------------------------------------------------------------------------
2021-07-22 23:06:13,888 EPOCH 12 done: loss 0.0949 - lr 0.0000300
2021-07-22 23:06:15,961 DEV : loss 0.030093451961874962 - score 0.993
2021-07-22 23:06:15,986 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:06:20,206 ----------------------------------------------------------------------------------------------------
2021-07-22 23:06:23,646 epoch 13 - iter 14/141 - loss 0.13094866 - samples/sec: 130.29 - lr: 0.000030
2021-07-22 23:06:26,886 epoch 13 - iter 28/141 - loss 0.09914408 - samples/sec: 138.30 - lr: 0.000030
2021-07-22 23:06:30,279 epoch 13 - iter 42/141 - loss 0.09610899 - samples/sec: 132.09 - lr: 0.000030
2021-07-22 23:06:33,616 epoch 13 - iter 56/141 - loss 0.09013549 - samples/sec: 134.27 - lr: 0.000030
2021-07-22 23:06:36,880 epoch 13 - iter 70/141 - loss 0.09147936 - samples/sec: 137.30 - lr: 0.000030
2021-07-22 23:06:40,258 epoch 13 - iter 84/141 - loss 0.09381162 - samples/sec: 132.68 - lr: 0.000030
2021-07-22 23:06:43,534 epoch 13 - iter 98/141 - loss 0.09548899 - samples/sec: 136.77 - lr: 0.000030
2021-07-22 23:06:47,076 epoch 13 - iter 112/141 - loss 0.09484259 - samples/sec: 126.52 - lr: 0.000030
2021-07-22 23:06:50,376 epoch 13 - iter 126/141 - loss 0.09449121 - samples/sec: 135.78 - lr: 0.000030
2021-07-22 23:06:53,728 epoch 13 - iter 140/141 - loss 0.09524954 - samples/sec: 133.69 - lr: 0.000030
2021-07-22 23:06:53,862 ----------------------------------------------------------------------------------------------------
2021-07-22 23:06:53,862 EPOCH 13 done: loss 0.0948 - lr 0.0000300
2021-07-22 23:06:55,936 DEV : loss 0.029104124754667282 - score 0.993
2021-07-22 23:06:55,961 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:07:00,506 ----------------------------------------------------------------------------------------------------
2021-07-22 23:07:04,010 epoch 14 - iter 14/141 - loss 0.09158165 - samples/sec: 127.93 - lr: 0.000030
2021-07-22 23:07:07,397 epoch 14 - iter 28/141 - loss 0.09250519 - samples/sec: 132.33 - lr: 0.000030
2021-07-22 23:07:10,817 epoch 14 - iter 42/141 - loss 0.09251296 - samples/sec: 131.02 - lr: 0.000030
2021-07-22 23:07:14,191 epoch 14 - iter 56/141 - loss 0.09696907 - samples/sec: 132.80 - lr: 0.000030
2021-07-22 23:07:17,595 epoch 14 - iter 70/141 - loss 0.10320098 - samples/sec: 131.65 - lr: 0.000030
2021-07-22 23:07:20,844 epoch 14 - iter 84/141 - loss 0.10283437 - samples/sec: 137.93 - lr: 0.000030
2021-07-22 23:07:24,257 epoch 14 - iter 98/141 - loss 0.10362593 - samples/sec: 131.32 - lr: 0.000030
2021-07-22 23:07:27,664 epoch 14 - iter 112/141 - loss 0.10039066 - samples/sec: 131.52 - lr: 0.000030
2021-07-22 23:07:30,969 epoch 14 - iter 126/141 - loss 0.09868585 - samples/sec: 135.59 - lr: 0.000030
2021-07-22 23:07:34,237 epoch 14 - iter 140/141 - loss 0.09724072 - samples/sec: 137.13 - lr: 0.000030
2021-07-22 23:07:34,366 ----------------------------------------------------------------------------------------------------
2021-07-22 23:07:34,366 EPOCH 14 done: loss 0.0988 - lr 0.0000300
2021-07-22 23:07:36,439 DEV : loss 0.03063701093196869 - score 0.9939
2021-07-22 23:07:36,464 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:07:40,605 ----------------------------------------------------------------------------------------------------
2021-07-22 23:07:44,017 epoch 15 - iter 14/141 - loss 0.08334576 - samples/sec: 131.42 - lr: 0.000030
2021-07-22 23:07:47,263 epoch 15 - iter 28/141 - loss 0.09825351 - samples/sec: 138.04 - lr: 0.000030
2021-07-22 23:07:50,674 epoch 15 - iter 42/141 - loss 0.09720027 - samples/sec: 131.36 - lr: 0.000030
2021-07-22 23:07:54,031 epoch 15 - iter 56/141 - loss 0.09375674 - samples/sec: 133.49 - lr: 0.000030
2021-07-22 23:07:57,231 epoch 15 - iter 70/141 - loss 0.09187881 - samples/sec: 140.04 - lr: 0.000030
2021-07-22 23:08:00,649 epoch 15 - iter 84/141 - loss 0.09028106 - samples/sec: 131.13 - lr: 0.000030
2021-07-22 23:08:04,033 epoch 15 - iter 98/141 - loss 0.09326919 - samples/sec: 132.39 - lr: 0.000030
2021-07-22 23:08:07,324 epoch 15 - iter 112/141 - loss 0.09301801 - samples/sec: 136.19 - lr: 0.000030
2021-07-22 23:08:10,674 epoch 15 - iter 126/141 - loss 0.09319825 - samples/sec: 133.74 - lr: 0.000030
2021-07-22 23:08:14,044 epoch 15 - iter 140/141 - loss 0.09368256 - samples/sec: 132.97 - lr: 0.000030
2021-07-22 23:08:14,202 ----------------------------------------------------------------------------------------------------
2021-07-22 23:08:14,202 EPOCH 15 done: loss 0.0933 - lr 0.0000300
2021-07-22 23:08:16,274 DEV : loss 0.03201049193739891 - score 0.993
2021-07-22 23:08:16,299 BAD EPOCHS (no improvement): 1
2021-07-22 23:08:16,299 ----------------------------------------------------------------------------------------------------
2021-07-22 23:08:19,631 epoch 16 - iter 14/141 - loss 0.10846161 - samples/sec: 134.54 - lr: 0.000030
2021-07-22 23:08:22,967 epoch 16 - iter 28/141 - loss 0.10979503 - samples/sec: 134.31 - lr: 0.000030
2021-07-22 23:08:26,380 epoch 16 - iter 42/141 - loss 0.09879285 - samples/sec: 131.28 - lr: 0.000030
2021-07-22 23:08:29,763 epoch 16 - iter 56/141 - loss 0.09630422 - samples/sec: 132.50 - lr: 0.000030
2021-07-22 23:08:33,198 epoch 16 - iter 70/141 - loss 0.09539811 - samples/sec: 130.43 - lr: 0.000030
2021-07-22 23:08:36,440 epoch 16 - iter 84/141 - loss 0.09143705 - samples/sec: 138.22 - lr: 0.000030
2021-07-22 23:08:39,703 epoch 16 - iter 98/141 - loss 0.09029409 - samples/sec: 137.36 - lr: 0.000030
2021-07-22 23:08:43,050 epoch 16 - iter 112/141 - loss 0.09058856 - samples/sec: 133.89 - lr: 0.000030
2021-07-22 23:08:46,487 epoch 16 - iter 126/141 - loss 0.09141414 - samples/sec: 130.36 - lr: 0.000030
2021-07-22 23:08:49,800 epoch 16 - iter 140/141 - loss 0.08968714 - samples/sec: 135.26 - lr: 0.000030
2021-07-22 23:08:49,966 ----------------------------------------------------------------------------------------------------
2021-07-22 23:08:49,966 EPOCH 16 done: loss 0.0904 - lr 0.0000300
2021-07-22 23:08:52,045 DEV : loss 0.039543792605400085 - score 0.993
2021-07-22 23:08:52,070 BAD EPOCHS (no improvement): 2
2021-07-22 23:08:52,070 ----------------------------------------------------------------------------------------------------
2021-07-22 23:08:55,485 epoch 17 - iter 14/141 - loss 0.10408344 - samples/sec: 131.28 - lr: 0.000030
2021-07-22 23:08:58,869 epoch 17 - iter 28/141 - loss 0.08976458 - samples/sec: 132.41 - lr: 0.000030
2021-07-22 23:09:02,353 epoch 17 - iter 42/141 - loss 0.09661437 - samples/sec: 128.62 - lr: 0.000030
2021-07-22 23:09:05,599 epoch 17 - iter 56/141 - loss 0.09340175 - samples/sec: 138.04 - lr: 0.000030
2021-07-22 23:09:08,884 epoch 17 - iter 70/141 - loss 0.09007126 - samples/sec: 136.44 - lr: 0.000030
2021-07-22 23:09:12,220 epoch 17 - iter 84/141 - loss 0.08415897 - samples/sec: 134.33 - lr: 0.000030
2021-07-22 23:09:15,579 epoch 17 - iter 98/141 - loss 0.08315749 - samples/sec: 133.39 - lr: 0.000030
2021-07-22 23:09:18,828 epoch 17 - iter 112/141 - loss 0.08756991 - samples/sec: 137.90 - lr: 0.000030
2021-07-22 23:09:22,166 epoch 17 - iter 126/141 - loss 0.08610231 - samples/sec: 134.27 - lr: 0.000030
2021-07-22 23:09:25,575 epoch 17 - iter 140/141 - loss 0.08460813 - samples/sec: 131.43 - lr: 0.000030
2021-07-22 23:09:25,731 ----------------------------------------------------------------------------------------------------
2021-07-22 23:09:25,731 EPOCH 17 done: loss 0.0842 - lr 0.0000300
2021-07-22 23:09:27,811 DEV : loss 0.02883746288716793 - score 0.9939
2021-07-22 23:09:27,836 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:09:31,982 ----------------------------------------------------------------------------------------------------
2021-07-22 23:09:35,295 epoch 18 - iter 14/141 - loss 0.09524604 - samples/sec: 135.32 - lr: 0.000030
2021-07-22 23:09:38,647 epoch 18 - iter 28/141 - loss 0.07825170 - samples/sec: 133.72 - lr: 0.000030
2021-07-22 23:09:41,908 epoch 18 - iter 42/141 - loss 0.08006127 - samples/sec: 137.40 - lr: 0.000030
2021-07-22 23:09:45,296 epoch 18 - iter 56/141 - loss 0.08063428 - samples/sec: 132.27 - lr: 0.000030
2021-07-22 23:09:48,723 epoch 18 - iter 70/141 - loss 0.07518978 - samples/sec: 130.76 - lr: 0.000030
2021-07-22 23:09:52,001 epoch 18 - iter 84/141 - loss 0.07764604 - samples/sec: 136.72 - lr: 0.000030
2021-07-22 23:09:55,352 epoch 18 - iter 98/141 - loss 0.08221441 - samples/sec: 133.71 - lr: 0.000030
2021-07-22 23:09:58,799 epoch 18 - iter 112/141 - loss 0.08216365 - samples/sec: 130.02 - lr: 0.000030
2021-07-22 23:10:02,124 epoch 18 - iter 126/141 - loss 0.08269130 - samples/sec: 134.76 - lr: 0.000030
2021-07-22 23:10:05,450 epoch 18 - iter 140/141 - loss 0.08073382 - samples/sec: 134.72 - lr: 0.000030
2021-07-22 23:10:05,626 ----------------------------------------------------------------------------------------------------
2021-07-22 23:10:05,626 EPOCH 18 done: loss 0.0803 - lr 0.0000300
2021-07-22 23:10:07,698 DEV : loss 0.033167533576488495 - score 0.9939
2021-07-22 23:10:07,723 BAD EPOCHS (no improvement): 1
2021-07-22 23:10:07,723 ----------------------------------------------------------------------------------------------------
2021-07-22 23:10:10,843 epoch 19 - iter 14/141 - loss 0.09900418 - samples/sec: 143.66 - lr: 0.000030
2021-07-22 23:10:14,332 epoch 19 - iter 28/141 - loss 0.09263383 - samples/sec: 128.43 - lr: 0.000030
2021-07-22 23:10:17,719 epoch 19 - iter 42/141 - loss 0.08489199 - samples/sec: 132.33 - lr: 0.000030
2021-07-22 23:10:21,019 epoch 19 - iter 56/141 - loss 0.08055518 - samples/sec: 135.79 - lr: 0.000030
2021-07-22 23:10:24,411 epoch 19 - iter 70/141 - loss 0.08344012 - samples/sec: 132.09 - lr: 0.000030
2021-07-22 23:10:27,881 epoch 19 - iter 84/141 - loss 0.07992306 - samples/sec: 129.15 - lr: 0.000030
2021-07-22 23:10:31,204 epoch 19 - iter 98/141 - loss 0.08574649 - samples/sec: 134.87 - lr: 0.000030
2021-07-22 23:10:34,534 epoch 19 - iter 112/141 - loss 0.08599756 - samples/sec: 134.56 - lr: 0.000030
2021-07-22 23:10:37,779 epoch 19 - iter 126/141 - loss 0.08543053 - samples/sec: 138.10 - lr: 0.000030
2021-07-22 23:10:41,175 epoch 19 - iter 140/141 - loss 0.08644491 - samples/sec: 131.95 - lr: 0.000030
2021-07-22 23:10:41,314 ----------------------------------------------------------------------------------------------------
2021-07-22 23:10:41,315 EPOCH 19 done: loss 0.0859 - lr 0.0000300
2021-07-22 23:10:43,415 DEV : loss 0.029752075672149658 - score 0.9947
2021-07-22 23:10:43,456 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:10:47,347 ----------------------------------------------------------------------------------------------------
2021-07-22 23:10:50,696 epoch 20 - iter 14/141 - loss 0.08299082 - samples/sec: 133.87 - lr: 0.000030
2021-07-22 23:10:54,116 epoch 20 - iter 28/141 - loss 0.08272518 - samples/sec: 131.05 - lr: 0.000030
2021-07-22 23:10:57,352 epoch 20 - iter 42/141 - loss 0.08061670 - samples/sec: 138.48 - lr: 0.000030
2021-07-22 23:11:00,760 epoch 20 - iter 56/141 - loss 0.08492718 - samples/sec: 131.47 - lr: 0.000030
2021-07-22 23:11:04,102 epoch 20 - iter 70/141 - loss 0.08035974 - samples/sec: 134.10 - lr: 0.000030
2021-07-22 23:11:07,443 epoch 20 - iter 84/141 - loss 0.07830677 - samples/sec: 134.13 - lr: 0.000030
2021-07-22 23:11:10,760 epoch 20 - iter 98/141 - loss 0.08031507 - samples/sec: 135.11 - lr: 0.000030
2021-07-22 23:11:14,232 epoch 20 - iter 112/141 - loss 0.07801331 - samples/sec: 129.06 - lr: 0.000030
2021-07-22 23:11:17,511 epoch 20 - iter 126/141 - loss 0.08085846 - samples/sec: 136.65 - lr: 0.000030
2021-07-22 23:11:20,897 epoch 20 - iter 140/141 - loss 0.08052371 - samples/sec: 132.36 - lr: 0.000030
2021-07-22 23:11:21,027 ----------------------------------------------------------------------------------------------------
2021-07-22 23:11:21,028 EPOCH 20 done: loss 0.0803 - lr 0.0000300
2021-07-22 23:11:23,099 DEV : loss 0.030597124248743057 - score 0.993
2021-07-22 23:11:23,124 BAD EPOCHS (no improvement): 1
2021-07-22 23:11:23,124 ----------------------------------------------------------------------------------------------------
2021-07-22 23:11:26,507 epoch 21 - iter 14/141 - loss 0.07972231 - samples/sec: 132.53 - lr: 0.000030
2021-07-22 23:11:29,914 epoch 21 - iter 28/141 - loss 0.06970676 - samples/sec: 131.51 - lr: 0.000030
2021-07-22 23:11:33,099 epoch 21 - iter 42/141 - loss 0.06888011 - samples/sec: 140.70 - lr: 0.000030
2021-07-22 23:11:36,484 epoch 21 - iter 56/141 - loss 0.07033982 - samples/sec: 132.39 - lr: 0.000030
2021-07-22 23:11:39,828 epoch 21 - iter 70/141 - loss 0.07148611 - samples/sec: 134.00 - lr: 0.000030
2021-07-22 23:11:43,215 epoch 21 - iter 84/141 - loss 0.07546464 - samples/sec: 132.30 - lr: 0.000030
2021-07-22 23:11:46,647 epoch 21 - iter 98/141 - loss 0.07327828 - samples/sec: 130.59 - lr: 0.000030
2021-07-22 23:11:50,008 epoch 21 - iter 112/141 - loss 0.07409186 - samples/sec: 133.32 - lr: 0.000030
2021-07-22 23:11:53,282 epoch 21 - iter 126/141 - loss 0.07412036 - samples/sec: 136.86 - lr: 0.000030
2021-07-22 23:11:56,650 epoch 21 - iter 140/141 - loss 0.07135435 - samples/sec: 133.05 - lr: 0.000030
2021-07-22 23:11:56,783 ----------------------------------------------------------------------------------------------------
2021-07-22 23:11:56,783 EPOCH 21 done: loss 0.0715 - lr 0.0000300
2021-07-22 23:11:58,853 DEV : loss 0.039079900830984116 - score 0.993
2021-07-22 23:11:58,878 BAD EPOCHS (no improvement): 2
2021-07-22 23:11:58,878 ----------------------------------------------------------------------------------------------------
2021-07-22 23:12:02,325 epoch 22 - iter 14/141 - loss 0.05757955 - samples/sec: 130.02 - lr: 0.000030
2021-07-22 23:12:05,766 epoch 22 - iter 28/141 - loss 0.06445925 - samples/sec: 130.24 - lr: 0.000030
2021-07-22 23:12:08,920 epoch 22 - iter 42/141 - loss 0.06959674 - samples/sec: 142.12 - lr: 0.000030
2021-07-22 23:12:12,087 epoch 22 - iter 56/141 - loss 0.06730476 - samples/sec: 141.49 - lr: 0.000030
2021-07-22 23:12:15,367 epoch 22 - iter 70/141 - loss 0.07306519 - samples/sec: 136.63 - lr: 0.000030
2021-07-22 23:12:18,762 epoch 22 - iter 84/141 - loss 0.07160561 - samples/sec: 132.02 - lr: 0.000030
2021-07-22 23:12:22,179 epoch 22 - iter 98/141 - loss 0.07221094 - samples/sec: 131.15 - lr: 0.000030
2021-07-22 23:12:25,401 epoch 22 - iter 112/141 - loss 0.07089408 - samples/sec: 139.10 - lr: 0.000030
2021-07-22 23:12:28,696 epoch 22 - iter 126/141 - loss 0.07117722 - samples/sec: 136.00 - lr: 0.000030
2021-07-22 23:12:32,139 epoch 22 - iter 140/141 - loss 0.06993513 - samples/sec: 130.14 - lr: 0.000030
2021-07-22 23:12:32,284 ----------------------------------------------------------------------------------------------------
2021-07-22 23:12:32,284 EPOCH 22 done: loss 0.0696 - lr 0.0000300
2021-07-22 23:12:34,361 DEV : loss 0.03286346048116684 - score 0.993
2021-07-22 23:12:34,385 BAD EPOCHS (no improvement): 3
2021-07-22 23:12:34,385 ----------------------------------------------------------------------------------------------------
2021-07-22 23:12:37,775 epoch 23 - iter 14/141 - loss 0.09786773 - samples/sec: 132.23 - lr: 0.000030
2021-07-22 23:12:41,000 epoch 23 - iter 28/141 - loss 0.09392522 - samples/sec: 138.96 - lr: 0.000030
2021-07-22 23:12:44,349 epoch 23 - iter 42/141 - loss 0.08307076 - samples/sec: 133.82 - lr: 0.000030
2021-07-22 23:12:47,668 epoch 23 - iter 56/141 - loss 0.07909706 - samples/sec: 135.00 - lr: 0.000030
2021-07-22 23:12:51,027 epoch 23 - iter 70/141 - loss 0.08012882 - samples/sec: 133.39 - lr: 0.000030
2021-07-22 23:12:54,537 epoch 23 - iter 84/141 - loss 0.08189857 - samples/sec: 127.69 - lr: 0.000030
2021-07-22 23:12:58,019 epoch 23 - iter 98/141 - loss 0.07843502 - samples/sec: 128.68 - lr: 0.000030
2021-07-22 23:13:01,374 epoch 23 - iter 112/141 - loss 0.07799371 - samples/sec: 133.54 - lr: 0.000030
2021-07-22 23:13:04,688 epoch 23 - iter 126/141 - loss 0.07701546 - samples/sec: 135.26 - lr: 0.000030
2021-07-22 23:13:07,956 epoch 23 - iter 140/141 - loss 0.07590818 - samples/sec: 137.12 - lr: 0.000030
2021-07-22 23:13:08,097 ----------------------------------------------------------------------------------------------------
2021-07-22 23:13:08,097 EPOCH 23 done: loss 0.0766 - lr 0.0000300
2021-07-22 23:13:10,177 DEV : loss 0.026469912379980087 - score 0.9922
Epoch    23: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 23:13:10,202 BAD EPOCHS (no improvement): 4
2021-07-22 23:13:10,202 ----------------------------------------------------------------------------------------------------
2021-07-22 23:13:13,742 epoch 24 - iter 14/141 - loss 0.08590162 - samples/sec: 126.65 - lr: 0.000015
2021-07-22 23:13:17,087 epoch 24 - iter 28/141 - loss 0.07501683 - samples/sec: 133.95 - lr: 0.000015
2021-07-22 23:13:20,514 epoch 24 - iter 42/141 - loss 0.06402158 - samples/sec: 130.78 - lr: 0.000015
2021-07-22 23:13:23,753 epoch 24 - iter 56/141 - loss 0.06190836 - samples/sec: 138.33 - lr: 0.000015
2021-07-22 23:13:27,053 epoch 24 - iter 70/141 - loss 0.06246079 - samples/sec: 135.81 - lr: 0.000015
2021-07-22 23:13:30,297 epoch 24 - iter 84/141 - loss 0.06307230 - samples/sec: 138.16 - lr: 0.000015
2021-07-22 23:13:33,587 epoch 24 - iter 98/141 - loss 0.06174975 - samples/sec: 136.20 - lr: 0.000015
2021-07-22 23:13:36,871 epoch 24 - iter 112/141 - loss 0.05940557 - samples/sec: 136.46 - lr: 0.000015
2021-07-22 23:13:40,087 epoch 24 - iter 126/141 - loss 0.05807897 - samples/sec: 139.35 - lr: 0.000015
2021-07-22 23:13:43,530 epoch 24 - iter 140/141 - loss 0.06018434 - samples/sec: 130.15 - lr: 0.000015
2021-07-22 23:13:43,695 ----------------------------------------------------------------------------------------------------
2021-07-22 23:13:43,695 EPOCH 24 done: loss 0.0598 - lr 0.0000150
2021-07-22 23:13:45,765 DEV : loss 0.037692733108997345 - score 0.9912
2021-07-22 23:13:45,790 BAD EPOCHS (no improvement): 1
2021-07-22 23:13:45,790 ----------------------------------------------------------------------------------------------------
2021-07-22 23:13:49,026 epoch 25 - iter 14/141 - loss 0.05498960 - samples/sec: 138.51 - lr: 0.000015
2021-07-22 23:13:52,300 epoch 25 - iter 28/141 - loss 0.06793896 - samples/sec: 136.90 - lr: 0.000015
2021-07-22 23:13:55,776 epoch 25 - iter 42/141 - loss 0.06864692 - samples/sec: 128.89 - lr: 0.000015
2021-07-22 23:13:59,055 epoch 25 - iter 56/141 - loss 0.06775506 - samples/sec: 136.69 - lr: 0.000015
2021-07-22 23:14:02,328 epoch 25 - iter 70/141 - loss 0.06479835 - samples/sec: 136.88 - lr: 0.000015
2021-07-22 23:14:05,733 epoch 25 - iter 84/141 - loss 0.06473456 - samples/sec: 131.62 - lr: 0.000015
2021-07-22 23:14:09,128 epoch 25 - iter 98/141 - loss 0.06644229 - samples/sec: 131.97 - lr: 0.000015
2021-07-22 23:14:12,435 epoch 25 - iter 112/141 - loss 0.06400171 - samples/sec: 135.54 - lr: 0.000015
2021-07-22 23:14:15,716 epoch 25 - iter 126/141 - loss 0.06460938 - samples/sec: 136.56 - lr: 0.000015
2021-07-22 23:14:19,059 epoch 25 - iter 140/141 - loss 0.06584250 - samples/sec: 134.07 - lr: 0.000015
2021-07-22 23:14:19,218 ----------------------------------------------------------------------------------------------------
2021-07-22 23:14:19,218 EPOCH 25 done: loss 0.0655 - lr 0.0000150
2021-07-22 23:14:21,290 DEV : loss 0.026612283661961555 - score 0.993
2021-07-22 23:14:21,315 BAD EPOCHS (no improvement): 2
2021-07-22 23:14:21,315 ----------------------------------------------------------------------------------------------------
2021-07-22 23:14:24,551 epoch 26 - iter 14/141 - loss 0.07382206 - samples/sec: 138.50 - lr: 0.000015
2021-07-22 23:14:27,816 epoch 26 - iter 28/141 - loss 0.06352447 - samples/sec: 137.26 - lr: 0.000015
2021-07-22 23:14:31,179 epoch 26 - iter 42/141 - loss 0.06652849 - samples/sec: 133.24 - lr: 0.000015
2021-07-22 23:14:34,513 epoch 26 - iter 56/141 - loss 0.06505132 - samples/sec: 134.41 - lr: 0.000015
2021-07-22 23:14:37,904 epoch 26 - iter 70/141 - loss 0.06626420 - samples/sec: 132.16 - lr: 0.000015
2021-07-22 23:14:41,178 epoch 26 - iter 84/141 - loss 0.06385795 - samples/sec: 136.89 - lr: 0.000015
2021-07-22 23:14:44,522 epoch 26 - iter 98/141 - loss 0.06325132 - samples/sec: 134.01 - lr: 0.000015
2021-07-22 23:14:47,928 epoch 26 - iter 112/141 - loss 0.06615545 - samples/sec: 131.56 - lr: 0.000015
2021-07-22 23:14:51,324 epoch 26 - iter 126/141 - loss 0.06547811 - samples/sec: 131.97 - lr: 0.000015
2021-07-22 23:14:54,694 epoch 26 - iter 140/141 - loss 0.06507807 - samples/sec: 132.94 - lr: 0.000015
2021-07-22 23:14:54,816 ----------------------------------------------------------------------------------------------------
2021-07-22 23:14:54,816 EPOCH 26 done: loss 0.0652 - lr 0.0000150
2021-07-22 23:14:56,889 DEV : loss 0.030048206448554993 - score 0.9939
2021-07-22 23:14:56,913 BAD EPOCHS (no improvement): 3
2021-07-22 23:14:56,914 ----------------------------------------------------------------------------------------------------
2021-07-22 23:15:00,191 epoch 27 - iter 14/141 - loss 0.04723756 - samples/sec: 136.78 - lr: 0.000015
2021-07-22 23:15:03,459 epoch 27 - iter 28/141 - loss 0.04381197 - samples/sec: 137.12 - lr: 0.000015
2021-07-22 23:15:06,798 epoch 27 - iter 42/141 - loss 0.05216102 - samples/sec: 134.22 - lr: 0.000015
2021-07-22 23:15:10,088 epoch 27 - iter 56/141 - loss 0.05473478 - samples/sec: 136.19 - lr: 0.000015
2021-07-22 23:15:13,590 epoch 27 - iter 70/141 - loss 0.05463439 - samples/sec: 127.96 - lr: 0.000015
2021-07-22 23:15:16,903 epoch 27 - iter 84/141 - loss 0.05596518 - samples/sec: 135.26 - lr: 0.000015
2021-07-22 23:15:20,223 epoch 27 - iter 98/141 - loss 0.06047163 - samples/sec: 135.00 - lr: 0.000015
2021-07-22 23:15:23,506 epoch 27 - iter 112/141 - loss 0.06176400 - samples/sec: 136.48 - lr: 0.000015
2021-07-22 23:15:26,783 epoch 27 - iter 126/141 - loss 0.06303462 - samples/sec: 136.74 - lr: 0.000015
2021-07-22 23:15:30,148 epoch 27 - iter 140/141 - loss 0.06442658 - samples/sec: 133.21 - lr: 0.000015
2021-07-22 23:15:30,271 ----------------------------------------------------------------------------------------------------
2021-07-22 23:15:30,272 EPOCH 27 done: loss 0.0660 - lr 0.0000150
2021-07-22 23:15:32,340 DEV : loss 0.02602367289364338 - score 0.993
Epoch    27: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 23:15:32,365 BAD EPOCHS (no improvement): 4
2021-07-22 23:15:32,366 ----------------------------------------------------------------------------------------------------
2021-07-22 23:15:35,756 epoch 28 - iter 14/141 - loss 0.06621177 - samples/sec: 132.22 - lr: 0.000008
2021-07-22 23:15:39,159 epoch 28 - iter 28/141 - loss 0.07069071 - samples/sec: 131.69 - lr: 0.000008
2021-07-22 23:15:42,560 epoch 28 - iter 42/141 - loss 0.06951698 - samples/sec: 131.76 - lr: 0.000008
2021-07-22 23:15:45,809 epoch 28 - iter 56/141 - loss 0.06763107 - samples/sec: 137.93 - lr: 0.000008
2021-07-22 23:15:49,103 epoch 28 - iter 70/141 - loss 0.06609090 - samples/sec: 136.03 - lr: 0.000008
2021-07-22 23:15:52,502 epoch 28 - iter 84/141 - loss 0.06717656 - samples/sec: 131.82 - lr: 0.000008
2021-07-22 23:15:55,647 epoch 28 - iter 98/141 - loss 0.06725201 - samples/sec: 142.51 - lr: 0.000008
2021-07-22 23:15:59,082 epoch 28 - iter 112/141 - loss 0.06683344 - samples/sec: 130.44 - lr: 0.000008
2021-07-22 23:16:02,388 epoch 28 - iter 126/141 - loss 0.06648265 - samples/sec: 135.55 - lr: 0.000008
2021-07-22 23:16:05,669 epoch 28 - iter 140/141 - loss 0.06561245 - samples/sec: 136.60 - lr: 0.000008
2021-07-22 23:16:05,793 ----------------------------------------------------------------------------------------------------
2021-07-22 23:16:05,794 EPOCH 28 done: loss 0.0659 - lr 0.0000075
2021-07-22 23:16:07,869 DEV : loss 0.027106475085020065 - score 0.993
2021-07-22 23:16:07,894 BAD EPOCHS (no improvement): 1
2021-07-22 23:16:07,895 ----------------------------------------------------------------------------------------------------
2021-07-22 23:16:11,388 epoch 29 - iter 14/141 - loss 0.05865013 - samples/sec: 128.33 - lr: 0.000008
2021-07-22 23:16:14,828 epoch 29 - iter 28/141 - loss 0.06229856 - samples/sec: 130.25 - lr: 0.000008
2021-07-22 23:16:18,164 epoch 29 - iter 42/141 - loss 0.05558286 - samples/sec: 134.35 - lr: 0.000008
2021-07-22 23:16:21,574 epoch 29 - iter 56/141 - loss 0.05933729 - samples/sec: 131.38 - lr: 0.000008
2021-07-22 23:16:24,837 epoch 29 - iter 70/141 - loss 0.06377011 - samples/sec: 137.36 - lr: 0.000008
2021-07-22 23:16:28,101 epoch 29 - iter 84/141 - loss 0.06044271 - samples/sec: 137.29 - lr: 0.000008
2021-07-22 23:16:31,498 epoch 29 - iter 98/141 - loss 0.06205442 - samples/sec: 131.89 - lr: 0.000008
2021-07-22 23:16:34,715 epoch 29 - iter 112/141 - loss 0.06022312 - samples/sec: 139.33 - lr: 0.000008
2021-07-22 23:16:38,136 epoch 29 - iter 126/141 - loss 0.05976563 - samples/sec: 130.99 - lr: 0.000008
2021-07-22 23:16:41,436 epoch 29 - iter 140/141 - loss 0.05946759 - samples/sec: 135.78 - lr: 0.000008
2021-07-22 23:16:41,575 ----------------------------------------------------------------------------------------------------
2021-07-22 23:16:41,575 EPOCH 29 done: loss 0.0591 - lr 0.0000075
2021-07-22 23:16:43,648 DEV : loss 0.028911232948303223 - score 0.993
2021-07-22 23:16:43,673 BAD EPOCHS (no improvement): 2
2021-07-22 23:16:43,673 ----------------------------------------------------------------------------------------------------
2021-07-22 23:16:46,887 epoch 30 - iter 14/141 - loss 0.04486666 - samples/sec: 139.49 - lr: 0.000008
2021-07-22 23:16:50,220 epoch 30 - iter 28/141 - loss 0.05633946 - samples/sec: 134.43 - lr: 0.000008
2021-07-22 23:16:53,412 epoch 30 - iter 42/141 - loss 0.06299414 - samples/sec: 140.41 - lr: 0.000008
2021-07-22 23:16:56,870 epoch 30 - iter 56/141 - loss 0.06190757 - samples/sec: 129.56 - lr: 0.000008
2021-07-22 23:17:00,345 epoch 30 - iter 70/141 - loss 0.06197068 - samples/sec: 128.98 - lr: 0.000008
2021-07-22 23:17:03,739 epoch 30 - iter 84/141 - loss 0.06141111 - samples/sec: 132.01 - lr: 0.000008
2021-07-22 23:17:07,048 epoch 30 - iter 98/141 - loss 0.06629257 - samples/sec: 135.43 - lr: 0.000008
2021-07-22 23:17:10,336 epoch 30 - iter 112/141 - loss 0.06621183 - samples/sec: 136.28 - lr: 0.000008
2021-07-22 23:17:13,673 epoch 30 - iter 126/141 - loss 0.06384521 - samples/sec: 134.30 - lr: 0.000008
2021-07-22 23:17:17,012 epoch 30 - iter 140/141 - loss 0.06199023 - samples/sec: 134.22 - lr: 0.000008
2021-07-22 23:17:17,166 ----------------------------------------------------------------------------------------------------
2021-07-22 23:17:17,167 EPOCH 30 done: loss 0.0617 - lr 0.0000075
2021-07-22 23:17:19,246 DEV : loss 0.030307482928037643 - score 0.993
2021-07-22 23:17:19,271 BAD EPOCHS (no improvement): 3
2021-07-22 23:17:19,271 ----------------------------------------------------------------------------------------------------
2021-07-22 23:17:22,615 epoch 31 - iter 14/141 - loss 0.02999106 - samples/sec: 134.06 - lr: 0.000008
2021-07-22 23:17:26,020 epoch 31 - iter 28/141 - loss 0.05346183 - samples/sec: 131.61 - lr: 0.000008
2021-07-22 23:17:29,441 epoch 31 - iter 42/141 - loss 0.05824932 - samples/sec: 130.97 - lr: 0.000008
2021-07-22 23:17:32,740 epoch 31 - iter 56/141 - loss 0.05974038 - samples/sec: 135.85 - lr: 0.000008
2021-07-22 23:17:36,052 epoch 31 - iter 70/141 - loss 0.06088995 - samples/sec: 135.27 - lr: 0.000008
2021-07-22 23:17:39,448 epoch 31 - iter 84/141 - loss 0.06146991 - samples/sec: 131.96 - lr: 0.000008
2021-07-22 23:17:42,750 epoch 31 - iter 98/141 - loss 0.06166657 - samples/sec: 135.71 - lr: 0.000008
2021-07-22 23:17:46,079 epoch 31 - iter 112/141 - loss 0.06262153 - samples/sec: 134.60 - lr: 0.000008
2021-07-22 23:17:49,421 epoch 31 - iter 126/141 - loss 0.06343559 - samples/sec: 134.12 - lr: 0.000008
2021-07-22 23:17:52,827 epoch 31 - iter 140/141 - loss 0.06259119 - samples/sec: 131.55 - lr: 0.000008
2021-07-22 23:17:52,980 ----------------------------------------------------------------------------------------------------
2021-07-22 23:17:52,981 EPOCH 31 done: loss 0.0628 - lr 0.0000075
2021-07-22 23:17:55,054 DEV : loss 0.031804993748664856 - score 0.993
Epoch    31: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 23:17:55,078 BAD EPOCHS (no improvement): 4
2021-07-22 23:17:55,079 ----------------------------------------------------------------------------------------------------
2021-07-22 23:17:58,443 epoch 32 - iter 14/141 - loss 0.07990304 - samples/sec: 133.22 - lr: 0.000004
2021-07-22 23:18:01,876 epoch 32 - iter 28/141 - loss 0.06664065 - samples/sec: 130.57 - lr: 0.000004
2021-07-22 23:18:05,151 epoch 32 - iter 42/141 - loss 0.05924252 - samples/sec: 136.81 - lr: 0.000004
2021-07-22 23:18:08,446 epoch 32 - iter 56/141 - loss 0.06041548 - samples/sec: 135.98 - lr: 0.000004
2021-07-22 23:18:11,684 epoch 32 - iter 70/141 - loss 0.05881349 - samples/sec: 138.40 - lr: 0.000004
2021-07-22 23:18:15,050 epoch 32 - iter 84/141 - loss 0.05619247 - samples/sec: 133.15 - lr: 0.000004
2021-07-22 23:18:18,403 epoch 32 - iter 98/141 - loss 0.05524966 - samples/sec: 133.63 - lr: 0.000004
2021-07-22 23:18:21,788 epoch 32 - iter 112/141 - loss 0.05494541 - samples/sec: 132.40 - lr: 0.000004
2021-07-22 23:18:25,215 epoch 32 - iter 126/141 - loss 0.05562618 - samples/sec: 130.75 - lr: 0.000004
2021-07-22 23:18:28,563 epoch 32 - iter 140/141 - loss 0.05833266 - samples/sec: 133.86 - lr: 0.000004
2021-07-22 23:18:28,722 ----------------------------------------------------------------------------------------------------
2021-07-22 23:18:28,723 EPOCH 32 done: loss 0.0595 - lr 0.0000038
2021-07-22 23:18:30,799 DEV : loss 0.028373360633850098 - score 0.9913
2021-07-22 23:18:30,824 BAD EPOCHS (no improvement): 1
2021-07-22 23:18:30,824 ----------------------------------------------------------------------------------------------------
2021-07-22 23:18:34,168 epoch 33 - iter 14/141 - loss 0.07387555 - samples/sec: 134.08 - lr: 0.000004
2021-07-22 23:18:37,551 epoch 33 - iter 28/141 - loss 0.06501193 - samples/sec: 132.43 - lr: 0.000004
2021-07-22 23:18:40,979 epoch 33 - iter 42/141 - loss 0.06724929 - samples/sec: 130.75 - lr: 0.000004
2021-07-22 23:18:44,352 epoch 33 - iter 56/141 - loss 0.06690044 - samples/sec: 132.83 - lr: 0.000004
2021-07-22 23:18:47,683 epoch 33 - iter 70/141 - loss 0.06228615 - samples/sec: 134.55 - lr: 0.000004
2021-07-22 23:18:51,020 epoch 33 - iter 84/141 - loss 0.06426313 - samples/sec: 134.29 - lr: 0.000004
2021-07-22 23:18:54,420 epoch 33 - iter 98/141 - loss 0.06100115 - samples/sec: 131.80 - lr: 0.000004
2021-07-22 23:18:57,678 epoch 33 - iter 112/141 - loss 0.06210942 - samples/sec: 137.55 - lr: 0.000004
2021-07-22 23:19:01,003 epoch 33 - iter 126/141 - loss 0.06169669 - samples/sec: 134.74 - lr: 0.000004
2021-07-22 23:19:04,245 epoch 33 - iter 140/141 - loss 0.06216678 - samples/sec: 138.25 - lr: 0.000004
2021-07-22 23:19:04,403 ----------------------------------------------------------------------------------------------------
2021-07-22 23:19:04,403 EPOCH 33 done: loss 0.0626 - lr 0.0000038
2021-07-22 23:19:06,474 DEV : loss 0.03338415548205376 - score 0.9939
2021-07-22 23:19:06,499 BAD EPOCHS (no improvement): 2
2021-07-22 23:19:06,499 ----------------------------------------------------------------------------------------------------
2021-07-22 23:19:10,085 epoch 34 - iter 14/141 - loss 0.04795864 - samples/sec: 125.00 - lr: 0.000004
2021-07-22 23:19:13,476 epoch 34 - iter 28/141 - loss 0.04892278 - samples/sec: 132.17 - lr: 0.000004
2021-07-22 23:19:16,704 epoch 34 - iter 42/141 - loss 0.05949317 - samples/sec: 138.81 - lr: 0.000004
2021-07-22 23:19:20,055 epoch 34 - iter 56/141 - loss 0.05641492 - samples/sec: 133.74 - lr: 0.000004
2021-07-22 23:19:23,436 epoch 34 - iter 70/141 - loss 0.05682266 - samples/sec: 132.51 - lr: 0.000004
2021-07-22 23:19:26,674 epoch 34 - iter 84/141 - loss 0.05612767 - samples/sec: 138.42 - lr: 0.000004
2021-07-22 23:19:29,854 epoch 34 - iter 98/141 - loss 0.05679908 - samples/sec: 140.90 - lr: 0.000004
2021-07-22 23:19:33,174 epoch 34 - iter 112/141 - loss 0.05984568 - samples/sec: 134.97 - lr: 0.000004
2021-07-22 23:19:36,564 epoch 34 - iter 126/141 - loss 0.05912198 - samples/sec: 132.22 - lr: 0.000004
2021-07-22 23:19:39,907 epoch 34 - iter 140/141 - loss 0.05725415 - samples/sec: 134.03 - lr: 0.000004
2021-07-22 23:19:40,083 ----------------------------------------------------------------------------------------------------
2021-07-22 23:19:40,083 EPOCH 34 done: loss 0.0572 - lr 0.0000038
2021-07-22 23:19:42,156 DEV : loss 0.030294759199023247 - score 0.993
2021-07-22 23:19:42,181 BAD EPOCHS (no improvement): 3
2021-07-22 23:19:42,182 ----------------------------------------------------------------------------------------------------
2021-07-22 23:19:45,440 epoch 35 - iter 14/141 - loss 0.07755491 - samples/sec: 137.56 - lr: 0.000004
2021-07-22 23:19:48,712 epoch 35 - iter 28/141 - loss 0.07277589 - samples/sec: 136.97 - lr: 0.000004
2021-07-22 23:19:52,031 epoch 35 - iter 42/141 - loss 0.06411173 - samples/sec: 135.01 - lr: 0.000004
2021-07-22 23:19:55,368 epoch 35 - iter 56/141 - loss 0.06112250 - samples/sec: 134.30 - lr: 0.000004
2021-07-22 23:19:58,641 epoch 35 - iter 70/141 - loss 0.06297912 - samples/sec: 136.90 - lr: 0.000004
2021-07-22 23:20:02,001 epoch 35 - iter 84/141 - loss 0.06324926 - samples/sec: 133.38 - lr: 0.000004
2021-07-22 23:20:05,291 epoch 35 - iter 98/141 - loss 0.06466032 - samples/sec: 136.20 - lr: 0.000004
2021-07-22 23:20:08,706 epoch 35 - iter 112/141 - loss 0.06419355 - samples/sec: 131.21 - lr: 0.000004
2021-07-22 23:20:12,024 epoch 35 - iter 126/141 - loss 0.06504814 - samples/sec: 135.06 - lr: 0.000004
2021-07-22 23:20:15,459 epoch 35 - iter 140/141 - loss 0.06625705 - samples/sec: 130.47 - lr: 0.000004
2021-07-22 23:20:15,611 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:15,611 EPOCH 35 done: loss 0.0670 - lr 0.0000038
2021-07-22 23:20:17,681 DEV : loss 0.02980079874396324 - score 0.993
Epoch    35: reducing learning rate of group 0 to 1.8750e-06.
2021-07-22 23:20:17,705 BAD EPOCHS (no improvement): 4
2021-07-22 23:20:17,705 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:17,706 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:17,706 learning rate too small - quitting training!
2021-07-22 23:20:17,706 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:18,934 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:18,934 Testing using best model ...
2021-07-22 23:20:18,935 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/por.rst.cstn/best-model.pt
2021-07-22 23:20:45,967 0.9903	0.9951	0.9927
2021-07-22 23:20:45,967 
Results:
- F1-score (micro) 0.9927
- F1-score (macro) 0.9918

By class:
SENT       tp: 542 - fp: 12 - fn: 6 - precision: 0.9783 - recall: 0.9891 - f1-score: 0.9837
X          tp: 679 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 23:20:45,967 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/deu.rst.pcc/
2021-07-22 23:20:46,013 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/deu.rst.pcc
2021-07-22 23:20:46,014 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/deu.rst.pcc/sent_train.txt
2021-07-22 23:20:46,015 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/deu.rst.pcc/sent_dev.txt
2021-07-22 23:20:46,017 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/deu.rst.pcc/sent_test.txt
Corpus: 3194 train + 506 dev + 1067 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 23:20:49,646 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:49,648 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 23:20:49,648 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:49,648 Corpus: "Corpus: 3194 train + 506 dev + 1067 test sentences"
2021-07-22 23:20:49,648 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:49,648 Parameters:
2021-07-22 23:20:49,648  - learning_rate: "3e-05"
2021-07-22 23:20:49,648  - mini_batch_size: "32"
2021-07-22 23:20:49,648  - patience: "3"
2021-07-22 23:20:49,648  - anneal_factor: "0.5"
2021-07-22 23:20:49,648  - max_epochs: "40"
2021-07-22 23:20:49,648  - shuffle: "True"
2021-07-22 23:20:49,648  - train_with_dev: "False"
2021-07-22 23:20:49,648  - batch_growth_annealing: "False"
2021-07-22 23:20:49,648 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:49,648 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/deu.rst.pcc"
2021-07-22 23:20:49,648 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:49,648 Device: cuda:0
2021-07-22 23:20:49,649 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:49,649 Embeddings storage mode: cpu
2021-07-22 23:20:49,651 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:55,223 epoch 1 - iter 10/100 - loss 2.81945026 - samples/sec: 57.44 - lr: 0.000030
2021-07-22 23:21:00,740 epoch 1 - iter 20/100 - loss 2.68682169 - samples/sec: 58.00 - lr: 0.000030
2021-07-22 23:21:06,174 epoch 1 - iter 30/100 - loss 2.62870184 - samples/sec: 58.89 - lr: 0.000030
2021-07-22 23:21:11,791 epoch 1 - iter 40/100 - loss 2.54804381 - samples/sec: 56.98 - lr: 0.000030
2021-07-22 23:21:17,480 epoch 1 - iter 50/100 - loss 2.44933427 - samples/sec: 56.26 - lr: 0.000030
2021-07-22 23:21:23,155 epoch 1 - iter 60/100 - loss 2.36652184 - samples/sec: 56.39 - lr: 0.000030
2021-07-22 23:21:28,857 epoch 1 - iter 70/100 - loss 2.27846009 - samples/sec: 56.13 - lr: 0.000030
2021-07-22 23:21:34,577 epoch 1 - iter 80/100 - loss 2.20037615 - samples/sec: 55.95 - lr: 0.000030
2021-07-22 23:21:40,374 epoch 1 - iter 90/100 - loss 2.11811673 - samples/sec: 55.21 - lr: 0.000030
2021-07-22 23:21:46,137 epoch 1 - iter 100/100 - loss 2.03816283 - samples/sec: 55.53 - lr: 0.000030
2021-07-22 23:21:46,138 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:46,138 EPOCH 1 done: loss 2.0382 - lr 0.0000300
2021-07-22 23:21:52,786 DEV : loss 0.9759153127670288 - score 0.6203
2021-07-22 23:21:52,798 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:21:53,427 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:55,782 epoch 2 - iter 10/100 - loss 1.22094324 - samples/sec: 135.99 - lr: 0.000030
2021-07-22 23:21:58,048 epoch 2 - iter 20/100 - loss 1.10121938 - samples/sec: 141.28 - lr: 0.000030
2021-07-22 23:22:00,263 epoch 2 - iter 30/100 - loss 1.04847586 - samples/sec: 144.48 - lr: 0.000030
2021-07-22 23:22:02,478 epoch 2 - iter 40/100 - loss 1.01887370 - samples/sec: 144.54 - lr: 0.000030
2021-07-22 23:22:04,744 epoch 2 - iter 50/100 - loss 0.97858660 - samples/sec: 141.24 - lr: 0.000030
2021-07-22 23:22:06,869 epoch 2 - iter 60/100 - loss 0.94410374 - samples/sec: 150.62 - lr: 0.000030
2021-07-22 23:22:09,063 epoch 2 - iter 70/100 - loss 0.90315515 - samples/sec: 145.92 - lr: 0.000030
2021-07-22 23:22:11,332 epoch 2 - iter 80/100 - loss 0.86582820 - samples/sec: 141.11 - lr: 0.000030
2021-07-22 23:22:13,532 epoch 2 - iter 90/100 - loss 0.83301033 - samples/sec: 145.49 - lr: 0.000030
2021-07-22 23:22:15,668 epoch 2 - iter 100/100 - loss 0.80288827 - samples/sec: 149.86 - lr: 0.000030
2021-07-22 23:22:15,669 ----------------------------------------------------------------------------------------------------
2021-07-22 23:22:15,669 EPOCH 2 done: loss 0.8029 - lr 0.0000300
2021-07-22 23:22:16,796 DEV : loss 0.3404381573200226 - score 0.9394
2021-07-22 23:22:16,808 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:22:19,074 ----------------------------------------------------------------------------------------------------
2021-07-22 23:22:21,318 epoch 3 - iter 10/100 - loss 0.49390138 - samples/sec: 142.80 - lr: 0.000030
2021-07-22 23:22:23,628 epoch 3 - iter 20/100 - loss 0.49267660 - samples/sec: 138.58 - lr: 0.000030
2021-07-22 23:22:25,731 epoch 3 - iter 30/100 - loss 0.47007596 - samples/sec: 152.18 - lr: 0.000030
2021-07-22 23:22:27,958 epoch 3 - iter 40/100 - loss 0.45498872 - samples/sec: 143.72 - lr: 0.000030
2021-07-22 23:22:30,123 epoch 3 - iter 50/100 - loss 0.43396869 - samples/sec: 147.86 - lr: 0.000030
2021-07-22 23:22:32,291 epoch 3 - iter 60/100 - loss 0.43026536 - samples/sec: 147.69 - lr: 0.000030
2021-07-22 23:22:34,461 epoch 3 - iter 70/100 - loss 0.41698811 - samples/sec: 147.48 - lr: 0.000030
2021-07-22 23:22:36,585 epoch 3 - iter 80/100 - loss 0.40682955 - samples/sec: 150.72 - lr: 0.000030
2021-07-22 23:22:38,843 epoch 3 - iter 90/100 - loss 0.39696411 - samples/sec: 141.81 - lr: 0.000030
2021-07-22 23:22:41,070 epoch 3 - iter 100/100 - loss 0.38788151 - samples/sec: 143.71 - lr: 0.000030
2021-07-22 23:22:41,071 ----------------------------------------------------------------------------------------------------
2021-07-22 23:22:41,071 EPOCH 3 done: loss 0.3879 - lr 0.0000300
2021-07-22 23:22:42,194 DEV : loss 0.1809587925672531 - score 0.9676
2021-07-22 23:22:42,206 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:22:44,907 ----------------------------------------------------------------------------------------------------
2021-07-22 23:22:47,050 epoch 4 - iter 10/100 - loss 0.34015206 - samples/sec: 149.50 - lr: 0.000030
2021-07-22 23:22:49,322 epoch 4 - iter 20/100 - loss 0.31835352 - samples/sec: 140.86 - lr: 0.000030
2021-07-22 23:22:51,556 epoch 4 - iter 30/100 - loss 0.30162982 - samples/sec: 143.32 - lr: 0.000030
2021-07-22 23:22:53,722 epoch 4 - iter 40/100 - loss 0.29134400 - samples/sec: 147.76 - lr: 0.000030
2021-07-22 23:22:55,920 epoch 4 - iter 50/100 - loss 0.28742154 - samples/sec: 145.64 - lr: 0.000030
2021-07-22 23:22:58,064 epoch 4 - iter 60/100 - loss 0.28089209 - samples/sec: 149.29 - lr: 0.000030
2021-07-22 23:23:00,318 epoch 4 - iter 70/100 - loss 0.28191333 - samples/sec: 142.00 - lr: 0.000030
2021-07-22 23:23:02,526 epoch 4 - iter 80/100 - loss 0.27793043 - samples/sec: 145.02 - lr: 0.000030
2021-07-22 23:23:04,709 epoch 4 - iter 90/100 - loss 0.27233817 - samples/sec: 146.63 - lr: 0.000030
2021-07-22 23:23:06,926 epoch 4 - iter 100/100 - loss 0.28048330 - samples/sec: 144.39 - lr: 0.000030
2021-07-22 23:23:06,928 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:06,928 EPOCH 4 done: loss 0.2805 - lr 0.0000300
2021-07-22 23:23:08,056 DEV : loss 0.12569326162338257 - score 0.9758
2021-07-22 23:23:08,069 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:23:10,492 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:12,716 epoch 5 - iter 10/100 - loss 0.25513763 - samples/sec: 144.03 - lr: 0.000030
2021-07-22 23:23:14,971 epoch 5 - iter 20/100 - loss 0.26720782 - samples/sec: 141.94 - lr: 0.000030
2021-07-22 23:23:17,189 epoch 5 - iter 30/100 - loss 0.26975868 - samples/sec: 144.34 - lr: 0.000030
2021-07-22 23:23:19,338 epoch 5 - iter 40/100 - loss 0.25980657 - samples/sec: 149.00 - lr: 0.000030
2021-07-22 23:23:21,536 epoch 5 - iter 50/100 - loss 0.23974266 - samples/sec: 145.61 - lr: 0.000030
2021-07-22 23:23:23,636 epoch 5 - iter 60/100 - loss 0.23490432 - samples/sec: 152.42 - lr: 0.000030
2021-07-22 23:23:25,848 epoch 5 - iter 70/100 - loss 0.23523361 - samples/sec: 144.76 - lr: 0.000030
2021-07-22 23:23:27,925 epoch 5 - iter 80/100 - loss 0.22949693 - samples/sec: 154.08 - lr: 0.000030
2021-07-22 23:23:30,151 epoch 5 - iter 90/100 - loss 0.22855501 - samples/sec: 143.82 - lr: 0.000030
2021-07-22 23:23:32,364 epoch 5 - iter 100/100 - loss 0.22780224 - samples/sec: 144.67 - lr: 0.000030
2021-07-22 23:23:32,365 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:32,365 EPOCH 5 done: loss 0.2278 - lr 0.0000300
2021-07-22 23:23:33,489 DEV : loss 0.09650671482086182 - score 0.9743
2021-07-22 23:23:33,501 BAD EPOCHS (no improvement): 1
2021-07-22 23:23:33,501 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:35,682 epoch 6 - iter 10/100 - loss 0.22500465 - samples/sec: 146.87 - lr: 0.000030
2021-07-22 23:23:37,832 epoch 6 - iter 20/100 - loss 0.21706134 - samples/sec: 148.84 - lr: 0.000030
2021-07-22 23:23:39,971 epoch 6 - iter 30/100 - loss 0.20929307 - samples/sec: 149.68 - lr: 0.000030
2021-07-22 23:23:42,283 epoch 6 - iter 40/100 - loss 0.21576218 - samples/sec: 138.42 - lr: 0.000030
2021-07-22 23:23:44,408 epoch 6 - iter 50/100 - loss 0.20890136 - samples/sec: 150.69 - lr: 0.000030
2021-07-22 23:23:46,620 epoch 6 - iter 60/100 - loss 0.20651112 - samples/sec: 144.66 - lr: 0.000030
2021-07-22 23:23:48,791 epoch 6 - iter 70/100 - loss 0.21262750 - samples/sec: 147.46 - lr: 0.000030
2021-07-22 23:23:51,082 epoch 6 - iter 80/100 - loss 0.20588887 - samples/sec: 139.73 - lr: 0.000030
2021-07-22 23:23:53,318 epoch 6 - iter 90/100 - loss 0.20243312 - samples/sec: 143.15 - lr: 0.000030
2021-07-22 23:23:55,509 epoch 6 - iter 100/100 - loss 0.19993251 - samples/sec: 146.16 - lr: 0.000030
2021-07-22 23:23:55,510 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:55,510 EPOCH 6 done: loss 0.1999 - lr 0.0000300
2021-07-22 23:23:56,636 DEV : loss 0.085568368434906 - score 0.9729
2021-07-22 23:23:56,649 BAD EPOCHS (no improvement): 2
2021-07-22 23:23:56,649 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:58,816 epoch 7 - iter 10/100 - loss 0.17418244 - samples/sec: 147.78 - lr: 0.000030
2021-07-22 23:24:01,016 epoch 7 - iter 20/100 - loss 0.18300664 - samples/sec: 145.46 - lr: 0.000030
2021-07-22 23:24:03,196 epoch 7 - iter 30/100 - loss 0.20796375 - samples/sec: 146.87 - lr: 0.000030
2021-07-22 23:24:05,496 epoch 7 - iter 40/100 - loss 0.19335820 - samples/sec: 139.18 - lr: 0.000030
2021-07-22 23:24:07,636 epoch 7 - iter 50/100 - loss 0.18843392 - samples/sec: 149.56 - lr: 0.000030
2021-07-22 23:24:09,841 epoch 7 - iter 60/100 - loss 0.18602146 - samples/sec: 145.18 - lr: 0.000030
2021-07-22 23:24:12,087 epoch 7 - iter 70/100 - loss 0.19378676 - samples/sec: 142.54 - lr: 0.000030
2021-07-22 23:24:14,287 epoch 7 - iter 80/100 - loss 0.19688525 - samples/sec: 145.50 - lr: 0.000030
2021-07-22 23:24:16,555 epoch 7 - iter 90/100 - loss 0.20163363 - samples/sec: 141.10 - lr: 0.000030
2021-07-22 23:24:18,731 epoch 7 - iter 100/100 - loss 0.19488366 - samples/sec: 147.10 - lr: 0.000030
2021-07-22 23:24:18,732 ----------------------------------------------------------------------------------------------------
2021-07-22 23:24:18,732 EPOCH 7 done: loss 0.1949 - lr 0.0000300
2021-07-22 23:24:19,905 DEV : loss 0.0763225182890892 - score 0.9781
2021-07-22 23:24:19,918 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:24:22,030 ----------------------------------------------------------------------------------------------------
2021-07-22 23:24:24,258 epoch 8 - iter 10/100 - loss 0.20617185 - samples/sec: 143.77 - lr: 0.000030
2021-07-22 23:24:26,491 epoch 8 - iter 20/100 - loss 0.17778166 - samples/sec: 143.37 - lr: 0.000030
2021-07-22 23:24:28,629 epoch 8 - iter 30/100 - loss 0.19346674 - samples/sec: 149.72 - lr: 0.000030
2021-07-22 23:24:30,871 epoch 8 - iter 40/100 - loss 0.18679872 - samples/sec: 142.79 - lr: 0.000030
2021-07-22 23:24:33,066 epoch 8 - iter 50/100 - loss 0.18179093 - samples/sec: 145.81 - lr: 0.000030
2021-07-22 23:24:35,211 epoch 8 - iter 60/100 - loss 0.18079156 - samples/sec: 149.27 - lr: 0.000030
2021-07-22 23:24:37,447 epoch 8 - iter 70/100 - loss 0.17866012 - samples/sec: 143.11 - lr: 0.000030
2021-07-22 23:24:39,604 epoch 8 - iter 80/100 - loss 0.18114950 - samples/sec: 148.39 - lr: 0.000030
2021-07-22 23:24:41,803 epoch 8 - iter 90/100 - loss 0.17481490 - samples/sec: 145.56 - lr: 0.000030
2021-07-22 23:24:43,910 epoch 8 - iter 100/100 - loss 0.17436995 - samples/sec: 151.96 - lr: 0.000030
2021-07-22 23:24:43,911 ----------------------------------------------------------------------------------------------------
2021-07-22 23:24:43,911 EPOCH 8 done: loss 0.1744 - lr 0.0000300
2021-07-22 23:24:45,042 DEV : loss 0.0825459212064743 - score 0.9786
2021-07-22 23:24:45,054 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:24:47,443 ----------------------------------------------------------------------------------------------------
2021-07-22 23:24:49,643 epoch 9 - iter 10/100 - loss 0.16421315 - samples/sec: 145.62 - lr: 0.000030
2021-07-22 23:24:51,735 epoch 9 - iter 20/100 - loss 0.16154652 - samples/sec: 153.05 - lr: 0.000030
2021-07-22 23:24:53,998 epoch 9 - iter 30/100 - loss 0.15599911 - samples/sec: 141.40 - lr: 0.000030
2021-07-22 23:24:56,183 epoch 9 - iter 40/100 - loss 0.17178101 - samples/sec: 146.50 - lr: 0.000030
2021-07-22 23:24:58,508 epoch 9 - iter 50/100 - loss 0.18516722 - samples/sec: 137.69 - lr: 0.000030
2021-07-22 23:25:00,743 epoch 9 - iter 60/100 - loss 0.18464534 - samples/sec: 143.19 - lr: 0.000030
2021-07-22 23:25:03,028 epoch 9 - iter 70/100 - loss 0.18467599 - samples/sec: 140.09 - lr: 0.000030
2021-07-22 23:25:05,180 epoch 9 - iter 80/100 - loss 0.18604841 - samples/sec: 148.78 - lr: 0.000030
2021-07-22 23:25:07,396 epoch 9 - iter 90/100 - loss 0.18406982 - samples/sec: 144.46 - lr: 0.000030
2021-07-22 23:25:09,549 epoch 9 - iter 100/100 - loss 0.18648813 - samples/sec: 148.64 - lr: 0.000030
2021-07-22 23:25:09,550 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:09,550 EPOCH 9 done: loss 0.1865 - lr 0.0000300
2021-07-22 23:25:10,683 DEV : loss 0.07209190726280212 - score 0.9784
2021-07-22 23:25:10,695 BAD EPOCHS (no improvement): 1
2021-07-22 23:25:10,695 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:12,956 epoch 10 - iter 10/100 - loss 0.20055099 - samples/sec: 141.65 - lr: 0.000030
2021-07-22 23:25:15,148 epoch 10 - iter 20/100 - loss 0.18266332 - samples/sec: 146.06 - lr: 0.000030
2021-07-22 23:25:17,391 epoch 10 - iter 30/100 - loss 0.18238648 - samples/sec: 142.72 - lr: 0.000030
2021-07-22 23:25:19,622 epoch 10 - iter 40/100 - loss 0.16971480 - samples/sec: 143.42 - lr: 0.000030
2021-07-22 23:25:21,805 epoch 10 - iter 50/100 - loss 0.16723548 - samples/sec: 146.69 - lr: 0.000030
2021-07-22 23:25:23,892 epoch 10 - iter 60/100 - loss 0.17004297 - samples/sec: 153.34 - lr: 0.000030
2021-07-22 23:25:26,048 epoch 10 - iter 70/100 - loss 0.16639868 - samples/sec: 148.51 - lr: 0.000030
2021-07-22 23:25:28,263 epoch 10 - iter 80/100 - loss 0.16745147 - samples/sec: 144.47 - lr: 0.000030
2021-07-22 23:25:30,466 epoch 10 - iter 90/100 - loss 0.16944304 - samples/sec: 145.31 - lr: 0.000030
2021-07-22 23:25:32,739 epoch 10 - iter 100/100 - loss 0.17173138 - samples/sec: 140.84 - lr: 0.000030
2021-07-22 23:25:32,740 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:32,740 EPOCH 10 done: loss 0.1717 - lr 0.0000300
2021-07-22 23:25:33,872 DEV : loss 0.08162640780210495 - score 0.976
2021-07-22 23:25:33,884 BAD EPOCHS (no improvement): 2
2021-07-22 23:25:33,884 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:36,019 epoch 11 - iter 10/100 - loss 0.16314078 - samples/sec: 150.00 - lr: 0.000030
2021-07-22 23:25:38,243 epoch 11 - iter 20/100 - loss 0.17996798 - samples/sec: 143.95 - lr: 0.000030
2021-07-22 23:25:40,356 epoch 11 - iter 30/100 - loss 0.17036874 - samples/sec: 151.49 - lr: 0.000030
2021-07-22 23:25:42,580 epoch 11 - iter 40/100 - loss 0.16720226 - samples/sec: 143.94 - lr: 0.000030
2021-07-22 23:25:44,824 epoch 11 - iter 50/100 - loss 0.16292206 - samples/sec: 142.64 - lr: 0.000030
2021-07-22 23:25:47,156 epoch 11 - iter 60/100 - loss 0.16338909 - samples/sec: 137.27 - lr: 0.000030
2021-07-22 23:25:49,384 epoch 11 - iter 70/100 - loss 0.16428122 - samples/sec: 143.63 - lr: 0.000030
2021-07-22 23:25:51,620 epoch 11 - iter 80/100 - loss 0.16786350 - samples/sec: 143.18 - lr: 0.000030
2021-07-22 23:25:53,814 epoch 11 - iter 90/100 - loss 0.17003003 - samples/sec: 145.92 - lr: 0.000030
2021-07-22 23:25:55,951 epoch 11 - iter 100/100 - loss 0.16830862 - samples/sec: 149.77 - lr: 0.000030
2021-07-22 23:25:55,952 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:55,952 EPOCH 11 done: loss 0.1683 - lr 0.0000300
2021-07-22 23:25:57,084 DEV : loss 0.062426213175058365 - score 0.9811
2021-07-22 23:25:57,100 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:25:59,350 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:01,563 epoch 12 - iter 10/100 - loss 0.13883279 - samples/sec: 144.74 - lr: 0.000030
2021-07-22 23:26:03,888 epoch 12 - iter 20/100 - loss 0.14134949 - samples/sec: 137.65 - lr: 0.000030
2021-07-22 23:26:06,032 epoch 12 - iter 30/100 - loss 0.14945429 - samples/sec: 149.36 - lr: 0.000030
2021-07-22 23:26:08,171 epoch 12 - iter 40/100 - loss 0.14283068 - samples/sec: 149.63 - lr: 0.000030
2021-07-22 23:26:10,369 epoch 12 - iter 50/100 - loss 0.13726006 - samples/sec: 145.64 - lr: 0.000030
2021-07-22 23:26:12,559 epoch 12 - iter 60/100 - loss 0.13946962 - samples/sec: 146.21 - lr: 0.000030
2021-07-22 23:26:14,700 epoch 12 - iter 70/100 - loss 0.14525476 - samples/sec: 149.52 - lr: 0.000030
2021-07-22 23:26:16,920 epoch 12 - iter 80/100 - loss 0.14729183 - samples/sec: 144.16 - lr: 0.000030
2021-07-22 23:26:19,067 epoch 12 - iter 90/100 - loss 0.15209613 - samples/sec: 149.07 - lr: 0.000030
2021-07-22 23:26:21,247 epoch 12 - iter 100/100 - loss 0.15124430 - samples/sec: 146.87 - lr: 0.000030
2021-07-22 23:26:21,248 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:21,248 EPOCH 12 done: loss 0.1512 - lr 0.0000300
2021-07-22 23:26:22,373 DEV : loss 0.05987223982810974 - score 0.9851
2021-07-22 23:26:22,385 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:26:24,732 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:27,021 epoch 13 - iter 10/100 - loss 0.13868387 - samples/sec: 139.99 - lr: 0.000030
2021-07-22 23:26:29,260 epoch 13 - iter 20/100 - loss 0.12568625 - samples/sec: 142.99 - lr: 0.000030
2021-07-22 23:26:31,494 epoch 13 - iter 30/100 - loss 0.13596663 - samples/sec: 143.24 - lr: 0.000030
2021-07-22 23:26:33,627 epoch 13 - iter 40/100 - loss 0.13586381 - samples/sec: 150.11 - lr: 0.000030
2021-07-22 23:26:35,759 epoch 13 - iter 50/100 - loss 0.14268483 - samples/sec: 150.14 - lr: 0.000030
2021-07-22 23:26:37,856 epoch 13 - iter 60/100 - loss 0.14487678 - samples/sec: 152.65 - lr: 0.000030
2021-07-22 23:26:40,022 epoch 13 - iter 70/100 - loss 0.14220798 - samples/sec: 147.73 - lr: 0.000030
2021-07-22 23:26:42,254 epoch 13 - iter 80/100 - loss 0.14074429 - samples/sec: 143.45 - lr: 0.000030
2021-07-22 23:26:44,442 epoch 13 - iter 90/100 - loss 0.14138550 - samples/sec: 146.27 - lr: 0.000030
2021-07-22 23:26:46,605 epoch 13 - iter 100/100 - loss 0.14463255 - samples/sec: 148.04 - lr: 0.000030
2021-07-22 23:26:46,606 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:46,606 EPOCH 13 done: loss 0.1446 - lr 0.0000300
2021-07-22 23:26:47,737 DEV : loss 0.06564293056726456 - score 0.9799
2021-07-22 23:26:47,749 BAD EPOCHS (no improvement): 1
2021-07-22 23:26:47,749 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:49,948 epoch 14 - iter 10/100 - loss 0.16712433 - samples/sec: 145.64 - lr: 0.000030
2021-07-22 23:26:52,090 epoch 14 - iter 20/100 - loss 0.15412648 - samples/sec: 149.47 - lr: 0.000030
2021-07-22 23:26:54,231 epoch 14 - iter 30/100 - loss 0.14292036 - samples/sec: 149.48 - lr: 0.000030
2021-07-22 23:26:56,418 epoch 14 - iter 40/100 - loss 0.14845224 - samples/sec: 146.41 - lr: 0.000030
2021-07-22 23:26:58,543 epoch 14 - iter 50/100 - loss 0.14439626 - samples/sec: 150.64 - lr: 0.000030
2021-07-22 23:27:00,743 epoch 14 - iter 60/100 - loss 0.14047081 - samples/sec: 145.47 - lr: 0.000030
2021-07-22 23:27:03,032 epoch 14 - iter 70/100 - loss 0.13932242 - samples/sec: 139.88 - lr: 0.000030
2021-07-22 23:27:05,278 epoch 14 - iter 80/100 - loss 0.14154032 - samples/sec: 142.49 - lr: 0.000030
2021-07-22 23:27:07,499 epoch 14 - iter 90/100 - loss 0.13848589 - samples/sec: 144.13 - lr: 0.000030
2021-07-22 23:27:09,736 epoch 14 - iter 100/100 - loss 0.13632356 - samples/sec: 143.09 - lr: 0.000030
2021-07-22 23:27:09,737 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:09,737 EPOCH 14 done: loss 0.1363 - lr 0.0000300
2021-07-22 23:27:10,865 DEV : loss 0.06192401796579361 - score 0.9825
2021-07-22 23:27:10,877 BAD EPOCHS (no improvement): 2
2021-07-22 23:27:10,877 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:13,027 epoch 15 - iter 10/100 - loss 0.11370133 - samples/sec: 149.01 - lr: 0.000030
2021-07-22 23:27:15,267 epoch 15 - iter 20/100 - loss 0.14262922 - samples/sec: 142.90 - lr: 0.000030
2021-07-22 23:27:17,436 epoch 15 - iter 30/100 - loss 0.13166997 - samples/sec: 147.54 - lr: 0.000030
2021-07-22 23:27:19,720 epoch 15 - iter 40/100 - loss 0.13127371 - samples/sec: 140.18 - lr: 0.000030
2021-07-22 23:27:21,936 epoch 15 - iter 50/100 - loss 0.13045928 - samples/sec: 144.44 - lr: 0.000030
2021-07-22 23:27:24,160 epoch 15 - iter 60/100 - loss 0.13233182 - samples/sec: 143.89 - lr: 0.000030
2021-07-22 23:27:26,399 epoch 15 - iter 70/100 - loss 0.13734227 - samples/sec: 143.01 - lr: 0.000030
2021-07-22 23:27:28,664 epoch 15 - iter 80/100 - loss 0.14008974 - samples/sec: 141.31 - lr: 0.000030
2021-07-22 23:27:30,810 epoch 15 - iter 90/100 - loss 0.13796915 - samples/sec: 149.15 - lr: 0.000030
2021-07-22 23:27:32,950 epoch 15 - iter 100/100 - loss 0.13679499 - samples/sec: 149.59 - lr: 0.000030
2021-07-22 23:27:32,951 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:32,951 EPOCH 15 done: loss 0.1368 - lr 0.0000300
2021-07-22 23:27:34,278 DEV : loss 0.06110623478889465 - score 0.9812
2021-07-22 23:27:34,294 BAD EPOCHS (no improvement): 3
2021-07-22 23:27:34,294 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:36,456 epoch 16 - iter 10/100 - loss 0.10756218 - samples/sec: 148.15 - lr: 0.000030
2021-07-22 23:27:38,730 epoch 16 - iter 20/100 - loss 0.13758740 - samples/sec: 140.73 - lr: 0.000030
2021-07-22 23:27:40,879 epoch 16 - iter 30/100 - loss 0.13709049 - samples/sec: 148.92 - lr: 0.000030
2021-07-22 23:27:43,095 epoch 16 - iter 40/100 - loss 0.13243096 - samples/sec: 144.51 - lr: 0.000030
2021-07-22 23:27:45,291 epoch 16 - iter 50/100 - loss 0.12255486 - samples/sec: 145.73 - lr: 0.000030
2021-07-22 23:27:47,484 epoch 16 - iter 60/100 - loss 0.12640020 - samples/sec: 145.97 - lr: 0.000030
2021-07-22 23:27:49,814 epoch 16 - iter 70/100 - loss 0.12396357 - samples/sec: 137.37 - lr: 0.000030
2021-07-22 23:27:52,039 epoch 16 - iter 80/100 - loss 0.12587968 - samples/sec: 143.91 - lr: 0.000030
2021-07-22 23:27:54,235 epoch 16 - iter 90/100 - loss 0.12310875 - samples/sec: 145.71 - lr: 0.000030
2021-07-22 23:27:56,356 epoch 16 - iter 100/100 - loss 0.12782658 - samples/sec: 150.97 - lr: 0.000030
2021-07-22 23:27:56,357 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:56,357 EPOCH 16 done: loss 0.1278 - lr 0.0000300
2021-07-22 23:27:57,481 DEV : loss 0.06046133488416672 - score 0.9826
Epoch    16: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 23:27:57,493 BAD EPOCHS (no improvement): 4
2021-07-22 23:27:57,494 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:59,632 epoch 17 - iter 10/100 - loss 0.10372428 - samples/sec: 149.78 - lr: 0.000015
2021-07-22 23:28:01,841 epoch 17 - iter 20/100 - loss 0.11592347 - samples/sec: 144.90 - lr: 0.000015
2021-07-22 23:28:04,131 epoch 17 - iter 30/100 - loss 0.12377759 - samples/sec: 139.76 - lr: 0.000015
2021-07-22 23:28:06,392 epoch 17 - iter 40/100 - loss 0.13323460 - samples/sec: 141.58 - lr: 0.000015
2021-07-22 23:28:08,548 epoch 17 - iter 50/100 - loss 0.13830755 - samples/sec: 148.45 - lr: 0.000015
2021-07-22 23:28:10,715 epoch 17 - iter 60/100 - loss 0.13327240 - samples/sec: 147.77 - lr: 0.000015
2021-07-22 23:28:12,858 epoch 17 - iter 70/100 - loss 0.12883984 - samples/sec: 149.35 - lr: 0.000015
2021-07-22 23:28:15,023 epoch 17 - iter 80/100 - loss 0.12542675 - samples/sec: 147.84 - lr: 0.000015
2021-07-22 23:28:17,267 epoch 17 - iter 90/100 - loss 0.12374824 - samples/sec: 142.65 - lr: 0.000015
2021-07-22 23:28:19,374 epoch 17 - iter 100/100 - loss 0.12515099 - samples/sec: 151.91 - lr: 0.000015
2021-07-22 23:28:19,375 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:19,375 EPOCH 17 done: loss 0.1252 - lr 0.0000150
2021-07-22 23:28:20,502 DEV : loss 0.05669068545103073 - score 0.9811
2021-07-22 23:28:20,515 BAD EPOCHS (no improvement): 1
2021-07-22 23:28:20,515 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:22,638 epoch 18 - iter 10/100 - loss 0.12758260 - samples/sec: 150.81 - lr: 0.000015
2021-07-22 23:28:24,802 epoch 18 - iter 20/100 - loss 0.16429937 - samples/sec: 147.96 - lr: 0.000015
2021-07-22 23:28:26,992 epoch 18 - iter 30/100 - loss 0.13847295 - samples/sec: 146.16 - lr: 0.000015
2021-07-22 23:28:29,151 epoch 18 - iter 40/100 - loss 0.13893628 - samples/sec: 148.27 - lr: 0.000015
2021-07-22 23:28:31,418 epoch 18 - iter 50/100 - loss 0.13866885 - samples/sec: 141.15 - lr: 0.000015
2021-07-22 23:28:33,523 epoch 18 - iter 60/100 - loss 0.13603822 - samples/sec: 152.11 - lr: 0.000015
2021-07-22 23:28:35,723 epoch 18 - iter 70/100 - loss 0.13373345 - samples/sec: 145.47 - lr: 0.000015
2021-07-22 23:28:37,945 epoch 18 - iter 80/100 - loss 0.13316049 - samples/sec: 144.05 - lr: 0.000015
2021-07-22 23:28:40,108 epoch 18 - iter 90/100 - loss 0.13216403 - samples/sec: 148.03 - lr: 0.000015
2021-07-22 23:28:42,347 epoch 18 - iter 100/100 - loss 0.13424756 - samples/sec: 142.96 - lr: 0.000015
2021-07-22 23:28:42,348 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:42,348 EPOCH 18 done: loss 0.1342 - lr 0.0000150
2021-07-22 23:28:43,478 DEV : loss 0.05272704362869263 - score 0.9837
2021-07-22 23:28:43,490 BAD EPOCHS (no improvement): 2
2021-07-22 23:28:43,490 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:45,686 epoch 19 - iter 10/100 - loss 0.11807708 - samples/sec: 145.83 - lr: 0.000015
2021-07-22 23:28:47,923 epoch 19 - iter 20/100 - loss 0.12605327 - samples/sec: 143.08 - lr: 0.000015
2021-07-22 23:28:50,073 epoch 19 - iter 30/100 - loss 0.12628768 - samples/sec: 148.92 - lr: 0.000015
2021-07-22 23:28:52,336 epoch 19 - iter 40/100 - loss 0.12458149 - samples/sec: 141.43 - lr: 0.000015
2021-07-22 23:28:54,629 epoch 19 - iter 50/100 - loss 0.12113006 - samples/sec: 139.63 - lr: 0.000015
2021-07-22 23:28:56,783 epoch 19 - iter 60/100 - loss 0.11967710 - samples/sec: 148.56 - lr: 0.000015
2021-07-22 23:28:58,954 epoch 19 - iter 70/100 - loss 0.12349117 - samples/sec: 147.43 - lr: 0.000015
2021-07-22 23:29:01,019 epoch 19 - iter 80/100 - loss 0.12286373 - samples/sec: 155.02 - lr: 0.000015
2021-07-22 23:29:03,188 epoch 19 - iter 90/100 - loss 0.12633138 - samples/sec: 147.58 - lr: 0.000015
2021-07-22 23:29:05,339 epoch 19 - iter 100/100 - loss 0.13011326 - samples/sec: 148.90 - lr: 0.000015
2021-07-22 23:29:05,339 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:05,340 EPOCH 19 done: loss 0.1301 - lr 0.0000150
2021-07-22 23:29:06,469 DEV : loss 0.05351555347442627 - score 0.9851
2021-07-22 23:29:06,481 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:29:08,685 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:10,725 epoch 20 - iter 10/100 - loss 0.10664886 - samples/sec: 157.06 - lr: 0.000015
2021-07-22 23:29:12,975 epoch 20 - iter 20/100 - loss 0.11534361 - samples/sec: 142.27 - lr: 0.000015
2021-07-22 23:29:15,219 epoch 20 - iter 30/100 - loss 0.12441307 - samples/sec: 142.63 - lr: 0.000015
2021-07-22 23:29:17,379 epoch 20 - iter 40/100 - loss 0.13145272 - samples/sec: 148.25 - lr: 0.000015
2021-07-22 23:29:19,640 epoch 20 - iter 50/100 - loss 0.13167897 - samples/sec: 141.58 - lr: 0.000015
2021-07-22 23:29:21,779 epoch 20 - iter 60/100 - loss 0.12741887 - samples/sec: 149.63 - lr: 0.000015
2021-07-22 23:29:23,960 epoch 20 - iter 70/100 - loss 0.12601063 - samples/sec: 146.81 - lr: 0.000015
2021-07-22 23:29:26,207 epoch 20 - iter 80/100 - loss 0.12689949 - samples/sec: 142.40 - lr: 0.000015
2021-07-22 23:29:28,559 epoch 20 - iter 90/100 - loss 0.12668908 - samples/sec: 136.14 - lr: 0.000015
2021-07-22 23:29:30,720 epoch 20 - iter 100/100 - loss 0.12702113 - samples/sec: 148.14 - lr: 0.000015
2021-07-22 23:29:30,720 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:30,721 EPOCH 20 done: loss 0.1270 - lr 0.0000150
2021-07-22 23:29:31,849 DEV : loss 0.06579489260911942 - score 0.9773
2021-07-22 23:29:31,861 BAD EPOCHS (no improvement): 1
2021-07-22 23:29:31,861 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:34,110 epoch 21 - iter 10/100 - loss 0.11394949 - samples/sec: 142.45 - lr: 0.000015
2021-07-22 23:29:36,368 epoch 21 - iter 20/100 - loss 0.10844751 - samples/sec: 141.73 - lr: 0.000015
2021-07-22 23:29:38,475 epoch 21 - iter 30/100 - loss 0.10806905 - samples/sec: 151.94 - lr: 0.000015
2021-07-22 23:29:40,713 epoch 21 - iter 40/100 - loss 0.10272043 - samples/sec: 143.05 - lr: 0.000015
2021-07-22 23:29:42,886 epoch 21 - iter 50/100 - loss 0.10467020 - samples/sec: 147.27 - lr: 0.000015
2021-07-22 23:29:45,114 epoch 21 - iter 60/100 - loss 0.10728514 - samples/sec: 143.67 - lr: 0.000015
2021-07-22 23:29:47,334 epoch 21 - iter 70/100 - loss 0.11636787 - samples/sec: 144.22 - lr: 0.000015
2021-07-22 23:29:49,559 epoch 21 - iter 80/100 - loss 0.11542971 - samples/sec: 143.89 - lr: 0.000015
2021-07-22 23:29:51,736 epoch 21 - iter 90/100 - loss 0.12050179 - samples/sec: 147.01 - lr: 0.000015
2021-07-22 23:29:53,819 epoch 21 - iter 100/100 - loss 0.11796068 - samples/sec: 153.71 - lr: 0.000015
2021-07-22 23:29:53,820 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:53,821 EPOCH 21 done: loss 0.1180 - lr 0.0000150
2021-07-22 23:29:54,948 DEV : loss 0.05069256201386452 - score 0.9877
2021-07-22 23:29:54,960 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:29:57,171 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:59,289 epoch 22 - iter 10/100 - loss 0.10814082 - samples/sec: 151.24 - lr: 0.000015
2021-07-22 23:30:01,534 epoch 22 - iter 20/100 - loss 0.13272724 - samples/sec: 142.57 - lr: 0.000015
2021-07-22 23:30:03,737 epoch 22 - iter 30/100 - loss 0.12646407 - samples/sec: 145.36 - lr: 0.000015
2021-07-22 23:30:05,958 epoch 22 - iter 40/100 - loss 0.13990451 - samples/sec: 144.15 - lr: 0.000015
2021-07-22 23:30:08,114 epoch 22 - iter 50/100 - loss 0.14230879 - samples/sec: 148.43 - lr: 0.000015
2021-07-22 23:30:10,323 epoch 22 - iter 60/100 - loss 0.13644055 - samples/sec: 144.92 - lr: 0.000015
2021-07-22 23:30:12,586 epoch 22 - iter 70/100 - loss 0.13682631 - samples/sec: 141.43 - lr: 0.000015
2021-07-22 23:30:14,784 epoch 22 - iter 80/100 - loss 0.12993296 - samples/sec: 145.67 - lr: 0.000015
2021-07-22 23:30:16,967 epoch 22 - iter 90/100 - loss 0.13164535 - samples/sec: 146.63 - lr: 0.000015
2021-07-22 23:30:19,115 epoch 22 - iter 100/100 - loss 0.13267914 - samples/sec: 148.97 - lr: 0.000015
2021-07-22 23:30:19,116 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:19,116 EPOCH 22 done: loss 0.1327 - lr 0.0000150
2021-07-22 23:30:20,243 DEV : loss 0.05561750754714012 - score 0.9852
2021-07-22 23:30:20,256 BAD EPOCHS (no improvement): 1
2021-07-22 23:30:20,256 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:22,473 epoch 23 - iter 10/100 - loss 0.11940222 - samples/sec: 144.45 - lr: 0.000015
2021-07-22 23:30:24,723 epoch 23 - iter 20/100 - loss 0.12408615 - samples/sec: 142.26 - lr: 0.000015
2021-07-22 23:30:26,912 epoch 23 - iter 30/100 - loss 0.11713062 - samples/sec: 146.25 - lr: 0.000015
2021-07-22 23:30:29,086 epoch 23 - iter 40/100 - loss 0.12122823 - samples/sec: 147.20 - lr: 0.000015
2021-07-22 23:30:31,296 epoch 23 - iter 50/100 - loss 0.12717825 - samples/sec: 144.87 - lr: 0.000015
2021-07-22 23:30:33,708 epoch 23 - iter 60/100 - loss 0.12480202 - samples/sec: 132.71 - lr: 0.000015
2021-07-22 23:30:35,948 epoch 23 - iter 70/100 - loss 0.12269604 - samples/sec: 142.93 - lr: 0.000015
2021-07-22 23:30:38,119 epoch 23 - iter 80/100 - loss 0.12449210 - samples/sec: 147.44 - lr: 0.000015
2021-07-22 23:30:40,214 epoch 23 - iter 90/100 - loss 0.12456765 - samples/sec: 152.79 - lr: 0.000015
2021-07-22 23:30:42,415 epoch 23 - iter 100/100 - loss 0.12266500 - samples/sec: 145.44 - lr: 0.000015
2021-07-22 23:30:42,416 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:42,416 EPOCH 23 done: loss 0.1227 - lr 0.0000150
2021-07-22 23:30:43,547 DEV : loss 0.059922631829977036 - score 0.9786
2021-07-22 23:30:43,571 BAD EPOCHS (no improvement): 2
2021-07-22 23:30:43,571 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:45,766 epoch 24 - iter 10/100 - loss 0.13574175 - samples/sec: 145.91 - lr: 0.000015
2021-07-22 23:30:48,008 epoch 24 - iter 20/100 - loss 0.13036590 - samples/sec: 142.78 - lr: 0.000015
2021-07-22 23:30:50,251 epoch 24 - iter 30/100 - loss 0.13707671 - samples/sec: 142.74 - lr: 0.000015
2021-07-22 23:30:52,524 epoch 24 - iter 40/100 - loss 0.13348100 - samples/sec: 140.81 - lr: 0.000015
2021-07-22 23:30:54,708 epoch 24 - iter 50/100 - loss 0.13788529 - samples/sec: 146.57 - lr: 0.000015
2021-07-22 23:30:56,879 epoch 24 - iter 60/100 - loss 0.13839158 - samples/sec: 147.41 - lr: 0.000015
2021-07-22 23:30:59,095 epoch 24 - iter 70/100 - loss 0.13501880 - samples/sec: 144.48 - lr: 0.000015
2021-07-22 23:31:01,214 epoch 24 - iter 80/100 - loss 0.13446704 - samples/sec: 151.01 - lr: 0.000015
2021-07-22 23:31:03,473 epoch 24 - iter 90/100 - loss 0.12955961 - samples/sec: 141.75 - lr: 0.000015
2021-07-22 23:31:05,610 epoch 24 - iter 100/100 - loss 0.12935223 - samples/sec: 149.79 - lr: 0.000015
2021-07-22 23:31:05,611 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:05,611 EPOCH 24 done: loss 0.1294 - lr 0.0000150
2021-07-22 23:31:06,735 DEV : loss 0.054471585899591446 - score 0.9878
2021-07-22 23:31:06,747 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:31:08,929 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:11,224 epoch 25 - iter 10/100 - loss 0.09908789 - samples/sec: 139.62 - lr: 0.000015
2021-07-22 23:31:13,362 epoch 25 - iter 20/100 - loss 0.12089878 - samples/sec: 149.67 - lr: 0.000015
2021-07-22 23:31:15,442 epoch 25 - iter 30/100 - loss 0.11800034 - samples/sec: 153.95 - lr: 0.000015
2021-07-22 23:31:17,664 epoch 25 - iter 40/100 - loss 0.11826365 - samples/sec: 144.04 - lr: 0.000015
2021-07-22 23:31:19,880 epoch 25 - iter 50/100 - loss 0.12244488 - samples/sec: 144.45 - lr: 0.000015
2021-07-22 23:31:22,170 epoch 25 - iter 60/100 - loss 0.12153483 - samples/sec: 139.77 - lr: 0.000015
2021-07-22 23:31:24,292 epoch 25 - iter 70/100 - loss 0.11843981 - samples/sec: 150.86 - lr: 0.000015
2021-07-22 23:31:26,480 epoch 25 - iter 80/100 - loss 0.12111465 - samples/sec: 146.33 - lr: 0.000015
2021-07-22 23:31:28,692 epoch 25 - iter 90/100 - loss 0.12351572 - samples/sec: 144.70 - lr: 0.000015
2021-07-22 23:31:30,976 epoch 25 - iter 100/100 - loss 0.12331843 - samples/sec: 140.15 - lr: 0.000015
2021-07-22 23:31:30,977 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:30,977 EPOCH 25 done: loss 0.1233 - lr 0.0000150
2021-07-22 23:31:32,102 DEV : loss 0.04942788928747177 - score 0.9877
2021-07-22 23:31:32,114 BAD EPOCHS (no improvement): 1
2021-07-22 23:31:32,115 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:34,303 epoch 26 - iter 10/100 - loss 0.13196131 - samples/sec: 146.31 - lr: 0.000015
2021-07-22 23:31:36,448 epoch 26 - iter 20/100 - loss 0.12746080 - samples/sec: 149.28 - lr: 0.000015
2021-07-22 23:31:38,620 epoch 26 - iter 30/100 - loss 0.12827225 - samples/sec: 147.36 - lr: 0.000015
2021-07-22 23:31:40,744 epoch 26 - iter 40/100 - loss 0.12931109 - samples/sec: 150.71 - lr: 0.000015
2021-07-22 23:31:42,951 epoch 26 - iter 50/100 - loss 0.12873868 - samples/sec: 145.04 - lr: 0.000015
2021-07-22 23:31:45,259 epoch 26 - iter 60/100 - loss 0.12874119 - samples/sec: 138.70 - lr: 0.000015
2021-07-22 23:31:47,538 epoch 26 - iter 70/100 - loss 0.12023346 - samples/sec: 140.42 - lr: 0.000015
2021-07-22 23:31:49,742 epoch 26 - iter 80/100 - loss 0.11767312 - samples/sec: 145.30 - lr: 0.000015
2021-07-22 23:31:51,986 epoch 26 - iter 90/100 - loss 0.11695989 - samples/sec: 142.59 - lr: 0.000015
2021-07-22 23:31:54,123 epoch 26 - iter 100/100 - loss 0.11827223 - samples/sec: 149.85 - lr: 0.000015
2021-07-22 23:31:54,124 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:54,124 EPOCH 26 done: loss 0.1183 - lr 0.0000150
2021-07-22 23:31:55,246 DEV : loss 0.05647478625178337 - score 0.9799
2021-07-22 23:31:55,259 BAD EPOCHS (no improvement): 2
2021-07-22 23:31:55,259 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:57,482 epoch 27 - iter 10/100 - loss 0.13900226 - samples/sec: 144.04 - lr: 0.000015
2021-07-22 23:31:59,651 epoch 27 - iter 20/100 - loss 0.12095050 - samples/sec: 147.56 - lr: 0.000015
2021-07-22 23:32:01,898 epoch 27 - iter 30/100 - loss 0.11597922 - samples/sec: 142.51 - lr: 0.000015
2021-07-22 23:32:04,041 epoch 27 - iter 40/100 - loss 0.10817175 - samples/sec: 149.37 - lr: 0.000015
2021-07-22 23:32:06,312 epoch 27 - iter 50/100 - loss 0.10387223 - samples/sec: 140.96 - lr: 0.000015
2021-07-22 23:32:08,501 epoch 27 - iter 60/100 - loss 0.10518207 - samples/sec: 146.19 - lr: 0.000015
2021-07-22 23:32:10,791 epoch 27 - iter 70/100 - loss 0.10692284 - samples/sec: 139.79 - lr: 0.000015
2021-07-22 23:32:12,970 epoch 27 - iter 80/100 - loss 0.11249040 - samples/sec: 146.88 - lr: 0.000015
2021-07-22 23:32:15,140 epoch 27 - iter 90/100 - loss 0.11171439 - samples/sec: 147.56 - lr: 0.000015
2021-07-22 23:32:17,255 epoch 27 - iter 100/100 - loss 0.11340582 - samples/sec: 151.30 - lr: 0.000015
2021-07-22 23:32:17,256 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:17,256 EPOCH 27 done: loss 0.1134 - lr 0.0000150
2021-07-22 23:32:18,386 DEV : loss 0.052434977144002914 - score 0.9852
2021-07-22 23:32:18,398 BAD EPOCHS (no improvement): 3
2021-07-22 23:32:18,399 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:20,620 epoch 28 - iter 10/100 - loss 0.10965001 - samples/sec: 144.18 - lr: 0.000015
2021-07-22 23:32:22,884 epoch 28 - iter 20/100 - loss 0.14039890 - samples/sec: 141.38 - lr: 0.000015
2021-07-22 23:32:25,117 epoch 28 - iter 30/100 - loss 0.12464092 - samples/sec: 143.36 - lr: 0.000015
2021-07-22 23:32:27,290 epoch 28 - iter 40/100 - loss 0.12777755 - samples/sec: 147.26 - lr: 0.000015
2021-07-22 23:32:29,419 epoch 28 - iter 50/100 - loss 0.11795262 - samples/sec: 150.35 - lr: 0.000015
2021-07-22 23:32:31,644 epoch 28 - iter 60/100 - loss 0.11649292 - samples/sec: 143.88 - lr: 0.000015
2021-07-22 23:32:33,888 epoch 28 - iter 70/100 - loss 0.11547609 - samples/sec: 142.65 - lr: 0.000015
2021-07-22 23:32:36,031 epoch 28 - iter 80/100 - loss 0.11635774 - samples/sec: 149.38 - lr: 0.000015
2021-07-22 23:32:38,116 epoch 28 - iter 90/100 - loss 0.11476454 - samples/sec: 153.55 - lr: 0.000015
2021-07-22 23:32:40,385 epoch 28 - iter 100/100 - loss 0.11351795 - samples/sec: 141.04 - lr: 0.000015
2021-07-22 23:32:40,386 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:40,386 EPOCH 28 done: loss 0.1135 - lr 0.0000150
2021-07-22 23:32:41,515 DEV : loss 0.05920693278312683 - score 0.9799
Epoch    28: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 23:32:41,527 BAD EPOCHS (no improvement): 4
2021-07-22 23:32:41,527 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:43,667 epoch 29 - iter 10/100 - loss 0.08287881 - samples/sec: 149.68 - lr: 0.000008
2021-07-22 23:32:45,924 epoch 29 - iter 20/100 - loss 0.09432304 - samples/sec: 141.79 - lr: 0.000008
2021-07-22 23:32:48,132 epoch 29 - iter 30/100 - loss 0.11126843 - samples/sec: 145.02 - lr: 0.000008
2021-07-22 23:32:50,404 epoch 29 - iter 40/100 - loss 0.10657624 - samples/sec: 140.86 - lr: 0.000008
2021-07-22 23:32:52,587 epoch 29 - iter 50/100 - loss 0.09974689 - samples/sec: 146.63 - lr: 0.000008
2021-07-22 23:32:54,723 epoch 29 - iter 60/100 - loss 0.09874812 - samples/sec: 149.88 - lr: 0.000008
2021-07-22 23:32:56,919 epoch 29 - iter 70/100 - loss 0.10233143 - samples/sec: 145.78 - lr: 0.000008
2021-07-22 23:32:59,213 epoch 29 - iter 80/100 - loss 0.10171187 - samples/sec: 139.54 - lr: 0.000008
2021-07-22 23:33:01,413 epoch 29 - iter 90/100 - loss 0.10452067 - samples/sec: 145.50 - lr: 0.000008
2021-07-22 23:33:03,609 epoch 29 - iter 100/100 - loss 0.10333728 - samples/sec: 145.73 - lr: 0.000008
2021-07-22 23:33:03,610 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:03,610 EPOCH 29 done: loss 0.1033 - lr 0.0000075
2021-07-22 23:33:04,738 DEV : loss 0.05137158930301666 - score 0.9864
2021-07-22 23:33:04,750 BAD EPOCHS (no improvement): 1
2021-07-22 23:33:04,751 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:06,996 epoch 30 - iter 10/100 - loss 0.15200046 - samples/sec: 142.65 - lr: 0.000008
2021-07-22 23:33:09,290 epoch 30 - iter 20/100 - loss 0.13718359 - samples/sec: 139.48 - lr: 0.000008
2021-07-22 23:33:11,460 epoch 30 - iter 30/100 - loss 0.13153343 - samples/sec: 147.57 - lr: 0.000008
2021-07-22 23:33:13,636 epoch 30 - iter 40/100 - loss 0.12292727 - samples/sec: 147.07 - lr: 0.000008
2021-07-22 23:33:15,868 epoch 30 - iter 50/100 - loss 0.12137722 - samples/sec: 143.42 - lr: 0.000008
2021-07-22 23:33:18,047 epoch 30 - iter 60/100 - loss 0.12110459 - samples/sec: 146.88 - lr: 0.000008
2021-07-22 23:33:20,318 epoch 30 - iter 70/100 - loss 0.12100363 - samples/sec: 141.00 - lr: 0.000008
2021-07-22 23:33:22,526 epoch 30 - iter 80/100 - loss 0.11888838 - samples/sec: 144.91 - lr: 0.000008
2021-07-22 23:33:24,643 epoch 30 - iter 90/100 - loss 0.12257928 - samples/sec: 151.23 - lr: 0.000008
2021-07-22 23:33:26,790 epoch 30 - iter 100/100 - loss 0.12462148 - samples/sec: 149.08 - lr: 0.000008
2021-07-22 23:33:26,791 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:26,791 EPOCH 30 done: loss 0.1246 - lr 0.0000075
2021-07-22 23:33:27,922 DEV : loss 0.050916630774736404 - score 0.9864
2021-07-22 23:33:27,935 BAD EPOCHS (no improvement): 2
2021-07-22 23:33:27,935 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:30,230 epoch 31 - iter 10/100 - loss 0.12849885 - samples/sec: 139.52 - lr: 0.000008
2021-07-22 23:33:32,395 epoch 31 - iter 20/100 - loss 0.13120804 - samples/sec: 147.83 - lr: 0.000008
2021-07-22 23:33:34,508 epoch 31 - iter 30/100 - loss 0.12199893 - samples/sec: 151.54 - lr: 0.000008
2021-07-22 23:33:36,707 epoch 31 - iter 40/100 - loss 0.12532946 - samples/sec: 145.53 - lr: 0.000008
2021-07-22 23:33:38,858 epoch 31 - iter 50/100 - loss 0.12319390 - samples/sec: 148.83 - lr: 0.000008
2021-07-22 23:33:41,115 epoch 31 - iter 60/100 - loss 0.12969726 - samples/sec: 141.85 - lr: 0.000008
2021-07-22 23:33:43,374 epoch 31 - iter 70/100 - loss 0.13188150 - samples/sec: 141.68 - lr: 0.000008
2021-07-22 23:33:45,594 epoch 31 - iter 80/100 - loss 0.12811728 - samples/sec: 144.14 - lr: 0.000008
2021-07-22 23:33:47,812 epoch 31 - iter 90/100 - loss 0.12553172 - samples/sec: 144.35 - lr: 0.000008
2021-07-22 23:33:50,074 epoch 31 - iter 100/100 - loss 0.11998463 - samples/sec: 141.52 - lr: 0.000008
2021-07-22 23:33:50,075 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:50,075 EPOCH 31 done: loss 0.1200 - lr 0.0000075
2021-07-22 23:33:51,202 DEV : loss 0.04975788667798042 - score 0.9878
2021-07-22 23:33:51,214 BAD EPOCHS (no improvement): 3
2021-07-22 23:33:51,215 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:53,399 epoch 32 - iter 10/100 - loss 0.12982169 - samples/sec: 146.61 - lr: 0.000008
2021-07-22 23:33:55,649 epoch 32 - iter 20/100 - loss 0.11976884 - samples/sec: 142.26 - lr: 0.000008
2021-07-22 23:33:57,956 epoch 32 - iter 30/100 - loss 0.11265713 - samples/sec: 138.75 - lr: 0.000008
2021-07-22 23:34:00,132 epoch 32 - iter 40/100 - loss 0.11640179 - samples/sec: 147.11 - lr: 0.000008
2021-07-22 23:34:02,288 epoch 32 - iter 50/100 - loss 0.11219722 - samples/sec: 148.48 - lr: 0.000008
2021-07-22 23:34:04,571 epoch 32 - iter 60/100 - loss 0.11588951 - samples/sec: 140.21 - lr: 0.000008
2021-07-22 23:34:06,832 epoch 32 - iter 70/100 - loss 0.11637756 - samples/sec: 141.59 - lr: 0.000008
2021-07-22 23:34:08,944 epoch 32 - iter 80/100 - loss 0.11763608 - samples/sec: 151.53 - lr: 0.000008
2021-07-22 23:34:11,088 epoch 32 - iter 90/100 - loss 0.11862663 - samples/sec: 149.31 - lr: 0.000008
2021-07-22 23:34:13,239 epoch 32 - iter 100/100 - loss 0.11943105 - samples/sec: 148.85 - lr: 0.000008
2021-07-22 23:34:13,240 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:13,240 EPOCH 32 done: loss 0.1194 - lr 0.0000075
2021-07-22 23:34:14,365 DEV : loss 0.05389179661870003 - score 0.9825
Epoch    32: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 23:34:14,380 BAD EPOCHS (no improvement): 4
2021-07-22 23:34:14,381 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:16,558 epoch 33 - iter 10/100 - loss 0.14485674 - samples/sec: 147.07 - lr: 0.000004
2021-07-22 23:34:18,759 epoch 33 - iter 20/100 - loss 0.13281824 - samples/sec: 145.48 - lr: 0.000004
2021-07-22 23:34:20,976 epoch 33 - iter 30/100 - loss 0.12233492 - samples/sec: 144.36 - lr: 0.000004
2021-07-22 23:34:23,209 epoch 33 - iter 40/100 - loss 0.11587831 - samples/sec: 143.34 - lr: 0.000004
2021-07-22 23:34:25,408 epoch 33 - iter 50/100 - loss 0.10871058 - samples/sec: 145.60 - lr: 0.000004
2021-07-22 23:34:27,552 epoch 33 - iter 60/100 - loss 0.11001118 - samples/sec: 149.31 - lr: 0.000004
2021-07-22 23:34:29,779 epoch 33 - iter 70/100 - loss 0.11055090 - samples/sec: 143.72 - lr: 0.000004
2021-07-22 23:34:31,952 epoch 33 - iter 80/100 - loss 0.11158855 - samples/sec: 147.36 - lr: 0.000004
2021-07-22 23:34:34,108 epoch 33 - iter 90/100 - loss 0.11303326 - samples/sec: 148.47 - lr: 0.000004
2021-07-22 23:34:36,307 epoch 33 - iter 100/100 - loss 0.11334394 - samples/sec: 145.56 - lr: 0.000004
2021-07-22 23:34:36,308 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:36,308 EPOCH 33 done: loss 0.1133 - lr 0.0000038
2021-07-22 23:34:37,436 DEV : loss 0.052150990813970566 - score 0.9838
2021-07-22 23:34:37,452 BAD EPOCHS (no improvement): 1
2021-07-22 23:34:37,453 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:39,601 epoch 34 - iter 10/100 - loss 0.11656166 - samples/sec: 149.05 - lr: 0.000004
2021-07-22 23:34:41,823 epoch 34 - iter 20/100 - loss 0.13557213 - samples/sec: 144.04 - lr: 0.000004
2021-07-22 23:34:43,931 epoch 34 - iter 30/100 - loss 0.14071124 - samples/sec: 151.86 - lr: 0.000004
2021-07-22 23:34:46,131 epoch 34 - iter 40/100 - loss 0.13567416 - samples/sec: 145.52 - lr: 0.000004
2021-07-22 23:34:48,312 epoch 34 - iter 50/100 - loss 0.12838917 - samples/sec: 146.76 - lr: 0.000004
2021-07-22 23:34:50,560 epoch 34 - iter 60/100 - loss 0.12745501 - samples/sec: 142.38 - lr: 0.000004
2021-07-22 23:34:52,715 epoch 34 - iter 70/100 - loss 0.11970822 - samples/sec: 148.54 - lr: 0.000004
2021-07-22 23:34:54,935 epoch 34 - iter 80/100 - loss 0.11942551 - samples/sec: 144.20 - lr: 0.000004
2021-07-22 23:34:57,129 epoch 34 - iter 90/100 - loss 0.12291940 - samples/sec: 145.91 - lr: 0.000004
2021-07-22 23:34:59,325 epoch 34 - iter 100/100 - loss 0.12083607 - samples/sec: 145.73 - lr: 0.000004
2021-07-22 23:34:59,326 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:59,327 EPOCH 34 done: loss 0.1208 - lr 0.0000038
2021-07-22 23:35:00,454 DEV : loss 0.05168110877275467 - score 0.9851
2021-07-22 23:35:00,469 BAD EPOCHS (no improvement): 2
2021-07-22 23:35:00,470 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:02,684 epoch 35 - iter 10/100 - loss 0.10879364 - samples/sec: 144.65 - lr: 0.000004
2021-07-22 23:35:04,798 epoch 35 - iter 20/100 - loss 0.09324805 - samples/sec: 151.36 - lr: 0.000004
2021-07-22 23:35:06,985 epoch 35 - iter 30/100 - loss 0.10870168 - samples/sec: 146.40 - lr: 0.000004
2021-07-22 23:35:09,187 epoch 35 - iter 40/100 - loss 0.11099322 - samples/sec: 145.34 - lr: 0.000004
2021-07-22 23:35:11,431 epoch 35 - iter 50/100 - loss 0.10719397 - samples/sec: 142.69 - lr: 0.000004
2021-07-22 23:35:13,574 epoch 35 - iter 60/100 - loss 0.10362789 - samples/sec: 149.33 - lr: 0.000004
2021-07-22 23:35:15,815 epoch 35 - iter 70/100 - loss 0.10789104 - samples/sec: 142.85 - lr: 0.000004
2021-07-22 23:35:18,051 epoch 35 - iter 80/100 - loss 0.10673615 - samples/sec: 143.14 - lr: 0.000004
2021-07-22 23:35:20,318 epoch 35 - iter 90/100 - loss 0.10792757 - samples/sec: 141.19 - lr: 0.000004
2021-07-22 23:35:22,483 epoch 35 - iter 100/100 - loss 0.11319923 - samples/sec: 147.90 - lr: 0.000004
2021-07-22 23:35:22,484 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:22,484 EPOCH 35 done: loss 0.1132 - lr 0.0000038
2021-07-22 23:35:23,614 DEV : loss 0.05244991555809975 - score 0.9825
2021-07-22 23:35:23,626 BAD EPOCHS (no improvement): 3
2021-07-22 23:35:23,626 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:25,664 epoch 36 - iter 10/100 - loss 0.08159030 - samples/sec: 157.21 - lr: 0.000004
2021-07-22 23:35:27,913 epoch 36 - iter 20/100 - loss 0.10583029 - samples/sec: 142.30 - lr: 0.000004
2021-07-22 23:35:30,054 epoch 36 - iter 30/100 - loss 0.11511912 - samples/sec: 149.51 - lr: 0.000004
2021-07-22 23:35:32,291 epoch 36 - iter 40/100 - loss 0.11533731 - samples/sec: 143.12 - lr: 0.000004
2021-07-22 23:35:34,399 epoch 36 - iter 50/100 - loss 0.12585734 - samples/sec: 151.81 - lr: 0.000004
2021-07-22 23:35:36,619 epoch 36 - iter 60/100 - loss 0.12994160 - samples/sec: 144.20 - lr: 0.000004
2021-07-22 23:35:38,831 epoch 36 - iter 70/100 - loss 0.12794974 - samples/sec: 144.70 - lr: 0.000004
2021-07-22 23:35:41,148 epoch 36 - iter 80/100 - loss 0.12731871 - samples/sec: 138.17 - lr: 0.000004
2021-07-22 23:35:43,300 epoch 36 - iter 90/100 - loss 0.12867644 - samples/sec: 148.75 - lr: 0.000004
2021-07-22 23:35:45,559 epoch 36 - iter 100/100 - loss 0.13108168 - samples/sec: 141.71 - lr: 0.000004
2021-07-22 23:35:45,560 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:45,560 EPOCH 36 done: loss 0.1311 - lr 0.0000038
2021-07-22 23:35:46,681 DEV : loss 0.0516129694879055 - score 0.9838
Epoch    36: reducing learning rate of group 0 to 1.8750e-06.
2021-07-22 23:35:46,694 BAD EPOCHS (no improvement): 4
2021-07-22 23:35:46,694 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:46,694 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:46,694 learning rate too small - quitting training!
2021-07-22 23:35:46,694 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:47,319 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:47,319 Testing using best model ...
2021-07-22 23:35:47,320 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/deu.rst.pcc/best-model.pt
2021-07-22 23:36:02,759 0.9835	0.9898	0.9866
2021-07-22 23:36:02,760 
Results:
- F1-score (micro) 0.9866
- F1-score (macro) 0.9883

By class:
SENT       tp: 438 - fp: 13 - fn: 8 - precision: 0.9712 - recall: 0.9821 - f1-score: 0.9766
X          tp: 335 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 23:36:02,760 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/spa.rst.sctb/
2021-07-22 23:36:02,792 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/spa.rst.sctb
2021-07-22 23:36:02,793 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/spa.rst.sctb/sent_train.txt
2021-07-22 23:36:02,794 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/spa.rst.sctb/sent_dev.txt
2021-07-22 23:36:02,796 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/spa.rst.sctb/sent_test.txt
Corpus: 1063 train + 302 dev + 220 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 23:36:19,740 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:19,741 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 23:36:19,742 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:19,742 Corpus: "Corpus: 1063 train + 302 dev + 220 test sentences"
2021-07-22 23:36:19,742 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:19,742 Parameters:
2021-07-22 23:36:19,742  - learning_rate: "3e-05"
2021-07-22 23:36:19,742  - mini_batch_size: "32"
2021-07-22 23:36:19,742  - patience: "3"
2021-07-22 23:36:19,742  - anneal_factor: "0.5"
2021-07-22 23:36:19,742  - max_epochs: "40"
2021-07-22 23:36:19,742  - shuffle: "True"
2021-07-22 23:36:19,742  - train_with_dev: "False"
2021-07-22 23:36:19,742  - batch_growth_annealing: "False"
2021-07-22 23:36:19,742 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:19,742 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/spa.rst.sctb"
2021-07-22 23:36:19,742 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:19,742 Device: cuda:0
2021-07-22 23:36:19,742 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:19,742 Embeddings storage mode: cpu
2021-07-22 23:36:19,745 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:21,513 epoch 1 - iter 3/34 - loss 26.45487849 - samples/sec: 54.33 - lr: 0.000030
2021-07-22 23:36:23,300 epoch 1 - iter 6/34 - loss 25.86143621 - samples/sec: 53.72 - lr: 0.000030
2021-07-22 23:36:25,051 epoch 1 - iter 9/34 - loss 24.91815461 - samples/sec: 54.83 - lr: 0.000030
2021-07-22 23:36:26,806 epoch 1 - iter 12/34 - loss 24.34155146 - samples/sec: 54.73 - lr: 0.000030
2021-07-22 23:36:28,592 epoch 1 - iter 15/34 - loss 24.12106285 - samples/sec: 53.74 - lr: 0.000030
2021-07-22 23:36:30,388 epoch 1 - iter 18/34 - loss 23.92030599 - samples/sec: 53.48 - lr: 0.000030
2021-07-22 23:36:32,167 epoch 1 - iter 21/34 - loss 23.49900173 - samples/sec: 53.95 - lr: 0.000030
2021-07-22 23:36:33,938 epoch 1 - iter 24/34 - loss 23.12604769 - samples/sec: 54.22 - lr: 0.000030
2021-07-22 23:36:35,681 epoch 1 - iter 27/34 - loss 22.67334641 - samples/sec: 55.09 - lr: 0.000030
2021-07-22 23:36:37,482 epoch 1 - iter 30/34 - loss 22.41237742 - samples/sec: 53.31 - lr: 0.000030
2021-07-22 23:36:39,244 epoch 1 - iter 33/34 - loss 21.90324124 - samples/sec: 54.48 - lr: 0.000030
2021-07-22 23:36:39,406 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:39,407 EPOCH 1 done: loss 21.7290 - lr 0.0000300
2021-07-22 23:36:43,826 DEV : loss 16.573280334472656 - score 0.0
2021-07-22 23:36:43,835 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:36:44,449 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:45,183 epoch 2 - iter 3/34 - loss 16.40162341 - samples/sec: 131.01 - lr: 0.000030
2021-07-22 23:36:45,827 epoch 2 - iter 6/34 - loss 14.91654650 - samples/sec: 149.20 - lr: 0.000030
2021-07-22 23:36:46,551 epoch 2 - iter 9/34 - loss 15.13201968 - samples/sec: 132.63 - lr: 0.000030
2021-07-22 23:36:47,344 epoch 2 - iter 12/34 - loss 15.69883664 - samples/sec: 121.10 - lr: 0.000030
2021-07-22 23:36:48,123 epoch 2 - iter 15/34 - loss 15.80855198 - samples/sec: 123.41 - lr: 0.000030
2021-07-22 23:36:48,884 epoch 2 - iter 18/34 - loss 15.69980595 - samples/sec: 126.08 - lr: 0.000030
2021-07-22 23:36:49,575 epoch 2 - iter 21/34 - loss 15.14499265 - samples/sec: 139.00 - lr: 0.000030
2021-07-22 23:36:50,347 epoch 2 - iter 24/34 - loss 14.93470263 - samples/sec: 124.50 - lr: 0.000030
2021-07-22 23:36:51,069 epoch 2 - iter 27/34 - loss 14.72054739 - samples/sec: 133.09 - lr: 0.000030
2021-07-22 23:36:51,847 epoch 2 - iter 30/34 - loss 14.52467982 - samples/sec: 123.38 - lr: 0.000030
2021-07-22 23:36:52,577 epoch 2 - iter 33/34 - loss 14.15713316 - samples/sec: 131.53 - lr: 0.000030
2021-07-22 23:36:52,666 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:52,667 EPOCH 2 done: loss 13.9591 - lr 0.0000300
2021-07-22 23:36:53,442 DEV : loss 7.128775119781494 - score 0.0
2021-07-22 23:36:53,451 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:36:56,252 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:57,095 epoch 3 - iter 3/34 - loss 12.88962364 - samples/sec: 114.05 - lr: 0.000030
2021-07-22 23:36:57,827 epoch 3 - iter 6/34 - loss 11.15443722 - samples/sec: 131.32 - lr: 0.000030
2021-07-22 23:36:58,507 epoch 3 - iter 9/34 - loss 10.34016715 - samples/sec: 141.29 - lr: 0.000030
2021-07-22 23:36:59,259 epoch 3 - iter 12/34 - loss 10.01131948 - samples/sec: 127.71 - lr: 0.000030
2021-07-22 23:37:00,013 epoch 3 - iter 15/34 - loss 9.58161201 - samples/sec: 127.38 - lr: 0.000030
2021-07-22 23:37:00,744 epoch 3 - iter 18/34 - loss 9.07314791 - samples/sec: 131.44 - lr: 0.000030
2021-07-22 23:37:01,451 epoch 3 - iter 21/34 - loss 8.68865871 - samples/sec: 135.79 - lr: 0.000030
2021-07-22 23:37:02,207 epoch 3 - iter 24/34 - loss 8.49138208 - samples/sec: 126.96 - lr: 0.000030
2021-07-22 23:37:02,965 epoch 3 - iter 27/34 - loss 8.24091722 - samples/sec: 126.86 - lr: 0.000030
2021-07-22 23:37:03,642 epoch 3 - iter 30/34 - loss 7.88549919 - samples/sec: 141.74 - lr: 0.000030
2021-07-22 23:37:04,362 epoch 3 - iter 33/34 - loss 7.57363794 - samples/sec: 133.43 - lr: 0.000030
2021-07-22 23:37:04,470 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:04,471 EPOCH 3 done: loss 7.4791 - lr 0.0000300
2021-07-22 23:37:05,236 DEV : loss 2.588526487350464 - score 0.0
2021-07-22 23:37:05,246 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:37:07,495 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:08,266 epoch 4 - iter 3/34 - loss 3.84612258 - samples/sec: 124.92 - lr: 0.000030
2021-07-22 23:37:08,994 epoch 4 - iter 6/34 - loss 3.59702003 - samples/sec: 131.95 - lr: 0.000030
2021-07-22 23:37:09,722 epoch 4 - iter 9/34 - loss 3.56325144 - samples/sec: 131.99 - lr: 0.000030
2021-07-22 23:37:10,373 epoch 4 - iter 12/34 - loss 3.49050860 - samples/sec: 147.49 - lr: 0.000030
2021-07-22 23:37:11,134 epoch 4 - iter 15/34 - loss 3.42606548 - samples/sec: 126.16 - lr: 0.000030
2021-07-22 23:37:11,817 epoch 4 - iter 18/34 - loss 3.23604135 - samples/sec: 140.74 - lr: 0.000030
2021-07-22 23:37:12,555 epoch 4 - iter 21/34 - loss 3.15726955 - samples/sec: 130.20 - lr: 0.000030
2021-07-22 23:37:13,319 epoch 4 - iter 24/34 - loss 3.05461975 - samples/sec: 125.77 - lr: 0.000030
2021-07-22 23:37:14,078 epoch 4 - iter 27/34 - loss 2.98529053 - samples/sec: 126.49 - lr: 0.000030
2021-07-22 23:37:14,770 epoch 4 - iter 30/34 - loss 2.91718841 - samples/sec: 138.84 - lr: 0.000030
2021-07-22 23:37:15,574 epoch 4 - iter 33/34 - loss 2.84560453 - samples/sec: 119.46 - lr: 0.000030
2021-07-22 23:37:15,663 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:15,663 EPOCH 4 done: loss 2.7882 - lr 0.0000300
2021-07-22 23:37:16,428 DEV : loss 1.583413004875183 - score 0.0
2021-07-22 23:37:16,437 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:37:18,640 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:19,328 epoch 5 - iter 3/34 - loss 1.88095041 - samples/sec: 139.86 - lr: 0.000030
2021-07-22 23:37:20,081 epoch 5 - iter 6/34 - loss 1.85207180 - samples/sec: 127.61 - lr: 0.000030
2021-07-22 23:37:20,803 epoch 5 - iter 9/34 - loss 1.79848060 - samples/sec: 133.07 - lr: 0.000030
2021-07-22 23:37:21,532 epoch 5 - iter 12/34 - loss 1.74569517 - samples/sec: 131.78 - lr: 0.000030
2021-07-22 23:37:22,258 epoch 5 - iter 15/34 - loss 1.72866244 - samples/sec: 132.18 - lr: 0.000030
2021-07-22 23:37:22,995 epoch 5 - iter 18/34 - loss 1.66893644 - samples/sec: 130.42 - lr: 0.000030
2021-07-22 23:37:23,743 epoch 5 - iter 21/34 - loss 1.63854337 - samples/sec: 128.32 - lr: 0.000030
2021-07-22 23:37:24,447 epoch 5 - iter 24/34 - loss 1.58843012 - samples/sec: 136.56 - lr: 0.000030
2021-07-22 23:37:25,203 epoch 5 - iter 27/34 - loss 1.55222642 - samples/sec: 126.94 - lr: 0.000030
2021-07-22 23:37:25,978 epoch 5 - iter 30/34 - loss 1.51929995 - samples/sec: 123.90 - lr: 0.000030
2021-07-22 23:37:26,719 epoch 5 - iter 33/34 - loss 1.48355780 - samples/sec: 129.67 - lr: 0.000030
2021-07-22 23:37:26,814 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:26,814 EPOCH 5 done: loss 1.4718 - lr 0.0000300
2021-07-22 23:37:27,580 DEV : loss 0.9305666089057922 - score 0.7595
2021-07-22 23:37:27,589 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:37:29,788 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:30,505 epoch 6 - iter 3/34 - loss 1.13063176 - samples/sec: 134.40 - lr: 0.000030
2021-07-22 23:37:31,217 epoch 6 - iter 6/34 - loss 1.16896439 - samples/sec: 134.88 - lr: 0.000030
2021-07-22 23:37:31,976 epoch 6 - iter 9/34 - loss 1.17028965 - samples/sec: 126.46 - lr: 0.000030
2021-07-22 23:37:32,711 epoch 6 - iter 12/34 - loss 1.13874874 - samples/sec: 130.79 - lr: 0.000030
2021-07-22 23:37:33,426 epoch 6 - iter 15/34 - loss 1.08146036 - samples/sec: 134.28 - lr: 0.000030
2021-07-22 23:37:34,185 epoch 6 - iter 18/34 - loss 1.08296467 - samples/sec: 126.60 - lr: 0.000030
2021-07-22 23:37:34,906 epoch 6 - iter 21/34 - loss 1.05603871 - samples/sec: 133.14 - lr: 0.000030
2021-07-22 23:37:35,661 epoch 6 - iter 24/34 - loss 1.02346551 - samples/sec: 127.38 - lr: 0.000030
2021-07-22 23:37:36,410 epoch 6 - iter 27/34 - loss 1.00287873 - samples/sec: 128.18 - lr: 0.000030
2021-07-22 23:37:37,131 epoch 6 - iter 30/34 - loss 0.99260319 - samples/sec: 133.19 - lr: 0.000030
2021-07-22 23:37:37,967 epoch 6 - iter 33/34 - loss 0.97837169 - samples/sec: 114.91 - lr: 0.000030
2021-07-22 23:37:38,047 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:38,047 EPOCH 6 done: loss 0.9724 - lr 0.0000300
2021-07-22 23:37:38,815 DEV : loss 0.6199407577514648 - score 0.7634
2021-07-22 23:37:38,824 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:37:41,089 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:41,811 epoch 7 - iter 3/34 - loss 0.83452284 - samples/sec: 133.32 - lr: 0.000030
2021-07-22 23:37:42,538 epoch 7 - iter 6/34 - loss 0.79056039 - samples/sec: 132.12 - lr: 0.000030
2021-07-22 23:37:43,328 epoch 7 - iter 9/34 - loss 0.75553497 - samples/sec: 121.54 - lr: 0.000030
2021-07-22 23:37:44,114 epoch 7 - iter 12/34 - loss 0.73229992 - samples/sec: 122.21 - lr: 0.000030
2021-07-22 23:37:44,873 epoch 7 - iter 15/34 - loss 0.73778035 - samples/sec: 126.62 - lr: 0.000030
2021-07-22 23:37:45,563 epoch 7 - iter 18/34 - loss 0.72914801 - samples/sec: 139.14 - lr: 0.000030
2021-07-22 23:37:46,337 epoch 7 - iter 21/34 - loss 0.72940539 - samples/sec: 124.13 - lr: 0.000030
2021-07-22 23:37:47,007 epoch 7 - iter 24/34 - loss 0.72365551 - samples/sec: 143.30 - lr: 0.000030
2021-07-22 23:37:47,740 epoch 7 - iter 27/34 - loss 0.72791141 - samples/sec: 131.12 - lr: 0.000030
2021-07-22 23:37:48,479 epoch 7 - iter 30/34 - loss 0.70814759 - samples/sec: 129.86 - lr: 0.000030
2021-07-22 23:37:49,180 epoch 7 - iter 33/34 - loss 0.69695724 - samples/sec: 137.09 - lr: 0.000030
2021-07-22 23:37:49,276 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:49,276 EPOCH 7 done: loss 0.6921 - lr 0.0000300
2021-07-22 23:37:50,044 DEV : loss 0.40906429290771484 - score 0.8263
2021-07-22 23:37:50,053 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:37:52,137 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:52,873 epoch 8 - iter 3/34 - loss 0.66882626 - samples/sec: 130.70 - lr: 0.000030
2021-07-22 23:37:53,586 epoch 8 - iter 6/34 - loss 0.64877342 - samples/sec: 134.69 - lr: 0.000030
2021-07-22 23:37:54,288 epoch 8 - iter 9/34 - loss 0.60112588 - samples/sec: 136.96 - lr: 0.000030
2021-07-22 23:37:55,065 epoch 8 - iter 12/34 - loss 0.58442461 - samples/sec: 123.63 - lr: 0.000030
2021-07-22 23:37:55,764 epoch 8 - iter 15/34 - loss 0.57127750 - samples/sec: 137.42 - lr: 0.000030
2021-07-22 23:37:56,515 epoch 8 - iter 18/34 - loss 0.57717556 - samples/sec: 127.84 - lr: 0.000030
2021-07-22 23:37:57,241 epoch 8 - iter 21/34 - loss 0.57084186 - samples/sec: 132.36 - lr: 0.000030
2021-07-22 23:37:58,044 epoch 8 - iter 24/34 - loss 0.56674132 - samples/sec: 119.52 - lr: 0.000030
2021-07-22 23:37:58,783 epoch 8 - iter 27/34 - loss 0.56091494 - samples/sec: 129.92 - lr: 0.000030
2021-07-22 23:37:59,544 epoch 8 - iter 30/34 - loss 0.55707386 - samples/sec: 126.35 - lr: 0.000030
2021-07-22 23:38:00,291 epoch 8 - iter 33/34 - loss 0.55222561 - samples/sec: 128.49 - lr: 0.000030
2021-07-22 23:38:00,377 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:00,377 EPOCH 8 done: loss 0.5494 - lr 0.0000300
2021-07-22 23:38:01,144 DEV : loss 0.2918253242969513 - score 0.9231
2021-07-22 23:38:01,153 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:38:03,277 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:04,056 epoch 9 - iter 3/34 - loss 0.46246746 - samples/sec: 123.61 - lr: 0.000030
2021-07-22 23:38:04,779 epoch 9 - iter 6/34 - loss 0.46751891 - samples/sec: 132.82 - lr: 0.000030
2021-07-22 23:38:05,555 epoch 9 - iter 9/34 - loss 0.46340043 - samples/sec: 123.85 - lr: 0.000030
2021-07-22 23:38:06,316 epoch 9 - iter 12/34 - loss 0.47735459 - samples/sec: 126.13 - lr: 0.000030
2021-07-22 23:38:07,053 epoch 9 - iter 15/34 - loss 0.46939444 - samples/sec: 130.41 - lr: 0.000030
2021-07-22 23:38:07,796 epoch 9 - iter 18/34 - loss 0.45799481 - samples/sec: 129.20 - lr: 0.000030
2021-07-22 23:38:08,569 epoch 9 - iter 21/34 - loss 0.45077802 - samples/sec: 124.37 - lr: 0.000030
2021-07-22 23:38:09,243 epoch 9 - iter 24/34 - loss 0.42920345 - samples/sec: 142.50 - lr: 0.000030
2021-07-22 23:38:10,027 epoch 9 - iter 27/34 - loss 0.42693527 - samples/sec: 122.40 - lr: 0.000030
2021-07-22 23:38:10,711 epoch 9 - iter 30/34 - loss 0.41305169 - samples/sec: 140.51 - lr: 0.000030
2021-07-22 23:38:11,459 epoch 9 - iter 33/34 - loss 0.41460994 - samples/sec: 128.33 - lr: 0.000030
2021-07-22 23:38:11,526 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:11,526 EPOCH 9 done: loss 0.4086 - lr 0.0000300
2021-07-22 23:38:12,296 DEV : loss 0.2125687450170517 - score 0.9521
2021-07-22 23:38:12,309 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:38:14,373 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:15,134 epoch 10 - iter 3/34 - loss 0.50010946 - samples/sec: 126.46 - lr: 0.000030
2021-07-22 23:38:15,961 epoch 10 - iter 6/34 - loss 0.45127467 - samples/sec: 116.18 - lr: 0.000030
2021-07-22 23:38:16,641 epoch 10 - iter 9/34 - loss 0.39078726 - samples/sec: 141.32 - lr: 0.000030
2021-07-22 23:38:17,340 epoch 10 - iter 12/34 - loss 0.37345299 - samples/sec: 137.33 - lr: 0.000030
2021-07-22 23:38:18,068 epoch 10 - iter 15/34 - loss 0.36666686 - samples/sec: 131.93 - lr: 0.000030
2021-07-22 23:38:18,829 epoch 10 - iter 18/34 - loss 0.36882887 - samples/sec: 126.17 - lr: 0.000030
2021-07-22 23:38:19,584 epoch 10 - iter 21/34 - loss 0.36627499 - samples/sec: 127.32 - lr: 0.000030
2021-07-22 23:38:20,263 epoch 10 - iter 24/34 - loss 0.36833639 - samples/sec: 141.44 - lr: 0.000030
2021-07-22 23:38:20,985 epoch 10 - iter 27/34 - loss 0.35823998 - samples/sec: 133.08 - lr: 0.000030
2021-07-22 23:38:21,732 epoch 10 - iter 30/34 - loss 0.34653278 - samples/sec: 128.45 - lr: 0.000030
2021-07-22 23:38:22,456 epoch 10 - iter 33/34 - loss 0.33896487 - samples/sec: 132.83 - lr: 0.000030
2021-07-22 23:38:22,547 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:22,547 EPOCH 10 done: loss 0.3427 - lr 0.0000300
2021-07-22 23:38:23,318 DEV : loss 0.16938792169094086 - score 0.9659
2021-07-22 23:38:23,330 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:38:25,381 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:26,130 epoch 11 - iter 3/34 - loss 0.29680049 - samples/sec: 128.54 - lr: 0.000030
2021-07-22 23:38:26,867 epoch 11 - iter 6/34 - loss 0.29815361 - samples/sec: 130.38 - lr: 0.000030
2021-07-22 23:38:27,576 epoch 11 - iter 9/34 - loss 0.29436445 - samples/sec: 135.44 - lr: 0.000030
2021-07-22 23:38:28,284 epoch 11 - iter 12/34 - loss 0.28592741 - samples/sec: 135.68 - lr: 0.000030
2021-07-22 23:38:29,008 epoch 11 - iter 15/34 - loss 0.26396977 - samples/sec: 132.57 - lr: 0.000030
2021-07-22 23:38:29,747 epoch 11 - iter 18/34 - loss 0.27345045 - samples/sec: 130.13 - lr: 0.000030
2021-07-22 23:38:30,448 epoch 11 - iter 21/34 - loss 0.27856932 - samples/sec: 137.00 - lr: 0.000030
2021-07-22 23:38:31,196 epoch 11 - iter 24/34 - loss 0.27816404 - samples/sec: 128.31 - lr: 0.000030
2021-07-22 23:38:31,916 epoch 11 - iter 27/34 - loss 0.28216738 - samples/sec: 133.53 - lr: 0.000030
2021-07-22 23:38:32,670 epoch 11 - iter 30/34 - loss 0.28743438 - samples/sec: 127.26 - lr: 0.000030
2021-07-22 23:38:33,425 epoch 11 - iter 33/34 - loss 0.28968739 - samples/sec: 127.25 - lr: 0.000030
2021-07-22 23:38:33,515 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:33,515 EPOCH 11 done: loss 0.2958 - lr 0.0000300
2021-07-22 23:38:34,282 DEV : loss 0.13799725472927094 - score 0.9713
2021-07-22 23:38:34,291 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:38:36,462 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:37,228 epoch 12 - iter 3/34 - loss 0.37226336 - samples/sec: 125.67 - lr: 0.000030
2021-07-22 23:38:37,959 epoch 12 - iter 6/34 - loss 0.27129962 - samples/sec: 131.36 - lr: 0.000030
2021-07-22 23:38:38,704 epoch 12 - iter 9/34 - loss 0.25188907 - samples/sec: 129.00 - lr: 0.000030
2021-07-22 23:38:39,459 epoch 12 - iter 12/34 - loss 0.24892844 - samples/sec: 127.22 - lr: 0.000030
2021-07-22 23:38:40,160 epoch 12 - iter 15/34 - loss 0.26654711 - samples/sec: 137.03 - lr: 0.000030
2021-07-22 23:38:40,939 epoch 12 - iter 18/34 - loss 0.25902735 - samples/sec: 123.17 - lr: 0.000030
2021-07-22 23:38:41,687 epoch 12 - iter 21/34 - loss 0.25200409 - samples/sec: 128.57 - lr: 0.000030
2021-07-22 23:38:42,445 epoch 12 - iter 24/34 - loss 0.25413437 - samples/sec: 126.61 - lr: 0.000030
2021-07-22 23:38:43,185 epoch 12 - iter 27/34 - loss 0.24937569 - samples/sec: 129.88 - lr: 0.000030
2021-07-22 23:38:43,924 epoch 12 - iter 30/34 - loss 0.24935932 - samples/sec: 129.98 - lr: 0.000030
2021-07-22 23:38:44,635 epoch 12 - iter 33/34 - loss 0.25019121 - samples/sec: 135.06 - lr: 0.000030
2021-07-22 23:38:44,719 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:44,719 EPOCH 12 done: loss 0.2450 - lr 0.0000300
2021-07-22 23:38:45,568 DEV : loss 0.1192685142159462 - score 0.9714
2021-07-22 23:38:45,578 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:38:47,853 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:48,532 epoch 13 - iter 3/34 - loss 0.19562434 - samples/sec: 141.95 - lr: 0.000030
2021-07-22 23:38:49,332 epoch 13 - iter 6/34 - loss 0.21245237 - samples/sec: 120.04 - lr: 0.000030
2021-07-22 23:38:50,059 epoch 13 - iter 9/34 - loss 0.22176869 - samples/sec: 132.01 - lr: 0.000030
2021-07-22 23:38:50,848 epoch 13 - iter 12/34 - loss 0.22141171 - samples/sec: 121.78 - lr: 0.000030
2021-07-22 23:38:51,551 epoch 13 - iter 15/34 - loss 0.23792286 - samples/sec: 136.69 - lr: 0.000030
2021-07-22 23:38:52,245 epoch 13 - iter 18/34 - loss 0.24485183 - samples/sec: 138.30 - lr: 0.000030
2021-07-22 23:38:53,018 epoch 13 - iter 21/34 - loss 0.23240648 - samples/sec: 124.23 - lr: 0.000030
2021-07-22 23:38:53,740 epoch 13 - iter 24/34 - loss 0.23278120 - samples/sec: 133.07 - lr: 0.000030
2021-07-22 23:38:54,430 epoch 13 - iter 27/34 - loss 0.22918377 - samples/sec: 139.38 - lr: 0.000030
2021-07-22 23:38:55,169 epoch 13 - iter 30/34 - loss 0.23361958 - samples/sec: 129.89 - lr: 0.000030
2021-07-22 23:38:55,945 epoch 13 - iter 33/34 - loss 0.23456724 - samples/sec: 123.89 - lr: 0.000030
2021-07-22 23:38:56,044 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:56,044 EPOCH 13 done: loss 0.2347 - lr 0.0000300
2021-07-22 23:38:56,812 DEV : loss 0.1025267168879509 - score 0.9741
2021-07-22 23:38:56,822 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:38:59,108 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:59,861 epoch 14 - iter 3/34 - loss 0.18176716 - samples/sec: 127.87 - lr: 0.000030
2021-07-22 23:39:00,604 epoch 14 - iter 6/34 - loss 0.21013884 - samples/sec: 129.16 - lr: 0.000030
2021-07-22 23:39:01,343 epoch 14 - iter 9/34 - loss 0.20894834 - samples/sec: 130.07 - lr: 0.000030
2021-07-22 23:39:02,027 epoch 14 - iter 12/34 - loss 0.22060268 - samples/sec: 140.49 - lr: 0.000030
2021-07-22 23:39:02,773 epoch 14 - iter 15/34 - loss 0.21278295 - samples/sec: 128.63 - lr: 0.000030
2021-07-22 23:39:03,540 epoch 14 - iter 18/34 - loss 0.20988958 - samples/sec: 125.26 - lr: 0.000030
2021-07-22 23:39:04,299 epoch 14 - iter 21/34 - loss 0.21802911 - samples/sec: 126.55 - lr: 0.000030
2021-07-22 23:39:05,031 epoch 14 - iter 24/34 - loss 0.21784129 - samples/sec: 131.33 - lr: 0.000030
2021-07-22 23:39:05,845 epoch 14 - iter 27/34 - loss 0.21711551 - samples/sec: 117.96 - lr: 0.000030
2021-07-22 23:39:06,535 epoch 14 - iter 30/34 - loss 0.21396133 - samples/sec: 139.28 - lr: 0.000030
2021-07-22 23:39:07,235 epoch 14 - iter 33/34 - loss 0.21442271 - samples/sec: 137.19 - lr: 0.000030
2021-07-22 23:39:07,326 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:07,326 EPOCH 14 done: loss 0.2172 - lr 0.0000300
2021-07-22 23:39:08,093 DEV : loss 0.09072936326265335 - score 0.9741
2021-07-22 23:39:08,103 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:10,409 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:11,123 epoch 15 - iter 3/34 - loss 0.12933923 - samples/sec: 134.85 - lr: 0.000030
2021-07-22 23:39:11,893 epoch 15 - iter 6/34 - loss 0.15612789 - samples/sec: 124.81 - lr: 0.000030
2021-07-22 23:39:12,607 epoch 15 - iter 9/34 - loss 0.18872769 - samples/sec: 134.47 - lr: 0.000030
2021-07-22 23:39:13,402 epoch 15 - iter 12/34 - loss 0.17788365 - samples/sec: 120.85 - lr: 0.000030
2021-07-22 23:39:14,147 epoch 15 - iter 15/34 - loss 0.18744989 - samples/sec: 128.82 - lr: 0.000030
2021-07-22 23:39:14,870 epoch 15 - iter 18/34 - loss 0.18480705 - samples/sec: 132.93 - lr: 0.000030
2021-07-22 23:39:15,620 epoch 15 - iter 21/34 - loss 0.19839298 - samples/sec: 128.07 - lr: 0.000030
2021-07-22 23:39:16,368 epoch 15 - iter 24/34 - loss 0.19114925 - samples/sec: 128.41 - lr: 0.000030
2021-07-22 23:39:17,108 epoch 15 - iter 27/34 - loss 0.19136037 - samples/sec: 129.74 - lr: 0.000030
2021-07-22 23:39:17,844 epoch 15 - iter 30/34 - loss 0.18615839 - samples/sec: 130.61 - lr: 0.000030
2021-07-22 23:39:18,583 epoch 15 - iter 33/34 - loss 0.18557513 - samples/sec: 129.86 - lr: 0.000030
2021-07-22 23:39:18,662 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:18,662 EPOCH 15 done: loss 0.1809 - lr 0.0000300
2021-07-22 23:39:19,430 DEV : loss 0.08645404130220413 - score 0.9766
2021-07-22 23:39:19,439 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:21,671 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:22,411 epoch 16 - iter 3/34 - loss 0.25562747 - samples/sec: 130.01 - lr: 0.000030
2021-07-22 23:39:23,188 epoch 16 - iter 6/34 - loss 0.19996731 - samples/sec: 123.62 - lr: 0.000030
2021-07-22 23:39:23,952 epoch 16 - iter 9/34 - loss 0.19673527 - samples/sec: 125.72 - lr: 0.000030
2021-07-22 23:39:24,651 epoch 16 - iter 12/34 - loss 0.19962316 - samples/sec: 137.56 - lr: 0.000030
2021-07-22 23:39:25,341 epoch 16 - iter 15/34 - loss 0.18790214 - samples/sec: 139.20 - lr: 0.000030
2021-07-22 23:39:26,055 epoch 16 - iter 18/34 - loss 0.17817158 - samples/sec: 134.43 - lr: 0.000030
2021-07-22 23:39:26,832 epoch 16 - iter 21/34 - loss 0.17580633 - samples/sec: 123.57 - lr: 0.000030
2021-07-22 23:39:27,562 epoch 16 - iter 24/34 - loss 0.17773899 - samples/sec: 131.63 - lr: 0.000030
2021-07-22 23:39:28,339 epoch 16 - iter 27/34 - loss 0.17716177 - samples/sec: 123.68 - lr: 0.000030
2021-07-22 23:39:29,052 epoch 16 - iter 30/34 - loss 0.17100325 - samples/sec: 134.81 - lr: 0.000030
2021-07-22 23:39:29,812 epoch 16 - iter 33/34 - loss 0.16930840 - samples/sec: 126.34 - lr: 0.000030
2021-07-22 23:39:29,902 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:29,902 EPOCH 16 done: loss 0.1665 - lr 0.0000300
2021-07-22 23:39:30,668 DEV : loss 0.07505783438682556 - score 0.9794
2021-07-22 23:39:30,677 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:32,879 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:33,667 epoch 17 - iter 3/34 - loss 0.23179584 - samples/sec: 122.27 - lr: 0.000030
2021-07-22 23:39:34,391 epoch 17 - iter 6/34 - loss 0.20609421 - samples/sec: 132.65 - lr: 0.000030
2021-07-22 23:39:35,096 epoch 17 - iter 9/34 - loss 0.20588436 - samples/sec: 136.26 - lr: 0.000030
2021-07-22 23:39:35,827 epoch 17 - iter 12/34 - loss 0.19447481 - samples/sec: 131.28 - lr: 0.000030
2021-07-22 23:39:36,559 epoch 17 - iter 15/34 - loss 0.19178354 - samples/sec: 131.25 - lr: 0.000030
2021-07-22 23:39:37,303 epoch 17 - iter 18/34 - loss 0.20201878 - samples/sec: 129.16 - lr: 0.000030
2021-07-22 23:39:38,068 epoch 17 - iter 21/34 - loss 0.19440351 - samples/sec: 125.55 - lr: 0.000030
2021-07-22 23:39:38,829 epoch 17 - iter 24/34 - loss 0.19772037 - samples/sec: 126.16 - lr: 0.000030
2021-07-22 23:39:39,602 epoch 17 - iter 27/34 - loss 0.19383528 - samples/sec: 124.29 - lr: 0.000030
2021-07-22 23:39:40,333 epoch 17 - iter 30/34 - loss 0.19532766 - samples/sec: 131.40 - lr: 0.000030
2021-07-22 23:39:41,064 epoch 17 - iter 33/34 - loss 0.19290006 - samples/sec: 131.41 - lr: 0.000030
2021-07-22 23:39:41,151 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:41,151 EPOCH 17 done: loss 0.1887 - lr 0.0000300
2021-07-22 23:39:41,919 DEV : loss 0.07215828448534012 - score 0.9767
2021-07-22 23:39:41,928 BAD EPOCHS (no improvement): 1
2021-07-22 23:39:41,928 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:42,676 epoch 18 - iter 3/34 - loss 0.20560652 - samples/sec: 128.68 - lr: 0.000030
2021-07-22 23:39:43,442 epoch 18 - iter 6/34 - loss 0.15673536 - samples/sec: 125.37 - lr: 0.000030
2021-07-22 23:39:44,215 epoch 18 - iter 9/34 - loss 0.17909478 - samples/sec: 124.16 - lr: 0.000030
2021-07-22 23:39:45,015 epoch 18 - iter 12/34 - loss 0.17580786 - samples/sec: 120.16 - lr: 0.000030
2021-07-22 23:39:45,704 epoch 18 - iter 15/34 - loss 0.17450107 - samples/sec: 139.37 - lr: 0.000030
2021-07-22 23:39:46,396 epoch 18 - iter 18/34 - loss 0.17923867 - samples/sec: 138.70 - lr: 0.000030
2021-07-22 23:39:47,145 epoch 18 - iter 21/34 - loss 0.17837705 - samples/sec: 128.32 - lr: 0.000030
2021-07-22 23:39:47,876 epoch 18 - iter 24/34 - loss 0.17026377 - samples/sec: 131.44 - lr: 0.000030
2021-07-22 23:39:48,612 epoch 18 - iter 27/34 - loss 0.16595477 - samples/sec: 130.44 - lr: 0.000030
2021-07-22 23:39:49,395 epoch 18 - iter 30/34 - loss 0.16087707 - samples/sec: 122.68 - lr: 0.000030
2021-07-22 23:39:50,087 epoch 18 - iter 33/34 - loss 0.15862680 - samples/sec: 138.75 - lr: 0.000030
2021-07-22 23:39:50,175 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:50,175 EPOCH 18 done: loss 0.1545 - lr 0.0000300
2021-07-22 23:39:50,942 DEV : loss 0.06626584380865097 - score 0.9794
2021-07-22 23:39:50,951 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:52,877 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:53,606 epoch 19 - iter 3/34 - loss 0.15110866 - samples/sec: 132.11 - lr: 0.000030
2021-07-22 23:39:54,360 epoch 19 - iter 6/34 - loss 0.16250970 - samples/sec: 127.25 - lr: 0.000030
2021-07-22 23:39:55,087 epoch 19 - iter 9/34 - loss 0.16911287 - samples/sec: 132.28 - lr: 0.000030
2021-07-22 23:39:55,786 epoch 19 - iter 12/34 - loss 0.16766024 - samples/sec: 137.25 - lr: 0.000030
2021-07-22 23:39:56,532 epoch 19 - iter 15/34 - loss 0.17194419 - samples/sec: 128.78 - lr: 0.000030
2021-07-22 23:39:57,280 epoch 19 - iter 18/34 - loss 0.16895416 - samples/sec: 128.50 - lr: 0.000030
2021-07-22 23:39:57,980 epoch 19 - iter 21/34 - loss 0.16639795 - samples/sec: 137.15 - lr: 0.000030
2021-07-22 23:39:58,753 epoch 19 - iter 24/34 - loss 0.16979513 - samples/sec: 124.25 - lr: 0.000030
2021-07-22 23:39:59,531 epoch 19 - iter 27/34 - loss 0.15870586 - samples/sec: 123.51 - lr: 0.000030
2021-07-22 23:40:00,300 epoch 19 - iter 30/34 - loss 0.15930269 - samples/sec: 124.83 - lr: 0.000030
2021-07-22 23:40:01,029 epoch 19 - iter 33/34 - loss 0.16240546 - samples/sec: 131.82 - lr: 0.000030
2021-07-22 23:40:01,140 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:01,140 EPOCH 19 done: loss 0.1680 - lr 0.0000300
2021-07-22 23:40:01,908 DEV : loss 0.061926763504743576 - score 0.9846
2021-07-22 23:40:01,917 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:04,214 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:04,936 epoch 20 - iter 3/34 - loss 0.13018683 - samples/sec: 133.48 - lr: 0.000030
2021-07-22 23:40:05,680 epoch 20 - iter 6/34 - loss 0.12270931 - samples/sec: 129.04 - lr: 0.000030
2021-07-22 23:40:06,448 epoch 20 - iter 9/34 - loss 0.12978234 - samples/sec: 125.00 - lr: 0.000030
2021-07-22 23:40:07,196 epoch 20 - iter 12/34 - loss 0.13366427 - samples/sec: 128.52 - lr: 0.000030
2021-07-22 23:40:07,943 epoch 20 - iter 15/34 - loss 0.13135740 - samples/sec: 128.61 - lr: 0.000030
2021-07-22 23:40:08,667 epoch 20 - iter 18/34 - loss 0.14888876 - samples/sec: 132.51 - lr: 0.000030
2021-07-22 23:40:09,457 epoch 20 - iter 21/34 - loss 0.14331138 - samples/sec: 121.63 - lr: 0.000030
2021-07-22 23:40:10,227 epoch 20 - iter 24/34 - loss 0.14004530 - samples/sec: 124.71 - lr: 0.000030
2021-07-22 23:40:10,975 epoch 20 - iter 27/34 - loss 0.13902845 - samples/sec: 128.55 - lr: 0.000030
2021-07-22 23:40:11,655 epoch 20 - iter 30/34 - loss 0.14146212 - samples/sec: 141.25 - lr: 0.000030
2021-07-22 23:40:12,408 epoch 20 - iter 33/34 - loss 0.13411896 - samples/sec: 127.47 - lr: 0.000030
2021-07-22 23:40:12,485 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:12,486 EPOCH 20 done: loss 0.1325 - lr 0.0000300
2021-07-22 23:40:13,252 DEV : loss 0.05923685431480408 - score 0.9846
2021-07-22 23:40:13,261 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:15,379 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:16,152 epoch 21 - iter 3/34 - loss 0.13710843 - samples/sec: 124.56 - lr: 0.000030
2021-07-22 23:40:16,929 epoch 21 - iter 6/34 - loss 0.13938680 - samples/sec: 123.64 - lr: 0.000030
2021-07-22 23:40:17,624 epoch 21 - iter 9/34 - loss 0.16041090 - samples/sec: 138.22 - lr: 0.000030
2021-07-22 23:40:18,367 epoch 21 - iter 12/34 - loss 0.15395392 - samples/sec: 129.25 - lr: 0.000030
2021-07-22 23:40:19,127 epoch 21 - iter 15/34 - loss 0.14156289 - samples/sec: 126.33 - lr: 0.000030
2021-07-22 23:40:19,878 epoch 21 - iter 18/34 - loss 0.14502513 - samples/sec: 127.86 - lr: 0.000030
2021-07-22 23:40:20,613 epoch 21 - iter 21/34 - loss 0.13995212 - samples/sec: 130.80 - lr: 0.000030
2021-07-22 23:40:21,352 epoch 21 - iter 24/34 - loss 0.13405418 - samples/sec: 129.88 - lr: 0.000030
2021-07-22 23:40:22,108 epoch 21 - iter 27/34 - loss 0.13362247 - samples/sec: 127.16 - lr: 0.000030
2021-07-22 23:40:22,848 epoch 21 - iter 30/34 - loss 0.13369518 - samples/sec: 129.79 - lr: 0.000030
2021-07-22 23:40:23,530 epoch 21 - iter 33/34 - loss 0.13181989 - samples/sec: 140.76 - lr: 0.000030
2021-07-22 23:40:23,619 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:23,619 EPOCH 21 done: loss 0.1291 - lr 0.0000300
2021-07-22 23:40:24,386 DEV : loss 0.05593534931540489 - score 0.9846
2021-07-22 23:40:24,395 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:26,554 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:27,272 epoch 22 - iter 3/34 - loss 0.15193769 - samples/sec: 134.18 - lr: 0.000030
2021-07-22 23:40:28,087 epoch 22 - iter 6/34 - loss 0.18473656 - samples/sec: 117.76 - lr: 0.000030
2021-07-22 23:40:28,880 epoch 22 - iter 9/34 - loss 0.16356693 - samples/sec: 121.11 - lr: 0.000030
2021-07-22 23:40:29,627 epoch 22 - iter 12/34 - loss 0.15975720 - samples/sec: 128.64 - lr: 0.000030
2021-07-22 23:40:30,384 epoch 22 - iter 15/34 - loss 0.15839354 - samples/sec: 126.91 - lr: 0.000030
2021-07-22 23:40:31,116 epoch 22 - iter 18/34 - loss 0.15450128 - samples/sec: 131.27 - lr: 0.000030
2021-07-22 23:40:31,897 epoch 22 - iter 21/34 - loss 0.15468816 - samples/sec: 122.92 - lr: 0.000030
2021-07-22 23:40:32,631 epoch 22 - iter 24/34 - loss 0.15409281 - samples/sec: 130.81 - lr: 0.000030
2021-07-22 23:40:33,313 epoch 22 - iter 27/34 - loss 0.15137935 - samples/sec: 140.99 - lr: 0.000030
2021-07-22 23:40:34,044 epoch 22 - iter 30/34 - loss 0.14758283 - samples/sec: 131.41 - lr: 0.000030
2021-07-22 23:40:34,740 epoch 22 - iter 33/34 - loss 0.15032323 - samples/sec: 138.00 - lr: 0.000030
2021-07-22 23:40:34,844 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:34,844 EPOCH 22 done: loss 0.1470 - lr 0.0000300
2021-07-22 23:40:35,612 DEV : loss 0.05439815670251846 - score 0.9821
2021-07-22 23:40:35,625 BAD EPOCHS (no improvement): 1
2021-07-22 23:40:35,625 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:36,376 epoch 23 - iter 3/34 - loss 0.06153253 - samples/sec: 128.06 - lr: 0.000030
2021-07-22 23:40:37,103 epoch 23 - iter 6/34 - loss 0.11594302 - samples/sec: 132.23 - lr: 0.000030
2021-07-22 23:40:37,863 epoch 23 - iter 9/34 - loss 0.12005886 - samples/sec: 126.30 - lr: 0.000030
2021-07-22 23:40:38,592 epoch 23 - iter 12/34 - loss 0.11864915 - samples/sec: 131.75 - lr: 0.000030
2021-07-22 23:40:39,331 epoch 23 - iter 15/34 - loss 0.11665686 - samples/sec: 129.93 - lr: 0.000030
2021-07-22 23:40:40,108 epoch 23 - iter 18/34 - loss 0.12570710 - samples/sec: 123.65 - lr: 0.000030
2021-07-22 23:40:40,815 epoch 23 - iter 21/34 - loss 0.12049660 - samples/sec: 135.89 - lr: 0.000030
2021-07-22 23:40:41,508 epoch 23 - iter 24/34 - loss 0.11724848 - samples/sec: 138.71 - lr: 0.000030
2021-07-22 23:40:42,225 epoch 23 - iter 27/34 - loss 0.11178129 - samples/sec: 133.94 - lr: 0.000030
2021-07-22 23:40:42,983 epoch 23 - iter 30/34 - loss 0.11842514 - samples/sec: 126.69 - lr: 0.000030
2021-07-22 23:40:43,711 epoch 23 - iter 33/34 - loss 0.11615681 - samples/sec: 131.83 - lr: 0.000030
2021-07-22 23:40:43,804 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:43,804 EPOCH 23 done: loss 0.1213 - lr 0.0000300
2021-07-22 23:40:44,571 DEV : loss 0.05354655906558037 - score 0.9846
2021-07-22 23:40:44,581 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:47,109 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:47,826 epoch 24 - iter 3/34 - loss 0.15692076 - samples/sec: 134.31 - lr: 0.000030
2021-07-22 23:40:48,605 epoch 24 - iter 6/34 - loss 0.13853946 - samples/sec: 123.19 - lr: 0.000030
2021-07-22 23:40:49,327 epoch 24 - iter 9/34 - loss 0.13755734 - samples/sec: 133.03 - lr: 0.000030
2021-07-22 23:40:50,043 epoch 24 - iter 12/34 - loss 0.15690654 - samples/sec: 134.30 - lr: 0.000030
2021-07-22 23:40:50,811 epoch 24 - iter 15/34 - loss 0.15636476 - samples/sec: 125.01 - lr: 0.000030
2021-07-22 23:40:51,575 epoch 24 - iter 18/34 - loss 0.13918726 - samples/sec: 125.80 - lr: 0.000030
2021-07-22 23:40:52,342 epoch 24 - iter 21/34 - loss 0.13100702 - samples/sec: 125.10 - lr: 0.000030
2021-07-22 23:40:53,040 epoch 24 - iter 24/34 - loss 0.12589186 - samples/sec: 137.78 - lr: 0.000030
2021-07-22 23:40:53,787 epoch 24 - iter 27/34 - loss 0.12867415 - samples/sec: 128.50 - lr: 0.000030
2021-07-22 23:40:54,497 epoch 24 - iter 30/34 - loss 0.12611598 - samples/sec: 135.35 - lr: 0.000030
2021-07-22 23:40:55,228 epoch 24 - iter 33/34 - loss 0.12339635 - samples/sec: 131.31 - lr: 0.000030
2021-07-22 23:40:55,303 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:55,303 EPOCH 24 done: loss 0.1203 - lr 0.0000300
2021-07-22 23:40:56,072 DEV : loss 0.05208083614706993 - score 0.9872
2021-07-22 23:40:56,081 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:58,230 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:59,051 epoch 25 - iter 3/34 - loss 0.12879260 - samples/sec: 117.16 - lr: 0.000030
2021-07-22 23:40:59,824 epoch 25 - iter 6/34 - loss 0.13963970 - samples/sec: 124.41 - lr: 0.000030
2021-07-22 23:41:00,531 epoch 25 - iter 9/34 - loss 0.14744468 - samples/sec: 135.70 - lr: 0.000030
2021-07-22 23:41:01,337 epoch 25 - iter 12/34 - loss 0.14170532 - samples/sec: 119.26 - lr: 0.000030
2021-07-22 23:41:02,043 epoch 25 - iter 15/34 - loss 0.12939228 - samples/sec: 136.09 - lr: 0.000030
2021-07-22 23:41:02,792 epoch 25 - iter 18/34 - loss 0.12206352 - samples/sec: 128.13 - lr: 0.000030
2021-07-22 23:41:03,549 epoch 25 - iter 21/34 - loss 0.13060759 - samples/sec: 126.94 - lr: 0.000030
2021-07-22 23:41:04,294 epoch 25 - iter 24/34 - loss 0.12411250 - samples/sec: 128.88 - lr: 0.000030
2021-07-22 23:41:04,986 epoch 25 - iter 27/34 - loss 0.12295269 - samples/sec: 138.87 - lr: 0.000030
2021-07-22 23:41:05,723 epoch 25 - iter 30/34 - loss 0.12884089 - samples/sec: 130.42 - lr: 0.000030
2021-07-22 23:41:06,425 epoch 25 - iter 33/34 - loss 0.12561274 - samples/sec: 136.73 - lr: 0.000030
2021-07-22 23:41:06,509 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:06,510 EPOCH 25 done: loss 0.1330 - lr 0.0000300
2021-07-22 23:41:07,276 DEV : loss 0.05042479187250137 - score 0.9822
2021-07-22 23:41:07,285 BAD EPOCHS (no improvement): 1
2021-07-22 23:41:07,285 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:07,987 epoch 26 - iter 3/34 - loss 0.06043008 - samples/sec: 137.06 - lr: 0.000030
2021-07-22 23:41:08,691 epoch 26 - iter 6/34 - loss 0.09945859 - samples/sec: 136.49 - lr: 0.000030
2021-07-22 23:41:09,460 epoch 26 - iter 9/34 - loss 0.10631989 - samples/sec: 124.87 - lr: 0.000030
2021-07-22 23:41:10,203 epoch 26 - iter 12/34 - loss 0.11083149 - samples/sec: 129.29 - lr: 0.000030
2021-07-22 23:41:10,923 epoch 26 - iter 15/34 - loss 0.12294814 - samples/sec: 133.47 - lr: 0.000030
2021-07-22 23:41:11,664 epoch 26 - iter 18/34 - loss 0.12595733 - samples/sec: 129.60 - lr: 0.000030
2021-07-22 23:41:12,460 epoch 26 - iter 21/34 - loss 0.11793779 - samples/sec: 120.61 - lr: 0.000030
2021-07-22 23:41:13,275 epoch 26 - iter 24/34 - loss 0.12254951 - samples/sec: 117.92 - lr: 0.000030
2021-07-22 23:41:14,020 epoch 26 - iter 27/34 - loss 0.12634769 - samples/sec: 128.80 - lr: 0.000030
2021-07-22 23:41:14,777 epoch 26 - iter 30/34 - loss 0.12343930 - samples/sec: 126.99 - lr: 0.000030
2021-07-22 23:41:15,448 epoch 26 - iter 33/34 - loss 0.12592949 - samples/sec: 143.08 - lr: 0.000030
2021-07-22 23:41:15,542 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:15,542 EPOCH 26 done: loss 0.1235 - lr 0.0000300
2021-07-22 23:41:16,308 DEV : loss 0.04896773025393486 - score 0.9822
2021-07-22 23:41:16,317 BAD EPOCHS (no improvement): 2
2021-07-22 23:41:16,317 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:16,999 epoch 27 - iter 3/34 - loss 0.14376634 - samples/sec: 141.01 - lr: 0.000030
2021-07-22 23:41:17,775 epoch 27 - iter 6/34 - loss 0.13028896 - samples/sec: 123.76 - lr: 0.000030
2021-07-22 23:41:18,487 epoch 27 - iter 9/34 - loss 0.11144502 - samples/sec: 134.96 - lr: 0.000030
2021-07-22 23:41:19,240 epoch 27 - iter 12/34 - loss 0.12061192 - samples/sec: 127.57 - lr: 0.000030
2021-07-22 23:41:19,976 epoch 27 - iter 15/34 - loss 0.12615800 - samples/sec: 130.45 - lr: 0.000030
2021-07-22 23:41:20,704 epoch 27 - iter 18/34 - loss 0.11715532 - samples/sec: 132.03 - lr: 0.000030
2021-07-22 23:41:21,447 epoch 27 - iter 21/34 - loss 0.11608182 - samples/sec: 129.23 - lr: 0.000030
2021-07-22 23:41:22,261 epoch 27 - iter 24/34 - loss 0.11376604 - samples/sec: 117.99 - lr: 0.000030
2021-07-22 23:41:23,000 epoch 27 - iter 27/34 - loss 0.11397086 - samples/sec: 130.08 - lr: 0.000030
2021-07-22 23:41:23,750 epoch 27 - iter 30/34 - loss 0.11203780 - samples/sec: 127.90 - lr: 0.000030
2021-07-22 23:41:24,492 epoch 27 - iter 33/34 - loss 0.11497866 - samples/sec: 129.51 - lr: 0.000030
2021-07-22 23:41:24,583 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:24,583 EPOCH 27 done: loss 0.1209 - lr 0.0000300
2021-07-22 23:41:25,353 DEV : loss 0.048531439155340195 - score 0.9872
2021-07-22 23:41:25,362 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:41:29,772 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:30,554 epoch 28 - iter 3/34 - loss 0.08593057 - samples/sec: 123.17 - lr: 0.000030
2021-07-22 23:41:31,231 epoch 28 - iter 6/34 - loss 0.10023836 - samples/sec: 141.94 - lr: 0.000030
2021-07-22 23:41:31,865 epoch 28 - iter 9/34 - loss 0.09877762 - samples/sec: 151.48 - lr: 0.000030
2021-07-22 23:41:32,513 epoch 28 - iter 12/34 - loss 0.12816359 - samples/sec: 148.17 - lr: 0.000030
2021-07-22 23:41:33,183 epoch 28 - iter 15/34 - loss 0.13285671 - samples/sec: 143.35 - lr: 0.000030
2021-07-22 23:41:33,943 epoch 28 - iter 18/34 - loss 0.12691082 - samples/sec: 126.54 - lr: 0.000030
2021-07-22 23:41:34,668 epoch 28 - iter 21/34 - loss 0.12982132 - samples/sec: 132.41 - lr: 0.000030
2021-07-22 23:41:35,427 epoch 28 - iter 24/34 - loss 0.13038600 - samples/sec: 126.62 - lr: 0.000030
2021-07-22 23:41:36,229 epoch 28 - iter 27/34 - loss 0.12342796 - samples/sec: 119.72 - lr: 0.000030
2021-07-22 23:41:36,983 epoch 28 - iter 30/34 - loss 0.11828606 - samples/sec: 127.37 - lr: 0.000030
2021-07-22 23:41:37,717 epoch 28 - iter 33/34 - loss 0.11189660 - samples/sec: 130.87 - lr: 0.000030
2021-07-22 23:41:37,817 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:37,817 EPOCH 28 done: loss 0.1088 - lr 0.0000300
2021-07-22 23:41:38,628 DEV : loss 0.04770360887050629 - score 0.9822
2021-07-22 23:41:38,640 BAD EPOCHS (no improvement): 1
2021-07-22 23:41:38,640 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:39,387 epoch 29 - iter 3/34 - loss 0.13278785 - samples/sec: 128.72 - lr: 0.000030
2021-07-22 23:41:40,143 epoch 29 - iter 6/34 - loss 0.14138914 - samples/sec: 126.94 - lr: 0.000030
2021-07-22 23:41:40,879 epoch 29 - iter 9/34 - loss 0.13873564 - samples/sec: 130.61 - lr: 0.000030
2021-07-22 23:41:41,551 epoch 29 - iter 12/34 - loss 0.12322540 - samples/sec: 142.91 - lr: 0.000030
2021-07-22 23:41:42,228 epoch 29 - iter 15/34 - loss 0.13148714 - samples/sec: 141.89 - lr: 0.000030
2021-07-22 23:41:42,955 epoch 29 - iter 18/34 - loss 0.13919779 - samples/sec: 132.18 - lr: 0.000030
2021-07-22 23:41:43,710 epoch 29 - iter 21/34 - loss 0.13149262 - samples/sec: 127.07 - lr: 0.000030
2021-07-22 23:41:44,403 epoch 29 - iter 24/34 - loss 0.13346761 - samples/sec: 138.76 - lr: 0.000030
2021-07-22 23:41:45,135 epoch 29 - iter 27/34 - loss 0.12733611 - samples/sec: 131.23 - lr: 0.000030
2021-07-22 23:41:45,937 epoch 29 - iter 30/34 - loss 0.12788962 - samples/sec: 119.74 - lr: 0.000030
2021-07-22 23:41:46,706 epoch 29 - iter 33/34 - loss 0.12872102 - samples/sec: 124.84 - lr: 0.000030
2021-07-22 23:41:46,809 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:46,809 EPOCH 29 done: loss 0.1266 - lr 0.0000300
2021-07-22 23:41:47,575 DEV : loss 0.04916830733418465 - score 0.9873
2021-07-22 23:41:47,585 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:41:49,892 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:50,647 epoch 30 - iter 3/34 - loss 0.16906437 - samples/sec: 127.46 - lr: 0.000030
2021-07-22 23:41:51,402 epoch 30 - iter 6/34 - loss 0.15291974 - samples/sec: 127.25 - lr: 0.000030
2021-07-22 23:41:52,102 epoch 30 - iter 9/34 - loss 0.14590850 - samples/sec: 137.21 - lr: 0.000030
2021-07-22 23:41:52,831 epoch 30 - iter 12/34 - loss 0.14054125 - samples/sec: 131.82 - lr: 0.000030
2021-07-22 23:41:53,539 epoch 30 - iter 15/34 - loss 0.13347773 - samples/sec: 135.53 - lr: 0.000030
2021-07-22 23:41:54,291 epoch 30 - iter 18/34 - loss 0.13275810 - samples/sec: 127.77 - lr: 0.000030
2021-07-22 23:41:55,079 epoch 30 - iter 21/34 - loss 0.12192829 - samples/sec: 121.96 - lr: 0.000030
2021-07-22 23:41:55,748 epoch 30 - iter 24/34 - loss 0.11997126 - samples/sec: 143.63 - lr: 0.000030
2021-07-22 23:41:56,463 epoch 30 - iter 27/34 - loss 0.11629636 - samples/sec: 134.28 - lr: 0.000030
2021-07-22 23:41:57,228 epoch 30 - iter 30/34 - loss 0.11438769 - samples/sec: 125.47 - lr: 0.000030
2021-07-22 23:41:57,975 epoch 30 - iter 33/34 - loss 0.10934217 - samples/sec: 128.54 - lr: 0.000030
2021-07-22 23:41:58,067 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:58,067 EPOCH 30 done: loss 0.1086 - lr 0.0000300
2021-07-22 23:41:58,840 DEV : loss 0.04643889144062996 - score 0.9822
2021-07-22 23:41:58,849 BAD EPOCHS (no improvement): 1
2021-07-22 23:41:58,850 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:59,604 epoch 31 - iter 3/34 - loss 0.07338887 - samples/sec: 127.47 - lr: 0.000030
2021-07-22 23:42:00,392 epoch 31 - iter 6/34 - loss 0.12924623 - samples/sec: 121.94 - lr: 0.000030
2021-07-22 23:42:01,095 epoch 31 - iter 9/34 - loss 0.11569512 - samples/sec: 136.53 - lr: 0.000030
2021-07-22 23:42:01,892 epoch 31 - iter 12/34 - loss 0.10832642 - samples/sec: 120.56 - lr: 0.000030
2021-07-22 23:42:02,607 epoch 31 - iter 15/34 - loss 0.11717100 - samples/sec: 134.39 - lr: 0.000030
2021-07-22 23:42:03,327 epoch 31 - iter 18/34 - loss 0.11125882 - samples/sec: 133.30 - lr: 0.000030
2021-07-22 23:42:04,008 epoch 31 - iter 21/34 - loss 0.10622183 - samples/sec: 141.12 - lr: 0.000030
2021-07-22 23:42:04,682 epoch 31 - iter 24/34 - loss 0.11001947 - samples/sec: 142.41 - lr: 0.000030
2021-07-22 23:42:05,484 epoch 31 - iter 27/34 - loss 0.10640929 - samples/sec: 119.81 - lr: 0.000030
2021-07-22 23:42:06,239 epoch 31 - iter 30/34 - loss 0.11036745 - samples/sec: 127.18 - lr: 0.000030
2021-07-22 23:42:07,017 epoch 31 - iter 33/34 - loss 0.10634492 - samples/sec: 123.45 - lr: 0.000030
2021-07-22 23:42:07,111 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:07,111 EPOCH 31 done: loss 0.1046 - lr 0.0000300
2021-07-22 23:42:07,876 DEV : loss 0.0486161969602108 - score 0.9848
2021-07-22 23:42:07,885 BAD EPOCHS (no improvement): 2
2021-07-22 23:42:07,885 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:08,616 epoch 32 - iter 3/34 - loss 0.12237661 - samples/sec: 131.69 - lr: 0.000030
2021-07-22 23:42:09,364 epoch 32 - iter 6/34 - loss 0.11804285 - samples/sec: 128.37 - lr: 0.000030
2021-07-22 23:42:10,099 epoch 32 - iter 9/34 - loss 0.11495918 - samples/sec: 130.64 - lr: 0.000030
2021-07-22 23:42:10,834 epoch 32 - iter 12/34 - loss 0.11390999 - samples/sec: 130.76 - lr: 0.000030
2021-07-22 23:42:11,580 epoch 32 - iter 15/34 - loss 0.10904642 - samples/sec: 128.70 - lr: 0.000030
2021-07-22 23:42:12,324 epoch 32 - iter 18/34 - loss 0.10341617 - samples/sec: 129.12 - lr: 0.000030
2021-07-22 23:42:13,004 epoch 32 - iter 21/34 - loss 0.10249581 - samples/sec: 141.34 - lr: 0.000030
2021-07-22 23:42:13,716 epoch 32 - iter 24/34 - loss 0.10033432 - samples/sec: 134.90 - lr: 0.000030
2021-07-22 23:42:14,447 epoch 32 - iter 27/34 - loss 0.10582133 - samples/sec: 131.26 - lr: 0.000030
2021-07-22 23:42:15,177 epoch 32 - iter 30/34 - loss 0.11055225 - samples/sec: 131.63 - lr: 0.000030
2021-07-22 23:42:15,932 epoch 32 - iter 33/34 - loss 0.10597729 - samples/sec: 127.31 - lr: 0.000030
2021-07-22 23:42:16,022 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:16,022 EPOCH 32 done: loss 0.1111 - lr 0.0000300
2021-07-22 23:42:16,788 DEV : loss 0.046462543308734894 - score 0.9822
2021-07-22 23:42:16,798 BAD EPOCHS (no improvement): 3
2021-07-22 23:42:16,798 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:17,495 epoch 33 - iter 3/34 - loss 0.08995212 - samples/sec: 137.87 - lr: 0.000030
2021-07-22 23:42:18,220 epoch 33 - iter 6/34 - loss 0.07290675 - samples/sec: 132.54 - lr: 0.000030
2021-07-22 23:42:18,987 epoch 33 - iter 9/34 - loss 0.09395733 - samples/sec: 125.25 - lr: 0.000030
2021-07-22 23:42:19,745 epoch 33 - iter 12/34 - loss 0.09756931 - samples/sec: 126.74 - lr: 0.000030
2021-07-22 23:42:20,498 epoch 33 - iter 15/34 - loss 0.09744539 - samples/sec: 127.53 - lr: 0.000030
2021-07-22 23:42:21,185 epoch 33 - iter 18/34 - loss 0.09564362 - samples/sec: 139.97 - lr: 0.000030
2021-07-22 23:42:21,903 epoch 33 - iter 21/34 - loss 0.10159095 - samples/sec: 133.82 - lr: 0.000030
2021-07-22 23:42:22,654 epoch 33 - iter 24/34 - loss 0.09581538 - samples/sec: 127.76 - lr: 0.000030
2021-07-22 23:42:23,336 epoch 33 - iter 27/34 - loss 0.09614719 - samples/sec: 140.83 - lr: 0.000030
2021-07-22 23:42:24,087 epoch 33 - iter 30/34 - loss 0.09652065 - samples/sec: 128.05 - lr: 0.000030
2021-07-22 23:42:24,869 epoch 33 - iter 33/34 - loss 0.09535874 - samples/sec: 122.78 - lr: 0.000030
2021-07-22 23:42:24,950 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:24,950 EPOCH 33 done: loss 0.0932 - lr 0.0000300
2021-07-22 23:42:25,718 DEV : loss 0.04561636224389076 - score 0.9822
Epoch    33: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 23:42:25,727 BAD EPOCHS (no improvement): 4
2021-07-22 23:42:25,727 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:26,415 epoch 34 - iter 3/34 - loss 0.07353497 - samples/sec: 139.81 - lr: 0.000015
2021-07-22 23:42:27,181 epoch 34 - iter 6/34 - loss 0.06747028 - samples/sec: 125.41 - lr: 0.000015
2021-07-22 23:42:27,873 epoch 34 - iter 9/34 - loss 0.08255114 - samples/sec: 138.91 - lr: 0.000015
2021-07-22 23:42:28,566 epoch 34 - iter 12/34 - loss 0.08525727 - samples/sec: 138.46 - lr: 0.000015
2021-07-22 23:42:29,302 epoch 34 - iter 15/34 - loss 0.07773930 - samples/sec: 130.55 - lr: 0.000015
2021-07-22 23:42:30,098 epoch 34 - iter 18/34 - loss 0.07402068 - samples/sec: 120.69 - lr: 0.000015
2021-07-22 23:42:30,851 epoch 34 - iter 21/34 - loss 0.07305432 - samples/sec: 127.53 - lr: 0.000015
2021-07-22 23:42:31,672 epoch 34 - iter 24/34 - loss 0.07800752 - samples/sec: 117.05 - lr: 0.000015
2021-07-22 23:42:32,395 epoch 34 - iter 27/34 - loss 0.09068327 - samples/sec: 132.74 - lr: 0.000015
2021-07-22 23:42:33,152 epoch 34 - iter 30/34 - loss 0.09118716 - samples/sec: 126.87 - lr: 0.000015
2021-07-22 23:42:33,862 epoch 34 - iter 33/34 - loss 0.09513911 - samples/sec: 135.25 - lr: 0.000015
2021-07-22 23:42:33,949 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:33,949 EPOCH 34 done: loss 0.0934 - lr 0.0000150
2021-07-22 23:42:34,714 DEV : loss 0.0455000065267086 - score 0.9822
2021-07-22 23:42:34,723 BAD EPOCHS (no improvement): 1
2021-07-22 23:42:34,724 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:35,491 epoch 35 - iter 3/34 - loss 0.09365843 - samples/sec: 125.25 - lr: 0.000015
2021-07-22 23:42:36,237 epoch 35 - iter 6/34 - loss 0.13102727 - samples/sec: 128.81 - lr: 0.000015
2021-07-22 23:42:36,959 epoch 35 - iter 9/34 - loss 0.12521613 - samples/sec: 133.01 - lr: 0.000015
2021-07-22 23:42:37,688 epoch 35 - iter 12/34 - loss 0.11392174 - samples/sec: 131.82 - lr: 0.000015
2021-07-22 23:42:38,394 epoch 35 - iter 15/34 - loss 0.10535920 - samples/sec: 136.03 - lr: 0.000015
2021-07-22 23:42:39,104 epoch 35 - iter 18/34 - loss 0.10608588 - samples/sec: 135.21 - lr: 0.000015
2021-07-22 23:42:39,868 epoch 35 - iter 21/34 - loss 0.10582431 - samples/sec: 125.74 - lr: 0.000015
2021-07-22 23:42:40,633 epoch 35 - iter 24/34 - loss 0.11059469 - samples/sec: 125.63 - lr: 0.000015
2021-07-22 23:42:41,417 epoch 35 - iter 27/34 - loss 0.11183624 - samples/sec: 122.52 - lr: 0.000015
2021-07-22 23:42:42,128 epoch 35 - iter 30/34 - loss 0.10838956 - samples/sec: 135.06 - lr: 0.000015
2021-07-22 23:42:42,872 epoch 35 - iter 33/34 - loss 0.10475471 - samples/sec: 129.06 - lr: 0.000015
2021-07-22 23:42:42,961 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:42,961 EPOCH 35 done: loss 0.1021 - lr 0.0000150
2021-07-22 23:42:44,096 DEV : loss 0.04425911605358124 - score 0.9822
2021-07-22 23:42:44,110 BAD EPOCHS (no improvement): 2
2021-07-22 23:42:44,110 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:44,835 epoch 36 - iter 3/34 - loss 0.12072591 - samples/sec: 132.60 - lr: 0.000015
2021-07-22 23:42:45,589 epoch 36 - iter 6/34 - loss 0.09095771 - samples/sec: 127.44 - lr: 0.000015
2021-07-22 23:42:46,316 epoch 36 - iter 9/34 - loss 0.09112973 - samples/sec: 132.18 - lr: 0.000015
2021-07-22 23:42:47,082 epoch 36 - iter 12/34 - loss 0.11260772 - samples/sec: 125.38 - lr: 0.000015
2021-07-22 23:42:47,827 epoch 36 - iter 15/34 - loss 0.10070916 - samples/sec: 128.79 - lr: 0.000015
2021-07-22 23:42:48,590 epoch 36 - iter 18/34 - loss 0.09673410 - samples/sec: 126.03 - lr: 0.000015
2021-07-22 23:42:49,337 epoch 36 - iter 21/34 - loss 0.09205956 - samples/sec: 128.55 - lr: 0.000015
2021-07-22 23:42:50,073 epoch 36 - iter 24/34 - loss 0.09355356 - samples/sec: 130.44 - lr: 0.000015
2021-07-22 23:42:50,796 epoch 36 - iter 27/34 - loss 0.09428402 - samples/sec: 132.81 - lr: 0.000015
2021-07-22 23:42:51,508 epoch 36 - iter 30/34 - loss 0.09308833 - samples/sec: 134.98 - lr: 0.000015
2021-07-22 23:42:52,255 epoch 36 - iter 33/34 - loss 0.09767310 - samples/sec: 128.48 - lr: 0.000015
2021-07-22 23:42:52,360 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:52,360 EPOCH 36 done: loss 0.0960 - lr 0.0000150
2021-07-22 23:42:53,124 DEV : loss 0.044537466019392014 - score 0.9822
2021-07-22 23:42:53,134 BAD EPOCHS (no improvement): 3
2021-07-22 23:42:53,134 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:53,879 epoch 37 - iter 3/34 - loss 0.03795469 - samples/sec: 129.03 - lr: 0.000015
2021-07-22 23:42:54,563 epoch 37 - iter 6/34 - loss 0.04464668 - samples/sec: 140.51 - lr: 0.000015
2021-07-22 23:42:55,309 epoch 37 - iter 9/34 - loss 0.05369670 - samples/sec: 128.81 - lr: 0.000015
2021-07-22 23:42:56,052 epoch 37 - iter 12/34 - loss 0.05254772 - samples/sec: 129.25 - lr: 0.000015
2021-07-22 23:42:56,795 epoch 37 - iter 15/34 - loss 0.06822194 - samples/sec: 129.21 - lr: 0.000015
2021-07-22 23:42:57,479 epoch 37 - iter 18/34 - loss 0.08676892 - samples/sec: 140.43 - lr: 0.000015
2021-07-22 23:42:58,269 epoch 37 - iter 21/34 - loss 0.09074053 - samples/sec: 121.57 - lr: 0.000015
2021-07-22 23:42:58,951 epoch 37 - iter 24/34 - loss 0.09712716 - samples/sec: 140.83 - lr: 0.000015
2021-07-22 23:42:59,711 epoch 37 - iter 27/34 - loss 0.09634474 - samples/sec: 126.45 - lr: 0.000015
2021-07-22 23:43:00,562 epoch 37 - iter 30/34 - loss 0.08910056 - samples/sec: 112.88 - lr: 0.000015
2021-07-22 23:43:01,320 epoch 37 - iter 33/34 - loss 0.08957660 - samples/sec: 126.63 - lr: 0.000015
2021-07-22 23:43:01,403 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:01,403 EPOCH 37 done: loss 0.0881 - lr 0.0000150
2021-07-22 23:43:02,169 DEV : loss 0.0439462810754776 - score 0.9822
Epoch    37: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 23:43:02,178 BAD EPOCHS (no improvement): 4
2021-07-22 23:43:02,179 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:03,059 epoch 38 - iter 3/34 - loss 0.12847774 - samples/sec: 109.16 - lr: 0.000008
2021-07-22 23:43:03,798 epoch 38 - iter 6/34 - loss 0.13224064 - samples/sec: 129.97 - lr: 0.000008
2021-07-22 23:43:04,532 epoch 38 - iter 9/34 - loss 0.14752782 - samples/sec: 130.97 - lr: 0.000008
2021-07-22 23:43:05,303 epoch 38 - iter 12/34 - loss 0.12136321 - samples/sec: 124.51 - lr: 0.000008
2021-07-22 23:43:06,052 epoch 38 - iter 15/34 - loss 0.10915471 - samples/sec: 128.19 - lr: 0.000008
2021-07-22 23:43:06,796 epoch 38 - iter 18/34 - loss 0.09956216 - samples/sec: 129.22 - lr: 0.000008
2021-07-22 23:43:07,523 epoch 38 - iter 21/34 - loss 0.10824976 - samples/sec: 132.03 - lr: 0.000008
2021-07-22 23:43:08,260 epoch 38 - iter 24/34 - loss 0.11106686 - samples/sec: 130.41 - lr: 0.000008
2021-07-22 23:43:09,055 epoch 38 - iter 27/34 - loss 0.10832360 - samples/sec: 120.68 - lr: 0.000008
2021-07-22 23:43:09,768 epoch 38 - iter 30/34 - loss 0.10110285 - samples/sec: 134.86 - lr: 0.000008
2021-07-22 23:43:10,443 epoch 38 - iter 33/34 - loss 0.10442660 - samples/sec: 142.25 - lr: 0.000008
2021-07-22 23:43:10,518 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:10,518 EPOCH 38 done: loss 0.1016 - lr 0.0000075
2021-07-22 23:43:11,284 DEV : loss 0.043764229863882065 - score 0.9822
2021-07-22 23:43:11,293 BAD EPOCHS (no improvement): 1
2021-07-22 23:43:11,294 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:12,144 epoch 39 - iter 3/34 - loss 0.06826375 - samples/sec: 113.11 - lr: 0.000008
2021-07-22 23:43:12,885 epoch 39 - iter 6/34 - loss 0.06292103 - samples/sec: 129.63 - lr: 0.000008
2021-07-22 23:43:13,551 epoch 39 - iter 9/34 - loss 0.06570010 - samples/sec: 144.03 - lr: 0.000008
2021-07-22 23:43:14,306 epoch 39 - iter 12/34 - loss 0.08245487 - samples/sec: 127.26 - lr: 0.000008
2021-07-22 23:43:15,025 epoch 39 - iter 15/34 - loss 0.10285452 - samples/sec: 133.68 - lr: 0.000008
2021-07-22 23:43:15,765 epoch 39 - iter 18/34 - loss 0.09842071 - samples/sec: 129.75 - lr: 0.000008
2021-07-22 23:43:16,458 epoch 39 - iter 21/34 - loss 0.09556661 - samples/sec: 138.73 - lr: 0.000008
2021-07-22 23:43:17,153 epoch 39 - iter 24/34 - loss 0.10200081 - samples/sec: 138.10 - lr: 0.000008
2021-07-22 23:43:17,925 epoch 39 - iter 27/34 - loss 0.09879975 - samples/sec: 124.46 - lr: 0.000008
2021-07-22 23:43:18,669 epoch 39 - iter 30/34 - loss 0.09469237 - samples/sec: 129.14 - lr: 0.000008
2021-07-22 23:43:19,368 epoch 39 - iter 33/34 - loss 0.09186176 - samples/sec: 137.46 - lr: 0.000008
2021-07-22 23:43:19,451 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:19,452 EPOCH 39 done: loss 0.0974 - lr 0.0000075
2021-07-22 23:43:20,217 DEV : loss 0.04427797347307205 - score 0.9822
2021-07-22 23:43:20,226 BAD EPOCHS (no improvement): 2
2021-07-22 23:43:20,226 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:20,889 epoch 40 - iter 3/34 - loss 0.14464557 - samples/sec: 145.15 - lr: 0.000008
2021-07-22 23:43:21,609 epoch 40 - iter 6/34 - loss 0.15052806 - samples/sec: 133.48 - lr: 0.000008
2021-07-22 23:43:22,353 epoch 40 - iter 9/34 - loss 0.13903737 - samples/sec: 129.13 - lr: 0.000008
2021-07-22 23:43:23,109 epoch 40 - iter 12/34 - loss 0.12422756 - samples/sec: 127.02 - lr: 0.000008
2021-07-22 23:43:23,808 epoch 40 - iter 15/34 - loss 0.12303302 - samples/sec: 137.38 - lr: 0.000008
2021-07-22 23:43:24,562 epoch 40 - iter 18/34 - loss 0.11550866 - samples/sec: 127.36 - lr: 0.000008
2021-07-22 23:43:25,294 epoch 40 - iter 21/34 - loss 0.11548838 - samples/sec: 131.16 - lr: 0.000008
2021-07-22 23:43:26,007 epoch 40 - iter 24/34 - loss 0.11090342 - samples/sec: 134.71 - lr: 0.000008
2021-07-22 23:43:26,769 epoch 40 - iter 27/34 - loss 0.11040818 - samples/sec: 126.07 - lr: 0.000008
2021-07-22 23:43:27,539 epoch 40 - iter 30/34 - loss 0.10530389 - samples/sec: 124.75 - lr: 0.000008
2021-07-22 23:43:28,336 epoch 40 - iter 33/34 - loss 0.10203271 - samples/sec: 120.59 - lr: 0.000008
2021-07-22 23:43:28,411 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:28,411 EPOCH 40 done: loss 0.1012 - lr 0.0000075
2021-07-22 23:43:29,176 DEV : loss 0.043816372752189636 - score 0.9822
2021-07-22 23:43:29,186 BAD EPOCHS (no improvement): 3
2021-07-22 23:43:29,802 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:29,802 Testing using best model ...
2021-07-22 23:43:29,803 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/spa.rst.sctb/best-model.pt
2021-07-22 23:43:34,876 1.0000	0.9586	0.9789
2021-07-22 23:43:34,876 
Results:
- F1-score (micro) 0.9789
- F1-score (macro) 0.9737

By class:
SENT       tp: 54 - fp: 0 - fn: 6 - precision: 1.0000 - recall: 0.9000 - f1-score: 0.9474
X          tp: 85 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 23:43:34,876 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.pdtb.pdtb/
2021-07-22 23:43:34,901 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.pdtb.pdtb
2021-07-22 23:43:34,901 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.pdtb.pdtb/sent_train.txt
2021-07-22 23:43:34,903 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.pdtb.pdtb/sent_dev.txt
2021-07-22 23:43:34,904 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.pdtb.pdtb/sent_test.txt
Corpus: 109112 train + 5406 dev + 34572 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 23:43:56,649 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:56,651 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 23:43:56,651 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:56,651 Corpus: "Corpus: 109112 train + 5406 dev + 34572 test sentences"
2021-07-22 23:43:56,651 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:56,651 Parameters:
2021-07-22 23:43:56,651  - learning_rate: "3e-05"
2021-07-22 23:43:56,651  - mini_batch_size: "32"
2021-07-22 23:43:56,651  - patience: "3"
2021-07-22 23:43:56,651  - anneal_factor: "0.5"
2021-07-22 23:43:56,651  - max_epochs: "40"
2021-07-22 23:43:56,651  - shuffle: "True"
2021-07-22 23:43:56,651  - train_with_dev: "False"
2021-07-22 23:43:56,651  - batch_growth_annealing: "False"
2021-07-22 23:43:56,651 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:56,651 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.pdtb.pdtb"
2021-07-22 23:43:56,651 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:56,651 Device: cuda:0
2021-07-22 23:43:56,651 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:56,651 Embeddings storage mode: cpu
2021-07-22 23:43:56,654 ----------------------------------------------------------------------------------------------------
2021-07-22 23:47:19,070 epoch 1 - iter 341/3410 - loss 3.73229635 - samples/sec: 53.91 - lr: 0.000030
2021-07-22 23:50:39,437 epoch 1 - iter 682/3410 - loss 1.99284561 - samples/sec: 54.46 - lr: 0.000030
2021-07-22 23:53:59,975 epoch 1 - iter 1023/3410 - loss 1.39574582 - samples/sec: 54.42 - lr: 0.000030
2021-07-22 23:57:20,819 epoch 1 - iter 1364/3410 - loss 1.09010027 - samples/sec: 54.33 - lr: 0.000030
2021-07-23 00:00:42,633 epoch 1 - iter 1705/3410 - loss 0.90316590 - samples/sec: 54.07 - lr: 0.000030
2021-07-23 00:04:05,447 epoch 1 - iter 2046/3410 - loss 0.77633090 - samples/sec: 53.81 - lr: 0.000030
2021-07-23 00:07:28,193 epoch 1 - iter 2387/3410 - loss 0.68598232 - samples/sec: 53.83 - lr: 0.000030
2021-07-23 00:10:51,045 epoch 1 - iter 2728/3410 - loss 0.61887657 - samples/sec: 53.80 - lr: 0.000030
2021-07-23 00:14:14,004 epoch 1 - iter 3069/3410 - loss 0.56546498 - samples/sec: 53.77 - lr: 0.000030
2021-07-23 00:17:37,737 epoch 1 - iter 3410/3410 - loss 0.52276217 - samples/sec: 53.56 - lr: 0.000030
2021-07-23 00:17:37,738 ----------------------------------------------------------------------------------------------------
2021-07-23 00:17:37,738 EPOCH 1 done: loss 0.5228 - lr 0.0000300
2021-07-23 00:18:52,270 DEV : loss 0.06980875879526138 - score 0.9814
2021-07-23 00:18:52,418 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 00:18:53,059 ----------------------------------------------------------------------------------------------------
2021-07-23 00:20:14,651 epoch 2 - iter 341/3410 - loss 0.13123506 - samples/sec: 133.77 - lr: 0.000030
2021-07-23 00:21:36,853 epoch 2 - iter 682/3410 - loss 0.13338906 - samples/sec: 132.77 - lr: 0.000030
2021-07-23 00:22:59,716 epoch 2 - iter 1023/3410 - loss 0.12961845 - samples/sec: 131.71 - lr: 0.000030
2021-07-23 00:24:22,195 epoch 2 - iter 1364/3410 - loss 0.12681173 - samples/sec: 132.33 - lr: 0.000030
2021-07-23 00:25:44,741 epoch 2 - iter 1705/3410 - loss 0.12433796 - samples/sec: 132.22 - lr: 0.000030
2021-07-23 00:27:06,883 epoch 2 - iter 2046/3410 - loss 0.12209983 - samples/sec: 132.87 - lr: 0.000030
2021-07-23 00:28:29,537 epoch 2 - iter 2387/3410 - loss 0.11847517 - samples/sec: 132.05 - lr: 0.000030
2021-07-23 00:29:52,055 epoch 2 - iter 2728/3410 - loss 0.11614073 - samples/sec: 132.26 - lr: 0.000030
2021-07-23 00:31:15,176 epoch 2 - iter 3069/3410 - loss 0.11450325 - samples/sec: 131.31 - lr: 0.000030
2021-07-23 00:32:37,614 epoch 2 - iter 3410/3410 - loss 0.11271542 - samples/sec: 132.39 - lr: 0.000030
2021-07-23 00:32:37,615 ----------------------------------------------------------------------------------------------------
2021-07-23 00:32:37,615 EPOCH 2 done: loss 0.1127 - lr 0.0000300
2021-07-23 00:32:50,660 DEV : loss 0.05464373901486397 - score 0.9852
2021-07-23 00:32:50,807 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 00:32:53,081 ----------------------------------------------------------------------------------------------------
2021-07-23 00:34:15,780 epoch 3 - iter 341/3410 - loss 0.09039163 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 00:35:38,712 epoch 3 - iter 682/3410 - loss 0.09002977 - samples/sec: 131.61 - lr: 0.000030
2021-07-23 00:37:02,811 epoch 3 - iter 1023/3410 - loss 0.08956153 - samples/sec: 129.78 - lr: 0.000030
2021-07-23 00:38:25,431 epoch 3 - iter 1364/3410 - loss 0.08876652 - samples/sec: 132.10 - lr: 0.000030
2021-07-23 00:39:48,091 epoch 3 - iter 1705/3410 - loss 0.08820503 - samples/sec: 132.04 - lr: 0.000030
2021-07-23 00:41:11,165 epoch 3 - iter 2046/3410 - loss 0.08636549 - samples/sec: 131.38 - lr: 0.000030
2021-07-23 00:42:34,737 epoch 3 - iter 2387/3410 - loss 0.08541169 - samples/sec: 130.60 - lr: 0.000030
2021-07-23 00:43:57,976 epoch 3 - iter 2728/3410 - loss 0.08464872 - samples/sec: 131.12 - lr: 0.000030
2021-07-23 00:45:21,076 epoch 3 - iter 3069/3410 - loss 0.08429015 - samples/sec: 131.34 - lr: 0.000030
2021-07-23 00:46:43,183 epoch 3 - iter 3410/3410 - loss 0.08430351 - samples/sec: 132.93 - lr: 0.000030
2021-07-23 00:46:43,184 ----------------------------------------------------------------------------------------------------
2021-07-23 00:46:43,184 EPOCH 3 done: loss 0.0843 - lr 0.0000300
2021-07-23 00:46:56,274 DEV : loss 0.05030953139066696 - score 0.9865
2021-07-23 00:46:56,423 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 00:46:58,600 ----------------------------------------------------------------------------------------------------
2021-07-23 00:48:23,212 epoch 4 - iter 341/3410 - loss 0.08222936 - samples/sec: 129.00 - lr: 0.000030
2021-07-23 00:49:46,889 epoch 4 - iter 682/3410 - loss 0.08028060 - samples/sec: 130.43 - lr: 0.000030
2021-07-23 00:51:10,408 epoch 4 - iter 1023/3410 - loss 0.07957666 - samples/sec: 130.68 - lr: 0.000030
2021-07-23 00:52:33,071 epoch 4 - iter 1364/3410 - loss 0.07839553 - samples/sec: 132.03 - lr: 0.000030
2021-07-23 00:53:56,161 epoch 4 - iter 1705/3410 - loss 0.07741376 - samples/sec: 131.35 - lr: 0.000030
2021-07-23 00:55:19,333 epoch 4 - iter 2046/3410 - loss 0.07648356 - samples/sec: 131.23 - lr: 0.000030
2021-07-23 00:56:43,653 epoch 4 - iter 2387/3410 - loss 0.07606102 - samples/sec: 129.44 - lr: 0.000030
2021-07-23 00:58:06,135 epoch 4 - iter 2728/3410 - loss 0.07631938 - samples/sec: 132.32 - lr: 0.000030
2021-07-23 00:59:29,296 epoch 4 - iter 3069/3410 - loss 0.07577425 - samples/sec: 131.24 - lr: 0.000030
2021-07-23 01:00:52,516 epoch 4 - iter 3410/3410 - loss 0.07539671 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 01:00:52,517 ----------------------------------------------------------------------------------------------------
2021-07-23 01:00:52,517 EPOCH 4 done: loss 0.0754 - lr 0.0000300
2021-07-23 01:01:05,727 DEV : loss 0.04656265676021576 - score 0.9874
2021-07-23 01:01:05,877 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 01:01:08,089 ----------------------------------------------------------------------------------------------------
2021-07-23 01:02:31,832 epoch 5 - iter 341/3410 - loss 0.07719062 - samples/sec: 130.34 - lr: 0.000030
2021-07-23 01:03:54,324 epoch 5 - iter 682/3410 - loss 0.07258710 - samples/sec: 132.31 - lr: 0.000030
2021-07-23 01:05:17,916 epoch 5 - iter 1023/3410 - loss 0.07208359 - samples/sec: 130.57 - lr: 0.000030
2021-07-23 01:06:41,259 epoch 5 - iter 1364/3410 - loss 0.07234550 - samples/sec: 130.95 - lr: 0.000030
2021-07-23 01:08:05,280 epoch 5 - iter 1705/3410 - loss 0.07249548 - samples/sec: 129.90 - lr: 0.000030
2021-07-23 01:09:28,963 epoch 5 - iter 2046/3410 - loss 0.07216047 - samples/sec: 130.42 - lr: 0.000030
2021-07-23 01:10:52,888 epoch 5 - iter 2387/3410 - loss 0.07163868 - samples/sec: 130.05 - lr: 0.000030
2021-07-23 01:12:17,111 epoch 5 - iter 2728/3410 - loss 0.07130252 - samples/sec: 129.59 - lr: 0.000030
2021-07-23 01:13:41,008 epoch 5 - iter 3069/3410 - loss 0.07117687 - samples/sec: 130.09 - lr: 0.000030
2021-07-23 01:15:05,250 epoch 5 - iter 3410/3410 - loss 0.07121230 - samples/sec: 129.56 - lr: 0.000030
2021-07-23 01:15:05,251 ----------------------------------------------------------------------------------------------------
2021-07-23 01:15:05,251 EPOCH 5 done: loss 0.0712 - lr 0.0000300
2021-07-23 01:15:18,436 DEV : loss 0.04744420945644379 - score 0.9872
2021-07-23 01:15:18,584 BAD EPOCHS (no improvement): 1
2021-07-23 01:15:18,585 ----------------------------------------------------------------------------------------------------
2021-07-23 01:16:41,892 epoch 6 - iter 341/3410 - loss 0.06604023 - samples/sec: 131.02 - lr: 0.000030
2021-07-23 01:18:05,990 epoch 6 - iter 682/3410 - loss 0.06530882 - samples/sec: 129.78 - lr: 0.000030
2021-07-23 01:19:29,345 epoch 6 - iter 1023/3410 - loss 0.06399822 - samples/sec: 130.94 - lr: 0.000030
2021-07-23 01:20:52,642 epoch 6 - iter 1364/3410 - loss 0.06472412 - samples/sec: 131.03 - lr: 0.000030
2021-07-23 01:22:16,375 epoch 6 - iter 1705/3410 - loss 0.06451857 - samples/sec: 130.35 - lr: 0.000030
2021-07-23 01:23:39,553 epoch 6 - iter 2046/3410 - loss 0.06471922 - samples/sec: 131.21 - lr: 0.000030
2021-07-23 01:25:03,207 epoch 6 - iter 2387/3410 - loss 0.06433286 - samples/sec: 130.47 - lr: 0.000030
2021-07-23 01:26:25,940 epoch 6 - iter 2728/3410 - loss 0.06554999 - samples/sec: 131.92 - lr: 0.000030
2021-07-23 01:27:50,082 epoch 6 - iter 3069/3410 - loss 0.06597765 - samples/sec: 129.71 - lr: 0.000030
2021-07-23 01:29:14,356 epoch 6 - iter 3410/3410 - loss 0.06597079 - samples/sec: 129.51 - lr: 0.000030
2021-07-23 01:29:14,357 ----------------------------------------------------------------------------------------------------
2021-07-23 01:29:14,357 EPOCH 6 done: loss 0.0660 - lr 0.0000300
2021-07-23 01:29:27,553 DEV : loss 0.04926222935318947 - score 0.9869
2021-07-23 01:29:27,702 BAD EPOCHS (no improvement): 2
2021-07-23 01:29:27,703 ----------------------------------------------------------------------------------------------------
2021-07-23 01:30:51,030 epoch 7 - iter 341/3410 - loss 0.06607365 - samples/sec: 130.99 - lr: 0.000030
2021-07-23 01:32:14,952 epoch 7 - iter 682/3410 - loss 0.06810301 - samples/sec: 130.05 - lr: 0.000030
2021-07-23 01:33:39,008 epoch 7 - iter 1023/3410 - loss 0.06693445 - samples/sec: 129.84 - lr: 0.000030
2021-07-23 01:35:03,042 epoch 7 - iter 1364/3410 - loss 0.06619422 - samples/sec: 129.88 - lr: 0.000030
2021-07-23 01:36:26,472 epoch 7 - iter 1705/3410 - loss 0.06675093 - samples/sec: 130.82 - lr: 0.000030
2021-07-23 01:37:50,525 epoch 7 - iter 2046/3410 - loss 0.06650314 - samples/sec: 129.85 - lr: 0.000030
2021-07-23 01:39:14,184 epoch 7 - iter 2387/3410 - loss 0.06523260 - samples/sec: 130.46 - lr: 0.000030
2021-07-23 01:40:37,709 epoch 7 - iter 2728/3410 - loss 0.06505599 - samples/sec: 130.67 - lr: 0.000030
2021-07-23 01:42:01,672 epoch 7 - iter 3069/3410 - loss 0.06541660 - samples/sec: 129.99 - lr: 0.000030
2021-07-23 01:43:26,115 epoch 7 - iter 3410/3410 - loss 0.06463902 - samples/sec: 129.25 - lr: 0.000030
2021-07-23 01:43:26,116 ----------------------------------------------------------------------------------------------------
2021-07-23 01:43:26,116 EPOCH 7 done: loss 0.0646 - lr 0.0000300
2021-07-23 01:43:39,310 DEV : loss 0.04384731501340866 - score 0.9883
2021-07-23 01:43:39,461 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 01:43:41,883 ----------------------------------------------------------------------------------------------------
2021-07-23 01:45:05,240 epoch 8 - iter 341/3410 - loss 0.06031776 - samples/sec: 130.95 - lr: 0.000030
2021-07-23 01:46:31,613 epoch 8 - iter 682/3410 - loss 0.05955106 - samples/sec: 126.36 - lr: 0.000030
2021-07-23 01:47:55,431 epoch 8 - iter 1023/3410 - loss 0.05993750 - samples/sec: 130.21 - lr: 0.000030
2021-07-23 01:49:19,368 epoch 8 - iter 1364/3410 - loss 0.06163403 - samples/sec: 130.03 - lr: 0.000030
2021-07-23 01:50:43,604 epoch 8 - iter 1705/3410 - loss 0.06269713 - samples/sec: 129.57 - lr: 0.000030
2021-07-23 01:52:07,564 epoch 8 - iter 2046/3410 - loss 0.06180994 - samples/sec: 129.99 - lr: 0.000030
2021-07-23 01:53:31,848 epoch 8 - iter 2387/3410 - loss 0.06137409 - samples/sec: 129.49 - lr: 0.000030
2021-07-23 01:54:55,252 epoch 8 - iter 2728/3410 - loss 0.06173232 - samples/sec: 130.86 - lr: 0.000030
2021-07-23 01:56:19,080 epoch 8 - iter 3069/3410 - loss 0.06181626 - samples/sec: 130.20 - lr: 0.000030
2021-07-23 01:57:42,620 epoch 8 - iter 3410/3410 - loss 0.06183658 - samples/sec: 130.65 - lr: 0.000030
2021-07-23 01:57:42,621 ----------------------------------------------------------------------------------------------------
2021-07-23 01:57:42,621 EPOCH 8 done: loss 0.0618 - lr 0.0000300
2021-07-23 01:57:55,856 DEV : loss 0.043829262256622314 - score 0.9884
2021-07-23 01:57:56,008 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 01:57:58,308 ----------------------------------------------------------------------------------------------------
2021-07-23 01:59:22,309 epoch 9 - iter 341/3410 - loss 0.05610590 - samples/sec: 129.94 - lr: 0.000030
2021-07-23 02:00:46,661 epoch 9 - iter 682/3410 - loss 0.05650854 - samples/sec: 129.39 - lr: 0.000030
2021-07-23 02:02:09,971 epoch 9 - iter 1023/3410 - loss 0.05901484 - samples/sec: 131.01 - lr: 0.000030
2021-07-23 02:03:33,656 epoch 9 - iter 1364/3410 - loss 0.05902451 - samples/sec: 130.42 - lr: 0.000030
2021-07-23 02:04:57,581 epoch 9 - iter 1705/3410 - loss 0.05868017 - samples/sec: 130.05 - lr: 0.000030
2021-07-23 02:06:21,669 epoch 9 - iter 2046/3410 - loss 0.05924430 - samples/sec: 129.80 - lr: 0.000030
2021-07-23 02:07:45,211 epoch 9 - iter 2387/3410 - loss 0.06002631 - samples/sec: 130.64 - lr: 0.000030
2021-07-23 02:09:08,968 epoch 9 - iter 2728/3410 - loss 0.06019070 - samples/sec: 130.31 - lr: 0.000030
2021-07-23 02:10:32,931 epoch 9 - iter 3069/3410 - loss 0.05986656 - samples/sec: 129.99 - lr: 0.000030
2021-07-23 02:11:56,819 epoch 9 - iter 3410/3410 - loss 0.05953078 - samples/sec: 130.11 - lr: 0.000030
2021-07-23 02:11:56,820 ----------------------------------------------------------------------------------------------------
2021-07-23 02:11:56,821 EPOCH 9 done: loss 0.0595 - lr 0.0000300
2021-07-23 02:12:10,060 DEV : loss 0.042054176330566406 - score 0.9888
2021-07-23 02:12:10,212 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 02:12:12,370 ----------------------------------------------------------------------------------------------------
2021-07-23 02:13:36,244 epoch 10 - iter 341/3410 - loss 0.05949926 - samples/sec: 130.14 - lr: 0.000030
2021-07-23 02:15:00,045 epoch 10 - iter 682/3410 - loss 0.06103334 - samples/sec: 130.24 - lr: 0.000030
2021-07-23 02:16:22,733 epoch 10 - iter 1023/3410 - loss 0.06170227 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 02:17:47,024 epoch 10 - iter 1364/3410 - loss 0.06057626 - samples/sec: 129.48 - lr: 0.000030
2021-07-23 02:19:10,692 epoch 10 - iter 1705/3410 - loss 0.06013710 - samples/sec: 130.45 - lr: 0.000030
2021-07-23 02:20:34,444 epoch 10 - iter 2046/3410 - loss 0.05904758 - samples/sec: 130.31 - lr: 0.000030
2021-07-23 02:21:58,289 epoch 10 - iter 2387/3410 - loss 0.05969923 - samples/sec: 130.17 - lr: 0.000030
2021-07-23 02:23:22,397 epoch 10 - iter 2728/3410 - loss 0.05947918 - samples/sec: 129.77 - lr: 0.000030
2021-07-23 02:24:46,700 epoch 10 - iter 3069/3410 - loss 0.05897733 - samples/sec: 129.46 - lr: 0.000030
2021-07-23 02:26:10,199 epoch 10 - iter 3410/3410 - loss 0.05892236 - samples/sec: 130.71 - lr: 0.000030
2021-07-23 02:26:10,200 ----------------------------------------------------------------------------------------------------
2021-07-23 02:26:10,200 EPOCH 10 done: loss 0.0589 - lr 0.0000300
2021-07-23 02:26:23,420 DEV : loss 0.04234270751476288 - score 0.9888
2021-07-23 02:26:23,570 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 02:26:25,788 ----------------------------------------------------------------------------------------------------
2021-07-23 02:27:49,617 epoch 11 - iter 341/3410 - loss 0.04973068 - samples/sec: 130.21 - lr: 0.000030
2021-07-23 02:29:13,910 epoch 11 - iter 682/3410 - loss 0.05467703 - samples/sec: 129.48 - lr: 0.000030
2021-07-23 02:30:36,917 epoch 11 - iter 1023/3410 - loss 0.05600631 - samples/sec: 131.49 - lr: 0.000030
2021-07-23 02:32:00,575 epoch 11 - iter 1364/3410 - loss 0.05686735 - samples/sec: 130.46 - lr: 0.000030
2021-07-23 02:33:24,535 epoch 11 - iter 1705/3410 - loss 0.05736375 - samples/sec: 129.99 - lr: 0.000030
2021-07-23 02:34:47,761 epoch 11 - iter 2046/3410 - loss 0.05703904 - samples/sec: 131.14 - lr: 0.000030
2021-07-23 02:36:11,716 epoch 11 - iter 2387/3410 - loss 0.05653631 - samples/sec: 130.00 - lr: 0.000030
2021-07-23 02:37:35,639 epoch 11 - iter 2728/3410 - loss 0.05661299 - samples/sec: 130.05 - lr: 0.000030
2021-07-23 02:38:58,827 epoch 11 - iter 3069/3410 - loss 0.05654589 - samples/sec: 131.20 - lr: 0.000030
2021-07-23 02:40:21,959 epoch 11 - iter 3410/3410 - loss 0.05701682 - samples/sec: 131.29 - lr: 0.000030
2021-07-23 02:40:21,960 ----------------------------------------------------------------------------------------------------
2021-07-23 02:40:21,960 EPOCH 11 done: loss 0.0570 - lr 0.0000300
2021-07-23 02:40:35,222 DEV : loss 0.04366767406463623 - score 0.9885
2021-07-23 02:40:35,373 BAD EPOCHS (no improvement): 1
2021-07-23 02:40:35,373 ----------------------------------------------------------------------------------------------------
2021-07-23 02:41:57,769 epoch 12 - iter 341/3410 - loss 0.04997817 - samples/sec: 132.47 - lr: 0.000030
2021-07-23 02:43:21,291 epoch 12 - iter 682/3410 - loss 0.05211284 - samples/sec: 130.68 - lr: 0.000030
2021-07-23 02:44:44,847 epoch 12 - iter 1023/3410 - loss 0.05377198 - samples/sec: 130.62 - lr: 0.000030
2021-07-23 02:46:08,487 epoch 12 - iter 1364/3410 - loss 0.05265444 - samples/sec: 130.49 - lr: 0.000030
2021-07-23 02:47:32,001 epoch 12 - iter 1705/3410 - loss 0.05297598 - samples/sec: 130.69 - lr: 0.000030
2021-07-23 02:48:55,236 epoch 12 - iter 2046/3410 - loss 0.05331288 - samples/sec: 131.12 - lr: 0.000030
2021-07-23 02:50:18,908 epoch 12 - iter 2387/3410 - loss 0.05326439 - samples/sec: 130.44 - lr: 0.000030
2021-07-23 02:51:42,413 epoch 12 - iter 2728/3410 - loss 0.05384105 - samples/sec: 130.70 - lr: 0.000030
2021-07-23 02:53:07,430 epoch 12 - iter 3069/3410 - loss 0.05390060 - samples/sec: 128.38 - lr: 0.000030
2021-07-23 02:54:31,520 epoch 12 - iter 3410/3410 - loss 0.05413297 - samples/sec: 129.79 - lr: 0.000030
2021-07-23 02:54:31,521 ----------------------------------------------------------------------------------------------------
2021-07-23 02:54:31,521 EPOCH 12 done: loss 0.0541 - lr 0.0000300
2021-07-23 02:54:44,798 DEV : loss 0.044013768434524536 - score 0.9883
2021-07-23 02:54:44,949 BAD EPOCHS (no improvement): 2
2021-07-23 02:54:44,949 ----------------------------------------------------------------------------------------------------
2021-07-23 02:56:08,696 epoch 13 - iter 341/3410 - loss 0.05327485 - samples/sec: 130.33 - lr: 0.000030
2021-07-23 02:57:32,520 epoch 13 - iter 682/3410 - loss 0.05323655 - samples/sec: 130.20 - lr: 0.000030
2021-07-23 02:58:55,718 epoch 13 - iter 1023/3410 - loss 0.05209965 - samples/sec: 131.18 - lr: 0.000030
2021-07-23 03:00:19,476 epoch 13 - iter 1364/3410 - loss 0.05298001 - samples/sec: 130.31 - lr: 0.000030
2021-07-23 03:01:42,737 epoch 13 - iter 1705/3410 - loss 0.05285324 - samples/sec: 131.08 - lr: 0.000030
2021-07-23 03:03:06,313 epoch 13 - iter 2046/3410 - loss 0.05366959 - samples/sec: 130.59 - lr: 0.000030
2021-07-23 03:04:29,780 epoch 13 - iter 2387/3410 - loss 0.05368096 - samples/sec: 130.76 - lr: 0.000030
2021-07-23 03:05:53,345 epoch 13 - iter 2728/3410 - loss 0.05342325 - samples/sec: 130.61 - lr: 0.000030
2021-07-23 03:07:17,170 epoch 13 - iter 3069/3410 - loss 0.05353575 - samples/sec: 130.20 - lr: 0.000030
2021-07-23 03:08:41,106 epoch 13 - iter 3410/3410 - loss 0.05380827 - samples/sec: 130.03 - lr: 0.000030
2021-07-23 03:08:41,107 ----------------------------------------------------------------------------------------------------
2021-07-23 03:08:41,107 EPOCH 13 done: loss 0.0538 - lr 0.0000300
2021-07-23 03:08:54,335 DEV : loss 0.04019714891910553 - score 0.9893
2021-07-23 03:08:54,485 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 03:08:56,585 ----------------------------------------------------------------------------------------------------
2021-07-23 03:10:20,482 epoch 14 - iter 341/3410 - loss 0.05107152 - samples/sec: 130.10 - lr: 0.000030
2021-07-23 03:11:44,289 epoch 14 - iter 682/3410 - loss 0.05199333 - samples/sec: 130.23 - lr: 0.000030
2021-07-23 03:13:07,969 epoch 14 - iter 1023/3410 - loss 0.05240200 - samples/sec: 130.43 - lr: 0.000030
2021-07-23 03:14:32,206 epoch 14 - iter 1364/3410 - loss 0.05217492 - samples/sec: 129.57 - lr: 0.000030
2021-07-23 03:15:56,276 epoch 14 - iter 1705/3410 - loss 0.05217638 - samples/sec: 129.82 - lr: 0.000030
2021-07-23 03:17:20,081 epoch 14 - iter 2046/3410 - loss 0.05202592 - samples/sec: 130.23 - lr: 0.000030
2021-07-23 03:18:42,815 epoch 14 - iter 2387/3410 - loss 0.05180062 - samples/sec: 131.92 - lr: 0.000030
2021-07-23 03:20:06,865 epoch 14 - iter 2728/3410 - loss 0.05206514 - samples/sec: 129.85 - lr: 0.000030
2021-07-23 03:21:30,943 epoch 14 - iter 3069/3410 - loss 0.05232461 - samples/sec: 129.81 - lr: 0.000030
2021-07-23 03:22:54,611 epoch 14 - iter 3410/3410 - loss 0.05252996 - samples/sec: 130.45 - lr: 0.000030
2021-07-23 03:22:54,612 ----------------------------------------------------------------------------------------------------
2021-07-23 03:22:54,612 EPOCH 14 done: loss 0.0525 - lr 0.0000300
2021-07-23 03:23:07,849 DEV : loss 0.0415768176317215 - score 0.9895
2021-07-23 03:23:08,001 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 03:23:10,278 ----------------------------------------------------------------------------------------------------
2021-07-23 03:24:34,911 epoch 15 - iter 341/3410 - loss 0.05250229 - samples/sec: 128.97 - lr: 0.000030
2021-07-23 03:25:58,554 epoch 15 - iter 682/3410 - loss 0.04950753 - samples/sec: 130.49 - lr: 0.000030
2021-07-23 03:27:25,563 epoch 15 - iter 1023/3410 - loss 0.05053882 - samples/sec: 125.44 - lr: 0.000030
2021-07-23 03:28:49,415 epoch 15 - iter 1364/3410 - loss 0.05065597 - samples/sec: 130.16 - lr: 0.000030
2021-07-23 03:30:13,645 epoch 15 - iter 1705/3410 - loss 0.05130674 - samples/sec: 129.58 - lr: 0.000030
2021-07-23 03:31:37,160 epoch 15 - iter 2046/3410 - loss 0.05048719 - samples/sec: 130.68 - lr: 0.000030
2021-07-23 03:33:01,144 epoch 15 - iter 2387/3410 - loss 0.05069844 - samples/sec: 129.96 - lr: 0.000030
2021-07-23 03:34:24,440 epoch 15 - iter 2728/3410 - loss 0.05028520 - samples/sec: 131.03 - lr: 0.000030
2021-07-23 03:35:48,357 epoch 15 - iter 3069/3410 - loss 0.05121637 - samples/sec: 130.06 - lr: 0.000030
2021-07-23 03:37:11,878 epoch 15 - iter 3410/3410 - loss 0.05108698 - samples/sec: 130.68 - lr: 0.000030
2021-07-23 03:37:11,879 ----------------------------------------------------------------------------------------------------
2021-07-23 03:37:11,879 EPOCH 15 done: loss 0.0511 - lr 0.0000300
2021-07-23 03:37:25,116 DEV : loss 0.04161541163921356 - score 0.9897
2021-07-23 03:37:25,266 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 03:37:27,471 ----------------------------------------------------------------------------------------------------
2021-07-23 03:38:50,716 epoch 16 - iter 341/3410 - loss 0.04905982 - samples/sec: 131.13 - lr: 0.000030
2021-07-23 03:40:14,356 epoch 16 - iter 682/3410 - loss 0.04919571 - samples/sec: 130.49 - lr: 0.000030
2021-07-23 03:41:38,042 epoch 16 - iter 1023/3410 - loss 0.04953147 - samples/sec: 130.42 - lr: 0.000030
2021-07-23 03:43:02,069 epoch 16 - iter 1364/3410 - loss 0.04949145 - samples/sec: 129.89 - lr: 0.000030
2021-07-23 03:44:25,696 epoch 16 - iter 1705/3410 - loss 0.04961934 - samples/sec: 130.51 - lr: 0.000030
2021-07-23 03:45:48,592 epoch 16 - iter 2046/3410 - loss 0.05016643 - samples/sec: 131.66 - lr: 0.000030
2021-07-23 03:47:11,703 epoch 16 - iter 2387/3410 - loss 0.05037593 - samples/sec: 131.32 - lr: 0.000030
2021-07-23 03:48:35,095 epoch 16 - iter 2728/3410 - loss 0.05069046 - samples/sec: 130.88 - lr: 0.000030
2021-07-23 03:49:59,667 epoch 16 - iter 3069/3410 - loss 0.04995268 - samples/sec: 129.05 - lr: 0.000030
2021-07-23 03:51:23,600 epoch 16 - iter 3410/3410 - loss 0.04968327 - samples/sec: 130.04 - lr: 0.000030
2021-07-23 03:51:23,601 ----------------------------------------------------------------------------------------------------
2021-07-23 03:51:23,601 EPOCH 16 done: loss 0.0497 - lr 0.0000300
2021-07-23 03:51:36,873 DEV : loss 0.04125220328569412 - score 0.9897
2021-07-23 03:51:37,025 BAD EPOCHS (no improvement): 1
2021-07-23 03:51:37,026 ----------------------------------------------------------------------------------------------------
2021-07-23 03:53:01,020 epoch 17 - iter 341/3410 - loss 0.04681606 - samples/sec: 129.95 - lr: 0.000030
2021-07-23 03:54:24,481 epoch 17 - iter 682/3410 - loss 0.04884546 - samples/sec: 130.77 - lr: 0.000030
2021-07-23 03:55:48,699 epoch 17 - iter 1023/3410 - loss 0.04880207 - samples/sec: 129.59 - lr: 0.000030
2021-07-23 03:57:12,588 epoch 17 - iter 1364/3410 - loss 0.04853169 - samples/sec: 130.10 - lr: 0.000030
2021-07-23 03:58:36,300 epoch 17 - iter 1705/3410 - loss 0.04936585 - samples/sec: 130.38 - lr: 0.000030
2021-07-23 04:00:00,193 epoch 17 - iter 2046/3410 - loss 0.04961375 - samples/sec: 130.10 - lr: 0.000030
2021-07-23 04:01:23,851 epoch 17 - iter 2387/3410 - loss 0.04933508 - samples/sec: 130.46 - lr: 0.000030
2021-07-23 04:02:47,948 epoch 17 - iter 2728/3410 - loss 0.04913636 - samples/sec: 129.78 - lr: 0.000030
2021-07-23 04:04:11,707 epoch 17 - iter 3069/3410 - loss 0.04924337 - samples/sec: 130.31 - lr: 0.000030
2021-07-23 04:05:35,692 epoch 17 - iter 3410/3410 - loss 0.04935710 - samples/sec: 129.96 - lr: 0.000030
2021-07-23 04:05:35,693 ----------------------------------------------------------------------------------------------------
2021-07-23 04:05:35,693 EPOCH 17 done: loss 0.0494 - lr 0.0000300
2021-07-23 04:05:48,937 DEV : loss 0.04104221984744072 - score 0.9897
2021-07-23 04:05:49,090 BAD EPOCHS (no improvement): 2
2021-07-23 04:05:49,090 ----------------------------------------------------------------------------------------------------
2021-07-23 04:07:12,386 epoch 18 - iter 341/3410 - loss 0.04498761 - samples/sec: 131.04 - lr: 0.000030
2021-07-23 04:08:35,909 epoch 18 - iter 682/3410 - loss 0.04586502 - samples/sec: 130.67 - lr: 0.000030
2021-07-23 04:09:59,306 epoch 18 - iter 1023/3410 - loss 0.04749508 - samples/sec: 130.87 - lr: 0.000030
2021-07-23 04:11:23,200 epoch 18 - iter 1364/3410 - loss 0.04792315 - samples/sec: 130.09 - lr: 0.000030
2021-07-23 04:12:46,788 epoch 18 - iter 1705/3410 - loss 0.04805267 - samples/sec: 130.57 - lr: 0.000030
2021-07-23 04:14:10,714 epoch 18 - iter 2046/3410 - loss 0.04827933 - samples/sec: 130.04 - lr: 0.000030
2021-07-23 04:15:34,743 epoch 18 - iter 2387/3410 - loss 0.04804126 - samples/sec: 129.89 - lr: 0.000030
2021-07-23 04:16:59,424 epoch 18 - iter 2728/3410 - loss 0.04840208 - samples/sec: 128.89 - lr: 0.000030
2021-07-23 04:18:23,412 epoch 18 - iter 3069/3410 - loss 0.04854437 - samples/sec: 129.95 - lr: 0.000030
2021-07-23 04:19:47,059 epoch 18 - iter 3410/3410 - loss 0.04883807 - samples/sec: 130.48 - lr: 0.000030
2021-07-23 04:19:47,060 ----------------------------------------------------------------------------------------------------
2021-07-23 04:19:47,060 EPOCH 18 done: loss 0.0488 - lr 0.0000300
2021-07-23 04:20:00,305 DEV : loss 0.04067091643810272 - score 0.9894
2021-07-23 04:20:00,455 BAD EPOCHS (no improvement): 3
2021-07-23 04:20:00,455 ----------------------------------------------------------------------------------------------------
2021-07-23 04:21:24,636 epoch 19 - iter 341/3410 - loss 0.05012524 - samples/sec: 129.66 - lr: 0.000030
2021-07-23 04:22:48,132 epoch 19 - iter 682/3410 - loss 0.04850233 - samples/sec: 130.72 - lr: 0.000030
2021-07-23 04:24:11,205 epoch 19 - iter 1023/3410 - loss 0.04840999 - samples/sec: 131.38 - lr: 0.000030
2021-07-23 04:25:34,241 epoch 19 - iter 1364/3410 - loss 0.04883771 - samples/sec: 131.44 - lr: 0.000030
2021-07-23 04:26:57,891 epoch 19 - iter 1705/3410 - loss 0.04853103 - samples/sec: 130.48 - lr: 0.000030
2021-07-23 04:28:21,733 epoch 19 - iter 2046/3410 - loss 0.04779242 - samples/sec: 130.17 - lr: 0.000030
2021-07-23 04:29:44,939 epoch 19 - iter 2387/3410 - loss 0.04773210 - samples/sec: 131.17 - lr: 0.000030
2021-07-23 04:31:09,473 epoch 19 - iter 2728/3410 - loss 0.04779033 - samples/sec: 129.11 - lr: 0.000030
2021-07-23 04:32:33,094 epoch 19 - iter 3069/3410 - loss 0.04782565 - samples/sec: 130.52 - lr: 0.000030
2021-07-23 04:33:56,807 epoch 19 - iter 3410/3410 - loss 0.04730450 - samples/sec: 130.38 - lr: 0.000030
2021-07-23 04:33:56,808 ----------------------------------------------------------------------------------------------------
2021-07-23 04:33:56,808 EPOCH 19 done: loss 0.0473 - lr 0.0000300
2021-07-23 04:34:10,057 DEV : loss 0.040511708706617355 - score 0.9895
Epoch    19: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 04:34:10,209 BAD EPOCHS (no improvement): 4
2021-07-23 04:34:10,209 ----------------------------------------------------------------------------------------------------
2021-07-23 04:35:34,088 epoch 20 - iter 341/3410 - loss 0.04413680 - samples/sec: 130.13 - lr: 0.000015
2021-07-23 04:36:57,847 epoch 20 - iter 682/3410 - loss 0.04417231 - samples/sec: 130.30 - lr: 0.000015
2021-07-23 04:38:21,006 epoch 20 - iter 1023/3410 - loss 0.04423895 - samples/sec: 131.24 - lr: 0.000015
2021-07-23 04:39:45,029 epoch 20 - iter 1364/3410 - loss 0.04467917 - samples/sec: 129.89 - lr: 0.000015
2021-07-23 04:41:09,036 epoch 20 - iter 1705/3410 - loss 0.04550652 - samples/sec: 129.92 - lr: 0.000015
2021-07-23 04:42:33,023 epoch 20 - iter 2046/3410 - loss 0.04532163 - samples/sec: 129.95 - lr: 0.000015
2021-07-23 04:43:56,842 epoch 20 - iter 2387/3410 - loss 0.04508542 - samples/sec: 130.21 - lr: 0.000015
2021-07-23 04:45:20,858 epoch 20 - iter 2728/3410 - loss 0.04472367 - samples/sec: 129.91 - lr: 0.000015
2021-07-23 04:46:44,593 epoch 20 - iter 3069/3410 - loss 0.04456308 - samples/sec: 130.34 - lr: 0.000015
2021-07-23 04:48:07,727 epoch 20 - iter 3410/3410 - loss 0.04478120 - samples/sec: 131.29 - lr: 0.000015
2021-07-23 04:48:07,728 ----------------------------------------------------------------------------------------------------
2021-07-23 04:48:07,728 EPOCH 20 done: loss 0.0448 - lr 0.0000150
2021-07-23 04:48:20,990 DEV : loss 0.041007161140441895 - score 0.9895
2021-07-23 04:48:21,142 BAD EPOCHS (no improvement): 1
2021-07-23 04:48:21,142 ----------------------------------------------------------------------------------------------------
2021-07-23 04:49:45,135 epoch 21 - iter 341/3410 - loss 0.04177705 - samples/sec: 129.95 - lr: 0.000015
2021-07-23 04:51:08,953 epoch 21 - iter 682/3410 - loss 0.04362216 - samples/sec: 130.21 - lr: 0.000015
2021-07-23 04:52:32,631 epoch 21 - iter 1023/3410 - loss 0.04490259 - samples/sec: 130.43 - lr: 0.000015
2021-07-23 04:53:56,552 epoch 21 - iter 1364/3410 - loss 0.04452065 - samples/sec: 130.05 - lr: 0.000015
2021-07-23 04:55:19,928 epoch 21 - iter 1705/3410 - loss 0.04391565 - samples/sec: 130.90 - lr: 0.000015
2021-07-23 04:56:44,159 epoch 21 - iter 2046/3410 - loss 0.04385111 - samples/sec: 129.58 - lr: 0.000015
2021-07-23 04:58:07,533 epoch 21 - iter 2387/3410 - loss 0.04404924 - samples/sec: 130.91 - lr: 0.000015
2021-07-23 04:59:31,392 epoch 21 - iter 2728/3410 - loss 0.04399449 - samples/sec: 130.15 - lr: 0.000015
2021-07-23 05:00:54,467 epoch 21 - iter 3069/3410 - loss 0.04393595 - samples/sec: 131.38 - lr: 0.000015
2021-07-23 05:02:18,123 epoch 21 - iter 3410/3410 - loss 0.04441024 - samples/sec: 130.47 - lr: 0.000015
2021-07-23 05:02:18,124 ----------------------------------------------------------------------------------------------------
2021-07-23 05:02:18,124 EPOCH 21 done: loss 0.0444 - lr 0.0000150
2021-07-23 05:02:31,380 DEV : loss 0.04239266365766525 - score 0.9894
2021-07-23 05:02:31,532 BAD EPOCHS (no improvement): 2
2021-07-23 05:02:31,532 ----------------------------------------------------------------------------------------------------
2021-07-23 05:03:55,219 epoch 22 - iter 341/3410 - loss 0.04920080 - samples/sec: 130.43 - lr: 0.000015
2021-07-23 05:05:21,854 epoch 22 - iter 682/3410 - loss 0.04791790 - samples/sec: 125.98 - lr: 0.000015
2021-07-23 05:06:45,738 epoch 22 - iter 1023/3410 - loss 0.04732208 - samples/sec: 130.11 - lr: 0.000015
2021-07-23 05:08:09,345 epoch 22 - iter 1364/3410 - loss 0.04698831 - samples/sec: 130.54 - lr: 0.000015
2021-07-23 05:09:32,892 epoch 22 - iter 1705/3410 - loss 0.04665722 - samples/sec: 130.64 - lr: 0.000015
2021-07-23 05:10:56,575 epoch 22 - iter 2046/3410 - loss 0.04575167 - samples/sec: 130.42 - lr: 0.000015
2021-07-23 05:12:20,350 epoch 22 - iter 2387/3410 - loss 0.04591644 - samples/sec: 130.28 - lr: 0.000015
2021-07-23 05:13:44,908 epoch 22 - iter 2728/3410 - loss 0.04556927 - samples/sec: 129.07 - lr: 0.000015
2021-07-23 05:15:08,649 epoch 22 - iter 3069/3410 - loss 0.04542013 - samples/sec: 130.33 - lr: 0.000015
2021-07-23 05:16:31,879 epoch 22 - iter 3410/3410 - loss 0.04485822 - samples/sec: 131.13 - lr: 0.000015
2021-07-23 05:16:31,880 ----------------------------------------------------------------------------------------------------
2021-07-23 05:16:31,880 EPOCH 22 done: loss 0.0449 - lr 0.0000150
2021-07-23 05:16:45,132 DEV : loss 0.045680999755859375 - score 0.9883
2021-07-23 05:16:45,284 BAD EPOCHS (no improvement): 3
2021-07-23 05:16:45,284 ----------------------------------------------------------------------------------------------------
2021-07-23 05:18:09,152 epoch 23 - iter 341/3410 - loss 0.04370615 - samples/sec: 130.14 - lr: 0.000015
2021-07-23 05:19:32,273 epoch 23 - iter 682/3410 - loss 0.04248857 - samples/sec: 131.31 - lr: 0.000015
2021-07-23 05:20:56,608 epoch 23 - iter 1023/3410 - loss 0.04366872 - samples/sec: 129.41 - lr: 0.000015
2021-07-23 05:22:21,278 epoch 23 - iter 1364/3410 - loss 0.04248579 - samples/sec: 128.90 - lr: 0.000015
2021-07-23 05:23:45,064 epoch 23 - iter 1705/3410 - loss 0.04288012 - samples/sec: 130.26 - lr: 0.000015
2021-07-23 05:25:09,240 epoch 23 - iter 2046/3410 - loss 0.04358037 - samples/sec: 129.66 - lr: 0.000015
2021-07-23 05:26:32,836 epoch 23 - iter 2387/3410 - loss 0.04356254 - samples/sec: 130.56 - lr: 0.000015
2021-07-23 05:27:56,723 epoch 23 - iter 2728/3410 - loss 0.04329415 - samples/sec: 130.11 - lr: 0.000015
2021-07-23 05:29:20,141 epoch 23 - iter 3069/3410 - loss 0.04335323 - samples/sec: 130.84 - lr: 0.000015
2021-07-23 05:30:43,494 epoch 23 - iter 3410/3410 - loss 0.04363918 - samples/sec: 130.94 - lr: 0.000015
2021-07-23 05:30:43,495 ----------------------------------------------------------------------------------------------------
2021-07-23 05:30:43,495 EPOCH 23 done: loss 0.0436 - lr 0.0000150
2021-07-23 05:30:56,772 DEV : loss 0.04256666824221611 - score 0.9888
Epoch    23: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 05:30:56,924 BAD EPOCHS (no improvement): 4
2021-07-23 05:30:56,924 ----------------------------------------------------------------------------------------------------
2021-07-23 05:32:20,868 epoch 24 - iter 341/3410 - loss 0.04460443 - samples/sec: 130.03 - lr: 0.000008
2021-07-23 05:33:44,789 epoch 24 - iter 682/3410 - loss 0.04391137 - samples/sec: 130.05 - lr: 0.000008
2021-07-23 05:35:07,361 epoch 24 - iter 1023/3410 - loss 0.04166971 - samples/sec: 132.18 - lr: 0.000008
2021-07-23 05:36:31,396 epoch 24 - iter 1364/3410 - loss 0.04183555 - samples/sec: 129.88 - lr: 0.000008
2021-07-23 05:37:54,837 epoch 24 - iter 1705/3410 - loss 0.04221640 - samples/sec: 130.80 - lr: 0.000008
2021-07-23 05:39:18,331 epoch 24 - iter 2046/3410 - loss 0.04202526 - samples/sec: 130.72 - lr: 0.000008
2021-07-23 05:40:42,541 epoch 24 - iter 2387/3410 - loss 0.04228557 - samples/sec: 129.61 - lr: 0.000008
2021-07-23 05:42:06,647 epoch 24 - iter 2728/3410 - loss 0.04193240 - samples/sec: 129.77 - lr: 0.000008
2021-07-23 05:43:30,136 epoch 24 - iter 3069/3410 - loss 0.04232183 - samples/sec: 130.73 - lr: 0.000008
2021-07-23 05:44:54,550 epoch 24 - iter 3410/3410 - loss 0.04240478 - samples/sec: 129.29 - lr: 0.000008
2021-07-23 05:44:54,551 ----------------------------------------------------------------------------------------------------
2021-07-23 05:44:54,551 EPOCH 24 done: loss 0.0424 - lr 0.0000075
2021-07-23 05:45:07,823 DEV : loss 0.04125479236245155 - score 0.9888
2021-07-23 05:45:07,974 BAD EPOCHS (no improvement): 1
2021-07-23 05:45:07,974 ----------------------------------------------------------------------------------------------------
2021-07-23 05:46:31,504 epoch 25 - iter 341/3410 - loss 0.04209697 - samples/sec: 130.67 - lr: 0.000008
2021-07-23 05:47:55,727 epoch 25 - iter 682/3410 - loss 0.04091056 - samples/sec: 129.59 - lr: 0.000008
2021-07-23 05:49:19,481 epoch 25 - iter 1023/3410 - loss 0.04098213 - samples/sec: 130.31 - lr: 0.000008
2021-07-23 05:50:42,588 epoch 25 - iter 1364/3410 - loss 0.04171148 - samples/sec: 131.33 - lr: 0.000008
2021-07-23 05:52:06,205 epoch 25 - iter 1705/3410 - loss 0.04133919 - samples/sec: 130.53 - lr: 0.000008
2021-07-23 05:53:30,404 epoch 25 - iter 2046/3410 - loss 0.04226770 - samples/sec: 129.62 - lr: 0.000008
2021-07-23 05:54:54,222 epoch 25 - iter 2387/3410 - loss 0.04215207 - samples/sec: 130.21 - lr: 0.000008
2021-07-23 05:56:17,744 epoch 25 - iter 2728/3410 - loss 0.04173119 - samples/sec: 130.67 - lr: 0.000008
2021-07-23 05:57:41,236 epoch 25 - iter 3069/3410 - loss 0.04205096 - samples/sec: 130.72 - lr: 0.000008
2021-07-23 05:59:05,755 epoch 25 - iter 3410/3410 - loss 0.04169707 - samples/sec: 129.13 - lr: 0.000008
2021-07-23 05:59:05,756 ----------------------------------------------------------------------------------------------------
2021-07-23 05:59:05,756 EPOCH 25 done: loss 0.0417 - lr 0.0000075
2021-07-23 05:59:19,023 DEV : loss 0.04410487413406372 - score 0.9888
2021-07-23 05:59:19,174 BAD EPOCHS (no improvement): 2
2021-07-23 05:59:19,174 ----------------------------------------------------------------------------------------------------
2021-07-23 06:00:42,988 epoch 26 - iter 341/3410 - loss 0.04194650 - samples/sec: 130.23 - lr: 0.000008
2021-07-23 06:02:06,944 epoch 26 - iter 682/3410 - loss 0.04021782 - samples/sec: 130.00 - lr: 0.000008
2021-07-23 06:03:30,725 epoch 26 - iter 1023/3410 - loss 0.04112569 - samples/sec: 130.27 - lr: 0.000008
2021-07-23 06:04:54,280 epoch 26 - iter 1364/3410 - loss 0.04143182 - samples/sec: 130.62 - lr: 0.000008
2021-07-23 06:06:18,860 epoch 26 - iter 1705/3410 - loss 0.04120230 - samples/sec: 129.04 - lr: 0.000008
2021-07-23 06:07:42,719 epoch 26 - iter 2046/3410 - loss 0.04071408 - samples/sec: 130.15 - lr: 0.000008
2021-07-23 06:09:06,893 epoch 26 - iter 2387/3410 - loss 0.04057827 - samples/sec: 129.66 - lr: 0.000008
2021-07-23 06:10:30,389 epoch 26 - iter 2728/3410 - loss 0.04053849 - samples/sec: 130.72 - lr: 0.000008
2021-07-23 06:11:53,661 epoch 26 - iter 3069/3410 - loss 0.04047834 - samples/sec: 131.07 - lr: 0.000008
2021-07-23 06:13:17,678 epoch 26 - iter 3410/3410 - loss 0.04090746 - samples/sec: 129.91 - lr: 0.000008
2021-07-23 06:13:17,679 ----------------------------------------------------------------------------------------------------
2021-07-23 06:13:17,679 EPOCH 26 done: loss 0.0409 - lr 0.0000075
2021-07-23 06:13:30,964 DEV : loss 0.0431121401488781 - score 0.9887
2021-07-23 06:13:31,115 BAD EPOCHS (no improvement): 3
2021-07-23 06:13:31,115 ----------------------------------------------------------------------------------------------------
2021-07-23 06:14:55,104 epoch 27 - iter 341/3410 - loss 0.04067618 - samples/sec: 129.96 - lr: 0.000008
2021-07-23 06:16:18,643 epoch 27 - iter 682/3410 - loss 0.04163293 - samples/sec: 130.65 - lr: 0.000008
2021-07-23 06:17:42,409 epoch 27 - iter 1023/3410 - loss 0.04024962 - samples/sec: 130.29 - lr: 0.000008
2021-07-23 06:19:07,334 epoch 27 - iter 1364/3410 - loss 0.04111949 - samples/sec: 128.51 - lr: 0.000008
2021-07-23 06:20:31,348 epoch 27 - iter 1705/3410 - loss 0.04131996 - samples/sec: 129.91 - lr: 0.000008
2021-07-23 06:21:54,898 epoch 27 - iter 2046/3410 - loss 0.04044614 - samples/sec: 130.63 - lr: 0.000008
2021-07-23 06:23:18,732 epoch 27 - iter 2387/3410 - loss 0.04034484 - samples/sec: 130.19 - lr: 0.000008
2021-07-23 06:24:42,448 epoch 27 - iter 2728/3410 - loss 0.04000729 - samples/sec: 130.37 - lr: 0.000008
2021-07-23 06:26:06,272 epoch 27 - iter 3069/3410 - loss 0.03990471 - samples/sec: 130.20 - lr: 0.000008
2021-07-23 06:27:29,288 epoch 27 - iter 3410/3410 - loss 0.04014744 - samples/sec: 131.47 - lr: 0.000008
2021-07-23 06:27:29,289 ----------------------------------------------------------------------------------------------------
2021-07-23 06:27:29,289 EPOCH 27 done: loss 0.0401 - lr 0.0000075
2021-07-23 06:27:42,543 DEV : loss 0.04355144873261452 - score 0.9886
Epoch    27: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 06:27:42,693 BAD EPOCHS (no improvement): 4
2021-07-23 06:27:42,694 ----------------------------------------------------------------------------------------------------
2021-07-23 06:29:05,757 epoch 28 - iter 341/3410 - loss 0.03704280 - samples/sec: 131.41 - lr: 0.000004
2021-07-23 06:30:29,332 epoch 28 - iter 682/3410 - loss 0.03797767 - samples/sec: 130.59 - lr: 0.000004
2021-07-23 06:31:53,248 epoch 28 - iter 1023/3410 - loss 0.03884709 - samples/sec: 130.06 - lr: 0.000004
2021-07-23 06:33:17,423 epoch 28 - iter 1364/3410 - loss 0.03990476 - samples/sec: 129.66 - lr: 0.000004
2021-07-23 06:34:41,474 epoch 28 - iter 1705/3410 - loss 0.04119879 - samples/sec: 129.85 - lr: 0.000004
2021-07-23 06:36:05,518 epoch 28 - iter 2046/3410 - loss 0.04075096 - samples/sec: 129.86 - lr: 0.000004
2021-07-23 06:37:28,792 epoch 28 - iter 2387/3410 - loss 0.04064028 - samples/sec: 131.06 - lr: 0.000004
2021-07-23 06:38:52,648 epoch 28 - iter 2728/3410 - loss 0.04075784 - samples/sec: 130.15 - lr: 0.000004
2021-07-23 06:40:16,616 epoch 28 - iter 3069/3410 - loss 0.04050610 - samples/sec: 129.98 - lr: 0.000004
2021-07-23 06:41:40,344 epoch 28 - iter 3410/3410 - loss 0.04045377 - samples/sec: 130.35 - lr: 0.000004
2021-07-23 06:41:40,345 ----------------------------------------------------------------------------------------------------
2021-07-23 06:41:40,345 EPOCH 28 done: loss 0.0405 - lr 0.0000038
2021-07-23 06:41:53,640 DEV : loss 0.04293276369571686 - score 0.989
2021-07-23 06:41:53,791 BAD EPOCHS (no improvement): 1
2021-07-23 06:41:53,791 ----------------------------------------------------------------------------------------------------
2021-07-23 06:43:17,365 epoch 29 - iter 341/3410 - loss 0.04208005 - samples/sec: 130.60 - lr: 0.000004
2021-07-23 06:44:41,313 epoch 29 - iter 682/3410 - loss 0.03976189 - samples/sec: 130.01 - lr: 0.000004
2021-07-23 06:46:07,658 epoch 29 - iter 1023/3410 - loss 0.03923323 - samples/sec: 126.40 - lr: 0.000004
2021-07-23 06:47:31,094 epoch 29 - iter 1364/3410 - loss 0.03974703 - samples/sec: 130.81 - lr: 0.000004
2021-07-23 06:48:54,945 epoch 29 - iter 1705/3410 - loss 0.04048846 - samples/sec: 130.16 - lr: 0.000004
2021-07-23 06:50:19,265 epoch 29 - iter 2046/3410 - loss 0.04036596 - samples/sec: 129.44 - lr: 0.000004
2021-07-23 06:51:42,535 epoch 29 - iter 2387/3410 - loss 0.04044866 - samples/sec: 131.07 - lr: 0.000004
2021-07-23 06:53:06,440 epoch 29 - iter 2728/3410 - loss 0.04052597 - samples/sec: 130.08 - lr: 0.000004
2021-07-23 06:54:30,324 epoch 29 - iter 3069/3410 - loss 0.04030894 - samples/sec: 130.11 - lr: 0.000004
2021-07-23 06:55:54,820 epoch 29 - iter 3410/3410 - loss 0.04047722 - samples/sec: 129.17 - lr: 0.000004
2021-07-23 06:55:54,821 ----------------------------------------------------------------------------------------------------
2021-07-23 06:55:54,821 EPOCH 29 done: loss 0.0405 - lr 0.0000038
2021-07-23 06:56:08,110 DEV : loss 0.042657557874917984 - score 0.9892
2021-07-23 06:56:08,263 BAD EPOCHS (no improvement): 2
2021-07-23 06:56:08,263 ----------------------------------------------------------------------------------------------------
2021-07-23 06:57:32,085 epoch 30 - iter 341/3410 - loss 0.04382018 - samples/sec: 130.22 - lr: 0.000004
2021-07-23 06:58:56,545 epoch 30 - iter 682/3410 - loss 0.04232153 - samples/sec: 129.22 - lr: 0.000004
2021-07-23 07:00:20,141 epoch 30 - iter 1023/3410 - loss 0.04172325 - samples/sec: 130.56 - lr: 0.000004
2021-07-23 07:01:43,957 epoch 30 - iter 1364/3410 - loss 0.04244876 - samples/sec: 130.22 - lr: 0.000004
2021-07-23 07:03:07,594 epoch 30 - iter 1705/3410 - loss 0.04182502 - samples/sec: 130.49 - lr: 0.000004
2021-07-23 07:04:31,525 epoch 30 - iter 2046/3410 - loss 0.04139104 - samples/sec: 130.04 - lr: 0.000004
2021-07-23 07:05:56,195 epoch 30 - iter 2387/3410 - loss 0.04035287 - samples/sec: 128.90 - lr: 0.000004
2021-07-23 07:07:19,864 epoch 30 - iter 2728/3410 - loss 0.04005920 - samples/sec: 130.44 - lr: 0.000004
2021-07-23 07:08:43,856 epoch 30 - iter 3069/3410 - loss 0.03977955 - samples/sec: 129.94 - lr: 0.000004
2021-07-23 07:10:07,520 epoch 30 - iter 3410/3410 - loss 0.03966762 - samples/sec: 130.45 - lr: 0.000004
2021-07-23 07:10:07,521 ----------------------------------------------------------------------------------------------------
2021-07-23 07:10:07,521 EPOCH 30 done: loss 0.0397 - lr 0.0000038
2021-07-23 07:10:20,797 DEV : loss 0.04295302927494049 - score 0.9891
2021-07-23 07:10:20,950 BAD EPOCHS (no improvement): 3
2021-07-23 07:10:20,950 ----------------------------------------------------------------------------------------------------
2021-07-23 07:11:45,057 epoch 31 - iter 341/3410 - loss 0.03350860 - samples/sec: 129.77 - lr: 0.000004
2021-07-23 07:13:08,284 epoch 31 - iter 682/3410 - loss 0.03843132 - samples/sec: 131.14 - lr: 0.000004
2021-07-23 07:14:32,638 epoch 31 - iter 1023/3410 - loss 0.04059968 - samples/sec: 129.39 - lr: 0.000004
2021-07-23 07:15:56,356 epoch 31 - iter 1364/3410 - loss 0.03917383 - samples/sec: 130.37 - lr: 0.000004
2021-07-23 07:17:20,404 epoch 31 - iter 1705/3410 - loss 0.03855335 - samples/sec: 129.86 - lr: 0.000004
2021-07-23 07:18:44,076 epoch 31 - iter 2046/3410 - loss 0.03935591 - samples/sec: 130.44 - lr: 0.000004
2021-07-23 07:20:08,500 epoch 31 - iter 2387/3410 - loss 0.03946681 - samples/sec: 129.28 - lr: 0.000004
2021-07-23 07:21:32,425 epoch 31 - iter 2728/3410 - loss 0.03912251 - samples/sec: 130.05 - lr: 0.000004
2021-07-23 07:22:55,699 epoch 31 - iter 3069/3410 - loss 0.03901763 - samples/sec: 131.06 - lr: 0.000004
2021-07-23 07:24:19,248 epoch 31 - iter 3410/3410 - loss 0.03923030 - samples/sec: 130.63 - lr: 0.000004
2021-07-23 07:24:19,249 ----------------------------------------------------------------------------------------------------
2021-07-23 07:24:19,249 EPOCH 31 done: loss 0.0392 - lr 0.0000038
2021-07-23 07:24:32,490 DEV : loss 0.04273634031414986 - score 0.9892
Epoch    31: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 07:24:32,641 BAD EPOCHS (no improvement): 4
2021-07-23 07:24:32,641 ----------------------------------------------------------------------------------------------------
2021-07-23 07:24:32,641 ----------------------------------------------------------------------------------------------------
2021-07-23 07:24:32,641 learning rate too small - quitting training!
2021-07-23 07:24:32,641 ----------------------------------------------------------------------------------------------------
2021-07-23 07:24:33,298 ----------------------------------------------------------------------------------------------------
2021-07-23 07:24:33,299 Testing using best model ...
2021-07-23 07:24:33,300 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.pdtb.pdtb/best-model.pt
2021-07-23 07:31:58,561 0.9883	0.9910	0.9896
2021-07-23 07:31:58,561 
Results:
- F1-score (micro) 0.9896
- F1-score (macro) 0.9887

By class:
SENT       tp: 10432 - fp: 272 - fn: 209 - precision: 0.9746 - recall: 0.9804 - f1-score: 0.9775
X          tp: 12465 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 07:31:58,561 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/rus.rst.rrt/
2021-07-23 07:31:58,604 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/rus.rst.rrt
2021-07-23 07:31:58,606 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/rus.rst.rrt/sent_train.txt
2021-07-23 07:31:58,608 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/rus.rst.rrt/sent_dev.txt
2021-07-23 07:31:58,609 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/rus.rst.rrt/sent_test.txt
Corpus: 43301 train + 5825 dev + 11929 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 07:32:32,398 ----------------------------------------------------------------------------------------------------
2021-07-23 07:32:32,400 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50021, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 07:32:32,400 ----------------------------------------------------------------------------------------------------
2021-07-23 07:32:32,400 Corpus: "Corpus: 43301 train + 5825 dev + 11929 test sentences"
2021-07-23 07:32:32,400 ----------------------------------------------------------------------------------------------------
2021-07-23 07:32:32,400 Parameters:
2021-07-23 07:32:32,400  - learning_rate: "3e-05"
2021-07-23 07:32:32,400  - mini_batch_size: "32"
2021-07-23 07:32:32,400  - patience: "3"
2021-07-23 07:32:32,401  - anneal_factor: "0.5"
2021-07-23 07:32:32,401  - max_epochs: "40"
2021-07-23 07:32:32,401  - shuffle: "True"
2021-07-23 07:32:32,401  - train_with_dev: "False"
2021-07-23 07:32:32,401  - batch_growth_annealing: "False"
2021-07-23 07:32:32,401 ----------------------------------------------------------------------------------------------------
2021-07-23 07:32:32,401 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/rus.rst.rrt"
2021-07-23 07:32:32,401 ----------------------------------------------------------------------------------------------------
2021-07-23 07:32:32,401 Device: cuda:0
2021-07-23 07:32:32,401 ----------------------------------------------------------------------------------------------------
2021-07-23 07:32:32,401 Embeddings storage mode: cpu
2021-07-23 07:32:32,403 ----------------------------------------------------------------------------------------------------
2021-07-23 07:33:51,914 epoch 1 - iter 135/1354 - loss 3.93773128 - samples/sec: 54.34 - lr: 0.000030
2021-07-23 07:35:15,733 epoch 1 - iter 270/1354 - loss 2.20125067 - samples/sec: 51.54 - lr: 0.000030
2021-07-23 07:36:38,047 epoch 1 - iter 405/1354 - loss 1.58318486 - samples/sec: 52.49 - lr: 0.000030
2021-07-23 07:38:02,565 epoch 1 - iter 540/1354 - loss 1.26355645 - samples/sec: 51.12 - lr: 0.000030
2021-07-23 07:39:26,397 epoch 1 - iter 675/1354 - loss 1.06373375 - samples/sec: 51.53 - lr: 0.000030
2021-07-23 07:40:48,967 epoch 1 - iter 810/1354 - loss 0.94183804 - samples/sec: 52.32 - lr: 0.000030
2021-07-23 07:42:11,570 epoch 1 - iter 945/1354 - loss 0.84721292 - samples/sec: 52.30 - lr: 0.000030
2021-07-23 07:43:34,719 epoch 1 - iter 1080/1354 - loss 0.77626950 - samples/sec: 51.96 - lr: 0.000030
2021-07-23 07:44:57,604 epoch 1 - iter 1215/1354 - loss 0.71811257 - samples/sec: 52.12 - lr: 0.000030
2021-07-23 07:46:25,134 epoch 1 - iter 1350/1354 - loss 0.66929596 - samples/sec: 49.36 - lr: 0.000030
2021-07-23 07:46:26,991 ----------------------------------------------------------------------------------------------------
2021-07-23 07:46:26,991 EPOCH 1 done: loss 0.6688 - lr 0.0000300
2021-07-23 07:47:50,674 DEV : loss 0.10907438397407532 - score 0.9713
2021-07-23 07:47:50,824 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 07:47:51,491 ----------------------------------------------------------------------------------------------------
2021-07-23 07:48:24,884 epoch 2 - iter 135/1354 - loss 0.22867147 - samples/sec: 129.40 - lr: 0.000030
2021-07-23 07:48:57,956 epoch 2 - iter 270/1354 - loss 0.23297030 - samples/sec: 130.65 - lr: 0.000030
2021-07-23 07:49:31,696 epoch 2 - iter 405/1354 - loss 0.23182556 - samples/sec: 128.06 - lr: 0.000030
2021-07-23 07:50:05,408 epoch 2 - iter 540/1354 - loss 0.23295424 - samples/sec: 128.17 - lr: 0.000030
2021-07-23 07:50:38,505 epoch 2 - iter 675/1354 - loss 0.23237939 - samples/sec: 130.55 - lr: 0.000030
2021-07-23 07:51:12,125 epoch 2 - iter 810/1354 - loss 0.22808414 - samples/sec: 128.52 - lr: 0.000030
2021-07-23 07:51:46,103 epoch 2 - iter 945/1354 - loss 0.22830323 - samples/sec: 127.16 - lr: 0.000030
2021-07-23 07:52:19,423 epoch 2 - iter 1080/1354 - loss 0.22320751 - samples/sec: 129.68 - lr: 0.000030
2021-07-23 07:52:52,902 epoch 2 - iter 1215/1354 - loss 0.22177908 - samples/sec: 129.06 - lr: 0.000030
2021-07-23 07:53:26,489 epoch 2 - iter 1350/1354 - loss 0.21815432 - samples/sec: 128.65 - lr: 0.000030
2021-07-23 07:53:27,335 ----------------------------------------------------------------------------------------------------
2021-07-23 07:53:27,335 EPOCH 2 done: loss 0.2181 - lr 0.0000300
2021-07-23 07:53:41,643 DEV : loss 0.08341243118047714 - score 0.9784
2021-07-23 07:53:41,796 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 07:53:44,504 ----------------------------------------------------------------------------------------------------
2021-07-23 07:54:17,920 epoch 3 - iter 135/1354 - loss 0.19936637 - samples/sec: 129.32 - lr: 0.000030
2021-07-23 07:54:51,960 epoch 3 - iter 270/1354 - loss 0.19502867 - samples/sec: 126.94 - lr: 0.000030
2021-07-23 07:55:25,396 epoch 3 - iter 405/1354 - loss 0.19610903 - samples/sec: 129.23 - lr: 0.000030
2021-07-23 07:55:59,072 epoch 3 - iter 540/1354 - loss 0.19460194 - samples/sec: 128.30 - lr: 0.000030
2021-07-23 07:56:32,488 epoch 3 - iter 675/1354 - loss 0.19279193 - samples/sec: 129.31 - lr: 0.000030
2021-07-23 07:57:06,303 epoch 3 - iter 810/1354 - loss 0.19144232 - samples/sec: 127.78 - lr: 0.000030
2021-07-23 07:57:39,928 epoch 3 - iter 945/1354 - loss 0.19049440 - samples/sec: 128.50 - lr: 0.000030
2021-07-23 07:58:13,132 epoch 3 - iter 1080/1354 - loss 0.18960679 - samples/sec: 130.13 - lr: 0.000030
2021-07-23 07:58:46,877 epoch 3 - iter 1215/1354 - loss 0.18798410 - samples/sec: 128.04 - lr: 0.000030
2021-07-23 07:59:20,371 epoch 3 - iter 1350/1354 - loss 0.18683154 - samples/sec: 129.00 - lr: 0.000030
2021-07-23 07:59:21,106 ----------------------------------------------------------------------------------------------------
2021-07-23 07:59:21,107 EPOCH 3 done: loss 0.1872 - lr 0.0000300
2021-07-23 07:59:35,329 DEV : loss 0.07555647939443588 - score 0.9801
2021-07-23 07:59:35,482 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 07:59:38,026 ----------------------------------------------------------------------------------------------------
2021-07-23 08:00:11,597 epoch 4 - iter 135/1354 - loss 0.16356407 - samples/sec: 128.73 - lr: 0.000030
2021-07-23 08:00:45,500 epoch 4 - iter 270/1354 - loss 0.16864136 - samples/sec: 127.45 - lr: 0.000030
2021-07-23 08:01:18,960 epoch 4 - iter 405/1354 - loss 0.16303391 - samples/sec: 129.13 - lr: 0.000030
2021-07-23 08:01:52,517 epoch 4 - iter 540/1354 - loss 0.16149656 - samples/sec: 128.77 - lr: 0.000030
2021-07-23 08:02:26,021 epoch 4 - iter 675/1354 - loss 0.16193657 - samples/sec: 128.96 - lr: 0.000030
2021-07-23 08:02:59,514 epoch 4 - iter 810/1354 - loss 0.16242729 - samples/sec: 129.01 - lr: 0.000030
2021-07-23 08:03:32,798 epoch 4 - iter 945/1354 - loss 0.15924253 - samples/sec: 129.82 - lr: 0.000030
2021-07-23 08:04:06,639 epoch 4 - iter 1080/1354 - loss 0.15807434 - samples/sec: 127.68 - lr: 0.000030
2021-07-23 08:04:40,212 epoch 4 - iter 1215/1354 - loss 0.15631077 - samples/sec: 128.70 - lr: 0.000030
2021-07-23 08:05:13,411 epoch 4 - iter 1350/1354 - loss 0.15419618 - samples/sec: 130.15 - lr: 0.000030
2021-07-23 08:05:14,270 ----------------------------------------------------------------------------------------------------
2021-07-23 08:05:14,270 EPOCH 4 done: loss 0.1543 - lr 0.0000300
2021-07-23 08:05:28,640 DEV : loss 0.06974106281995773 - score 0.9801
2021-07-23 08:05:28,795 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 08:05:31,293 ----------------------------------------------------------------------------------------------------
2021-07-23 08:06:05,120 epoch 5 - iter 135/1354 - loss 0.12861175 - samples/sec: 127.76 - lr: 0.000030
2021-07-23 08:06:38,743 epoch 5 - iter 270/1354 - loss 0.12545151 - samples/sec: 128.51 - lr: 0.000030
2021-07-23 08:07:12,115 epoch 5 - iter 405/1354 - loss 0.12070880 - samples/sec: 129.47 - lr: 0.000030
2021-07-23 08:07:46,149 epoch 5 - iter 540/1354 - loss 0.11793228 - samples/sec: 126.96 - lr: 0.000030
2021-07-23 08:08:19,992 epoch 5 - iter 675/1354 - loss 0.11609696 - samples/sec: 127.67 - lr: 0.000030
2021-07-23 08:08:53,682 epoch 5 - iter 810/1354 - loss 0.11471828 - samples/sec: 128.25 - lr: 0.000030
2021-07-23 08:09:27,208 epoch 5 - iter 945/1354 - loss 0.11480343 - samples/sec: 128.88 - lr: 0.000030
2021-07-23 08:10:00,697 epoch 5 - iter 1080/1354 - loss 0.11378576 - samples/sec: 129.02 - lr: 0.000030
2021-07-23 08:10:34,029 epoch 5 - iter 1215/1354 - loss 0.11259649 - samples/sec: 129.63 - lr: 0.000030
2021-07-23 08:11:09,019 epoch 5 - iter 1350/1354 - loss 0.11124387 - samples/sec: 123.49 - lr: 0.000030
2021-07-23 08:11:09,793 ----------------------------------------------------------------------------------------------------
2021-07-23 08:11:09,794 EPOCH 5 done: loss 0.1111 - lr 0.0000300
2021-07-23 08:11:24,263 DEV : loss 0.06751150637865067 - score 0.9806
2021-07-23 08:11:24,415 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 08:11:27,050 ----------------------------------------------------------------------------------------------------
2021-07-23 08:12:01,005 epoch 6 - iter 135/1354 - loss 0.10623262 - samples/sec: 127.27 - lr: 0.000030
2021-07-23 08:12:34,570 epoch 6 - iter 270/1354 - loss 0.10413000 - samples/sec: 128.73 - lr: 0.000030
2021-07-23 08:13:08,549 epoch 6 - iter 405/1354 - loss 0.09901481 - samples/sec: 127.16 - lr: 0.000030
2021-07-23 08:13:41,628 epoch 6 - iter 540/1354 - loss 0.09968839 - samples/sec: 130.62 - lr: 0.000030
2021-07-23 08:14:15,357 epoch 6 - iter 675/1354 - loss 0.10014824 - samples/sec: 128.11 - lr: 0.000030
2021-07-23 08:14:48,968 epoch 6 - iter 810/1354 - loss 0.09903901 - samples/sec: 128.56 - lr: 0.000030
2021-07-23 08:15:22,646 epoch 6 - iter 945/1354 - loss 0.09821817 - samples/sec: 128.30 - lr: 0.000030
2021-07-23 08:15:56,273 epoch 6 - iter 1080/1354 - loss 0.09726218 - samples/sec: 128.49 - lr: 0.000030
2021-07-23 08:16:30,084 epoch 6 - iter 1215/1354 - loss 0.09681836 - samples/sec: 127.79 - lr: 0.000030
2021-07-23 08:17:03,576 epoch 6 - iter 1350/1354 - loss 0.09630027 - samples/sec: 129.01 - lr: 0.000030
2021-07-23 08:17:04,363 ----------------------------------------------------------------------------------------------------
2021-07-23 08:17:04,363 EPOCH 6 done: loss 0.0962 - lr 0.0000300
2021-07-23 08:17:18,697 DEV : loss 0.06985531747341156 - score 0.9818
2021-07-23 08:17:18,850 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 08:17:21,430 ----------------------------------------------------------------------------------------------------
2021-07-23 08:17:55,058 epoch 7 - iter 135/1354 - loss 0.09389350 - samples/sec: 128.51 - lr: 0.000030
2021-07-23 08:18:28,896 epoch 7 - iter 270/1354 - loss 0.08701297 - samples/sec: 127.69 - lr: 0.000030
2021-07-23 08:19:02,965 epoch 7 - iter 405/1354 - loss 0.09179687 - samples/sec: 126.83 - lr: 0.000030
2021-07-23 08:19:36,517 epoch 7 - iter 540/1354 - loss 0.09079705 - samples/sec: 128.78 - lr: 0.000030
2021-07-23 08:20:09,849 epoch 7 - iter 675/1354 - loss 0.09191259 - samples/sec: 129.63 - lr: 0.000030
2021-07-23 08:20:43,891 epoch 7 - iter 810/1354 - loss 0.09229369 - samples/sec: 126.93 - lr: 0.000030
2021-07-23 08:21:17,426 epoch 7 - iter 945/1354 - loss 0.09244588 - samples/sec: 128.85 - lr: 0.000030
2021-07-23 08:21:50,783 epoch 7 - iter 1080/1354 - loss 0.09204342 - samples/sec: 129.53 - lr: 0.000030
2021-07-23 08:22:24,610 epoch 7 - iter 1215/1354 - loss 0.09253541 - samples/sec: 127.74 - lr: 0.000030
2021-07-23 08:22:58,040 epoch 7 - iter 1350/1354 - loss 0.09176862 - samples/sec: 129.25 - lr: 0.000030
2021-07-23 08:22:58,916 ----------------------------------------------------------------------------------------------------
2021-07-23 08:22:58,916 EPOCH 7 done: loss 0.0916 - lr 0.0000300
2021-07-23 08:23:13,308 DEV : loss 0.06457426398992538 - score 0.9815
2021-07-23 08:23:13,463 BAD EPOCHS (no improvement): 1
2021-07-23 08:23:13,463 ----------------------------------------------------------------------------------------------------
2021-07-23 08:23:47,193 epoch 8 - iter 135/1354 - loss 0.08368032 - samples/sec: 128.11 - lr: 0.000030
2021-07-23 08:24:21,060 epoch 8 - iter 270/1354 - loss 0.09106525 - samples/sec: 127.58 - lr: 0.000030
2021-07-23 08:24:54,215 epoch 8 - iter 405/1354 - loss 0.09382953 - samples/sec: 130.32 - lr: 0.000030
2021-07-23 08:25:27,649 epoch 8 - iter 540/1354 - loss 0.09402416 - samples/sec: 129.23 - lr: 0.000030
2021-07-23 08:26:01,152 epoch 8 - iter 675/1354 - loss 0.09235943 - samples/sec: 128.97 - lr: 0.000030
2021-07-23 08:26:35,226 epoch 8 - iter 810/1354 - loss 0.09042983 - samples/sec: 126.81 - lr: 0.000030
2021-07-23 08:27:08,816 epoch 8 - iter 945/1354 - loss 0.09027160 - samples/sec: 128.63 - lr: 0.000030
2021-07-23 08:27:42,612 epoch 8 - iter 1080/1354 - loss 0.09030181 - samples/sec: 127.85 - lr: 0.000030
2021-07-23 08:28:16,600 epoch 8 - iter 1215/1354 - loss 0.09073053 - samples/sec: 127.13 - lr: 0.000030
2021-07-23 08:28:50,268 epoch 8 - iter 1350/1354 - loss 0.09039731 - samples/sec: 128.34 - lr: 0.000030
2021-07-23 08:28:51,063 ----------------------------------------------------------------------------------------------------
2021-07-23 08:28:51,063 EPOCH 8 done: loss 0.0902 - lr 0.0000300
2021-07-23 08:29:05,483 DEV : loss 0.06572016328573227 - score 0.9816
2021-07-23 08:29:05,638 BAD EPOCHS (no improvement): 2
2021-07-23 08:29:05,638 ----------------------------------------------------------------------------------------------------
2021-07-23 08:29:39,268 epoch 9 - iter 135/1354 - loss 0.09451894 - samples/sec: 128.49 - lr: 0.000030
2021-07-23 08:30:13,056 epoch 9 - iter 270/1354 - loss 0.09266150 - samples/sec: 127.88 - lr: 0.000030
2021-07-23 08:30:46,649 epoch 9 - iter 405/1354 - loss 0.09056718 - samples/sec: 128.63 - lr: 0.000030
2021-07-23 08:31:19,853 epoch 9 - iter 540/1354 - loss 0.08809632 - samples/sec: 130.13 - lr: 0.000030
2021-07-23 08:31:53,253 epoch 9 - iter 675/1354 - loss 0.08956988 - samples/sec: 129.37 - lr: 0.000030
2021-07-23 08:32:26,997 epoch 9 - iter 810/1354 - loss 0.08825172 - samples/sec: 128.05 - lr: 0.000030
2021-07-23 08:33:00,777 epoch 9 - iter 945/1354 - loss 0.08631042 - samples/sec: 127.91 - lr: 0.000030
2021-07-23 08:33:34,328 epoch 9 - iter 1080/1354 - loss 0.08641032 - samples/sec: 128.78 - lr: 0.000030
2021-07-23 08:34:08,405 epoch 9 - iter 1215/1354 - loss 0.08605794 - samples/sec: 126.80 - lr: 0.000030
2021-07-23 08:34:42,384 epoch 9 - iter 1350/1354 - loss 0.08694739 - samples/sec: 127.16 - lr: 0.000030
2021-07-23 08:34:43,255 ----------------------------------------------------------------------------------------------------
2021-07-23 08:34:43,255 EPOCH 9 done: loss 0.0868 - lr 0.0000300
2021-07-23 08:34:59,099 DEV : loss 0.06293772161006927 - score 0.9822
2021-07-23 08:34:59,257 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 08:35:01,763 ----------------------------------------------------------------------------------------------------
2021-07-23 08:35:35,324 epoch 10 - iter 135/1354 - loss 0.08268496 - samples/sec: 128.76 - lr: 0.000030
2021-07-23 08:36:09,169 epoch 10 - iter 270/1354 - loss 0.08586552 - samples/sec: 127.67 - lr: 0.000030
2021-07-23 08:36:42,679 epoch 10 - iter 405/1354 - loss 0.08271050 - samples/sec: 128.94 - lr: 0.000030
2021-07-23 08:37:16,361 epoch 10 - iter 540/1354 - loss 0.08423942 - samples/sec: 128.29 - lr: 0.000030
2021-07-23 08:37:49,980 epoch 10 - iter 675/1354 - loss 0.08664516 - samples/sec: 128.52 - lr: 0.000030
2021-07-23 08:38:24,264 epoch 10 - iter 810/1354 - loss 0.08689458 - samples/sec: 126.03 - lr: 0.000030
2021-07-23 08:38:58,111 epoch 10 - iter 945/1354 - loss 0.08579597 - samples/sec: 127.66 - lr: 0.000030
2021-07-23 08:39:31,264 epoch 10 - iter 1080/1354 - loss 0.08534227 - samples/sec: 130.33 - lr: 0.000030
2021-07-23 08:40:04,636 epoch 10 - iter 1215/1354 - loss 0.08500418 - samples/sec: 129.48 - lr: 0.000030
2021-07-23 08:40:37,765 epoch 10 - iter 1350/1354 - loss 0.08431329 - samples/sec: 130.43 - lr: 0.000030
2021-07-23 08:40:38,562 ----------------------------------------------------------------------------------------------------
2021-07-23 08:40:38,562 EPOCH 10 done: loss 0.0842 - lr 0.0000300
2021-07-23 08:40:52,978 DEV : loss 0.06381481885910034 - score 0.9819
2021-07-23 08:40:53,132 BAD EPOCHS (no improvement): 1
2021-07-23 08:40:53,132 ----------------------------------------------------------------------------------------------------
2021-07-23 08:41:26,761 epoch 11 - iter 135/1354 - loss 0.08227680 - samples/sec: 128.50 - lr: 0.000030
2021-07-23 08:42:00,284 epoch 11 - iter 270/1354 - loss 0.08297780 - samples/sec: 128.89 - lr: 0.000030
2021-07-23 08:42:33,357 epoch 11 - iter 405/1354 - loss 0.08064376 - samples/sec: 130.65 - lr: 0.000030
2021-07-23 08:43:06,860 epoch 11 - iter 540/1354 - loss 0.08014586 - samples/sec: 128.97 - lr: 0.000030
2021-07-23 08:43:40,268 epoch 11 - iter 675/1354 - loss 0.08103198 - samples/sec: 129.33 - lr: 0.000030
2021-07-23 08:44:13,235 epoch 11 - iter 810/1354 - loss 0.08075429 - samples/sec: 131.07 - lr: 0.000030
2021-07-23 08:44:46,631 epoch 11 - iter 945/1354 - loss 0.08201154 - samples/sec: 129.38 - lr: 0.000030
2021-07-23 08:45:19,920 epoch 11 - iter 1080/1354 - loss 0.08171037 - samples/sec: 129.80 - lr: 0.000030
2021-07-23 08:45:54,137 epoch 11 - iter 1215/1354 - loss 0.08180376 - samples/sec: 126.28 - lr: 0.000030
2021-07-23 08:46:28,249 epoch 11 - iter 1350/1354 - loss 0.08193580 - samples/sec: 126.66 - lr: 0.000030
2021-07-23 08:46:28,996 ----------------------------------------------------------------------------------------------------
2021-07-23 08:46:28,996 EPOCH 11 done: loss 0.0819 - lr 0.0000300
2021-07-23 08:46:43,476 DEV : loss 0.061743687838315964 - score 0.983
2021-07-23 08:46:43,632 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 08:46:46,243 ----------------------------------------------------------------------------------------------------
2021-07-23 08:47:19,818 epoch 12 - iter 135/1354 - loss 0.07952425 - samples/sec: 128.72 - lr: 0.000030
2021-07-23 08:47:53,372 epoch 12 - iter 270/1354 - loss 0.07783328 - samples/sec: 128.77 - lr: 0.000030
2021-07-23 08:48:27,438 epoch 12 - iter 405/1354 - loss 0.07460076 - samples/sec: 126.84 - lr: 0.000030
2021-07-23 08:49:00,464 epoch 12 - iter 540/1354 - loss 0.07557261 - samples/sec: 130.83 - lr: 0.000030
2021-07-23 08:49:34,072 epoch 12 - iter 675/1354 - loss 0.07418293 - samples/sec: 128.57 - lr: 0.000030
2021-07-23 08:50:07,316 epoch 12 - iter 810/1354 - loss 0.07545628 - samples/sec: 129.97 - lr: 0.000030
2021-07-23 08:50:41,013 epoch 12 - iter 945/1354 - loss 0.07497964 - samples/sec: 128.23 - lr: 0.000030
2021-07-23 08:51:14,224 epoch 12 - iter 1080/1354 - loss 0.07511857 - samples/sec: 130.10 - lr: 0.000030
2021-07-23 08:51:47,897 epoch 12 - iter 1215/1354 - loss 0.07623103 - samples/sec: 128.32 - lr: 0.000030
2021-07-23 08:52:21,800 epoch 12 - iter 1350/1354 - loss 0.07749890 - samples/sec: 127.45 - lr: 0.000030
2021-07-23 08:52:22,610 ----------------------------------------------------------------------------------------------------
2021-07-23 08:52:22,611 EPOCH 12 done: loss 0.0778 - lr 0.0000300
2021-07-23 08:52:37,086 DEV : loss 0.06128884106874466 - score 0.9828
2021-07-23 08:52:37,243 BAD EPOCHS (no improvement): 1
2021-07-23 08:52:37,244 ----------------------------------------------------------------------------------------------------
2021-07-23 08:53:10,584 epoch 13 - iter 135/1354 - loss 0.06816673 - samples/sec: 129.61 - lr: 0.000030
2021-07-23 08:53:44,284 epoch 13 - iter 270/1354 - loss 0.07369150 - samples/sec: 128.21 - lr: 0.000030
2021-07-23 08:54:17,933 epoch 13 - iter 405/1354 - loss 0.07571361 - samples/sec: 128.41 - lr: 0.000030
2021-07-23 08:54:51,223 epoch 13 - iter 540/1354 - loss 0.07569539 - samples/sec: 129.79 - lr: 0.000030
2021-07-23 08:55:24,773 epoch 13 - iter 675/1354 - loss 0.07573874 - samples/sec: 128.79 - lr: 0.000030
2021-07-23 08:55:58,589 epoch 13 - iter 810/1354 - loss 0.07544490 - samples/sec: 127.77 - lr: 0.000030
2021-07-23 08:56:32,180 epoch 13 - iter 945/1354 - loss 0.07575818 - samples/sec: 128.63 - lr: 0.000030
2021-07-23 08:57:05,926 epoch 13 - iter 1080/1354 - loss 0.07598832 - samples/sec: 128.04 - lr: 0.000030
2021-07-23 08:57:39,503 epoch 13 - iter 1215/1354 - loss 0.07682550 - samples/sec: 128.68 - lr: 0.000030
2021-07-23 08:58:13,172 epoch 13 - iter 1350/1354 - loss 0.07690812 - samples/sec: 128.33 - lr: 0.000030
2021-07-23 08:58:13,969 ----------------------------------------------------------------------------------------------------
2021-07-23 08:58:13,969 EPOCH 13 done: loss 0.0768 - lr 0.0000300
2021-07-23 08:58:28,378 DEV : loss 0.06843093037605286 - score 0.9801
2021-07-23 08:58:28,534 BAD EPOCHS (no improvement): 2
2021-07-23 08:58:28,534 ----------------------------------------------------------------------------------------------------
2021-07-23 08:59:02,836 epoch 14 - iter 135/1354 - loss 0.07259695 - samples/sec: 125.97 - lr: 0.000030
2021-07-23 08:59:36,411 epoch 14 - iter 270/1354 - loss 0.07689427 - samples/sec: 128.69 - lr: 0.000030
2021-07-23 09:00:10,336 epoch 14 - iter 405/1354 - loss 0.07265283 - samples/sec: 127.36 - lr: 0.000030
2021-07-23 09:00:44,062 epoch 14 - iter 540/1354 - loss 0.07166607 - samples/sec: 128.12 - lr: 0.000030
2021-07-23 09:01:17,468 epoch 14 - iter 675/1354 - loss 0.07229642 - samples/sec: 129.34 - lr: 0.000030
2021-07-23 09:01:51,661 epoch 14 - iter 810/1354 - loss 0.07344799 - samples/sec: 126.36 - lr: 0.000030
2021-07-23 09:02:25,100 epoch 14 - iter 945/1354 - loss 0.07334924 - samples/sec: 129.22 - lr: 0.000030
2021-07-23 09:02:58,997 epoch 14 - iter 1080/1354 - loss 0.07257538 - samples/sec: 127.47 - lr: 0.000030
2021-07-23 09:03:32,105 epoch 14 - iter 1215/1354 - loss 0.07276763 - samples/sec: 130.51 - lr: 0.000030
2021-07-23 09:04:05,922 epoch 14 - iter 1350/1354 - loss 0.07322745 - samples/sec: 127.77 - lr: 0.000030
2021-07-23 09:04:06,799 ----------------------------------------------------------------------------------------------------
2021-07-23 09:04:06,799 EPOCH 14 done: loss 0.0732 - lr 0.0000300
2021-07-23 09:04:21,174 DEV : loss 0.06111082434654236 - score 0.9826
2021-07-23 09:04:21,329 BAD EPOCHS (no improvement): 3
2021-07-23 09:04:21,329 ----------------------------------------------------------------------------------------------------
2021-07-23 09:04:54,791 epoch 15 - iter 135/1354 - loss 0.07561083 - samples/sec: 129.14 - lr: 0.000030
2021-07-23 09:05:28,887 epoch 15 - iter 270/1354 - loss 0.07646490 - samples/sec: 126.73 - lr: 0.000030
2021-07-23 09:06:02,508 epoch 15 - iter 405/1354 - loss 0.07723620 - samples/sec: 128.52 - lr: 0.000030
2021-07-23 09:06:35,709 epoch 15 - iter 540/1354 - loss 0.07509628 - samples/sec: 130.14 - lr: 0.000030
2021-07-23 09:07:09,772 epoch 15 - iter 675/1354 - loss 0.07453830 - samples/sec: 126.85 - lr: 0.000030
2021-07-23 09:07:43,260 epoch 15 - iter 810/1354 - loss 0.07247313 - samples/sec: 129.03 - lr: 0.000030
2021-07-23 09:08:16,904 epoch 15 - iter 945/1354 - loss 0.07181110 - samples/sec: 128.43 - lr: 0.000030
2021-07-23 09:08:50,589 epoch 15 - iter 1080/1354 - loss 0.07300592 - samples/sec: 128.27 - lr: 0.000030
2021-07-23 09:09:24,224 epoch 15 - iter 1215/1354 - loss 0.07245233 - samples/sec: 128.46 - lr: 0.000030
2021-07-23 09:09:57,893 epoch 15 - iter 1350/1354 - loss 0.07291905 - samples/sec: 128.33 - lr: 0.000030
2021-07-23 09:09:58,752 ----------------------------------------------------------------------------------------------------
2021-07-23 09:09:58,752 EPOCH 15 done: loss 0.0729 - lr 0.0000300
2021-07-23 09:10:13,200 DEV : loss 0.059521447867155075 - score 0.9834
2021-07-23 09:10:13,355 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:10:15,983 ----------------------------------------------------------------------------------------------------
2021-07-23 09:10:50,020 epoch 16 - iter 135/1354 - loss 0.06622507 - samples/sec: 126.96 - lr: 0.000030
2021-07-23 09:11:23,912 epoch 16 - iter 270/1354 - loss 0.06922219 - samples/sec: 127.49 - lr: 0.000030
2021-07-23 09:11:57,400 epoch 16 - iter 405/1354 - loss 0.06915510 - samples/sec: 129.03 - lr: 0.000030
2021-07-23 09:12:31,389 epoch 16 - iter 540/1354 - loss 0.06904221 - samples/sec: 127.13 - lr: 0.000030
2021-07-23 09:13:04,974 epoch 16 - iter 675/1354 - loss 0.06953295 - samples/sec: 128.65 - lr: 0.000030
2021-07-23 09:13:38,304 epoch 16 - iter 810/1354 - loss 0.06957643 - samples/sec: 129.64 - lr: 0.000030
2021-07-23 09:14:12,025 epoch 16 - iter 945/1354 - loss 0.06922829 - samples/sec: 128.14 - lr: 0.000030
2021-07-23 09:14:45,285 epoch 16 - iter 1080/1354 - loss 0.06935498 - samples/sec: 129.91 - lr: 0.000030
2021-07-23 09:15:18,315 epoch 16 - iter 1215/1354 - loss 0.06981052 - samples/sec: 130.82 - lr: 0.000030
2021-07-23 09:15:51,869 epoch 16 - iter 1350/1354 - loss 0.07014473 - samples/sec: 128.77 - lr: 0.000030
2021-07-23 09:15:52,663 ----------------------------------------------------------------------------------------------------
2021-07-23 09:15:52,663 EPOCH 16 done: loss 0.0701 - lr 0.0000300
2021-07-23 09:16:07,131 DEV : loss 0.0622381754219532 - score 0.9824
2021-07-23 09:16:07,288 BAD EPOCHS (no improvement): 1
2021-07-23 09:16:07,288 ----------------------------------------------------------------------------------------------------
2021-07-23 09:16:40,312 epoch 17 - iter 135/1354 - loss 0.07106574 - samples/sec: 130.85 - lr: 0.000030
2021-07-23 09:17:13,649 epoch 17 - iter 270/1354 - loss 0.07321809 - samples/sec: 129.61 - lr: 0.000030
2021-07-23 09:17:47,259 epoch 17 - iter 405/1354 - loss 0.07238560 - samples/sec: 128.56 - lr: 0.000030
2021-07-23 09:18:20,674 epoch 17 - iter 540/1354 - loss 0.07062976 - samples/sec: 129.31 - lr: 0.000030
2021-07-23 09:18:54,865 epoch 17 - iter 675/1354 - loss 0.07169194 - samples/sec: 126.38 - lr: 0.000030
2021-07-23 09:19:29,046 epoch 17 - iter 810/1354 - loss 0.07120316 - samples/sec: 126.41 - lr: 0.000030
2021-07-23 09:20:02,520 epoch 17 - iter 945/1354 - loss 0.07056541 - samples/sec: 129.08 - lr: 0.000030
2021-07-23 09:20:35,872 epoch 17 - iter 1080/1354 - loss 0.06971564 - samples/sec: 129.55 - lr: 0.000030
2021-07-23 09:21:09,580 epoch 17 - iter 1215/1354 - loss 0.06874669 - samples/sec: 128.19 - lr: 0.000030
2021-07-23 09:21:43,241 epoch 17 - iter 1350/1354 - loss 0.06893658 - samples/sec: 128.36 - lr: 0.000030
2021-07-23 09:21:44,014 ----------------------------------------------------------------------------------------------------
2021-07-23 09:21:44,014 EPOCH 17 done: loss 0.0688 - lr 0.0000300
2021-07-23 09:21:58,564 DEV : loss 0.059541232883930206 - score 0.9828
2021-07-23 09:21:58,721 BAD EPOCHS (no improvement): 2
2021-07-23 09:21:58,721 ----------------------------------------------------------------------------------------------------
2021-07-23 09:22:32,520 epoch 18 - iter 135/1354 - loss 0.06837589 - samples/sec: 127.85 - lr: 0.000030
2021-07-23 09:23:06,000 epoch 18 - iter 270/1354 - loss 0.06798422 - samples/sec: 129.06 - lr: 0.000030
2021-07-23 09:23:39,858 epoch 18 - iter 405/1354 - loss 0.06863408 - samples/sec: 127.62 - lr: 0.000030
2021-07-23 09:24:13,587 epoch 18 - iter 540/1354 - loss 0.06688040 - samples/sec: 128.10 - lr: 0.000030
2021-07-23 09:24:46,885 epoch 18 - iter 675/1354 - loss 0.06637253 - samples/sec: 129.76 - lr: 0.000030
2021-07-23 09:25:20,152 epoch 18 - iter 810/1354 - loss 0.06723288 - samples/sec: 129.89 - lr: 0.000030
2021-07-23 09:25:53,693 epoch 18 - iter 945/1354 - loss 0.06768672 - samples/sec: 128.82 - lr: 0.000030
2021-07-23 09:26:27,022 epoch 18 - iter 1080/1354 - loss 0.06668706 - samples/sec: 129.64 - lr: 0.000030
2021-07-23 09:27:00,763 epoch 18 - iter 1215/1354 - loss 0.06639202 - samples/sec: 128.06 - lr: 0.000030
2021-07-23 09:27:34,175 epoch 18 - iter 1350/1354 - loss 0.06657943 - samples/sec: 129.32 - lr: 0.000030
2021-07-23 09:27:34,934 ----------------------------------------------------------------------------------------------------
2021-07-23 09:27:34,934 EPOCH 18 done: loss 0.0668 - lr 0.0000300
2021-07-23 09:27:50,797 DEV : loss 0.0621073879301548 - score 0.9821
2021-07-23 09:27:50,954 BAD EPOCHS (no improvement): 3
2021-07-23 09:27:50,954 ----------------------------------------------------------------------------------------------------
2021-07-23 09:28:24,761 epoch 19 - iter 135/1354 - loss 0.06341257 - samples/sec: 127.82 - lr: 0.000030
2021-07-23 09:28:57,805 epoch 19 - iter 270/1354 - loss 0.05944917 - samples/sec: 130.76 - lr: 0.000030
2021-07-23 09:29:31,226 epoch 19 - iter 405/1354 - loss 0.06331272 - samples/sec: 129.29 - lr: 0.000030
2021-07-23 09:30:04,749 epoch 19 - iter 540/1354 - loss 0.06147780 - samples/sec: 128.89 - lr: 0.000030
2021-07-23 09:30:38,660 epoch 19 - iter 675/1354 - loss 0.06332170 - samples/sec: 127.42 - lr: 0.000030
2021-07-23 09:31:12,376 epoch 19 - iter 810/1354 - loss 0.06423481 - samples/sec: 128.15 - lr: 0.000030
2021-07-23 09:31:45,995 epoch 19 - iter 945/1354 - loss 0.06466530 - samples/sec: 128.52 - lr: 0.000030
2021-07-23 09:32:19,493 epoch 19 - iter 1080/1354 - loss 0.06564998 - samples/sec: 128.99 - lr: 0.000030
2021-07-23 09:32:52,901 epoch 19 - iter 1215/1354 - loss 0.06603353 - samples/sec: 129.33 - lr: 0.000030
2021-07-23 09:33:26,872 epoch 19 - iter 1350/1354 - loss 0.06590256 - samples/sec: 127.19 - lr: 0.000030
2021-07-23 09:33:27,682 ----------------------------------------------------------------------------------------------------
2021-07-23 09:33:27,682 EPOCH 19 done: loss 0.0658 - lr 0.0000300
2021-07-23 09:33:42,194 DEV : loss 0.05985623598098755 - score 0.9837
2021-07-23 09:33:42,350 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:33:45,249 ----------------------------------------------------------------------------------------------------
2021-07-23 09:34:18,789 epoch 20 - iter 135/1354 - loss 0.06885319 - samples/sec: 128.85 - lr: 0.000030
2021-07-23 09:34:52,649 epoch 20 - iter 270/1354 - loss 0.06720064 - samples/sec: 127.61 - lr: 0.000030
2021-07-23 09:35:26,368 epoch 20 - iter 405/1354 - loss 0.06302030 - samples/sec: 128.14 - lr: 0.000030
2021-07-23 09:35:59,889 epoch 20 - iter 540/1354 - loss 0.06179326 - samples/sec: 128.90 - lr: 0.000030
2021-07-23 09:36:33,338 epoch 20 - iter 675/1354 - loss 0.06292812 - samples/sec: 129.18 - lr: 0.000030
2021-07-23 09:37:06,954 epoch 20 - iter 810/1354 - loss 0.06418440 - samples/sec: 128.53 - lr: 0.000030
2021-07-23 09:37:40,468 epoch 20 - iter 945/1354 - loss 0.06274107 - samples/sec: 128.93 - lr: 0.000030
2021-07-23 09:38:14,449 epoch 20 - iter 1080/1354 - loss 0.06349431 - samples/sec: 127.16 - lr: 0.000030
2021-07-23 09:38:48,017 epoch 20 - iter 1215/1354 - loss 0.06440126 - samples/sec: 128.72 - lr: 0.000030
2021-07-23 09:39:21,468 epoch 20 - iter 1350/1354 - loss 0.06360333 - samples/sec: 129.17 - lr: 0.000030
2021-07-23 09:39:22,243 ----------------------------------------------------------------------------------------------------
2021-07-23 09:39:22,243 EPOCH 20 done: loss 0.0638 - lr 0.0000300
2021-07-23 09:39:36,775 DEV : loss 0.05888563022017479 - score 0.984
2021-07-23 09:39:36,930 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:39:39,479 ----------------------------------------------------------------------------------------------------
2021-07-23 09:40:13,424 epoch 21 - iter 135/1354 - loss 0.06051300 - samples/sec: 127.30 - lr: 0.000030
2021-07-23 09:40:47,211 epoch 21 - iter 270/1354 - loss 0.06348693 - samples/sec: 127.89 - lr: 0.000030
2021-07-23 09:41:21,000 epoch 21 - iter 405/1354 - loss 0.06482512 - samples/sec: 127.88 - lr: 0.000030
2021-07-23 09:41:54,423 epoch 21 - iter 540/1354 - loss 0.06330137 - samples/sec: 129.28 - lr: 0.000030
2021-07-23 09:42:27,951 epoch 21 - iter 675/1354 - loss 0.06223909 - samples/sec: 128.87 - lr: 0.000030
2021-07-23 09:43:01,849 epoch 21 - iter 810/1354 - loss 0.06199101 - samples/sec: 127.46 - lr: 0.000030
2021-07-23 09:43:35,455 epoch 21 - iter 945/1354 - loss 0.06178348 - samples/sec: 128.57 - lr: 0.000030
2021-07-23 09:44:09,268 epoch 21 - iter 1080/1354 - loss 0.06263674 - samples/sec: 127.79 - lr: 0.000030
2021-07-23 09:44:42,930 epoch 21 - iter 1215/1354 - loss 0.06271733 - samples/sec: 128.36 - lr: 0.000030
2021-07-23 09:45:16,813 epoch 21 - iter 1350/1354 - loss 0.06256754 - samples/sec: 127.52 - lr: 0.000030
2021-07-23 09:45:17,573 ----------------------------------------------------------------------------------------------------
2021-07-23 09:45:17,573 EPOCH 21 done: loss 0.0624 - lr 0.0000300
2021-07-23 09:45:32,144 DEV : loss 0.05836407095193863 - score 0.986
2021-07-23 09:45:32,301 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:45:35,005 ----------------------------------------------------------------------------------------------------
2021-07-23 09:46:08,625 epoch 22 - iter 135/1354 - loss 0.06060035 - samples/sec: 128.54 - lr: 0.000030
2021-07-23 09:46:41,792 epoch 22 - iter 270/1354 - loss 0.05922443 - samples/sec: 130.28 - lr: 0.000030
2021-07-23 09:47:15,052 epoch 22 - iter 405/1354 - loss 0.05782615 - samples/sec: 129.91 - lr: 0.000030
2021-07-23 09:47:48,800 epoch 22 - iter 540/1354 - loss 0.05808958 - samples/sec: 128.03 - lr: 0.000030
2021-07-23 09:48:22,367 epoch 22 - iter 675/1354 - loss 0.06134374 - samples/sec: 128.72 - lr: 0.000030
2021-07-23 09:48:56,194 epoch 22 - iter 810/1354 - loss 0.06064875 - samples/sec: 127.74 - lr: 0.000030
2021-07-23 09:49:29,976 epoch 22 - iter 945/1354 - loss 0.06187780 - samples/sec: 127.90 - lr: 0.000030
2021-07-23 09:50:03,951 epoch 22 - iter 1080/1354 - loss 0.06186807 - samples/sec: 127.18 - lr: 0.000030
2021-07-23 09:50:37,601 epoch 22 - iter 1215/1354 - loss 0.06157627 - samples/sec: 128.40 - lr: 0.000030
2021-07-23 09:51:11,217 epoch 22 - iter 1350/1354 - loss 0.06206525 - samples/sec: 128.54 - lr: 0.000030
2021-07-23 09:51:11,995 ----------------------------------------------------------------------------------------------------
2021-07-23 09:51:11,996 EPOCH 22 done: loss 0.0621 - lr 0.0000300
2021-07-23 09:51:27,851 DEV : loss 0.05812486261129379 - score 0.9839
2021-07-23 09:51:28,008 BAD EPOCHS (no improvement): 1
2021-07-23 09:51:28,008 ----------------------------------------------------------------------------------------------------
2021-07-23 09:52:01,656 epoch 23 - iter 135/1354 - loss 0.05226181 - samples/sec: 128.43 - lr: 0.000030
2021-07-23 09:52:35,665 epoch 23 - iter 270/1354 - loss 0.05869677 - samples/sec: 127.05 - lr: 0.000030
2021-07-23 09:53:09,285 epoch 23 - iter 405/1354 - loss 0.06107668 - samples/sec: 128.52 - lr: 0.000030
2021-07-23 09:53:43,261 epoch 23 - iter 540/1354 - loss 0.05983731 - samples/sec: 127.17 - lr: 0.000030
2021-07-23 09:54:16,915 epoch 23 - iter 675/1354 - loss 0.06055133 - samples/sec: 128.39 - lr: 0.000030
2021-07-23 09:54:50,785 epoch 23 - iter 810/1354 - loss 0.06075065 - samples/sec: 127.57 - lr: 0.000030
2021-07-23 09:55:24,197 epoch 23 - iter 945/1354 - loss 0.06047805 - samples/sec: 129.32 - lr: 0.000030
2021-07-23 09:55:57,883 epoch 23 - iter 1080/1354 - loss 0.06049974 - samples/sec: 128.27 - lr: 0.000030
2021-07-23 09:56:31,396 epoch 23 - iter 1215/1354 - loss 0.06069479 - samples/sec: 128.93 - lr: 0.000030
2021-07-23 09:57:04,479 epoch 23 - iter 1350/1354 - loss 0.06156283 - samples/sec: 130.61 - lr: 0.000030
2021-07-23 09:57:05,396 ----------------------------------------------------------------------------------------------------
2021-07-23 09:57:05,396 EPOCH 23 done: loss 0.0615 - lr 0.0000300
2021-07-23 09:57:19,922 DEV : loss 0.056471798568964005 - score 0.9851
2021-07-23 09:57:20,078 BAD EPOCHS (no improvement): 2
2021-07-23 09:57:20,079 ----------------------------------------------------------------------------------------------------
2021-07-23 09:57:53,516 epoch 24 - iter 135/1354 - loss 0.05479418 - samples/sec: 129.24 - lr: 0.000030
2021-07-23 09:58:27,473 epoch 24 - iter 270/1354 - loss 0.05548885 - samples/sec: 127.24 - lr: 0.000030
2021-07-23 09:59:01,046 epoch 24 - iter 405/1354 - loss 0.05497788 - samples/sec: 128.70 - lr: 0.000030
2021-07-23 09:59:35,028 epoch 24 - iter 540/1354 - loss 0.05679278 - samples/sec: 127.15 - lr: 0.000030
2021-07-23 10:00:08,859 epoch 24 - iter 675/1354 - loss 0.05808627 - samples/sec: 127.72 - lr: 0.000030
2021-07-23 10:00:42,336 epoch 24 - iter 810/1354 - loss 0.05773409 - samples/sec: 129.07 - lr: 0.000030
2021-07-23 10:01:16,049 epoch 24 - iter 945/1354 - loss 0.05768909 - samples/sec: 128.16 - lr: 0.000030
2021-07-23 10:01:49,798 epoch 24 - iter 1080/1354 - loss 0.05708756 - samples/sec: 128.03 - lr: 0.000030
2021-07-23 10:02:23,081 epoch 24 - iter 1215/1354 - loss 0.05723453 - samples/sec: 129.82 - lr: 0.000030
2021-07-23 10:02:56,842 epoch 24 - iter 1350/1354 - loss 0.05746661 - samples/sec: 127.98 - lr: 0.000030
2021-07-23 10:02:57,686 ----------------------------------------------------------------------------------------------------
2021-07-23 10:02:57,686 EPOCH 24 done: loss 0.0575 - lr 0.0000300
2021-07-23 10:03:12,219 DEV : loss 0.06185160577297211 - score 0.9825
2021-07-23 10:03:12,374 BAD EPOCHS (no improvement): 3
2021-07-23 10:03:12,374 ----------------------------------------------------------------------------------------------------
2021-07-23 10:03:45,725 epoch 25 - iter 135/1354 - loss 0.05104880 - samples/sec: 129.57 - lr: 0.000030
2021-07-23 10:04:19,507 epoch 25 - iter 270/1354 - loss 0.05388989 - samples/sec: 127.90 - lr: 0.000030
2021-07-23 10:04:53,256 epoch 25 - iter 405/1354 - loss 0.05485472 - samples/sec: 128.03 - lr: 0.000030
2021-07-23 10:05:26,467 epoch 25 - iter 540/1354 - loss 0.05431799 - samples/sec: 130.10 - lr: 0.000030
2021-07-23 10:06:00,108 epoch 25 - iter 675/1354 - loss 0.05403115 - samples/sec: 128.44 - lr: 0.000030
2021-07-23 10:06:33,681 epoch 25 - iter 810/1354 - loss 0.05388525 - samples/sec: 128.70 - lr: 0.000030
2021-07-23 10:07:07,701 epoch 25 - iter 945/1354 - loss 0.05519206 - samples/sec: 127.01 - lr: 0.000030
2021-07-23 10:07:41,285 epoch 25 - iter 1080/1354 - loss 0.05688638 - samples/sec: 128.66 - lr: 0.000030
2021-07-23 10:08:14,745 epoch 25 - iter 1215/1354 - loss 0.05864190 - samples/sec: 129.13 - lr: 0.000030
2021-07-23 10:08:48,473 epoch 25 - iter 1350/1354 - loss 0.05891256 - samples/sec: 128.11 - lr: 0.000030
2021-07-23 10:08:49,311 ----------------------------------------------------------------------------------------------------
2021-07-23 10:08:49,311 EPOCH 25 done: loss 0.0589 - lr 0.0000300
2021-07-23 10:09:03,798 DEV : loss 0.05718393251299858 - score 0.985
Epoch    25: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 10:09:03,955 BAD EPOCHS (no improvement): 4
2021-07-23 10:09:03,955 ----------------------------------------------------------------------------------------------------
2021-07-23 10:09:37,616 epoch 26 - iter 135/1354 - loss 0.06190547 - samples/sec: 128.38 - lr: 0.000015
2021-07-23 10:10:11,624 epoch 26 - iter 270/1354 - loss 0.05737736 - samples/sec: 127.05 - lr: 0.000015
2021-07-23 10:10:44,874 epoch 26 - iter 405/1354 - loss 0.05456729 - samples/sec: 129.95 - lr: 0.000015
2021-07-23 10:11:18,370 epoch 26 - iter 540/1354 - loss 0.05465841 - samples/sec: 128.99 - lr: 0.000015
2021-07-23 10:11:51,777 epoch 26 - iter 675/1354 - loss 0.05426877 - samples/sec: 129.34 - lr: 0.000015
2021-07-23 10:12:25,105 epoch 26 - iter 810/1354 - loss 0.05340262 - samples/sec: 129.65 - lr: 0.000015
2021-07-23 10:12:58,647 epoch 26 - iter 945/1354 - loss 0.05388439 - samples/sec: 128.82 - lr: 0.000015
2021-07-23 10:13:31,831 epoch 26 - iter 1080/1354 - loss 0.05473900 - samples/sec: 130.21 - lr: 0.000015
2021-07-23 10:14:05,538 epoch 26 - iter 1215/1354 - loss 0.05488487 - samples/sec: 128.19 - lr: 0.000015
2021-07-23 10:14:38,736 epoch 26 - iter 1350/1354 - loss 0.05466998 - samples/sec: 130.15 - lr: 0.000015
2021-07-23 10:14:39,590 ----------------------------------------------------------------------------------------------------
2021-07-23 10:14:39,590 EPOCH 26 done: loss 0.0546 - lr 0.0000150
2021-07-23 10:14:54,165 DEV : loss 0.0584595613181591 - score 0.9832
2021-07-23 10:14:54,321 BAD EPOCHS (no improvement): 1
2021-07-23 10:14:54,322 ----------------------------------------------------------------------------------------------------
2021-07-23 10:15:27,976 epoch 27 - iter 135/1354 - loss 0.04752095 - samples/sec: 128.40 - lr: 0.000015
2021-07-23 10:16:01,616 epoch 27 - iter 270/1354 - loss 0.05155887 - samples/sec: 128.44 - lr: 0.000015
2021-07-23 10:16:35,301 epoch 27 - iter 405/1354 - loss 0.04995215 - samples/sec: 128.27 - lr: 0.000015
2021-07-23 10:17:08,613 epoch 27 - iter 540/1354 - loss 0.04989294 - samples/sec: 129.71 - lr: 0.000015
2021-07-23 10:17:43,503 epoch 27 - iter 675/1354 - loss 0.05132419 - samples/sec: 123.84 - lr: 0.000015
2021-07-23 10:18:16,408 epoch 27 - iter 810/1354 - loss 0.05177349 - samples/sec: 131.31 - lr: 0.000015
2021-07-23 10:18:49,720 epoch 27 - iter 945/1354 - loss 0.05197401 - samples/sec: 129.71 - lr: 0.000015
2021-07-23 10:19:23,413 epoch 27 - iter 1080/1354 - loss 0.05246867 - samples/sec: 128.24 - lr: 0.000015
2021-07-23 10:19:56,882 epoch 27 - iter 1215/1354 - loss 0.05250772 - samples/sec: 129.10 - lr: 0.000015
2021-07-23 10:20:30,541 epoch 27 - iter 1350/1354 - loss 0.05262125 - samples/sec: 128.37 - lr: 0.000015
2021-07-23 10:20:31,342 ----------------------------------------------------------------------------------------------------
2021-07-23 10:20:31,342 EPOCH 27 done: loss 0.0527 - lr 0.0000150
2021-07-23 10:20:45,900 DEV : loss 0.0595250129699707 - score 0.9842
2021-07-23 10:20:46,057 BAD EPOCHS (no improvement): 2
2021-07-23 10:20:46,057 ----------------------------------------------------------------------------------------------------
2021-07-23 10:21:19,589 epoch 28 - iter 135/1354 - loss 0.05376107 - samples/sec: 128.87 - lr: 0.000015
2021-07-23 10:21:53,404 epoch 28 - iter 270/1354 - loss 0.05273218 - samples/sec: 127.78 - lr: 0.000015
2021-07-23 10:22:26,421 epoch 28 - iter 405/1354 - loss 0.05440213 - samples/sec: 130.87 - lr: 0.000015
2021-07-23 10:23:00,124 epoch 28 - iter 540/1354 - loss 0.05380221 - samples/sec: 128.20 - lr: 0.000015
2021-07-23 10:23:33,998 epoch 28 - iter 675/1354 - loss 0.05376223 - samples/sec: 127.56 - lr: 0.000015
2021-07-23 10:24:07,475 epoch 28 - iter 810/1354 - loss 0.05366177 - samples/sec: 129.07 - lr: 0.000015
2021-07-23 10:24:41,133 epoch 28 - iter 945/1354 - loss 0.05392438 - samples/sec: 128.37 - lr: 0.000015
2021-07-23 10:25:15,084 epoch 28 - iter 1080/1354 - loss 0.05265924 - samples/sec: 127.27 - lr: 0.000015
2021-07-23 10:25:48,764 epoch 28 - iter 1215/1354 - loss 0.05256926 - samples/sec: 128.29 - lr: 0.000015
2021-07-23 10:26:22,584 epoch 28 - iter 1350/1354 - loss 0.05340793 - samples/sec: 127.76 - lr: 0.000015
2021-07-23 10:26:23,422 ----------------------------------------------------------------------------------------------------
2021-07-23 10:26:23,422 EPOCH 28 done: loss 0.0534 - lr 0.0000150
2021-07-23 10:26:37,970 DEV : loss 0.06214773654937744 - score 0.9823
2021-07-23 10:26:38,126 BAD EPOCHS (no improvement): 3
2021-07-23 10:26:38,126 ----------------------------------------------------------------------------------------------------
2021-07-23 10:27:11,588 epoch 29 - iter 135/1354 - loss 0.05087259 - samples/sec: 129.14 - lr: 0.000015
2021-07-23 10:27:45,338 epoch 29 - iter 270/1354 - loss 0.05395092 - samples/sec: 128.03 - lr: 0.000015
2021-07-23 10:28:18,588 epoch 29 - iter 405/1354 - loss 0.05343384 - samples/sec: 129.95 - lr: 0.000015
2021-07-23 10:28:52,092 epoch 29 - iter 540/1354 - loss 0.05186927 - samples/sec: 128.96 - lr: 0.000015
2021-07-23 10:29:25,988 epoch 29 - iter 675/1354 - loss 0.05119374 - samples/sec: 127.48 - lr: 0.000015
2021-07-23 10:29:59,813 epoch 29 - iter 810/1354 - loss 0.05023771 - samples/sec: 127.74 - lr: 0.000015
2021-07-23 10:30:33,329 epoch 29 - iter 945/1354 - loss 0.04993021 - samples/sec: 128.92 - lr: 0.000015
2021-07-23 10:31:06,828 epoch 29 - iter 1080/1354 - loss 0.05055853 - samples/sec: 128.98 - lr: 0.000015
2021-07-23 10:31:40,238 epoch 29 - iter 1215/1354 - loss 0.05053885 - samples/sec: 129.33 - lr: 0.000015
2021-07-23 10:32:13,877 epoch 29 - iter 1350/1354 - loss 0.05045423 - samples/sec: 128.45 - lr: 0.000015
2021-07-23 10:32:14,718 ----------------------------------------------------------------------------------------------------
2021-07-23 10:32:14,718 EPOCH 29 done: loss 0.0505 - lr 0.0000150
2021-07-23 10:32:29,253 DEV : loss 0.061029188334941864 - score 0.9839
Epoch    29: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 10:32:29,410 BAD EPOCHS (no improvement): 4
2021-07-23 10:32:29,410 ----------------------------------------------------------------------------------------------------
2021-07-23 10:33:02,888 epoch 30 - iter 135/1354 - loss 0.05497991 - samples/sec: 129.08 - lr: 0.000008
2021-07-23 10:33:36,888 epoch 30 - iter 270/1354 - loss 0.05191445 - samples/sec: 127.08 - lr: 0.000008
2021-07-23 10:34:09,952 epoch 30 - iter 405/1354 - loss 0.05354457 - samples/sec: 130.68 - lr: 0.000008
2021-07-23 10:34:43,734 epoch 30 - iter 540/1354 - loss 0.05391579 - samples/sec: 127.91 - lr: 0.000008
2021-07-23 10:35:17,605 epoch 30 - iter 675/1354 - loss 0.05285436 - samples/sec: 127.57 - lr: 0.000008
2021-07-23 10:35:51,240 epoch 30 - iter 810/1354 - loss 0.05057736 - samples/sec: 128.46 - lr: 0.000008
2021-07-23 10:36:24,736 epoch 30 - iter 945/1354 - loss 0.05157163 - samples/sec: 129.00 - lr: 0.000008
2021-07-23 10:36:58,421 epoch 30 - iter 1080/1354 - loss 0.05086572 - samples/sec: 128.27 - lr: 0.000008
2021-07-23 10:37:32,123 epoch 30 - iter 1215/1354 - loss 0.05083887 - samples/sec: 128.21 - lr: 0.000008
2021-07-23 10:38:05,997 epoch 30 - iter 1350/1354 - loss 0.05085144 - samples/sec: 127.56 - lr: 0.000008
2021-07-23 10:38:06,834 ----------------------------------------------------------------------------------------------------
2021-07-23 10:38:06,834 EPOCH 30 done: loss 0.0509 - lr 0.0000075
2021-07-23 10:38:21,367 DEV : loss 0.06038505956530571 - score 0.9845
2021-07-23 10:38:21,523 BAD EPOCHS (no improvement): 1
2021-07-23 10:38:21,524 ----------------------------------------------------------------------------------------------------
2021-07-23 10:38:55,237 epoch 31 - iter 135/1354 - loss 0.04926630 - samples/sec: 128.18 - lr: 0.000008
2021-07-23 10:39:28,554 epoch 31 - iter 270/1354 - loss 0.05230061 - samples/sec: 129.69 - lr: 0.000008
2021-07-23 10:40:02,050 epoch 31 - iter 405/1354 - loss 0.04922948 - samples/sec: 129.00 - lr: 0.000008
2021-07-23 10:40:35,582 epoch 31 - iter 540/1354 - loss 0.05177445 - samples/sec: 128.86 - lr: 0.000008
2021-07-23 10:41:09,372 epoch 31 - iter 675/1354 - loss 0.05174532 - samples/sec: 127.87 - lr: 0.000008
2021-07-23 10:41:43,184 epoch 31 - iter 810/1354 - loss 0.05218908 - samples/sec: 127.79 - lr: 0.000008
2021-07-23 10:42:17,344 epoch 31 - iter 945/1354 - loss 0.05044345 - samples/sec: 126.49 - lr: 0.000008
2021-07-23 10:42:50,687 epoch 31 - iter 1080/1354 - loss 0.05071538 - samples/sec: 129.59 - lr: 0.000008
2021-07-23 10:43:24,509 epoch 31 - iter 1215/1354 - loss 0.05000432 - samples/sec: 127.75 - lr: 0.000008
2021-07-23 10:43:58,416 epoch 31 - iter 1350/1354 - loss 0.04954576 - samples/sec: 127.43 - lr: 0.000008
2021-07-23 10:43:59,275 ----------------------------------------------------------------------------------------------------
2021-07-23 10:43:59,275 EPOCH 31 done: loss 0.0496 - lr 0.0000075
2021-07-23 10:44:15,153 DEV : loss 0.05985747650265694 - score 0.9843
2021-07-23 10:44:15,310 BAD EPOCHS (no improvement): 2
2021-07-23 10:44:15,310 ----------------------------------------------------------------------------------------------------
2021-07-23 10:44:48,591 epoch 32 - iter 135/1354 - loss 0.04591607 - samples/sec: 129.85 - lr: 0.000008
2021-07-23 10:45:22,269 epoch 32 - iter 270/1354 - loss 0.04519743 - samples/sec: 128.30 - lr: 0.000008
2021-07-23 10:45:55,860 epoch 32 - iter 405/1354 - loss 0.04879442 - samples/sec: 128.63 - lr: 0.000008
2021-07-23 10:46:29,905 epoch 32 - iter 540/1354 - loss 0.04997369 - samples/sec: 126.92 - lr: 0.000008
2021-07-23 10:47:03,522 epoch 32 - iter 675/1354 - loss 0.04915088 - samples/sec: 128.53 - lr: 0.000008
2021-07-23 10:47:37,260 epoch 32 - iter 810/1354 - loss 0.04846730 - samples/sec: 128.07 - lr: 0.000008
2021-07-23 10:48:10,956 epoch 32 - iter 945/1354 - loss 0.04865593 - samples/sec: 128.23 - lr: 0.000008
2021-07-23 10:48:44,277 epoch 32 - iter 1080/1354 - loss 0.04838004 - samples/sec: 129.67 - lr: 0.000008
2021-07-23 10:49:18,118 epoch 32 - iter 1215/1354 - loss 0.04800730 - samples/sec: 127.68 - lr: 0.000008
2021-07-23 10:49:51,507 epoch 32 - iter 1350/1354 - loss 0.04812017 - samples/sec: 129.41 - lr: 0.000008
2021-07-23 10:49:52,381 ----------------------------------------------------------------------------------------------------
2021-07-23 10:49:52,382 EPOCH 32 done: loss 0.0482 - lr 0.0000075
2021-07-23 10:50:06,887 DEV : loss 0.06008365377783775 - score 0.9847
2021-07-23 10:50:07,044 BAD EPOCHS (no improvement): 3
2021-07-23 10:50:07,044 ----------------------------------------------------------------------------------------------------
2021-07-23 10:50:40,749 epoch 33 - iter 135/1354 - loss 0.04573946 - samples/sec: 128.21 - lr: 0.000008
2021-07-23 10:51:14,225 epoch 33 - iter 270/1354 - loss 0.05030905 - samples/sec: 129.07 - lr: 0.000008
2021-07-23 10:51:47,961 epoch 33 - iter 405/1354 - loss 0.04827725 - samples/sec: 128.07 - lr: 0.000008
2021-07-23 10:52:21,561 epoch 33 - iter 540/1354 - loss 0.04852061 - samples/sec: 128.60 - lr: 0.000008
2021-07-23 10:52:55,413 epoch 33 - iter 675/1354 - loss 0.04845509 - samples/sec: 127.64 - lr: 0.000008
2021-07-23 10:53:28,973 epoch 33 - iter 810/1354 - loss 0.04814011 - samples/sec: 128.75 - lr: 0.000008
2021-07-23 10:54:02,558 epoch 33 - iter 945/1354 - loss 0.04786660 - samples/sec: 128.66 - lr: 0.000008
2021-07-23 10:54:36,180 epoch 33 - iter 1080/1354 - loss 0.04707285 - samples/sec: 128.51 - lr: 0.000008
2021-07-23 10:55:10,136 epoch 33 - iter 1215/1354 - loss 0.04758169 - samples/sec: 127.25 - lr: 0.000008
2021-07-23 10:55:43,527 epoch 33 - iter 1350/1354 - loss 0.04753139 - samples/sec: 129.40 - lr: 0.000008
2021-07-23 10:55:44,410 ----------------------------------------------------------------------------------------------------
2021-07-23 10:55:44,410 EPOCH 33 done: loss 0.0475 - lr 0.0000075
2021-07-23 10:55:58,978 DEV : loss 0.06022556498646736 - score 0.9848
Epoch    33: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 10:55:59,134 BAD EPOCHS (no improvement): 4
2021-07-23 10:55:59,135 ----------------------------------------------------------------------------------------------------
2021-07-23 10:56:32,273 epoch 34 - iter 135/1354 - loss 0.05016504 - samples/sec: 130.40 - lr: 0.000004
2021-07-23 10:57:05,886 epoch 34 - iter 270/1354 - loss 0.04750050 - samples/sec: 128.55 - lr: 0.000004
2021-07-23 10:57:39,840 epoch 34 - iter 405/1354 - loss 0.04775959 - samples/sec: 127.25 - lr: 0.000004
2021-07-23 10:58:13,272 epoch 34 - iter 540/1354 - loss 0.04794012 - samples/sec: 129.25 - lr: 0.000004
2021-07-23 10:58:46,868 epoch 34 - iter 675/1354 - loss 0.04856783 - samples/sec: 128.61 - lr: 0.000004
2021-07-23 10:59:20,684 epoch 34 - iter 810/1354 - loss 0.04790364 - samples/sec: 127.78 - lr: 0.000004
2021-07-23 10:59:54,473 epoch 34 - iter 945/1354 - loss 0.04737062 - samples/sec: 127.88 - lr: 0.000004
2021-07-23 11:00:28,106 epoch 34 - iter 1080/1354 - loss 0.04739451 - samples/sec: 128.47 - lr: 0.000004
2021-07-23 11:01:02,287 epoch 34 - iter 1215/1354 - loss 0.04679732 - samples/sec: 126.41 - lr: 0.000004
2021-07-23 11:01:36,059 epoch 34 - iter 1350/1354 - loss 0.04634574 - samples/sec: 127.94 - lr: 0.000004
2021-07-23 11:01:36,814 ----------------------------------------------------------------------------------------------------
2021-07-23 11:01:36,814 EPOCH 34 done: loss 0.0464 - lr 0.0000038
2021-07-23 11:01:51,381 DEV : loss 0.06016393378376961 - score 0.9845
2021-07-23 11:01:51,538 BAD EPOCHS (no improvement): 1
2021-07-23 11:01:51,538 ----------------------------------------------------------------------------------------------------
2021-07-23 11:02:25,261 epoch 35 - iter 135/1354 - loss 0.04369130 - samples/sec: 128.14 - lr: 0.000004
2021-07-23 11:02:58,945 epoch 35 - iter 270/1354 - loss 0.04529736 - samples/sec: 128.28 - lr: 0.000004
2021-07-23 11:03:32,342 epoch 35 - iter 405/1354 - loss 0.04619723 - samples/sec: 129.38 - lr: 0.000004
2021-07-23 11:04:06,161 epoch 35 - iter 540/1354 - loss 0.04659350 - samples/sec: 127.76 - lr: 0.000004
2021-07-23 11:04:39,912 epoch 35 - iter 675/1354 - loss 0.04774637 - samples/sec: 128.02 - lr: 0.000004
2021-07-23 11:05:14,139 epoch 35 - iter 810/1354 - loss 0.04788104 - samples/sec: 126.24 - lr: 0.000004
2021-07-23 11:05:47,422 epoch 35 - iter 945/1354 - loss 0.04765858 - samples/sec: 129.82 - lr: 0.000004
2021-07-23 11:06:20,840 epoch 35 - iter 1080/1354 - loss 0.04711419 - samples/sec: 129.30 - lr: 0.000004
2021-07-23 11:06:54,384 epoch 35 - iter 1215/1354 - loss 0.04710470 - samples/sec: 128.81 - lr: 0.000004
2021-07-23 11:07:28,271 epoch 35 - iter 1350/1354 - loss 0.04740071 - samples/sec: 127.51 - lr: 0.000004
2021-07-23 11:07:29,070 ----------------------------------------------------------------------------------------------------
2021-07-23 11:07:29,071 EPOCH 35 done: loss 0.0473 - lr 0.0000038
2021-07-23 11:07:44,976 DEV : loss 0.06046810373663902 - score 0.9848
2021-07-23 11:07:45,130 BAD EPOCHS (no improvement): 2
2021-07-23 11:07:45,130 ----------------------------------------------------------------------------------------------------
2021-07-23 11:08:18,402 epoch 36 - iter 135/1354 - loss 0.05009168 - samples/sec: 129.88 - lr: 0.000004
2021-07-23 11:08:52,001 epoch 36 - iter 270/1354 - loss 0.04868059 - samples/sec: 128.60 - lr: 0.000004
2021-07-23 11:09:25,281 epoch 36 - iter 405/1354 - loss 0.04894001 - samples/sec: 129.84 - lr: 0.000004
2021-07-23 11:09:59,688 epoch 36 - iter 540/1354 - loss 0.04827706 - samples/sec: 125.58 - lr: 0.000004
2021-07-23 11:10:33,367 epoch 36 - iter 675/1354 - loss 0.04831722 - samples/sec: 128.29 - lr: 0.000004
2021-07-23 11:11:07,017 epoch 36 - iter 810/1354 - loss 0.04820871 - samples/sec: 128.41 - lr: 0.000004
2021-07-23 11:11:40,997 epoch 36 - iter 945/1354 - loss 0.04860898 - samples/sec: 127.16 - lr: 0.000004
2021-07-23 11:12:14,674 epoch 36 - iter 1080/1354 - loss 0.04828138 - samples/sec: 128.30 - lr: 0.000004
2021-07-23 11:12:48,324 epoch 36 - iter 1215/1354 - loss 0.04779655 - samples/sec: 128.41 - lr: 0.000004
2021-07-23 11:13:21,678 epoch 36 - iter 1350/1354 - loss 0.04848025 - samples/sec: 129.55 - lr: 0.000004
2021-07-23 11:13:22,462 ----------------------------------------------------------------------------------------------------
2021-07-23 11:13:22,462 EPOCH 36 done: loss 0.0485 - lr 0.0000038
2021-07-23 11:13:37,030 DEV : loss 0.06030033156275749 - score 0.9844
2021-07-23 11:13:37,187 BAD EPOCHS (no improvement): 3
2021-07-23 11:13:37,188 ----------------------------------------------------------------------------------------------------
2021-07-23 11:14:10,566 epoch 37 - iter 135/1354 - loss 0.04359769 - samples/sec: 129.47 - lr: 0.000004
2021-07-23 11:14:44,081 epoch 37 - iter 270/1354 - loss 0.04766887 - samples/sec: 128.92 - lr: 0.000004
2021-07-23 11:15:17,820 epoch 37 - iter 405/1354 - loss 0.04815832 - samples/sec: 128.06 - lr: 0.000004
2021-07-23 11:15:51,305 epoch 37 - iter 540/1354 - loss 0.04804360 - samples/sec: 129.04 - lr: 0.000004
2021-07-23 11:16:24,916 epoch 37 - iter 675/1354 - loss 0.04752189 - samples/sec: 128.55 - lr: 0.000004
2021-07-23 11:16:58,641 epoch 37 - iter 810/1354 - loss 0.04896585 - samples/sec: 128.12 - lr: 0.000004
2021-07-23 11:17:32,049 epoch 37 - iter 945/1354 - loss 0.04740901 - samples/sec: 129.34 - lr: 0.000004
2021-07-23 11:18:06,047 epoch 37 - iter 1080/1354 - loss 0.04698569 - samples/sec: 127.09 - lr: 0.000004
2021-07-23 11:18:39,286 epoch 37 - iter 1215/1354 - loss 0.04682640 - samples/sec: 130.00 - lr: 0.000004
2021-07-23 11:19:13,260 epoch 37 - iter 1350/1354 - loss 0.04628418 - samples/sec: 127.18 - lr: 0.000004
2021-07-23 11:19:14,123 ----------------------------------------------------------------------------------------------------
2021-07-23 11:19:14,123 EPOCH 37 done: loss 0.0464 - lr 0.0000038
2021-07-23 11:19:28,678 DEV : loss 0.060874588787555695 - score 0.9849
Epoch    37: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 11:19:28,836 BAD EPOCHS (no improvement): 4
2021-07-23 11:19:28,836 ----------------------------------------------------------------------------------------------------
2021-07-23 11:19:28,836 ----------------------------------------------------------------------------------------------------
2021-07-23 11:19:28,836 learning rate too small - quitting training!
2021-07-23 11:19:28,836 ----------------------------------------------------------------------------------------------------
2021-07-23 11:19:29,504 ----------------------------------------------------------------------------------------------------
2021-07-23 11:19:29,504 Testing using best model ...
2021-07-23 11:19:29,505 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/rus.rst.rrt/best-model.pt
2021-07-23 11:22:16,902 0.9882	0.9946	0.9914
2021-07-23 11:22:16,902 
Results:
- F1-score (micro) 0.9914
- F1-score (macro) 0.9923

By class:
SENT       tp: 4648 - fp: 100 - fn: 46 - precision: 0.9789 - recall: 0.9902 - f1-score: 0.9845
X          tp: 3753 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 11:22:16,902 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.gum/
2021-07-23 11:22:16,951 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.gum
2021-07-23 11:22:16,952 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.gum/sent_train.txt
2021-07-23 11:22:16,953 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.gum/sent_dev.txt
2021-07-23 11:22:16,955 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.gum/sent_test.txt
Corpus: 12933 train + 2617 dev + 4074 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 11:22:25,531 ----------------------------------------------------------------------------------------------------
2021-07-23 11:22:25,533 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 11:22:25,533 ----------------------------------------------------------------------------------------------------
2021-07-23 11:22:25,533 Corpus: "Corpus: 12933 train + 2617 dev + 4074 test sentences"
2021-07-23 11:22:25,533 ----------------------------------------------------------------------------------------------------
2021-07-23 11:22:25,533 Parameters:
2021-07-23 11:22:25,533  - learning_rate: "3e-05"
2021-07-23 11:22:25,533  - mini_batch_size: "32"
2021-07-23 11:22:25,533  - patience: "3"
2021-07-23 11:22:25,534  - anneal_factor: "0.5"
2021-07-23 11:22:25,534  - max_epochs: "40"
2021-07-23 11:22:25,534  - shuffle: "True"
2021-07-23 11:22:25,534  - train_with_dev: "False"
2021-07-23 11:22:25,534  - batch_growth_annealing: "False"
2021-07-23 11:22:25,534 ----------------------------------------------------------------------------------------------------
2021-07-23 11:22:25,534 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.gum"
2021-07-23 11:22:25,534 ----------------------------------------------------------------------------------------------------
2021-07-23 11:22:25,534 Device: cuda:0
2021-07-23 11:22:25,534 ----------------------------------------------------------------------------------------------------
2021-07-23 11:22:25,534 Embeddings storage mode: cpu
2021-07-23 11:22:25,537 ----------------------------------------------------------------------------------------------------
2021-07-23 11:22:49,128 epoch 1 - iter 40/405 - loss 4.92804582 - samples/sec: 54.26 - lr: 0.000030
2021-07-23 11:23:10,752 epoch 1 - iter 80/405 - loss 3.64672614 - samples/sec: 59.20 - lr: 0.000030
2021-07-23 11:23:33,424 epoch 1 - iter 120/405 - loss 2.89645497 - samples/sec: 56.46 - lr: 0.000030
2021-07-23 11:23:56,621 epoch 1 - iter 160/405 - loss 2.39032263 - samples/sec: 55.18 - lr: 0.000030
2021-07-23 11:24:19,591 epoch 1 - iter 200/405 - loss 2.04695755 - samples/sec: 55.73 - lr: 0.000030
2021-07-23 11:24:43,370 epoch 1 - iter 240/405 - loss 1.79508618 - samples/sec: 53.83 - lr: 0.000030
2021-07-23 11:25:06,722 epoch 1 - iter 280/405 - loss 1.59635041 - samples/sec: 54.82 - lr: 0.000030
2021-07-23 11:25:30,044 epoch 1 - iter 320/405 - loss 1.44615149 - samples/sec: 54.89 - lr: 0.000030
2021-07-23 11:25:52,872 epoch 1 - iter 360/405 - loss 1.32298532 - samples/sec: 56.08 - lr: 0.000030
2021-07-23 11:26:15,871 epoch 1 - iter 400/405 - loss 1.21901109 - samples/sec: 55.66 - lr: 0.000030
2021-07-23 11:26:18,246 ----------------------------------------------------------------------------------------------------
2021-07-23 11:26:18,247 EPOCH 1 done: loss 1.2075 - lr 0.0000300
2021-07-23 11:26:52,560 DEV : loss 0.14020057022571564 - score 0.9805
2021-07-23 11:26:52,633 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:26:53,200 ----------------------------------------------------------------------------------------------------
2021-07-23 11:27:02,536 epoch 2 - iter 40/405 - loss 0.24944200 - samples/sec: 137.15 - lr: 0.000030
2021-07-23 11:27:11,812 epoch 2 - iter 80/405 - loss 0.22949658 - samples/sec: 138.04 - lr: 0.000030
2021-07-23 11:27:21,059 epoch 2 - iter 120/405 - loss 0.21905560 - samples/sec: 138.44 - lr: 0.000030
2021-07-23 11:27:30,234 epoch 2 - iter 160/405 - loss 0.21621697 - samples/sec: 139.55 - lr: 0.000030
2021-07-23 11:27:39,697 epoch 2 - iter 200/405 - loss 0.20624958 - samples/sec: 135.30 - lr: 0.000030
2021-07-23 11:27:48,943 epoch 2 - iter 240/405 - loss 0.20331988 - samples/sec: 138.46 - lr: 0.000030
2021-07-23 11:27:58,244 epoch 2 - iter 280/405 - loss 0.19851593 - samples/sec: 137.65 - lr: 0.000030
2021-07-23 11:28:07,488 epoch 2 - iter 320/405 - loss 0.19739155 - samples/sec: 138.51 - lr: 0.000030
2021-07-23 11:28:16,856 epoch 2 - iter 360/405 - loss 0.19472305 - samples/sec: 136.66 - lr: 0.000030
2021-07-23 11:28:26,160 epoch 2 - iter 400/405 - loss 0.19211188 - samples/sec: 137.60 - lr: 0.000030
2021-07-23 11:28:27,190 ----------------------------------------------------------------------------------------------------
2021-07-23 11:28:27,190 EPOCH 2 done: loss 0.1916 - lr 0.0000300
2021-07-23 11:28:33,366 DEV : loss 0.08315300941467285 - score 0.9838
2021-07-23 11:28:33,439 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:28:35,717 ----------------------------------------------------------------------------------------------------
2021-07-23 11:28:45,053 epoch 3 - iter 40/405 - loss 0.17244397 - samples/sec: 137.18 - lr: 0.000030
2021-07-23 11:28:54,173 epoch 3 - iter 80/405 - loss 0.17330227 - samples/sec: 140.38 - lr: 0.000030
2021-07-23 11:29:03,467 epoch 3 - iter 120/405 - loss 0.16632566 - samples/sec: 137.75 - lr: 0.000030
2021-07-23 11:29:12,919 epoch 3 - iter 160/405 - loss 0.16281185 - samples/sec: 135.45 - lr: 0.000030
2021-07-23 11:29:22,100 epoch 3 - iter 200/405 - loss 0.15893704 - samples/sec: 139.46 - lr: 0.000030
2021-07-23 11:29:31,316 epoch 3 - iter 240/405 - loss 0.15701100 - samples/sec: 138.91 - lr: 0.000030
2021-07-23 11:29:40,736 epoch 3 - iter 280/405 - loss 0.15473777 - samples/sec: 135.92 - lr: 0.000030
2021-07-23 11:29:49,956 epoch 3 - iter 320/405 - loss 0.15390234 - samples/sec: 138.85 - lr: 0.000030
2021-07-23 11:29:59,275 epoch 3 - iter 360/405 - loss 0.15229825 - samples/sec: 137.39 - lr: 0.000030
2021-07-23 11:30:08,340 epoch 3 - iter 400/405 - loss 0.15219045 - samples/sec: 141.23 - lr: 0.000030
2021-07-23 11:30:09,318 ----------------------------------------------------------------------------------------------------
2021-07-23 11:30:09,318 EPOCH 3 done: loss 0.1519 - lr 0.0000300
2021-07-23 11:30:15,493 DEV : loss 0.07397245615720749 - score 0.9838
2021-07-23 11:30:15,565 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:30:17,902 ----------------------------------------------------------------------------------------------------
2021-07-23 11:30:27,109 epoch 4 - iter 40/405 - loss 0.13031293 - samples/sec: 139.08 - lr: 0.000030
2021-07-23 11:30:36,713 epoch 4 - iter 80/405 - loss 0.14113509 - samples/sec: 133.32 - lr: 0.000030
2021-07-23 11:30:45,977 epoch 4 - iter 120/405 - loss 0.13847802 - samples/sec: 138.20 - lr: 0.000030
2021-07-23 11:30:55,280 epoch 4 - iter 160/405 - loss 0.13846420 - samples/sec: 137.62 - lr: 0.000030
2021-07-23 11:31:04,683 epoch 4 - iter 200/405 - loss 0.13796476 - samples/sec: 136.16 - lr: 0.000030
2021-07-23 11:31:13,543 epoch 4 - iter 240/405 - loss 0.13582001 - samples/sec: 144.50 - lr: 0.000030
2021-07-23 11:31:22,988 epoch 4 - iter 280/405 - loss 0.13564796 - samples/sec: 135.55 - lr: 0.000030
2021-07-23 11:31:32,338 epoch 4 - iter 320/405 - loss 0.13589914 - samples/sec: 136.94 - lr: 0.000030
2021-07-23 11:31:42,485 epoch 4 - iter 360/405 - loss 0.13571075 - samples/sec: 126.17 - lr: 0.000030
2021-07-23 11:31:51,675 epoch 4 - iter 400/405 - loss 0.13785899 - samples/sec: 139.31 - lr: 0.000030
2021-07-23 11:31:52,689 ----------------------------------------------------------------------------------------------------
2021-07-23 11:31:52,689 EPOCH 4 done: loss 0.1383 - lr 0.0000300
2021-07-23 11:31:58,914 DEV : loss 0.07006222754716873 - score 0.9849
2021-07-23 11:31:58,987 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:32:01,077 ----------------------------------------------------------------------------------------------------
2021-07-23 11:32:10,547 epoch 5 - iter 40/405 - loss 0.11128495 - samples/sec: 135.22 - lr: 0.000030
2021-07-23 11:32:19,768 epoch 5 - iter 80/405 - loss 0.11990624 - samples/sec: 138.85 - lr: 0.000030
2021-07-23 11:32:29,183 epoch 5 - iter 120/405 - loss 0.12094984 - samples/sec: 135.99 - lr: 0.000030
2021-07-23 11:32:38,427 epoch 5 - iter 160/405 - loss 0.12570423 - samples/sec: 138.49 - lr: 0.000030
2021-07-23 11:32:47,836 epoch 5 - iter 200/405 - loss 0.12054173 - samples/sec: 136.08 - lr: 0.000030
2021-07-23 11:32:57,064 epoch 5 - iter 240/405 - loss 0.12219871 - samples/sec: 138.73 - lr: 0.000030
2021-07-23 11:33:06,347 epoch 5 - iter 280/405 - loss 0.12198257 - samples/sec: 137.92 - lr: 0.000030
2021-07-23 11:33:15,692 epoch 5 - iter 320/405 - loss 0.12274507 - samples/sec: 137.02 - lr: 0.000030
2021-07-23 11:33:24,907 epoch 5 - iter 360/405 - loss 0.12368685 - samples/sec: 138.93 - lr: 0.000030
2021-07-23 11:33:34,391 epoch 5 - iter 400/405 - loss 0.12228835 - samples/sec: 134.99 - lr: 0.000030
2021-07-23 11:33:35,455 ----------------------------------------------------------------------------------------------------
2021-07-23 11:33:35,455 EPOCH 5 done: loss 0.1219 - lr 0.0000300
2021-07-23 11:33:41,667 DEV : loss 0.06789664924144745 - score 0.9849
2021-07-23 11:33:41,739 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:33:43,891 ----------------------------------------------------------------------------------------------------
2021-07-23 11:33:53,372 epoch 6 - iter 40/405 - loss 0.13702743 - samples/sec: 135.06 - lr: 0.000030
2021-07-23 11:34:02,925 epoch 6 - iter 80/405 - loss 0.14442755 - samples/sec: 134.02 - lr: 0.000030
2021-07-23 11:34:12,254 epoch 6 - iter 120/405 - loss 0.13431241 - samples/sec: 137.24 - lr: 0.000030
2021-07-23 11:34:21,403 epoch 6 - iter 160/405 - loss 0.12551765 - samples/sec: 139.94 - lr: 0.000030
2021-07-23 11:34:30,709 epoch 6 - iter 200/405 - loss 0.12596337 - samples/sec: 137.57 - lr: 0.000030
2021-07-23 11:34:39,923 epoch 6 - iter 240/405 - loss 0.12219313 - samples/sec: 138.95 - lr: 0.000030
2021-07-23 11:34:49,107 epoch 6 - iter 280/405 - loss 0.12155634 - samples/sec: 139.41 - lr: 0.000030
2021-07-23 11:34:58,453 epoch 6 - iter 320/405 - loss 0.12420085 - samples/sec: 136.99 - lr: 0.000030
2021-07-23 11:35:07,795 epoch 6 - iter 360/405 - loss 0.12360954 - samples/sec: 137.04 - lr: 0.000030
2021-07-23 11:35:17,177 epoch 6 - iter 400/405 - loss 0.12247450 - samples/sec: 136.47 - lr: 0.000030
2021-07-23 11:35:18,194 ----------------------------------------------------------------------------------------------------
2021-07-23 11:35:18,195 EPOCH 6 done: loss 0.1229 - lr 0.0000300
2021-07-23 11:35:24,391 DEV : loss 0.06643024832010269 - score 0.9854
2021-07-23 11:35:24,464 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:35:26,746 ----------------------------------------------------------------------------------------------------
2021-07-23 11:35:36,119 epoch 7 - iter 40/405 - loss 0.11944401 - samples/sec: 136.63 - lr: 0.000030
2021-07-23 11:35:45,244 epoch 7 - iter 80/405 - loss 0.11530903 - samples/sec: 140.32 - lr: 0.000030
2021-07-23 11:35:54,663 epoch 7 - iter 120/405 - loss 0.12419101 - samples/sec: 135.92 - lr: 0.000030
2021-07-23 11:36:04,152 epoch 7 - iter 160/405 - loss 0.12668872 - samples/sec: 134.92 - lr: 0.000030
2021-07-23 11:36:13,381 epoch 7 - iter 200/405 - loss 0.12394545 - samples/sec: 138.72 - lr: 0.000030
2021-07-23 11:36:22,720 epoch 7 - iter 240/405 - loss 0.12197905 - samples/sec: 137.09 - lr: 0.000030
2021-07-23 11:36:32,007 epoch 7 - iter 280/405 - loss 0.12416446 - samples/sec: 137.87 - lr: 0.000030
2021-07-23 11:36:41,253 epoch 7 - iter 320/405 - loss 0.12266062 - samples/sec: 138.46 - lr: 0.000030
2021-07-23 11:36:50,560 epoch 7 - iter 360/405 - loss 0.12305497 - samples/sec: 137.57 - lr: 0.000030
2021-07-23 11:36:59,897 epoch 7 - iter 400/405 - loss 0.12279616 - samples/sec: 137.12 - lr: 0.000030
2021-07-23 11:37:00,982 ----------------------------------------------------------------------------------------------------
2021-07-23 11:37:00,982 EPOCH 7 done: loss 0.1226 - lr 0.0000300
2021-07-23 11:37:07,171 DEV : loss 0.0657704621553421 - score 0.9862
2021-07-23 11:37:07,243 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:37:09,478 ----------------------------------------------------------------------------------------------------
2021-07-23 11:37:18,744 epoch 8 - iter 40/405 - loss 0.11845126 - samples/sec: 138.20 - lr: 0.000030
2021-07-23 11:37:27,996 epoch 8 - iter 80/405 - loss 0.11455431 - samples/sec: 138.38 - lr: 0.000030
2021-07-23 11:37:37,955 epoch 8 - iter 120/405 - loss 0.11314533 - samples/sec: 128.56 - lr: 0.000030
2021-07-23 11:37:47,132 epoch 8 - iter 160/405 - loss 0.11779481 - samples/sec: 139.52 - lr: 0.000030
2021-07-23 11:37:56,640 epoch 8 - iter 200/405 - loss 0.11513651 - samples/sec: 134.64 - lr: 0.000030
2021-07-23 11:38:06,084 epoch 8 - iter 240/405 - loss 0.11373128 - samples/sec: 135.57 - lr: 0.000030
2021-07-23 11:38:15,165 epoch 8 - iter 280/405 - loss 0.11497457 - samples/sec: 140.98 - lr: 0.000030
2021-07-23 11:38:24,620 epoch 8 - iter 320/405 - loss 0.11621564 - samples/sec: 135.41 - lr: 0.000030
2021-07-23 11:38:33,927 epoch 8 - iter 360/405 - loss 0.11743814 - samples/sec: 137.56 - lr: 0.000030
2021-07-23 11:38:43,048 epoch 8 - iter 400/405 - loss 0.11623151 - samples/sec: 140.37 - lr: 0.000030
2021-07-23 11:38:44,082 ----------------------------------------------------------------------------------------------------
2021-07-23 11:38:44,082 EPOCH 8 done: loss 0.1157 - lr 0.0000300
2021-07-23 11:38:50,264 DEV : loss 0.0635797530412674 - score 0.9868
2021-07-23 11:38:50,336 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:38:52,452 ----------------------------------------------------------------------------------------------------
2021-07-23 11:39:01,859 epoch 9 - iter 40/405 - loss 0.10422992 - samples/sec: 136.14 - lr: 0.000030
2021-07-23 11:39:11,060 epoch 9 - iter 80/405 - loss 0.10090518 - samples/sec: 139.15 - lr: 0.000030
2021-07-23 11:39:20,327 epoch 9 - iter 120/405 - loss 0.10912671 - samples/sec: 138.16 - lr: 0.000030
2021-07-23 11:39:29,656 epoch 9 - iter 160/405 - loss 0.10634638 - samples/sec: 137.23 - lr: 0.000030
2021-07-23 11:39:38,807 epoch 9 - iter 200/405 - loss 0.11062723 - samples/sec: 139.91 - lr: 0.000030
2021-07-23 11:39:48,007 epoch 9 - iter 240/405 - loss 0.10759557 - samples/sec: 139.17 - lr: 0.000030
2021-07-23 11:39:57,459 epoch 9 - iter 280/405 - loss 0.11059072 - samples/sec: 135.44 - lr: 0.000030
2021-07-23 11:40:06,516 epoch 9 - iter 320/405 - loss 0.10879156 - samples/sec: 141.36 - lr: 0.000030
2021-07-23 11:40:15,834 epoch 9 - iter 360/405 - loss 0.10692526 - samples/sec: 137.41 - lr: 0.000030
2021-07-23 11:40:25,091 epoch 9 - iter 400/405 - loss 0.10685283 - samples/sec: 138.30 - lr: 0.000030
2021-07-23 11:40:26,119 ----------------------------------------------------------------------------------------------------
2021-07-23 11:40:26,119 EPOCH 9 done: loss 0.1063 - lr 0.0000300
2021-07-23 11:40:32,295 DEV : loss 0.06248338893055916 - score 0.987
2021-07-23 11:40:32,368 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:40:34,549 ----------------------------------------------------------------------------------------------------
2021-07-23 11:40:43,776 epoch 10 - iter 40/405 - loss 0.10971515 - samples/sec: 138.79 - lr: 0.000030
2021-07-23 11:40:53,061 epoch 10 - iter 80/405 - loss 0.11171502 - samples/sec: 137.89 - lr: 0.000030
2021-07-23 11:41:02,513 epoch 10 - iter 120/405 - loss 0.11338637 - samples/sec: 135.45 - lr: 0.000030
2021-07-23 11:41:11,785 epoch 10 - iter 160/405 - loss 0.11248827 - samples/sec: 138.09 - lr: 0.000030
2021-07-23 11:41:21,269 epoch 10 - iter 200/405 - loss 0.10701149 - samples/sec: 134.99 - lr: 0.000030
2021-07-23 11:41:30,444 epoch 10 - iter 240/405 - loss 0.10281763 - samples/sec: 139.54 - lr: 0.000030
2021-07-23 11:41:39,796 epoch 10 - iter 280/405 - loss 0.10283728 - samples/sec: 136.90 - lr: 0.000030
2021-07-23 11:41:49,051 epoch 10 - iter 320/405 - loss 0.10506730 - samples/sec: 138.34 - lr: 0.000030
2021-07-23 11:41:58,299 epoch 10 - iter 360/405 - loss 0.10356749 - samples/sec: 138.43 - lr: 0.000030
2021-07-23 11:42:07,460 epoch 10 - iter 400/405 - loss 0.10322986 - samples/sec: 139.75 - lr: 0.000030
2021-07-23 11:42:08,461 ----------------------------------------------------------------------------------------------------
2021-07-23 11:42:08,461 EPOCH 10 done: loss 0.1028 - lr 0.0000300
2021-07-23 11:42:14,644 DEV : loss 0.06133819743990898 - score 0.987
2021-07-23 11:42:14,717 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:42:16,838 ----------------------------------------------------------------------------------------------------
2021-07-23 11:42:26,242 epoch 11 - iter 40/405 - loss 0.11508934 - samples/sec: 136.18 - lr: 0.000030
2021-07-23 11:42:35,484 epoch 11 - iter 80/405 - loss 0.10005429 - samples/sec: 138.52 - lr: 0.000030
2021-07-23 11:42:44,443 epoch 11 - iter 120/405 - loss 0.09659656 - samples/sec: 142.92 - lr: 0.000030
2021-07-23 11:42:53,563 epoch 11 - iter 160/405 - loss 0.09967403 - samples/sec: 140.38 - lr: 0.000030
2021-07-23 11:43:02,861 epoch 11 - iter 200/405 - loss 0.09887287 - samples/sec: 137.69 - lr: 0.000030
2021-07-23 11:43:12,136 epoch 11 - iter 240/405 - loss 0.10139936 - samples/sec: 138.04 - lr: 0.000030
2021-07-23 11:43:21,560 epoch 11 - iter 280/405 - loss 0.10333572 - samples/sec: 135.85 - lr: 0.000030
2021-07-23 11:43:30,876 epoch 11 - iter 320/405 - loss 0.10316347 - samples/sec: 137.43 - lr: 0.000030
2021-07-23 11:43:40,257 epoch 11 - iter 360/405 - loss 0.10349966 - samples/sec: 136.48 - lr: 0.000030
2021-07-23 11:43:49,730 epoch 11 - iter 400/405 - loss 0.10277556 - samples/sec: 135.14 - lr: 0.000030
2021-07-23 11:43:50,712 ----------------------------------------------------------------------------------------------------
2021-07-23 11:43:50,712 EPOCH 11 done: loss 0.1018 - lr 0.0000300
2021-07-23 11:43:56,887 DEV : loss 0.06166699901223183 - score 0.9879
2021-07-23 11:43:56,960 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:43:59,682 ----------------------------------------------------------------------------------------------------
2021-07-23 11:44:09,058 epoch 12 - iter 40/405 - loss 0.08167221 - samples/sec: 136.58 - lr: 0.000030
2021-07-23 11:44:18,450 epoch 12 - iter 80/405 - loss 0.10025722 - samples/sec: 136.31 - lr: 0.000030
2021-07-23 11:44:27,596 epoch 12 - iter 120/405 - loss 0.10333799 - samples/sec: 139.99 - lr: 0.000030
2021-07-23 11:44:36,769 epoch 12 - iter 160/405 - loss 0.10177710 - samples/sec: 139.56 - lr: 0.000030
2021-07-23 11:44:46,025 epoch 12 - iter 200/405 - loss 0.10594610 - samples/sec: 138.33 - lr: 0.000030
2021-07-23 11:44:55,412 epoch 12 - iter 240/405 - loss 0.10404211 - samples/sec: 136.39 - lr: 0.000030
2021-07-23 11:45:04,812 epoch 12 - iter 280/405 - loss 0.10425651 - samples/sec: 136.21 - lr: 0.000030
2021-07-23 11:45:14,086 epoch 12 - iter 320/405 - loss 0.10590310 - samples/sec: 138.05 - lr: 0.000030
2021-07-23 11:45:23,544 epoch 12 - iter 360/405 - loss 0.10667095 - samples/sec: 135.37 - lr: 0.000030
2021-07-23 11:45:32,757 epoch 12 - iter 400/405 - loss 0.10552823 - samples/sec: 138.96 - lr: 0.000030
2021-07-23 11:45:33,770 ----------------------------------------------------------------------------------------------------
2021-07-23 11:45:33,771 EPOCH 12 done: loss 0.1050 - lr 0.0000300
2021-07-23 11:45:39,955 DEV : loss 0.06110770255327225 - score 0.987
2021-07-23 11:45:40,027 BAD EPOCHS (no improvement): 1
2021-07-23 11:45:40,028 ----------------------------------------------------------------------------------------------------
2021-07-23 11:45:49,356 epoch 13 - iter 40/405 - loss 0.07611854 - samples/sec: 137.27 - lr: 0.000030
2021-07-23 11:45:58,694 epoch 13 - iter 80/405 - loss 0.08225403 - samples/sec: 137.11 - lr: 0.000030
2021-07-23 11:46:07,981 epoch 13 - iter 120/405 - loss 0.08906447 - samples/sec: 137.86 - lr: 0.000030
2021-07-23 11:46:17,310 epoch 13 - iter 160/405 - loss 0.08947499 - samples/sec: 137.24 - lr: 0.000030
2021-07-23 11:46:26,648 epoch 13 - iter 200/405 - loss 0.08784424 - samples/sec: 137.10 - lr: 0.000030
2021-07-23 11:46:35,543 epoch 13 - iter 240/405 - loss 0.08737309 - samples/sec: 143.93 - lr: 0.000030
2021-07-23 11:46:44,728 epoch 13 - iter 280/405 - loss 0.09364662 - samples/sec: 139.39 - lr: 0.000030
2021-07-23 11:46:54,140 epoch 13 - iter 320/405 - loss 0.09656930 - samples/sec: 136.03 - lr: 0.000030
2021-07-23 11:47:03,368 epoch 13 - iter 360/405 - loss 0.09656963 - samples/sec: 138.74 - lr: 0.000030
2021-07-23 11:47:12,564 epoch 13 - iter 400/405 - loss 0.09813419 - samples/sec: 139.22 - lr: 0.000030
2021-07-23 11:47:13,642 ----------------------------------------------------------------------------------------------------
2021-07-23 11:47:13,642 EPOCH 13 done: loss 0.0976 - lr 0.0000300
2021-07-23 11:47:19,808 DEV : loss 0.06087813526391983 - score 0.9865
2021-07-23 11:47:19,881 BAD EPOCHS (no improvement): 2
2021-07-23 11:47:19,881 ----------------------------------------------------------------------------------------------------
2021-07-23 11:47:29,005 epoch 14 - iter 40/405 - loss 0.09325452 - samples/sec: 140.35 - lr: 0.000030
2021-07-23 11:47:38,432 epoch 14 - iter 80/405 - loss 0.08338624 - samples/sec: 135.81 - lr: 0.000030
2021-07-23 11:47:47,910 epoch 14 - iter 120/405 - loss 0.08861272 - samples/sec: 135.08 - lr: 0.000030
2021-07-23 11:47:57,153 epoch 14 - iter 160/405 - loss 0.08958575 - samples/sec: 138.51 - lr: 0.000030
2021-07-23 11:48:06,345 epoch 14 - iter 200/405 - loss 0.09118860 - samples/sec: 139.29 - lr: 0.000030
2021-07-23 11:48:15,597 epoch 14 - iter 240/405 - loss 0.09376735 - samples/sec: 138.38 - lr: 0.000030
2021-07-23 11:48:24,944 epoch 14 - iter 280/405 - loss 0.09466200 - samples/sec: 136.97 - lr: 0.000030
2021-07-23 11:48:34,268 epoch 14 - iter 320/405 - loss 0.09526989 - samples/sec: 137.31 - lr: 0.000030
2021-07-23 11:48:43,507 epoch 14 - iter 360/405 - loss 0.09516821 - samples/sec: 138.57 - lr: 0.000030
2021-07-23 11:48:52,805 epoch 14 - iter 400/405 - loss 0.09500452 - samples/sec: 137.70 - lr: 0.000030
2021-07-23 11:48:53,822 ----------------------------------------------------------------------------------------------------
2021-07-23 11:48:53,822 EPOCH 14 done: loss 0.0946 - lr 0.0000300
2021-07-23 11:48:59,997 DEV : loss 0.05971602350473404 - score 0.9876
2021-07-23 11:49:00,069 BAD EPOCHS (no improvement): 3
2021-07-23 11:49:00,070 ----------------------------------------------------------------------------------------------------
2021-07-23 11:49:09,424 epoch 15 - iter 40/405 - loss 0.08982673 - samples/sec: 136.89 - lr: 0.000030
2021-07-23 11:49:18,781 epoch 15 - iter 80/405 - loss 0.08127930 - samples/sec: 136.83 - lr: 0.000030
2021-07-23 11:49:28,059 epoch 15 - iter 120/405 - loss 0.07964268 - samples/sec: 137.98 - lr: 0.000030
2021-07-23 11:49:37,472 epoch 15 - iter 160/405 - loss 0.08433034 - samples/sec: 136.02 - lr: 0.000030
2021-07-23 11:49:46,677 epoch 15 - iter 200/405 - loss 0.08357032 - samples/sec: 139.09 - lr: 0.000030
2021-07-23 11:49:55,996 epoch 15 - iter 240/405 - loss 0.08696159 - samples/sec: 137.37 - lr: 0.000030
2021-07-23 11:50:05,277 epoch 15 - iter 280/405 - loss 0.08915450 - samples/sec: 137.95 - lr: 0.000030
2021-07-23 11:50:14,393 epoch 15 - iter 320/405 - loss 0.09125317 - samples/sec: 140.45 - lr: 0.000030
2021-07-23 11:50:23,784 epoch 15 - iter 360/405 - loss 0.08995957 - samples/sec: 136.33 - lr: 0.000030
2021-07-23 11:50:33,125 epoch 15 - iter 400/405 - loss 0.09053146 - samples/sec: 137.07 - lr: 0.000030
2021-07-23 11:50:34,183 ----------------------------------------------------------------------------------------------------
2021-07-23 11:50:34,183 EPOCH 15 done: loss 0.0904 - lr 0.0000300
2021-07-23 11:50:40,383 DEV : loss 0.06065994128584862 - score 0.9879
2021-07-23 11:50:40,456 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:50:42,696 ----------------------------------------------------------------------------------------------------
2021-07-23 11:50:52,493 epoch 16 - iter 40/405 - loss 0.09377549 - samples/sec: 130.72 - lr: 0.000030
2021-07-23 11:51:01,910 epoch 16 - iter 80/405 - loss 0.08503691 - samples/sec: 135.96 - lr: 0.000030
2021-07-23 11:51:11,129 epoch 16 - iter 120/405 - loss 0.08825846 - samples/sec: 138.87 - lr: 0.000030
2021-07-23 11:51:20,592 epoch 16 - iter 160/405 - loss 0.08574794 - samples/sec: 135.29 - lr: 0.000030
2021-07-23 11:51:29,686 epoch 16 - iter 200/405 - loss 0.08759636 - samples/sec: 140.79 - lr: 0.000030
2021-07-23 11:51:39,235 epoch 16 - iter 240/405 - loss 0.08828610 - samples/sec: 134.07 - lr: 0.000030
2021-07-23 11:51:48,630 epoch 16 - iter 280/405 - loss 0.08804519 - samples/sec: 136.29 - lr: 0.000030
2021-07-23 11:51:57,877 epoch 16 - iter 320/405 - loss 0.08901146 - samples/sec: 138.45 - lr: 0.000030
2021-07-23 11:52:07,255 epoch 16 - iter 360/405 - loss 0.08940086 - samples/sec: 136.51 - lr: 0.000030
2021-07-23 11:52:16,239 epoch 16 - iter 400/405 - loss 0.08942119 - samples/sec: 142.52 - lr: 0.000030
2021-07-23 11:52:17,167 ----------------------------------------------------------------------------------------------------
2021-07-23 11:52:17,167 EPOCH 16 done: loss 0.0890 - lr 0.0000300
2021-07-23 11:52:23,355 DEV : loss 0.059580713510513306 - score 0.9879
2021-07-23 11:52:23,428 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:52:25,578 ----------------------------------------------------------------------------------------------------
2021-07-23 11:52:34,729 epoch 17 - iter 40/405 - loss 0.09309166 - samples/sec: 139.95 - lr: 0.000030
2021-07-23 11:52:43,732 epoch 17 - iter 80/405 - loss 0.09271394 - samples/sec: 142.20 - lr: 0.000030
2021-07-23 11:52:53,128 epoch 17 - iter 120/405 - loss 0.08741006 - samples/sec: 136.26 - lr: 0.000030
2021-07-23 11:53:02,418 epoch 17 - iter 160/405 - loss 0.09036011 - samples/sec: 137.81 - lr: 0.000030
2021-07-23 11:53:11,633 epoch 17 - iter 200/405 - loss 0.08968230 - samples/sec: 138.94 - lr: 0.000030
2021-07-23 11:53:20,936 epoch 17 - iter 240/405 - loss 0.09027972 - samples/sec: 137.62 - lr: 0.000030
2021-07-23 11:53:30,221 epoch 17 - iter 280/405 - loss 0.09001108 - samples/sec: 137.88 - lr: 0.000030
2021-07-23 11:53:39,488 epoch 17 - iter 320/405 - loss 0.08840263 - samples/sec: 138.16 - lr: 0.000030
2021-07-23 11:53:48,794 epoch 17 - iter 360/405 - loss 0.08924771 - samples/sec: 137.58 - lr: 0.000030
2021-07-23 11:53:58,057 epoch 17 - iter 400/405 - loss 0.08709020 - samples/sec: 138.22 - lr: 0.000030
2021-07-23 11:53:59,118 ----------------------------------------------------------------------------------------------------
2021-07-23 11:53:59,118 EPOCH 17 done: loss 0.0873 - lr 0.0000300
2021-07-23 11:54:05,309 DEV : loss 0.05978232994675636 - score 0.9865
2021-07-23 11:54:05,381 BAD EPOCHS (no improvement): 1
2021-07-23 11:54:05,381 ----------------------------------------------------------------------------------------------------
2021-07-23 11:54:14,696 epoch 18 - iter 40/405 - loss 0.07085058 - samples/sec: 137.47 - lr: 0.000030
2021-07-23 11:54:24,020 epoch 18 - iter 80/405 - loss 0.07907271 - samples/sec: 137.32 - lr: 0.000030
2021-07-23 11:54:33,476 epoch 18 - iter 120/405 - loss 0.08666861 - samples/sec: 135.39 - lr: 0.000030
2021-07-23 11:54:42,744 epoch 18 - iter 160/405 - loss 0.08655523 - samples/sec: 138.15 - lr: 0.000030
2021-07-23 11:54:52,080 epoch 18 - iter 200/405 - loss 0.08568551 - samples/sec: 137.12 - lr: 0.000030
2021-07-23 11:55:01,315 epoch 18 - iter 240/405 - loss 0.08407932 - samples/sec: 138.64 - lr: 0.000030
2021-07-23 11:55:10,302 epoch 18 - iter 280/405 - loss 0.08323774 - samples/sec: 142.46 - lr: 0.000030
2021-07-23 11:55:19,588 epoch 18 - iter 320/405 - loss 0.08175699 - samples/sec: 137.87 - lr: 0.000030
2021-07-23 11:55:29,048 epoch 18 - iter 360/405 - loss 0.08236517 - samples/sec: 135.34 - lr: 0.000030
2021-07-23 11:55:38,393 epoch 18 - iter 400/405 - loss 0.08378813 - samples/sec: 137.01 - lr: 0.000030
2021-07-23 11:55:39,442 ----------------------------------------------------------------------------------------------------
2021-07-23 11:55:39,442 EPOCH 18 done: loss 0.0839 - lr 0.0000300
2021-07-23 11:55:45,643 DEV : loss 0.059011999517679214 - score 0.9881
2021-07-23 11:55:45,717 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:55:47,935 ----------------------------------------------------------------------------------------------------
2021-07-23 11:55:57,151 epoch 19 - iter 40/405 - loss 0.06633815 - samples/sec: 138.96 - lr: 0.000030
2021-07-23 11:56:06,459 epoch 19 - iter 80/405 - loss 0.06894207 - samples/sec: 137.56 - lr: 0.000030
2021-07-23 11:56:15,725 epoch 19 - iter 120/405 - loss 0.07464641 - samples/sec: 138.17 - lr: 0.000030
2021-07-23 11:56:25,115 epoch 19 - iter 160/405 - loss 0.07900688 - samples/sec: 136.34 - lr: 0.000030
2021-07-23 11:56:34,468 epoch 19 - iter 200/405 - loss 0.07835234 - samples/sec: 136.88 - lr: 0.000030
2021-07-23 11:56:43,629 epoch 19 - iter 240/405 - loss 0.08333745 - samples/sec: 139.76 - lr: 0.000030
2021-07-23 11:56:52,975 epoch 19 - iter 280/405 - loss 0.08531269 - samples/sec: 136.98 - lr: 0.000030
2021-07-23 11:57:02,230 epoch 19 - iter 320/405 - loss 0.08679998 - samples/sec: 138.33 - lr: 0.000030
2021-07-23 11:57:11,608 epoch 19 - iter 360/405 - loss 0.08671280 - samples/sec: 136.52 - lr: 0.000030
2021-07-23 11:57:21,109 epoch 19 - iter 400/405 - loss 0.08619146 - samples/sec: 134.77 - lr: 0.000030
2021-07-23 11:57:22,084 ----------------------------------------------------------------------------------------------------
2021-07-23 11:57:22,085 EPOCH 19 done: loss 0.0859 - lr 0.0000300
2021-07-23 11:57:28,261 DEV : loss 0.058838922530412674 - score 0.9876
2021-07-23 11:57:28,334 BAD EPOCHS (no improvement): 1
2021-07-23 11:57:28,334 ----------------------------------------------------------------------------------------------------
2021-07-23 11:57:38,088 epoch 20 - iter 40/405 - loss 0.07500047 - samples/sec: 131.28 - lr: 0.000030
2021-07-23 11:57:47,451 epoch 20 - iter 80/405 - loss 0.08143337 - samples/sec: 136.74 - lr: 0.000030
2021-07-23 11:57:56,593 epoch 20 - iter 120/405 - loss 0.08308513 - samples/sec: 140.04 - lr: 0.000030
2021-07-23 11:58:06,013 epoch 20 - iter 160/405 - loss 0.08095403 - samples/sec: 135.92 - lr: 0.000030
2021-07-23 11:58:15,357 epoch 20 - iter 200/405 - loss 0.08047901 - samples/sec: 137.02 - lr: 0.000030
2021-07-23 11:58:24,641 epoch 20 - iter 240/405 - loss 0.08225166 - samples/sec: 137.89 - lr: 0.000030
2021-07-23 11:58:33,928 epoch 20 - iter 280/405 - loss 0.08104953 - samples/sec: 137.87 - lr: 0.000030
2021-07-23 11:58:43,348 epoch 20 - iter 320/405 - loss 0.08155314 - samples/sec: 135.91 - lr: 0.000030
2021-07-23 11:58:52,611 epoch 20 - iter 360/405 - loss 0.08142068 - samples/sec: 138.21 - lr: 0.000030
2021-07-23 11:59:02,089 epoch 20 - iter 400/405 - loss 0.08086143 - samples/sec: 135.08 - lr: 0.000030
2021-07-23 11:59:03,027 ----------------------------------------------------------------------------------------------------
2021-07-23 11:59:03,027 EPOCH 20 done: loss 0.0807 - lr 0.0000300
2021-07-23 11:59:09,205 DEV : loss 0.057337187230587006 - score 0.9884
2021-07-23 11:59:09,277 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:59:11,468 ----------------------------------------------------------------------------------------------------
2021-07-23 11:59:20,595 epoch 21 - iter 40/405 - loss 0.08338570 - samples/sec: 140.31 - lr: 0.000030
2021-07-23 11:59:29,820 epoch 21 - iter 80/405 - loss 0.08925658 - samples/sec: 138.79 - lr: 0.000030
2021-07-23 11:59:38,801 epoch 21 - iter 120/405 - loss 0.08209482 - samples/sec: 142.57 - lr: 0.000030
2021-07-23 11:59:48,045 epoch 21 - iter 160/405 - loss 0.08309867 - samples/sec: 138.49 - lr: 0.000030
2021-07-23 11:59:57,434 epoch 21 - iter 200/405 - loss 0.08299871 - samples/sec: 136.36 - lr: 0.000030
2021-07-23 12:00:06,826 epoch 21 - iter 240/405 - loss 0.08532170 - samples/sec: 136.32 - lr: 0.000030
2021-07-23 12:00:16,157 epoch 21 - iter 280/405 - loss 0.08521116 - samples/sec: 137.21 - lr: 0.000030
2021-07-23 12:00:25,420 epoch 21 - iter 320/405 - loss 0.08512233 - samples/sec: 138.21 - lr: 0.000030
2021-07-23 12:00:34,587 epoch 21 - iter 360/405 - loss 0.08212326 - samples/sec: 139.66 - lr: 0.000030
2021-07-23 12:00:43,973 epoch 21 - iter 400/405 - loss 0.08217596 - samples/sec: 136.41 - lr: 0.000030
2021-07-23 12:00:45,063 ----------------------------------------------------------------------------------------------------
2021-07-23 12:00:45,063 EPOCH 21 done: loss 0.0828 - lr 0.0000300
2021-07-23 12:00:51,251 DEV : loss 0.05796865001320839 - score 0.9881
2021-07-23 12:00:51,323 BAD EPOCHS (no improvement): 1
2021-07-23 12:00:51,324 ----------------------------------------------------------------------------------------------------
2021-07-23 12:01:00,601 epoch 22 - iter 40/405 - loss 0.10184270 - samples/sec: 138.03 - lr: 0.000030
2021-07-23 12:01:09,508 epoch 22 - iter 80/405 - loss 0.08680774 - samples/sec: 143.74 - lr: 0.000030
2021-07-23 12:01:18,727 epoch 22 - iter 120/405 - loss 0.08445612 - samples/sec: 138.88 - lr: 0.000030
2021-07-23 12:01:27,941 epoch 22 - iter 160/405 - loss 0.08154676 - samples/sec: 138.94 - lr: 0.000030
2021-07-23 12:01:37,305 epoch 22 - iter 200/405 - loss 0.08309207 - samples/sec: 136.73 - lr: 0.000030
2021-07-23 12:01:46,800 epoch 22 - iter 240/405 - loss 0.08502772 - samples/sec: 134.84 - lr: 0.000030
2021-07-23 12:01:56,179 epoch 22 - iter 280/405 - loss 0.08216891 - samples/sec: 136.50 - lr: 0.000030
2021-07-23 12:02:05,404 epoch 22 - iter 320/405 - loss 0.08113390 - samples/sec: 138.78 - lr: 0.000030
2021-07-23 12:02:14,857 epoch 22 - iter 360/405 - loss 0.07989305 - samples/sec: 135.45 - lr: 0.000030
2021-07-23 12:02:23,992 epoch 22 - iter 400/405 - loss 0.07892842 - samples/sec: 140.14 - lr: 0.000030
2021-07-23 12:02:24,990 ----------------------------------------------------------------------------------------------------
2021-07-23 12:02:24,990 EPOCH 22 done: loss 0.0789 - lr 0.0000300
2021-07-23 12:02:31,174 DEV : loss 0.05887840315699577 - score 0.9881
2021-07-23 12:02:31,247 BAD EPOCHS (no improvement): 2
2021-07-23 12:02:31,247 ----------------------------------------------------------------------------------------------------
2021-07-23 12:02:40,412 epoch 23 - iter 40/405 - loss 0.09261118 - samples/sec: 139.72 - lr: 0.000030
2021-07-23 12:02:49,784 epoch 23 - iter 80/405 - loss 0.08061070 - samples/sec: 136.61 - lr: 0.000030
2021-07-23 12:02:58,936 epoch 23 - iter 120/405 - loss 0.07956063 - samples/sec: 139.89 - lr: 0.000030
2021-07-23 12:03:08,331 epoch 23 - iter 160/405 - loss 0.07930862 - samples/sec: 136.27 - lr: 0.000030
2021-07-23 12:03:17,680 epoch 23 - iter 200/405 - loss 0.07815558 - samples/sec: 136.94 - lr: 0.000030
2021-07-23 12:03:27,073 epoch 23 - iter 240/405 - loss 0.07633350 - samples/sec: 136.31 - lr: 0.000030
2021-07-23 12:03:36,422 epoch 23 - iter 280/405 - loss 0.07543368 - samples/sec: 136.94 - lr: 0.000030
2021-07-23 12:03:45,827 epoch 23 - iter 320/405 - loss 0.07635935 - samples/sec: 136.13 - lr: 0.000030
2021-07-23 12:03:55,257 epoch 23 - iter 360/405 - loss 0.07775902 - samples/sec: 135.76 - lr: 0.000030
2021-07-23 12:04:04,449 epoch 23 - iter 400/405 - loss 0.07678411 - samples/sec: 139.29 - lr: 0.000030
2021-07-23 12:04:05,383 ----------------------------------------------------------------------------------------------------
2021-07-23 12:04:05,384 EPOCH 23 done: loss 0.0769 - lr 0.0000300
2021-07-23 12:04:11,569 DEV : loss 0.05707472562789917 - score 0.9879
2021-07-23 12:04:11,641 BAD EPOCHS (no improvement): 3
2021-07-23 12:04:11,641 ----------------------------------------------------------------------------------------------------
2021-07-23 12:04:21,440 epoch 24 - iter 40/405 - loss 0.05991486 - samples/sec: 130.68 - lr: 0.000030
2021-07-23 12:04:30,723 epoch 24 - iter 80/405 - loss 0.06311697 - samples/sec: 137.92 - lr: 0.000030
2021-07-23 12:04:40,029 epoch 24 - iter 120/405 - loss 0.06248216 - samples/sec: 137.58 - lr: 0.000030
2021-07-23 12:04:49,209 epoch 24 - iter 160/405 - loss 0.06586899 - samples/sec: 139.47 - lr: 0.000030
2021-07-23 12:04:58,500 epoch 24 - iter 200/405 - loss 0.07010142 - samples/sec: 137.80 - lr: 0.000030
2021-07-23 12:05:07,860 epoch 24 - iter 240/405 - loss 0.07014004 - samples/sec: 136.78 - lr: 0.000030
2021-07-23 12:05:17,079 epoch 24 - iter 280/405 - loss 0.07169859 - samples/sec: 138.87 - lr: 0.000030
2021-07-23 12:05:26,573 epoch 24 - iter 320/405 - loss 0.07454094 - samples/sec: 134.85 - lr: 0.000030
2021-07-23 12:05:35,800 epoch 24 - iter 360/405 - loss 0.07588129 - samples/sec: 138.76 - lr: 0.000030
2021-07-23 12:05:45,081 epoch 24 - iter 400/405 - loss 0.07641277 - samples/sec: 137.95 - lr: 0.000030
2021-07-23 12:05:46,099 ----------------------------------------------------------------------------------------------------
2021-07-23 12:05:46,099 EPOCH 24 done: loss 0.0760 - lr 0.0000300
2021-07-23 12:05:52,261 DEV : loss 0.05753691866993904 - score 0.9868
Epoch    24: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 12:05:52,334 BAD EPOCHS (no improvement): 4
2021-07-23 12:05:52,334 ----------------------------------------------------------------------------------------------------
2021-07-23 12:06:01,757 epoch 25 - iter 40/405 - loss 0.06459005 - samples/sec: 135.90 - lr: 0.000015
2021-07-23 12:06:11,092 epoch 25 - iter 80/405 - loss 0.07228195 - samples/sec: 137.15 - lr: 0.000015
2021-07-23 12:06:20,415 epoch 25 - iter 120/405 - loss 0.07326117 - samples/sec: 137.32 - lr: 0.000015
2021-07-23 12:06:29,764 epoch 25 - iter 160/405 - loss 0.07660101 - samples/sec: 136.95 - lr: 0.000015
2021-07-23 12:06:39,024 epoch 25 - iter 200/405 - loss 0.07129177 - samples/sec: 138.27 - lr: 0.000015
2021-07-23 12:06:48,235 epoch 25 - iter 240/405 - loss 0.07010647 - samples/sec: 138.99 - lr: 0.000015
2021-07-23 12:06:57,457 epoch 25 - iter 280/405 - loss 0.06949976 - samples/sec: 138.83 - lr: 0.000015
2021-07-23 12:07:06,900 epoch 25 - iter 320/405 - loss 0.07041298 - samples/sec: 135.59 - lr: 0.000015
2021-07-23 12:07:16,076 epoch 25 - iter 360/405 - loss 0.07079414 - samples/sec: 139.52 - lr: 0.000015
2021-07-23 12:07:25,244 epoch 25 - iter 400/405 - loss 0.07184602 - samples/sec: 139.65 - lr: 0.000015
2021-07-23 12:07:26,190 ----------------------------------------------------------------------------------------------------
2021-07-23 12:07:26,190 EPOCH 25 done: loss 0.0715 - lr 0.0000150
2021-07-23 12:07:32,373 DEV : loss 0.05772266536951065 - score 0.9887
2021-07-23 12:07:32,446 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:07:34,647 ----------------------------------------------------------------------------------------------------
2021-07-23 12:07:43,957 epoch 26 - iter 40/405 - loss 0.06305505 - samples/sec: 137.55 - lr: 0.000015
2021-07-23 12:07:53,304 epoch 26 - iter 80/405 - loss 0.06644184 - samples/sec: 136.98 - lr: 0.000015
2021-07-23 12:08:02,669 epoch 26 - iter 120/405 - loss 0.06919089 - samples/sec: 136.70 - lr: 0.000015
2021-07-23 12:08:11,819 epoch 26 - iter 160/405 - loss 0.06997823 - samples/sec: 139.93 - lr: 0.000015
2021-07-23 12:08:21,203 epoch 26 - iter 200/405 - loss 0.06994898 - samples/sec: 136.44 - lr: 0.000015
2021-07-23 12:08:30,688 epoch 26 - iter 240/405 - loss 0.07213985 - samples/sec: 134.97 - lr: 0.000015
2021-07-23 12:08:39,795 epoch 26 - iter 280/405 - loss 0.07162348 - samples/sec: 140.59 - lr: 0.000015
2021-07-23 12:08:49,128 epoch 26 - iter 320/405 - loss 0.07232702 - samples/sec: 137.19 - lr: 0.000015
2021-07-23 12:08:58,291 epoch 26 - iter 360/405 - loss 0.07270376 - samples/sec: 139.71 - lr: 0.000015
2021-07-23 12:09:07,809 epoch 26 - iter 400/405 - loss 0.07339282 - samples/sec: 134.51 - lr: 0.000015
2021-07-23 12:09:08,771 ----------------------------------------------------------------------------------------------------
2021-07-23 12:09:08,771 EPOCH 26 done: loss 0.0731 - lr 0.0000150
2021-07-23 12:09:14,942 DEV : loss 0.057818666100502014 - score 0.9878
2021-07-23 12:09:15,014 BAD EPOCHS (no improvement): 1
2021-07-23 12:09:15,015 ----------------------------------------------------------------------------------------------------
2021-07-23 12:09:24,376 epoch 27 - iter 40/405 - loss 0.06047017 - samples/sec: 136.78 - lr: 0.000015
2021-07-23 12:09:33,736 epoch 27 - iter 80/405 - loss 0.06660787 - samples/sec: 136.78 - lr: 0.000015
2021-07-23 12:09:42,981 epoch 27 - iter 120/405 - loss 0.06184225 - samples/sec: 138.49 - lr: 0.000015
2021-07-23 12:09:52,332 epoch 27 - iter 160/405 - loss 0.06173421 - samples/sec: 136.90 - lr: 0.000015
2021-07-23 12:10:01,655 epoch 27 - iter 200/405 - loss 0.06309691 - samples/sec: 137.33 - lr: 0.000015
2021-07-23 12:10:10,980 epoch 27 - iter 240/405 - loss 0.06705257 - samples/sec: 137.31 - lr: 0.000015
2021-07-23 12:10:20,477 epoch 27 - iter 280/405 - loss 0.06770958 - samples/sec: 134.81 - lr: 0.000015
2021-07-23 12:10:29,660 epoch 27 - iter 320/405 - loss 0.06731667 - samples/sec: 139.42 - lr: 0.000015
2021-07-23 12:10:38,844 epoch 27 - iter 360/405 - loss 0.06791234 - samples/sec: 139.40 - lr: 0.000015
2021-07-23 12:10:48,145 epoch 27 - iter 400/405 - loss 0.06728361 - samples/sec: 137.65 - lr: 0.000015
2021-07-23 12:10:49,141 ----------------------------------------------------------------------------------------------------
2021-07-23 12:10:49,141 EPOCH 27 done: loss 0.0668 - lr 0.0000150
2021-07-23 12:10:55,293 DEV : loss 0.0579482838511467 - score 0.9884
2021-07-23 12:10:55,365 BAD EPOCHS (no improvement): 2
2021-07-23 12:10:55,365 ----------------------------------------------------------------------------------------------------
2021-07-23 12:11:04,970 epoch 28 - iter 40/405 - loss 0.06866363 - samples/sec: 133.32 - lr: 0.000015
2021-07-23 12:11:14,417 epoch 28 - iter 80/405 - loss 0.06771170 - samples/sec: 135.53 - lr: 0.000015
2021-07-23 12:11:23,652 epoch 28 - iter 120/405 - loss 0.06534059 - samples/sec: 138.62 - lr: 0.000015
2021-07-23 12:11:33,025 epoch 28 - iter 160/405 - loss 0.06712137 - samples/sec: 136.59 - lr: 0.000015
2021-07-23 12:11:42,212 epoch 28 - iter 200/405 - loss 0.06960263 - samples/sec: 139.37 - lr: 0.000015
2021-07-23 12:11:51,608 epoch 28 - iter 240/405 - loss 0.07174823 - samples/sec: 136.25 - lr: 0.000015
2021-07-23 12:12:01,129 epoch 28 - iter 280/405 - loss 0.06917309 - samples/sec: 134.47 - lr: 0.000015
2021-07-23 12:12:10,437 epoch 28 - iter 320/405 - loss 0.06743247 - samples/sec: 137.55 - lr: 0.000015
2021-07-23 12:12:19,781 epoch 28 - iter 360/405 - loss 0.06707292 - samples/sec: 137.02 - lr: 0.000015
2021-07-23 12:12:29,083 epoch 28 - iter 400/405 - loss 0.06674717 - samples/sec: 137.63 - lr: 0.000015
2021-07-23 12:12:30,044 ----------------------------------------------------------------------------------------------------
2021-07-23 12:12:30,044 EPOCH 28 done: loss 0.0669 - lr 0.0000150
2021-07-23 12:12:36,206 DEV : loss 0.05847747623920441 - score 0.9873
2021-07-23 12:12:36,279 BAD EPOCHS (no improvement): 3
2021-07-23 12:12:36,280 ----------------------------------------------------------------------------------------------------
2021-07-23 12:12:45,497 epoch 29 - iter 40/405 - loss 0.08422854 - samples/sec: 138.93 - lr: 0.000015
2021-07-23 12:12:54,888 epoch 29 - iter 80/405 - loss 0.07506142 - samples/sec: 136.33 - lr: 0.000015
2021-07-23 12:13:04,180 epoch 29 - iter 120/405 - loss 0.07003473 - samples/sec: 137.79 - lr: 0.000015
2021-07-23 12:13:13,405 epoch 29 - iter 160/405 - loss 0.06779266 - samples/sec: 138.78 - lr: 0.000015
2021-07-23 12:13:22,503 epoch 29 - iter 200/405 - loss 0.06740544 - samples/sec: 140.73 - lr: 0.000015
2021-07-23 12:13:31,905 epoch 29 - iter 240/405 - loss 0.07106335 - samples/sec: 136.17 - lr: 0.000015
2021-07-23 12:13:41,084 epoch 29 - iter 280/405 - loss 0.06990832 - samples/sec: 139.48 - lr: 0.000015
2021-07-23 12:13:50,200 epoch 29 - iter 320/405 - loss 0.07009444 - samples/sec: 140.44 - lr: 0.000015
2021-07-23 12:13:59,638 epoch 29 - iter 360/405 - loss 0.07009074 - samples/sec: 135.66 - lr: 0.000015
2021-07-23 12:14:09,056 epoch 29 - iter 400/405 - loss 0.07014480 - samples/sec: 135.94 - lr: 0.000015
2021-07-23 12:14:10,124 ----------------------------------------------------------------------------------------------------
2021-07-23 12:14:10,124 EPOCH 29 done: loss 0.0708 - lr 0.0000150
2021-07-23 12:14:16,283 DEV : loss 0.05682273581624031 - score 0.9879
Epoch    29: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 12:14:16,356 BAD EPOCHS (no improvement): 4
2021-07-23 12:14:16,356 ----------------------------------------------------------------------------------------------------
2021-07-23 12:14:25,723 epoch 30 - iter 40/405 - loss 0.06918379 - samples/sec: 136.71 - lr: 0.000008
2021-07-23 12:14:34,883 epoch 30 - iter 80/405 - loss 0.06586131 - samples/sec: 139.77 - lr: 0.000008
2021-07-23 12:14:44,007 epoch 30 - iter 120/405 - loss 0.06668038 - samples/sec: 140.33 - lr: 0.000008
2021-07-23 12:14:53,099 epoch 30 - iter 160/405 - loss 0.06451545 - samples/sec: 140.80 - lr: 0.000008
2021-07-23 12:15:02,381 epoch 30 - iter 200/405 - loss 0.06794336 - samples/sec: 137.94 - lr: 0.000008
2021-07-23 12:15:11,534 epoch 30 - iter 240/405 - loss 0.06744118 - samples/sec: 139.87 - lr: 0.000008
2021-07-23 12:15:20,916 epoch 30 - iter 280/405 - loss 0.06628323 - samples/sec: 136.46 - lr: 0.000008
2021-07-23 12:15:30,264 epoch 30 - iter 320/405 - loss 0.06626489 - samples/sec: 136.96 - lr: 0.000008
2021-07-23 12:15:39,412 epoch 30 - iter 360/405 - loss 0.06483545 - samples/sec: 139.96 - lr: 0.000008
2021-07-23 12:15:48,900 epoch 30 - iter 400/405 - loss 0.06504108 - samples/sec: 134.94 - lr: 0.000008
2021-07-23 12:15:49,936 ----------------------------------------------------------------------------------------------------
2021-07-23 12:15:49,936 EPOCH 30 done: loss 0.0649 - lr 0.0000075
2021-07-23 12:15:56,101 DEV : loss 0.05592495948076248 - score 0.9884
2021-07-23 12:15:56,174 BAD EPOCHS (no improvement): 1
2021-07-23 12:15:56,174 ----------------------------------------------------------------------------------------------------
2021-07-23 12:16:05,445 epoch 31 - iter 40/405 - loss 0.08220463 - samples/sec: 138.12 - lr: 0.000008
2021-07-23 12:16:14,948 epoch 31 - iter 80/405 - loss 0.06969602 - samples/sec: 134.73 - lr: 0.000008
2021-07-23 12:16:24,052 epoch 31 - iter 120/405 - loss 0.06757839 - samples/sec: 140.63 - lr: 0.000008
2021-07-23 12:16:33,143 epoch 31 - iter 160/405 - loss 0.06031717 - samples/sec: 140.84 - lr: 0.000008
2021-07-23 12:16:42,495 epoch 31 - iter 200/405 - loss 0.06214296 - samples/sec: 136.89 - lr: 0.000008
2021-07-23 12:16:51,879 epoch 31 - iter 240/405 - loss 0.06389564 - samples/sec: 136.43 - lr: 0.000008
2021-07-23 12:17:01,028 epoch 31 - iter 280/405 - loss 0.06435244 - samples/sec: 139.94 - lr: 0.000008
2021-07-23 12:17:10,337 epoch 31 - iter 320/405 - loss 0.06518077 - samples/sec: 137.53 - lr: 0.000008
2021-07-23 12:17:19,614 epoch 31 - iter 360/405 - loss 0.06521258 - samples/sec: 138.02 - lr: 0.000008
2021-07-23 12:17:28,893 epoch 31 - iter 400/405 - loss 0.06549448 - samples/sec: 137.98 - lr: 0.000008
2021-07-23 12:17:29,926 ----------------------------------------------------------------------------------------------------
2021-07-23 12:17:29,927 EPOCH 31 done: loss 0.0652 - lr 0.0000075
2021-07-23 12:17:36,092 DEV : loss 0.05637853592634201 - score 0.989
2021-07-23 12:17:36,165 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:17:39,077 ----------------------------------------------------------------------------------------------------
2021-07-23 12:17:48,300 epoch 32 - iter 40/405 - loss 0.06195282 - samples/sec: 138.85 - lr: 0.000008
2021-07-23 12:17:57,777 epoch 32 - iter 80/405 - loss 0.06861251 - samples/sec: 135.09 - lr: 0.000008
2021-07-23 12:18:07,042 epoch 32 - iter 120/405 - loss 0.06732108 - samples/sec: 138.18 - lr: 0.000008
2021-07-23 12:18:16,321 epoch 32 - iter 160/405 - loss 0.06698683 - samples/sec: 137.99 - lr: 0.000008
2021-07-23 12:18:25,605 epoch 32 - iter 200/405 - loss 0.07027805 - samples/sec: 137.89 - lr: 0.000008
2021-07-23 12:18:34,953 epoch 32 - iter 240/405 - loss 0.06874741 - samples/sec: 136.97 - lr: 0.000008
2021-07-23 12:18:44,242 epoch 32 - iter 280/405 - loss 0.07062517 - samples/sec: 137.83 - lr: 0.000008
2021-07-23 12:18:53,588 epoch 32 - iter 320/405 - loss 0.06978591 - samples/sec: 136.98 - lr: 0.000008
2021-07-23 12:19:02,740 epoch 32 - iter 360/405 - loss 0.07035899 - samples/sec: 139.90 - lr: 0.000008
2021-07-23 12:19:12,095 epoch 32 - iter 400/405 - loss 0.06828061 - samples/sec: 136.85 - lr: 0.000008
2021-07-23 12:19:13,082 ----------------------------------------------------------------------------------------------------
2021-07-23 12:19:13,083 EPOCH 32 done: loss 0.0684 - lr 0.0000075
2021-07-23 12:19:19,236 DEV : loss 0.056721605360507965 - score 0.989
2021-07-23 12:19:19,309 BAD EPOCHS (no improvement): 1
2021-07-23 12:19:19,309 ----------------------------------------------------------------------------------------------------
2021-07-23 12:19:28,600 epoch 33 - iter 40/405 - loss 0.05514160 - samples/sec: 137.82 - lr: 0.000008
2021-07-23 12:19:37,704 epoch 33 - iter 80/405 - loss 0.06840999 - samples/sec: 140.63 - lr: 0.000008
2021-07-23 12:19:47,040 epoch 33 - iter 120/405 - loss 0.07011305 - samples/sec: 137.14 - lr: 0.000008
2021-07-23 12:19:56,348 epoch 33 - iter 160/405 - loss 0.06683804 - samples/sec: 137.56 - lr: 0.000008
2021-07-23 12:20:05,757 epoch 33 - iter 200/405 - loss 0.06695577 - samples/sec: 136.06 - lr: 0.000008
2021-07-23 12:20:15,068 epoch 33 - iter 240/405 - loss 0.06651097 - samples/sec: 137.51 - lr: 0.000008
2021-07-23 12:20:24,379 epoch 33 - iter 280/405 - loss 0.06586787 - samples/sec: 137.50 - lr: 0.000008
2021-07-23 12:20:33,628 epoch 33 - iter 320/405 - loss 0.06736431 - samples/sec: 138.42 - lr: 0.000008
2021-07-23 12:20:43,005 epoch 33 - iter 360/405 - loss 0.06547312 - samples/sec: 136.54 - lr: 0.000008
2021-07-23 12:20:52,206 epoch 33 - iter 400/405 - loss 0.06474307 - samples/sec: 139.13 - lr: 0.000008
2021-07-23 12:20:53,139 ----------------------------------------------------------------------------------------------------
2021-07-23 12:20:53,139 EPOCH 33 done: loss 0.0651 - lr 0.0000075
2021-07-23 12:20:59,296 DEV : loss 0.05921822413802147 - score 0.9881
2021-07-23 12:20:59,369 BAD EPOCHS (no improvement): 2
2021-07-23 12:20:59,370 ----------------------------------------------------------------------------------------------------
2021-07-23 12:21:08,593 epoch 34 - iter 40/405 - loss 0.07206850 - samples/sec: 138.84 - lr: 0.000008
2021-07-23 12:21:17,902 epoch 34 - iter 80/405 - loss 0.06268742 - samples/sec: 137.53 - lr: 0.000008
2021-07-23 12:21:27,185 epoch 34 - iter 120/405 - loss 0.06495616 - samples/sec: 137.92 - lr: 0.000008
2021-07-23 12:21:36,423 epoch 34 - iter 160/405 - loss 0.06572148 - samples/sec: 138.58 - lr: 0.000008
2021-07-23 12:21:45,617 epoch 34 - iter 200/405 - loss 0.06804797 - samples/sec: 139.26 - lr: 0.000008
2021-07-23 12:21:55,114 epoch 34 - iter 240/405 - loss 0.06759967 - samples/sec: 134.81 - lr: 0.000008
2021-07-23 12:22:04,495 epoch 34 - iter 280/405 - loss 0.06509871 - samples/sec: 136.48 - lr: 0.000008
2021-07-23 12:22:13,679 epoch 34 - iter 320/405 - loss 0.06630458 - samples/sec: 139.39 - lr: 0.000008
2021-07-23 12:22:22,995 epoch 34 - iter 360/405 - loss 0.06539106 - samples/sec: 137.43 - lr: 0.000008
2021-07-23 12:22:32,440 epoch 34 - iter 400/405 - loss 0.06384254 - samples/sec: 135.56 - lr: 0.000008
2021-07-23 12:22:33,423 ----------------------------------------------------------------------------------------------------
2021-07-23 12:22:33,423 EPOCH 34 done: loss 0.0644 - lr 0.0000075
2021-07-23 12:22:39,586 DEV : loss 0.05700819566845894 - score 0.989
2021-07-23 12:22:39,660 BAD EPOCHS (no improvement): 3
2021-07-23 12:22:39,660 ----------------------------------------------------------------------------------------------------
2021-07-23 12:22:49,129 epoch 35 - iter 40/405 - loss 0.06067631 - samples/sec: 135.23 - lr: 0.000008
2021-07-23 12:22:58,483 epoch 35 - iter 80/405 - loss 0.06158346 - samples/sec: 136.87 - lr: 0.000008
2021-07-23 12:23:07,648 epoch 35 - iter 120/405 - loss 0.06110447 - samples/sec: 139.70 - lr: 0.000008
2021-07-23 12:23:16,907 epoch 35 - iter 160/405 - loss 0.05855066 - samples/sec: 138.27 - lr: 0.000008
2021-07-23 12:23:26,197 epoch 35 - iter 200/405 - loss 0.06135422 - samples/sec: 137.82 - lr: 0.000008
2021-07-23 12:23:35,506 epoch 35 - iter 240/405 - loss 0.06019207 - samples/sec: 137.53 - lr: 0.000008
2021-07-23 12:23:44,796 epoch 35 - iter 280/405 - loss 0.06298043 - samples/sec: 137.80 - lr: 0.000008
2021-07-23 12:23:54,279 epoch 35 - iter 320/405 - loss 0.06355567 - samples/sec: 135.01 - lr: 0.000008
2021-07-23 12:24:03,530 epoch 35 - iter 360/405 - loss 0.06214741 - samples/sec: 138.40 - lr: 0.000008
2021-07-23 12:24:12,696 epoch 35 - iter 400/405 - loss 0.06376335 - samples/sec: 139.68 - lr: 0.000008
2021-07-23 12:24:13,703 ----------------------------------------------------------------------------------------------------
2021-07-23 12:24:13,703 EPOCH 35 done: loss 0.0639 - lr 0.0000075
2021-07-23 12:24:20,350 DEV : loss 0.0564330518245697 - score 0.9873
Epoch    35: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 12:24:20,422 BAD EPOCHS (no improvement): 4
2021-07-23 12:24:20,422 ----------------------------------------------------------------------------------------------------
2021-07-23 12:24:29,713 epoch 36 - iter 40/405 - loss 0.07102464 - samples/sec: 137.83 - lr: 0.000004
2021-07-23 12:24:38,948 epoch 36 - iter 80/405 - loss 0.06812362 - samples/sec: 138.63 - lr: 0.000004
2021-07-23 12:24:48,315 epoch 36 - iter 120/405 - loss 0.06109163 - samples/sec: 136.68 - lr: 0.000004
2021-07-23 12:24:57,565 epoch 36 - iter 160/405 - loss 0.06671720 - samples/sec: 138.42 - lr: 0.000004
2021-07-23 12:25:06,740 epoch 36 - iter 200/405 - loss 0.06778853 - samples/sec: 139.53 - lr: 0.000004
2021-07-23 12:25:15,920 epoch 36 - iter 240/405 - loss 0.06846028 - samples/sec: 139.47 - lr: 0.000004
2021-07-23 12:25:25,196 epoch 36 - iter 280/405 - loss 0.06591334 - samples/sec: 138.03 - lr: 0.000004
2021-07-23 12:25:34,523 epoch 36 - iter 320/405 - loss 0.06449027 - samples/sec: 137.26 - lr: 0.000004
2021-07-23 12:25:43,829 epoch 36 - iter 360/405 - loss 0.06386050 - samples/sec: 137.58 - lr: 0.000004
2021-07-23 12:25:53,172 epoch 36 - iter 400/405 - loss 0.06346700 - samples/sec: 137.04 - lr: 0.000004
2021-07-23 12:25:54,151 ----------------------------------------------------------------------------------------------------
2021-07-23 12:25:54,151 EPOCH 36 done: loss 0.0630 - lr 0.0000038
2021-07-23 12:26:00,301 DEV : loss 0.05674139782786369 - score 0.9884
2021-07-23 12:26:00,374 BAD EPOCHS (no improvement): 1
2021-07-23 12:26:00,374 ----------------------------------------------------------------------------------------------------
2021-07-23 12:26:09,736 epoch 37 - iter 40/405 - loss 0.06439991 - samples/sec: 136.78 - lr: 0.000004
2021-07-23 12:26:18,991 epoch 37 - iter 80/405 - loss 0.06202593 - samples/sec: 138.33 - lr: 0.000004
2021-07-23 12:26:28,204 epoch 37 - iter 120/405 - loss 0.06831559 - samples/sec: 138.98 - lr: 0.000004
2021-07-23 12:26:37,376 epoch 37 - iter 160/405 - loss 0.06584266 - samples/sec: 139.57 - lr: 0.000004
2021-07-23 12:26:46,757 epoch 37 - iter 200/405 - loss 0.06541442 - samples/sec: 136.49 - lr: 0.000004
2021-07-23 12:26:56,025 epoch 37 - iter 240/405 - loss 0.06425044 - samples/sec: 138.14 - lr: 0.000004
2021-07-23 12:27:05,238 epoch 37 - iter 280/405 - loss 0.06520373 - samples/sec: 138.97 - lr: 0.000004
2021-07-23 12:27:14,379 epoch 37 - iter 320/405 - loss 0.06435281 - samples/sec: 140.05 - lr: 0.000004
2021-07-23 12:27:23,670 epoch 37 - iter 360/405 - loss 0.06537281 - samples/sec: 137.80 - lr: 0.000004
2021-07-23 12:27:33,013 epoch 37 - iter 400/405 - loss 0.06358254 - samples/sec: 137.03 - lr: 0.000004
2021-07-23 12:27:34,018 ----------------------------------------------------------------------------------------------------
2021-07-23 12:27:34,019 EPOCH 37 done: loss 0.0633 - lr 0.0000038
2021-07-23 12:27:40,194 DEV : loss 0.05673354119062424 - score 0.9881
2021-07-23 12:27:40,266 BAD EPOCHS (no improvement): 2
2021-07-23 12:27:40,267 ----------------------------------------------------------------------------------------------------
2021-07-23 12:27:49,640 epoch 38 - iter 40/405 - loss 0.06007762 - samples/sec: 136.61 - lr: 0.000004
2021-07-23 12:27:58,812 epoch 38 - iter 80/405 - loss 0.05718062 - samples/sec: 139.59 - lr: 0.000004
2021-07-23 12:28:08,035 epoch 38 - iter 120/405 - loss 0.05755919 - samples/sec: 138.82 - lr: 0.000004
2021-07-23 12:28:17,497 epoch 38 - iter 160/405 - loss 0.06046841 - samples/sec: 135.31 - lr: 0.000004
2021-07-23 12:28:26,677 epoch 38 - iter 200/405 - loss 0.05911008 - samples/sec: 139.46 - lr: 0.000004
2021-07-23 12:28:35,924 epoch 38 - iter 240/405 - loss 0.06002286 - samples/sec: 138.46 - lr: 0.000004
2021-07-23 12:28:45,137 epoch 38 - iter 280/405 - loss 0.05978877 - samples/sec: 138.97 - lr: 0.000004
2021-07-23 12:28:54,437 epoch 38 - iter 320/405 - loss 0.05990754 - samples/sec: 137.66 - lr: 0.000004
2021-07-23 12:29:03,638 epoch 38 - iter 360/405 - loss 0.06059250 - samples/sec: 139.14 - lr: 0.000004
2021-07-23 12:29:12,869 epoch 38 - iter 400/405 - loss 0.06078579 - samples/sec: 138.70 - lr: 0.000004
2021-07-23 12:29:13,909 ----------------------------------------------------------------------------------------------------
2021-07-23 12:29:13,909 EPOCH 38 done: loss 0.0608 - lr 0.0000038
2021-07-23 12:29:20,069 DEV : loss 0.0571819432079792 - score 0.9887
2021-07-23 12:29:20,142 BAD EPOCHS (no improvement): 3
2021-07-23 12:29:20,142 ----------------------------------------------------------------------------------------------------
2021-07-23 12:29:29,296 epoch 39 - iter 40/405 - loss 0.05263204 - samples/sec: 139.88 - lr: 0.000004
2021-07-23 12:29:38,624 epoch 39 - iter 80/405 - loss 0.05633409 - samples/sec: 137.26 - lr: 0.000004
2021-07-23 12:29:48,011 epoch 39 - iter 120/405 - loss 0.06160599 - samples/sec: 136.40 - lr: 0.000004
2021-07-23 12:29:57,341 epoch 39 - iter 160/405 - loss 0.05889132 - samples/sec: 137.22 - lr: 0.000004
2021-07-23 12:30:06,456 epoch 39 - iter 200/405 - loss 0.06031893 - samples/sec: 140.45 - lr: 0.000004
2021-07-23 12:30:15,724 epoch 39 - iter 240/405 - loss 0.05949998 - samples/sec: 138.14 - lr: 0.000004
2021-07-23 12:30:24,837 epoch 39 - iter 280/405 - loss 0.06050187 - samples/sec: 140.50 - lr: 0.000004
2021-07-23 12:30:34,149 epoch 39 - iter 320/405 - loss 0.05927719 - samples/sec: 137.49 - lr: 0.000004
2021-07-23 12:30:43,551 epoch 39 - iter 360/405 - loss 0.06043057 - samples/sec: 136.17 - lr: 0.000004
2021-07-23 12:30:52,733 epoch 39 - iter 400/405 - loss 0.06214073 - samples/sec: 139.43 - lr: 0.000004
2021-07-23 12:30:53,657 ----------------------------------------------------------------------------------------------------
2021-07-23 12:30:53,657 EPOCH 39 done: loss 0.0618 - lr 0.0000038
2021-07-23 12:30:59,820 DEV : loss 0.057927075773477554 - score 0.9884
Epoch    39: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 12:30:59,893 BAD EPOCHS (no improvement): 4
2021-07-23 12:30:59,893 ----------------------------------------------------------------------------------------------------
2021-07-23 12:30:59,893 ----------------------------------------------------------------------------------------------------
2021-07-23 12:30:59,894 learning rate too small - quitting training!
2021-07-23 12:30:59,894 ----------------------------------------------------------------------------------------------------
2021-07-23 12:31:00,950 ----------------------------------------------------------------------------------------------------
2021-07-23 12:31:00,950 Testing using best model ...
2021-07-23 12:31:00,951 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.gum/best-model.pt
2021-07-23 12:31:54,531 0.9823	0.9891	0.9857
2021-07-23 12:31:54,531 
Results:
- F1-score (micro) 0.9857
- F1-score (macro) 0.9853

By class:
SENT       tp: 1304 - fp: 49 - fn: 30 - precision: 0.9638 - recall: 0.9775 - f1-score: 0.9706
X          tp: 1419 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 12:31:54,531 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/nld.rst.nldt/
2021-07-23 12:31:54,582 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/nld.rst.nldt
2021-07-23 12:31:54,582 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/nld.rst.nldt/sent_train.txt
2021-07-23 12:31:54,584 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/nld.rst.nldt/sent_dev.txt
2021-07-23 12:31:54,586 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/nld.rst.nldt/sent_test.txt
Corpus: 2189 train + 599 dev + 608 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 12:32:12,628 ----------------------------------------------------------------------------------------------------
2021-07-23 12:32:12,629 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30073, 768, padding_idx=3)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 12:32:12,629 ----------------------------------------------------------------------------------------------------
2021-07-23 12:32:12,630 Corpus: "Corpus: 2189 train + 599 dev + 608 test sentences"
2021-07-23 12:32:12,630 ----------------------------------------------------------------------------------------------------
2021-07-23 12:32:12,630 Parameters:
2021-07-23 12:32:12,630  - learning_rate: "3e-05"
2021-07-23 12:32:12,630  - mini_batch_size: "32"
2021-07-23 12:32:12,630  - patience: "3"
2021-07-23 12:32:12,630  - anneal_factor: "0.5"
2021-07-23 12:32:12,630  - max_epochs: "40"
2021-07-23 12:32:12,630  - shuffle: "True"
2021-07-23 12:32:12,630  - train_with_dev: "False"
2021-07-23 12:32:12,630  - batch_growth_annealing: "False"
2021-07-23 12:32:12,630 ----------------------------------------------------------------------------------------------------
2021-07-23 12:32:12,630 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/nld.rst.nldt"
2021-07-23 12:32:12,630 ----------------------------------------------------------------------------------------------------
2021-07-23 12:32:12,630 Device: cuda:0
2021-07-23 12:32:12,630 ----------------------------------------------------------------------------------------------------
2021-07-23 12:32:12,630 Embeddings storage mode: cpu
2021-07-23 12:32:12,633 ----------------------------------------------------------------------------------------------------
2021-07-23 12:32:16,101 epoch 1 - iter 6/69 - loss 5.70149589 - samples/sec: 55.37 - lr: 0.000030
2021-07-23 12:32:19,590 epoch 1 - iter 12/69 - loss 5.24732288 - samples/sec: 55.04 - lr: 0.000030
2021-07-23 12:32:23,124 epoch 1 - iter 18/69 - loss 4.83670339 - samples/sec: 54.33 - lr: 0.000030
2021-07-23 12:32:26,548 epoch 1 - iter 24/69 - loss 4.52215593 - samples/sec: 56.09 - lr: 0.000030
2021-07-23 12:32:29,897 epoch 1 - iter 30/69 - loss 4.27701592 - samples/sec: 57.33 - lr: 0.000030
2021-07-23 12:32:33,284 epoch 1 - iter 36/69 - loss 4.04853179 - samples/sec: 56.69 - lr: 0.000030
2021-07-23 12:32:36,632 epoch 1 - iter 42/69 - loss 3.84176382 - samples/sec: 57.36 - lr: 0.000030
2021-07-23 12:32:39,980 epoch 1 - iter 48/69 - loss 3.64723214 - samples/sec: 57.36 - lr: 0.000030
2021-07-23 12:32:43,439 epoch 1 - iter 54/69 - loss 3.49080100 - samples/sec: 55.51 - lr: 0.000030
2021-07-23 12:32:46,817 epoch 1 - iter 60/69 - loss 3.34109612 - samples/sec: 56.84 - lr: 0.000030
2021-07-23 12:32:50,290 epoch 1 - iter 66/69 - loss 3.19813081 - samples/sec: 55.30 - lr: 0.000030
2021-07-23 12:32:51,690 ----------------------------------------------------------------------------------------------------
2021-07-23 12:32:51,690 EPOCH 1 done: loss 3.1428 - lr 0.0000300
2021-07-23 12:32:59,332 DEV : loss 1.3117114305496216 - score 0.5933
2021-07-23 12:32:59,347 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:32:59,904 ----------------------------------------------------------------------------------------------------
2021-07-23 12:33:01,269 epoch 2 - iter 6/69 - loss 1.49755412 - samples/sec: 140.79 - lr: 0.000030
2021-07-23 12:33:02,587 epoch 2 - iter 12/69 - loss 1.46774529 - samples/sec: 145.72 - lr: 0.000030
2021-07-23 12:33:03,981 epoch 2 - iter 18/69 - loss 1.47203013 - samples/sec: 137.84 - lr: 0.000030
2021-07-23 12:33:05,316 epoch 2 - iter 24/69 - loss 1.41341170 - samples/sec: 143.85 - lr: 0.000030
2021-07-23 12:33:06,624 epoch 2 - iter 30/69 - loss 1.37610865 - samples/sec: 146.79 - lr: 0.000030
2021-07-23 12:33:08,065 epoch 2 - iter 36/69 - loss 1.35008229 - samples/sec: 133.32 - lr: 0.000030
2021-07-23 12:33:09,538 epoch 2 - iter 42/69 - loss 1.32673539 - samples/sec: 130.43 - lr: 0.000030
2021-07-23 12:33:10,998 epoch 2 - iter 48/69 - loss 1.29293425 - samples/sec: 131.51 - lr: 0.000030
2021-07-23 12:33:12,332 epoch 2 - iter 54/69 - loss 1.25943238 - samples/sec: 144.06 - lr: 0.000030
2021-07-23 12:33:13,703 epoch 2 - iter 60/69 - loss 1.22923957 - samples/sec: 140.02 - lr: 0.000030
2021-07-23 12:33:15,097 epoch 2 - iter 66/69 - loss 1.20407729 - samples/sec: 137.79 - lr: 0.000030
2021-07-23 12:33:15,699 ----------------------------------------------------------------------------------------------------
2021-07-23 12:33:15,699 EPOCH 2 done: loss 1.1902 - lr 0.0000300
2021-07-23 12:33:17,059 DEV : loss 0.7254976630210876 - score 0.6034
2021-07-23 12:33:17,074 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:33:19,276 ----------------------------------------------------------------------------------------------------
2021-07-23 12:33:20,772 epoch 3 - iter 6/69 - loss 0.87038434 - samples/sec: 128.48 - lr: 0.000030
2021-07-23 12:33:22,080 epoch 3 - iter 12/69 - loss 0.83996359 - samples/sec: 146.88 - lr: 0.000030
2021-07-23 12:33:23,424 epoch 3 - iter 18/69 - loss 0.83544488 - samples/sec: 142.87 - lr: 0.000030
2021-07-23 12:33:24,782 epoch 3 - iter 24/69 - loss 0.82440681 - samples/sec: 141.46 - lr: 0.000030
2021-07-23 12:33:26,203 epoch 3 - iter 30/69 - loss 0.82546074 - samples/sec: 135.14 - lr: 0.000030
2021-07-23 12:33:27,612 epoch 3 - iter 36/69 - loss 0.80155434 - samples/sec: 136.34 - lr: 0.000030
2021-07-23 12:33:28,966 epoch 3 - iter 42/69 - loss 0.78057470 - samples/sec: 141.84 - lr: 0.000030
2021-07-23 12:33:30,377 epoch 3 - iter 48/69 - loss 0.75663722 - samples/sec: 136.18 - lr: 0.000030
2021-07-23 12:33:31,740 epoch 3 - iter 54/69 - loss 0.74426101 - samples/sec: 140.89 - lr: 0.000030
2021-07-23 12:33:33,172 epoch 3 - iter 60/69 - loss 0.73111930 - samples/sec: 134.14 - lr: 0.000030
2021-07-23 12:33:34,492 epoch 3 - iter 66/69 - loss 0.72287150 - samples/sec: 145.48 - lr: 0.000030
2021-07-23 12:33:35,078 ----------------------------------------------------------------------------------------------------
2021-07-23 12:33:35,078 EPOCH 3 done: loss 0.7186 - lr 0.0000300
2021-07-23 12:33:36,441 DEV : loss 0.4671473801136017 - score 0.881
2021-07-23 12:33:36,456 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:33:40,136 ----------------------------------------------------------------------------------------------------
2021-07-23 12:33:41,533 epoch 4 - iter 6/69 - loss 0.57379677 - samples/sec: 137.72 - lr: 0.000030
2021-07-23 12:33:42,964 epoch 4 - iter 12/69 - loss 0.56376318 - samples/sec: 134.24 - lr: 0.000030
2021-07-23 12:33:44,389 epoch 4 - iter 18/69 - loss 0.55257146 - samples/sec: 134.76 - lr: 0.000030
2021-07-23 12:33:45,765 epoch 4 - iter 24/69 - loss 0.54606877 - samples/sec: 139.54 - lr: 0.000030
2021-07-23 12:33:47,156 epoch 4 - iter 30/69 - loss 0.54659886 - samples/sec: 138.08 - lr: 0.000030
2021-07-23 12:33:48,524 epoch 4 - iter 36/69 - loss 0.53828792 - samples/sec: 140.47 - lr: 0.000030
2021-07-23 12:33:49,949 epoch 4 - iter 42/69 - loss 0.53158908 - samples/sec: 134.79 - lr: 0.000030
2021-07-23 12:33:51,341 epoch 4 - iter 48/69 - loss 0.52817891 - samples/sec: 137.94 - lr: 0.000030
2021-07-23 12:33:52,639 epoch 4 - iter 54/69 - loss 0.52438699 - samples/sec: 147.99 - lr: 0.000030
2021-07-23 12:33:53,980 epoch 4 - iter 60/69 - loss 0.51609550 - samples/sec: 143.28 - lr: 0.000030
2021-07-23 12:33:55,392 epoch 4 - iter 66/69 - loss 0.51057260 - samples/sec: 136.03 - lr: 0.000030
2021-07-23 12:33:55,974 ----------------------------------------------------------------------------------------------------
2021-07-23 12:33:55,975 EPOCH 4 done: loss 0.5074 - lr 0.0000300
2021-07-23 12:33:57,358 DEV : loss 0.3234540820121765 - score 0.9552
2021-07-23 12:33:57,373 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:33:59,636 ----------------------------------------------------------------------------------------------------
2021-07-23 12:34:01,052 epoch 5 - iter 6/69 - loss 0.40156963 - samples/sec: 135.78 - lr: 0.000030
2021-07-23 12:34:02,513 epoch 5 - iter 12/69 - loss 0.43038164 - samples/sec: 131.45 - lr: 0.000030
2021-07-23 12:34:03,840 epoch 5 - iter 18/69 - loss 0.41955331 - samples/sec: 144.82 - lr: 0.000030
2021-07-23 12:34:05,239 epoch 5 - iter 24/69 - loss 0.40899835 - samples/sec: 137.27 - lr: 0.000030
2021-07-23 12:34:06,640 epoch 5 - iter 30/69 - loss 0.39886070 - samples/sec: 137.05 - lr: 0.000030
2021-07-23 12:34:07,971 epoch 5 - iter 36/69 - loss 0.39436423 - samples/sec: 144.34 - lr: 0.000030
2021-07-23 12:34:09,244 epoch 5 - iter 42/69 - loss 0.39198748 - samples/sec: 150.89 - lr: 0.000030
2021-07-23 12:34:10,673 epoch 5 - iter 48/69 - loss 0.38217517 - samples/sec: 134.39 - lr: 0.000030
2021-07-23 12:34:12,048 epoch 5 - iter 54/69 - loss 0.37744989 - samples/sec: 139.74 - lr: 0.000030
2021-07-23 12:34:13,476 epoch 5 - iter 60/69 - loss 0.38090628 - samples/sec: 134.47 - lr: 0.000030
2021-07-23 12:34:14,841 epoch 5 - iter 66/69 - loss 0.37717133 - samples/sec: 140.66 - lr: 0.000030
2021-07-23 12:34:15,432 ----------------------------------------------------------------------------------------------------
2021-07-23 12:34:15,432 EPOCH 5 done: loss 0.3740 - lr 0.0000300
2021-07-23 12:34:16,810 DEV : loss 0.22535470128059387 - score 0.9652
2021-07-23 12:34:16,826 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:34:19,180 ----------------------------------------------------------------------------------------------------
2021-07-23 12:34:20,530 epoch 6 - iter 6/69 - loss 0.30053852 - samples/sec: 142.45 - lr: 0.000030
2021-07-23 12:34:21,868 epoch 6 - iter 12/69 - loss 0.29927886 - samples/sec: 143.52 - lr: 0.000030
2021-07-23 12:34:23,219 epoch 6 - iter 18/69 - loss 0.29539144 - samples/sec: 142.22 - lr: 0.000030
2021-07-23 12:34:24,632 epoch 6 - iter 24/69 - loss 0.30656469 - samples/sec: 135.92 - lr: 0.000030
2021-07-23 12:34:26,135 epoch 6 - iter 30/69 - loss 0.31523208 - samples/sec: 127.80 - lr: 0.000030
2021-07-23 12:34:27,472 epoch 6 - iter 36/69 - loss 0.30913062 - samples/sec: 143.67 - lr: 0.000030
2021-07-23 12:34:28,867 epoch 6 - iter 42/69 - loss 0.31143998 - samples/sec: 137.64 - lr: 0.000030
2021-07-23 12:34:30,178 epoch 6 - iter 48/69 - loss 0.30700286 - samples/sec: 146.53 - lr: 0.000030
2021-07-23 12:34:31,593 epoch 6 - iter 54/69 - loss 0.30579860 - samples/sec: 135.74 - lr: 0.000030
2021-07-23 12:34:32,970 epoch 6 - iter 60/69 - loss 0.29914758 - samples/sec: 139.55 - lr: 0.000030
2021-07-23 12:34:34,399 epoch 6 - iter 66/69 - loss 0.29532052 - samples/sec: 134.34 - lr: 0.000030
2021-07-23 12:34:34,981 ----------------------------------------------------------------------------------------------------
2021-07-23 12:34:34,982 EPOCH 6 done: loss 0.2920 - lr 0.0000300
2021-07-23 12:34:36,362 DEV : loss 0.16791918873786926 - score 0.977
2021-07-23 12:34:36,377 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:34:38,604 ----------------------------------------------------------------------------------------------------
2021-07-23 12:34:39,899 epoch 7 - iter 6/69 - loss 0.25427289 - samples/sec: 148.53 - lr: 0.000030
2021-07-23 12:34:41,305 epoch 7 - iter 12/69 - loss 0.27484897 - samples/sec: 136.60 - lr: 0.000030
2021-07-23 12:34:42,719 epoch 7 - iter 18/69 - loss 0.26339178 - samples/sec: 135.83 - lr: 0.000030
2021-07-23 12:34:44,156 epoch 7 - iter 24/69 - loss 0.25264704 - samples/sec: 133.65 - lr: 0.000030
2021-07-23 12:34:45,472 epoch 7 - iter 30/69 - loss 0.24598166 - samples/sec: 145.98 - lr: 0.000030
2021-07-23 12:34:46,840 epoch 7 - iter 36/69 - loss 0.25453515 - samples/sec: 140.39 - lr: 0.000030
2021-07-23 12:34:48,223 epoch 7 - iter 42/69 - loss 0.26004266 - samples/sec: 138.88 - lr: 0.000030
2021-07-23 12:34:49,568 epoch 7 - iter 48/69 - loss 0.25935767 - samples/sec: 142.83 - lr: 0.000030
2021-07-23 12:34:50,965 epoch 7 - iter 54/69 - loss 0.25623345 - samples/sec: 137.50 - lr: 0.000030
2021-07-23 12:34:52,315 epoch 7 - iter 60/69 - loss 0.25292655 - samples/sec: 142.23 - lr: 0.000030
2021-07-23 12:34:53,780 epoch 7 - iter 66/69 - loss 0.25622165 - samples/sec: 131.09 - lr: 0.000030
2021-07-23 12:34:54,358 ----------------------------------------------------------------------------------------------------
2021-07-23 12:34:54,358 EPOCH 7 done: loss 0.2552 - lr 0.0000300
2021-07-23 12:34:55,738 DEV : loss 0.13565783202648163 - score 0.9805
2021-07-23 12:34:55,753 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:34:57,860 ----------------------------------------------------------------------------------------------------
2021-07-23 12:34:59,249 epoch 8 - iter 6/69 - loss 0.20304611 - samples/sec: 138.47 - lr: 0.000030
2021-07-23 12:35:00,663 epoch 8 - iter 12/69 - loss 0.22751108 - samples/sec: 135.81 - lr: 0.000030
2021-07-23 12:35:02,029 epoch 8 - iter 18/69 - loss 0.24086782 - samples/sec: 140.62 - lr: 0.000030
2021-07-23 12:35:03,328 epoch 8 - iter 24/69 - loss 0.22702038 - samples/sec: 147.81 - lr: 0.000030
2021-07-23 12:35:04,733 epoch 8 - iter 30/69 - loss 0.22737273 - samples/sec: 136.79 - lr: 0.000030
2021-07-23 12:35:06,027 epoch 8 - iter 36/69 - loss 0.22544860 - samples/sec: 148.36 - lr: 0.000030
2021-07-23 12:35:07,488 epoch 8 - iter 42/69 - loss 0.22482647 - samples/sec: 131.53 - lr: 0.000030
2021-07-23 12:35:08,909 epoch 8 - iter 48/69 - loss 0.22479718 - samples/sec: 135.17 - lr: 0.000030
2021-07-23 12:35:10,244 epoch 8 - iter 54/69 - loss 0.22298945 - samples/sec: 143.80 - lr: 0.000030
2021-07-23 12:35:11,632 epoch 8 - iter 60/69 - loss 0.21895843 - samples/sec: 138.44 - lr: 0.000030
2021-07-23 12:35:13,076 epoch 8 - iter 66/69 - loss 0.22253994 - samples/sec: 133.02 - lr: 0.000030
2021-07-23 12:35:13,646 ----------------------------------------------------------------------------------------------------
2021-07-23 12:35:13,646 EPOCH 8 done: loss 0.2222 - lr 0.0000300
2021-07-23 12:35:15,026 DEV : loss 0.10887017101049423 - score 0.9841
2021-07-23 12:35:15,042 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:35:17,305 ----------------------------------------------------------------------------------------------------
2021-07-23 12:35:18,680 epoch 9 - iter 6/69 - loss 0.20207554 - samples/sec: 139.87 - lr: 0.000030
2021-07-23 12:35:20,032 epoch 9 - iter 12/69 - loss 0.19903921 - samples/sec: 142.05 - lr: 0.000030
2021-07-23 12:35:21,365 epoch 9 - iter 18/69 - loss 0.18821794 - samples/sec: 144.11 - lr: 0.000030
2021-07-23 12:35:22,757 epoch 9 - iter 24/69 - loss 0.20363680 - samples/sec: 138.03 - lr: 0.000030
2021-07-23 12:35:24,132 epoch 9 - iter 30/69 - loss 0.20990014 - samples/sec: 139.61 - lr: 0.000030
2021-07-23 12:35:25,472 epoch 9 - iter 36/69 - loss 0.20354907 - samples/sec: 143.36 - lr: 0.000030
2021-07-23 12:35:26,931 epoch 9 - iter 42/69 - loss 0.20671202 - samples/sec: 131.65 - lr: 0.000030
2021-07-23 12:35:28,308 epoch 9 - iter 48/69 - loss 0.20504824 - samples/sec: 139.45 - lr: 0.000030
2021-07-23 12:35:29,788 epoch 9 - iter 54/69 - loss 0.20769755 - samples/sec: 129.81 - lr: 0.000030
2021-07-23 12:35:31,160 epoch 9 - iter 60/69 - loss 0.21345481 - samples/sec: 140.03 - lr: 0.000030
2021-07-23 12:35:32,569 epoch 9 - iter 66/69 - loss 0.20953448 - samples/sec: 136.28 - lr: 0.000030
2021-07-23 12:35:33,182 ----------------------------------------------------------------------------------------------------
2021-07-23 12:35:33,182 EPOCH 9 done: loss 0.2085 - lr 0.0000300
2021-07-23 12:35:34,667 DEV : loss 0.09691076725721359 - score 0.9852
2021-07-23 12:35:34,682 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:35:36,806 ----------------------------------------------------------------------------------------------------
2021-07-23 12:35:38,200 epoch 10 - iter 6/69 - loss 0.17112034 - samples/sec: 137.93 - lr: 0.000030
2021-07-23 12:35:39,565 epoch 10 - iter 12/69 - loss 0.15966134 - samples/sec: 140.78 - lr: 0.000030
2021-07-23 12:35:40,904 epoch 10 - iter 18/69 - loss 0.20471656 - samples/sec: 143.35 - lr: 0.000030
2021-07-23 12:35:42,329 epoch 10 - iter 24/69 - loss 0.18990811 - samples/sec: 134.84 - lr: 0.000030
2021-07-23 12:35:43,744 epoch 10 - iter 30/69 - loss 0.18778523 - samples/sec: 135.68 - lr: 0.000030
2021-07-23 12:35:45,124 epoch 10 - iter 36/69 - loss 0.18104492 - samples/sec: 139.21 - lr: 0.000030
2021-07-23 12:35:46,548 epoch 10 - iter 42/69 - loss 0.18709912 - samples/sec: 134.94 - lr: 0.000030
2021-07-23 12:35:47,976 epoch 10 - iter 48/69 - loss 0.18675103 - samples/sec: 134.50 - lr: 0.000030
2021-07-23 12:35:49,376 epoch 10 - iter 54/69 - loss 0.18452880 - samples/sec: 137.20 - lr: 0.000030
2021-07-23 12:35:50,767 epoch 10 - iter 60/69 - loss 0.18075276 - samples/sec: 138.06 - lr: 0.000030
2021-07-23 12:35:52,159 epoch 10 - iter 66/69 - loss 0.18338095 - samples/sec: 137.98 - lr: 0.000030
2021-07-23 12:35:52,691 ----------------------------------------------------------------------------------------------------
2021-07-23 12:35:52,691 EPOCH 10 done: loss 0.1847 - lr 0.0000300
2021-07-23 12:35:54,061 DEV : loss 0.08774067461490631 - score 0.9852
2021-07-23 12:35:54,076 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:35:56,286 ----------------------------------------------------------------------------------------------------
2021-07-23 12:35:57,700 epoch 11 - iter 6/69 - loss 0.17925418 - samples/sec: 135.96 - lr: 0.000030
2021-07-23 12:35:59,192 epoch 11 - iter 12/69 - loss 0.19127050 - samples/sec: 128.78 - lr: 0.000030
2021-07-23 12:36:00,556 epoch 11 - iter 18/69 - loss 0.19521317 - samples/sec: 140.76 - lr: 0.000030
2021-07-23 12:36:01,927 epoch 11 - iter 24/69 - loss 0.18511651 - samples/sec: 140.10 - lr: 0.000030
2021-07-23 12:36:03,347 epoch 11 - iter 30/69 - loss 0.18385488 - samples/sec: 135.24 - lr: 0.000030
2021-07-23 12:36:04,753 epoch 11 - iter 36/69 - loss 0.17967407 - samples/sec: 136.66 - lr: 0.000030
2021-07-23 12:36:06,112 epoch 11 - iter 42/69 - loss 0.17380333 - samples/sec: 141.26 - lr: 0.000030
2021-07-23 12:36:07,521 epoch 11 - iter 48/69 - loss 0.17254375 - samples/sec: 136.38 - lr: 0.000030
2021-07-23 12:36:08,874 epoch 11 - iter 54/69 - loss 0.17053180 - samples/sec: 141.98 - lr: 0.000030
2021-07-23 12:36:10,208 epoch 11 - iter 60/69 - loss 0.16902099 - samples/sec: 143.98 - lr: 0.000030
2021-07-23 12:36:11,587 epoch 11 - iter 66/69 - loss 0.16523363 - samples/sec: 139.23 - lr: 0.000030
2021-07-23 12:36:12,163 ----------------------------------------------------------------------------------------------------
2021-07-23 12:36:12,164 EPOCH 11 done: loss 0.1672 - lr 0.0000300
2021-07-23 12:36:13,541 DEV : loss 0.08108826726675034 - score 0.9852
2021-07-23 12:36:13,557 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:36:15,809 ----------------------------------------------------------------------------------------------------
2021-07-23 12:36:17,200 epoch 12 - iter 6/69 - loss 0.15668888 - samples/sec: 138.33 - lr: 0.000030
2021-07-23 12:36:18,529 epoch 12 - iter 12/69 - loss 0.14813507 - samples/sec: 144.46 - lr: 0.000030
2021-07-23 12:36:19,961 epoch 12 - iter 18/69 - loss 0.16165824 - samples/sec: 134.18 - lr: 0.000030
2021-07-23 12:36:21,239 epoch 12 - iter 24/69 - loss 0.16927674 - samples/sec: 150.24 - lr: 0.000030
2021-07-23 12:36:22,657 epoch 12 - iter 30/69 - loss 0.17368550 - samples/sec: 135.41 - lr: 0.000030
2021-07-23 12:36:24,051 epoch 12 - iter 36/69 - loss 0.16583323 - samples/sec: 137.86 - lr: 0.000030
2021-07-23 12:36:25,475 epoch 12 - iter 42/69 - loss 0.15884859 - samples/sec: 134.80 - lr: 0.000030
2021-07-23 12:36:26,923 epoch 12 - iter 48/69 - loss 0.15700318 - samples/sec: 132.65 - lr: 0.000030
2021-07-23 12:36:28,235 epoch 12 - iter 54/69 - loss 0.15471737 - samples/sec: 146.49 - lr: 0.000030
2021-07-23 12:36:29,549 epoch 12 - iter 60/69 - loss 0.15359817 - samples/sec: 146.13 - lr: 0.000030
2021-07-23 12:36:31,008 epoch 12 - iter 66/69 - loss 0.15290526 - samples/sec: 131.64 - lr: 0.000030
2021-07-23 12:36:31,586 ----------------------------------------------------------------------------------------------------
2021-07-23 12:36:31,586 EPOCH 12 done: loss 0.1545 - lr 0.0000300
2021-07-23 12:36:32,961 DEV : loss 0.07581523805856705 - score 0.9841
2021-07-23 12:36:32,976 BAD EPOCHS (no improvement): 1
2021-07-23 12:36:32,976 ----------------------------------------------------------------------------------------------------
2021-07-23 12:36:34,412 epoch 13 - iter 6/69 - loss 0.13714938 - samples/sec: 133.89 - lr: 0.000030
2021-07-23 12:36:35,848 epoch 13 - iter 12/69 - loss 0.15248114 - samples/sec: 133.75 - lr: 0.000030
2021-07-23 12:36:37,227 epoch 13 - iter 18/69 - loss 0.16080612 - samples/sec: 139.23 - lr: 0.000030
2021-07-23 12:36:38,551 epoch 13 - iter 24/69 - loss 0.16363508 - samples/sec: 145.16 - lr: 0.000030
2021-07-23 12:36:39,888 epoch 13 - iter 30/69 - loss 0.15687741 - samples/sec: 143.59 - lr: 0.000030
2021-07-23 12:36:41,235 epoch 13 - iter 36/69 - loss 0.14819544 - samples/sec: 142.61 - lr: 0.000030
2021-07-23 12:36:42,653 epoch 13 - iter 42/69 - loss 0.14384991 - samples/sec: 135.44 - lr: 0.000030
2021-07-23 12:36:44,063 epoch 13 - iter 48/69 - loss 0.15029677 - samples/sec: 136.22 - lr: 0.000030
2021-07-23 12:36:45,436 epoch 13 - iter 54/69 - loss 0.14827877 - samples/sec: 139.97 - lr: 0.000030
2021-07-23 12:36:46,811 epoch 13 - iter 60/69 - loss 0.14523713 - samples/sec: 139.65 - lr: 0.000030
2021-07-23 12:36:48,164 epoch 13 - iter 66/69 - loss 0.14557703 - samples/sec: 141.94 - lr: 0.000030
2021-07-23 12:36:48,730 ----------------------------------------------------------------------------------------------------
2021-07-23 12:36:48,730 EPOCH 13 done: loss 0.1483 - lr 0.0000300
2021-07-23 12:36:50,103 DEV : loss 0.07222457230091095 - score 0.9841
2021-07-23 12:36:50,119 BAD EPOCHS (no improvement): 2
2021-07-23 12:36:50,119 ----------------------------------------------------------------------------------------------------
2021-07-23 12:36:51,491 epoch 14 - iter 6/69 - loss 0.15323679 - samples/sec: 140.04 - lr: 0.000030
2021-07-23 12:36:52,885 epoch 14 - iter 12/69 - loss 0.15208157 - samples/sec: 137.82 - lr: 0.000030
2021-07-23 12:36:54,251 epoch 14 - iter 18/69 - loss 0.14147290 - samples/sec: 140.65 - lr: 0.000030
2021-07-23 12:36:55,635 epoch 14 - iter 24/69 - loss 0.13425813 - samples/sec: 138.73 - lr: 0.000030
2021-07-23 12:36:57,000 epoch 14 - iter 30/69 - loss 0.14783593 - samples/sec: 140.76 - lr: 0.000030
2021-07-23 12:36:58,380 epoch 14 - iter 36/69 - loss 0.14566090 - samples/sec: 139.11 - lr: 0.000030
2021-07-23 12:36:59,779 epoch 14 - iter 42/69 - loss 0.14370702 - samples/sec: 137.36 - lr: 0.000030
2021-07-23 12:37:01,084 epoch 14 - iter 48/69 - loss 0.14599731 - samples/sec: 147.19 - lr: 0.000030
2021-07-23 12:37:02,558 epoch 14 - iter 54/69 - loss 0.14490151 - samples/sec: 130.30 - lr: 0.000030
2021-07-23 12:37:03,997 epoch 14 - iter 60/69 - loss 0.14528898 - samples/sec: 133.43 - lr: 0.000030
2021-07-23 12:37:05,361 epoch 14 - iter 66/69 - loss 0.14159632 - samples/sec: 140.82 - lr: 0.000030
2021-07-23 12:37:05,931 ----------------------------------------------------------------------------------------------------
2021-07-23 12:37:05,931 EPOCH 14 done: loss 0.1400 - lr 0.0000300
2021-07-23 12:37:07,304 DEV : loss 0.06907631456851959 - score 0.9829
2021-07-23 12:37:07,319 BAD EPOCHS (no improvement): 3
2021-07-23 12:37:07,319 ----------------------------------------------------------------------------------------------------
2021-07-23 12:37:08,755 epoch 15 - iter 6/69 - loss 0.11806323 - samples/sec: 133.81 - lr: 0.000030
2021-07-23 12:37:10,105 epoch 15 - iter 12/69 - loss 0.14169143 - samples/sec: 142.36 - lr: 0.000030
2021-07-23 12:37:11,560 epoch 15 - iter 18/69 - loss 0.16283096 - samples/sec: 132.01 - lr: 0.000030
2021-07-23 12:37:13,125 epoch 15 - iter 24/69 - loss 0.15073572 - samples/sec: 122.69 - lr: 0.000030
2021-07-23 12:37:14,493 epoch 15 - iter 30/69 - loss 0.15525478 - samples/sec: 140.45 - lr: 0.000030
2021-07-23 12:37:15,896 epoch 15 - iter 36/69 - loss 0.14913515 - samples/sec: 136.90 - lr: 0.000030
2021-07-23 12:37:17,231 epoch 15 - iter 42/69 - loss 0.14706501 - samples/sec: 143.84 - lr: 0.000030
2021-07-23 12:37:18,636 epoch 15 - iter 48/69 - loss 0.14665556 - samples/sec: 136.76 - lr: 0.000030
2021-07-23 12:37:19,991 epoch 15 - iter 54/69 - loss 0.14359355 - samples/sec: 141.76 - lr: 0.000030
2021-07-23 12:37:21,392 epoch 15 - iter 60/69 - loss 0.13963553 - samples/sec: 137.03 - lr: 0.000030
2021-07-23 12:37:22,713 epoch 15 - iter 66/69 - loss 0.13745299 - samples/sec: 145.48 - lr: 0.000030
2021-07-23 12:37:23,296 ----------------------------------------------------------------------------------------------------
2021-07-23 12:37:23,296 EPOCH 15 done: loss 0.1409 - lr 0.0000300
2021-07-23 12:37:24,668 DEV : loss 0.06569197028875351 - score 0.9852
2021-07-23 12:37:24,684 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:37:27,075 ----------------------------------------------------------------------------------------------------
2021-07-23 12:37:28,482 epoch 16 - iter 6/69 - loss 0.11787224 - samples/sec: 136.69 - lr: 0.000030
2021-07-23 12:37:29,857 epoch 16 - iter 12/69 - loss 0.12426317 - samples/sec: 139.71 - lr: 0.000030
2021-07-23 12:37:31,147 epoch 16 - iter 18/69 - loss 0.12001806 - samples/sec: 148.87 - lr: 0.000030
2021-07-23 12:37:32,630 epoch 16 - iter 24/69 - loss 0.13687117 - samples/sec: 129.49 - lr: 0.000030
2021-07-23 12:37:33,997 epoch 16 - iter 30/69 - loss 0.14723529 - samples/sec: 140.54 - lr: 0.000030
2021-07-23 12:37:35,377 epoch 16 - iter 36/69 - loss 0.13892450 - samples/sec: 139.15 - lr: 0.000030
2021-07-23 12:37:36,697 epoch 16 - iter 42/69 - loss 0.13547547 - samples/sec: 145.52 - lr: 0.000030
2021-07-23 12:37:38,106 epoch 16 - iter 48/69 - loss 0.13449919 - samples/sec: 136.29 - lr: 0.000030
2021-07-23 12:37:39,585 epoch 16 - iter 54/69 - loss 0.13714071 - samples/sec: 129.91 - lr: 0.000030
2021-07-23 12:37:40,931 epoch 16 - iter 60/69 - loss 0.13549455 - samples/sec: 142.73 - lr: 0.000030
2021-07-23 12:37:42,340 epoch 16 - iter 66/69 - loss 0.13092858 - samples/sec: 136.27 - lr: 0.000030
2021-07-23 12:37:42,954 ----------------------------------------------------------------------------------------------------
2021-07-23 12:37:42,955 EPOCH 16 done: loss 0.1307 - lr 0.0000300
2021-07-23 12:37:44,326 DEV : loss 0.06332091242074966 - score 0.9853
2021-07-23 12:37:44,341 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:37:46,793 ----------------------------------------------------------------------------------------------------
2021-07-23 12:37:48,289 epoch 17 - iter 6/69 - loss 0.14121801 - samples/sec: 128.54 - lr: 0.000030
2021-07-23 12:37:49,663 epoch 17 - iter 12/69 - loss 0.14007246 - samples/sec: 139.74 - lr: 0.000030
2021-07-23 12:37:51,126 epoch 17 - iter 18/69 - loss 0.12422344 - samples/sec: 131.35 - lr: 0.000030
2021-07-23 12:37:52,552 epoch 17 - iter 24/69 - loss 0.12813502 - samples/sec: 134.67 - lr: 0.000030
2021-07-23 12:37:53,903 epoch 17 - iter 30/69 - loss 0.13133961 - samples/sec: 142.16 - lr: 0.000030
2021-07-23 12:37:55,300 epoch 17 - iter 36/69 - loss 0.13048088 - samples/sec: 137.52 - lr: 0.000030
2021-07-23 12:37:56,668 epoch 17 - iter 42/69 - loss 0.12774870 - samples/sec: 140.38 - lr: 0.000030
2021-07-23 12:37:58,024 epoch 17 - iter 48/69 - loss 0.12778912 - samples/sec: 141.60 - lr: 0.000030
2021-07-23 12:37:59,400 epoch 17 - iter 54/69 - loss 0.12746263 - samples/sec: 139.60 - lr: 0.000030
2021-07-23 12:38:00,816 epoch 17 - iter 60/69 - loss 0.12688360 - samples/sec: 135.62 - lr: 0.000030
2021-07-23 12:38:02,167 epoch 17 - iter 66/69 - loss 0.12543819 - samples/sec: 142.19 - lr: 0.000030
2021-07-23 12:38:02,694 ----------------------------------------------------------------------------------------------------
2021-07-23 12:38:02,694 EPOCH 17 done: loss 0.1321 - lr 0.0000300
2021-07-23 12:38:04,066 DEV : loss 0.06145317852497101 - score 0.9864
2021-07-23 12:38:04,081 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:38:06,315 ----------------------------------------------------------------------------------------------------
2021-07-23 12:38:07,751 epoch 18 - iter 6/69 - loss 0.15724602 - samples/sec: 133.87 - lr: 0.000030
2021-07-23 12:38:09,089 epoch 18 - iter 12/69 - loss 0.14424460 - samples/sec: 143.62 - lr: 0.000030
2021-07-23 12:38:10,505 epoch 18 - iter 18/69 - loss 0.13445074 - samples/sec: 135.66 - lr: 0.000030
2021-07-23 12:38:11,887 epoch 18 - iter 24/69 - loss 0.14155507 - samples/sec: 138.91 - lr: 0.000030
2021-07-23 12:38:13,259 epoch 18 - iter 30/69 - loss 0.13800199 - samples/sec: 140.04 - lr: 0.000030
2021-07-23 12:38:14,568 epoch 18 - iter 36/69 - loss 0.13260942 - samples/sec: 146.76 - lr: 0.000030
2021-07-23 12:38:15,928 epoch 18 - iter 42/69 - loss 0.12985321 - samples/sec: 141.22 - lr: 0.000030
2021-07-23 12:38:17,413 epoch 18 - iter 48/69 - loss 0.13092753 - samples/sec: 129.28 - lr: 0.000030
2021-07-23 12:38:18,881 epoch 18 - iter 54/69 - loss 0.12633419 - samples/sec: 130.89 - lr: 0.000030
2021-07-23 12:38:20,211 epoch 18 - iter 60/69 - loss 0.12297637 - samples/sec: 144.44 - lr: 0.000030
2021-07-23 12:38:21,464 epoch 18 - iter 66/69 - loss 0.11949434 - samples/sec: 153.25 - lr: 0.000030
2021-07-23 12:38:22,099 ----------------------------------------------------------------------------------------------------
2021-07-23 12:38:22,099 EPOCH 18 done: loss 0.1186 - lr 0.0000300
2021-07-23 12:38:23,473 DEV : loss 0.06090543046593666 - score 0.9852
2021-07-23 12:38:23,488 BAD EPOCHS (no improvement): 1
2021-07-23 12:38:23,489 ----------------------------------------------------------------------------------------------------
2021-07-23 12:38:24,833 epoch 19 - iter 6/69 - loss 0.11681229 - samples/sec: 142.95 - lr: 0.000030
2021-07-23 12:38:26,060 epoch 19 - iter 12/69 - loss 0.12136955 - samples/sec: 156.59 - lr: 0.000030
2021-07-23 12:38:27,430 epoch 19 - iter 18/69 - loss 0.10564354 - samples/sec: 140.14 - lr: 0.000030
2021-07-23 12:38:28,791 epoch 19 - iter 24/69 - loss 0.11327381 - samples/sec: 141.16 - lr: 0.000030
2021-07-23 12:38:30,121 epoch 19 - iter 30/69 - loss 0.11279447 - samples/sec: 144.41 - lr: 0.000030
2021-07-23 12:38:31,523 epoch 19 - iter 36/69 - loss 0.11792381 - samples/sec: 136.97 - lr: 0.000030
2021-07-23 12:38:32,924 epoch 19 - iter 42/69 - loss 0.11973087 - samples/sec: 137.17 - lr: 0.000030
2021-07-23 12:38:34,308 epoch 19 - iter 48/69 - loss 0.11424584 - samples/sec: 138.79 - lr: 0.000030
2021-07-23 12:38:35,701 epoch 19 - iter 54/69 - loss 0.12016605 - samples/sec: 137.86 - lr: 0.000030
2021-07-23 12:38:37,188 epoch 19 - iter 60/69 - loss 0.12244824 - samples/sec: 129.13 - lr: 0.000030
2021-07-23 12:38:38,677 epoch 19 - iter 66/69 - loss 0.11966663 - samples/sec: 128.97 - lr: 0.000030
2021-07-23 12:38:39,266 ----------------------------------------------------------------------------------------------------
2021-07-23 12:38:39,267 EPOCH 19 done: loss 0.1195 - lr 0.0000300
2021-07-23 12:38:40,639 DEV : loss 0.057663027197122574 - score 0.9852
2021-07-23 12:38:40,654 BAD EPOCHS (no improvement): 2
2021-07-23 12:38:40,655 ----------------------------------------------------------------------------------------------------
2021-07-23 12:38:42,089 epoch 20 - iter 6/69 - loss 0.07562289 - samples/sec: 133.99 - lr: 0.000030
2021-07-23 12:38:43,381 epoch 20 - iter 12/69 - loss 0.11749310 - samples/sec: 148.73 - lr: 0.000030
2021-07-23 12:38:44,771 epoch 20 - iter 18/69 - loss 0.10176422 - samples/sec: 138.17 - lr: 0.000030
2021-07-23 12:38:46,204 epoch 20 - iter 24/69 - loss 0.10021506 - samples/sec: 134.02 - lr: 0.000030
2021-07-23 12:38:47,583 epoch 20 - iter 30/69 - loss 0.09826364 - samples/sec: 139.22 - lr: 0.000030
2021-07-23 12:38:48,983 epoch 20 - iter 36/69 - loss 0.09802151 - samples/sec: 137.23 - lr: 0.000030
2021-07-23 12:38:50,364 epoch 20 - iter 42/69 - loss 0.09835468 - samples/sec: 139.13 - lr: 0.000030
2021-07-23 12:38:51,792 epoch 20 - iter 48/69 - loss 0.10203014 - samples/sec: 134.51 - lr: 0.000030
2021-07-23 12:38:53,148 epoch 20 - iter 54/69 - loss 0.10465937 - samples/sec: 141.56 - lr: 0.000030
2021-07-23 12:38:54,506 epoch 20 - iter 60/69 - loss 0.10517686 - samples/sec: 141.50 - lr: 0.000030
2021-07-23 12:38:55,808 epoch 20 - iter 66/69 - loss 0.10764725 - samples/sec: 147.49 - lr: 0.000030
2021-07-23 12:38:56,438 ----------------------------------------------------------------------------------------------------
2021-07-23 12:38:56,438 EPOCH 20 done: loss 0.1105 - lr 0.0000300
2021-07-23 12:38:57,807 DEV : loss 0.05620685964822769 - score 0.9853
2021-07-23 12:38:57,822 BAD EPOCHS (no improvement): 3
2021-07-23 12:38:57,822 ----------------------------------------------------------------------------------------------------
2021-07-23 12:38:59,213 epoch 21 - iter 6/69 - loss 0.13255037 - samples/sec: 138.18 - lr: 0.000030
2021-07-23 12:39:00,675 epoch 21 - iter 12/69 - loss 0.13795826 - samples/sec: 131.40 - lr: 0.000030
2021-07-23 12:39:02,121 epoch 21 - iter 18/69 - loss 0.12078017 - samples/sec: 132.78 - lr: 0.000030
2021-07-23 12:39:03,495 epoch 21 - iter 24/69 - loss 0.11307206 - samples/sec: 139.78 - lr: 0.000030
2021-07-23 12:39:04,873 epoch 21 - iter 30/69 - loss 0.10991136 - samples/sec: 139.43 - lr: 0.000030
2021-07-23 12:39:06,260 epoch 21 - iter 36/69 - loss 0.10741380 - samples/sec: 138.43 - lr: 0.000030
2021-07-23 12:39:07,671 epoch 21 - iter 42/69 - loss 0.10531092 - samples/sec: 136.16 - lr: 0.000030
2021-07-23 12:39:09,020 epoch 21 - iter 48/69 - loss 0.10453826 - samples/sec: 142.37 - lr: 0.000030
2021-07-23 12:39:10,397 epoch 21 - iter 54/69 - loss 0.10263641 - samples/sec: 139.46 - lr: 0.000030
2021-07-23 12:39:11,785 epoch 21 - iter 60/69 - loss 0.10230292 - samples/sec: 138.40 - lr: 0.000030
2021-07-23 12:39:13,169 epoch 21 - iter 66/69 - loss 0.10158647 - samples/sec: 138.84 - lr: 0.000030
2021-07-23 12:39:13,727 ----------------------------------------------------------------------------------------------------
2021-07-23 12:39:13,727 EPOCH 21 done: loss 0.1046 - lr 0.0000300
2021-07-23 12:39:15,101 DEV : loss 0.05516574904322624 - score 0.9852
Epoch    21: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 12:39:15,116 BAD EPOCHS (no improvement): 4
2021-07-23 12:39:15,117 ----------------------------------------------------------------------------------------------------
2021-07-23 12:39:16,520 epoch 22 - iter 6/69 - loss 0.07483753 - samples/sec: 136.95 - lr: 0.000015
2021-07-23 12:39:17,875 epoch 22 - iter 12/69 - loss 0.07905728 - samples/sec: 141.75 - lr: 0.000015
2021-07-23 12:39:19,312 epoch 22 - iter 18/69 - loss 0.08588261 - samples/sec: 133.66 - lr: 0.000015
2021-07-23 12:39:20,728 epoch 22 - iter 24/69 - loss 0.08594510 - samples/sec: 135.61 - lr: 0.000015
2021-07-23 12:39:22,049 epoch 22 - iter 30/69 - loss 0.08786809 - samples/sec: 145.50 - lr: 0.000015
2021-07-23 12:39:23,414 epoch 22 - iter 36/69 - loss 0.08566535 - samples/sec: 140.65 - lr: 0.000015
2021-07-23 12:39:24,783 epoch 22 - iter 42/69 - loss 0.08839269 - samples/sec: 140.31 - lr: 0.000015
2021-07-23 12:39:26,167 epoch 22 - iter 48/69 - loss 0.08790975 - samples/sec: 138.76 - lr: 0.000015
2021-07-23 12:39:27,543 epoch 22 - iter 54/69 - loss 0.09176589 - samples/sec: 139.59 - lr: 0.000015
2021-07-23 12:39:28,936 epoch 22 - iter 60/69 - loss 0.09586811 - samples/sec: 137.94 - lr: 0.000015
2021-07-23 12:39:30,309 epoch 22 - iter 66/69 - loss 0.09507203 - samples/sec: 139.84 - lr: 0.000015
2021-07-23 12:39:30,906 ----------------------------------------------------------------------------------------------------
2021-07-23 12:39:30,907 EPOCH 22 done: loss 0.0999 - lr 0.0000150
2021-07-23 12:39:32,274 DEV : loss 0.05377744883298874 - score 0.9853
2021-07-23 12:39:32,290 BAD EPOCHS (no improvement): 1
2021-07-23 12:39:32,290 ----------------------------------------------------------------------------------------------------
2021-07-23 12:39:33,665 epoch 23 - iter 6/69 - loss 0.11142638 - samples/sec: 139.75 - lr: 0.000015
2021-07-23 12:39:35,062 epoch 23 - iter 12/69 - loss 0.11533390 - samples/sec: 137.50 - lr: 0.000015
2021-07-23 12:39:36,371 epoch 23 - iter 18/69 - loss 0.11917206 - samples/sec: 146.78 - lr: 0.000015
2021-07-23 12:39:37,729 epoch 23 - iter 24/69 - loss 0.10620526 - samples/sec: 141.43 - lr: 0.000015
2021-07-23 12:39:39,176 epoch 23 - iter 30/69 - loss 0.10136584 - samples/sec: 132.73 - lr: 0.000015
2021-07-23 12:39:40,524 epoch 23 - iter 36/69 - loss 0.10282360 - samples/sec: 142.47 - lr: 0.000015
2021-07-23 12:39:41,867 epoch 23 - iter 42/69 - loss 0.10378341 - samples/sec: 143.04 - lr: 0.000015
2021-07-23 12:39:43,272 epoch 23 - iter 48/69 - loss 0.10224806 - samples/sec: 136.66 - lr: 0.000015
2021-07-23 12:39:44,632 epoch 23 - iter 54/69 - loss 0.10162497 - samples/sec: 141.32 - lr: 0.000015
2021-07-23 12:39:46,063 epoch 23 - iter 60/69 - loss 0.10655900 - samples/sec: 134.14 - lr: 0.000015
2021-07-23 12:39:47,400 epoch 23 - iter 66/69 - loss 0.10557753 - samples/sec: 143.70 - lr: 0.000015
2021-07-23 12:39:48,028 ----------------------------------------------------------------------------------------------------
2021-07-23 12:39:48,028 EPOCH 23 done: loss 0.1043 - lr 0.0000150
2021-07-23 12:39:49,401 DEV : loss 0.05470617115497589 - score 0.9841
2021-07-23 12:39:49,416 BAD EPOCHS (no improvement): 2
2021-07-23 12:39:49,416 ----------------------------------------------------------------------------------------------------
2021-07-23 12:39:50,860 epoch 24 - iter 6/69 - loss 0.12703772 - samples/sec: 133.13 - lr: 0.000015
2021-07-23 12:39:52,305 epoch 24 - iter 12/69 - loss 0.11988391 - samples/sec: 132.91 - lr: 0.000015
2021-07-23 12:39:53,655 epoch 24 - iter 18/69 - loss 0.12091964 - samples/sec: 142.31 - lr: 0.000015
2021-07-23 12:39:55,046 epoch 24 - iter 24/69 - loss 0.11324176 - samples/sec: 138.10 - lr: 0.000015
2021-07-23 12:39:56,498 epoch 24 - iter 30/69 - loss 0.11354580 - samples/sec: 132.26 - lr: 0.000015
2021-07-23 12:39:57,848 epoch 24 - iter 36/69 - loss 0.11266455 - samples/sec: 142.29 - lr: 0.000015
2021-07-23 12:39:59,204 epoch 24 - iter 42/69 - loss 0.11230796 - samples/sec: 141.64 - lr: 0.000015
2021-07-23 12:40:00,563 epoch 24 - iter 48/69 - loss 0.11118051 - samples/sec: 141.30 - lr: 0.000015
2021-07-23 12:40:01,993 epoch 24 - iter 54/69 - loss 0.11378201 - samples/sec: 134.37 - lr: 0.000015
2021-07-23 12:40:03,279 epoch 24 - iter 60/69 - loss 0.11311860 - samples/sec: 149.32 - lr: 0.000015
2021-07-23 12:40:04,620 epoch 24 - iter 66/69 - loss 0.11263920 - samples/sec: 143.25 - lr: 0.000015
2021-07-23 12:40:05,188 ----------------------------------------------------------------------------------------------------
2021-07-23 12:40:05,188 EPOCH 24 done: loss 0.1139 - lr 0.0000150
2021-07-23 12:40:06,554 DEV : loss 0.05400296300649643 - score 0.9853
2021-07-23 12:40:06,569 BAD EPOCHS (no improvement): 3
2021-07-23 12:40:06,569 ----------------------------------------------------------------------------------------------------
2021-07-23 12:40:08,017 epoch 25 - iter 6/69 - loss 0.08548646 - samples/sec: 132.75 - lr: 0.000015
2021-07-23 12:40:09,377 epoch 25 - iter 12/69 - loss 0.09864349 - samples/sec: 141.23 - lr: 0.000015
2021-07-23 12:40:10,734 epoch 25 - iter 18/69 - loss 0.11073694 - samples/sec: 141.58 - lr: 0.000015
2021-07-23 12:40:12,131 epoch 25 - iter 24/69 - loss 0.10669537 - samples/sec: 137.41 - lr: 0.000015
2021-07-23 12:40:13,524 epoch 25 - iter 30/69 - loss 0.10276902 - samples/sec: 137.97 - lr: 0.000015
2021-07-23 12:40:14,951 epoch 25 - iter 36/69 - loss 0.09911808 - samples/sec: 134.52 - lr: 0.000015
2021-07-23 12:40:16,329 epoch 25 - iter 42/69 - loss 0.10296783 - samples/sec: 139.39 - lr: 0.000015
2021-07-23 12:40:17,692 epoch 25 - iter 48/69 - loss 0.10175792 - samples/sec: 141.00 - lr: 0.000015
2021-07-23 12:40:19,120 epoch 25 - iter 54/69 - loss 0.09911705 - samples/sec: 134.49 - lr: 0.000015
2021-07-23 12:40:20,438 epoch 25 - iter 60/69 - loss 0.09627035 - samples/sec: 145.67 - lr: 0.000015
2021-07-23 12:40:21,796 epoch 25 - iter 66/69 - loss 0.09867053 - samples/sec: 141.43 - lr: 0.000015
2021-07-23 12:40:22,395 ----------------------------------------------------------------------------------------------------
2021-07-23 12:40:22,395 EPOCH 25 done: loss 0.0997 - lr 0.0000150
2021-07-23 12:40:23,759 DEV : loss 0.053025439381599426 - score 0.9853
Epoch    25: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 12:40:23,775 BAD EPOCHS (no improvement): 4
2021-07-23 12:40:23,775 ----------------------------------------------------------------------------------------------------
2021-07-23 12:40:25,100 epoch 26 - iter 6/69 - loss 0.07671066 - samples/sec: 145.00 - lr: 0.000008
2021-07-23 12:40:26,470 epoch 26 - iter 12/69 - loss 0.10307700 - samples/sec: 140.27 - lr: 0.000008
2021-07-23 12:40:27,901 epoch 26 - iter 18/69 - loss 0.10338770 - samples/sec: 134.21 - lr: 0.000008
2021-07-23 12:40:29,325 epoch 26 - iter 24/69 - loss 0.10947836 - samples/sec: 134.85 - lr: 0.000008
2021-07-23 12:40:30,688 epoch 26 - iter 30/69 - loss 0.10076499 - samples/sec: 140.92 - lr: 0.000008
2021-07-23 12:40:32,118 epoch 26 - iter 36/69 - loss 0.09826819 - samples/sec: 134.30 - lr: 0.000008
2021-07-23 12:40:33,516 epoch 26 - iter 42/69 - loss 0.09635221 - samples/sec: 137.45 - lr: 0.000008
2021-07-23 12:40:34,855 epoch 26 - iter 48/69 - loss 0.09367931 - samples/sec: 143.41 - lr: 0.000008
2021-07-23 12:40:36,151 epoch 26 - iter 54/69 - loss 0.09417475 - samples/sec: 148.23 - lr: 0.000008
2021-07-23 12:40:37,613 epoch 26 - iter 60/69 - loss 0.09450143 - samples/sec: 131.33 - lr: 0.000008
2021-07-23 12:40:39,004 epoch 26 - iter 66/69 - loss 0.09429495 - samples/sec: 138.09 - lr: 0.000008
2021-07-23 12:40:39,614 ----------------------------------------------------------------------------------------------------
2021-07-23 12:40:39,614 EPOCH 26 done: loss 0.0935 - lr 0.0000075
2021-07-23 12:40:40,978 DEV : loss 0.05382407456636429 - score 0.9875
2021-07-23 12:40:40,993 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:40:43,205 ----------------------------------------------------------------------------------------------------
2021-07-23 12:40:44,741 epoch 27 - iter 6/69 - loss 0.08318954 - samples/sec: 125.15 - lr: 0.000008
2021-07-23 12:40:46,168 epoch 27 - iter 12/69 - loss 0.08105092 - samples/sec: 134.59 - lr: 0.000008
2021-07-23 12:40:47,589 epoch 27 - iter 18/69 - loss 0.07757424 - samples/sec: 135.20 - lr: 0.000008
2021-07-23 12:40:48,935 epoch 27 - iter 24/69 - loss 0.08050291 - samples/sec: 142.63 - lr: 0.000008
2021-07-23 12:40:50,344 epoch 27 - iter 30/69 - loss 0.09032285 - samples/sec: 136.31 - lr: 0.000008
2021-07-23 12:40:51,643 epoch 27 - iter 36/69 - loss 0.08827808 - samples/sec: 147.90 - lr: 0.000008
2021-07-23 12:40:53,008 epoch 27 - iter 42/69 - loss 0.08848039 - samples/sec: 140.76 - lr: 0.000008
2021-07-23 12:40:54,389 epoch 27 - iter 48/69 - loss 0.08993821 - samples/sec: 139.05 - lr: 0.000008
2021-07-23 12:40:55,801 epoch 27 - iter 54/69 - loss 0.09039598 - samples/sec: 136.02 - lr: 0.000008
2021-07-23 12:40:57,192 epoch 27 - iter 60/69 - loss 0.09700636 - samples/sec: 138.11 - lr: 0.000008
2021-07-23 12:40:58,583 epoch 27 - iter 66/69 - loss 0.09629067 - samples/sec: 138.05 - lr: 0.000008
2021-07-23 12:40:59,163 ----------------------------------------------------------------------------------------------------
2021-07-23 12:40:59,163 EPOCH 27 done: loss 0.0949 - lr 0.0000075
2021-07-23 12:41:00,528 DEV : loss 0.05310749262571335 - score 0.9852
2021-07-23 12:41:00,543 BAD EPOCHS (no improvement): 1
2021-07-23 12:41:00,544 ----------------------------------------------------------------------------------------------------
2021-07-23 12:41:01,919 epoch 28 - iter 6/69 - loss 0.06282349 - samples/sec: 139.78 - lr: 0.000008
2021-07-23 12:41:03,336 epoch 28 - iter 12/69 - loss 0.05740331 - samples/sec: 135.54 - lr: 0.000008
2021-07-23 12:41:04,667 epoch 28 - iter 18/69 - loss 0.07835775 - samples/sec: 144.24 - lr: 0.000008
2021-07-23 12:41:06,053 epoch 28 - iter 24/69 - loss 0.08600697 - samples/sec: 138.60 - lr: 0.000008
2021-07-23 12:41:07,443 epoch 28 - iter 30/69 - loss 0.09056853 - samples/sec: 138.21 - lr: 0.000008
2021-07-23 12:41:08,806 epoch 28 - iter 36/69 - loss 0.08512224 - samples/sec: 140.87 - lr: 0.000008
2021-07-23 12:41:10,127 epoch 28 - iter 42/69 - loss 0.09024204 - samples/sec: 145.47 - lr: 0.000008
2021-07-23 12:41:11,572 epoch 28 - iter 48/69 - loss 0.08767424 - samples/sec: 132.90 - lr: 0.000008
2021-07-23 12:41:12,955 epoch 28 - iter 54/69 - loss 0.08854512 - samples/sec: 138.86 - lr: 0.000008
2021-07-23 12:41:14,372 epoch 28 - iter 60/69 - loss 0.09169947 - samples/sec: 135.52 - lr: 0.000008
2021-07-23 12:41:15,800 epoch 28 - iter 66/69 - loss 0.09376183 - samples/sec: 134.51 - lr: 0.000008
2021-07-23 12:41:16,362 ----------------------------------------------------------------------------------------------------
2021-07-23 12:41:16,362 EPOCH 28 done: loss 0.0936 - lr 0.0000075
2021-07-23 12:41:17,726 DEV : loss 0.05137346312403679 - score 0.9841
2021-07-23 12:41:17,741 BAD EPOCHS (no improvement): 2
2021-07-23 12:41:17,741 ----------------------------------------------------------------------------------------------------
2021-07-23 12:41:19,189 epoch 29 - iter 6/69 - loss 0.09952078 - samples/sec: 132.74 - lr: 0.000008
2021-07-23 12:41:20,635 epoch 29 - iter 12/69 - loss 0.08896003 - samples/sec: 132.85 - lr: 0.000008
2021-07-23 12:41:22,027 epoch 29 - iter 18/69 - loss 0.10272142 - samples/sec: 138.04 - lr: 0.000008
2021-07-23 12:41:23,399 epoch 29 - iter 24/69 - loss 0.09515960 - samples/sec: 139.99 - lr: 0.000008
2021-07-23 12:41:24,821 epoch 29 - iter 30/69 - loss 0.10344348 - samples/sec: 135.04 - lr: 0.000008
2021-07-23 12:41:26,132 epoch 29 - iter 36/69 - loss 0.09874533 - samples/sec: 146.47 - lr: 0.000008
2021-07-23 12:41:27,487 epoch 29 - iter 42/69 - loss 0.09482979 - samples/sec: 141.74 - lr: 0.000008
2021-07-23 12:41:28,828 epoch 29 - iter 48/69 - loss 0.09118310 - samples/sec: 143.26 - lr: 0.000008
2021-07-23 12:41:30,217 epoch 29 - iter 54/69 - loss 0.09209036 - samples/sec: 138.35 - lr: 0.000008
2021-07-23 12:41:31,584 epoch 29 - iter 60/69 - loss 0.09479926 - samples/sec: 140.43 - lr: 0.000008
2021-07-23 12:41:32,983 epoch 29 - iter 66/69 - loss 0.09447701 - samples/sec: 137.27 - lr: 0.000008
2021-07-23 12:41:33,579 ----------------------------------------------------------------------------------------------------
2021-07-23 12:41:33,580 EPOCH 29 done: loss 0.0934 - lr 0.0000075
2021-07-23 12:41:34,948 DEV : loss 0.05184668302536011 - score 0.9852
2021-07-23 12:41:34,963 BAD EPOCHS (no improvement): 3
2021-07-23 12:41:34,963 ----------------------------------------------------------------------------------------------------
2021-07-23 12:41:36,325 epoch 30 - iter 6/69 - loss 0.07950567 - samples/sec: 141.17 - lr: 0.000008
2021-07-23 12:41:37,649 epoch 30 - iter 12/69 - loss 0.09387532 - samples/sec: 145.03 - lr: 0.000008
2021-07-23 12:41:39,069 epoch 30 - iter 18/69 - loss 0.10103107 - samples/sec: 135.27 - lr: 0.000008
2021-07-23 12:41:40,408 epoch 30 - iter 24/69 - loss 0.10818048 - samples/sec: 143.42 - lr: 0.000008
2021-07-23 12:41:41,775 epoch 30 - iter 30/69 - loss 0.10143962 - samples/sec: 140.53 - lr: 0.000008
2021-07-23 12:41:43,227 epoch 30 - iter 36/69 - loss 0.10209402 - samples/sec: 132.25 - lr: 0.000008
2021-07-23 12:41:44,613 epoch 30 - iter 42/69 - loss 0.09989525 - samples/sec: 138.64 - lr: 0.000008
2021-07-23 12:41:46,003 epoch 30 - iter 48/69 - loss 0.10229897 - samples/sec: 138.18 - lr: 0.000008
2021-07-23 12:41:47,464 epoch 30 - iter 54/69 - loss 0.09980340 - samples/sec: 131.41 - lr: 0.000008
2021-07-23 12:41:48,855 epoch 30 - iter 60/69 - loss 0.10171849 - samples/sec: 138.16 - lr: 0.000008
2021-07-23 12:41:50,227 epoch 30 - iter 66/69 - loss 0.10010777 - samples/sec: 139.95 - lr: 0.000008
2021-07-23 12:41:50,831 ----------------------------------------------------------------------------------------------------
2021-07-23 12:41:50,831 EPOCH 30 done: loss 0.0995 - lr 0.0000075
2021-07-23 12:41:52,197 DEV : loss 0.05189374461770058 - score 0.9853
Epoch    30: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 12:41:52,212 BAD EPOCHS (no improvement): 4
2021-07-23 12:41:52,212 ----------------------------------------------------------------------------------------------------
2021-07-23 12:41:53,528 epoch 31 - iter 6/69 - loss 0.11071876 - samples/sec: 146.08 - lr: 0.000004
2021-07-23 12:41:54,939 epoch 31 - iter 12/69 - loss 0.09484556 - samples/sec: 136.10 - lr: 0.000004
2021-07-23 12:41:56,411 epoch 31 - iter 18/69 - loss 0.10377616 - samples/sec: 130.48 - lr: 0.000004
2021-07-23 12:41:57,824 epoch 31 - iter 24/69 - loss 0.09358630 - samples/sec: 135.94 - lr: 0.000004
2021-07-23 12:41:59,171 epoch 31 - iter 30/69 - loss 0.09165849 - samples/sec: 142.67 - lr: 0.000004
2021-07-23 12:42:00,676 epoch 31 - iter 36/69 - loss 0.09249823 - samples/sec: 127.61 - lr: 0.000004
2021-07-23 12:42:02,110 epoch 31 - iter 42/69 - loss 0.09124887 - samples/sec: 133.96 - lr: 0.000004
2021-07-23 12:42:03,470 epoch 31 - iter 48/69 - loss 0.09034954 - samples/sec: 141.21 - lr: 0.000004
2021-07-23 12:42:04,839 epoch 31 - iter 54/69 - loss 0.09179859 - samples/sec: 140.34 - lr: 0.000004
2021-07-23 12:42:06,226 epoch 31 - iter 60/69 - loss 0.09093556 - samples/sec: 138.41 - lr: 0.000004
2021-07-23 12:42:07,520 epoch 31 - iter 66/69 - loss 0.09254990 - samples/sec: 148.52 - lr: 0.000004
2021-07-23 12:42:08,068 ----------------------------------------------------------------------------------------------------
2021-07-23 12:42:08,068 EPOCH 31 done: loss 0.0920 - lr 0.0000038
2021-07-23 12:42:09,436 DEV : loss 0.05231840908527374 - score 0.9864
2021-07-23 12:42:09,451 BAD EPOCHS (no improvement): 1
2021-07-23 12:42:09,451 ----------------------------------------------------------------------------------------------------
2021-07-23 12:42:10,825 epoch 32 - iter 6/69 - loss 0.06689546 - samples/sec: 139.88 - lr: 0.000004
2021-07-23 12:42:12,224 epoch 32 - iter 12/69 - loss 0.10106709 - samples/sec: 137.30 - lr: 0.000004
2021-07-23 12:42:13,611 epoch 32 - iter 18/69 - loss 0.09023050 - samples/sec: 138.51 - lr: 0.000004
2021-07-23 12:42:14,988 epoch 32 - iter 24/69 - loss 0.08807845 - samples/sec: 139.43 - lr: 0.000004
2021-07-23 12:42:16,347 epoch 32 - iter 30/69 - loss 0.08465976 - samples/sec: 141.40 - lr: 0.000004
2021-07-23 12:42:17,753 epoch 32 - iter 36/69 - loss 0.09316699 - samples/sec: 136.55 - lr: 0.000004
2021-07-23 12:42:19,101 epoch 32 - iter 42/69 - loss 0.09702267 - samples/sec: 142.57 - lr: 0.000004
2021-07-23 12:42:20,528 epoch 32 - iter 48/69 - loss 0.09228249 - samples/sec: 134.59 - lr: 0.000004
2021-07-23 12:42:21,924 epoch 32 - iter 54/69 - loss 0.09446060 - samples/sec: 137.58 - lr: 0.000004
2021-07-23 12:42:23,279 epoch 32 - iter 60/69 - loss 0.09225217 - samples/sec: 141.70 - lr: 0.000004
2021-07-23 12:42:24,713 epoch 32 - iter 66/69 - loss 0.09257458 - samples/sec: 133.93 - lr: 0.000004
2021-07-23 12:42:25,314 ----------------------------------------------------------------------------------------------------
2021-07-23 12:42:25,314 EPOCH 32 done: loss 0.0913 - lr 0.0000038
2021-07-23 12:42:26,797 DEV : loss 0.05229724198579788 - score 0.9864
2021-07-23 12:42:26,813 BAD EPOCHS (no improvement): 2
2021-07-23 12:42:26,813 ----------------------------------------------------------------------------------------------------
2021-07-23 12:42:28,211 epoch 33 - iter 6/69 - loss 0.09289874 - samples/sec: 137.48 - lr: 0.000004
2021-07-23 12:42:29,672 epoch 33 - iter 12/69 - loss 0.07579022 - samples/sec: 131.49 - lr: 0.000004
2021-07-23 12:42:31,035 epoch 33 - iter 18/69 - loss 0.07852228 - samples/sec: 140.87 - lr: 0.000004
2021-07-23 12:42:32,446 epoch 33 - iter 24/69 - loss 0.07064729 - samples/sec: 136.16 - lr: 0.000004
2021-07-23 12:42:33,783 epoch 33 - iter 30/69 - loss 0.08529206 - samples/sec: 143.65 - lr: 0.000004
2021-07-23 12:42:35,218 epoch 33 - iter 36/69 - loss 0.08439473 - samples/sec: 133.85 - lr: 0.000004
2021-07-23 12:42:36,540 epoch 33 - iter 42/69 - loss 0.08278694 - samples/sec: 145.25 - lr: 0.000004
2021-07-23 12:42:37,873 epoch 33 - iter 48/69 - loss 0.08845887 - samples/sec: 144.14 - lr: 0.000004
2021-07-23 12:42:39,341 epoch 33 - iter 54/69 - loss 0.09294133 - samples/sec: 130.81 - lr: 0.000004
2021-07-23 12:42:40,705 epoch 33 - iter 60/69 - loss 0.09843272 - samples/sec: 140.84 - lr: 0.000004
2021-07-23 12:42:42,037 epoch 33 - iter 66/69 - loss 0.09653254 - samples/sec: 144.15 - lr: 0.000004
2021-07-23 12:42:42,627 ----------------------------------------------------------------------------------------------------
2021-07-23 12:42:42,627 EPOCH 33 done: loss 0.0965 - lr 0.0000038
2021-07-23 12:42:43,995 DEV : loss 0.05254534259438515 - score 0.9886
2021-07-23 12:42:44,010 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:42:46,277 ----------------------------------------------------------------------------------------------------
2021-07-23 12:42:47,657 epoch 34 - iter 6/69 - loss 0.14303374 - samples/sec: 139.31 - lr: 0.000004
2021-07-23 12:42:49,073 epoch 34 - iter 12/69 - loss 0.12126299 - samples/sec: 135.70 - lr: 0.000004
2021-07-23 12:42:50,460 epoch 34 - iter 18/69 - loss 0.10486653 - samples/sec: 138.41 - lr: 0.000004
2021-07-23 12:42:51,828 epoch 34 - iter 24/69 - loss 0.10505565 - samples/sec: 140.42 - lr: 0.000004
2021-07-23 12:42:53,157 epoch 34 - iter 30/69 - loss 0.09842399 - samples/sec: 144.51 - lr: 0.000004
2021-07-23 12:42:54,528 epoch 34 - iter 36/69 - loss 0.09916152 - samples/sec: 140.15 - lr: 0.000004
2021-07-23 12:42:55,982 epoch 34 - iter 42/69 - loss 0.10199367 - samples/sec: 132.04 - lr: 0.000004
2021-07-23 12:42:57,460 epoch 34 - iter 48/69 - loss 0.09925295 - samples/sec: 129.95 - lr: 0.000004
2021-07-23 12:42:58,832 epoch 34 - iter 54/69 - loss 0.10132976 - samples/sec: 140.07 - lr: 0.000004
2021-07-23 12:43:00,139 epoch 34 - iter 60/69 - loss 0.10006502 - samples/sec: 146.93 - lr: 0.000004
2021-07-23 12:43:01,554 epoch 34 - iter 66/69 - loss 0.10159485 - samples/sec: 135.75 - lr: 0.000004
2021-07-23 12:43:02,169 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:02,170 EPOCH 34 done: loss 0.1020 - lr 0.0000038
2021-07-23 12:43:03,534 DEV : loss 0.051755599677562714 - score 0.9864
2021-07-23 12:43:03,549 BAD EPOCHS (no improvement): 1
2021-07-23 12:43:03,550 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:04,927 epoch 35 - iter 6/69 - loss 0.09615799 - samples/sec: 139.50 - lr: 0.000004
2021-07-23 12:43:06,296 epoch 35 - iter 12/69 - loss 0.08183504 - samples/sec: 140.35 - lr: 0.000004
2021-07-23 12:43:07,651 epoch 35 - iter 18/69 - loss 0.08625929 - samples/sec: 141.76 - lr: 0.000004
2021-07-23 12:43:09,019 epoch 35 - iter 24/69 - loss 0.08992449 - samples/sec: 140.38 - lr: 0.000004
2021-07-23 12:43:10,417 epoch 35 - iter 30/69 - loss 0.08766055 - samples/sec: 137.45 - lr: 0.000004
2021-07-23 12:43:11,722 epoch 35 - iter 36/69 - loss 0.08531143 - samples/sec: 147.12 - lr: 0.000004
2021-07-23 12:43:13,173 epoch 35 - iter 42/69 - loss 0.08689995 - samples/sec: 132.36 - lr: 0.000004
2021-07-23 12:43:14,581 epoch 35 - iter 48/69 - loss 0.08702977 - samples/sec: 136.45 - lr: 0.000004
2021-07-23 12:43:16,002 epoch 35 - iter 54/69 - loss 0.08804280 - samples/sec: 135.12 - lr: 0.000004
2021-07-23 12:43:17,440 epoch 35 - iter 60/69 - loss 0.08689072 - samples/sec: 133.60 - lr: 0.000004
2021-07-23 12:43:18,824 epoch 35 - iter 66/69 - loss 0.08486998 - samples/sec: 138.78 - lr: 0.000004
2021-07-23 12:43:19,360 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:19,360 EPOCH 35 done: loss 0.0840 - lr 0.0000038
2021-07-23 12:43:20,728 DEV : loss 0.05097963660955429 - score 0.9852
2021-07-23 12:43:20,744 BAD EPOCHS (no improvement): 2
2021-07-23 12:43:20,744 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:22,159 epoch 36 - iter 6/69 - loss 0.07289910 - samples/sec: 135.81 - lr: 0.000004
2021-07-23 12:43:23,577 epoch 36 - iter 12/69 - loss 0.09597939 - samples/sec: 135.50 - lr: 0.000004
2021-07-23 12:43:24,894 epoch 36 - iter 18/69 - loss 0.08621058 - samples/sec: 145.78 - lr: 0.000004
2021-07-23 12:43:26,372 epoch 36 - iter 24/69 - loss 0.08609137 - samples/sec: 130.01 - lr: 0.000004
2021-07-23 12:43:27,820 epoch 36 - iter 30/69 - loss 0.08468450 - samples/sec: 132.59 - lr: 0.000004
2021-07-23 12:43:29,184 epoch 36 - iter 36/69 - loss 0.08005573 - samples/sec: 140.88 - lr: 0.000004
2021-07-23 12:43:30,556 epoch 36 - iter 42/69 - loss 0.07841782 - samples/sec: 139.97 - lr: 0.000004
2021-07-23 12:43:31,975 epoch 36 - iter 48/69 - loss 0.08384372 - samples/sec: 135.34 - lr: 0.000004
2021-07-23 12:43:33,319 epoch 36 - iter 54/69 - loss 0.09112152 - samples/sec: 142.91 - lr: 0.000004
2021-07-23 12:43:34,650 epoch 36 - iter 60/69 - loss 0.08805912 - samples/sec: 144.38 - lr: 0.000004
2021-07-23 12:43:36,049 epoch 36 - iter 66/69 - loss 0.08897122 - samples/sec: 137.21 - lr: 0.000004
2021-07-23 12:43:36,611 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:36,611 EPOCH 36 done: loss 0.0930 - lr 0.0000038
2021-07-23 12:43:37,975 DEV : loss 0.0515034943819046 - score 0.9864
2021-07-23 12:43:37,990 BAD EPOCHS (no improvement): 3
2021-07-23 12:43:37,990 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:39,308 epoch 37 - iter 6/69 - loss 0.09262045 - samples/sec: 145.92 - lr: 0.000004
2021-07-23 12:43:40,760 epoch 37 - iter 12/69 - loss 0.09057507 - samples/sec: 132.28 - lr: 0.000004
2021-07-23 12:43:42,169 epoch 37 - iter 18/69 - loss 0.09490088 - samples/sec: 136.25 - lr: 0.000004
2021-07-23 12:43:43,581 epoch 37 - iter 24/69 - loss 0.09610707 - samples/sec: 136.10 - lr: 0.000004
2021-07-23 12:43:45,023 epoch 37 - iter 30/69 - loss 0.10421043 - samples/sec: 133.12 - lr: 0.000004
2021-07-23 12:43:46,315 epoch 37 - iter 36/69 - loss 0.10435122 - samples/sec: 148.74 - lr: 0.000004
2021-07-23 12:43:47,724 epoch 37 - iter 42/69 - loss 0.10229768 - samples/sec: 136.28 - lr: 0.000004
2021-07-23 12:43:49,100 epoch 37 - iter 48/69 - loss 0.10070308 - samples/sec: 139.57 - lr: 0.000004
2021-07-23 12:43:50,488 epoch 37 - iter 54/69 - loss 0.09805605 - samples/sec: 138.38 - lr: 0.000004
2021-07-23 12:43:51,852 epoch 37 - iter 60/69 - loss 0.10024591 - samples/sec: 140.84 - lr: 0.000004
2021-07-23 12:43:53,251 epoch 37 - iter 66/69 - loss 0.09726303 - samples/sec: 137.30 - lr: 0.000004
2021-07-23 12:43:53,836 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:53,836 EPOCH 37 done: loss 0.0973 - lr 0.0000038
2021-07-23 12:43:55,201 DEV : loss 0.05198538675904274 - score 0.9875
Epoch    37: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 12:43:55,216 BAD EPOCHS (no improvement): 4
2021-07-23 12:43:55,217 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:55,217 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:55,217 learning rate too small - quitting training!
2021-07-23 12:43:55,217 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:55,895 ----------------------------------------------------------------------------------------------------
2021-07-23 12:43:55,895 Testing using best model ...
2021-07-23 12:43:55,896 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/nld.rst.nldt/best-model.pt
2021-07-23 12:44:05,662 0.9714	0.9866	0.9790
2021-07-23 12:44:05,662 
Results:
- F1-score (micro) 0.9790
- F1-score (macro) 0.9824

By class:
SENT       tp: 261 - fp: 13 - fn: 6 - precision: 0.9526 - recall: 0.9775 - f1-score: 0.9649
X          tp: 181 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 12:44:05,662 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.sdrt.stac/
2021-07-23 12:44:05,698 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.sdrt.stac
2021-07-23 12:44:05,700 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.sdrt.stac/sent_train.txt
2021-07-23 12:44:05,702 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.sdrt.stac/sent_dev.txt
2021-07-23 12:44:05,704 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.sdrt.stac/sent_test.txt
Corpus: 7716 train + 1406 dev + 4516 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 12:44:09,138 ----------------------------------------------------------------------------------------------------
2021-07-23 12:44:09,141 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 12:44:09,141 ----------------------------------------------------------------------------------------------------
2021-07-23 12:44:09,141 Corpus: "Corpus: 7716 train + 1406 dev + 4516 test sentences"
2021-07-23 12:44:09,141 ----------------------------------------------------------------------------------------------------
2021-07-23 12:44:09,141 Parameters:
2021-07-23 12:44:09,142  - learning_rate: "3e-05"
2021-07-23 12:44:09,142  - mini_batch_size: "32"
2021-07-23 12:44:09,142  - patience: "3"
2021-07-23 12:44:09,142  - anneal_factor: "0.5"
2021-07-23 12:44:09,142  - max_epochs: "40"
2021-07-23 12:44:09,142  - shuffle: "True"
2021-07-23 12:44:09,142  - train_with_dev: "False"
2021-07-23 12:44:09,142  - batch_growth_annealing: "False"
2021-07-23 12:44:09,142 ----------------------------------------------------------------------------------------------------
2021-07-23 12:44:09,142 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.sdrt.stac"
2021-07-23 12:44:09,142 ----------------------------------------------------------------------------------------------------
2021-07-23 12:44:09,142 Device: cuda:0
2021-07-23 12:44:09,142 ----------------------------------------------------------------------------------------------------
2021-07-23 12:44:09,142 Embeddings storage mode: cpu
2021-07-23 12:44:09,148 ----------------------------------------------------------------------------------------------------
2021-07-23 12:44:20,753 epoch 1 - iter 24/242 - loss 5.49598340 - samples/sec: 66.19 - lr: 0.000030
2021-07-23 12:44:32,105 epoch 1 - iter 48/242 - loss 4.69844076 - samples/sec: 67.66 - lr: 0.000030
2021-07-23 12:44:43,592 epoch 1 - iter 72/242 - loss 4.18487320 - samples/sec: 66.87 - lr: 0.000030
2021-07-23 12:44:55,092 epoch 1 - iter 96/242 - loss 3.73386668 - samples/sec: 66.79 - lr: 0.000030
2021-07-23 12:45:06,544 epoch 1 - iter 120/242 - loss 3.35581211 - samples/sec: 67.07 - lr: 0.000030
2021-07-23 12:45:17,957 epoch 1 - iter 144/242 - loss 3.04852774 - samples/sec: 67.30 - lr: 0.000030
2021-07-23 12:45:29,414 epoch 1 - iter 168/242 - loss 2.79107974 - samples/sec: 67.04 - lr: 0.000030
2021-07-23 12:45:40,933 epoch 1 - iter 192/242 - loss 2.56294777 - samples/sec: 66.68 - lr: 0.000030
2021-07-23 12:45:52,593 epoch 1 - iter 216/242 - loss 2.36884977 - samples/sec: 65.87 - lr: 0.000030
2021-07-23 12:46:04,338 epoch 1 - iter 240/242 - loss 2.20501682 - samples/sec: 65.40 - lr: 0.000030
2021-07-23 12:46:04,927 ----------------------------------------------------------------------------------------------------
2021-07-23 12:46:04,927 EPOCH 1 done: loss 2.1932 - lr 0.0000300
2021-07-23 12:46:20,833 DEV : loss 0.47689929604530334 - score 0.9151
2021-07-23 12:46:20,854 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:46:21,408 ----------------------------------------------------------------------------------------------------
2021-07-23 12:46:25,244 epoch 2 - iter 24/242 - loss 0.65293168 - samples/sec: 200.36 - lr: 0.000030
2021-07-23 12:46:29,086 epoch 2 - iter 48/242 - loss 0.63330499 - samples/sec: 199.92 - lr: 0.000030
2021-07-23 12:46:32,894 epoch 2 - iter 72/242 - loss 0.61106816 - samples/sec: 201.79 - lr: 0.000030
2021-07-23 12:46:36,684 epoch 2 - iter 96/242 - loss 0.60595326 - samples/sec: 202.69 - lr: 0.000030
2021-07-23 12:46:40,534 epoch 2 - iter 120/242 - loss 0.58833263 - samples/sec: 199.52 - lr: 0.000030
2021-07-23 12:46:44,391 epoch 2 - iter 144/242 - loss 0.57361108 - samples/sec: 199.22 - lr: 0.000030
2021-07-23 12:46:48,163 epoch 2 - iter 168/242 - loss 0.56561873 - samples/sec: 203.64 - lr: 0.000030
2021-07-23 12:46:51,996 epoch 2 - iter 192/242 - loss 0.55389575 - samples/sec: 200.46 - lr: 0.000030
2021-07-23 12:46:55,870 epoch 2 - iter 216/242 - loss 0.54566354 - samples/sec: 198.30 - lr: 0.000030
2021-07-23 12:46:59,683 epoch 2 - iter 240/242 - loss 0.53677390 - samples/sec: 201.48 - lr: 0.000030
2021-07-23 12:46:59,889 ----------------------------------------------------------------------------------------------------
2021-07-23 12:46:59,889 EPOCH 2 done: loss 0.5348 - lr 0.0000300
2021-07-23 12:47:02,160 DEV : loss 0.3244890868663788 - score 0.9288
2021-07-23 12:47:02,181 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:47:04,649 ----------------------------------------------------------------------------------------------------
2021-07-23 12:47:08,606 epoch 3 - iter 24/242 - loss 0.44830220 - samples/sec: 194.26 - lr: 0.000030
2021-07-23 12:47:12,422 epoch 3 - iter 48/242 - loss 0.45294149 - samples/sec: 201.35 - lr: 0.000030
2021-07-23 12:47:16,180 epoch 3 - iter 72/242 - loss 0.44794043 - samples/sec: 204.46 - lr: 0.000030
2021-07-23 12:47:20,011 epoch 3 - iter 96/242 - loss 0.43554254 - samples/sec: 200.51 - lr: 0.000030
2021-07-23 12:47:23,722 epoch 3 - iter 120/242 - loss 0.42781026 - samples/sec: 207.03 - lr: 0.000030
2021-07-23 12:47:27,546 epoch 3 - iter 144/242 - loss 0.43518740 - samples/sec: 200.90 - lr: 0.000030
2021-07-23 12:47:31,432 epoch 3 - iter 168/242 - loss 0.43695978 - samples/sec: 197.71 - lr: 0.000030
2021-07-23 12:47:35,316 epoch 3 - iter 192/242 - loss 0.43409933 - samples/sec: 197.79 - lr: 0.000030
2021-07-23 12:47:39,177 epoch 3 - iter 216/242 - loss 0.42990452 - samples/sec: 198.96 - lr: 0.000030
2021-07-23 12:47:42,950 epoch 3 - iter 240/242 - loss 0.42611051 - samples/sec: 203.65 - lr: 0.000030
2021-07-23 12:47:43,156 ----------------------------------------------------------------------------------------------------
2021-07-23 12:47:43,156 EPOCH 3 done: loss 0.4253 - lr 0.0000300
2021-07-23 12:47:45,405 DEV : loss 0.28567928075790405 - score 0.9339
2021-07-23 12:47:45,425 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:47:47,716 ----------------------------------------------------------------------------------------------------
2021-07-23 12:47:51,643 epoch 4 - iter 24/242 - loss 0.35365757 - samples/sec: 195.75 - lr: 0.000030
2021-07-23 12:47:55,449 epoch 4 - iter 48/242 - loss 0.38561864 - samples/sec: 201.85 - lr: 0.000030
2021-07-23 12:47:59,271 epoch 4 - iter 72/242 - loss 0.38800788 - samples/sec: 201.04 - lr: 0.000030
2021-07-23 12:48:03,068 epoch 4 - iter 96/242 - loss 0.40259644 - samples/sec: 202.35 - lr: 0.000030
2021-07-23 12:48:06,888 epoch 4 - iter 120/242 - loss 0.39884106 - samples/sec: 201.12 - lr: 0.000030
2021-07-23 12:48:10,667 epoch 4 - iter 144/242 - loss 0.40626839 - samples/sec: 203.27 - lr: 0.000030
2021-07-23 12:48:14,500 epoch 4 - iter 168/242 - loss 0.40597775 - samples/sec: 200.46 - lr: 0.000030
2021-07-23 12:48:18,344 epoch 4 - iter 192/242 - loss 0.40535524 - samples/sec: 199.83 - lr: 0.000030
2021-07-23 12:48:22,227 epoch 4 - iter 216/242 - loss 0.40466033 - samples/sec: 197.88 - lr: 0.000030
2021-07-23 12:48:26,035 epoch 4 - iter 240/242 - loss 0.40107828 - samples/sec: 201.72 - lr: 0.000030
2021-07-23 12:48:26,246 ----------------------------------------------------------------------------------------------------
2021-07-23 12:48:26,246 EPOCH 4 done: loss 0.4006 - lr 0.0000300
2021-07-23 12:48:28,496 DEV : loss 0.26912686228752136 - score 0.9381
2021-07-23 12:48:28,517 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:48:30,860 ----------------------------------------------------------------------------------------------------
2021-07-23 12:48:34,587 epoch 5 - iter 24/242 - loss 0.37391111 - samples/sec: 206.27 - lr: 0.000030
2021-07-23 12:48:38,450 epoch 5 - iter 48/242 - loss 0.38406406 - samples/sec: 198.91 - lr: 0.000030
2021-07-23 12:48:42,227 epoch 5 - iter 72/242 - loss 0.38763944 - samples/sec: 203.36 - lr: 0.000030
2021-07-23 12:48:46,124 epoch 5 - iter 96/242 - loss 0.38319566 - samples/sec: 197.17 - lr: 0.000030
2021-07-23 12:48:49,914 epoch 5 - iter 120/242 - loss 0.37529193 - samples/sec: 202.71 - lr: 0.000030
2021-07-23 12:48:53,827 epoch 5 - iter 144/242 - loss 0.37473555 - samples/sec: 196.35 - lr: 0.000030
2021-07-23 12:48:57,659 epoch 5 - iter 168/242 - loss 0.36841003 - samples/sec: 200.46 - lr: 0.000030
2021-07-23 12:49:01,455 epoch 5 - iter 192/242 - loss 0.37390726 - samples/sec: 202.38 - lr: 0.000030
2021-07-23 12:49:05,278 epoch 5 - iter 216/242 - loss 0.36859791 - samples/sec: 200.94 - lr: 0.000030
2021-07-23 12:49:09,075 epoch 5 - iter 240/242 - loss 0.37083349 - samples/sec: 202.36 - lr: 0.000030
2021-07-23 12:49:09,299 ----------------------------------------------------------------------------------------------------
2021-07-23 12:49:09,300 EPOCH 5 done: loss 0.3725 - lr 0.0000300
2021-07-23 12:49:11,547 DEV : loss 0.254751056432724 - score 0.944
2021-07-23 12:49:11,568 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:49:14,070 ----------------------------------------------------------------------------------------------------
2021-07-23 12:49:17,936 epoch 6 - iter 24/242 - loss 0.32820492 - samples/sec: 198.84 - lr: 0.000030
2021-07-23 12:49:21,640 epoch 6 - iter 48/242 - loss 0.34083411 - samples/sec: 207.41 - lr: 0.000030
2021-07-23 12:49:25,606 epoch 6 - iter 72/242 - loss 0.34703542 - samples/sec: 193.67 - lr: 0.000030
2021-07-23 12:49:29,503 epoch 6 - iter 96/242 - loss 0.35247103 - samples/sec: 197.17 - lr: 0.000030
2021-07-23 12:49:33,375 epoch 6 - iter 120/242 - loss 0.35326573 - samples/sec: 198.42 - lr: 0.000030
2021-07-23 12:49:37,126 epoch 6 - iter 144/242 - loss 0.34976714 - samples/sec: 204.83 - lr: 0.000030
2021-07-23 12:49:40,934 epoch 6 - iter 168/242 - loss 0.34921353 - samples/sec: 201.73 - lr: 0.000030
2021-07-23 12:49:44,683 epoch 6 - iter 192/242 - loss 0.35767737 - samples/sec: 204.94 - lr: 0.000030
2021-07-23 12:49:48,507 epoch 6 - iter 216/242 - loss 0.36291616 - samples/sec: 200.94 - lr: 0.000030
2021-07-23 12:49:52,351 epoch 6 - iter 240/242 - loss 0.36306190 - samples/sec: 199.85 - lr: 0.000030
2021-07-23 12:49:52,554 ----------------------------------------------------------------------------------------------------
2021-07-23 12:49:52,554 EPOCH 6 done: loss 0.3621 - lr 0.0000300
2021-07-23 12:49:54,797 DEV : loss 0.25511425733566284 - score 0.9433
2021-07-23 12:49:54,818 BAD EPOCHS (no improvement): 1
2021-07-23 12:49:54,818 ----------------------------------------------------------------------------------------------------
2021-07-23 12:49:58,730 epoch 7 - iter 24/242 - loss 0.36889902 - samples/sec: 196.44 - lr: 0.000030
2021-07-23 12:50:02,644 epoch 7 - iter 48/242 - loss 0.36058117 - samples/sec: 196.29 - lr: 0.000030
2021-07-23 12:50:06,462 epoch 7 - iter 72/242 - loss 0.36107024 - samples/sec: 201.23 - lr: 0.000030
2021-07-23 12:50:10,202 epoch 7 - iter 96/242 - loss 0.36102736 - samples/sec: 205.38 - lr: 0.000030
2021-07-23 12:50:13,987 epoch 7 - iter 120/242 - loss 0.36556018 - samples/sec: 203.01 - lr: 0.000030
2021-07-23 12:50:17,763 epoch 7 - iter 144/242 - loss 0.37066946 - samples/sec: 203.44 - lr: 0.000030
2021-07-23 12:50:21,495 epoch 7 - iter 168/242 - loss 0.36609138 - samples/sec: 205.84 - lr: 0.000030
2021-07-23 12:50:25,278 epoch 7 - iter 192/242 - loss 0.36699311 - samples/sec: 203.09 - lr: 0.000030
2021-07-23 12:50:29,107 epoch 7 - iter 216/242 - loss 0.36701720 - samples/sec: 200.66 - lr: 0.000030
2021-07-23 12:50:33,011 epoch 7 - iter 240/242 - loss 0.36174748 - samples/sec: 196.80 - lr: 0.000030
2021-07-23 12:50:33,226 ----------------------------------------------------------------------------------------------------
2021-07-23 12:50:33,227 EPOCH 7 done: loss 0.3611 - lr 0.0000300
2021-07-23 12:50:35,473 DEV : loss 0.2579282820224762 - score 0.9404
2021-07-23 12:50:35,494 BAD EPOCHS (no improvement): 2
2021-07-23 12:50:35,494 ----------------------------------------------------------------------------------------------------
2021-07-23 12:50:39,261 epoch 8 - iter 24/242 - loss 0.31926778 - samples/sec: 204.04 - lr: 0.000030
2021-07-23 12:50:43,024 epoch 8 - iter 48/242 - loss 0.34866281 - samples/sec: 204.20 - lr: 0.000030
2021-07-23 12:50:46,920 epoch 8 - iter 72/242 - loss 0.34558211 - samples/sec: 197.20 - lr: 0.000030
2021-07-23 12:50:50,740 epoch 8 - iter 96/242 - loss 0.36645616 - samples/sec: 201.12 - lr: 0.000030
2021-07-23 12:50:54,564 epoch 8 - iter 120/242 - loss 0.36482425 - samples/sec: 200.90 - lr: 0.000030
2021-07-23 12:50:58,406 epoch 8 - iter 144/242 - loss 0.35855384 - samples/sec: 199.94 - lr: 0.000030
2021-07-23 12:51:02,232 epoch 8 - iter 168/242 - loss 0.35988499 - samples/sec: 200.83 - lr: 0.000030
2021-07-23 12:51:06,022 epoch 8 - iter 192/242 - loss 0.35564532 - samples/sec: 202.66 - lr: 0.000030
2021-07-23 12:51:09,839 epoch 8 - iter 216/242 - loss 0.35320698 - samples/sec: 201.30 - lr: 0.000030
2021-07-23 12:51:13,773 epoch 8 - iter 240/242 - loss 0.35196363 - samples/sec: 195.26 - lr: 0.000030
2021-07-23 12:51:13,983 ----------------------------------------------------------------------------------------------------
2021-07-23 12:51:13,983 EPOCH 8 done: loss 0.3519 - lr 0.0000300
2021-07-23 12:51:16,226 DEV : loss 0.25356990098953247 - score 0.9424
2021-07-23 12:51:16,247 BAD EPOCHS (no improvement): 3
2021-07-23 12:51:16,248 ----------------------------------------------------------------------------------------------------
2021-07-23 12:51:20,091 epoch 9 - iter 24/242 - loss 0.28951892 - samples/sec: 199.97 - lr: 0.000030
2021-07-23 12:51:23,903 epoch 9 - iter 48/242 - loss 0.30912656 - samples/sec: 201.55 - lr: 0.000030
2021-07-23 12:51:27,700 epoch 9 - iter 72/242 - loss 0.33627716 - samples/sec: 202.35 - lr: 0.000030
2021-07-23 12:51:31,483 epoch 9 - iter 96/242 - loss 0.33149745 - samples/sec: 203.04 - lr: 0.000030
2021-07-23 12:51:35,263 epoch 9 - iter 120/242 - loss 0.33048414 - samples/sec: 203.29 - lr: 0.000030
2021-07-23 12:51:39,090 epoch 9 - iter 144/242 - loss 0.34134427 - samples/sec: 200.72 - lr: 0.000030
2021-07-23 12:51:42,862 epoch 9 - iter 168/242 - loss 0.34485381 - samples/sec: 203.67 - lr: 0.000030
2021-07-23 12:51:46,678 epoch 9 - iter 192/242 - loss 0.34555743 - samples/sec: 201.34 - lr: 0.000030
2021-07-23 12:51:50,607 epoch 9 - iter 216/242 - loss 0.34054973 - samples/sec: 195.51 - lr: 0.000030
2021-07-23 12:51:54,439 epoch 9 - iter 240/242 - loss 0.34633282 - samples/sec: 200.50 - lr: 0.000030
2021-07-23 12:51:54,668 ----------------------------------------------------------------------------------------------------
2021-07-23 12:51:54,668 EPOCH 9 done: loss 0.3455 - lr 0.0000300
2021-07-23 12:51:56,913 DEV : loss 0.23699626326560974 - score 0.9446
2021-07-23 12:51:56,934 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:51:59,204 ----------------------------------------------------------------------------------------------------
2021-07-23 12:52:03,079 epoch 10 - iter 24/242 - loss 0.34599535 - samples/sec: 198.36 - lr: 0.000030
2021-07-23 12:52:06,914 epoch 10 - iter 48/242 - loss 0.34398801 - samples/sec: 200.34 - lr: 0.000030
2021-07-23 12:52:10,739 epoch 10 - iter 72/242 - loss 0.33862922 - samples/sec: 200.88 - lr: 0.000030
2021-07-23 12:52:14,571 epoch 10 - iter 96/242 - loss 0.34182568 - samples/sec: 200.47 - lr: 0.000030
2021-07-23 12:52:18,466 epoch 10 - iter 120/242 - loss 0.34058593 - samples/sec: 197.23 - lr: 0.000030
2021-07-23 12:52:22,367 epoch 10 - iter 144/242 - loss 0.34380836 - samples/sec: 196.97 - lr: 0.000030
2021-07-23 12:52:26,163 epoch 10 - iter 168/242 - loss 0.34942750 - samples/sec: 202.37 - lr: 0.000030
2021-07-23 12:52:29,955 epoch 10 - iter 192/242 - loss 0.34857590 - samples/sec: 202.60 - lr: 0.000030
2021-07-23 12:52:33,812 epoch 10 - iter 216/242 - loss 0.34615568 - samples/sec: 199.21 - lr: 0.000030
2021-07-23 12:52:37,488 epoch 10 - iter 240/242 - loss 0.34431224 - samples/sec: 208.99 - lr: 0.000030
2021-07-23 12:52:37,706 ----------------------------------------------------------------------------------------------------
2021-07-23 12:52:37,707 EPOCH 10 done: loss 0.3448 - lr 0.0000300
2021-07-23 12:52:39,952 DEV : loss 0.2533828616142273 - score 0.9434
2021-07-23 12:52:39,973 BAD EPOCHS (no improvement): 1
2021-07-23 12:52:39,973 ----------------------------------------------------------------------------------------------------
2021-07-23 12:52:43,795 epoch 11 - iter 24/242 - loss 0.36470590 - samples/sec: 201.10 - lr: 0.000030
2021-07-23 12:52:47,615 epoch 11 - iter 48/242 - loss 0.35745843 - samples/sec: 201.09 - lr: 0.000030
2021-07-23 12:52:51,400 epoch 11 - iter 72/242 - loss 0.34922339 - samples/sec: 202.98 - lr: 0.000030
2021-07-23 12:52:55,123 epoch 11 - iter 96/242 - loss 0.33911463 - samples/sec: 206.41 - lr: 0.000030
2021-07-23 12:52:59,012 epoch 11 - iter 120/242 - loss 0.32926305 - samples/sec: 197.51 - lr: 0.000030
2021-07-23 12:53:02,797 epoch 11 - iter 144/242 - loss 0.32786314 - samples/sec: 202.97 - lr: 0.000030
2021-07-23 12:53:06,709 epoch 11 - iter 168/242 - loss 0.32601154 - samples/sec: 196.40 - lr: 0.000030
2021-07-23 12:53:10,566 epoch 11 - iter 192/242 - loss 0.32466516 - samples/sec: 199.22 - lr: 0.000030
2021-07-23 12:53:14,352 epoch 11 - iter 216/242 - loss 0.32693190 - samples/sec: 202.92 - lr: 0.000030
2021-07-23 12:53:18,123 epoch 11 - iter 240/242 - loss 0.32635959 - samples/sec: 203.71 - lr: 0.000030
2021-07-23 12:53:18,321 ----------------------------------------------------------------------------------------------------
2021-07-23 12:53:18,321 EPOCH 11 done: loss 0.3249 - lr 0.0000300
2021-07-23 12:53:20,574 DEV : loss 0.2497924119234085 - score 0.9445
2021-07-23 12:53:20,595 BAD EPOCHS (no improvement): 2
2021-07-23 12:53:20,595 ----------------------------------------------------------------------------------------------------
2021-07-23 12:53:24,401 epoch 12 - iter 24/242 - loss 0.27700249 - samples/sec: 201.90 - lr: 0.000030
2021-07-23 12:53:28,147 epoch 12 - iter 48/242 - loss 0.28330379 - samples/sec: 205.13 - lr: 0.000030
2021-07-23 12:53:31,988 epoch 12 - iter 72/242 - loss 0.29907582 - samples/sec: 200.02 - lr: 0.000030
2021-07-23 12:53:35,806 epoch 12 - iter 96/242 - loss 0.31082310 - samples/sec: 201.22 - lr: 0.000030
2021-07-23 12:53:39,569 epoch 12 - iter 120/242 - loss 0.30813095 - samples/sec: 204.12 - lr: 0.000030
2021-07-23 12:53:43,375 epoch 12 - iter 144/242 - loss 0.31006741 - samples/sec: 201.90 - lr: 0.000030
2021-07-23 12:53:47,218 epoch 12 - iter 168/242 - loss 0.31079816 - samples/sec: 199.87 - lr: 0.000030
2021-07-23 12:53:51,029 epoch 12 - iter 192/242 - loss 0.31983196 - samples/sec: 201.59 - lr: 0.000030
2021-07-23 12:53:54,795 epoch 12 - iter 216/242 - loss 0.32160880 - samples/sec: 204.00 - lr: 0.000030
2021-07-23 12:53:58,628 epoch 12 - iter 240/242 - loss 0.32079992 - samples/sec: 200.48 - lr: 0.000030
2021-07-23 12:53:58,837 ----------------------------------------------------------------------------------------------------
2021-07-23 12:53:58,837 EPOCH 12 done: loss 0.3205 - lr 0.0000300
2021-07-23 12:54:01,080 DEV : loss 0.2521961033344269 - score 0.9445
2021-07-23 12:54:01,101 BAD EPOCHS (no improvement): 3
2021-07-23 12:54:01,101 ----------------------------------------------------------------------------------------------------
2021-07-23 12:54:04,977 epoch 13 - iter 24/242 - loss 0.31000491 - samples/sec: 198.26 - lr: 0.000030
2021-07-23 12:54:08,794 epoch 13 - iter 48/242 - loss 0.31015214 - samples/sec: 201.32 - lr: 0.000030
2021-07-23 12:54:12,570 epoch 13 - iter 72/242 - loss 0.30947085 - samples/sec: 203.45 - lr: 0.000030
2021-07-23 12:54:16,408 epoch 13 - iter 96/242 - loss 0.31164863 - samples/sec: 200.16 - lr: 0.000030
2021-07-23 12:54:20,215 epoch 13 - iter 120/242 - loss 0.31093960 - samples/sec: 201.81 - lr: 0.000030
2021-07-23 12:54:24,005 epoch 13 - iter 144/242 - loss 0.31799132 - samples/sec: 202.69 - lr: 0.000030
2021-07-23 12:54:27,798 epoch 13 - iter 168/242 - loss 0.32012968 - samples/sec: 202.57 - lr: 0.000030
2021-07-23 12:54:31,736 epoch 13 - iter 192/242 - loss 0.32230534 - samples/sec: 195.09 - lr: 0.000030
2021-07-23 12:54:35,487 epoch 13 - iter 216/242 - loss 0.32203880 - samples/sec: 204.79 - lr: 0.000030
2021-07-23 12:54:39,283 epoch 13 - iter 240/242 - loss 0.32142503 - samples/sec: 202.41 - lr: 0.000030
2021-07-23 12:54:39,483 ----------------------------------------------------------------------------------------------------
2021-07-23 12:54:39,483 EPOCH 13 done: loss 0.3204 - lr 0.0000300
2021-07-23 12:54:41,731 DEV : loss 0.24848493933677673 - score 0.944
Epoch    13: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 12:54:41,752 BAD EPOCHS (no improvement): 4
2021-07-23 12:54:41,753 ----------------------------------------------------------------------------------------------------
2021-07-23 12:54:45,534 epoch 14 - iter 24/242 - loss 0.31213238 - samples/sec: 203.24 - lr: 0.000015
2021-07-23 12:54:49,288 epoch 14 - iter 48/242 - loss 0.31914088 - samples/sec: 204.68 - lr: 0.000015
2021-07-23 12:54:53,135 epoch 14 - iter 72/242 - loss 0.30501885 - samples/sec: 199.66 - lr: 0.000015
2021-07-23 12:54:56,929 epoch 14 - iter 96/242 - loss 0.31244993 - samples/sec: 202.52 - lr: 0.000015
2021-07-23 12:55:00,727 epoch 14 - iter 120/242 - loss 0.31538857 - samples/sec: 202.26 - lr: 0.000015
2021-07-23 12:55:04,499 epoch 14 - iter 144/242 - loss 0.32298221 - samples/sec: 203.68 - lr: 0.000015
2021-07-23 12:55:08,314 epoch 14 - iter 168/242 - loss 0.32480195 - samples/sec: 201.40 - lr: 0.000015
2021-07-23 12:55:12,115 epoch 14 - iter 192/242 - loss 0.32747862 - samples/sec: 202.13 - lr: 0.000015
2021-07-23 12:55:15,786 epoch 14 - iter 216/242 - loss 0.32136925 - samples/sec: 209.24 - lr: 0.000015
2021-07-23 12:55:19,687 epoch 14 - iter 240/242 - loss 0.32368442 - samples/sec: 196.95 - lr: 0.000015
2021-07-23 12:55:19,902 ----------------------------------------------------------------------------------------------------
2021-07-23 12:55:19,903 EPOCH 14 done: loss 0.3226 - lr 0.0000150
2021-07-23 12:55:22,153 DEV : loss 0.24201425909996033 - score 0.9443
2021-07-23 12:55:22,174 BAD EPOCHS (no improvement): 1
2021-07-23 12:55:22,174 ----------------------------------------------------------------------------------------------------
2021-07-23 12:55:25,916 epoch 15 - iter 24/242 - loss 0.32083729 - samples/sec: 205.42 - lr: 0.000015
2021-07-23 12:55:29,696 epoch 15 - iter 48/242 - loss 0.34889702 - samples/sec: 203.25 - lr: 0.000015
2021-07-23 12:55:33,482 epoch 15 - iter 72/242 - loss 0.33309901 - samples/sec: 202.88 - lr: 0.000015
2021-07-23 12:55:37,182 epoch 15 - iter 96/242 - loss 0.32832565 - samples/sec: 207.69 - lr: 0.000015
2021-07-23 12:55:41,112 epoch 15 - iter 120/242 - loss 0.32302273 - samples/sec: 195.47 - lr: 0.000015
2021-07-23 12:55:45,010 epoch 15 - iter 144/242 - loss 0.32037819 - samples/sec: 197.09 - lr: 0.000015
2021-07-23 12:55:48,871 epoch 15 - iter 168/242 - loss 0.32336293 - samples/sec: 199.00 - lr: 0.000015
2021-07-23 12:55:52,679 epoch 15 - iter 192/242 - loss 0.33096877 - samples/sec: 201.73 - lr: 0.000015
2021-07-23 12:55:56,362 epoch 15 - iter 216/242 - loss 0.33038633 - samples/sec: 208.63 - lr: 0.000015
2021-07-23 12:56:00,231 epoch 15 - iter 240/242 - loss 0.32489251 - samples/sec: 198.55 - lr: 0.000015
2021-07-23 12:56:00,441 ----------------------------------------------------------------------------------------------------
2021-07-23 12:56:00,442 EPOCH 15 done: loss 0.3242 - lr 0.0000150
2021-07-23 12:56:02,692 DEV : loss 0.25420108437538147 - score 0.9434
2021-07-23 12:56:02,713 BAD EPOCHS (no improvement): 2
2021-07-23 12:56:02,713 ----------------------------------------------------------------------------------------------------
2021-07-23 12:56:06,464 epoch 16 - iter 24/242 - loss 0.28444983 - samples/sec: 204.89 - lr: 0.000015
2021-07-23 12:56:10,318 epoch 16 - iter 48/242 - loss 0.29000025 - samples/sec: 199.34 - lr: 0.000015
2021-07-23 12:56:14,135 epoch 16 - iter 72/242 - loss 0.32690070 - samples/sec: 201.26 - lr: 0.000015
2021-07-23 12:56:17,822 epoch 16 - iter 96/242 - loss 0.32854806 - samples/sec: 208.38 - lr: 0.000015
2021-07-23 12:56:21,732 epoch 16 - iter 120/242 - loss 0.32923689 - samples/sec: 196.51 - lr: 0.000015
2021-07-23 12:56:25,602 epoch 16 - iter 144/242 - loss 0.32670227 - samples/sec: 198.52 - lr: 0.000015
2021-07-23 12:56:29,403 epoch 16 - iter 168/242 - loss 0.32478713 - samples/sec: 202.12 - lr: 0.000015
2021-07-23 12:56:33,244 epoch 16 - iter 192/242 - loss 0.32692504 - samples/sec: 200.01 - lr: 0.000015
2021-07-23 12:56:37,030 epoch 16 - iter 216/242 - loss 0.32360471 - samples/sec: 202.93 - lr: 0.000015
2021-07-23 12:56:40,774 epoch 16 - iter 240/242 - loss 0.32600837 - samples/sec: 205.19 - lr: 0.000015
2021-07-23 12:56:40,962 ----------------------------------------------------------------------------------------------------
2021-07-23 12:56:40,962 EPOCH 16 done: loss 0.3245 - lr 0.0000150
2021-07-23 12:56:43,212 DEV : loss 0.23490312695503235 - score 0.9448
2021-07-23 12:56:43,233 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 12:56:45,474 ----------------------------------------------------------------------------------------------------
2021-07-23 12:56:49,251 epoch 17 - iter 24/242 - loss 0.29180640 - samples/sec: 203.54 - lr: 0.000015
2021-07-23 12:56:53,095 epoch 17 - iter 48/242 - loss 0.29296920 - samples/sec: 199.85 - lr: 0.000015
2021-07-23 12:56:56,914 epoch 17 - iter 72/242 - loss 0.30806298 - samples/sec: 201.14 - lr: 0.000015
2021-07-23 12:57:00,699 epoch 17 - iter 96/242 - loss 0.30366539 - samples/sec: 203.00 - lr: 0.000015
2021-07-23 12:57:04,490 epoch 17 - iter 120/242 - loss 0.31312503 - samples/sec: 202.68 - lr: 0.000015
2021-07-23 12:57:08,332 epoch 17 - iter 144/242 - loss 0.31525653 - samples/sec: 199.95 - lr: 0.000015
2021-07-23 12:57:12,083 epoch 17 - iter 168/242 - loss 0.31496997 - samples/sec: 204.80 - lr: 0.000015
2021-07-23 12:57:15,851 epoch 17 - iter 192/242 - loss 0.31449718 - samples/sec: 203.89 - lr: 0.000015
2021-07-23 12:57:19,667 epoch 17 - iter 216/242 - loss 0.31830915 - samples/sec: 201.36 - lr: 0.000015
2021-07-23 12:57:23,439 epoch 17 - iter 240/242 - loss 0.31696759 - samples/sec: 203.65 - lr: 0.000015
2021-07-23 12:57:23,644 ----------------------------------------------------------------------------------------------------
2021-07-23 12:57:23,644 EPOCH 17 done: loss 0.3183 - lr 0.0000150
2021-07-23 12:57:25,885 DEV : loss 0.24182027578353882 - score 0.9447
2021-07-23 12:57:25,906 BAD EPOCHS (no improvement): 1
2021-07-23 12:57:25,906 ----------------------------------------------------------------------------------------------------
2021-07-23 12:57:29,686 epoch 18 - iter 24/242 - loss 0.31868917 - samples/sec: 203.31 - lr: 0.000015
2021-07-23 12:57:33,482 epoch 18 - iter 48/242 - loss 0.31493817 - samples/sec: 202.37 - lr: 0.000015
2021-07-23 12:57:37,283 epoch 18 - iter 72/242 - loss 0.31901773 - samples/sec: 202.13 - lr: 0.000015
2021-07-23 12:57:41,040 epoch 18 - iter 96/242 - loss 0.31291522 - samples/sec: 204.52 - lr: 0.000015
2021-07-23 12:57:44,815 epoch 18 - iter 120/242 - loss 0.31220805 - samples/sec: 203.50 - lr: 0.000015
2021-07-23 12:57:48,627 epoch 18 - iter 144/242 - loss 0.31112459 - samples/sec: 201.54 - lr: 0.000015
2021-07-23 12:57:52,447 epoch 18 - iter 168/242 - loss 0.30947124 - samples/sec: 201.10 - lr: 0.000015
2021-07-23 12:57:56,272 epoch 18 - iter 192/242 - loss 0.31105581 - samples/sec: 200.89 - lr: 0.000015
2021-07-23 12:58:00,071 epoch 18 - iter 216/242 - loss 0.30882316 - samples/sec: 202.21 - lr: 0.000015
2021-07-23 12:58:03,944 epoch 18 - iter 240/242 - loss 0.30978776 - samples/sec: 198.37 - lr: 0.000015
2021-07-23 12:58:04,177 ----------------------------------------------------------------------------------------------------
2021-07-23 12:58:04,177 EPOCH 18 done: loss 0.3109 - lr 0.0000150
2021-07-23 12:58:06,415 DEV : loss 0.2427673190832138 - score 0.9439
2021-07-23 12:58:06,436 BAD EPOCHS (no improvement): 2
2021-07-23 12:58:06,436 ----------------------------------------------------------------------------------------------------
2021-07-23 12:58:10,312 epoch 19 - iter 24/242 - loss 0.27881108 - samples/sec: 198.29 - lr: 0.000015
2021-07-23 12:58:14,100 epoch 19 - iter 48/242 - loss 0.28337151 - samples/sec: 202.85 - lr: 0.000015
2021-07-23 12:58:17,831 epoch 19 - iter 72/242 - loss 0.29516555 - samples/sec: 205.90 - lr: 0.000015
2021-07-23 12:58:21,698 epoch 19 - iter 96/242 - loss 0.30598665 - samples/sec: 198.65 - lr: 0.000015
2021-07-23 12:58:25,409 epoch 19 - iter 120/242 - loss 0.30474954 - samples/sec: 207.02 - lr: 0.000015
2021-07-23 12:58:29,247 epoch 19 - iter 144/242 - loss 0.30397993 - samples/sec: 200.18 - lr: 0.000015
2021-07-23 12:58:33,032 epoch 19 - iter 168/242 - loss 0.30346759 - samples/sec: 203.00 - lr: 0.000015
2021-07-23 12:58:36,766 epoch 19 - iter 192/242 - loss 0.30393073 - samples/sec: 205.75 - lr: 0.000015
2021-07-23 12:58:40,611 epoch 19 - iter 216/242 - loss 0.30490453 - samples/sec: 199.78 - lr: 0.000015
2021-07-23 12:58:44,423 epoch 19 - iter 240/242 - loss 0.30479607 - samples/sec: 201.56 - lr: 0.000015
2021-07-23 12:58:44,627 ----------------------------------------------------------------------------------------------------
2021-07-23 12:58:44,627 EPOCH 19 done: loss 0.3064 - lr 0.0000150
2021-07-23 12:58:46,872 DEV : loss 0.24278931319713593 - score 0.9446
2021-07-23 12:58:46,893 BAD EPOCHS (no improvement): 3
2021-07-23 12:58:46,894 ----------------------------------------------------------------------------------------------------
2021-07-23 12:58:50,728 epoch 20 - iter 24/242 - loss 0.33631824 - samples/sec: 200.44 - lr: 0.000015
2021-07-23 12:58:54,526 epoch 20 - iter 48/242 - loss 0.33175716 - samples/sec: 202.25 - lr: 0.000015
2021-07-23 12:58:58,438 epoch 20 - iter 72/242 - loss 0.32867143 - samples/sec: 196.42 - lr: 0.000015
2021-07-23 12:59:02,311 epoch 20 - iter 96/242 - loss 0.31043764 - samples/sec: 198.37 - lr: 0.000015
2021-07-23 12:59:06,047 epoch 20 - iter 120/242 - loss 0.30528596 - samples/sec: 205.62 - lr: 0.000015
2021-07-23 12:59:09,879 epoch 20 - iter 144/242 - loss 0.30853514 - samples/sec: 200.48 - lr: 0.000015
2021-07-23 12:59:13,781 epoch 20 - iter 168/242 - loss 0.31201039 - samples/sec: 196.89 - lr: 0.000015
2021-07-23 12:59:17,660 epoch 20 - iter 192/242 - loss 0.31205260 - samples/sec: 198.06 - lr: 0.000015
2021-07-23 12:59:21,403 epoch 20 - iter 216/242 - loss 0.30830208 - samples/sec: 205.24 - lr: 0.000015
2021-07-23 12:59:25,139 epoch 20 - iter 240/242 - loss 0.30808023 - samples/sec: 205.68 - lr: 0.000015
2021-07-23 12:59:25,349 ----------------------------------------------------------------------------------------------------
2021-07-23 12:59:25,349 EPOCH 20 done: loss 0.3077 - lr 0.0000150
2021-07-23 12:59:27,594 DEV : loss 0.24352797865867615 - score 0.9445
Epoch    20: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 12:59:27,615 BAD EPOCHS (no improvement): 4
2021-07-23 12:59:27,615 ----------------------------------------------------------------------------------------------------
2021-07-23 12:59:31,438 epoch 21 - iter 24/242 - loss 0.35321330 - samples/sec: 201.06 - lr: 0.000008
2021-07-23 12:59:35,290 epoch 21 - iter 48/242 - loss 0.30302386 - samples/sec: 199.45 - lr: 0.000008
2021-07-23 12:59:39,160 epoch 21 - iter 72/242 - loss 0.29646649 - samples/sec: 198.50 - lr: 0.000008
2021-07-23 12:59:42,915 epoch 21 - iter 96/242 - loss 0.30086235 - samples/sec: 204.58 - lr: 0.000008
2021-07-23 12:59:46,675 epoch 21 - iter 120/242 - loss 0.30793922 - samples/sec: 204.36 - lr: 0.000008
2021-07-23 12:59:50,510 epoch 21 - iter 144/242 - loss 0.31417844 - samples/sec: 200.31 - lr: 0.000008
2021-07-23 12:59:54,339 epoch 21 - iter 168/242 - loss 0.31436983 - samples/sec: 200.65 - lr: 0.000008
2021-07-23 12:59:58,181 epoch 21 - iter 192/242 - loss 0.31353820 - samples/sec: 199.94 - lr: 0.000008
2021-07-23 13:00:02,026 epoch 21 - iter 216/242 - loss 0.31733449 - samples/sec: 199.83 - lr: 0.000008
2021-07-23 13:00:05,834 epoch 21 - iter 240/242 - loss 0.31376174 - samples/sec: 201.76 - lr: 0.000008
2021-07-23 13:00:06,034 ----------------------------------------------------------------------------------------------------
2021-07-23 13:00:06,035 EPOCH 21 done: loss 0.3150 - lr 0.0000075
2021-07-23 13:00:08,274 DEV : loss 0.23358334600925446 - score 0.9455
2021-07-23 13:00:08,295 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:00:10,664 ----------------------------------------------------------------------------------------------------
2021-07-23 13:00:14,498 epoch 22 - iter 24/242 - loss 0.31790609 - samples/sec: 200.51 - lr: 0.000008
2021-07-23 13:00:18,291 epoch 22 - iter 48/242 - loss 0.31995839 - samples/sec: 202.53 - lr: 0.000008
2021-07-23 13:00:22,072 epoch 22 - iter 72/242 - loss 0.31853896 - samples/sec: 203.22 - lr: 0.000008
2021-07-23 13:00:25,680 epoch 22 - iter 96/242 - loss 0.32118560 - samples/sec: 212.95 - lr: 0.000008
2021-07-23 13:00:29,486 epoch 22 - iter 120/242 - loss 0.31468694 - samples/sec: 201.81 - lr: 0.000008
2021-07-23 13:00:33,331 epoch 22 - iter 144/242 - loss 0.30988637 - samples/sec: 199.82 - lr: 0.000008
2021-07-23 13:00:37,130 epoch 22 - iter 168/242 - loss 0.30965419 - samples/sec: 202.24 - lr: 0.000008
2021-07-23 13:00:40,975 epoch 22 - iter 192/242 - loss 0.31125611 - samples/sec: 199.81 - lr: 0.000008
2021-07-23 13:00:44,774 epoch 22 - iter 216/242 - loss 0.31166322 - samples/sec: 202.23 - lr: 0.000008
2021-07-23 13:00:48,566 epoch 22 - iter 240/242 - loss 0.30979730 - samples/sec: 202.57 - lr: 0.000008
2021-07-23 13:00:48,803 ----------------------------------------------------------------------------------------------------
2021-07-23 13:00:48,804 EPOCH 22 done: loss 0.3094 - lr 0.0000075
2021-07-23 13:00:51,056 DEV : loss 0.23639258742332458 - score 0.9442
2021-07-23 13:00:51,076 BAD EPOCHS (no improvement): 1
2021-07-23 13:00:51,077 ----------------------------------------------------------------------------------------------------
2021-07-23 13:00:54,936 epoch 23 - iter 24/242 - loss 0.31967785 - samples/sec: 199.16 - lr: 0.000008
2021-07-23 13:00:58,687 epoch 23 - iter 48/242 - loss 0.31708041 - samples/sec: 204.77 - lr: 0.000008
2021-07-23 13:01:02,539 epoch 23 - iter 72/242 - loss 0.30254057 - samples/sec: 199.45 - lr: 0.000008
2021-07-23 13:01:06,379 epoch 23 - iter 96/242 - loss 0.30828596 - samples/sec: 200.10 - lr: 0.000008
2021-07-23 13:01:10,194 epoch 23 - iter 120/242 - loss 0.30534513 - samples/sec: 201.38 - lr: 0.000008
2021-07-23 13:01:14,144 epoch 23 - iter 144/242 - loss 0.30331313 - samples/sec: 194.51 - lr: 0.000008
2021-07-23 13:01:17,967 epoch 23 - iter 168/242 - loss 0.30709201 - samples/sec: 200.94 - lr: 0.000008
2021-07-23 13:01:21,818 epoch 23 - iter 192/242 - loss 0.30576852 - samples/sec: 199.48 - lr: 0.000008
2021-07-23 13:01:25,611 epoch 23 - iter 216/242 - loss 0.30635562 - samples/sec: 202.55 - lr: 0.000008
2021-07-23 13:01:29,362 epoch 23 - iter 240/242 - loss 0.30573124 - samples/sec: 204.81 - lr: 0.000008
2021-07-23 13:01:29,572 ----------------------------------------------------------------------------------------------------
2021-07-23 13:01:29,572 EPOCH 23 done: loss 0.3050 - lr 0.0000075
2021-07-23 13:01:31,820 DEV : loss 0.2354211062192917 - score 0.9445
2021-07-23 13:01:31,841 BAD EPOCHS (no improvement): 2
2021-07-23 13:01:31,841 ----------------------------------------------------------------------------------------------------
2021-07-23 13:01:35,606 epoch 24 - iter 24/242 - loss 0.28697872 - samples/sec: 204.12 - lr: 0.000008
2021-07-23 13:01:39,402 epoch 24 - iter 48/242 - loss 0.29894445 - samples/sec: 202.41 - lr: 0.000008
2021-07-23 13:01:43,190 epoch 24 - iter 72/242 - loss 0.28625705 - samples/sec: 202.79 - lr: 0.000008
2021-07-23 13:01:47,018 epoch 24 - iter 96/242 - loss 0.29974567 - samples/sec: 200.73 - lr: 0.000008
2021-07-23 13:01:50,892 epoch 24 - iter 120/242 - loss 0.30290012 - samples/sec: 198.30 - lr: 0.000008
2021-07-23 13:01:54,827 epoch 24 - iter 144/242 - loss 0.30243544 - samples/sec: 195.21 - lr: 0.000008
2021-07-23 13:01:58,655 epoch 24 - iter 168/242 - loss 0.29857488 - samples/sec: 200.72 - lr: 0.000008
2021-07-23 13:02:02,466 epoch 24 - iter 192/242 - loss 0.29925466 - samples/sec: 201.60 - lr: 0.000008
2021-07-23 13:02:06,302 epoch 24 - iter 216/242 - loss 0.30088265 - samples/sec: 200.27 - lr: 0.000008
2021-07-23 13:02:10,058 epoch 24 - iter 240/242 - loss 0.29989202 - samples/sec: 204.52 - lr: 0.000008
2021-07-23 13:02:10,273 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:10,274 EPOCH 24 done: loss 0.2987 - lr 0.0000075
2021-07-23 13:02:12,509 DEV : loss 0.23484018445014954 - score 0.9452
2021-07-23 13:02:12,530 BAD EPOCHS (no improvement): 3
2021-07-23 13:02:12,530 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:16,359 epoch 25 - iter 24/242 - loss 0.29080204 - samples/sec: 200.71 - lr: 0.000008
2021-07-23 13:02:20,172 epoch 25 - iter 48/242 - loss 0.29212641 - samples/sec: 201.52 - lr: 0.000008
2021-07-23 13:02:23,970 epoch 25 - iter 72/242 - loss 0.30007875 - samples/sec: 202.32 - lr: 0.000008
2021-07-23 13:02:27,783 epoch 25 - iter 96/242 - loss 0.30531177 - samples/sec: 201.46 - lr: 0.000008
2021-07-23 13:02:31,651 epoch 25 - iter 120/242 - loss 0.29923247 - samples/sec: 198.63 - lr: 0.000008
2021-07-23 13:02:35,420 epoch 25 - iter 144/242 - loss 0.29617824 - samples/sec: 203.87 - lr: 0.000008
2021-07-23 13:02:39,171 epoch 25 - iter 168/242 - loss 0.29399331 - samples/sec: 204.78 - lr: 0.000008
2021-07-23 13:02:42,952 epoch 25 - iter 192/242 - loss 0.29016030 - samples/sec: 203.22 - lr: 0.000008
2021-07-23 13:02:46,822 epoch 25 - iter 216/242 - loss 0.29366603 - samples/sec: 198.52 - lr: 0.000008
2021-07-23 13:02:50,684 epoch 25 - iter 240/242 - loss 0.29599619 - samples/sec: 198.94 - lr: 0.000008
2021-07-23 13:02:50,899 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:50,899 EPOCH 25 done: loss 0.2951 - lr 0.0000075
2021-07-23 13:02:53,362 DEV : loss 0.23659352958202362 - score 0.9433
Epoch    25: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 13:02:53,383 BAD EPOCHS (no improvement): 4
2021-07-23 13:02:53,384 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:57,371 epoch 26 - iter 24/242 - loss 0.28042036 - samples/sec: 192.72 - lr: 0.000004
2021-07-23 13:03:01,208 epoch 26 - iter 48/242 - loss 0.29778942 - samples/sec: 200.25 - lr: 0.000004
2021-07-23 13:03:05,060 epoch 26 - iter 72/242 - loss 0.30027014 - samples/sec: 199.45 - lr: 0.000004
2021-07-23 13:03:08,759 epoch 26 - iter 96/242 - loss 0.29283485 - samples/sec: 207.69 - lr: 0.000004
2021-07-23 13:03:12,502 epoch 26 - iter 120/242 - loss 0.29648304 - samples/sec: 205.22 - lr: 0.000004
2021-07-23 13:03:16,351 epoch 26 - iter 144/242 - loss 0.29840828 - samples/sec: 199.63 - lr: 0.000004
2021-07-23 13:03:20,147 epoch 26 - iter 168/242 - loss 0.29848462 - samples/sec: 202.40 - lr: 0.000004
2021-07-23 13:03:23,847 epoch 26 - iter 192/242 - loss 0.30032134 - samples/sec: 207.62 - lr: 0.000004
2021-07-23 13:03:27,699 epoch 26 - iter 216/242 - loss 0.29788356 - samples/sec: 199.45 - lr: 0.000004
2021-07-23 13:03:31,548 epoch 26 - iter 240/242 - loss 0.29762370 - samples/sec: 199.60 - lr: 0.000004
2021-07-23 13:03:31,763 ----------------------------------------------------------------------------------------------------
2021-07-23 13:03:31,763 EPOCH 26 done: loss 0.2962 - lr 0.0000038
2021-07-23 13:03:34,000 DEV : loss 0.23751938343048096 - score 0.9442
2021-07-23 13:03:34,021 BAD EPOCHS (no improvement): 1
2021-07-23 13:03:34,021 ----------------------------------------------------------------------------------------------------
2021-07-23 13:03:37,787 epoch 27 - iter 24/242 - loss 0.30005251 - samples/sec: 204.11 - lr: 0.000004
2021-07-23 13:03:41,638 epoch 27 - iter 48/242 - loss 0.30736876 - samples/sec: 199.45 - lr: 0.000004
2021-07-23 13:03:45,507 epoch 27 - iter 72/242 - loss 0.31017093 - samples/sec: 198.61 - lr: 0.000004
2021-07-23 13:03:49,323 epoch 27 - iter 96/242 - loss 0.30585480 - samples/sec: 201.32 - lr: 0.000004
2021-07-23 13:03:53,207 epoch 27 - iter 120/242 - loss 0.30658046 - samples/sec: 197.76 - lr: 0.000004
2021-07-23 13:03:57,115 epoch 27 - iter 144/242 - loss 0.30642671 - samples/sec: 196.58 - lr: 0.000004
2021-07-23 13:04:00,887 epoch 27 - iter 168/242 - loss 0.29884350 - samples/sec: 203.66 - lr: 0.000004
2021-07-23 13:04:04,701 epoch 27 - iter 192/242 - loss 0.30045221 - samples/sec: 201.46 - lr: 0.000004
2021-07-23 13:04:08,500 epoch 27 - iter 216/242 - loss 0.30031475 - samples/sec: 202.26 - lr: 0.000004
2021-07-23 13:04:12,253 epoch 27 - iter 240/242 - loss 0.29748164 - samples/sec: 204.70 - lr: 0.000004
2021-07-23 13:04:12,472 ----------------------------------------------------------------------------------------------------
2021-07-23 13:04:12,472 EPOCH 27 done: loss 0.2966 - lr 0.0000038
2021-07-23 13:04:14,712 DEV : loss 0.23656460642814636 - score 0.9437
2021-07-23 13:04:14,733 BAD EPOCHS (no improvement): 2
2021-07-23 13:04:14,734 ----------------------------------------------------------------------------------------------------
2021-07-23 13:04:18,516 epoch 28 - iter 24/242 - loss 0.27781145 - samples/sec: 203.21 - lr: 0.000004
2021-07-23 13:04:22,435 epoch 28 - iter 48/242 - loss 0.28021731 - samples/sec: 196.00 - lr: 0.000004
2021-07-23 13:04:26,170 epoch 28 - iter 72/242 - loss 0.29134645 - samples/sec: 205.72 - lr: 0.000004
2021-07-23 13:04:30,072 epoch 28 - iter 96/242 - loss 0.28148465 - samples/sec: 196.91 - lr: 0.000004
2021-07-23 13:04:33,923 epoch 28 - iter 120/242 - loss 0.28449893 - samples/sec: 199.49 - lr: 0.000004
2021-07-23 13:04:37,639 epoch 28 - iter 144/242 - loss 0.28481004 - samples/sec: 206.73 - lr: 0.000004
2021-07-23 13:04:41,456 epoch 28 - iter 168/242 - loss 0.28590794 - samples/sec: 201.27 - lr: 0.000004
2021-07-23 13:04:45,371 epoch 28 - iter 192/242 - loss 0.28662672 - samples/sec: 196.26 - lr: 0.000004
2021-07-23 13:04:49,182 epoch 28 - iter 216/242 - loss 0.29202775 - samples/sec: 201.55 - lr: 0.000004
2021-07-23 13:04:52,959 epoch 28 - iter 240/242 - loss 0.29431822 - samples/sec: 203.42 - lr: 0.000004
2021-07-23 13:04:53,168 ----------------------------------------------------------------------------------------------------
2021-07-23 13:04:53,168 EPOCH 28 done: loss 0.2933 - lr 0.0000038
2021-07-23 13:04:55,405 DEV : loss 0.23551802337169647 - score 0.9455
2021-07-23 13:04:55,426 BAD EPOCHS (no improvement): 3
2021-07-23 13:04:55,427 ----------------------------------------------------------------------------------------------------
2021-07-23 13:04:59,294 epoch 29 - iter 24/242 - loss 0.29943430 - samples/sec: 198.74 - lr: 0.000004
2021-07-23 13:05:03,154 epoch 29 - iter 48/242 - loss 0.30919926 - samples/sec: 199.02 - lr: 0.000004
2021-07-23 13:05:06,996 epoch 29 - iter 72/242 - loss 0.31309644 - samples/sec: 199.95 - lr: 0.000004
2021-07-23 13:05:10,794 epoch 29 - iter 96/242 - loss 0.30175099 - samples/sec: 202.29 - lr: 0.000004
2021-07-23 13:05:14,571 epoch 29 - iter 120/242 - loss 0.29898067 - samples/sec: 203.41 - lr: 0.000004
2021-07-23 13:05:18,403 epoch 29 - iter 144/242 - loss 0.29404406 - samples/sec: 200.50 - lr: 0.000004
2021-07-23 13:05:22,259 epoch 29 - iter 168/242 - loss 0.29156311 - samples/sec: 199.25 - lr: 0.000004
2021-07-23 13:05:26,060 epoch 29 - iter 192/242 - loss 0.29262497 - samples/sec: 202.08 - lr: 0.000004
2021-07-23 13:05:29,950 epoch 29 - iter 216/242 - loss 0.29358880 - samples/sec: 197.49 - lr: 0.000004
2021-07-23 13:05:33,661 epoch 29 - iter 240/242 - loss 0.29336455 - samples/sec: 207.02 - lr: 0.000004
2021-07-23 13:05:33,861 ----------------------------------------------------------------------------------------------------
2021-07-23 13:05:33,862 EPOCH 29 done: loss 0.2926 - lr 0.0000038
2021-07-23 13:05:36,102 DEV : loss 0.23513950407505035 - score 0.9455
Epoch    29: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 13:05:36,123 BAD EPOCHS (no improvement): 4
2021-07-23 13:05:36,124 ----------------------------------------------------------------------------------------------------
2021-07-23 13:05:36,124 ----------------------------------------------------------------------------------------------------
2021-07-23 13:05:36,124 learning rate too small - quitting training!
2021-07-23 13:05:36,124 ----------------------------------------------------------------------------------------------------
2021-07-23 13:05:36,678 ----------------------------------------------------------------------------------------------------
2021-07-23 13:05:36,678 Testing using best model ...
2021-07-23 13:05:36,679 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.sdrt.stac/best-model.pt
2021-07-23 13:06:29,135 0.9151	0.9843	0.9484
2021-07-23 13:06:29,135 
Results:
- F1-score (micro) 0.9484
- F1-score (macro) 0.9683

By class:
SENT       tp: 3149 - fp: 360 - fn: 62 - precision: 0.8974 - recall: 0.9807 - f1-score: 0.9372
X          tp: 741 - fp: 1 - fn: 0 - precision: 0.9987 - recall: 1.0000 - f1-score: 0.9993
2021-07-23 13:06:29,135 ----------------------------------------------------------------------------------------------------
