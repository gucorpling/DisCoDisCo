/home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/
2021-06-21 22:58:08,243 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb
2021-06-21 22:58:08,243 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/sent_train.txt
2021-06-21 22:58:08,243 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/sent_dev.txt
2021-06-21 22:58:08,243 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/sent_test.txt
Corpus: 2538 train + 541 dev + 490 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-21 22:58:24,077 ----------------------------------------------------------------------------------------------------
2021-06-21 22:58:24,078 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(21128, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-21 22:58:24,078 ----------------------------------------------------------------------------------------------------
2021-06-21 22:58:24,078 Corpus: "Corpus: 2538 train + 541 dev + 490 test sentences"
2021-06-21 22:58:24,078 ----------------------------------------------------------------------------------------------------
2021-06-21 22:58:24,078 Parameters:
2021-06-21 22:58:24,079  - learning_rate: "3e-05"
2021-06-21 22:58:24,079  - mini_batch_size: "32"
2021-06-21 22:58:24,079  - patience: "3"
2021-06-21 22:58:24,079  - anneal_factor: "0.5"
2021-06-21 22:58:24,079  - max_epochs: "40"
2021-06-21 22:58:24,079  - shuffle: "True"
2021-06-21 22:58:24,079  - train_with_dev: "False"
2021-06-21 22:58:24,079  - batch_growth_annealing: "False"
2021-06-21 22:58:24,079 ----------------------------------------------------------------------------------------------------
2021-06-21 22:58:24,079 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb"
2021-06-21 22:58:24,079 ----------------------------------------------------------------------------------------------------
2021-06-21 22:58:24,079 Device: cuda:0
2021-06-21 22:58:24,079 ----------------------------------------------------------------------------------------------------
2021-06-21 22:58:24,079 Embeddings storage mode: cpu
2021-06-21 22:58:24,080 ----------------------------------------------------------------------------------------------------
2021-06-21 22:58:30,759 epoch 1 - iter 8/80 - loss 31.44358540 - samples/sec: 38.33 - lr: 0.000030
2021-06-21 22:58:37,389 epoch 1 - iter 16/80 - loss 20.91830838 - samples/sec: 38.62 - lr: 0.000030
2021-06-21 22:58:43,973 epoch 1 - iter 24/80 - loss 15.46724582 - samples/sec: 38.89 - lr: 0.000030
2021-06-21 22:58:50,563 epoch 1 - iter 32/80 - loss 12.63423310 - samples/sec: 38.85 - lr: 0.000030
2021-06-21 22:58:57,124 epoch 1 - iter 40/80 - loss 10.79120201 - samples/sec: 39.02 - lr: 0.000030
2021-06-21 22:59:03,747 epoch 1 - iter 48/80 - loss 9.46891045 - samples/sec: 38.66 - lr: 0.000030
2021-06-21 22:59:10,366 epoch 1 - iter 56/80 - loss 8.50124102 - samples/sec: 38.68 - lr: 0.000030
2021-06-21 22:59:17,070 epoch 1 - iter 64/80 - loss 7.73117312 - samples/sec: 38.19 - lr: 0.000030
2021-06-21 22:59:23,754 epoch 1 - iter 72/80 - loss 7.10802956 - samples/sec: 38.30 - lr: 0.000030
2021-06-21 22:59:29,939 epoch 1 - iter 80/80 - loss 6.60760809 - samples/sec: 41.40 - lr: 0.000030
2021-06-21 22:59:29,939 ----------------------------------------------------------------------------------------------------
2021-06-21 22:59:29,939 EPOCH 1 done: loss 6.6076 - lr 0.0000300
2021-06-21 22:59:39,311 DEV : loss 1.642780065536499 - score 0.4334
2021-06-21 22:59:39,349 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 22:59:39,758 ----------------------------------------------------------------------------------------------------
2021-06-21 22:59:43,030 epoch 2 - iter 8/80 - loss 1.74155626 - samples/sec: 78.25 - lr: 0.000030
2021-06-21 22:59:46,298 epoch 2 - iter 16/80 - loss 1.69623607 - samples/sec: 78.36 - lr: 0.000030
2021-06-21 22:59:49,597 epoch 2 - iter 24/80 - loss 1.67468596 - samples/sec: 77.62 - lr: 0.000030
2021-06-21 22:59:52,856 epoch 2 - iter 32/80 - loss 1.61893310 - samples/sec: 78.58 - lr: 0.000030
2021-06-21 22:59:56,116 epoch 2 - iter 40/80 - loss 1.56642988 - samples/sec: 78.53 - lr: 0.000030
2021-06-21 22:59:59,392 epoch 2 - iter 48/80 - loss 1.50929825 - samples/sec: 78.16 - lr: 0.000030
2021-06-21 23:00:02,659 epoch 2 - iter 56/80 - loss 1.48561057 - samples/sec: 78.38 - lr: 0.000030
2021-06-21 23:00:05,905 epoch 2 - iter 64/80 - loss 1.46806237 - samples/sec: 78.89 - lr: 0.000030
2021-06-21 23:00:09,177 epoch 2 - iter 72/80 - loss 1.43878007 - samples/sec: 78.24 - lr: 0.000030
2021-06-21 23:00:12,211 epoch 2 - iter 80/80 - loss 1.41750345 - samples/sec: 84.42 - lr: 0.000030
2021-06-21 23:00:12,211 ----------------------------------------------------------------------------------------------------
2021-06-21 23:00:12,211 EPOCH 2 done: loss 1.4175 - lr 0.0000300
2021-06-21 23:00:14,656 DEV : loss 0.9657211303710938 - score 0.7809
2021-06-21 23:00:14,695 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:00:18,878 ----------------------------------------------------------------------------------------------------
2021-06-21 23:00:22,125 epoch 3 - iter 8/80 - loss 1.04032306 - samples/sec: 78.87 - lr: 0.000030
2021-06-21 23:00:25,394 epoch 3 - iter 16/80 - loss 1.06304659 - samples/sec: 78.32 - lr: 0.000030
2021-06-21 23:00:28,684 epoch 3 - iter 24/80 - loss 1.05288203 - samples/sec: 77.83 - lr: 0.000030
2021-06-21 23:00:31,955 epoch 3 - iter 32/80 - loss 1.01557753 - samples/sec: 78.30 - lr: 0.000030
2021-06-21 23:00:35,236 epoch 3 - iter 40/80 - loss 1.00009558 - samples/sec: 78.03 - lr: 0.000030
2021-06-21 23:00:38,529 epoch 3 - iter 48/80 - loss 0.99116994 - samples/sec: 77.75 - lr: 0.000030
2021-06-21 23:00:41,822 epoch 3 - iter 56/80 - loss 0.97478473 - samples/sec: 77.78 - lr: 0.000030
2021-06-21 23:00:45,083 epoch 3 - iter 64/80 - loss 0.96403700 - samples/sec: 78.50 - lr: 0.000030
2021-06-21 23:00:48,356 epoch 3 - iter 72/80 - loss 0.95166915 - samples/sec: 78.24 - lr: 0.000030
2021-06-21 23:00:51,368 epoch 3 - iter 80/80 - loss 0.92811135 - samples/sec: 85.02 - lr: 0.000030
2021-06-21 23:00:51,368 ----------------------------------------------------------------------------------------------------
2021-06-21 23:00:51,368 EPOCH 3 done: loss 0.9281 - lr 0.0000300
2021-06-21 23:00:54,030 DEV : loss 0.679599940776825 - score 0.8461
2021-06-21 23:00:54,068 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:00:58,155 ----------------------------------------------------------------------------------------------------
2021-06-21 23:01:01,466 epoch 4 - iter 8/80 - loss 0.90638666 - samples/sec: 77.34 - lr: 0.000030
2021-06-21 23:01:04,722 epoch 4 - iter 16/80 - loss 0.81466306 - samples/sec: 78.66 - lr: 0.000030
2021-06-21 23:01:08,008 epoch 4 - iter 24/80 - loss 0.79138933 - samples/sec: 77.90 - lr: 0.000030
2021-06-21 23:01:11,276 epoch 4 - iter 32/80 - loss 0.76492046 - samples/sec: 78.36 - lr: 0.000030
2021-06-21 23:01:14,580 epoch 4 - iter 40/80 - loss 0.74118922 - samples/sec: 77.50 - lr: 0.000030
2021-06-21 23:01:17,844 epoch 4 - iter 48/80 - loss 0.73636560 - samples/sec: 78.46 - lr: 0.000030
2021-06-21 23:01:21,141 epoch 4 - iter 56/80 - loss 0.73528218 - samples/sec: 77.66 - lr: 0.000030
2021-06-21 23:01:24,427 epoch 4 - iter 64/80 - loss 0.72866405 - samples/sec: 77.92 - lr: 0.000030
2021-06-21 23:01:27,673 epoch 4 - iter 72/80 - loss 0.72126022 - samples/sec: 78.89 - lr: 0.000030
2021-06-21 23:01:30,697 epoch 4 - iter 80/80 - loss 0.70841328 - samples/sec: 84.67 - lr: 0.000030
2021-06-21 23:01:30,697 ----------------------------------------------------------------------------------------------------
2021-06-21 23:01:30,697 EPOCH 4 done: loss 0.7084 - lr 0.0000300
2021-06-21 23:01:33,145 DEV : loss 0.5294801592826843 - score 0.8905
2021-06-21 23:01:33,184 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:01:37,302 ----------------------------------------------------------------------------------------------------
2021-06-21 23:01:40,584 epoch 5 - iter 8/80 - loss 0.64387694 - samples/sec: 78.03 - lr: 0.000030
2021-06-21 23:01:43,926 epoch 5 - iter 16/80 - loss 0.60942202 - samples/sec: 76.62 - lr: 0.000030
2021-06-21 23:01:47,208 epoch 5 - iter 24/80 - loss 0.60288139 - samples/sec: 78.01 - lr: 0.000030
2021-06-21 23:01:50,507 epoch 5 - iter 32/80 - loss 0.59003498 - samples/sec: 77.62 - lr: 0.000030
2021-06-21 23:01:53,767 epoch 5 - iter 40/80 - loss 0.58630990 - samples/sec: 78.55 - lr: 0.000030
2021-06-21 23:01:57,053 epoch 5 - iter 48/80 - loss 0.57480207 - samples/sec: 77.93 - lr: 0.000030
2021-06-21 23:02:00,338 epoch 5 - iter 56/80 - loss 0.56950225 - samples/sec: 77.93 - lr: 0.000030
2021-06-21 23:02:03,600 epoch 5 - iter 64/80 - loss 0.57191923 - samples/sec: 78.51 - lr: 0.000030
2021-06-21 23:02:06,855 epoch 5 - iter 72/80 - loss 0.56457303 - samples/sec: 78.64 - lr: 0.000030
2021-06-21 23:02:09,916 epoch 5 - iter 80/80 - loss 0.57529224 - samples/sec: 83.66 - lr: 0.000030
2021-06-21 23:02:09,916 ----------------------------------------------------------------------------------------------------
2021-06-21 23:02:09,917 EPOCH 5 done: loss 0.5753 - lr 0.0000300
2021-06-21 23:02:12,366 DEV : loss 0.456493079662323 - score 0.9093
2021-06-21 23:02:12,405 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:02:16,594 ----------------------------------------------------------------------------------------------------
2021-06-21 23:02:19,864 epoch 6 - iter 8/80 - loss 0.54999589 - samples/sec: 78.33 - lr: 0.000030
2021-06-21 23:02:23,144 epoch 6 - iter 16/80 - loss 0.50948606 - samples/sec: 78.07 - lr: 0.000030
2021-06-21 23:02:26,432 epoch 6 - iter 24/80 - loss 0.51340323 - samples/sec: 77.86 - lr: 0.000030
2021-06-21 23:02:29,756 epoch 6 - iter 32/80 - loss 0.52167501 - samples/sec: 77.04 - lr: 0.000030
2021-06-21 23:02:33,043 epoch 6 - iter 40/80 - loss 0.51673816 - samples/sec: 77.91 - lr: 0.000030
2021-06-21 23:02:36,297 epoch 6 - iter 48/80 - loss 0.50578308 - samples/sec: 78.68 - lr: 0.000030
2021-06-21 23:02:39,614 epoch 6 - iter 56/80 - loss 0.49740536 - samples/sec: 77.19 - lr: 0.000030
2021-06-21 23:02:42,921 epoch 6 - iter 64/80 - loss 0.49179956 - samples/sec: 77.43 - lr: 0.000030
2021-06-21 23:02:46,178 epoch 6 - iter 72/80 - loss 0.48266252 - samples/sec: 78.61 - lr: 0.000030
2021-06-21 23:02:49,228 epoch 6 - iter 80/80 - loss 0.47108718 - samples/sec: 83.97 - lr: 0.000030
2021-06-21 23:02:49,228 ----------------------------------------------------------------------------------------------------
2021-06-21 23:02:49,228 EPOCH 6 done: loss 0.4711 - lr 0.0000300
2021-06-21 23:02:51,898 DEV : loss 0.39127472043037415 - score 0.9184
2021-06-21 23:02:51,936 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:02:56,106 ----------------------------------------------------------------------------------------------------
2021-06-21 23:02:59,370 epoch 7 - iter 8/80 - loss 0.43919465 - samples/sec: 78.46 - lr: 0.000030
2021-06-21 23:03:02,666 epoch 7 - iter 16/80 - loss 0.44796031 - samples/sec: 77.69 - lr: 0.000030
2021-06-21 23:03:05,968 epoch 7 - iter 24/80 - loss 0.42532630 - samples/sec: 77.53 - lr: 0.000030
2021-06-21 23:03:09,248 epoch 7 - iter 32/80 - loss 0.42415722 - samples/sec: 78.07 - lr: 0.000030
2021-06-21 23:03:12,555 epoch 7 - iter 40/80 - loss 0.43952670 - samples/sec: 77.43 - lr: 0.000030
2021-06-21 23:03:15,838 epoch 7 - iter 48/80 - loss 0.44677806 - samples/sec: 78.00 - lr: 0.000030
2021-06-21 23:03:19,131 epoch 7 - iter 56/80 - loss 0.44676335 - samples/sec: 77.76 - lr: 0.000030
2021-06-21 23:03:22,438 epoch 7 - iter 64/80 - loss 0.44392586 - samples/sec: 77.42 - lr: 0.000030
2021-06-21 23:03:25,694 epoch 7 - iter 72/80 - loss 0.43192255 - samples/sec: 78.66 - lr: 0.000030
2021-06-21 23:03:28,723 epoch 7 - iter 80/80 - loss 0.42619632 - samples/sec: 84.54 - lr: 0.000030
2021-06-21 23:03:28,723 ----------------------------------------------------------------------------------------------------
2021-06-21 23:03:28,723 EPOCH 7 done: loss 0.4262 - lr 0.0000300
2021-06-21 23:03:31,178 DEV : loss 0.3617613911628723 - score 0.9307
2021-06-21 23:03:31,216 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:03:35,318 ----------------------------------------------------------------------------------------------------
2021-06-21 23:03:38,607 epoch 8 - iter 8/80 - loss 0.42826528 - samples/sec: 77.86 - lr: 0.000030
2021-06-21 23:03:41,903 epoch 8 - iter 16/80 - loss 0.39387770 - samples/sec: 77.70 - lr: 0.000030
2021-06-21 23:03:45,190 epoch 8 - iter 24/80 - loss 0.37881947 - samples/sec: 77.91 - lr: 0.000030
2021-06-21 23:03:48,492 epoch 8 - iter 32/80 - loss 0.37306858 - samples/sec: 77.53 - lr: 0.000030
2021-06-21 23:03:51,776 epoch 8 - iter 40/80 - loss 0.39768915 - samples/sec: 77.98 - lr: 0.000030
2021-06-21 23:03:55,069 epoch 8 - iter 48/80 - loss 0.38571311 - samples/sec: 77.76 - lr: 0.000030
2021-06-21 23:03:58,317 epoch 8 - iter 56/80 - loss 0.38049306 - samples/sec: 78.84 - lr: 0.000030
2021-06-21 23:04:01,608 epoch 8 - iter 64/80 - loss 0.37734258 - samples/sec: 77.80 - lr: 0.000030
2021-06-21 23:04:04,883 epoch 8 - iter 72/80 - loss 0.38003328 - samples/sec: 78.17 - lr: 0.000030
2021-06-21 23:04:07,917 epoch 8 - iter 80/80 - loss 0.37526152 - samples/sec: 84.42 - lr: 0.000030
2021-06-21 23:04:07,917 ----------------------------------------------------------------------------------------------------
2021-06-21 23:04:07,917 EPOCH 8 done: loss 0.3753 - lr 0.0000300
2021-06-21 23:04:10,367 DEV : loss 0.33759605884552 - score 0.9286
2021-06-21 23:04:10,406 BAD EPOCHS (no improvement): 1
2021-06-21 23:04:10,407 ----------------------------------------------------------------------------------------------------
2021-06-21 23:04:13,700 epoch 9 - iter 8/80 - loss 0.43614639 - samples/sec: 77.76 - lr: 0.000030
2021-06-21 23:04:16,977 epoch 9 - iter 16/80 - loss 0.42277429 - samples/sec: 78.14 - lr: 0.000030
2021-06-21 23:04:20,246 epoch 9 - iter 24/80 - loss 0.38370678 - samples/sec: 78.32 - lr: 0.000030
2021-06-21 23:04:23,546 epoch 9 - iter 32/80 - loss 0.36889747 - samples/sec: 77.58 - lr: 0.000030
2021-06-21 23:04:26,817 epoch 9 - iter 40/80 - loss 0.36148378 - samples/sec: 78.28 - lr: 0.000030
2021-06-21 23:04:30,081 epoch 9 - iter 48/80 - loss 0.35246692 - samples/sec: 78.45 - lr: 0.000030
2021-06-21 23:04:33,326 epoch 9 - iter 56/80 - loss 0.35127961 - samples/sec: 78.89 - lr: 0.000030
2021-06-21 23:04:36,583 epoch 9 - iter 64/80 - loss 0.34369954 - samples/sec: 78.62 - lr: 0.000030
2021-06-21 23:04:39,844 epoch 9 - iter 72/80 - loss 0.35318051 - samples/sec: 78.52 - lr: 0.000030
2021-06-21 23:04:42,887 epoch 9 - iter 80/80 - loss 0.35093409 - samples/sec: 84.16 - lr: 0.000030
2021-06-21 23:04:42,887 ----------------------------------------------------------------------------------------------------
2021-06-21 23:04:42,887 EPOCH 9 done: loss 0.3509 - lr 0.0000300
2021-06-21 23:04:45,556 DEV : loss 0.2951861023902893 - score 0.9349
2021-06-21 23:04:45,595 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:04:49,680 ----------------------------------------------------------------------------------------------------
2021-06-21 23:04:52,912 epoch 10 - iter 8/80 - loss 0.31514328 - samples/sec: 79.22 - lr: 0.000030
2021-06-21 23:04:56,187 epoch 10 - iter 16/80 - loss 0.31834920 - samples/sec: 78.18 - lr: 0.000030
2021-06-21 23:04:59,464 epoch 10 - iter 24/80 - loss 0.31338142 - samples/sec: 78.15 - lr: 0.000030
2021-06-21 23:05:02,729 epoch 10 - iter 32/80 - loss 0.33709012 - samples/sec: 78.42 - lr: 0.000030
2021-06-21 23:05:06,017 epoch 10 - iter 40/80 - loss 0.33299853 - samples/sec: 77.89 - lr: 0.000030
2021-06-21 23:05:09,314 epoch 10 - iter 48/80 - loss 0.33286086 - samples/sec: 77.66 - lr: 0.000030
2021-06-21 23:05:12,596 epoch 10 - iter 56/80 - loss 0.32663887 - samples/sec: 78.01 - lr: 0.000030
2021-06-21 23:05:15,880 epoch 10 - iter 64/80 - loss 0.32300700 - samples/sec: 77.98 - lr: 0.000030
2021-06-21 23:05:19,168 epoch 10 - iter 72/80 - loss 0.31781357 - samples/sec: 77.87 - lr: 0.000030
2021-06-21 23:05:22,195 epoch 10 - iter 80/80 - loss 0.31471886 - samples/sec: 84.59 - lr: 0.000030
2021-06-21 23:05:22,195 ----------------------------------------------------------------------------------------------------
2021-06-21 23:05:22,195 EPOCH 10 done: loss 0.3147 - lr 0.0000300
2021-06-21 23:05:24,649 DEV : loss 0.2814641296863556 - score 0.9389
2021-06-21 23:05:24,688 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:05:29,150 ----------------------------------------------------------------------------------------------------
2021-06-21 23:05:32,420 epoch 11 - iter 8/80 - loss 0.29579600 - samples/sec: 78.30 - lr: 0.000030
2021-06-21 23:05:35,719 epoch 11 - iter 16/80 - loss 0.28182923 - samples/sec: 77.62 - lr: 0.000030
2021-06-21 23:05:39,006 epoch 11 - iter 24/80 - loss 0.27501407 - samples/sec: 77.91 - lr: 0.000030
2021-06-21 23:05:42,241 epoch 11 - iter 32/80 - loss 0.28677965 - samples/sec: 79.15 - lr: 0.000030
2021-06-21 23:05:45,539 epoch 11 - iter 40/80 - loss 0.29462854 - samples/sec: 77.66 - lr: 0.000030
2021-06-21 23:05:48,803 epoch 11 - iter 48/80 - loss 0.29566659 - samples/sec: 78.43 - lr: 0.000030
2021-06-21 23:05:52,027 epoch 11 - iter 56/80 - loss 0.28393862 - samples/sec: 79.45 - lr: 0.000030
2021-06-21 23:05:55,318 epoch 11 - iter 64/80 - loss 0.28774290 - samples/sec: 77.80 - lr: 0.000030
2021-06-21 23:05:58,613 epoch 11 - iter 72/80 - loss 0.28553237 - samples/sec: 77.70 - lr: 0.000030
2021-06-21 23:06:01,631 epoch 11 - iter 80/80 - loss 0.28501813 - samples/sec: 84.85 - lr: 0.000030
2021-06-21 23:06:01,631 ----------------------------------------------------------------------------------------------------
2021-06-21 23:06:01,631 EPOCH 11 done: loss 0.2850 - lr 0.0000300
2021-06-21 23:06:04,087 DEV : loss 0.2685922384262085 - score 0.9428
2021-06-21 23:06:04,126 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:06:08,345 ----------------------------------------------------------------------------------------------------
2021-06-21 23:06:11,603 epoch 12 - iter 8/80 - loss 0.31717905 - samples/sec: 78.61 - lr: 0.000030
2021-06-21 23:06:14,872 epoch 12 - iter 16/80 - loss 0.32394692 - samples/sec: 78.33 - lr: 0.000030
2021-06-21 23:06:18,105 epoch 12 - iter 24/80 - loss 0.30790689 - samples/sec: 79.20 - lr: 0.000030
2021-06-21 23:06:21,417 epoch 12 - iter 32/80 - loss 0.30749677 - samples/sec: 77.31 - lr: 0.000030
2021-06-21 23:06:24,730 epoch 12 - iter 40/80 - loss 0.29583260 - samples/sec: 77.29 - lr: 0.000030
2021-06-21 23:06:28,007 epoch 12 - iter 48/80 - loss 0.28877878 - samples/sec: 78.14 - lr: 0.000030
2021-06-21 23:06:31,258 epoch 12 - iter 56/80 - loss 0.28407872 - samples/sec: 78.76 - lr: 0.000030
2021-06-21 23:06:34,554 epoch 12 - iter 64/80 - loss 0.28744086 - samples/sec: 77.69 - lr: 0.000030
2021-06-21 23:06:37,838 epoch 12 - iter 72/80 - loss 0.28392963 - samples/sec: 77.97 - lr: 0.000030
2021-06-21 23:06:40,865 epoch 12 - iter 80/80 - loss 0.28192603 - samples/sec: 84.59 - lr: 0.000030
2021-06-21 23:06:40,865 ----------------------------------------------------------------------------------------------------
2021-06-21 23:06:40,866 EPOCH 12 done: loss 0.2819 - lr 0.0000300
2021-06-21 23:06:43,320 DEV : loss 0.26109078526496887 - score 0.9382
2021-06-21 23:06:43,359 BAD EPOCHS (no improvement): 1
2021-06-21 23:06:43,360 ----------------------------------------------------------------------------------------------------
2021-06-21 23:06:46,599 epoch 13 - iter 8/80 - loss 0.27009122 - samples/sec: 79.05 - lr: 0.000030
2021-06-21 23:06:49,891 epoch 13 - iter 16/80 - loss 0.27521364 - samples/sec: 77.78 - lr: 0.000030
2021-06-21 23:06:53,188 epoch 13 - iter 24/80 - loss 0.26820482 - samples/sec: 77.66 - lr: 0.000030
2021-06-21 23:06:56,470 epoch 13 - iter 32/80 - loss 0.25616906 - samples/sec: 78.02 - lr: 0.000030
2021-06-21 23:06:59,776 epoch 13 - iter 40/80 - loss 0.25806857 - samples/sec: 77.44 - lr: 0.000030
2021-06-21 23:07:03,063 epoch 13 - iter 48/80 - loss 0.25217417 - samples/sec: 77.90 - lr: 0.000030
2021-06-21 23:07:06,317 epoch 13 - iter 56/80 - loss 0.24050098 - samples/sec: 78.70 - lr: 0.000030
2021-06-21 23:07:09,571 epoch 13 - iter 64/80 - loss 0.24233926 - samples/sec: 78.68 - lr: 0.000030
2021-06-21 23:07:12,845 epoch 13 - iter 72/80 - loss 0.24658964 - samples/sec: 78.21 - lr: 0.000030
2021-06-21 23:07:15,888 epoch 13 - iter 80/80 - loss 0.24774646 - samples/sec: 84.16 - lr: 0.000030
2021-06-21 23:07:15,888 ----------------------------------------------------------------------------------------------------
2021-06-21 23:07:15,888 EPOCH 13 done: loss 0.2477 - lr 0.0000300
2021-06-21 23:07:18,562 DEV : loss 0.25309324264526367 - score 0.9371
2021-06-21 23:07:18,601 BAD EPOCHS (no improvement): 2
2021-06-21 23:07:18,601 ----------------------------------------------------------------------------------------------------
2021-06-21 23:07:21,857 epoch 14 - iter 8/80 - loss 0.26557011 - samples/sec: 78.66 - lr: 0.000030
2021-06-21 23:07:25,158 epoch 14 - iter 16/80 - loss 0.25873804 - samples/sec: 77.55 - lr: 0.000030
2021-06-21 23:07:28,415 epoch 14 - iter 24/80 - loss 0.26369144 - samples/sec: 78.64 - lr: 0.000030
2021-06-21 23:07:31,717 epoch 14 - iter 32/80 - loss 0.25993340 - samples/sec: 77.56 - lr: 0.000030
2021-06-21 23:07:34,997 epoch 14 - iter 40/80 - loss 0.25416248 - samples/sec: 78.04 - lr: 0.000030
2021-06-21 23:07:38,259 epoch 14 - iter 48/80 - loss 0.24211775 - samples/sec: 78.51 - lr: 0.000030
2021-06-21 23:07:41,574 epoch 14 - iter 56/80 - loss 0.24268296 - samples/sec: 77.25 - lr: 0.000030
2021-06-21 23:07:44,849 epoch 14 - iter 64/80 - loss 0.23680593 - samples/sec: 78.19 - lr: 0.000030
2021-06-21 23:07:48,141 epoch 14 - iter 72/80 - loss 0.24539818 - samples/sec: 77.77 - lr: 0.000030
2021-06-21 23:07:51,170 epoch 14 - iter 80/80 - loss 0.24221672 - samples/sec: 84.53 - lr: 0.000030
2021-06-21 23:07:51,171 ----------------------------------------------------------------------------------------------------
2021-06-21 23:07:51,171 EPOCH 14 done: loss 0.2422 - lr 0.0000300
2021-06-21 23:07:53,625 DEV : loss 0.24512897431850433 - score 0.9436
2021-06-21 23:07:53,664 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:07:57,775 ----------------------------------------------------------------------------------------------------
2021-06-21 23:08:01,064 epoch 15 - iter 8/80 - loss 0.18149815 - samples/sec: 77.86 - lr: 0.000030
2021-06-21 23:08:04,325 epoch 15 - iter 16/80 - loss 0.19837539 - samples/sec: 78.53 - lr: 0.000030
2021-06-21 23:08:07,600 epoch 15 - iter 24/80 - loss 0.19784065 - samples/sec: 78.18 - lr: 0.000030
2021-06-21 23:08:10,900 epoch 15 - iter 32/80 - loss 0.20530350 - samples/sec: 77.59 - lr: 0.000030
2021-06-21 23:08:14,189 epoch 15 - iter 40/80 - loss 0.20335242 - samples/sec: 77.87 - lr: 0.000030
2021-06-21 23:08:17,467 epoch 15 - iter 48/80 - loss 0.20733744 - samples/sec: 78.11 - lr: 0.000030
2021-06-21 23:08:20,797 epoch 15 - iter 56/80 - loss 0.20862963 - samples/sec: 76.89 - lr: 0.000030
2021-06-21 23:08:24,088 epoch 15 - iter 64/80 - loss 0.20915960 - samples/sec: 77.80 - lr: 0.000030
2021-06-21 23:08:27,405 epoch 15 - iter 72/80 - loss 0.21295403 - samples/sec: 77.18 - lr: 0.000030
2021-06-21 23:08:30,407 epoch 15 - iter 80/80 - loss 0.21132665 - samples/sec: 85.32 - lr: 0.000030
2021-06-21 23:08:30,407 ----------------------------------------------------------------------------------------------------
2021-06-21 23:08:30,407 EPOCH 15 done: loss 0.2113 - lr 0.0000300
2021-06-21 23:08:32,869 DEV : loss 0.24358431994915009 - score 0.9447
2021-06-21 23:08:32,907 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:08:37,107 ----------------------------------------------------------------------------------------------------
2021-06-21 23:08:40,371 epoch 16 - iter 8/80 - loss 0.20622149 - samples/sec: 78.47 - lr: 0.000030
2021-06-21 23:08:43,639 epoch 16 - iter 16/80 - loss 0.20190751 - samples/sec: 78.33 - lr: 0.000030
2021-06-21 23:08:46,929 epoch 16 - iter 24/80 - loss 0.19778814 - samples/sec: 77.83 - lr: 0.000030
2021-06-21 23:08:50,216 epoch 16 - iter 32/80 - loss 0.18950766 - samples/sec: 77.92 - lr: 0.000030
2021-06-21 23:08:53,487 epoch 16 - iter 40/80 - loss 0.18313184 - samples/sec: 78.27 - lr: 0.000030
2021-06-21 23:08:56,792 epoch 16 - iter 48/80 - loss 0.17942629 - samples/sec: 77.48 - lr: 0.000030
2021-06-21 23:09:00,092 epoch 16 - iter 56/80 - loss 0.18384939 - samples/sec: 77.58 - lr: 0.000030
2021-06-21 23:09:03,396 epoch 16 - iter 64/80 - loss 0.18565886 - samples/sec: 77.52 - lr: 0.000030
2021-06-21 23:09:06,684 epoch 16 - iter 72/80 - loss 0.18905266 - samples/sec: 77.87 - lr: 0.000030
2021-06-21 23:09:09,767 epoch 16 - iter 80/80 - loss 0.19615172 - samples/sec: 83.04 - lr: 0.000030
2021-06-21 23:09:09,768 ----------------------------------------------------------------------------------------------------
2021-06-21 23:09:09,768 EPOCH 16 done: loss 0.1962 - lr 0.0000300
2021-06-21 23:09:12,459 DEV : loss 0.2343984991312027 - score 0.9452
2021-06-21 23:09:12,498 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:09:16,609 ----------------------------------------------------------------------------------------------------
2021-06-21 23:09:19,910 epoch 17 - iter 8/80 - loss 0.14782809 - samples/sec: 77.57 - lr: 0.000030
2021-06-21 23:09:23,202 epoch 17 - iter 16/80 - loss 0.15516626 - samples/sec: 77.77 - lr: 0.000030
2021-06-21 23:09:26,466 epoch 17 - iter 24/80 - loss 0.15592133 - samples/sec: 78.45 - lr: 0.000030
2021-06-21 23:09:29,752 epoch 17 - iter 32/80 - loss 0.18083128 - samples/sec: 77.93 - lr: 0.000030
2021-06-21 23:09:33,031 epoch 17 - iter 40/80 - loss 0.19172698 - samples/sec: 78.09 - lr: 0.000030
2021-06-21 23:09:36,321 epoch 17 - iter 48/80 - loss 0.18458930 - samples/sec: 77.81 - lr: 0.000030
2021-06-21 23:09:39,591 epoch 17 - iter 56/80 - loss 0.19228226 - samples/sec: 78.30 - lr: 0.000030
2021-06-21 23:09:42,885 epoch 17 - iter 64/80 - loss 0.18980034 - samples/sec: 77.75 - lr: 0.000030
2021-06-21 23:09:46,190 epoch 17 - iter 72/80 - loss 0.19192412 - samples/sec: 77.47 - lr: 0.000030
2021-06-21 23:09:49,238 epoch 17 - iter 80/80 - loss 0.19498903 - samples/sec: 83.99 - lr: 0.000030
2021-06-21 23:09:49,239 ----------------------------------------------------------------------------------------------------
2021-06-21 23:09:49,239 EPOCH 17 done: loss 0.1950 - lr 0.0000300
2021-06-21 23:09:51,704 DEV : loss 0.21647554636001587 - score 0.9487
2021-06-21 23:09:51,743 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:09:55,957 ----------------------------------------------------------------------------------------------------
2021-06-21 23:09:59,237 epoch 18 - iter 8/80 - loss 0.16752835 - samples/sec: 78.08 - lr: 0.000030
2021-06-21 23:10:02,517 epoch 18 - iter 16/80 - loss 0.19557213 - samples/sec: 78.08 - lr: 0.000030
2021-06-21 23:10:05,803 epoch 18 - iter 24/80 - loss 0.19949929 - samples/sec: 77.92 - lr: 0.000030
2021-06-21 23:10:09,107 epoch 18 - iter 32/80 - loss 0.19288314 - samples/sec: 77.49 - lr: 0.000030
2021-06-21 23:10:12,404 epoch 18 - iter 40/80 - loss 0.19268383 - samples/sec: 77.67 - lr: 0.000030
2021-06-21 23:10:15,719 epoch 18 - iter 48/80 - loss 0.18802794 - samples/sec: 77.24 - lr: 0.000030
2021-06-21 23:10:18,982 epoch 18 - iter 56/80 - loss 0.18445015 - samples/sec: 78.45 - lr: 0.000030
2021-06-21 23:10:22,271 epoch 18 - iter 64/80 - loss 0.18450945 - samples/sec: 77.85 - lr: 0.000030
2021-06-21 23:10:25,604 epoch 18 - iter 72/80 - loss 0.18227603 - samples/sec: 76.84 - lr: 0.000030
2021-06-21 23:10:28,647 epoch 18 - iter 80/80 - loss 0.17711100 - samples/sec: 84.14 - lr: 0.000030
2021-06-21 23:10:28,647 ----------------------------------------------------------------------------------------------------
2021-06-21 23:10:28,647 EPOCH 18 done: loss 0.1771 - lr 0.0000300
2021-06-21 23:10:31,111 DEV : loss 0.23299747705459595 - score 0.9498
2021-06-21 23:10:31,151 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:10:35,368 ----------------------------------------------------------------------------------------------------
2021-06-21 23:10:38,627 epoch 19 - iter 8/80 - loss 0.13224925 - samples/sec: 78.58 - lr: 0.000030
2021-06-21 23:10:41,923 epoch 19 - iter 16/80 - loss 0.15425391 - samples/sec: 77.68 - lr: 0.000030
2021-06-21 23:10:45,250 epoch 19 - iter 24/80 - loss 0.17936751 - samples/sec: 76.97 - lr: 0.000030
2021-06-21 23:10:48,537 epoch 19 - iter 32/80 - loss 0.17927705 - samples/sec: 77.89 - lr: 0.000030
2021-06-21 23:10:51,790 epoch 19 - iter 40/80 - loss 0.17877669 - samples/sec: 78.73 - lr: 0.000030
2021-06-21 23:10:55,070 epoch 19 - iter 48/80 - loss 0.19844913 - samples/sec: 78.06 - lr: 0.000030
2021-06-21 23:10:58,357 epoch 19 - iter 56/80 - loss 0.18955650 - samples/sec: 77.89 - lr: 0.000030
2021-06-21 23:11:01,638 epoch 19 - iter 64/80 - loss 0.18049275 - samples/sec: 78.04 - lr: 0.000030
2021-06-21 23:11:04,954 epoch 19 - iter 72/80 - loss 0.18491078 - samples/sec: 77.21 - lr: 0.000030
2021-06-21 23:11:08,008 epoch 19 - iter 80/80 - loss 0.19945239 - samples/sec: 83.85 - lr: 0.000030
2021-06-21 23:11:08,009 ----------------------------------------------------------------------------------------------------
2021-06-21 23:11:08,009 EPOCH 19 done: loss 0.1995 - lr 0.0000300
2021-06-21 23:11:10,701 DEV : loss 0.20877954363822937 - score 0.951
2021-06-21 23:11:10,740 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:11:14,923 ----------------------------------------------------------------------------------------------------
2021-06-21 23:11:18,201 epoch 20 - iter 8/80 - loss 0.16777067 - samples/sec: 78.12 - lr: 0.000030
2021-06-21 23:11:21,494 epoch 20 - iter 16/80 - loss 0.15249922 - samples/sec: 77.75 - lr: 0.000030
2021-06-21 23:11:24,774 epoch 20 - iter 24/80 - loss 0.16656655 - samples/sec: 78.08 - lr: 0.000030
2021-06-21 23:11:28,066 epoch 20 - iter 32/80 - loss 0.16850084 - samples/sec: 77.79 - lr: 0.000030
2021-06-21 23:11:31,378 epoch 20 - iter 40/80 - loss 0.16946591 - samples/sec: 77.31 - lr: 0.000030
2021-06-21 23:11:34,668 epoch 20 - iter 48/80 - loss 0.16336076 - samples/sec: 77.82 - lr: 0.000030
2021-06-21 23:11:37,972 epoch 20 - iter 56/80 - loss 0.16125860 - samples/sec: 77.49 - lr: 0.000030
2021-06-21 23:11:41,247 epoch 20 - iter 64/80 - loss 0.16047508 - samples/sec: 78.20 - lr: 0.000030
2021-06-21 23:11:44,524 epoch 20 - iter 72/80 - loss 0.16154825 - samples/sec: 78.13 - lr: 0.000030
2021-06-21 23:11:47,547 epoch 20 - iter 80/80 - loss 0.17462521 - samples/sec: 84.70 - lr: 0.000030
2021-06-21 23:11:47,547 ----------------------------------------------------------------------------------------------------
2021-06-21 23:11:47,548 EPOCH 20 done: loss 0.1746 - lr 0.0000300
2021-06-21 23:11:50,005 DEV : loss 0.2241026610136032 - score 0.9439
2021-06-21 23:11:50,044 BAD EPOCHS (no improvement): 1
2021-06-21 23:11:50,044 ----------------------------------------------------------------------------------------------------
2021-06-21 23:11:53,325 epoch 21 - iter 8/80 - loss 0.09373600 - samples/sec: 78.05 - lr: 0.000030
2021-06-21 23:11:56,610 epoch 21 - iter 16/80 - loss 0.11458552 - samples/sec: 77.94 - lr: 0.000030
2021-06-21 23:11:59,902 epoch 21 - iter 24/80 - loss 0.12294656 - samples/sec: 77.78 - lr: 0.000030
2021-06-21 23:12:03,205 epoch 21 - iter 32/80 - loss 0.12761312 - samples/sec: 77.53 - lr: 0.000030
2021-06-21 23:12:06,492 epoch 21 - iter 40/80 - loss 0.13629141 - samples/sec: 77.90 - lr: 0.000030
2021-06-21 23:12:09,773 epoch 21 - iter 48/80 - loss 0.13570785 - samples/sec: 78.04 - lr: 0.000030
2021-06-21 23:12:13,081 epoch 21 - iter 56/80 - loss 0.14396286 - samples/sec: 77.40 - lr: 0.000030
2021-06-21 23:12:16,328 epoch 21 - iter 64/80 - loss 0.14858363 - samples/sec: 78.85 - lr: 0.000030
2021-06-21 23:12:19,634 epoch 21 - iter 72/80 - loss 0.14948091 - samples/sec: 77.45 - lr: 0.000030
2021-06-21 23:12:22,688 epoch 21 - iter 80/80 - loss 0.15155581 - samples/sec: 83.86 - lr: 0.000030
2021-06-21 23:12:22,688 ----------------------------------------------------------------------------------------------------
2021-06-21 23:12:22,688 EPOCH 21 done: loss 0.1516 - lr 0.0000300
2021-06-21 23:12:25,148 DEV : loss 0.22361138463020325 - score 0.9501
2021-06-21 23:12:25,187 BAD EPOCHS (no improvement): 2
2021-06-21 23:12:25,187 ----------------------------------------------------------------------------------------------------
2021-06-21 23:12:28,436 epoch 22 - iter 8/80 - loss 0.15692303 - samples/sec: 78.81 - lr: 0.000030
2021-06-21 23:12:31,701 epoch 22 - iter 16/80 - loss 0.13882200 - samples/sec: 78.44 - lr: 0.000030
2021-06-21 23:12:34,943 epoch 22 - iter 24/80 - loss 0.14309224 - samples/sec: 78.96 - lr: 0.000030
2021-06-21 23:12:38,181 epoch 22 - iter 32/80 - loss 0.13453384 - samples/sec: 79.08 - lr: 0.000030
2021-06-21 23:12:41,453 epoch 22 - iter 40/80 - loss 0.13369933 - samples/sec: 78.26 - lr: 0.000030
2021-06-21 23:12:44,732 epoch 22 - iter 48/80 - loss 0.14643981 - samples/sec: 78.11 - lr: 0.000030
2021-06-21 23:12:47,970 epoch 22 - iter 56/80 - loss 0.14694724 - samples/sec: 79.07 - lr: 0.000030
2021-06-21 23:12:51,237 epoch 22 - iter 64/80 - loss 0.15047233 - samples/sec: 78.37 - lr: 0.000030
2021-06-21 23:12:54,458 epoch 22 - iter 72/80 - loss 0.15510557 - samples/sec: 79.50 - lr: 0.000030
2021-06-21 23:12:57,505 epoch 22 - iter 80/80 - loss 0.16005245 - samples/sec: 84.03 - lr: 0.000030
2021-06-21 23:12:57,505 ----------------------------------------------------------------------------------------------------
2021-06-21 23:12:57,505 EPOCH 22 done: loss 0.1601 - lr 0.0000300
2021-06-21 23:13:00,190 DEV : loss 0.21286511421203613 - score 0.9569
2021-06-21 23:13:00,228 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:13:04,455 ----------------------------------------------------------------------------------------------------
2021-06-21 23:13:07,711 epoch 23 - iter 8/80 - loss 0.15711041 - samples/sec: 78.65 - lr: 0.000030
2021-06-21 23:13:10,971 epoch 23 - iter 16/80 - loss 0.15183331 - samples/sec: 78.55 - lr: 0.000030
2021-06-21 23:13:14,239 epoch 23 - iter 24/80 - loss 0.15154025 - samples/sec: 78.36 - lr: 0.000030
2021-06-21 23:13:17,464 epoch 23 - iter 32/80 - loss 0.13730717 - samples/sec: 79.40 - lr: 0.000030
2021-06-21 23:13:20,691 epoch 23 - iter 40/80 - loss 0.13880154 - samples/sec: 79.35 - lr: 0.000030
2021-06-21 23:13:23,953 epoch 23 - iter 48/80 - loss 0.14398831 - samples/sec: 78.48 - lr: 0.000030
2021-06-21 23:13:27,236 epoch 23 - iter 56/80 - loss 0.14110991 - samples/sec: 78.01 - lr: 0.000030
2021-06-21 23:13:30,520 epoch 23 - iter 64/80 - loss 0.14290685 - samples/sec: 77.98 - lr: 0.000030
2021-06-21 23:13:33,782 epoch 23 - iter 72/80 - loss 0.14391569 - samples/sec: 78.49 - lr: 0.000030
2021-06-21 23:13:36,806 epoch 23 - iter 80/80 - loss 0.14710137 - samples/sec: 84.68 - lr: 0.000030
2021-06-21 23:13:36,806 ----------------------------------------------------------------------------------------------------
2021-06-21 23:13:36,806 EPOCH 23 done: loss 0.1471 - lr 0.0000300
2021-06-21 23:13:39,267 DEV : loss 0.21141469478607178 - score 0.9549
2021-06-21 23:13:39,305 BAD EPOCHS (no improvement): 1
2021-06-21 23:13:39,305 ----------------------------------------------------------------------------------------------------
2021-06-21 23:13:42,542 epoch 24 - iter 8/80 - loss 0.16857816 - samples/sec: 79.10 - lr: 0.000030
2021-06-21 23:13:45,797 epoch 24 - iter 16/80 - loss 0.14925325 - samples/sec: 78.68 - lr: 0.000030
2021-06-21 23:13:49,036 epoch 24 - iter 24/80 - loss 0.13629909 - samples/sec: 79.05 - lr: 0.000030
2021-06-21 23:13:52,310 epoch 24 - iter 32/80 - loss 0.14040787 - samples/sec: 78.21 - lr: 0.000030
2021-06-21 23:13:55,563 epoch 24 - iter 40/80 - loss 0.13782170 - samples/sec: 78.72 - lr: 0.000030
2021-06-21 23:13:58,835 epoch 24 - iter 48/80 - loss 0.13951259 - samples/sec: 78.26 - lr: 0.000030
2021-06-21 23:14:02,085 epoch 24 - iter 56/80 - loss 0.13663427 - samples/sec: 78.79 - lr: 0.000030
2021-06-21 23:14:05,379 epoch 24 - iter 64/80 - loss 0.14195904 - samples/sec: 77.72 - lr: 0.000030
2021-06-21 23:14:08,666 epoch 24 - iter 72/80 - loss 0.14457331 - samples/sec: 77.92 - lr: 0.000030
2021-06-21 23:14:11,680 epoch 24 - iter 80/80 - loss 0.14362432 - samples/sec: 84.94 - lr: 0.000030
2021-06-21 23:14:11,681 ----------------------------------------------------------------------------------------------------
2021-06-21 23:14:11,681 EPOCH 24 done: loss 0.1436 - lr 0.0000300
2021-06-21 23:14:14,141 DEV : loss 0.20972144603729248 - score 0.9527
2021-06-21 23:14:14,181 BAD EPOCHS (no improvement): 2
2021-06-21 23:14:14,181 ----------------------------------------------------------------------------------------------------
2021-06-21 23:14:17,437 epoch 25 - iter 8/80 - loss 0.13791901 - samples/sec: 78.64 - lr: 0.000030
2021-06-21 23:14:20,686 epoch 25 - iter 16/80 - loss 0.16019543 - samples/sec: 78.83 - lr: 0.000030
2021-06-21 23:14:23,936 epoch 25 - iter 24/80 - loss 0.13677259 - samples/sec: 78.77 - lr: 0.000030
2021-06-21 23:14:27,182 epoch 25 - iter 32/80 - loss 0.13621515 - samples/sec: 78.89 - lr: 0.000030
2021-06-21 23:14:30,394 epoch 25 - iter 40/80 - loss 0.13395396 - samples/sec: 79.72 - lr: 0.000030
2021-06-21 23:14:33,689 epoch 25 - iter 48/80 - loss 0.13703451 - samples/sec: 77.70 - lr: 0.000030
2021-06-21 23:14:36,926 epoch 25 - iter 56/80 - loss 0.13498121 - samples/sec: 79.12 - lr: 0.000030
2021-06-21 23:14:40,231 epoch 25 - iter 64/80 - loss 0.13856407 - samples/sec: 77.47 - lr: 0.000030
2021-06-21 23:14:43,527 epoch 25 - iter 72/80 - loss 0.13860820 - samples/sec: 77.68 - lr: 0.000030
2021-06-21 23:14:46,538 epoch 25 - iter 80/80 - loss 0.13929035 - samples/sec: 85.05 - lr: 0.000030
2021-06-21 23:14:46,538 ----------------------------------------------------------------------------------------------------
2021-06-21 23:14:46,538 EPOCH 25 done: loss 0.1393 - lr 0.0000300
2021-06-21 23:14:48,998 DEV : loss 0.2005365937948227 - score 0.9542
2021-06-21 23:14:49,037 BAD EPOCHS (no improvement): 3
2021-06-21 23:14:49,038 ----------------------------------------------------------------------------------------------------
2021-06-21 23:14:52,291 epoch 26 - iter 8/80 - loss 0.12410719 - samples/sec: 78.72 - lr: 0.000030
2021-06-21 23:14:55,542 epoch 26 - iter 16/80 - loss 0.15063099 - samples/sec: 78.75 - lr: 0.000030
2021-06-21 23:14:58,820 epoch 26 - iter 24/80 - loss 0.15336273 - samples/sec: 78.11 - lr: 0.000030
2021-06-21 23:15:02,092 epoch 26 - iter 32/80 - loss 0.14039386 - samples/sec: 78.26 - lr: 0.000030
2021-06-21 23:15:05,329 epoch 26 - iter 40/80 - loss 0.13551417 - samples/sec: 79.11 - lr: 0.000030
2021-06-21 23:15:08,600 epoch 26 - iter 48/80 - loss 0.13484216 - samples/sec: 78.28 - lr: 0.000030
2021-06-21 23:15:11,871 epoch 26 - iter 56/80 - loss 0.13345835 - samples/sec: 78.29 - lr: 0.000030
2021-06-21 23:15:15,129 epoch 26 - iter 64/80 - loss 0.13436027 - samples/sec: 78.60 - lr: 0.000030
2021-06-21 23:15:18,382 epoch 26 - iter 72/80 - loss 0.13210516 - samples/sec: 78.71 - lr: 0.000030
2021-06-21 23:15:21,412 epoch 26 - iter 80/80 - loss 0.13087592 - samples/sec: 84.49 - lr: 0.000030
2021-06-21 23:15:21,413 ----------------------------------------------------------------------------------------------------
2021-06-21 23:15:21,413 EPOCH 26 done: loss 0.1309 - lr 0.0000300
2021-06-21 23:15:24,101 DEV : loss 0.19619567692279816 - score 0.9519
Epoch    26: reducing learning rate of group 0 to 1.5000e-05.
2021-06-21 23:15:24,140 BAD EPOCHS (no improvement): 4
2021-06-21 23:15:24,140 ----------------------------------------------------------------------------------------------------
2021-06-21 23:15:27,392 epoch 27 - iter 8/80 - loss 0.13439184 - samples/sec: 78.75 - lr: 0.000015
2021-06-21 23:15:30,663 epoch 27 - iter 16/80 - loss 0.12963408 - samples/sec: 78.27 - lr: 0.000015
2021-06-21 23:15:33,888 epoch 27 - iter 24/80 - loss 0.12911691 - samples/sec: 79.39 - lr: 0.000015
2021-06-21 23:15:37,144 epoch 27 - iter 32/80 - loss 0.12128158 - samples/sec: 78.64 - lr: 0.000015
2021-06-21 23:15:40,399 epoch 27 - iter 40/80 - loss 0.11560219 - samples/sec: 78.67 - lr: 0.000015
2021-06-21 23:15:43,650 epoch 27 - iter 48/80 - loss 0.11631788 - samples/sec: 78.75 - lr: 0.000015
2021-06-21 23:15:46,925 epoch 27 - iter 56/80 - loss 0.12206674 - samples/sec: 78.19 - lr: 0.000015
2021-06-21 23:15:50,200 epoch 27 - iter 64/80 - loss 0.12459286 - samples/sec: 78.18 - lr: 0.000015
2021-06-21 23:15:53,498 epoch 27 - iter 72/80 - loss 0.12057318 - samples/sec: 77.64 - lr: 0.000015
2021-06-21 23:15:56,524 epoch 27 - iter 80/80 - loss 0.11821104 - samples/sec: 84.64 - lr: 0.000015
2021-06-21 23:15:56,524 ----------------------------------------------------------------------------------------------------
2021-06-21 23:15:56,524 EPOCH 27 done: loss 0.1182 - lr 0.0000150
2021-06-21 23:15:58,981 DEV : loss 0.20751789212226868 - score 0.952
2021-06-21 23:15:59,020 BAD EPOCHS (no improvement): 1
2021-06-21 23:15:59,020 ----------------------------------------------------------------------------------------------------
2021-06-21 23:16:02,301 epoch 28 - iter 8/80 - loss 0.12359080 - samples/sec: 78.05 - lr: 0.000015
2021-06-21 23:16:05,572 epoch 28 - iter 16/80 - loss 0.12324044 - samples/sec: 78.27 - lr: 0.000015
2021-06-21 23:16:08,821 epoch 28 - iter 24/80 - loss 0.12600527 - samples/sec: 78.81 - lr: 0.000015
2021-06-21 23:16:12,073 epoch 28 - iter 32/80 - loss 0.12421346 - samples/sec: 78.74 - lr: 0.000015
2021-06-21 23:16:15,316 epoch 28 - iter 40/80 - loss 0.12249244 - samples/sec: 78.96 - lr: 0.000015
2021-06-21 23:16:18,568 epoch 28 - iter 48/80 - loss 0.12111084 - samples/sec: 78.74 - lr: 0.000015
2021-06-21 23:16:21,842 epoch 28 - iter 56/80 - loss 0.12084415 - samples/sec: 78.20 - lr: 0.000015
2021-06-21 23:16:25,112 epoch 28 - iter 64/80 - loss 0.11843718 - samples/sec: 78.32 - lr: 0.000015
2021-06-21 23:16:28,379 epoch 28 - iter 72/80 - loss 0.11901340 - samples/sec: 78.36 - lr: 0.000015
2021-06-21 23:16:31,387 epoch 28 - iter 80/80 - loss 0.12197986 - samples/sec: 85.12 - lr: 0.000015
2021-06-21 23:16:31,388 ----------------------------------------------------------------------------------------------------
2021-06-21 23:16:31,388 EPOCH 28 done: loss 0.1220 - lr 0.0000150
2021-06-21 23:16:33,847 DEV : loss 0.19967947900295258 - score 0.9517
2021-06-21 23:16:33,886 BAD EPOCHS (no improvement): 2
2021-06-21 23:16:33,886 ----------------------------------------------------------------------------------------------------
2021-06-21 23:16:37,155 epoch 29 - iter 8/80 - loss 0.12879702 - samples/sec: 78.34 - lr: 0.000015
2021-06-21 23:16:40,401 epoch 29 - iter 16/80 - loss 0.11831278 - samples/sec: 78.89 - lr: 0.000015
2021-06-21 23:16:43,676 epoch 29 - iter 24/80 - loss 0.13772634 - samples/sec: 78.19 - lr: 0.000015
2021-06-21 23:16:46,954 epoch 29 - iter 32/80 - loss 0.13374749 - samples/sec: 78.09 - lr: 0.000015
2021-06-21 23:16:50,222 epoch 29 - iter 40/80 - loss 0.13255954 - samples/sec: 78.36 - lr: 0.000015
2021-06-21 23:16:53,480 epoch 29 - iter 48/80 - loss 0.12810536 - samples/sec: 78.60 - lr: 0.000015
2021-06-21 23:16:56,766 epoch 29 - iter 56/80 - loss 0.12722152 - samples/sec: 77.91 - lr: 0.000015
2021-06-21 23:17:00,033 epoch 29 - iter 64/80 - loss 0.12282948 - samples/sec: 78.38 - lr: 0.000015
2021-06-21 23:17:03,294 epoch 29 - iter 72/80 - loss 0.11753396 - samples/sec: 78.52 - lr: 0.000015
2021-06-21 23:17:06,327 epoch 29 - iter 80/80 - loss 0.12540041 - samples/sec: 84.44 - lr: 0.000015
2021-06-21 23:17:06,327 ----------------------------------------------------------------------------------------------------
2021-06-21 23:17:06,327 EPOCH 29 done: loss 0.1254 - lr 0.0000150
2021-06-21 23:17:09,013 DEV : loss 0.1982465237379074 - score 0.9528
2021-06-21 23:17:09,052 BAD EPOCHS (no improvement): 3
2021-06-21 23:17:09,053 ----------------------------------------------------------------------------------------------------
2021-06-21 23:17:12,306 epoch 30 - iter 8/80 - loss 0.11568177 - samples/sec: 78.71 - lr: 0.000015
2021-06-21 23:17:15,565 epoch 30 - iter 16/80 - loss 0.09294161 - samples/sec: 78.57 - lr: 0.000015
2021-06-21 23:17:18,828 epoch 30 - iter 24/80 - loss 0.10353633 - samples/sec: 78.47 - lr: 0.000015
2021-06-21 23:17:22,121 epoch 30 - iter 32/80 - loss 0.10025374 - samples/sec: 77.76 - lr: 0.000015
2021-06-21 23:17:25,410 epoch 30 - iter 40/80 - loss 0.09759286 - samples/sec: 77.85 - lr: 0.000015
2021-06-21 23:17:28,716 epoch 30 - iter 48/80 - loss 0.09362320 - samples/sec: 77.45 - lr: 0.000015
2021-06-21 23:17:32,028 epoch 30 - iter 56/80 - loss 0.09431689 - samples/sec: 77.31 - lr: 0.000015
2021-06-21 23:17:35,328 epoch 30 - iter 64/80 - loss 0.09957980 - samples/sec: 77.60 - lr: 0.000015
2021-06-21 23:17:38,644 epoch 30 - iter 72/80 - loss 0.10096546 - samples/sec: 77.22 - lr: 0.000015
2021-06-21 23:17:41,670 epoch 30 - iter 80/80 - loss 0.10175685 - samples/sec: 84.61 - lr: 0.000015
2021-06-21 23:17:41,670 ----------------------------------------------------------------------------------------------------
2021-06-21 23:17:41,671 EPOCH 30 done: loss 0.1018 - lr 0.0000150
2021-06-21 23:17:44,133 DEV : loss 0.20643214881420135 - score 0.9528
Epoch    30: reducing learning rate of group 0 to 7.5000e-06.
2021-06-21 23:17:44,172 BAD EPOCHS (no improvement): 4
2021-06-21 23:17:44,173 ----------------------------------------------------------------------------------------------------
2021-06-21 23:17:47,439 epoch 31 - iter 8/80 - loss 0.09307745 - samples/sec: 78.39 - lr: 0.000008
2021-06-21 23:17:50,732 epoch 31 - iter 16/80 - loss 0.10373466 - samples/sec: 77.75 - lr: 0.000008
2021-06-21 23:17:54,032 epoch 31 - iter 24/80 - loss 0.10284599 - samples/sec: 77.59 - lr: 0.000008
2021-06-21 23:17:57,292 epoch 31 - iter 32/80 - loss 0.10693756 - samples/sec: 78.55 - lr: 0.000008
2021-06-21 23:18:00,553 epoch 31 - iter 40/80 - loss 0.10561598 - samples/sec: 78.52 - lr: 0.000008
2021-06-21 23:18:03,865 epoch 31 - iter 48/80 - loss 0.10453231 - samples/sec: 77.33 - lr: 0.000008
2021-06-21 23:18:07,163 epoch 31 - iter 56/80 - loss 0.10484477 - samples/sec: 77.63 - lr: 0.000008
2021-06-21 23:18:10,446 epoch 31 - iter 64/80 - loss 0.10161070 - samples/sec: 77.99 - lr: 0.000008
2021-06-21 23:18:13,746 epoch 31 - iter 72/80 - loss 0.09717271 - samples/sec: 77.60 - lr: 0.000008
2021-06-21 23:18:16,797 epoch 31 - iter 80/80 - loss 0.09851040 - samples/sec: 83.91 - lr: 0.000008
2021-06-21 23:18:16,798 ----------------------------------------------------------------------------------------------------
2021-06-21 23:18:16,798 EPOCH 31 done: loss 0.0985 - lr 0.0000075
2021-06-21 23:18:19,259 DEV : loss 0.21156015992164612 - score 0.9502
2021-06-21 23:18:19,298 BAD EPOCHS (no improvement): 1
2021-06-21 23:18:19,299 ----------------------------------------------------------------------------------------------------
2021-06-21 23:18:22,585 epoch 32 - iter 8/80 - loss 0.09346356 - samples/sec: 77.91 - lr: 0.000008
2021-06-21 23:18:25,852 epoch 32 - iter 16/80 - loss 0.11382859 - samples/sec: 78.40 - lr: 0.000008
2021-06-21 23:18:29,143 epoch 32 - iter 24/80 - loss 0.10750520 - samples/sec: 77.79 - lr: 0.000008
2021-06-21 23:18:32,475 epoch 32 - iter 32/80 - loss 0.11177417 - samples/sec: 76.84 - lr: 0.000008
2021-06-21 23:18:35,754 epoch 32 - iter 40/80 - loss 0.11398310 - samples/sec: 78.09 - lr: 0.000008
2021-06-21 23:18:39,046 epoch 32 - iter 48/80 - loss 0.12157065 - samples/sec: 77.79 - lr: 0.000008
2021-06-21 23:18:42,375 epoch 32 - iter 56/80 - loss 0.12657266 - samples/sec: 76.92 - lr: 0.000008
2021-06-21 23:18:45,651 epoch 32 - iter 64/80 - loss 0.12410887 - samples/sec: 78.16 - lr: 0.000008
2021-06-21 23:18:48,943 epoch 32 - iter 72/80 - loss 0.12017224 - samples/sec: 77.78 - lr: 0.000008
2021-06-21 23:18:51,935 epoch 32 - iter 80/80 - loss 0.12377155 - samples/sec: 85.58 - lr: 0.000008
2021-06-21 23:18:51,936 ----------------------------------------------------------------------------------------------------
2021-06-21 23:18:51,936 EPOCH 32 done: loss 0.1238 - lr 0.0000075
2021-06-21 23:18:54,398 DEV : loss 0.21574720740318298 - score 0.9513
2021-06-21 23:18:54,438 BAD EPOCHS (no improvement): 2
2021-06-21 23:18:54,438 ----------------------------------------------------------------------------------------------------
2021-06-21 23:18:57,706 epoch 33 - iter 8/80 - loss 0.08924652 - samples/sec: 78.37 - lr: 0.000008
2021-06-21 23:19:01,002 epoch 33 - iter 16/80 - loss 0.09066455 - samples/sec: 77.69 - lr: 0.000008
2021-06-21 23:19:04,278 epoch 33 - iter 24/80 - loss 0.10271633 - samples/sec: 78.15 - lr: 0.000008
2021-06-21 23:19:07,550 epoch 33 - iter 32/80 - loss 0.11096770 - samples/sec: 78.28 - lr: 0.000008
2021-06-21 23:19:10,843 epoch 33 - iter 40/80 - loss 0.10918482 - samples/sec: 77.74 - lr: 0.000008
2021-06-21 23:19:14,114 epoch 33 - iter 48/80 - loss 0.11051875 - samples/sec: 78.30 - lr: 0.000008
2021-06-21 23:19:17,372 epoch 33 - iter 56/80 - loss 0.10550074 - samples/sec: 78.58 - lr: 0.000008
2021-06-21 23:19:20,634 epoch 33 - iter 64/80 - loss 0.11041802 - samples/sec: 78.51 - lr: 0.000008
2021-06-21 23:19:23,892 epoch 33 - iter 72/80 - loss 0.10910900 - samples/sec: 78.58 - lr: 0.000008
2021-06-21 23:19:26,898 epoch 33 - iter 80/80 - loss 0.10569956 - samples/sec: 85.18 - lr: 0.000008
2021-06-21 23:19:26,899 ----------------------------------------------------------------------------------------------------
2021-06-21 23:19:26,899 EPOCH 33 done: loss 0.1057 - lr 0.0000075
2021-06-21 23:19:29,584 DEV : loss 0.20086655020713806 - score 0.9519
2021-06-21 23:19:29,623 BAD EPOCHS (no improvement): 3
2021-06-21 23:19:29,623 ----------------------------------------------------------------------------------------------------
2021-06-21 23:19:32,872 epoch 34 - iter 8/80 - loss 0.10100221 - samples/sec: 78.81 - lr: 0.000008
2021-06-21 23:19:36,144 epoch 34 - iter 16/80 - loss 0.08309479 - samples/sec: 78.26 - lr: 0.000008
2021-06-21 23:19:39,391 epoch 34 - iter 24/80 - loss 0.08904260 - samples/sec: 78.86 - lr: 0.000008
2021-06-21 23:19:42,652 epoch 34 - iter 32/80 - loss 0.09593759 - samples/sec: 78.52 - lr: 0.000008
2021-06-21 23:19:45,916 epoch 34 - iter 40/80 - loss 0.09231757 - samples/sec: 78.46 - lr: 0.000008
2021-06-21 23:19:49,192 epoch 34 - iter 48/80 - loss 0.09184332 - samples/sec: 78.15 - lr: 0.000008
2021-06-21 23:19:52,448 epoch 34 - iter 56/80 - loss 0.09794399 - samples/sec: 78.64 - lr: 0.000008
2021-06-21 23:19:55,724 epoch 34 - iter 64/80 - loss 0.10089980 - samples/sec: 78.17 - lr: 0.000008
2021-06-21 23:19:58,975 epoch 34 - iter 72/80 - loss 0.10332288 - samples/sec: 78.76 - lr: 0.000008
2021-06-21 23:20:01,987 epoch 34 - iter 80/80 - loss 0.10141886 - samples/sec: 85.02 - lr: 0.000008
2021-06-21 23:20:01,987 ----------------------------------------------------------------------------------------------------
2021-06-21 23:20:01,987 EPOCH 34 done: loss 0.1014 - lr 0.0000075
2021-06-21 23:20:04,445 DEV : loss 0.19682632386684418 - score 0.9544
Epoch    34: reducing learning rate of group 0 to 3.7500e-06.
2021-06-21 23:20:04,484 BAD EPOCHS (no improvement): 4
2021-06-21 23:20:04,485 ----------------------------------------------------------------------------------------------------
2021-06-21 23:20:07,746 epoch 35 - iter 8/80 - loss 0.09575076 - samples/sec: 78.52 - lr: 0.000004
2021-06-21 23:20:11,004 epoch 35 - iter 16/80 - loss 0.13760041 - samples/sec: 78.59 - lr: 0.000004
2021-06-21 23:20:14,295 epoch 35 - iter 24/80 - loss 0.12545192 - samples/sec: 77.81 - lr: 0.000004
2021-06-21 23:20:17,582 epoch 35 - iter 32/80 - loss 0.12326685 - samples/sec: 77.89 - lr: 0.000004
2021-06-21 23:20:20,869 epoch 35 - iter 40/80 - loss 0.12240131 - samples/sec: 77.91 - lr: 0.000004
2021-06-21 23:20:24,113 epoch 35 - iter 48/80 - loss 0.11983089 - samples/sec: 78.93 - lr: 0.000004
2021-06-21 23:20:27,383 epoch 35 - iter 56/80 - loss 0.11459479 - samples/sec: 78.31 - lr: 0.000004
2021-06-21 23:20:30,619 epoch 35 - iter 64/80 - loss 0.11218799 - samples/sec: 79.13 - lr: 0.000004
2021-06-21 23:20:33,885 epoch 35 - iter 72/80 - loss 0.11075011 - samples/sec: 78.40 - lr: 0.000004
2021-06-21 23:20:36,937 epoch 35 - iter 80/80 - loss 0.10788020 - samples/sec: 83.89 - lr: 0.000004
2021-06-21 23:20:36,938 ----------------------------------------------------------------------------------------------------
2021-06-21 23:20:36,938 EPOCH 35 done: loss 0.1079 - lr 0.0000038
2021-06-21 23:20:39,399 DEV : loss 0.20254608988761902 - score 0.954
2021-06-21 23:20:39,438 BAD EPOCHS (no improvement): 1
2021-06-21 23:20:39,439 ----------------------------------------------------------------------------------------------------
2021-06-21 23:20:42,700 epoch 36 - iter 8/80 - loss 0.12555759 - samples/sec: 78.53 - lr: 0.000004
2021-06-21 23:20:45,981 epoch 36 - iter 16/80 - loss 0.11845676 - samples/sec: 78.02 - lr: 0.000004
2021-06-21 23:20:49,253 epoch 36 - iter 24/80 - loss 0.10664388 - samples/sec: 78.27 - lr: 0.000004
2021-06-21 23:20:52,533 epoch 36 - iter 32/80 - loss 0.10248577 - samples/sec: 78.06 - lr: 0.000004
2021-06-21 23:20:55,795 epoch 36 - iter 40/80 - loss 0.10764804 - samples/sec: 78.50 - lr: 0.000004
2021-06-21 23:20:59,033 epoch 36 - iter 48/80 - loss 0.10574184 - samples/sec: 79.06 - lr: 0.000004
2021-06-21 23:21:02,256 epoch 36 - iter 56/80 - loss 0.10822710 - samples/sec: 79.45 - lr: 0.000004
2021-06-21 23:21:05,576 epoch 36 - iter 64/80 - loss 0.10400386 - samples/sec: 77.12 - lr: 0.000004
2021-06-21 23:21:08,834 epoch 36 - iter 72/80 - loss 0.10404049 - samples/sec: 78.60 - lr: 0.000004
2021-06-21 23:21:12,110 epoch 36 - iter 80/80 - loss 0.10651697 - samples/sec: 78.15 - lr: 0.000004
2021-06-21 23:21:12,111 ----------------------------------------------------------------------------------------------------
2021-06-21 23:21:12,111 EPOCH 36 done: loss 0.1065 - lr 0.0000038
2021-06-21 23:21:14,569 DEV : loss 0.20190906524658203 - score 0.9566
2021-06-21 23:21:14,609 BAD EPOCHS (no improvement): 2
2021-06-21 23:21:14,609 ----------------------------------------------------------------------------------------------------
2021-06-21 23:21:17,847 epoch 37 - iter 8/80 - loss 0.10924834 - samples/sec: 79.08 - lr: 0.000004
2021-06-21 23:21:21,074 epoch 37 - iter 16/80 - loss 0.10494321 - samples/sec: 79.35 - lr: 0.000004
2021-06-21 23:21:24,350 epoch 37 - iter 24/80 - loss 0.09237362 - samples/sec: 78.15 - lr: 0.000004
2021-06-21 23:21:27,641 epoch 37 - iter 32/80 - loss 0.08266780 - samples/sec: 77.82 - lr: 0.000004
2021-06-21 23:21:30,878 epoch 37 - iter 40/80 - loss 0.08109263 - samples/sec: 79.11 - lr: 0.000004
2021-06-21 23:21:34,163 epoch 37 - iter 48/80 - loss 0.08667168 - samples/sec: 77.93 - lr: 0.000004
2021-06-21 23:21:37,378 epoch 37 - iter 56/80 - loss 0.08322344 - samples/sec: 79.66 - lr: 0.000004
2021-06-21 23:21:40,623 epoch 37 - iter 64/80 - loss 0.08604659 - samples/sec: 78.90 - lr: 0.000004
2021-06-21 23:21:43,900 epoch 37 - iter 72/80 - loss 0.08840210 - samples/sec: 78.14 - lr: 0.000004
2021-06-21 23:21:46,945 epoch 37 - iter 80/80 - loss 0.09061845 - samples/sec: 84.10 - lr: 0.000004
2021-06-21 23:21:46,945 ----------------------------------------------------------------------------------------------------
2021-06-21 23:21:46,945 EPOCH 37 done: loss 0.0906 - lr 0.0000038
2021-06-21 23:21:49,406 DEV : loss 0.20445983111858368 - score 0.9553
2021-06-21 23:21:49,445 BAD EPOCHS (no improvement): 3
2021-06-21 23:21:49,446 ----------------------------------------------------------------------------------------------------
2021-06-21 23:21:52,727 epoch 38 - iter 8/80 - loss 0.11316746 - samples/sec: 78.03 - lr: 0.000004
2021-06-21 23:21:56,013 epoch 38 - iter 16/80 - loss 0.10489345 - samples/sec: 77.92 - lr: 0.000004
2021-06-21 23:21:59,307 epoch 38 - iter 24/80 - loss 0.10588762 - samples/sec: 77.75 - lr: 0.000004
2021-06-21 23:22:02,602 epoch 38 - iter 32/80 - loss 0.11005155 - samples/sec: 77.70 - lr: 0.000004
2021-06-21 23:22:05,865 epoch 38 - iter 40/80 - loss 0.10808740 - samples/sec: 78.48 - lr: 0.000004
2021-06-21 23:22:09,075 epoch 38 - iter 48/80 - loss 0.10247336 - samples/sec: 79.75 - lr: 0.000004
2021-06-21 23:22:12,350 epoch 38 - iter 56/80 - loss 0.09949599 - samples/sec: 78.19 - lr: 0.000004
2021-06-21 23:22:15,597 epoch 38 - iter 64/80 - loss 0.09801980 - samples/sec: 78.86 - lr: 0.000004
2021-06-21 23:22:18,858 epoch 38 - iter 72/80 - loss 0.09594739 - samples/sec: 78.53 - lr: 0.000004
2021-06-21 23:22:21,880 epoch 38 - iter 80/80 - loss 0.09487860 - samples/sec: 84.74 - lr: 0.000004
2021-06-21 23:22:21,880 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:21,880 EPOCH 38 done: loss 0.0949 - lr 0.0000038
2021-06-21 23:22:24,337 DEV : loss 0.2032981514930725 - score 0.9562
Epoch    38: reducing learning rate of group 0 to 1.8750e-06.
2021-06-21 23:22:24,376 BAD EPOCHS (no improvement): 4
2021-06-21 23:22:24,376 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:24,376 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:24,376 learning rate too small - quitting training!
2021-06-21 23:22:24,376 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:24,781 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:24,781 Testing using best model ...
2021-06-21 23:22:24,781 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/best-model.pt
2021-06-21 23:22:33,045 0.9499	0.9381	0.9440
2021-06-21 23:22:33,045 
Results:
- F1-score (micro) 0.9440
- F1-score (macro) 0.9440

By class:
SENT       tp: 379 - fp: 20 - fn: 25 - precision: 0.9499 - recall: 0.9381 - f1-score: 0.9440
2021-06-21 23:22:33,046 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/
2021-06-21 23:22:33,051 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb
2021-06-21 23:22:33,051 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/sent_train.txt
2021-06-21 23:22:33,051 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/sent_dev.txt
2021-06-21 23:22:33,051 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/sent_test.txt
Corpus: 2146 train + 371 dev + 396 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-21 23:22:53,303 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:53,305 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-21 23:22:53,305 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:53,305 Corpus: "Corpus: 2146 train + 371 dev + 396 test sentences"
2021-06-21 23:22:53,305 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:53,305 Parameters:
2021-06-21 23:22:53,305  - learning_rate: "3e-05"
2021-06-21 23:22:53,305  - mini_batch_size: "32"
2021-06-21 23:22:53,305  - patience: "3"
2021-06-21 23:22:53,305  - anneal_factor: "0.5"
2021-06-21 23:22:53,305  - max_epochs: "40"
2021-06-21 23:22:53,305  - shuffle: "True"
2021-06-21 23:22:53,305  - train_with_dev: "False"
2021-06-21 23:22:53,305  - batch_growth_annealing: "False"
2021-06-21 23:22:53,305 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:53,306 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb"
2021-06-21 23:22:53,306 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:53,306 Device: cuda:0
2021-06-21 23:22:53,306 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:53,306 Embeddings storage mode: cpu
2021-06-21 23:22:53,307 ----------------------------------------------------------------------------------------------------
2021-06-21 23:22:58,667 epoch 1 - iter 6/68 - loss 11.95436827 - samples/sec: 35.82 - lr: 0.000030
2021-06-21 23:23:04,061 epoch 1 - iter 12/68 - loss 8.63941209 - samples/sec: 35.60 - lr: 0.000030
2021-06-21 23:23:09,437 epoch 1 - iter 18/68 - loss 6.98686760 - samples/sec: 35.72 - lr: 0.000030
2021-06-21 23:23:14,723 epoch 1 - iter 24/68 - loss 6.04998805 - samples/sec: 36.32 - lr: 0.000030
2021-06-21 23:23:20,037 epoch 1 - iter 30/68 - loss 5.40376735 - samples/sec: 36.14 - lr: 0.000030
2021-06-21 23:23:25,427 epoch 1 - iter 36/68 - loss 4.89585787 - samples/sec: 35.62 - lr: 0.000030
2021-06-21 23:23:30,851 epoch 1 - iter 42/68 - loss 4.50963138 - samples/sec: 35.40 - lr: 0.000030
2021-06-21 23:23:36,291 epoch 1 - iter 48/68 - loss 4.14544944 - samples/sec: 35.30 - lr: 0.000030
2021-06-21 23:23:41,686 epoch 1 - iter 54/68 - loss 3.83698897 - samples/sec: 35.59 - lr: 0.000030
2021-06-21 23:23:47,292 epoch 1 - iter 60/68 - loss 3.57347886 - samples/sec: 34.25 - lr: 0.000030
2021-06-21 23:23:52,593 epoch 1 - iter 66/68 - loss 3.32905754 - samples/sec: 36.22 - lr: 0.000030
2021-06-21 23:23:53,617 ----------------------------------------------------------------------------------------------------
2021-06-21 23:23:53,617 EPOCH 1 done: loss 3.2734 - lr 0.0000300
2021-06-21 23:23:59,925 DEV : loss 0.43307337164878845 - score 0.9121
2021-06-21 23:23:59,950 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:24:00,369 ----------------------------------------------------------------------------------------------------
2021-06-21 23:24:03,075 epoch 2 - iter 6/68 - loss 0.72078211 - samples/sec: 70.99 - lr: 0.000030
2021-06-21 23:24:05,790 epoch 2 - iter 12/68 - loss 0.75346142 - samples/sec: 70.73 - lr: 0.000030
2021-06-21 23:24:08,514 epoch 2 - iter 18/68 - loss 0.69471787 - samples/sec: 70.50 - lr: 0.000030
2021-06-21 23:24:11,234 epoch 2 - iter 24/68 - loss 0.69018018 - samples/sec: 70.59 - lr: 0.000030
2021-06-21 23:24:13,920 epoch 2 - iter 30/68 - loss 0.65013180 - samples/sec: 71.49 - lr: 0.000030
2021-06-21 23:24:16,666 epoch 2 - iter 36/68 - loss 0.61271394 - samples/sec: 69.93 - lr: 0.000030
2021-06-21 23:24:19,405 epoch 2 - iter 42/68 - loss 0.60356270 - samples/sec: 70.13 - lr: 0.000030
2021-06-21 23:24:22,099 epoch 2 - iter 48/68 - loss 0.59289588 - samples/sec: 71.28 - lr: 0.000030
2021-06-21 23:24:24,840 epoch 2 - iter 54/68 - loss 0.56576007 - samples/sec: 70.06 - lr: 0.000030
2021-06-21 23:24:27,545 epoch 2 - iter 60/68 - loss 0.55646033 - samples/sec: 71.00 - lr: 0.000030
2021-06-21 23:24:30,246 epoch 2 - iter 66/68 - loss 0.54232965 - samples/sec: 71.11 - lr: 0.000030
2021-06-21 23:24:30,770 ----------------------------------------------------------------------------------------------------
2021-06-21 23:24:30,771 EPOCH 2 done: loss 0.5379 - lr 0.0000300
2021-06-21 23:24:32,624 DEV : loss 0.19522082805633545 - score 0.9488
2021-06-21 23:24:32,650 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:24:37,055 ----------------------------------------------------------------------------------------------------
2021-06-21 23:24:39,746 epoch 3 - iter 6/68 - loss 0.35403528 - samples/sec: 71.38 - lr: 0.000030
2021-06-21 23:24:42,394 epoch 3 - iter 12/68 - loss 0.34035931 - samples/sec: 72.52 - lr: 0.000030
2021-06-21 23:24:45,129 epoch 3 - iter 18/68 - loss 0.40147892 - samples/sec: 70.22 - lr: 0.000030
2021-06-21 23:24:47,850 epoch 3 - iter 24/68 - loss 0.40005925 - samples/sec: 70.59 - lr: 0.000030
2021-06-21 23:24:50,595 epoch 3 - iter 30/68 - loss 0.41128055 - samples/sec: 69.96 - lr: 0.000030
2021-06-21 23:24:53,306 epoch 3 - iter 36/68 - loss 0.40537507 - samples/sec: 70.84 - lr: 0.000030
2021-06-21 23:24:55,994 epoch 3 - iter 42/68 - loss 0.40690176 - samples/sec: 71.43 - lr: 0.000030
2021-06-21 23:24:58,677 epoch 3 - iter 48/68 - loss 0.38739451 - samples/sec: 71.59 - lr: 0.000030
2021-06-21 23:25:01,399 epoch 3 - iter 54/68 - loss 0.37937198 - samples/sec: 70.56 - lr: 0.000030
2021-06-21 23:25:04,145 epoch 3 - iter 60/68 - loss 0.37689296 - samples/sec: 69.92 - lr: 0.000030
2021-06-21 23:25:06,884 epoch 3 - iter 66/68 - loss 0.37329978 - samples/sec: 70.11 - lr: 0.000030
2021-06-21 23:25:07,413 ----------------------------------------------------------------------------------------------------
2021-06-21 23:25:07,413 EPOCH 3 done: loss 0.3717 - lr 0.0000300
2021-06-21 23:25:09,258 DEV : loss 0.15053698420524597 - score 0.9562
2021-06-21 23:25:09,284 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:25:13,825 ----------------------------------------------------------------------------------------------------
2021-06-21 23:25:16,521 epoch 4 - iter 6/68 - loss 0.51223912 - samples/sec: 71.24 - lr: 0.000030
2021-06-21 23:25:19,238 epoch 4 - iter 12/68 - loss 0.45638229 - samples/sec: 70.70 - lr: 0.000030
2021-06-21 23:25:21,931 epoch 4 - iter 18/68 - loss 0.42632175 - samples/sec: 71.32 - lr: 0.000030
2021-06-21 23:25:24,634 epoch 4 - iter 24/68 - loss 0.40750312 - samples/sec: 71.05 - lr: 0.000030
2021-06-21 23:25:27,356 epoch 4 - iter 30/68 - loss 0.40165379 - samples/sec: 70.55 - lr: 0.000030
2021-06-21 23:25:30,083 epoch 4 - iter 36/68 - loss 0.38938171 - samples/sec: 70.42 - lr: 0.000030
2021-06-21 23:25:32,826 epoch 4 - iter 42/68 - loss 0.36283614 - samples/sec: 70.01 - lr: 0.000030
2021-06-21 23:25:35,497 epoch 4 - iter 48/68 - loss 0.35297821 - samples/sec: 71.93 - lr: 0.000030
2021-06-21 23:25:38,240 epoch 4 - iter 54/68 - loss 0.34051909 - samples/sec: 70.03 - lr: 0.000030
2021-06-21 23:25:40,952 epoch 4 - iter 60/68 - loss 0.33083280 - samples/sec: 70.79 - lr: 0.000030
2021-06-21 23:25:43,672 epoch 4 - iter 66/68 - loss 0.32640684 - samples/sec: 70.61 - lr: 0.000030
2021-06-21 23:25:44,206 ----------------------------------------------------------------------------------------------------
2021-06-21 23:25:44,206 EPOCH 4 done: loss 0.3272 - lr 0.0000300
2021-06-21 23:25:46,052 DEV : loss 0.11641635745763779 - score 0.9675
2021-06-21 23:25:46,078 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:25:50,630 ----------------------------------------------------------------------------------------------------
2021-06-21 23:25:53,316 epoch 5 - iter 6/68 - loss 0.32063647 - samples/sec: 71.49 - lr: 0.000030
2021-06-21 23:25:56,017 epoch 5 - iter 12/68 - loss 0.26672868 - samples/sec: 71.13 - lr: 0.000030
2021-06-21 23:25:58,716 epoch 5 - iter 18/68 - loss 0.27755498 - samples/sec: 71.13 - lr: 0.000030
2021-06-21 23:26:01,451 epoch 5 - iter 24/68 - loss 0.26175703 - samples/sec: 70.22 - lr: 0.000030
2021-06-21 23:26:04,179 epoch 5 - iter 30/68 - loss 0.27809814 - samples/sec: 70.41 - lr: 0.000030
2021-06-21 23:26:06,898 epoch 5 - iter 36/68 - loss 0.27588945 - samples/sec: 70.63 - lr: 0.000030
2021-06-21 23:26:09,619 epoch 5 - iter 42/68 - loss 0.26705671 - samples/sec: 70.59 - lr: 0.000030
2021-06-21 23:26:12,320 epoch 5 - iter 48/68 - loss 0.26144330 - samples/sec: 71.09 - lr: 0.000030
2021-06-21 23:26:15,094 epoch 5 - iter 54/68 - loss 0.26738818 - samples/sec: 69.24 - lr: 0.000030
2021-06-21 23:26:17,838 epoch 5 - iter 60/68 - loss 0.26795807 - samples/sec: 69.99 - lr: 0.000030
2021-06-21 23:26:20,525 epoch 5 - iter 66/68 - loss 0.27069324 - samples/sec: 71.46 - lr: 0.000030
2021-06-21 23:26:21,067 ----------------------------------------------------------------------------------------------------
2021-06-21 23:26:21,067 EPOCH 5 done: loss 0.2783 - lr 0.0000300
2021-06-21 23:26:22,918 DEV : loss 0.10189887881278992 - score 0.9713
2021-06-21 23:26:22,944 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:26:27,123 ----------------------------------------------------------------------------------------------------
2021-06-21 23:26:29,860 epoch 6 - iter 6/68 - loss 0.25356857 - samples/sec: 70.17 - lr: 0.000030
2021-06-21 23:26:32,558 epoch 6 - iter 12/68 - loss 0.23162536 - samples/sec: 71.19 - lr: 0.000030
2021-06-21 23:26:35,241 epoch 6 - iter 18/68 - loss 0.22355538 - samples/sec: 71.58 - lr: 0.000030
2021-06-21 23:26:37,981 epoch 6 - iter 24/68 - loss 0.25818062 - samples/sec: 70.10 - lr: 0.000030
2021-06-21 23:26:40,670 epoch 6 - iter 30/68 - loss 0.27775106 - samples/sec: 71.42 - lr: 0.000030
2021-06-21 23:26:43,343 epoch 6 - iter 36/68 - loss 0.28050348 - samples/sec: 71.84 - lr: 0.000030
2021-06-21 23:26:46,049 epoch 6 - iter 42/68 - loss 0.27528505 - samples/sec: 70.98 - lr: 0.000030
2021-06-21 23:26:48,786 epoch 6 - iter 48/68 - loss 0.26111053 - samples/sec: 70.15 - lr: 0.000030
2021-06-21 23:26:51,490 epoch 6 - iter 54/68 - loss 0.26670124 - samples/sec: 71.02 - lr: 0.000030
2021-06-21 23:26:54,191 epoch 6 - iter 60/68 - loss 0.26834365 - samples/sec: 71.12 - lr: 0.000030
2021-06-21 23:26:56,884 epoch 6 - iter 66/68 - loss 0.27543880 - samples/sec: 71.30 - lr: 0.000030
2021-06-21 23:26:57,412 ----------------------------------------------------------------------------------------------------
2021-06-21 23:26:57,413 EPOCH 6 done: loss 0.2726 - lr 0.0000300
2021-06-21 23:26:59,269 DEV : loss 0.0870109423995018 - score 0.9827
2021-06-21 23:26:59,295 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:27:03,360 ----------------------------------------------------------------------------------------------------
2021-06-21 23:27:06,054 epoch 7 - iter 6/68 - loss 0.32061958 - samples/sec: 71.29 - lr: 0.000030
2021-06-21 23:27:08,785 epoch 7 - iter 12/68 - loss 0.25332042 - samples/sec: 70.34 - lr: 0.000030
2021-06-21 23:27:11,511 epoch 7 - iter 18/68 - loss 0.26027606 - samples/sec: 70.45 - lr: 0.000030
2021-06-21 23:27:14,200 epoch 7 - iter 24/68 - loss 0.25718873 - samples/sec: 71.40 - lr: 0.000030
2021-06-21 23:27:16,965 epoch 7 - iter 30/68 - loss 0.24598901 - samples/sec: 69.46 - lr: 0.000030
2021-06-21 23:27:19,692 epoch 7 - iter 36/68 - loss 0.24781249 - samples/sec: 70.44 - lr: 0.000030
2021-06-21 23:27:22,402 epoch 7 - iter 42/68 - loss 0.25410168 - samples/sec: 70.85 - lr: 0.000030
2021-06-21 23:27:25,110 epoch 7 - iter 48/68 - loss 0.25275205 - samples/sec: 70.91 - lr: 0.000030
2021-06-21 23:27:28,007 epoch 7 - iter 54/68 - loss 0.24447702 - samples/sec: 66.31 - lr: 0.000030
2021-06-21 23:27:30,741 epoch 7 - iter 60/68 - loss 0.24584146 - samples/sec: 70.23 - lr: 0.000030
2021-06-21 23:27:33,434 epoch 7 - iter 66/68 - loss 0.24294710 - samples/sec: 71.32 - lr: 0.000030
2021-06-21 23:27:33,979 ----------------------------------------------------------------------------------------------------
2021-06-21 23:27:33,980 EPOCH 7 done: loss 0.2462 - lr 0.0000300
2021-06-21 23:27:35,830 DEV : loss 0.07702521979808807 - score 0.9827
2021-06-21 23:27:35,856 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:27:40,360 ----------------------------------------------------------------------------------------------------
2021-06-21 23:27:43,119 epoch 8 - iter 6/68 - loss 0.21412646 - samples/sec: 69.60 - lr: 0.000030
2021-06-21 23:27:45,855 epoch 8 - iter 12/68 - loss 0.18728668 - samples/sec: 70.19 - lr: 0.000030
2021-06-21 23:27:48,532 epoch 8 - iter 18/68 - loss 0.18086445 - samples/sec: 71.75 - lr: 0.000030
2021-06-21 23:27:51,171 epoch 8 - iter 24/68 - loss 0.19976091 - samples/sec: 72.76 - lr: 0.000030
2021-06-21 23:27:53,887 epoch 8 - iter 30/68 - loss 0.19172020 - samples/sec: 70.73 - lr: 0.000030
2021-06-21 23:27:56,610 epoch 8 - iter 36/68 - loss 0.19002280 - samples/sec: 70.51 - lr: 0.000030
2021-06-21 23:27:59,330 epoch 8 - iter 42/68 - loss 0.19411165 - samples/sec: 70.62 - lr: 0.000030
2021-06-21 23:28:02,054 epoch 8 - iter 48/68 - loss 0.19493740 - samples/sec: 70.48 - lr: 0.000030
2021-06-21 23:28:04,775 epoch 8 - iter 54/68 - loss 0.19254735 - samples/sec: 70.60 - lr: 0.000030
2021-06-21 23:28:07,521 epoch 8 - iter 60/68 - loss 0.20248972 - samples/sec: 69.93 - lr: 0.000030
2021-06-21 23:28:10,213 epoch 8 - iter 66/68 - loss 0.20727688 - samples/sec: 71.35 - lr: 0.000030
2021-06-21 23:28:10,743 ----------------------------------------------------------------------------------------------------
2021-06-21 23:28:10,743 EPOCH 8 done: loss 0.2074 - lr 0.0000300
2021-06-21 23:28:12,598 DEV : loss 0.06174544245004654 - score 0.9903
2021-06-21 23:28:12,624 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:28:17,113 ----------------------------------------------------------------------------------------------------
2021-06-21 23:28:19,842 epoch 9 - iter 6/68 - loss 0.20285356 - samples/sec: 70.40 - lr: 0.000030
2021-06-21 23:28:22,586 epoch 9 - iter 12/68 - loss 0.20192508 - samples/sec: 69.98 - lr: 0.000030
2021-06-21 23:28:25,300 epoch 9 - iter 18/68 - loss 0.20310293 - samples/sec: 70.77 - lr: 0.000030
2021-06-21 23:28:28,006 epoch 9 - iter 24/68 - loss 0.19590799 - samples/sec: 70.97 - lr: 0.000030
2021-06-21 23:28:30,738 epoch 9 - iter 30/68 - loss 0.20076255 - samples/sec: 70.29 - lr: 0.000030
2021-06-21 23:28:33,482 epoch 9 - iter 36/68 - loss 0.20461692 - samples/sec: 69.99 - lr: 0.000030
2021-06-21 23:28:36,231 epoch 9 - iter 42/68 - loss 0.20320483 - samples/sec: 69.85 - lr: 0.000030
2021-06-21 23:28:38,946 epoch 9 - iter 48/68 - loss 0.19777113 - samples/sec: 70.73 - lr: 0.000030
2021-06-21 23:28:41,648 epoch 9 - iter 54/68 - loss 0.19350289 - samples/sec: 71.08 - lr: 0.000030
2021-06-21 23:28:44,405 epoch 9 - iter 60/68 - loss 0.19606973 - samples/sec: 69.65 - lr: 0.000030
2021-06-21 23:28:47,095 epoch 9 - iter 66/68 - loss 0.20050729 - samples/sec: 71.39 - lr: 0.000030
2021-06-21 23:28:47,624 ----------------------------------------------------------------------------------------------------
2021-06-21 23:28:47,624 EPOCH 9 done: loss 0.1986 - lr 0.0000300
2021-06-21 23:28:49,474 DEV : loss 0.06069273501634598 - score 0.9903
2021-06-21 23:28:49,499 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:28:53,848 ----------------------------------------------------------------------------------------------------
2021-06-21 23:28:56,572 epoch 10 - iter 6/68 - loss 0.24151123 - samples/sec: 70.52 - lr: 0.000030
2021-06-21 23:28:59,302 epoch 10 - iter 12/68 - loss 0.23437318 - samples/sec: 70.35 - lr: 0.000030
2021-06-21 23:29:02,031 epoch 10 - iter 18/68 - loss 0.20922302 - samples/sec: 70.37 - lr: 0.000030
2021-06-21 23:29:04,768 epoch 10 - iter 24/68 - loss 0.20325595 - samples/sec: 70.18 - lr: 0.000030
2021-06-21 23:29:07,506 epoch 10 - iter 30/68 - loss 0.19777577 - samples/sec: 70.12 - lr: 0.000030
2021-06-21 23:29:10,250 epoch 10 - iter 36/68 - loss 0.20583428 - samples/sec: 69.98 - lr: 0.000030
2021-06-21 23:29:12,950 epoch 10 - iter 42/68 - loss 0.19656726 - samples/sec: 71.13 - lr: 0.000030
2021-06-21 23:29:15,684 epoch 10 - iter 48/68 - loss 0.18850008 - samples/sec: 70.25 - lr: 0.000030
2021-06-21 23:29:18,406 epoch 10 - iter 54/68 - loss 0.19068544 - samples/sec: 70.56 - lr: 0.000030
2021-06-21 23:29:21,154 epoch 10 - iter 60/68 - loss 0.18869137 - samples/sec: 69.89 - lr: 0.000030
2021-06-21 23:29:23,852 epoch 10 - iter 66/68 - loss 0.18751866 - samples/sec: 71.19 - lr: 0.000030
2021-06-21 23:29:24,368 ----------------------------------------------------------------------------------------------------
2021-06-21 23:29:24,368 EPOCH 10 done: loss 0.1843 - lr 0.0000300
2021-06-21 23:29:26,417 DEV : loss 0.07083702832460403 - score 0.9865
2021-06-21 23:29:26,443 BAD EPOCHS (no improvement): 1
2021-06-21 23:29:26,444 ----------------------------------------------------------------------------------------------------
2021-06-21 23:29:29,147 epoch 11 - iter 6/68 - loss 0.21148724 - samples/sec: 71.03 - lr: 0.000030
2021-06-21 23:29:31,833 epoch 11 - iter 12/68 - loss 0.18266628 - samples/sec: 71.51 - lr: 0.000030
2021-06-21 23:29:34,518 epoch 11 - iter 18/68 - loss 0.16898812 - samples/sec: 71.52 - lr: 0.000030
2021-06-21 23:29:37,217 epoch 11 - iter 24/68 - loss 0.16015506 - samples/sec: 71.15 - lr: 0.000030
2021-06-21 23:29:39,900 epoch 11 - iter 30/68 - loss 0.17231978 - samples/sec: 71.57 - lr: 0.000030
2021-06-21 23:29:42,631 epoch 11 - iter 36/68 - loss 0.17261035 - samples/sec: 70.34 - lr: 0.000030
2021-06-21 23:29:45,346 epoch 11 - iter 42/68 - loss 0.18213442 - samples/sec: 70.72 - lr: 0.000030
2021-06-21 23:29:48,074 epoch 11 - iter 48/68 - loss 0.18254655 - samples/sec: 70.41 - lr: 0.000030
2021-06-21 23:29:50,793 epoch 11 - iter 54/68 - loss 0.17591629 - samples/sec: 70.62 - lr: 0.000030
2021-06-21 23:29:53,515 epoch 11 - iter 60/68 - loss 0.17382572 - samples/sec: 70.56 - lr: 0.000030
2021-06-21 23:29:56,228 epoch 11 - iter 66/68 - loss 0.17598078 - samples/sec: 70.79 - lr: 0.000030
2021-06-21 23:29:56,746 ----------------------------------------------------------------------------------------------------
2021-06-21 23:29:56,746 EPOCH 11 done: loss 0.1761 - lr 0.0000300
2021-06-21 23:29:58,599 DEV : loss 0.05473646521568298 - score 0.9884
2021-06-21 23:29:58,625 BAD EPOCHS (no improvement): 2
2021-06-21 23:29:58,625 ----------------------------------------------------------------------------------------------------
2021-06-21 23:30:01,329 epoch 12 - iter 6/68 - loss 0.10201119 - samples/sec: 71.03 - lr: 0.000030
2021-06-21 23:30:04,067 epoch 12 - iter 12/68 - loss 0.15883883 - samples/sec: 70.14 - lr: 0.000030
2021-06-21 23:30:06,782 epoch 12 - iter 18/68 - loss 0.16827615 - samples/sec: 70.72 - lr: 0.000030
2021-06-21 23:30:09,513 epoch 12 - iter 24/68 - loss 0.17436535 - samples/sec: 70.33 - lr: 0.000030
2021-06-21 23:30:12,245 epoch 12 - iter 30/68 - loss 0.17604918 - samples/sec: 70.28 - lr: 0.000030
2021-06-21 23:30:14,953 epoch 12 - iter 36/68 - loss 0.16830297 - samples/sec: 70.93 - lr: 0.000030
2021-06-21 23:30:17,644 epoch 12 - iter 42/68 - loss 0.16306274 - samples/sec: 71.38 - lr: 0.000030
2021-06-21 23:30:20,357 epoch 12 - iter 48/68 - loss 0.16867378 - samples/sec: 70.79 - lr: 0.000030
2021-06-21 23:30:23,126 epoch 12 - iter 54/68 - loss 0.17407882 - samples/sec: 69.34 - lr: 0.000030
2021-06-21 23:30:25,831 epoch 12 - iter 60/68 - loss 0.17780923 - samples/sec: 70.99 - lr: 0.000030
2021-06-21 23:30:28,586 epoch 12 - iter 66/68 - loss 0.17822561 - samples/sec: 69.72 - lr: 0.000030
2021-06-21 23:30:29,116 ----------------------------------------------------------------------------------------------------
2021-06-21 23:30:29,116 EPOCH 12 done: loss 0.1741 - lr 0.0000300
2021-06-21 23:30:30,969 DEV : loss 0.07154551893472672 - score 0.9865
2021-06-21 23:30:30,995 BAD EPOCHS (no improvement): 3
2021-06-21 23:30:30,995 ----------------------------------------------------------------------------------------------------
2021-06-21 23:30:33,705 epoch 13 - iter 6/68 - loss 0.15466913 - samples/sec: 70.86 - lr: 0.000030
2021-06-21 23:30:36,467 epoch 13 - iter 12/68 - loss 0.16712594 - samples/sec: 69.54 - lr: 0.000030
2021-06-21 23:30:39,159 epoch 13 - iter 18/68 - loss 0.15127450 - samples/sec: 71.35 - lr: 0.000030
2021-06-21 23:30:41,873 epoch 13 - iter 24/68 - loss 0.16496910 - samples/sec: 70.75 - lr: 0.000030
2021-06-21 23:30:44,579 epoch 13 - iter 30/68 - loss 0.16057809 - samples/sec: 70.96 - lr: 0.000030
2021-06-21 23:30:47,283 epoch 13 - iter 36/68 - loss 0.16438553 - samples/sec: 71.03 - lr: 0.000030
2021-06-21 23:30:49,983 epoch 13 - iter 42/68 - loss 0.15930932 - samples/sec: 71.12 - lr: 0.000030
2021-06-21 23:30:52,719 epoch 13 - iter 48/68 - loss 0.16431281 - samples/sec: 70.22 - lr: 0.000030
2021-06-21 23:30:55,415 epoch 13 - iter 54/68 - loss 0.16206222 - samples/sec: 71.22 - lr: 0.000030
2021-06-21 23:30:58,167 epoch 13 - iter 60/68 - loss 0.16679422 - samples/sec: 69.79 - lr: 0.000030
2021-06-21 23:31:00,914 epoch 13 - iter 66/68 - loss 0.16744004 - samples/sec: 69.91 - lr: 0.000030
2021-06-21 23:31:01,448 ----------------------------------------------------------------------------------------------------
2021-06-21 23:31:01,448 EPOCH 13 done: loss 0.1636 - lr 0.0000300
2021-06-21 23:31:03,297 DEV : loss 0.06443998217582703 - score 0.9865
Epoch    13: reducing learning rate of group 0 to 1.5000e-05.
2021-06-21 23:31:03,323 BAD EPOCHS (no improvement): 4
2021-06-21 23:31:03,323 ----------------------------------------------------------------------------------------------------
2021-06-21 23:31:06,039 epoch 14 - iter 6/68 - loss 0.19478044 - samples/sec: 70.71 - lr: 0.000015
2021-06-21 23:31:08,811 epoch 14 - iter 12/68 - loss 0.18011582 - samples/sec: 69.28 - lr: 0.000015
2021-06-21 23:31:11,551 epoch 14 - iter 18/68 - loss 0.15874321 - samples/sec: 70.08 - lr: 0.000015
2021-06-21 23:31:14,251 epoch 14 - iter 24/68 - loss 0.16831246 - samples/sec: 71.13 - lr: 0.000015
2021-06-21 23:31:16,944 epoch 14 - iter 30/68 - loss 0.16420376 - samples/sec: 71.31 - lr: 0.000015
2021-06-21 23:31:19,659 epoch 14 - iter 36/68 - loss 0.15806018 - samples/sec: 70.73 - lr: 0.000015
2021-06-21 23:31:22,403 epoch 14 - iter 42/68 - loss 0.15459727 - samples/sec: 70.00 - lr: 0.000015
2021-06-21 23:31:25,074 epoch 14 - iter 48/68 - loss 0.15167221 - samples/sec: 71.90 - lr: 0.000015
2021-06-21 23:31:27,826 epoch 14 - iter 54/68 - loss 0.14894240 - samples/sec: 69.78 - lr: 0.000015
2021-06-21 23:31:30,724 epoch 14 - iter 60/68 - loss 0.14890350 - samples/sec: 66.27 - lr: 0.000015
2021-06-21 23:31:33,424 epoch 14 - iter 66/68 - loss 0.14712170 - samples/sec: 71.12 - lr: 0.000015
2021-06-21 23:31:33,948 ----------------------------------------------------------------------------------------------------
2021-06-21 23:31:33,948 EPOCH 14 done: loss 0.1456 - lr 0.0000150
2021-06-21 23:31:35,797 DEV : loss 0.05694594606757164 - score 0.9884
2021-06-21 23:31:35,823 BAD EPOCHS (no improvement): 1
2021-06-21 23:31:35,823 ----------------------------------------------------------------------------------------------------
2021-06-21 23:31:38,542 epoch 15 - iter 6/68 - loss 0.09153705 - samples/sec: 70.64 - lr: 0.000015
2021-06-21 23:31:41,196 epoch 15 - iter 12/68 - loss 0.11611519 - samples/sec: 72.36 - lr: 0.000015
2021-06-21 23:31:43,917 epoch 15 - iter 18/68 - loss 0.12062391 - samples/sec: 70.57 - lr: 0.000015
2021-06-21 23:31:46,669 epoch 15 - iter 24/68 - loss 0.12381553 - samples/sec: 69.80 - lr: 0.000015
2021-06-21 23:31:49,405 epoch 15 - iter 30/68 - loss 0.12853796 - samples/sec: 70.20 - lr: 0.000015
2021-06-21 23:31:52,126 epoch 15 - iter 36/68 - loss 0.12840088 - samples/sec: 70.56 - lr: 0.000015
2021-06-21 23:31:54,856 epoch 15 - iter 42/68 - loss 0.13355274 - samples/sec: 70.34 - lr: 0.000015
2021-06-21 23:31:57,587 epoch 15 - iter 48/68 - loss 0.13911922 - samples/sec: 70.34 - lr: 0.000015
2021-06-21 23:32:00,295 epoch 15 - iter 54/68 - loss 0.14151126 - samples/sec: 70.91 - lr: 0.000015
2021-06-21 23:32:03,081 epoch 15 - iter 60/68 - loss 0.14630248 - samples/sec: 68.94 - lr: 0.000015
2021-06-21 23:32:05,754 epoch 15 - iter 66/68 - loss 0.14719513 - samples/sec: 71.83 - lr: 0.000015
2021-06-21 23:32:06,295 ----------------------------------------------------------------------------------------------------
2021-06-21 23:32:06,296 EPOCH 15 done: loss 0.1491 - lr 0.0000150
2021-06-21 23:32:08,142 DEV : loss 0.05330831930041313 - score 0.9884
2021-06-21 23:32:08,168 BAD EPOCHS (no improvement): 2
2021-06-21 23:32:08,168 ----------------------------------------------------------------------------------------------------
2021-06-21 23:32:10,914 epoch 16 - iter 6/68 - loss 0.11188692 - samples/sec: 69.92 - lr: 0.000015
2021-06-21 23:32:13,643 epoch 16 - iter 12/68 - loss 0.15694066 - samples/sec: 70.39 - lr: 0.000015
2021-06-21 23:32:16,365 epoch 16 - iter 18/68 - loss 0.17454230 - samples/sec: 70.54 - lr: 0.000015
2021-06-21 23:32:19,084 epoch 16 - iter 24/68 - loss 0.16548149 - samples/sec: 70.64 - lr: 0.000015
2021-06-21 23:32:21,775 epoch 16 - iter 30/68 - loss 0.16943223 - samples/sec: 71.38 - lr: 0.000015
2021-06-21 23:32:24,546 epoch 16 - iter 36/68 - loss 0.16535052 - samples/sec: 69.28 - lr: 0.000015
2021-06-21 23:32:27,260 epoch 16 - iter 42/68 - loss 0.15849333 - samples/sec: 70.77 - lr: 0.000015
2021-06-21 23:32:29,955 epoch 16 - iter 48/68 - loss 0.15647217 - samples/sec: 71.25 - lr: 0.000015
2021-06-21 23:32:32,718 epoch 16 - iter 54/68 - loss 0.15184634 - samples/sec: 69.51 - lr: 0.000015
2021-06-21 23:32:35,438 epoch 16 - iter 60/68 - loss 0.15290061 - samples/sec: 70.62 - lr: 0.000015
2021-06-21 23:32:38,148 epoch 16 - iter 66/68 - loss 0.14539124 - samples/sec: 70.87 - lr: 0.000015
2021-06-21 23:32:38,684 ----------------------------------------------------------------------------------------------------
2021-06-21 23:32:38,684 EPOCH 16 done: loss 0.1441 - lr 0.0000150
2021-06-21 23:32:40,536 DEV : loss 0.05295528098940849 - score 0.9884
2021-06-21 23:32:40,562 BAD EPOCHS (no improvement): 3
2021-06-21 23:32:40,562 ----------------------------------------------------------------------------------------------------
2021-06-21 23:32:43,256 epoch 17 - iter 6/68 - loss 0.14332495 - samples/sec: 71.30 - lr: 0.000015
2021-06-21 23:32:45,998 epoch 17 - iter 12/68 - loss 0.14615222 - samples/sec: 70.04 - lr: 0.000015
2021-06-21 23:32:48,681 epoch 17 - iter 18/68 - loss 0.13730593 - samples/sec: 71.58 - lr: 0.000015
2021-06-21 23:32:51,406 epoch 17 - iter 24/68 - loss 0.12462428 - samples/sec: 70.47 - lr: 0.000015
2021-06-21 23:32:54,138 epoch 17 - iter 30/68 - loss 0.12724756 - samples/sec: 70.30 - lr: 0.000015
2021-06-21 23:32:56,873 epoch 17 - iter 36/68 - loss 0.12862729 - samples/sec: 70.23 - lr: 0.000015
2021-06-21 23:32:59,577 epoch 17 - iter 42/68 - loss 0.12785136 - samples/sec: 71.03 - lr: 0.000015
2021-06-21 23:33:02,321 epoch 17 - iter 48/68 - loss 0.13347017 - samples/sec: 69.97 - lr: 0.000015
2021-06-21 23:33:05,026 epoch 17 - iter 54/68 - loss 0.12994724 - samples/sec: 71.01 - lr: 0.000015
2021-06-21 23:33:07,748 epoch 17 - iter 60/68 - loss 0.13744324 - samples/sec: 70.55 - lr: 0.000015
2021-06-21 23:33:10,498 epoch 17 - iter 66/68 - loss 0.13567535 - samples/sec: 69.83 - lr: 0.000015
2021-06-21 23:33:11,038 ----------------------------------------------------------------------------------------------------
2021-06-21 23:33:11,038 EPOCH 17 done: loss 0.1623 - lr 0.0000150
2021-06-21 23:33:12,892 DEV : loss 0.05071339011192322 - score 0.9884
Epoch    17: reducing learning rate of group 0 to 7.5000e-06.
2021-06-21 23:33:12,918 BAD EPOCHS (no improvement): 4
2021-06-21 23:33:12,918 ----------------------------------------------------------------------------------------------------
2021-06-21 23:33:15,832 epoch 18 - iter 6/68 - loss 0.12691383 - samples/sec: 65.90 - lr: 0.000008
2021-06-21 23:33:18,589 epoch 18 - iter 12/68 - loss 0.13681335 - samples/sec: 69.65 - lr: 0.000008
2021-06-21 23:33:21,288 epoch 18 - iter 18/68 - loss 0.13298098 - samples/sec: 71.16 - lr: 0.000008
2021-06-21 23:33:23,985 epoch 18 - iter 24/68 - loss 0.12772060 - samples/sec: 71.21 - lr: 0.000008
2021-06-21 23:33:26,738 epoch 18 - iter 30/68 - loss 0.12579488 - samples/sec: 69.76 - lr: 0.000008
2021-06-21 23:33:29,465 epoch 18 - iter 36/68 - loss 0.12446666 - samples/sec: 70.42 - lr: 0.000008
2021-06-21 23:33:32,205 epoch 18 - iter 42/68 - loss 0.13381615 - samples/sec: 70.10 - lr: 0.000008
2021-06-21 23:33:34,921 epoch 18 - iter 48/68 - loss 0.13372895 - samples/sec: 70.72 - lr: 0.000008
2021-06-21 23:33:37,622 epoch 18 - iter 54/68 - loss 0.12983178 - samples/sec: 71.08 - lr: 0.000008
2021-06-21 23:33:40,374 epoch 18 - iter 60/68 - loss 0.13063107 - samples/sec: 69.80 - lr: 0.000008
2021-06-21 23:33:43,057 epoch 18 - iter 66/68 - loss 0.12574123 - samples/sec: 71.56 - lr: 0.000008
2021-06-21 23:33:43,575 ----------------------------------------------------------------------------------------------------
2021-06-21 23:33:43,575 EPOCH 18 done: loss 0.1240 - lr 0.0000075
2021-06-21 23:33:45,426 DEV : loss 0.0498964861035347 - score 0.9884
2021-06-21 23:33:45,452 BAD EPOCHS (no improvement): 1
2021-06-21 23:33:45,452 ----------------------------------------------------------------------------------------------------
2021-06-21 23:33:48,149 epoch 19 - iter 6/68 - loss 0.13363305 - samples/sec: 71.21 - lr: 0.000008
2021-06-21 23:33:50,898 epoch 19 - iter 12/68 - loss 0.13608307 - samples/sec: 69.85 - lr: 0.000008
2021-06-21 23:33:53,641 epoch 19 - iter 18/68 - loss 0.12996896 - samples/sec: 70.02 - lr: 0.000008
2021-06-21 23:33:56,338 epoch 19 - iter 24/68 - loss 0.13628175 - samples/sec: 71.22 - lr: 0.000008
2021-06-21 23:33:59,004 epoch 19 - iter 30/68 - loss 0.13517367 - samples/sec: 72.02 - lr: 0.000008
2021-06-21 23:34:01,719 epoch 19 - iter 36/68 - loss 0.13485790 - samples/sec: 70.73 - lr: 0.000008
2021-06-21 23:34:04,444 epoch 19 - iter 42/68 - loss 0.12889348 - samples/sec: 70.47 - lr: 0.000008
2021-06-21 23:34:07,154 epoch 19 - iter 48/68 - loss 0.12779145 - samples/sec: 70.88 - lr: 0.000008
2021-06-21 23:34:09,912 epoch 19 - iter 54/68 - loss 0.12518182 - samples/sec: 69.63 - lr: 0.000008
2021-06-21 23:34:12,661 epoch 19 - iter 60/68 - loss 0.12566394 - samples/sec: 69.87 - lr: 0.000008
2021-06-21 23:34:15,415 epoch 19 - iter 66/68 - loss 0.12351935 - samples/sec: 69.72 - lr: 0.000008
2021-06-21 23:34:15,939 ----------------------------------------------------------------------------------------------------
2021-06-21 23:34:15,940 EPOCH 19 done: loss 0.1209 - lr 0.0000075
2021-06-21 23:34:17,790 DEV : loss 0.05089646577835083 - score 0.9884
2021-06-21 23:34:17,816 BAD EPOCHS (no improvement): 2
2021-06-21 23:34:17,816 ----------------------------------------------------------------------------------------------------
2021-06-21 23:34:20,536 epoch 20 - iter 6/68 - loss 0.10164175 - samples/sec: 70.61 - lr: 0.000008
2021-06-21 23:34:23,263 epoch 20 - iter 12/68 - loss 0.10037732 - samples/sec: 70.44 - lr: 0.000008
2021-06-21 23:34:26,010 epoch 20 - iter 18/68 - loss 0.11876882 - samples/sec: 69.90 - lr: 0.000008
2021-06-21 23:34:28,757 epoch 20 - iter 24/68 - loss 0.11525277 - samples/sec: 69.92 - lr: 0.000008
2021-06-21 23:34:31,431 epoch 20 - iter 30/68 - loss 0.11748076 - samples/sec: 71.81 - lr: 0.000008
2021-06-21 23:34:34,102 epoch 20 - iter 36/68 - loss 0.11504448 - samples/sec: 71.90 - lr: 0.000008
2021-06-21 23:34:36,798 epoch 20 - iter 42/68 - loss 0.11599125 - samples/sec: 71.22 - lr: 0.000008
2021-06-21 23:34:39,508 epoch 20 - iter 48/68 - loss 0.11656203 - samples/sec: 70.87 - lr: 0.000008
2021-06-21 23:34:42,232 epoch 20 - iter 54/68 - loss 0.11556043 - samples/sec: 70.50 - lr: 0.000008
2021-06-21 23:34:44,994 epoch 20 - iter 60/68 - loss 0.11394251 - samples/sec: 69.53 - lr: 0.000008
2021-06-21 23:34:47,693 epoch 20 - iter 66/68 - loss 0.11075840 - samples/sec: 71.16 - lr: 0.000008
2021-06-21 23:34:48,235 ----------------------------------------------------------------------------------------------------
2021-06-21 23:34:48,235 EPOCH 20 done: loss 0.1095 - lr 0.0000075
2021-06-21 23:34:50,088 DEV : loss 0.05316887050867081 - score 0.9884
2021-06-21 23:34:50,114 BAD EPOCHS (no improvement): 3
2021-06-21 23:34:50,114 ----------------------------------------------------------------------------------------------------
2021-06-21 23:34:52,842 epoch 21 - iter 6/68 - loss 0.14518786 - samples/sec: 70.41 - lr: 0.000008
2021-06-21 23:34:55,605 epoch 21 - iter 12/68 - loss 0.13017082 - samples/sec: 69.49 - lr: 0.000008
2021-06-21 23:34:58,329 epoch 21 - iter 18/68 - loss 0.12256872 - samples/sec: 70.51 - lr: 0.000008
2021-06-21 23:35:01,068 epoch 21 - iter 24/68 - loss 0.11927320 - samples/sec: 70.12 - lr: 0.000008
2021-06-21 23:35:03,837 epoch 21 - iter 30/68 - loss 0.10932768 - samples/sec: 69.35 - lr: 0.000008
2021-06-21 23:35:06,562 epoch 21 - iter 36/68 - loss 0.10884261 - samples/sec: 70.48 - lr: 0.000008
2021-06-21 23:35:09,268 epoch 21 - iter 42/68 - loss 0.10636845 - samples/sec: 70.97 - lr: 0.000008
2021-06-21 23:35:11,970 epoch 21 - iter 48/68 - loss 0.10692228 - samples/sec: 71.07 - lr: 0.000008
2021-06-21 23:35:14,719 epoch 21 - iter 54/68 - loss 0.11870184 - samples/sec: 69.87 - lr: 0.000008
2021-06-21 23:35:17,426 epoch 21 - iter 60/68 - loss 0.11837004 - samples/sec: 70.93 - lr: 0.000008
2021-06-21 23:35:20,190 epoch 21 - iter 66/68 - loss 0.12138582 - samples/sec: 69.50 - lr: 0.000008
2021-06-21 23:35:20,704 ----------------------------------------------------------------------------------------------------
2021-06-21 23:35:20,704 EPOCH 21 done: loss 0.1213 - lr 0.0000075
2021-06-21 23:35:22,749 DEV : loss 0.05677448958158493 - score 0.9884
Epoch    21: reducing learning rate of group 0 to 3.7500e-06.
2021-06-21 23:35:22,775 BAD EPOCHS (no improvement): 4
2021-06-21 23:35:22,775 ----------------------------------------------------------------------------------------------------
2021-06-21 23:35:25,448 epoch 22 - iter 6/68 - loss 0.08682813 - samples/sec: 71.86 - lr: 0.000004
2021-06-21 23:35:28,155 epoch 22 - iter 12/68 - loss 0.10996170 - samples/sec: 70.93 - lr: 0.000004
2021-06-21 23:35:30,907 epoch 22 - iter 18/68 - loss 0.11078429 - samples/sec: 69.78 - lr: 0.000004
2021-06-21 23:35:33,653 epoch 22 - iter 24/68 - loss 0.11522355 - samples/sec: 69.93 - lr: 0.000004
2021-06-21 23:35:36,349 epoch 22 - iter 30/68 - loss 0.10711628 - samples/sec: 71.23 - lr: 0.000004
2021-06-21 23:35:39,062 epoch 22 - iter 36/68 - loss 0.11044839 - samples/sec: 70.79 - lr: 0.000004
2021-06-21 23:35:41,748 epoch 22 - iter 42/68 - loss 0.11352674 - samples/sec: 71.50 - lr: 0.000004
2021-06-21 23:35:44,487 epoch 22 - iter 48/68 - loss 0.11559296 - samples/sec: 70.13 - lr: 0.000004
2021-06-21 23:35:47,242 epoch 22 - iter 54/68 - loss 0.11939951 - samples/sec: 69.69 - lr: 0.000004
2021-06-21 23:35:49,992 epoch 22 - iter 60/68 - loss 0.11716803 - samples/sec: 69.83 - lr: 0.000004
2021-06-21 23:35:52,743 epoch 22 - iter 66/68 - loss 0.11492962 - samples/sec: 69.81 - lr: 0.000004
2021-06-21 23:35:53,269 ----------------------------------------------------------------------------------------------------
2021-06-21 23:35:53,270 EPOCH 22 done: loss 0.1132 - lr 0.0000038
2021-06-21 23:35:55,126 DEV : loss 0.051972031593322754 - score 0.9903
2021-06-21 23:35:55,152 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:35:59,716 ----------------------------------------------------------------------------------------------------
2021-06-21 23:36:02,444 epoch 23 - iter 6/68 - loss 0.15193398 - samples/sec: 70.39 - lr: 0.000004
2021-06-21 23:36:05,117 epoch 23 - iter 12/68 - loss 0.11848866 - samples/sec: 71.87 - lr: 0.000004
2021-06-21 23:36:07,848 epoch 23 - iter 18/68 - loss 0.12805642 - samples/sec: 70.30 - lr: 0.000004
2021-06-21 23:36:10,569 epoch 23 - iter 24/68 - loss 0.12910225 - samples/sec: 70.60 - lr: 0.000004
2021-06-21 23:36:13,273 epoch 23 - iter 30/68 - loss 0.11805035 - samples/sec: 71.01 - lr: 0.000004
2021-06-21 23:36:15,984 epoch 23 - iter 36/68 - loss 0.11455174 - samples/sec: 70.84 - lr: 0.000004
2021-06-21 23:36:18,690 epoch 23 - iter 42/68 - loss 0.11505015 - samples/sec: 70.97 - lr: 0.000004
2021-06-21 23:36:21,433 epoch 23 - iter 48/68 - loss 0.11339948 - samples/sec: 70.01 - lr: 0.000004
2021-06-21 23:36:24,207 epoch 23 - iter 54/68 - loss 0.11598360 - samples/sec: 69.23 - lr: 0.000004
2021-06-21 23:36:26,923 epoch 23 - iter 60/68 - loss 0.11382431 - samples/sec: 70.73 - lr: 0.000004
2021-06-21 23:36:29,654 epoch 23 - iter 66/68 - loss 0.11132744 - samples/sec: 70.30 - lr: 0.000004
2021-06-21 23:36:30,196 ----------------------------------------------------------------------------------------------------
2021-06-21 23:36:30,196 EPOCH 23 done: loss 0.1111 - lr 0.0000038
2021-06-21 23:36:32,048 DEV : loss 0.052433472126722336 - score 0.9884
2021-06-21 23:36:32,073 BAD EPOCHS (no improvement): 1
2021-06-21 23:36:32,074 ----------------------------------------------------------------------------------------------------
2021-06-21 23:36:34,810 epoch 24 - iter 6/68 - loss 0.13772558 - samples/sec: 70.18 - lr: 0.000004
2021-06-21 23:36:37,532 epoch 24 - iter 12/68 - loss 0.11155221 - samples/sec: 70.57 - lr: 0.000004
2021-06-21 23:36:40,292 epoch 24 - iter 18/68 - loss 0.10889568 - samples/sec: 69.56 - lr: 0.000004
2021-06-21 23:36:42,967 epoch 24 - iter 24/68 - loss 0.11179832 - samples/sec: 71.81 - lr: 0.000004
2021-06-21 23:36:45,686 epoch 24 - iter 30/68 - loss 0.11923741 - samples/sec: 70.62 - lr: 0.000004
2021-06-21 23:36:48,422 epoch 24 - iter 36/68 - loss 0.12221300 - samples/sec: 70.18 - lr: 0.000004
2021-06-21 23:36:51,181 epoch 24 - iter 42/68 - loss 0.11571683 - samples/sec: 69.60 - lr: 0.000004
2021-06-21 23:36:53,937 epoch 24 - iter 48/68 - loss 0.11357051 - samples/sec: 69.70 - lr: 0.000004
2021-06-21 23:36:56,686 epoch 24 - iter 54/68 - loss 0.11752662 - samples/sec: 69.87 - lr: 0.000004
2021-06-21 23:36:59,413 epoch 24 - iter 60/68 - loss 0.11470805 - samples/sec: 70.41 - lr: 0.000004
2021-06-21 23:37:02,137 epoch 24 - iter 66/68 - loss 0.11612397 - samples/sec: 70.50 - lr: 0.000004
2021-06-21 23:37:02,663 ----------------------------------------------------------------------------------------------------
2021-06-21 23:37:02,663 EPOCH 24 done: loss 0.1143 - lr 0.0000038
2021-06-21 23:37:04,516 DEV : loss 0.0504460483789444 - score 0.9903
2021-06-21 23:37:04,542 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:37:09,090 ----------------------------------------------------------------------------------------------------
2021-06-21 23:37:11,809 epoch 25 - iter 6/68 - loss 0.12093696 - samples/sec: 70.64 - lr: 0.000004
2021-06-21 23:37:14,560 epoch 25 - iter 12/68 - loss 0.11189014 - samples/sec: 69.81 - lr: 0.000004
2021-06-21 23:37:17,312 epoch 25 - iter 18/68 - loss 0.11052616 - samples/sec: 69.78 - lr: 0.000004
2021-06-21 23:37:20,052 epoch 25 - iter 24/68 - loss 0.12305719 - samples/sec: 70.09 - lr: 0.000004
2021-06-21 23:37:22,773 epoch 25 - iter 30/68 - loss 0.13334737 - samples/sec: 70.57 - lr: 0.000004
2021-06-21 23:37:25,522 epoch 25 - iter 36/68 - loss 0.12816312 - samples/sec: 69.87 - lr: 0.000004
2021-06-21 23:37:28,236 epoch 25 - iter 42/68 - loss 0.12111602 - samples/sec: 70.76 - lr: 0.000004
2021-06-21 23:37:30,961 epoch 25 - iter 48/68 - loss 0.12678459 - samples/sec: 70.48 - lr: 0.000004
2021-06-21 23:37:33,685 epoch 25 - iter 54/68 - loss 0.12487380 - samples/sec: 70.50 - lr: 0.000004
2021-06-21 23:37:36,429 epoch 25 - iter 60/68 - loss 0.12596730 - samples/sec: 69.99 - lr: 0.000004
2021-06-21 23:37:39,160 epoch 25 - iter 66/68 - loss 0.13095718 - samples/sec: 70.31 - lr: 0.000004
2021-06-21 23:37:39,696 ----------------------------------------------------------------------------------------------------
2021-06-21 23:37:39,697 EPOCH 25 done: loss 0.1476 - lr 0.0000038
2021-06-21 23:37:41,734 DEV : loss 0.05421256273984909 - score 0.9846
2021-06-21 23:37:41,760 BAD EPOCHS (no improvement): 1
2021-06-21 23:37:41,760 ----------------------------------------------------------------------------------------------------
2021-06-21 23:37:44,457 epoch 26 - iter 6/68 - loss 0.14130993 - samples/sec: 71.22 - lr: 0.000004
2021-06-21 23:37:47,175 epoch 26 - iter 12/68 - loss 0.12578700 - samples/sec: 70.63 - lr: 0.000004
2021-06-21 23:37:49,930 epoch 26 - iter 18/68 - loss 0.11555565 - samples/sec: 69.73 - lr: 0.000004
2021-06-21 23:37:52,659 epoch 26 - iter 24/68 - loss 0.11678938 - samples/sec: 70.37 - lr: 0.000004
2021-06-21 23:37:55,390 epoch 26 - iter 30/68 - loss 0.12148787 - samples/sec: 70.32 - lr: 0.000004
2021-06-21 23:37:58,154 epoch 26 - iter 36/68 - loss 0.11997422 - samples/sec: 69.49 - lr: 0.000004
2021-06-21 23:38:00,855 epoch 26 - iter 42/68 - loss 0.11583420 - samples/sec: 71.11 - lr: 0.000004
2021-06-21 23:38:03,561 epoch 26 - iter 48/68 - loss 0.11037783 - samples/sec: 70.95 - lr: 0.000004
2021-06-21 23:38:06,299 epoch 26 - iter 54/68 - loss 0.11579217 - samples/sec: 70.14 - lr: 0.000004
2021-06-21 23:38:09,034 epoch 26 - iter 60/68 - loss 0.11541053 - samples/sec: 70.22 - lr: 0.000004
2021-06-21 23:38:11,692 epoch 26 - iter 66/68 - loss 0.11800220 - samples/sec: 72.25 - lr: 0.000004
2021-06-21 23:38:12,228 ----------------------------------------------------------------------------------------------------
2021-06-21 23:38:12,229 EPOCH 26 done: loss 0.1154 - lr 0.0000038
2021-06-21 23:38:14,079 DEV : loss 0.05106073617935181 - score 0.9865
2021-06-21 23:38:14,105 BAD EPOCHS (no improvement): 2
2021-06-21 23:38:14,105 ----------------------------------------------------------------------------------------------------
2021-06-21 23:38:16,837 epoch 27 - iter 6/68 - loss 0.09544057 - samples/sec: 70.30 - lr: 0.000004
2021-06-21 23:38:19,565 epoch 27 - iter 12/68 - loss 0.10042603 - samples/sec: 70.40 - lr: 0.000004
2021-06-21 23:38:22,296 epoch 27 - iter 18/68 - loss 0.11200693 - samples/sec: 70.31 - lr: 0.000004
2021-06-21 23:38:24,944 epoch 27 - iter 24/68 - loss 0.10222033 - samples/sec: 72.53 - lr: 0.000004
2021-06-21 23:38:27,655 epoch 27 - iter 30/68 - loss 0.10910584 - samples/sec: 70.84 - lr: 0.000004
2021-06-21 23:38:30,335 epoch 27 - iter 36/68 - loss 0.10951915 - samples/sec: 71.67 - lr: 0.000004
2021-06-21 23:38:33,058 epoch 27 - iter 42/68 - loss 0.11049983 - samples/sec: 70.50 - lr: 0.000004
2021-06-21 23:38:35,758 epoch 27 - iter 48/68 - loss 0.10950770 - samples/sec: 71.14 - lr: 0.000004
2021-06-21 23:38:38,510 epoch 27 - iter 54/68 - loss 0.10845350 - samples/sec: 69.78 - lr: 0.000004
2021-06-21 23:38:41,211 epoch 27 - iter 60/68 - loss 0.10546881 - samples/sec: 71.10 - lr: 0.000004
2021-06-21 23:38:43,885 epoch 27 - iter 66/68 - loss 0.11053324 - samples/sec: 71.84 - lr: 0.000004
2021-06-21 23:38:44,410 ----------------------------------------------------------------------------------------------------
2021-06-21 23:38:44,410 EPOCH 27 done: loss 0.1183 - lr 0.0000038
2021-06-21 23:38:46,263 DEV : loss 0.05152352154254913 - score 0.9884
2021-06-21 23:38:46,289 BAD EPOCHS (no improvement): 3
2021-06-21 23:38:46,289 ----------------------------------------------------------------------------------------------------
2021-06-21 23:38:48,999 epoch 28 - iter 6/68 - loss 0.18169949 - samples/sec: 70.88 - lr: 0.000004
2021-06-21 23:38:51,771 epoch 28 - iter 12/68 - loss 0.16585926 - samples/sec: 69.28 - lr: 0.000004
2021-06-21 23:38:54,524 epoch 28 - iter 18/68 - loss 0.15718965 - samples/sec: 69.76 - lr: 0.000004
2021-06-21 23:38:57,232 epoch 28 - iter 24/68 - loss 0.13866565 - samples/sec: 70.92 - lr: 0.000004
2021-06-21 23:38:59,912 epoch 28 - iter 30/68 - loss 0.13528860 - samples/sec: 71.64 - lr: 0.000004
2021-06-21 23:39:02,615 epoch 28 - iter 36/68 - loss 0.13476261 - samples/sec: 71.08 - lr: 0.000004
2021-06-21 23:39:05,289 epoch 28 - iter 42/68 - loss 0.12973169 - samples/sec: 71.83 - lr: 0.000004
2021-06-21 23:39:08,031 epoch 28 - iter 48/68 - loss 0.13153507 - samples/sec: 70.03 - lr: 0.000004
2021-06-21 23:39:10,741 epoch 28 - iter 54/68 - loss 0.12362217 - samples/sec: 70.87 - lr: 0.000004
2021-06-21 23:39:13,447 epoch 28 - iter 60/68 - loss 0.11916272 - samples/sec: 70.97 - lr: 0.000004
2021-06-21 23:39:16,163 epoch 28 - iter 66/68 - loss 0.11734497 - samples/sec: 70.69 - lr: 0.000004
2021-06-21 23:39:16,691 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:16,691 EPOCH 28 done: loss 0.1184 - lr 0.0000038
2021-06-21 23:39:18,542 DEV : loss 0.05241268128156662 - score 0.9846
Epoch    28: reducing learning rate of group 0 to 1.8750e-06.
2021-06-21 23:39:18,568 BAD EPOCHS (no improvement): 4
2021-06-21 23:39:18,568 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:18,568 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:18,568 learning rate too small - quitting training!
2021-06-21 23:39:18,568 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:18,984 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:18,984 Testing using best model ...
2021-06-21 23:39:18,984 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/best-model.pt
2021-06-21 23:39:26,260 0.9768	0.9736	0.9752
2021-06-21 23:39:26,261 
Results:
- F1-score (micro) 0.9752
- F1-score (macro) 0.9752

By class:
SENT       tp: 295 - fp: 7 - fn: 8 - precision: 0.9768 - recall: 0.9736 - f1-score: 0.9752
2021-06-21 23:39:26,261 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/
2021-06-21 23:39:26,266 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb
2021-06-21 23:39:26,266 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/sent_train.txt
2021-06-21 23:39:26,266 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/sent_dev.txt
2021-06-21 23:39:26,267 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/sent_test.txt
Corpus: 441 train + 104 dev + 165 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-21 23:39:28,638 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:28,640 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(21128, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-21 23:39:28,640 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:28,640 Corpus: "Corpus: 441 train + 104 dev + 165 test sentences"
2021-06-21 23:39:28,640 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:28,640 Parameters:
2021-06-21 23:39:28,640  - learning_rate: "3e-05"
2021-06-21 23:39:28,640  - mini_batch_size: "32"
2021-06-21 23:39:28,640  - patience: "3"
2021-06-21 23:39:28,640  - anneal_factor: "0.5"
2021-06-21 23:39:28,640  - max_epochs: "40"
2021-06-21 23:39:28,640  - shuffle: "True"
2021-06-21 23:39:28,641  - train_with_dev: "False"
2021-06-21 23:39:28,641  - batch_growth_annealing: "False"
2021-06-21 23:39:28,641 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:28,641 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb"
2021-06-21 23:39:28,641 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:28,641 Device: cuda:0
2021-06-21 23:39:28,641 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:28,641 Embeddings storage mode: cpu
2021-06-21 23:39:28,642 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:29,476 epoch 1 - iter 1/14 - loss 45.22534180 - samples/sec: 38.35 - lr: 0.000030
2021-06-21 23:39:30,329 epoch 1 - iter 2/14 - loss 43.50635529 - samples/sec: 37.55 - lr: 0.000030
2021-06-21 23:39:31,169 epoch 1 - iter 3/14 - loss 41.61998749 - samples/sec: 38.08 - lr: 0.000030
2021-06-21 23:39:32,019 epoch 1 - iter 4/14 - loss 39.26748085 - samples/sec: 37.66 - lr: 0.000030
2021-06-21 23:39:32,893 epoch 1 - iter 5/14 - loss 38.04333038 - samples/sec: 36.64 - lr: 0.000030
2021-06-21 23:39:33,766 epoch 1 - iter 6/14 - loss 36.59052531 - samples/sec: 36.65 - lr: 0.000030
2021-06-21 23:39:34,624 epoch 1 - iter 7/14 - loss 34.82162094 - samples/sec: 37.33 - lr: 0.000030
2021-06-21 23:39:35,482 epoch 1 - iter 8/14 - loss 33.11535692 - samples/sec: 37.31 - lr: 0.000030
2021-06-21 23:39:36,353 epoch 1 - iter 9/14 - loss 31.71087816 - samples/sec: 36.74 - lr: 0.000030
2021-06-21 23:39:37,221 epoch 1 - iter 10/14 - loss 30.33536167 - samples/sec: 36.87 - lr: 0.000030
2021-06-21 23:39:38,087 epoch 1 - iter 11/14 - loss 28.94639553 - samples/sec: 36.99 - lr: 0.000030
2021-06-21 23:39:38,952 epoch 1 - iter 12/14 - loss 27.64867036 - samples/sec: 36.97 - lr: 0.000030
2021-06-21 23:39:39,793 epoch 1 - iter 13/14 - loss 26.46124070 - samples/sec: 38.06 - lr: 0.000030
2021-06-21 23:39:40,482 epoch 1 - iter 14/14 - loss 25.41014726 - samples/sec: 46.48 - lr: 0.000030
2021-06-21 23:39:40,482 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:40,482 EPOCH 1 done: loss 25.4101 - lr 0.0000300
2021-06-21 23:39:42,216 DEV : loss 6.341068267822266 - score 0.1152
2021-06-21 23:39:42,223 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:39:42,618 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:43,035 epoch 2 - iter 1/14 - loss 9.59596539 - samples/sec: 76.97 - lr: 0.000030
2021-06-21 23:39:43,452 epoch 2 - iter 2/14 - loss 9.65813398 - samples/sec: 76.71 - lr: 0.000030
2021-06-21 23:39:43,858 epoch 2 - iter 3/14 - loss 9.00932328 - samples/sec: 78.84 - lr: 0.000030
2021-06-21 23:39:44,270 epoch 2 - iter 4/14 - loss 8.65944910 - samples/sec: 77.88 - lr: 0.000030
2021-06-21 23:39:44,660 epoch 2 - iter 5/14 - loss 8.31412449 - samples/sec: 82.05 - lr: 0.000030
2021-06-21 23:39:45,070 epoch 2 - iter 6/14 - loss 7.97217369 - samples/sec: 78.04 - lr: 0.000030
2021-06-21 23:39:45,482 epoch 2 - iter 7/14 - loss 7.69130210 - samples/sec: 77.75 - lr: 0.000030
2021-06-21 23:39:45,889 epoch 2 - iter 8/14 - loss 7.40367496 - samples/sec: 78.83 - lr: 0.000030
2021-06-21 23:39:46,298 epoch 2 - iter 9/14 - loss 7.20437315 - samples/sec: 78.25 - lr: 0.000030
2021-06-21 23:39:46,717 epoch 2 - iter 10/14 - loss 6.97222610 - samples/sec: 76.50 - lr: 0.000030
2021-06-21 23:39:47,128 epoch 2 - iter 11/14 - loss 6.83350862 - samples/sec: 77.88 - lr: 0.000030
2021-06-21 23:39:47,533 epoch 2 - iter 12/14 - loss 6.59123166 - samples/sec: 79.20 - lr: 0.000030
2021-06-21 23:39:47,942 epoch 2 - iter 13/14 - loss 6.37640153 - samples/sec: 78.21 - lr: 0.000030
2021-06-21 23:39:48,285 epoch 2 - iter 14/14 - loss 6.21319975 - samples/sec: 93.36 - lr: 0.000030
2021-06-21 23:39:48,286 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:48,286 EPOCH 2 done: loss 6.2132 - lr 0.0000300
2021-06-21 23:39:48,769 DEV : loss 4.339608192443848 - score 0.0
2021-06-21 23:39:48,776 BAD EPOCHS (no improvement): 1
2021-06-21 23:39:48,776 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:49,175 epoch 3 - iter 1/14 - loss 4.06979275 - samples/sec: 80.37 - lr: 0.000030
2021-06-21 23:39:49,584 epoch 3 - iter 2/14 - loss 4.16938829 - samples/sec: 78.20 - lr: 0.000030
2021-06-21 23:39:49,999 epoch 3 - iter 3/14 - loss 4.24496921 - samples/sec: 77.28 - lr: 0.000030
2021-06-21 23:39:50,417 epoch 3 - iter 4/14 - loss 4.05148029 - samples/sec: 76.64 - lr: 0.000030
2021-06-21 23:39:50,828 epoch 3 - iter 5/14 - loss 4.07207451 - samples/sec: 77.92 - lr: 0.000030
2021-06-21 23:39:51,244 epoch 3 - iter 6/14 - loss 3.94787804 - samples/sec: 76.98 - lr: 0.000030
2021-06-21 23:39:51,641 epoch 3 - iter 7/14 - loss 3.89291947 - samples/sec: 80.66 - lr: 0.000030
2021-06-21 23:39:52,065 epoch 3 - iter 8/14 - loss 3.92259127 - samples/sec: 75.49 - lr: 0.000030
2021-06-21 23:39:52,485 epoch 3 - iter 9/14 - loss 4.01018508 - samples/sec: 76.38 - lr: 0.000030
2021-06-21 23:39:52,901 epoch 3 - iter 10/14 - loss 3.95828671 - samples/sec: 76.95 - lr: 0.000030
2021-06-21 23:39:53,316 epoch 3 - iter 11/14 - loss 3.92421378 - samples/sec: 77.13 - lr: 0.000030
2021-06-21 23:39:53,728 epoch 3 - iter 12/14 - loss 3.82997036 - samples/sec: 77.72 - lr: 0.000030
2021-06-21 23:39:54,134 epoch 3 - iter 13/14 - loss 3.80450280 - samples/sec: 79.03 - lr: 0.000030
2021-06-21 23:39:54,462 epoch 3 - iter 14/14 - loss 3.78645015 - samples/sec: 97.57 - lr: 0.000030
2021-06-21 23:39:54,462 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:54,462 EPOCH 3 done: loss 3.7865 - lr 0.0000300
2021-06-21 23:39:54,938 DEV : loss 3.370757579803467 - score 0.0
2021-06-21 23:39:54,945 BAD EPOCHS (no improvement): 2
2021-06-21 23:39:54,945 ----------------------------------------------------------------------------------------------------
2021-06-21 23:39:55,339 epoch 4 - iter 1/14 - loss 2.83309031 - samples/sec: 81.23 - lr: 0.000030
2021-06-21 23:39:55,759 epoch 4 - iter 2/14 - loss 3.44707918 - samples/sec: 76.40 - lr: 0.000030
2021-06-21 23:39:56,726 epoch 4 - iter 3/14 - loss 3.54641374 - samples/sec: 33.09 - lr: 0.000030
2021-06-21 23:39:57,138 epoch 4 - iter 4/14 - loss 3.42133033 - samples/sec: 77.79 - lr: 0.000030
2021-06-21 23:39:57,554 epoch 4 - iter 5/14 - loss 3.30396585 - samples/sec: 77.03 - lr: 0.000030
2021-06-21 23:39:57,957 epoch 4 - iter 6/14 - loss 3.25199850 - samples/sec: 79.50 - lr: 0.000030
2021-06-21 23:39:58,365 epoch 4 - iter 7/14 - loss 3.21775866 - samples/sec: 78.49 - lr: 0.000030
2021-06-21 23:39:58,767 epoch 4 - iter 8/14 - loss 3.09877315 - samples/sec: 79.56 - lr: 0.000030
2021-06-21 23:39:59,177 epoch 4 - iter 9/14 - loss 3.08955550 - samples/sec: 78.21 - lr: 0.000030
2021-06-21 23:39:59,583 epoch 4 - iter 10/14 - loss 3.06526711 - samples/sec: 78.85 - lr: 0.000030
2021-06-21 23:39:59,991 epoch 4 - iter 11/14 - loss 3.03458953 - samples/sec: 78.49 - lr: 0.000030
2021-06-21 23:40:00,405 epoch 4 - iter 12/14 - loss 3.02894658 - samples/sec: 77.51 - lr: 0.000030
2021-06-21 23:40:00,812 epoch 4 - iter 13/14 - loss 3.00819058 - samples/sec: 78.68 - lr: 0.000030
2021-06-21 23:40:01,147 epoch 4 - iter 14/14 - loss 2.98921709 - samples/sec: 95.56 - lr: 0.000030
2021-06-21 23:40:01,147 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:01,147 EPOCH 4 done: loss 2.9892 - lr 0.0000300
2021-06-21 23:40:01,624 DEV : loss 2.621554374694824 - score 0.0
2021-06-21 23:40:01,631 BAD EPOCHS (no improvement): 3
2021-06-21 23:40:01,631 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:02,042 epoch 5 - iter 1/14 - loss 2.69962907 - samples/sec: 77.90 - lr: 0.000030
2021-06-21 23:40:02,453 epoch 5 - iter 2/14 - loss 2.37811911 - samples/sec: 78.03 - lr: 0.000030
2021-06-21 23:40:02,874 epoch 5 - iter 3/14 - loss 2.58077343 - samples/sec: 75.93 - lr: 0.000030
2021-06-21 23:40:03,283 epoch 5 - iter 4/14 - loss 2.39790368 - samples/sec: 78.38 - lr: 0.000030
2021-06-21 23:40:03,697 epoch 5 - iter 5/14 - loss 2.47138991 - samples/sec: 77.31 - lr: 0.000030
2021-06-21 23:40:04,112 epoch 5 - iter 6/14 - loss 2.40461946 - samples/sec: 77.31 - lr: 0.000030
2021-06-21 23:40:04,531 epoch 5 - iter 7/14 - loss 2.40588645 - samples/sec: 76.39 - lr: 0.000030
2021-06-21 23:40:04,943 epoch 5 - iter 8/14 - loss 2.41473311 - samples/sec: 77.75 - lr: 0.000030
2021-06-21 23:40:05,350 epoch 5 - iter 9/14 - loss 2.36357085 - samples/sec: 78.73 - lr: 0.000030
2021-06-21 23:40:05,770 epoch 5 - iter 10/14 - loss 2.37720056 - samples/sec: 76.30 - lr: 0.000030
2021-06-21 23:40:06,179 epoch 5 - iter 11/14 - loss 2.38627674 - samples/sec: 78.16 - lr: 0.000030
2021-06-21 23:40:06,593 epoch 5 - iter 12/14 - loss 2.39250269 - samples/sec: 77.35 - lr: 0.000030
2021-06-21 23:40:07,012 epoch 5 - iter 13/14 - loss 2.35091433 - samples/sec: 76.56 - lr: 0.000030
2021-06-21 23:40:07,347 epoch 5 - iter 14/14 - loss 2.36319775 - samples/sec: 95.55 - lr: 0.000030
2021-06-21 23:40:07,348 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:07,348 EPOCH 5 done: loss 2.3632 - lr 0.0000300
2021-06-21 23:40:07,823 DEV : loss 2.1624157428741455 - score 0.2376
2021-06-21 23:40:07,830 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:40:12,011 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:12,420 epoch 6 - iter 1/14 - loss 1.74134016 - samples/sec: 78.50 - lr: 0.000030
2021-06-21 23:40:12,841 epoch 6 - iter 2/14 - loss 2.10576415 - samples/sec: 76.04 - lr: 0.000030
2021-06-21 23:40:13,252 epoch 6 - iter 3/14 - loss 2.00702087 - samples/sec: 77.88 - lr: 0.000030
2021-06-21 23:40:13,676 epoch 6 - iter 4/14 - loss 2.06739670 - samples/sec: 75.49 - lr: 0.000030
2021-06-21 23:40:14,090 epoch 6 - iter 5/14 - loss 2.12949753 - samples/sec: 77.38 - lr: 0.000030
2021-06-21 23:40:14,493 epoch 6 - iter 6/14 - loss 2.07605712 - samples/sec: 79.59 - lr: 0.000030
2021-06-21 23:40:14,899 epoch 6 - iter 7/14 - loss 2.09334656 - samples/sec: 78.88 - lr: 0.000030
2021-06-21 23:40:15,304 epoch 6 - iter 8/14 - loss 2.03190590 - samples/sec: 79.06 - lr: 0.000030
2021-06-21 23:40:15,717 epoch 6 - iter 9/14 - loss 2.00717404 - samples/sec: 77.61 - lr: 0.000030
2021-06-21 23:40:16,138 epoch 6 - iter 10/14 - loss 2.05697985 - samples/sec: 76.05 - lr: 0.000030
2021-06-21 23:40:16,548 epoch 6 - iter 11/14 - loss 2.03757841 - samples/sec: 78.11 - lr: 0.000030
2021-06-21 23:40:16,955 epoch 6 - iter 12/14 - loss 2.02136295 - samples/sec: 78.67 - lr: 0.000030
2021-06-21 23:40:17,378 epoch 6 - iter 13/14 - loss 2.01912523 - samples/sec: 75.68 - lr: 0.000030
2021-06-21 23:40:17,710 epoch 6 - iter 14/14 - loss 1.98380501 - samples/sec: 96.55 - lr: 0.000030
2021-06-21 23:40:17,711 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:17,711 EPOCH 6 done: loss 1.9838 - lr 0.0000300
2021-06-21 23:40:18,188 DEV : loss 1.9365569353103638 - score 0.4202
2021-06-21 23:40:18,195 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:40:22,451 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:22,862 epoch 7 - iter 1/14 - loss 1.74872100 - samples/sec: 78.01 - lr: 0.000030
2021-06-21 23:40:23,280 epoch 7 - iter 2/14 - loss 1.59326810 - samples/sec: 76.62 - lr: 0.000030
2021-06-21 23:40:23,700 epoch 7 - iter 3/14 - loss 1.83489660 - samples/sec: 76.22 - lr: 0.000030
2021-06-21 23:40:24,105 epoch 7 - iter 4/14 - loss 1.73900473 - samples/sec: 79.16 - lr: 0.000030
2021-06-21 23:40:24,525 epoch 7 - iter 5/14 - loss 1.65593758 - samples/sec: 76.26 - lr: 0.000030
2021-06-21 23:40:24,934 epoch 7 - iter 6/14 - loss 1.67436939 - samples/sec: 78.26 - lr: 0.000030
2021-06-21 23:40:25,340 epoch 7 - iter 7/14 - loss 1.71518540 - samples/sec: 79.01 - lr: 0.000030
2021-06-21 23:40:25,757 epoch 7 - iter 8/14 - loss 1.68265821 - samples/sec: 76.83 - lr: 0.000030
2021-06-21 23:40:26,176 epoch 7 - iter 9/14 - loss 1.70826823 - samples/sec: 76.44 - lr: 0.000030
2021-06-21 23:40:26,576 epoch 7 - iter 10/14 - loss 1.69181898 - samples/sec: 80.05 - lr: 0.000030
2021-06-21 23:40:26,992 epoch 7 - iter 11/14 - loss 1.66901664 - samples/sec: 77.04 - lr: 0.000030
2021-06-21 23:40:27,393 epoch 7 - iter 12/14 - loss 1.63490185 - samples/sec: 79.74 - lr: 0.000030
2021-06-21 23:40:27,814 epoch 7 - iter 13/14 - loss 1.67592415 - samples/sec: 76.08 - lr: 0.000030
2021-06-21 23:40:28,145 epoch 7 - iter 14/14 - loss 1.67843550 - samples/sec: 96.85 - lr: 0.000030
2021-06-21 23:40:28,146 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:28,146 EPOCH 7 done: loss 1.6784 - lr 0.0000300
2021-06-21 23:40:28,621 DEV : loss 1.6869523525238037 - score 0.5588
2021-06-21 23:40:28,628 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:40:32,745 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:33,159 epoch 8 - iter 1/14 - loss 1.73047924 - samples/sec: 77.35 - lr: 0.000030
2021-06-21 23:40:33,574 epoch 8 - iter 2/14 - loss 1.68830824 - samples/sec: 77.30 - lr: 0.000030
2021-06-21 23:40:33,977 epoch 8 - iter 3/14 - loss 1.58624462 - samples/sec: 79.38 - lr: 0.000030
2021-06-21 23:40:34,386 epoch 8 - iter 4/14 - loss 1.62671301 - samples/sec: 78.39 - lr: 0.000030
2021-06-21 23:40:34,781 epoch 8 - iter 5/14 - loss 1.59371879 - samples/sec: 80.97 - lr: 0.000030
2021-06-21 23:40:35,196 epoch 8 - iter 6/14 - loss 1.58500510 - samples/sec: 77.24 - lr: 0.000030
2021-06-21 23:40:35,616 epoch 8 - iter 7/14 - loss 1.56182955 - samples/sec: 76.24 - lr: 0.000030
2021-06-21 23:40:36,022 epoch 8 - iter 8/14 - loss 1.50461294 - samples/sec: 78.86 - lr: 0.000030
2021-06-21 23:40:36,446 epoch 8 - iter 9/14 - loss 1.54747045 - samples/sec: 75.65 - lr: 0.000030
2021-06-21 23:40:36,860 epoch 8 - iter 10/14 - loss 1.51268680 - samples/sec: 77.37 - lr: 0.000030
2021-06-21 23:40:37,278 epoch 8 - iter 11/14 - loss 1.51528742 - samples/sec: 76.63 - lr: 0.000030
2021-06-21 23:40:37,693 epoch 8 - iter 12/14 - loss 1.47168396 - samples/sec: 77.09 - lr: 0.000030
2021-06-21 23:40:38,100 epoch 8 - iter 13/14 - loss 1.45225116 - samples/sec: 78.75 - lr: 0.000030
2021-06-21 23:40:38,442 epoch 8 - iter 14/14 - loss 1.45094275 - samples/sec: 93.80 - lr: 0.000030
2021-06-21 23:40:38,442 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:38,442 EPOCH 8 done: loss 1.4509 - lr 0.0000300
2021-06-21 23:40:38,918 DEV : loss 1.6073015928268433 - score 0.5455
2021-06-21 23:40:38,925 BAD EPOCHS (no improvement): 1
2021-06-21 23:40:38,926 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:39,338 epoch 9 - iter 1/14 - loss 1.47874987 - samples/sec: 77.58 - lr: 0.000030
2021-06-21 23:40:39,753 epoch 9 - iter 2/14 - loss 1.29173654 - samples/sec: 77.33 - lr: 0.000030
2021-06-21 23:40:40,170 epoch 9 - iter 3/14 - loss 1.34629031 - samples/sec: 76.78 - lr: 0.000030
2021-06-21 23:40:40,586 epoch 9 - iter 4/14 - loss 1.47643393 - samples/sec: 76.87 - lr: 0.000030
2021-06-21 23:40:40,999 epoch 9 - iter 5/14 - loss 1.47986031 - samples/sec: 77.64 - lr: 0.000030
2021-06-21 23:40:41,413 epoch 9 - iter 6/14 - loss 1.52441780 - samples/sec: 77.37 - lr: 0.000030
2021-06-21 23:40:41,837 epoch 9 - iter 7/14 - loss 1.49397578 - samples/sec: 75.57 - lr: 0.000030
2021-06-21 23:40:42,248 epoch 9 - iter 8/14 - loss 1.48969303 - samples/sec: 77.95 - lr: 0.000030
2021-06-21 23:40:42,668 epoch 9 - iter 9/14 - loss 1.46276303 - samples/sec: 76.27 - lr: 0.000030
2021-06-21 23:40:43,089 epoch 9 - iter 10/14 - loss 1.41843916 - samples/sec: 76.08 - lr: 0.000030
2021-06-21 23:40:43,487 epoch 9 - iter 11/14 - loss 1.37285518 - samples/sec: 80.41 - lr: 0.000030
2021-06-21 23:40:43,912 epoch 9 - iter 12/14 - loss 1.36439104 - samples/sec: 75.43 - lr: 0.000030
2021-06-21 23:40:44,312 epoch 9 - iter 13/14 - loss 1.35604469 - samples/sec: 79.95 - lr: 0.000030
2021-06-21 23:40:44,652 epoch 9 - iter 14/14 - loss 1.37537760 - samples/sec: 94.45 - lr: 0.000030
2021-06-21 23:40:44,652 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:44,652 EPOCH 9 done: loss 1.3754 - lr 0.0000300
2021-06-21 23:40:45,128 DEV : loss 1.4470081329345703 - score 0.6
2021-06-21 23:40:45,136 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:40:49,493 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:49,910 epoch 10 - iter 1/14 - loss 1.00564623 - samples/sec: 76.94 - lr: 0.000030
2021-06-21 23:40:50,313 epoch 10 - iter 2/14 - loss 0.88335919 - samples/sec: 79.42 - lr: 0.000030
2021-06-21 23:40:50,732 epoch 10 - iter 3/14 - loss 1.02898908 - samples/sec: 76.57 - lr: 0.000030
2021-06-21 23:40:51,157 epoch 10 - iter 4/14 - loss 1.07691544 - samples/sec: 75.36 - lr: 0.000030
2021-06-21 23:40:51,558 epoch 10 - iter 5/14 - loss 1.11924090 - samples/sec: 79.88 - lr: 0.000030
2021-06-21 23:40:51,964 epoch 10 - iter 6/14 - loss 1.14776003 - samples/sec: 78.76 - lr: 0.000030
2021-06-21 23:40:52,383 epoch 10 - iter 7/14 - loss 1.10543254 - samples/sec: 76.48 - lr: 0.000030
2021-06-21 23:40:52,806 epoch 10 - iter 8/14 - loss 1.17587580 - samples/sec: 75.75 - lr: 0.000030
2021-06-21 23:40:53,231 epoch 10 - iter 9/14 - loss 1.20780003 - samples/sec: 75.41 - lr: 0.000030
2021-06-21 23:40:53,645 epoch 10 - iter 10/14 - loss 1.22086681 - samples/sec: 77.28 - lr: 0.000030
2021-06-21 23:40:54,053 epoch 10 - iter 11/14 - loss 1.21917828 - samples/sec: 78.61 - lr: 0.000030
2021-06-21 23:40:54,462 epoch 10 - iter 12/14 - loss 1.21899378 - samples/sec: 78.23 - lr: 0.000030
2021-06-21 23:40:54,886 epoch 10 - iter 13/14 - loss 1.21198194 - samples/sec: 75.54 - lr: 0.000030
2021-06-21 23:40:55,224 epoch 10 - iter 14/14 - loss 1.21585601 - samples/sec: 94.86 - lr: 0.000030
2021-06-21 23:40:55,224 ----------------------------------------------------------------------------------------------------
2021-06-21 23:40:55,224 EPOCH 10 done: loss 1.2159 - lr 0.0000300
2021-06-21 23:40:55,700 DEV : loss 1.3601722717285156 - score 0.68
2021-06-21 23:40:55,708 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:40:59,975 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:00,389 epoch 11 - iter 1/14 - loss 1.06952775 - samples/sec: 77.46 - lr: 0.000030
2021-06-21 23:41:00,819 epoch 11 - iter 2/14 - loss 1.30009598 - samples/sec: 74.47 - lr: 0.000030
2021-06-21 23:41:01,229 epoch 11 - iter 3/14 - loss 1.13367645 - samples/sec: 78.10 - lr: 0.000030
2021-06-21 23:41:01,653 epoch 11 - iter 4/14 - loss 1.11694491 - samples/sec: 75.45 - lr: 0.000030
2021-06-21 23:41:02,061 epoch 11 - iter 5/14 - loss 1.08368474 - samples/sec: 78.66 - lr: 0.000030
2021-06-21 23:41:02,481 epoch 11 - iter 6/14 - loss 1.09940486 - samples/sec: 76.24 - lr: 0.000030
2021-06-21 23:41:02,894 epoch 11 - iter 7/14 - loss 1.16467535 - samples/sec: 77.47 - lr: 0.000030
2021-06-21 23:41:03,305 epoch 11 - iter 8/14 - loss 1.11743636 - samples/sec: 77.99 - lr: 0.000030
2021-06-21 23:41:03,720 epoch 11 - iter 9/14 - loss 1.10975102 - samples/sec: 77.15 - lr: 0.000030
2021-06-21 23:41:04,147 epoch 11 - iter 10/14 - loss 1.10503905 - samples/sec: 75.08 - lr: 0.000030
2021-06-21 23:41:04,571 epoch 11 - iter 11/14 - loss 1.15467917 - samples/sec: 75.43 - lr: 0.000030
2021-06-21 23:41:04,974 epoch 11 - iter 12/14 - loss 1.15235013 - samples/sec: 79.51 - lr: 0.000030
2021-06-21 23:41:05,388 epoch 11 - iter 13/14 - loss 1.14656231 - samples/sec: 77.34 - lr: 0.000030
2021-06-21 23:41:05,711 epoch 11 - iter 14/14 - loss 1.12885442 - samples/sec: 99.21 - lr: 0.000030
2021-06-21 23:41:05,712 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:05,712 EPOCH 11 done: loss 1.1289 - lr 0.0000300
2021-06-21 23:41:06,188 DEV : loss 1.301023244857788 - score 0.6846
2021-06-21 23:41:06,195 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:41:10,487 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:10,916 epoch 12 - iter 1/14 - loss 1.06141376 - samples/sec: 74.75 - lr: 0.000030
2021-06-21 23:41:11,316 epoch 12 - iter 2/14 - loss 1.05448538 - samples/sec: 80.03 - lr: 0.000030
2021-06-21 23:41:11,734 epoch 12 - iter 3/14 - loss 1.01585613 - samples/sec: 76.76 - lr: 0.000030
2021-06-21 23:41:12,144 epoch 12 - iter 4/14 - loss 1.01846327 - samples/sec: 78.02 - lr: 0.000030
2021-06-21 23:41:12,541 epoch 12 - iter 5/14 - loss 0.98167908 - samples/sec: 80.67 - lr: 0.000030
2021-06-21 23:41:12,961 epoch 12 - iter 6/14 - loss 0.96315338 - samples/sec: 76.33 - lr: 0.000030
2021-06-21 23:41:13,371 epoch 12 - iter 7/14 - loss 0.98468462 - samples/sec: 78.11 - lr: 0.000030
2021-06-21 23:41:13,792 epoch 12 - iter 8/14 - loss 0.99998192 - samples/sec: 75.99 - lr: 0.000030
2021-06-21 23:41:14,214 epoch 12 - iter 9/14 - loss 1.05350056 - samples/sec: 75.92 - lr: 0.000030
2021-06-21 23:41:14,630 epoch 12 - iter 10/14 - loss 1.06797423 - samples/sec: 77.02 - lr: 0.000030
2021-06-21 23:41:15,054 epoch 12 - iter 11/14 - loss 1.09171042 - samples/sec: 75.61 - lr: 0.000030
2021-06-21 23:41:15,462 epoch 12 - iter 12/14 - loss 1.08233582 - samples/sec: 78.39 - lr: 0.000030
2021-06-21 23:41:15,889 epoch 12 - iter 13/14 - loss 1.06158007 - samples/sec: 75.02 - lr: 0.000030
2021-06-21 23:41:16,236 epoch 12 - iter 14/14 - loss 1.08853668 - samples/sec: 92.31 - lr: 0.000030
2021-06-21 23:41:16,237 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:16,237 EPOCH 12 done: loss 1.0885 - lr 0.0000300
2021-06-21 23:41:16,713 DEV : loss 1.2233577966690063 - score 0.7305
2021-06-21 23:41:16,720 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:41:21,128 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:21,546 epoch 13 - iter 1/14 - loss 1.28692150 - samples/sec: 76.71 - lr: 0.000030
2021-06-21 23:41:21,969 epoch 13 - iter 2/14 - loss 1.06490648 - samples/sec: 75.72 - lr: 0.000030
2021-06-21 23:41:22,393 epoch 13 - iter 3/14 - loss 1.01365042 - samples/sec: 75.44 - lr: 0.000030
2021-06-21 23:41:22,806 epoch 13 - iter 4/14 - loss 1.05006006 - samples/sec: 77.65 - lr: 0.000030
2021-06-21 23:41:23,220 epoch 13 - iter 5/14 - loss 1.09238722 - samples/sec: 77.30 - lr: 0.000030
2021-06-21 23:41:23,640 epoch 13 - iter 6/14 - loss 1.07014487 - samples/sec: 76.24 - lr: 0.000030
2021-06-21 23:41:24,051 epoch 13 - iter 7/14 - loss 1.02918494 - samples/sec: 77.96 - lr: 0.000030
2021-06-21 23:41:24,475 epoch 13 - iter 8/14 - loss 1.02030139 - samples/sec: 75.64 - lr: 0.000030
2021-06-21 23:41:24,885 epoch 13 - iter 9/14 - loss 0.98067038 - samples/sec: 77.98 - lr: 0.000030
2021-06-21 23:41:25,314 epoch 13 - iter 10/14 - loss 1.00325742 - samples/sec: 74.68 - lr: 0.000030
2021-06-21 23:41:25,729 epoch 13 - iter 11/14 - loss 1.03901569 - samples/sec: 77.18 - lr: 0.000030
2021-06-21 23:41:26,137 epoch 13 - iter 12/14 - loss 1.02379095 - samples/sec: 78.58 - lr: 0.000030
2021-06-21 23:41:26,541 epoch 13 - iter 13/14 - loss 1.01081561 - samples/sec: 79.23 - lr: 0.000030
2021-06-21 23:41:26,875 epoch 13 - iter 14/14 - loss 1.01642486 - samples/sec: 96.14 - lr: 0.000030
2021-06-21 23:41:26,875 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:26,875 EPOCH 13 done: loss 1.0164 - lr 0.0000300
2021-06-21 23:41:27,351 DEV : loss 1.2173669338226318 - score 0.698
2021-06-21 23:41:27,358 BAD EPOCHS (no improvement): 1
2021-06-21 23:41:27,359 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:27,766 epoch 14 - iter 1/14 - loss 1.00728250 - samples/sec: 78.70 - lr: 0.000030
2021-06-21 23:41:28,170 epoch 14 - iter 2/14 - loss 0.97351536 - samples/sec: 79.16 - lr: 0.000030
2021-06-21 23:41:28,588 epoch 14 - iter 3/14 - loss 0.97297047 - samples/sec: 76.61 - lr: 0.000030
2021-06-21 23:41:29,001 epoch 14 - iter 4/14 - loss 0.97537743 - samples/sec: 77.54 - lr: 0.000030
2021-06-21 23:41:29,425 epoch 14 - iter 5/14 - loss 0.92580336 - samples/sec: 75.69 - lr: 0.000030
2021-06-21 23:41:29,850 epoch 14 - iter 6/14 - loss 0.88343528 - samples/sec: 75.27 - lr: 0.000030
2021-06-21 23:41:30,259 epoch 14 - iter 7/14 - loss 0.88566159 - samples/sec: 78.27 - lr: 0.000030
2021-06-21 23:41:30,680 epoch 14 - iter 8/14 - loss 0.87421318 - samples/sec: 76.14 - lr: 0.000030
2021-06-21 23:41:31,109 epoch 14 - iter 9/14 - loss 0.87255483 - samples/sec: 74.69 - lr: 0.000030
2021-06-21 23:41:31,520 epoch 14 - iter 10/14 - loss 0.88092074 - samples/sec: 77.84 - lr: 0.000030
2021-06-21 23:41:31,934 epoch 14 - iter 11/14 - loss 0.87721846 - samples/sec: 77.37 - lr: 0.000030
2021-06-21 23:41:32,356 epoch 14 - iter 12/14 - loss 0.87653702 - samples/sec: 75.98 - lr: 0.000030
2021-06-21 23:41:32,769 epoch 14 - iter 13/14 - loss 0.89169070 - samples/sec: 77.58 - lr: 0.000030
2021-06-21 23:41:33,103 epoch 14 - iter 14/14 - loss 0.91656200 - samples/sec: 95.92 - lr: 0.000030
2021-06-21 23:41:33,103 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:33,103 EPOCH 14 done: loss 0.9166 - lr 0.0000300
2021-06-21 23:41:33,580 DEV : loss 1.1384079456329346 - score 0.7625
2021-06-21 23:41:33,587 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:41:37,868 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:38,294 epoch 15 - iter 1/14 - loss 1.25893116 - samples/sec: 75.35 - lr: 0.000030
2021-06-21 23:41:38,717 epoch 15 - iter 2/14 - loss 1.04388559 - samples/sec: 75.68 - lr: 0.000030
2021-06-21 23:41:39,115 epoch 15 - iter 3/14 - loss 0.94784896 - samples/sec: 80.39 - lr: 0.000030
2021-06-21 23:41:39,498 epoch 15 - iter 4/14 - loss 0.86188930 - samples/sec: 83.74 - lr: 0.000030
2021-06-21 23:41:39,910 epoch 15 - iter 5/14 - loss 0.92824943 - samples/sec: 77.68 - lr: 0.000030
2021-06-21 23:41:40,325 epoch 15 - iter 6/14 - loss 0.93308079 - samples/sec: 77.17 - lr: 0.000030
2021-06-21 23:41:40,740 epoch 15 - iter 7/14 - loss 0.95327633 - samples/sec: 77.21 - lr: 0.000030
2021-06-21 23:41:41,154 epoch 15 - iter 8/14 - loss 0.96657386 - samples/sec: 77.42 - lr: 0.000030
2021-06-21 23:41:41,571 epoch 15 - iter 9/14 - loss 0.95914198 - samples/sec: 76.81 - lr: 0.000030
2021-06-21 23:41:41,994 epoch 15 - iter 10/14 - loss 0.93310372 - samples/sec: 75.81 - lr: 0.000030
2021-06-21 23:41:42,418 epoch 15 - iter 11/14 - loss 0.93822569 - samples/sec: 75.48 - lr: 0.000030
2021-06-21 23:41:42,837 epoch 15 - iter 12/14 - loss 0.93378928 - samples/sec: 76.45 - lr: 0.000030
2021-06-21 23:41:43,261 epoch 15 - iter 13/14 - loss 0.91688584 - samples/sec: 75.54 - lr: 0.000030
2021-06-21 23:41:43,609 epoch 15 - iter 14/14 - loss 0.90101495 - samples/sec: 92.12 - lr: 0.000030
2021-06-21 23:41:43,609 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:43,609 EPOCH 15 done: loss 0.9010 - lr 0.0000300
2021-06-21 23:41:44,085 DEV : loss 1.0840749740600586 - score 0.7683
2021-06-21 23:41:44,093 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:41:48,338 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:48,760 epoch 16 - iter 1/14 - loss 0.83112049 - samples/sec: 75.95 - lr: 0.000030
2021-06-21 23:41:49,177 epoch 16 - iter 2/14 - loss 0.80465475 - samples/sec: 76.88 - lr: 0.000030
2021-06-21 23:41:49,596 epoch 16 - iter 3/14 - loss 0.78464435 - samples/sec: 76.45 - lr: 0.000030
2021-06-21 23:41:50,007 epoch 16 - iter 4/14 - loss 0.78887881 - samples/sec: 77.92 - lr: 0.000030
2021-06-21 23:41:50,420 epoch 16 - iter 5/14 - loss 0.76837134 - samples/sec: 77.55 - lr: 0.000030
2021-06-21 23:41:50,839 epoch 16 - iter 6/14 - loss 0.78567596 - samples/sec: 76.57 - lr: 0.000030
2021-06-21 23:41:51,261 epoch 16 - iter 7/14 - loss 0.78749623 - samples/sec: 75.92 - lr: 0.000030
2021-06-21 23:41:51,663 epoch 16 - iter 8/14 - loss 0.76824331 - samples/sec: 79.55 - lr: 0.000030
2021-06-21 23:41:52,084 epoch 16 - iter 9/14 - loss 0.76664731 - samples/sec: 76.20 - lr: 0.000030
2021-06-21 23:41:52,495 epoch 16 - iter 10/14 - loss 0.77362744 - samples/sec: 77.87 - lr: 0.000030
2021-06-21 23:41:52,917 epoch 16 - iter 11/14 - loss 0.77604148 - samples/sec: 75.86 - lr: 0.000030
2021-06-21 23:41:53,341 epoch 16 - iter 12/14 - loss 0.79266748 - samples/sec: 75.49 - lr: 0.000030
2021-06-21 23:41:53,759 epoch 16 - iter 13/14 - loss 0.80517298 - samples/sec: 76.80 - lr: 0.000030
2021-06-21 23:41:54,088 epoch 16 - iter 14/14 - loss 0.79555595 - samples/sec: 97.37 - lr: 0.000030
2021-06-21 23:41:54,088 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:54,088 EPOCH 16 done: loss 0.7956 - lr 0.0000300
2021-06-21 23:41:54,566 DEV : loss 1.0739315748214722 - score 0.7673
2021-06-21 23:41:54,574 BAD EPOCHS (no improvement): 1
2021-06-21 23:41:54,574 ----------------------------------------------------------------------------------------------------
2021-06-21 23:41:54,974 epoch 17 - iter 1/14 - loss 0.65823698 - samples/sec: 80.12 - lr: 0.000030
2021-06-21 23:41:55,398 epoch 17 - iter 2/14 - loss 0.89261401 - samples/sec: 75.51 - lr: 0.000030
2021-06-21 23:41:55,813 epoch 17 - iter 3/14 - loss 0.90629061 - samples/sec: 77.22 - lr: 0.000030
2021-06-21 23:41:56,214 epoch 17 - iter 4/14 - loss 0.81115493 - samples/sec: 79.80 - lr: 0.000030
2021-06-21 23:41:56,632 epoch 17 - iter 5/14 - loss 0.83874911 - samples/sec: 76.70 - lr: 0.000030
2021-06-21 23:41:57,045 epoch 17 - iter 6/14 - loss 0.83416152 - samples/sec: 77.48 - lr: 0.000030
2021-06-21 23:41:57,453 epoch 17 - iter 7/14 - loss 0.85521565 - samples/sec: 78.44 - lr: 0.000030
2021-06-21 23:41:57,883 epoch 17 - iter 8/14 - loss 0.85557002 - samples/sec: 74.52 - lr: 0.000030
2021-06-21 23:41:58,299 epoch 17 - iter 9/14 - loss 0.82427030 - samples/sec: 77.04 - lr: 0.000030
2021-06-21 23:41:58,726 epoch 17 - iter 10/14 - loss 0.80326087 - samples/sec: 74.97 - lr: 0.000030
2021-06-21 23:41:59,146 epoch 17 - iter 11/14 - loss 0.79212905 - samples/sec: 76.37 - lr: 0.000030
2021-06-21 23:41:59,568 epoch 17 - iter 12/14 - loss 0.76633152 - samples/sec: 75.75 - lr: 0.000030
2021-06-21 23:41:59,996 epoch 17 - iter 13/14 - loss 0.76983286 - samples/sec: 74.89 - lr: 0.000030
2021-06-21 23:42:00,327 epoch 17 - iter 14/14 - loss 0.75203950 - samples/sec: 96.87 - lr: 0.000030
2021-06-21 23:42:00,327 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:00,327 EPOCH 17 done: loss 0.7520 - lr 0.0000300
2021-06-21 23:42:00,806 DEV : loss 1.1150777339935303 - score 0.7333
2021-06-21 23:42:00,814 BAD EPOCHS (no improvement): 2
2021-06-21 23:42:00,814 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:01,233 epoch 18 - iter 1/14 - loss 0.95040488 - samples/sec: 76.35 - lr: 0.000030
2021-06-21 23:42:01,657 epoch 18 - iter 2/14 - loss 0.79378736 - samples/sec: 75.64 - lr: 0.000030
2021-06-21 23:42:02,072 epoch 18 - iter 3/14 - loss 0.79365810 - samples/sec: 77.21 - lr: 0.000030
2021-06-21 23:42:02,479 epoch 18 - iter 4/14 - loss 0.73327313 - samples/sec: 78.75 - lr: 0.000030
2021-06-21 23:42:02,893 epoch 18 - iter 5/14 - loss 0.68879238 - samples/sec: 77.40 - lr: 0.000030
2021-06-21 23:42:03,310 epoch 18 - iter 6/14 - loss 0.73044147 - samples/sec: 76.65 - lr: 0.000030
2021-06-21 23:42:03,729 epoch 18 - iter 7/14 - loss 0.73186609 - samples/sec: 76.54 - lr: 0.000030
2021-06-21 23:42:04,147 epoch 18 - iter 8/14 - loss 0.73034641 - samples/sec: 76.65 - lr: 0.000030
2021-06-21 23:42:04,571 epoch 18 - iter 9/14 - loss 0.72294145 - samples/sec: 75.49 - lr: 0.000030
2021-06-21 23:42:04,971 epoch 18 - iter 10/14 - loss 0.73438337 - samples/sec: 80.05 - lr: 0.000030
2021-06-21 23:42:05,393 epoch 18 - iter 11/14 - loss 0.72544382 - samples/sec: 75.94 - lr: 0.000030
2021-06-21 23:42:05,793 epoch 18 - iter 12/14 - loss 0.71662973 - samples/sec: 80.01 - lr: 0.000030
2021-06-21 23:42:06,219 epoch 18 - iter 13/14 - loss 0.71198365 - samples/sec: 75.20 - lr: 0.000030
2021-06-21 23:42:06,555 epoch 18 - iter 14/14 - loss 0.71320432 - samples/sec: 95.30 - lr: 0.000030
2021-06-21 23:42:06,556 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:06,556 EPOCH 18 done: loss 0.7132 - lr 0.0000300
2021-06-21 23:42:07,032 DEV : loss 1.026706337928772 - score 0.7831
2021-06-21 23:42:07,039 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:42:11,053 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:11,466 epoch 19 - iter 1/14 - loss 1.21850586 - samples/sec: 77.72 - lr: 0.000030
2021-06-21 23:42:11,886 epoch 19 - iter 2/14 - loss 1.04938698 - samples/sec: 76.18 - lr: 0.000030
2021-06-21 23:42:12,312 epoch 19 - iter 3/14 - loss 0.94140728 - samples/sec: 75.18 - lr: 0.000030
2021-06-21 23:42:12,732 epoch 19 - iter 4/14 - loss 0.83295685 - samples/sec: 76.24 - lr: 0.000030
2021-06-21 23:42:13,144 epoch 19 - iter 5/14 - loss 0.80481069 - samples/sec: 77.81 - lr: 0.000030
2021-06-21 23:42:13,552 epoch 19 - iter 6/14 - loss 0.77802318 - samples/sec: 78.58 - lr: 0.000030
2021-06-21 23:42:13,947 epoch 19 - iter 7/14 - loss 0.75643487 - samples/sec: 80.99 - lr: 0.000030
2021-06-21 23:42:14,371 epoch 19 - iter 8/14 - loss 0.73077093 - samples/sec: 75.52 - lr: 0.000030
2021-06-21 23:42:14,769 epoch 19 - iter 9/14 - loss 0.71644828 - samples/sec: 80.67 - lr: 0.000030
2021-06-21 23:42:15,179 epoch 19 - iter 10/14 - loss 0.71105789 - samples/sec: 78.09 - lr: 0.000030
2021-06-21 23:42:15,603 epoch 19 - iter 11/14 - loss 0.71396590 - samples/sec: 75.47 - lr: 0.000030
2021-06-21 23:42:16,028 epoch 19 - iter 12/14 - loss 0.71614741 - samples/sec: 75.39 - lr: 0.000030
2021-06-21 23:42:16,440 epoch 19 - iter 13/14 - loss 0.71893691 - samples/sec: 77.79 - lr: 0.000030
2021-06-21 23:42:16,777 epoch 19 - iter 14/14 - loss 0.72836531 - samples/sec: 94.97 - lr: 0.000030
2021-06-21 23:42:16,777 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:16,778 EPOCH 19 done: loss 0.7284 - lr 0.0000300
2021-06-21 23:42:17,257 DEV : loss 1.0081349611282349 - score 0.8
2021-06-21 23:42:17,265 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:42:21,652 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:22,061 epoch 20 - iter 1/14 - loss 0.74094957 - samples/sec: 78.36 - lr: 0.000030
2021-06-21 23:42:22,482 epoch 20 - iter 2/14 - loss 0.69576296 - samples/sec: 76.03 - lr: 0.000030
2021-06-21 23:42:22,903 epoch 20 - iter 3/14 - loss 0.62723746 - samples/sec: 76.18 - lr: 0.000030
2021-06-21 23:42:23,318 epoch 20 - iter 4/14 - loss 0.64294653 - samples/sec: 77.27 - lr: 0.000030
2021-06-21 23:42:23,735 epoch 20 - iter 5/14 - loss 0.65956260 - samples/sec: 76.74 - lr: 0.000030
2021-06-21 23:42:24,139 epoch 20 - iter 6/14 - loss 0.65780957 - samples/sec: 79.21 - lr: 0.000030
2021-06-21 23:42:24,558 epoch 20 - iter 7/14 - loss 0.63412556 - samples/sec: 76.50 - lr: 0.000030
2021-06-21 23:42:24,974 epoch 20 - iter 8/14 - loss 0.66359407 - samples/sec: 77.07 - lr: 0.000030
2021-06-21 23:42:25,391 epoch 20 - iter 9/14 - loss 0.67367033 - samples/sec: 76.79 - lr: 0.000030
2021-06-21 23:42:25,798 epoch 20 - iter 10/14 - loss 0.66393357 - samples/sec: 78.68 - lr: 0.000030
2021-06-21 23:42:26,222 epoch 20 - iter 11/14 - loss 0.64031135 - samples/sec: 75.52 - lr: 0.000030
2021-06-21 23:42:26,632 epoch 20 - iter 12/14 - loss 0.63937111 - samples/sec: 78.15 - lr: 0.000030
2021-06-21 23:42:27,045 epoch 20 - iter 13/14 - loss 0.63866629 - samples/sec: 77.58 - lr: 0.000030
2021-06-21 23:42:27,387 epoch 20 - iter 14/14 - loss 0.63380007 - samples/sec: 93.70 - lr: 0.000030
2021-06-21 23:42:27,387 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:27,387 EPOCH 20 done: loss 0.6338 - lr 0.0000300
2021-06-21 23:42:27,873 DEV : loss 0.9992729425430298 - score 0.7925
2021-06-21 23:42:27,880 BAD EPOCHS (no improvement): 1
2021-06-21 23:42:27,880 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:28,295 epoch 21 - iter 1/14 - loss 0.73346043 - samples/sec: 77.22 - lr: 0.000030
2021-06-21 23:42:28,714 epoch 21 - iter 2/14 - loss 0.70481238 - samples/sec: 76.45 - lr: 0.000030
2021-06-21 23:42:29,119 epoch 21 - iter 3/14 - loss 0.71523839 - samples/sec: 79.20 - lr: 0.000030
2021-06-21 23:42:29,541 epoch 21 - iter 4/14 - loss 0.70746468 - samples/sec: 75.74 - lr: 0.000030
2021-06-21 23:42:29,948 epoch 21 - iter 5/14 - loss 0.68734916 - samples/sec: 78.74 - lr: 0.000030
2021-06-21 23:42:30,358 epoch 21 - iter 6/14 - loss 0.69447821 - samples/sec: 78.19 - lr: 0.000030
2021-06-21 23:42:30,779 epoch 21 - iter 7/14 - loss 0.69426845 - samples/sec: 76.04 - lr: 0.000030
2021-06-21 23:42:31,165 epoch 21 - iter 8/14 - loss 0.66458625 - samples/sec: 83.04 - lr: 0.000030
2021-06-21 23:42:31,584 epoch 21 - iter 9/14 - loss 0.64830958 - samples/sec: 76.51 - lr: 0.000030
2021-06-21 23:42:32,010 epoch 21 - iter 10/14 - loss 0.66654367 - samples/sec: 75.21 - lr: 0.000030
2021-06-21 23:42:32,426 epoch 21 - iter 11/14 - loss 0.65426042 - samples/sec: 76.85 - lr: 0.000030
2021-06-21 23:42:32,849 epoch 21 - iter 12/14 - loss 0.64861499 - samples/sec: 75.86 - lr: 0.000030
2021-06-21 23:42:33,276 epoch 21 - iter 13/14 - loss 0.63708405 - samples/sec: 74.88 - lr: 0.000030
2021-06-21 23:42:33,611 epoch 21 - iter 14/14 - loss 0.62558906 - samples/sec: 95.58 - lr: 0.000030
2021-06-21 23:42:33,612 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:33,612 EPOCH 21 done: loss 0.6256 - lr 0.0000300
2021-06-21 23:42:34,088 DEV : loss 0.9561992883682251 - score 0.8284
2021-06-21 23:42:34,095 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:42:38,428 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:38,834 epoch 22 - iter 1/14 - loss 0.58436334 - samples/sec: 79.04 - lr: 0.000030
2021-06-21 23:42:39,254 epoch 22 - iter 2/14 - loss 0.57215971 - samples/sec: 76.31 - lr: 0.000030
2021-06-21 23:42:39,672 epoch 22 - iter 3/14 - loss 0.58580530 - samples/sec: 76.59 - lr: 0.000030
2021-06-21 23:42:40,097 epoch 22 - iter 4/14 - loss 0.60271880 - samples/sec: 75.39 - lr: 0.000030
2021-06-21 23:42:40,520 epoch 22 - iter 5/14 - loss 0.60109942 - samples/sec: 75.67 - lr: 0.000030
2021-06-21 23:42:40,933 epoch 22 - iter 6/14 - loss 0.62601121 - samples/sec: 77.66 - lr: 0.000030
2021-06-21 23:42:41,349 epoch 22 - iter 7/14 - loss 0.66931262 - samples/sec: 76.86 - lr: 0.000030
2021-06-21 23:42:41,771 epoch 22 - iter 8/14 - loss 0.66359977 - samples/sec: 76.03 - lr: 0.000030
2021-06-21 23:42:42,194 epoch 22 - iter 9/14 - loss 0.63755844 - samples/sec: 75.71 - lr: 0.000030
2021-06-21 23:42:42,598 epoch 22 - iter 10/14 - loss 0.63247775 - samples/sec: 79.42 - lr: 0.000030
2021-06-21 23:42:43,014 epoch 22 - iter 11/14 - loss 0.63271874 - samples/sec: 76.87 - lr: 0.000030
2021-06-21 23:42:43,435 epoch 22 - iter 12/14 - loss 0.62986056 - samples/sec: 76.11 - lr: 0.000030
2021-06-21 23:42:43,851 epoch 22 - iter 13/14 - loss 0.62991927 - samples/sec: 77.10 - lr: 0.000030
2021-06-21 23:42:44,176 epoch 22 - iter 14/14 - loss 0.62121326 - samples/sec: 98.40 - lr: 0.000030
2021-06-21 23:42:44,177 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:44,177 EPOCH 22 done: loss 0.6212 - lr 0.0000300
2021-06-21 23:42:44,653 DEV : loss 0.9530735015869141 - score 0.8235
2021-06-21 23:42:44,660 BAD EPOCHS (no improvement): 1
2021-06-21 23:42:44,660 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:45,068 epoch 23 - iter 1/14 - loss 0.57802582 - samples/sec: 78.53 - lr: 0.000030
2021-06-21 23:42:45,484 epoch 23 - iter 2/14 - loss 0.52725273 - samples/sec: 77.02 - lr: 0.000030
2021-06-21 23:42:45,896 epoch 23 - iter 3/14 - loss 0.64345400 - samples/sec: 77.59 - lr: 0.000030
2021-06-21 23:42:46,321 epoch 23 - iter 4/14 - loss 0.61931765 - samples/sec: 75.39 - lr: 0.000030
2021-06-21 23:42:46,732 epoch 23 - iter 5/14 - loss 0.59767175 - samples/sec: 78.08 - lr: 0.000030
2021-06-21 23:42:47,149 epoch 23 - iter 6/14 - loss 0.60696602 - samples/sec: 76.72 - lr: 0.000030
2021-06-21 23:42:47,575 epoch 23 - iter 7/14 - loss 0.58009550 - samples/sec: 75.11 - lr: 0.000030
2021-06-21 23:42:47,995 epoch 23 - iter 8/14 - loss 0.58804844 - samples/sec: 76.29 - lr: 0.000030
2021-06-21 23:42:48,397 epoch 23 - iter 9/14 - loss 0.57510976 - samples/sec: 79.80 - lr: 0.000030
2021-06-21 23:42:48,809 epoch 23 - iter 10/14 - loss 0.56948602 - samples/sec: 77.72 - lr: 0.000030
2021-06-21 23:42:49,230 epoch 23 - iter 11/14 - loss 0.56962895 - samples/sec: 76.15 - lr: 0.000030
2021-06-21 23:42:49,636 epoch 23 - iter 12/14 - loss 0.57578866 - samples/sec: 78.82 - lr: 0.000030
2021-06-21 23:42:50,045 epoch 23 - iter 13/14 - loss 0.55569734 - samples/sec: 78.28 - lr: 0.000030
2021-06-21 23:42:50,384 epoch 23 - iter 14/14 - loss 0.53712564 - samples/sec: 94.61 - lr: 0.000030
2021-06-21 23:42:50,384 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:50,384 EPOCH 23 done: loss 0.5371 - lr 0.0000300
2021-06-21 23:42:50,860 DEV : loss 0.9765167236328125 - score 0.7975
2021-06-21 23:42:50,867 BAD EPOCHS (no improvement): 2
2021-06-21 23:42:50,867 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:51,280 epoch 24 - iter 1/14 - loss 0.67940664 - samples/sec: 77.63 - lr: 0.000030
2021-06-21 23:42:51,689 epoch 24 - iter 2/14 - loss 0.52166893 - samples/sec: 78.28 - lr: 0.000030
2021-06-21 23:42:52,100 epoch 24 - iter 3/14 - loss 0.57000884 - samples/sec: 77.98 - lr: 0.000030
2021-06-21 23:42:52,515 epoch 24 - iter 4/14 - loss 0.53610656 - samples/sec: 77.23 - lr: 0.000030
2021-06-21 23:42:52,938 epoch 24 - iter 5/14 - loss 0.53079126 - samples/sec: 75.62 - lr: 0.000030
2021-06-21 23:42:53,360 epoch 24 - iter 6/14 - loss 0.51848982 - samples/sec: 76.03 - lr: 0.000030
2021-06-21 23:42:53,778 epoch 24 - iter 7/14 - loss 0.50097713 - samples/sec: 76.61 - lr: 0.000030
2021-06-21 23:42:54,196 epoch 24 - iter 8/14 - loss 0.50061139 - samples/sec: 76.52 - lr: 0.000030
2021-06-21 23:42:54,598 epoch 24 - iter 9/14 - loss 0.52303162 - samples/sec: 79.67 - lr: 0.000030
2021-06-21 23:42:55,016 epoch 24 - iter 10/14 - loss 0.53134475 - samples/sec: 76.71 - lr: 0.000030
2021-06-21 23:42:55,434 epoch 24 - iter 11/14 - loss 0.53180442 - samples/sec: 76.60 - lr: 0.000030
2021-06-21 23:42:55,847 epoch 24 - iter 12/14 - loss 0.51398571 - samples/sec: 77.65 - lr: 0.000030
2021-06-21 23:42:56,273 epoch 24 - iter 13/14 - loss 0.51249036 - samples/sec: 75.03 - lr: 0.000030
2021-06-21 23:42:56,602 epoch 24 - iter 14/14 - loss 0.50363459 - samples/sec: 97.67 - lr: 0.000030
2021-06-21 23:42:56,602 ----------------------------------------------------------------------------------------------------
2021-06-21 23:42:56,602 EPOCH 24 done: loss 0.5036 - lr 0.0000300
2021-06-21 23:42:57,078 DEV : loss 0.9198299050331116 - score 0.8333
2021-06-21 23:42:57,086 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:43:01,395 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:01,814 epoch 25 - iter 1/14 - loss 0.35143423 - samples/sec: 76.53 - lr: 0.000030
2021-06-21 23:43:02,228 epoch 25 - iter 2/14 - loss 0.50882083 - samples/sec: 77.47 - lr: 0.000030
2021-06-21 23:43:02,647 epoch 25 - iter 3/14 - loss 0.56827494 - samples/sec: 76.29 - lr: 0.000030
2021-06-21 23:43:03,065 epoch 25 - iter 4/14 - loss 0.55267958 - samples/sec: 76.76 - lr: 0.000030
2021-06-21 23:43:03,469 epoch 25 - iter 5/14 - loss 0.52565573 - samples/sec: 79.21 - lr: 0.000030
2021-06-21 23:43:03,881 epoch 25 - iter 6/14 - loss 0.53756676 - samples/sec: 77.79 - lr: 0.000030
2021-06-21 23:43:04,294 epoch 25 - iter 7/14 - loss 0.53579852 - samples/sec: 77.56 - lr: 0.000030
2021-06-21 23:43:04,711 epoch 25 - iter 8/14 - loss 0.54969136 - samples/sec: 76.85 - lr: 0.000030
2021-06-21 23:43:05,128 epoch 25 - iter 9/14 - loss 0.54191569 - samples/sec: 76.82 - lr: 0.000030
2021-06-21 23:43:05,547 epoch 25 - iter 10/14 - loss 0.56743485 - samples/sec: 76.27 - lr: 0.000030
2021-06-21 23:43:05,966 epoch 25 - iter 11/14 - loss 0.54354894 - samples/sec: 76.54 - lr: 0.000030
2021-06-21 23:43:06,383 epoch 25 - iter 12/14 - loss 0.55133144 - samples/sec: 76.75 - lr: 0.000030
2021-06-21 23:43:06,799 epoch 25 - iter 13/14 - loss 0.55329606 - samples/sec: 77.08 - lr: 0.000030
2021-06-21 23:43:07,142 epoch 25 - iter 14/14 - loss 0.53762994 - samples/sec: 93.43 - lr: 0.000030
2021-06-21 23:43:07,142 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:07,142 EPOCH 25 done: loss 0.5376 - lr 0.0000300
2021-06-21 23:43:07,619 DEV : loss 0.929482102394104 - score 0.8144
2021-06-21 23:43:07,626 BAD EPOCHS (no improvement): 1
2021-06-21 23:43:07,626 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:08,035 epoch 26 - iter 1/14 - loss 0.38730347 - samples/sec: 78.37 - lr: 0.000030
2021-06-21 23:43:08,449 epoch 26 - iter 2/14 - loss 0.44468457 - samples/sec: 77.26 - lr: 0.000030
2021-06-21 23:43:08,870 epoch 26 - iter 3/14 - loss 0.43709179 - samples/sec: 76.16 - lr: 0.000030
2021-06-21 23:43:09,296 epoch 26 - iter 4/14 - loss 0.40733436 - samples/sec: 75.15 - lr: 0.000030
2021-06-21 23:43:09,714 epoch 26 - iter 5/14 - loss 0.38347836 - samples/sec: 76.67 - lr: 0.000030
2021-06-21 23:43:10,140 epoch 26 - iter 6/14 - loss 0.42088528 - samples/sec: 75.20 - lr: 0.000030
2021-06-21 23:43:10,550 epoch 26 - iter 7/14 - loss 0.42764926 - samples/sec: 78.20 - lr: 0.000030
2021-06-21 23:43:10,966 epoch 26 - iter 8/14 - loss 0.43305468 - samples/sec: 76.97 - lr: 0.000030
2021-06-21 23:43:11,384 epoch 26 - iter 9/14 - loss 0.44310582 - samples/sec: 76.56 - lr: 0.000030
2021-06-21 23:43:11,805 epoch 26 - iter 10/14 - loss 0.46192381 - samples/sec: 76.08 - lr: 0.000030
2021-06-21 23:43:12,228 epoch 26 - iter 11/14 - loss 0.49037027 - samples/sec: 75.68 - lr: 0.000030
2021-06-21 23:43:12,628 epoch 26 - iter 12/14 - loss 0.48385438 - samples/sec: 80.21 - lr: 0.000030
2021-06-21 23:43:13,028 epoch 26 - iter 13/14 - loss 0.48782459 - samples/sec: 79.92 - lr: 0.000030
2021-06-21 23:43:13,369 epoch 26 - iter 14/14 - loss 0.47978273 - samples/sec: 93.97 - lr: 0.000030
2021-06-21 23:43:13,370 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:13,370 EPOCH 26 done: loss 0.4798 - lr 0.0000300
2021-06-21 23:43:13,846 DEV : loss 0.9091141223907471 - score 0.8193
2021-06-21 23:43:13,853 BAD EPOCHS (no improvement): 2
2021-06-21 23:43:13,853 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:14,265 epoch 27 - iter 1/14 - loss 0.40449476 - samples/sec: 77.80 - lr: 0.000030
2021-06-21 23:43:14,677 epoch 27 - iter 2/14 - loss 0.57868588 - samples/sec: 77.69 - lr: 0.000030
2021-06-21 23:43:15,075 epoch 27 - iter 3/14 - loss 0.60000873 - samples/sec: 80.65 - lr: 0.000030
2021-06-21 23:43:15,496 epoch 27 - iter 4/14 - loss 0.55315810 - samples/sec: 75.92 - lr: 0.000030
2021-06-21 23:43:15,921 epoch 27 - iter 5/14 - loss 0.52916217 - samples/sec: 75.39 - lr: 0.000030
2021-06-21 23:43:16,339 epoch 27 - iter 6/14 - loss 0.53910283 - samples/sec: 76.76 - lr: 0.000030
2021-06-21 23:43:16,746 epoch 27 - iter 7/14 - loss 0.50078452 - samples/sec: 78.64 - lr: 0.000030
2021-06-21 23:43:17,169 epoch 27 - iter 8/14 - loss 0.50817366 - samples/sec: 75.78 - lr: 0.000030
2021-06-21 23:43:17,598 epoch 27 - iter 9/14 - loss 0.50761455 - samples/sec: 74.56 - lr: 0.000030
2021-06-21 23:43:18,014 epoch 27 - iter 10/14 - loss 0.49884323 - samples/sec: 77.00 - lr: 0.000030
2021-06-21 23:43:18,421 epoch 27 - iter 11/14 - loss 0.51439433 - samples/sec: 78.74 - lr: 0.000030
2021-06-21 23:43:18,846 epoch 27 - iter 12/14 - loss 0.50899488 - samples/sec: 75.37 - lr: 0.000030
2021-06-21 23:43:19,260 epoch 27 - iter 13/14 - loss 0.50376519 - samples/sec: 77.30 - lr: 0.000030
2021-06-21 23:43:19,595 epoch 27 - iter 14/14 - loss 0.49293365 - samples/sec: 95.76 - lr: 0.000030
2021-06-21 23:43:19,595 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:19,595 EPOCH 27 done: loss 0.4929 - lr 0.0000300
2021-06-21 23:43:20,150 DEV : loss 0.9490921497344971 - score 0.7975
2021-06-21 23:43:20,157 BAD EPOCHS (no improvement): 3
2021-06-21 23:43:20,157 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:20,582 epoch 28 - iter 1/14 - loss 0.63723254 - samples/sec: 75.41 - lr: 0.000030
2021-06-21 23:43:20,997 epoch 28 - iter 2/14 - loss 0.61782539 - samples/sec: 77.11 - lr: 0.000030
2021-06-21 23:43:21,420 epoch 28 - iter 3/14 - loss 0.63158353 - samples/sec: 75.84 - lr: 0.000030
2021-06-21 23:43:21,828 epoch 28 - iter 4/14 - loss 0.53660718 - samples/sec: 78.46 - lr: 0.000030
2021-06-21 23:43:22,243 epoch 28 - iter 5/14 - loss 0.51228633 - samples/sec: 77.13 - lr: 0.000030
2021-06-21 23:43:22,663 epoch 28 - iter 6/14 - loss 0.47888589 - samples/sec: 76.23 - lr: 0.000030
2021-06-21 23:43:23,082 epoch 28 - iter 7/14 - loss 0.46675017 - samples/sec: 76.54 - lr: 0.000030
2021-06-21 23:43:23,509 epoch 28 - iter 8/14 - loss 0.48366433 - samples/sec: 75.01 - lr: 0.000030
2021-06-21 23:43:23,932 epoch 28 - iter 9/14 - loss 0.47846937 - samples/sec: 75.72 - lr: 0.000030
2021-06-21 23:43:24,339 epoch 28 - iter 10/14 - loss 0.48276719 - samples/sec: 78.68 - lr: 0.000030
2021-06-21 23:43:24,762 epoch 28 - iter 11/14 - loss 0.47181202 - samples/sec: 75.79 - lr: 0.000030
2021-06-21 23:43:25,187 epoch 28 - iter 12/14 - loss 0.46210215 - samples/sec: 75.36 - lr: 0.000030
2021-06-21 23:43:25,594 epoch 28 - iter 13/14 - loss 0.44569532 - samples/sec: 78.72 - lr: 0.000030
2021-06-21 23:43:25,908 epoch 28 - iter 14/14 - loss 0.44609702 - samples/sec: 101.99 - lr: 0.000030
2021-06-21 23:43:25,908 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:25,908 EPOCH 28 done: loss 0.4461 - lr 0.0000300
2021-06-21 23:43:26,383 DEV : loss 0.9163565635681152 - score 0.8344
2021-06-21 23:43:26,391 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:43:30,887 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:31,320 epoch 29 - iter 1/14 - loss 0.80295634 - samples/sec: 74.05 - lr: 0.000030
2021-06-21 23:43:31,741 epoch 29 - iter 2/14 - loss 0.56077051 - samples/sec: 76.01 - lr: 0.000030
2021-06-21 23:43:32,156 epoch 29 - iter 3/14 - loss 0.54250352 - samples/sec: 77.21 - lr: 0.000030
2021-06-21 23:43:32,572 epoch 29 - iter 4/14 - loss 0.48946063 - samples/sec: 77.14 - lr: 0.000030
2021-06-21 23:43:32,990 epoch 29 - iter 5/14 - loss 0.51136805 - samples/sec: 76.61 - lr: 0.000030
2021-06-21 23:43:33,381 epoch 29 - iter 6/14 - loss 0.49112631 - samples/sec: 81.78 - lr: 0.000030
2021-06-21 23:43:33,802 epoch 29 - iter 7/14 - loss 0.47746373 - samples/sec: 76.14 - lr: 0.000030
2021-06-21 23:43:34,216 epoch 29 - iter 8/14 - loss 0.50251811 - samples/sec: 77.37 - lr: 0.000030
2021-06-21 23:43:34,637 epoch 29 - iter 9/14 - loss 0.50057313 - samples/sec: 76.02 - lr: 0.000030
2021-06-21 23:43:35,059 epoch 29 - iter 10/14 - loss 0.49254021 - samples/sec: 75.92 - lr: 0.000030
2021-06-21 23:43:35,470 epoch 29 - iter 11/14 - loss 0.48572234 - samples/sec: 77.95 - lr: 0.000030
2021-06-21 23:43:35,872 epoch 29 - iter 12/14 - loss 0.46379633 - samples/sec: 79.62 - lr: 0.000030
2021-06-21 23:43:36,293 epoch 29 - iter 13/14 - loss 0.47136966 - samples/sec: 76.20 - lr: 0.000030
2021-06-21 23:43:36,626 epoch 29 - iter 14/14 - loss 0.46858860 - samples/sec: 96.25 - lr: 0.000030
2021-06-21 23:43:36,626 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:36,626 EPOCH 29 done: loss 0.4686 - lr 0.0000300
2021-06-21 23:43:37,102 DEV : loss 0.9001303911209106 - score 0.8364
2021-06-21 23:43:37,109 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:43:41,390 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:41,854 epoch 30 - iter 1/14 - loss 0.41242513 - samples/sec: 77.08 - lr: 0.000030
2021-06-21 23:43:42,274 epoch 30 - iter 2/14 - loss 0.47051661 - samples/sec: 76.21 - lr: 0.000030
2021-06-21 23:43:42,684 epoch 30 - iter 3/14 - loss 0.41760517 - samples/sec: 78.23 - lr: 0.000030
2021-06-21 23:43:43,092 epoch 30 - iter 4/14 - loss 0.41468747 - samples/sec: 78.44 - lr: 0.000030
2021-06-21 23:43:43,521 epoch 30 - iter 5/14 - loss 0.45579907 - samples/sec: 74.74 - lr: 0.000030
2021-06-21 23:43:43,935 epoch 30 - iter 6/14 - loss 0.41933000 - samples/sec: 77.33 - lr: 0.000030
2021-06-21 23:43:44,351 epoch 30 - iter 7/14 - loss 0.42717294 - samples/sec: 77.04 - lr: 0.000030
2021-06-21 23:43:44,773 epoch 30 - iter 8/14 - loss 0.43928651 - samples/sec: 75.81 - lr: 0.000030
2021-06-21 23:43:45,191 epoch 30 - iter 9/14 - loss 0.41683394 - samples/sec: 76.75 - lr: 0.000030
2021-06-21 23:43:45,604 epoch 30 - iter 10/14 - loss 0.43572406 - samples/sec: 77.53 - lr: 0.000030
2021-06-21 23:43:46,012 epoch 30 - iter 11/14 - loss 0.42320301 - samples/sec: 78.59 - lr: 0.000030
2021-06-21 23:43:46,426 epoch 30 - iter 12/14 - loss 0.41084694 - samples/sec: 77.21 - lr: 0.000030
2021-06-21 23:43:46,841 epoch 30 - iter 13/14 - loss 0.39975130 - samples/sec: 77.30 - lr: 0.000030
2021-06-21 23:43:47,186 epoch 30 - iter 14/14 - loss 0.41004097 - samples/sec: 92.72 - lr: 0.000030
2021-06-21 23:43:47,187 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:47,187 EPOCH 30 done: loss 0.4100 - lr 0.0000300
2021-06-21 23:43:47,662 DEV : loss 0.9116440415382385 - score 0.8293
2021-06-21 23:43:47,670 BAD EPOCHS (no improvement): 1
2021-06-21 23:43:47,670 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:48,076 epoch 31 - iter 1/14 - loss 0.42265144 - samples/sec: 78.96 - lr: 0.000030
2021-06-21 23:43:48,475 epoch 31 - iter 2/14 - loss 0.35470612 - samples/sec: 80.13 - lr: 0.000030
2021-06-21 23:43:48,901 epoch 31 - iter 3/14 - loss 0.34109073 - samples/sec: 75.27 - lr: 0.000030
2021-06-21 23:43:49,311 epoch 31 - iter 4/14 - loss 0.36725817 - samples/sec: 78.17 - lr: 0.000030
2021-06-21 23:43:49,724 epoch 31 - iter 5/14 - loss 0.39843025 - samples/sec: 77.54 - lr: 0.000030
2021-06-21 23:43:50,151 epoch 31 - iter 6/14 - loss 0.39594062 - samples/sec: 74.95 - lr: 0.000030
2021-06-21 23:43:50,564 epoch 31 - iter 7/14 - loss 0.36983605 - samples/sec: 77.48 - lr: 0.000030
2021-06-21 23:43:50,987 epoch 31 - iter 8/14 - loss 0.37810540 - samples/sec: 75.77 - lr: 0.000030
2021-06-21 23:43:51,416 epoch 31 - iter 9/14 - loss 0.38022309 - samples/sec: 74.74 - lr: 0.000030
2021-06-21 23:43:51,844 epoch 31 - iter 10/14 - loss 0.39727583 - samples/sec: 74.76 - lr: 0.000030
2021-06-21 23:43:52,261 epoch 31 - iter 11/14 - loss 0.42317348 - samples/sec: 76.89 - lr: 0.000030
2021-06-21 23:43:52,680 epoch 31 - iter 12/14 - loss 0.43332224 - samples/sec: 76.36 - lr: 0.000030
2021-06-21 23:43:53,090 epoch 31 - iter 13/14 - loss 0.43160199 - samples/sec: 78.14 - lr: 0.000030
2021-06-21 23:43:53,410 epoch 31 - iter 14/14 - loss 0.42393773 - samples/sec: 100.08 - lr: 0.000030
2021-06-21 23:43:53,411 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:53,411 EPOCH 31 done: loss 0.4239 - lr 0.0000300
2021-06-21 23:43:53,887 DEV : loss 0.8848483562469482 - score 0.8344
2021-06-21 23:43:53,894 BAD EPOCHS (no improvement): 2
2021-06-21 23:43:53,894 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:54,304 epoch 32 - iter 1/14 - loss 0.26539636 - samples/sec: 78.18 - lr: 0.000030
2021-06-21 23:43:54,725 epoch 32 - iter 2/14 - loss 0.26322901 - samples/sec: 76.12 - lr: 0.000030
2021-06-21 23:43:55,126 epoch 32 - iter 3/14 - loss 0.26115572 - samples/sec: 79.82 - lr: 0.000030
2021-06-21 23:43:55,533 epoch 32 - iter 4/14 - loss 0.26219684 - samples/sec: 78.75 - lr: 0.000030
2021-06-21 23:43:55,945 epoch 32 - iter 5/14 - loss 0.28985250 - samples/sec: 77.68 - lr: 0.000030
2021-06-21 23:43:56,365 epoch 32 - iter 6/14 - loss 0.30680440 - samples/sec: 76.21 - lr: 0.000030
2021-06-21 23:43:56,786 epoch 32 - iter 7/14 - loss 0.30780206 - samples/sec: 76.18 - lr: 0.000030
2021-06-21 23:43:57,200 epoch 32 - iter 8/14 - loss 0.32087220 - samples/sec: 77.28 - lr: 0.000030
2021-06-21 23:43:57,619 epoch 32 - iter 9/14 - loss 0.33794590 - samples/sec: 76.45 - lr: 0.000030
2021-06-21 23:43:58,045 epoch 32 - iter 10/14 - loss 0.34465606 - samples/sec: 75.24 - lr: 0.000030
2021-06-21 23:43:58,465 epoch 32 - iter 11/14 - loss 0.32990154 - samples/sec: 76.27 - lr: 0.000030
2021-06-21 23:43:58,872 epoch 32 - iter 12/14 - loss 0.33247849 - samples/sec: 78.75 - lr: 0.000030
2021-06-21 23:43:59,298 epoch 32 - iter 13/14 - loss 0.33821215 - samples/sec: 75.13 - lr: 0.000030
2021-06-21 23:43:59,645 epoch 32 - iter 14/14 - loss 0.33799485 - samples/sec: 92.32 - lr: 0.000030
2021-06-21 23:43:59,646 ----------------------------------------------------------------------------------------------------
2021-06-21 23:43:59,646 EPOCH 32 done: loss 0.3380 - lr 0.0000300
2021-06-21 23:44:00,122 DEV : loss 0.8207696676254272 - score 0.8353
2021-06-21 23:44:00,129 BAD EPOCHS (no improvement): 3
2021-06-21 23:44:00,129 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:00,544 epoch 33 - iter 1/14 - loss 0.44154543 - samples/sec: 77.20 - lr: 0.000030
2021-06-21 23:44:00,950 epoch 33 - iter 2/14 - loss 0.37126514 - samples/sec: 78.92 - lr: 0.000030
2021-06-21 23:44:01,358 epoch 33 - iter 3/14 - loss 0.34723318 - samples/sec: 78.49 - lr: 0.000030
2021-06-21 23:44:01,784 epoch 33 - iter 4/14 - loss 0.33508751 - samples/sec: 75.21 - lr: 0.000030
2021-06-21 23:44:02,191 epoch 33 - iter 5/14 - loss 0.37207026 - samples/sec: 78.72 - lr: 0.000030
2021-06-21 23:44:02,610 epoch 33 - iter 6/14 - loss 0.36567991 - samples/sec: 76.42 - lr: 0.000030
2021-06-21 23:44:03,033 epoch 33 - iter 7/14 - loss 0.35064923 - samples/sec: 75.79 - lr: 0.000030
2021-06-21 23:44:03,450 epoch 33 - iter 8/14 - loss 0.36586365 - samples/sec: 76.76 - lr: 0.000030
2021-06-21 23:44:03,861 epoch 33 - iter 9/14 - loss 0.38184950 - samples/sec: 77.87 - lr: 0.000030
2021-06-21 23:44:04,273 epoch 33 - iter 10/14 - loss 0.36917719 - samples/sec: 77.85 - lr: 0.000030
2021-06-21 23:44:04,693 epoch 33 - iter 11/14 - loss 0.37337606 - samples/sec: 76.26 - lr: 0.000030
2021-06-21 23:44:05,121 epoch 33 - iter 12/14 - loss 0.37044355 - samples/sec: 74.84 - lr: 0.000030
2021-06-21 23:44:05,545 epoch 33 - iter 13/14 - loss 0.36577556 - samples/sec: 75.46 - lr: 0.000030
2021-06-21 23:44:05,886 epoch 33 - iter 14/14 - loss 0.36266064 - samples/sec: 94.00 - lr: 0.000030
2021-06-21 23:44:05,886 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:05,886 EPOCH 33 done: loss 0.3627 - lr 0.0000300
2021-06-21 23:44:06,363 DEV : loss 0.8035271167755127 - score 0.8402
2021-06-21 23:44:06,370 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:44:10,664 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:11,090 epoch 34 - iter 1/14 - loss 0.53538299 - samples/sec: 75.19 - lr: 0.000030
2021-06-21 23:44:11,521 epoch 34 - iter 2/14 - loss 0.57823884 - samples/sec: 74.36 - lr: 0.000030
2021-06-21 23:44:11,947 epoch 34 - iter 3/14 - loss 0.45311093 - samples/sec: 75.30 - lr: 0.000030
2021-06-21 23:44:12,441 epoch 34 - iter 4/14 - loss 0.42617214 - samples/sec: 64.75 - lr: 0.000030
2021-06-21 23:44:12,858 epoch 34 - iter 5/14 - loss 0.40163765 - samples/sec: 76.77 - lr: 0.000030
2021-06-21 23:44:13,268 epoch 34 - iter 6/14 - loss 0.36658108 - samples/sec: 78.24 - lr: 0.000030
2021-06-21 23:44:13,685 epoch 34 - iter 7/14 - loss 0.36527442 - samples/sec: 76.77 - lr: 0.000030
2021-06-21 23:44:14,098 epoch 34 - iter 8/14 - loss 0.34781170 - samples/sec: 77.48 - lr: 0.000030
2021-06-21 23:44:14,505 epoch 34 - iter 9/14 - loss 0.34836946 - samples/sec: 78.82 - lr: 0.000030
2021-06-21 23:44:14,910 epoch 34 - iter 10/14 - loss 0.33784755 - samples/sec: 79.11 - lr: 0.000030
2021-06-21 23:44:15,337 epoch 34 - iter 11/14 - loss 0.32809854 - samples/sec: 74.98 - lr: 0.000030
2021-06-21 23:44:15,746 epoch 34 - iter 12/14 - loss 0.33851273 - samples/sec: 78.29 - lr: 0.000030
2021-06-21 23:44:16,157 epoch 34 - iter 13/14 - loss 0.34955399 - samples/sec: 78.03 - lr: 0.000030
2021-06-21 23:44:16,496 epoch 34 - iter 14/14 - loss 0.34672935 - samples/sec: 94.38 - lr: 0.000030
2021-06-21 23:44:16,496 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:16,496 EPOCH 34 done: loss 0.3467 - lr 0.0000300
2021-06-21 23:44:16,973 DEV : loss 0.8555939197540283 - score 0.825
2021-06-21 23:44:16,980 BAD EPOCHS (no improvement): 1
2021-06-21 23:44:16,980 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:17,395 epoch 35 - iter 1/14 - loss 0.18852100 - samples/sec: 77.18 - lr: 0.000030
2021-06-21 23:44:17,813 epoch 35 - iter 2/14 - loss 0.30026598 - samples/sec: 76.76 - lr: 0.000030
2021-06-21 23:44:18,224 epoch 35 - iter 3/14 - loss 0.32019364 - samples/sec: 77.81 - lr: 0.000030
2021-06-21 23:44:18,652 epoch 35 - iter 4/14 - loss 0.35559752 - samples/sec: 74.99 - lr: 0.000030
2021-06-21 23:44:19,066 epoch 35 - iter 5/14 - loss 0.37522687 - samples/sec: 77.35 - lr: 0.000030
2021-06-21 23:44:19,490 epoch 35 - iter 6/14 - loss 0.37711958 - samples/sec: 75.50 - lr: 0.000030
2021-06-21 23:44:19,902 epoch 35 - iter 7/14 - loss 0.36600841 - samples/sec: 77.80 - lr: 0.000030
2021-06-21 23:44:20,319 epoch 35 - iter 8/14 - loss 0.36501828 - samples/sec: 76.79 - lr: 0.000030
2021-06-21 23:44:20,743 epoch 35 - iter 9/14 - loss 0.35255835 - samples/sec: 75.57 - lr: 0.000030
2021-06-21 23:44:21,161 epoch 35 - iter 10/14 - loss 0.37338405 - samples/sec: 76.56 - lr: 0.000030
2021-06-21 23:44:21,567 epoch 35 - iter 11/14 - loss 0.36544089 - samples/sec: 78.85 - lr: 0.000030
2021-06-21 23:44:21,972 epoch 35 - iter 12/14 - loss 0.37591974 - samples/sec: 79.10 - lr: 0.000030
2021-06-21 23:44:22,397 epoch 35 - iter 13/14 - loss 0.36490644 - samples/sec: 75.36 - lr: 0.000030
2021-06-21 23:44:22,739 epoch 35 - iter 14/14 - loss 0.35838230 - samples/sec: 93.69 - lr: 0.000030
2021-06-21 23:44:22,740 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:22,740 EPOCH 35 done: loss 0.3584 - lr 0.0000300
2021-06-21 23:44:23,217 DEV : loss 0.804936945438385 - score 0.8452
2021-06-21 23:44:23,224 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:44:27,516 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:27,933 epoch 36 - iter 1/14 - loss 0.27671728 - samples/sec: 76.96 - lr: 0.000030
2021-06-21 23:44:28,363 epoch 36 - iter 2/14 - loss 0.25051646 - samples/sec: 74.37 - lr: 0.000030
2021-06-21 23:44:28,774 epoch 36 - iter 3/14 - loss 0.30690443 - samples/sec: 77.92 - lr: 0.000030
2021-06-21 23:44:29,193 epoch 36 - iter 4/14 - loss 0.29620948 - samples/sec: 76.49 - lr: 0.000030
2021-06-21 23:44:29,615 epoch 36 - iter 5/14 - loss 0.30368568 - samples/sec: 75.87 - lr: 0.000030
2021-06-21 23:44:30,034 epoch 36 - iter 6/14 - loss 0.31617178 - samples/sec: 76.53 - lr: 0.000030
2021-06-21 23:44:30,465 epoch 36 - iter 7/14 - loss 0.31679356 - samples/sec: 74.31 - lr: 0.000030
2021-06-21 23:44:30,877 epoch 36 - iter 8/14 - loss 0.31844297 - samples/sec: 77.71 - lr: 0.000030
2021-06-21 23:44:31,301 epoch 36 - iter 9/14 - loss 0.33179982 - samples/sec: 75.62 - lr: 0.000030
2021-06-21 23:44:31,712 epoch 36 - iter 10/14 - loss 0.34520131 - samples/sec: 77.83 - lr: 0.000030
2021-06-21 23:44:32,123 epoch 36 - iter 11/14 - loss 0.33452421 - samples/sec: 77.89 - lr: 0.000030
2021-06-21 23:44:32,539 epoch 36 - iter 12/14 - loss 0.32931338 - samples/sec: 77.03 - lr: 0.000030
2021-06-21 23:44:32,950 epoch 36 - iter 13/14 - loss 0.32176460 - samples/sec: 78.02 - lr: 0.000030
2021-06-21 23:44:33,269 epoch 36 - iter 14/14 - loss 0.32687218 - samples/sec: 100.47 - lr: 0.000030
2021-06-21 23:44:33,269 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:33,269 EPOCH 36 done: loss 0.3269 - lr 0.0000300
2021-06-21 23:44:33,745 DEV : loss 0.7987228631973267 - score 0.8554
2021-06-21 23:44:33,753 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:44:38,043 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:38,440 epoch 37 - iter 1/14 - loss 0.28016400 - samples/sec: 80.80 - lr: 0.000030
2021-06-21 23:44:38,868 epoch 37 - iter 2/14 - loss 0.24084461 - samples/sec: 74.92 - lr: 0.000030
2021-06-21 23:44:39,290 epoch 37 - iter 3/14 - loss 0.28728032 - samples/sec: 75.87 - lr: 0.000030
2021-06-21 23:44:39,717 epoch 37 - iter 4/14 - loss 0.29523867 - samples/sec: 75.06 - lr: 0.000030
2021-06-21 23:44:40,144 epoch 37 - iter 5/14 - loss 0.30916882 - samples/sec: 75.05 - lr: 0.000030
2021-06-21 23:44:40,552 epoch 37 - iter 6/14 - loss 0.30627147 - samples/sec: 78.35 - lr: 0.000030
2021-06-21 23:44:40,963 epoch 37 - iter 7/14 - loss 0.34923589 - samples/sec: 77.98 - lr: 0.000030
2021-06-21 23:44:41,376 epoch 37 - iter 8/14 - loss 0.37167373 - samples/sec: 77.61 - lr: 0.000030
2021-06-21 23:44:41,777 epoch 37 - iter 9/14 - loss 0.38354289 - samples/sec: 79.77 - lr: 0.000030
2021-06-21 23:44:42,186 epoch 37 - iter 10/14 - loss 0.39365492 - samples/sec: 78.47 - lr: 0.000030
2021-06-21 23:44:42,607 epoch 37 - iter 11/14 - loss 0.38345465 - samples/sec: 76.00 - lr: 0.000030
2021-06-21 23:44:43,033 epoch 37 - iter 12/14 - loss 0.37604231 - samples/sec: 75.20 - lr: 0.000030
2021-06-21 23:44:43,442 epoch 37 - iter 13/14 - loss 0.36904153 - samples/sec: 78.36 - lr: 0.000030
2021-06-21 23:44:43,784 epoch 37 - iter 14/14 - loss 0.36164446 - samples/sec: 93.54 - lr: 0.000030
2021-06-21 23:44:43,785 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:43,785 EPOCH 37 done: loss 0.3616 - lr 0.0000300
2021-06-21 23:44:44,260 DEV : loss 0.783645749092102 - score 0.8488
2021-06-21 23:44:44,267 BAD EPOCHS (no improvement): 1
2021-06-21 23:44:44,268 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:44,680 epoch 38 - iter 1/14 - loss 0.34826279 - samples/sec: 77.69 - lr: 0.000030
2021-06-21 23:44:45,097 epoch 38 - iter 2/14 - loss 0.36430037 - samples/sec: 76.87 - lr: 0.000030
2021-06-21 23:44:45,509 epoch 38 - iter 3/14 - loss 0.36242399 - samples/sec: 77.74 - lr: 0.000030
2021-06-21 23:44:45,901 epoch 38 - iter 4/14 - loss 0.35625488 - samples/sec: 81.58 - lr: 0.000030
2021-06-21 23:44:46,312 epoch 38 - iter 5/14 - loss 0.32550289 - samples/sec: 77.90 - lr: 0.000030
2021-06-21 23:44:46,730 epoch 38 - iter 6/14 - loss 0.34886950 - samples/sec: 76.72 - lr: 0.000030
2021-06-21 23:44:47,147 epoch 38 - iter 7/14 - loss 0.33825422 - samples/sec: 76.86 - lr: 0.000030
2021-06-21 23:44:47,569 epoch 38 - iter 8/14 - loss 0.34577078 - samples/sec: 75.82 - lr: 0.000030
2021-06-21 23:44:47,989 epoch 38 - iter 9/14 - loss 0.33045332 - samples/sec: 76.37 - lr: 0.000030
2021-06-21 23:44:48,409 epoch 38 - iter 10/14 - loss 0.33143530 - samples/sec: 76.19 - lr: 0.000030
2021-06-21 23:44:48,833 epoch 38 - iter 11/14 - loss 0.33215603 - samples/sec: 75.61 - lr: 0.000030
2021-06-21 23:44:49,252 epoch 38 - iter 12/14 - loss 0.33740050 - samples/sec: 76.41 - lr: 0.000030
2021-06-21 23:44:49,655 epoch 38 - iter 13/14 - loss 0.33887881 - samples/sec: 79.52 - lr: 0.000030
2021-06-21 23:44:49,990 epoch 38 - iter 14/14 - loss 0.34143232 - samples/sec: 95.41 - lr: 0.000030
2021-06-21 23:44:49,991 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:49,991 EPOCH 38 done: loss 0.3414 - lr 0.0000300
2021-06-21 23:44:50,467 DEV : loss 0.7863288521766663 - score 0.8383
2021-06-21 23:44:50,474 BAD EPOCHS (no improvement): 2
2021-06-21 23:44:50,474 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:50,881 epoch 39 - iter 1/14 - loss 0.21587890 - samples/sec: 78.75 - lr: 0.000030
2021-06-21 23:44:51,298 epoch 39 - iter 2/14 - loss 0.27103969 - samples/sec: 76.80 - lr: 0.000030
2021-06-21 23:44:51,712 epoch 39 - iter 3/14 - loss 0.25687108 - samples/sec: 77.37 - lr: 0.000030
2021-06-21 23:44:52,109 epoch 39 - iter 4/14 - loss 0.26440420 - samples/sec: 80.57 - lr: 0.000030
2021-06-21 23:44:52,537 epoch 39 - iter 5/14 - loss 0.28190944 - samples/sec: 74.93 - lr: 0.000030
2021-06-21 23:44:52,957 epoch 39 - iter 6/14 - loss 0.29349591 - samples/sec: 76.25 - lr: 0.000030
2021-06-21 23:44:53,374 epoch 39 - iter 7/14 - loss 0.26994031 - samples/sec: 76.88 - lr: 0.000030
2021-06-21 23:44:53,792 epoch 39 - iter 8/14 - loss 0.28881234 - samples/sec: 76.55 - lr: 0.000030
2021-06-21 23:44:54,206 epoch 39 - iter 9/14 - loss 0.29401466 - samples/sec: 77.32 - lr: 0.000030
2021-06-21 23:44:54,630 epoch 39 - iter 10/14 - loss 0.28900633 - samples/sec: 75.65 - lr: 0.000030
2021-06-21 23:44:55,054 epoch 39 - iter 11/14 - loss 0.29161585 - samples/sec: 75.53 - lr: 0.000030
2021-06-21 23:44:55,465 epoch 39 - iter 12/14 - loss 0.28825403 - samples/sec: 77.86 - lr: 0.000030
2021-06-21 23:44:55,896 epoch 39 - iter 13/14 - loss 0.28706456 - samples/sec: 74.36 - lr: 0.000030
2021-06-21 23:44:56,225 epoch 39 - iter 14/14 - loss 0.27764727 - samples/sec: 97.50 - lr: 0.000030
2021-06-21 23:44:56,225 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:56,225 EPOCH 39 done: loss 0.2776 - lr 0.0000300
2021-06-21 23:44:56,701 DEV : loss 0.7867769598960876 - score 0.8383
2021-06-21 23:44:56,708 BAD EPOCHS (no improvement): 3
2021-06-21 23:44:56,708 ----------------------------------------------------------------------------------------------------
2021-06-21 23:44:57,131 epoch 40 - iter 1/14 - loss 0.26485705 - samples/sec: 75.61 - lr: 0.000030
2021-06-21 23:44:57,542 epoch 40 - iter 2/14 - loss 0.20445774 - samples/sec: 77.99 - lr: 0.000030
2021-06-21 23:44:58,040 epoch 40 - iter 3/14 - loss 0.24627810 - samples/sec: 64.33 - lr: 0.000030
2021-06-21 23:44:58,465 epoch 40 - iter 4/14 - loss 0.28847907 - samples/sec: 75.41 - lr: 0.000030
2021-06-21 23:44:58,885 epoch 40 - iter 5/14 - loss 0.29099453 - samples/sec: 76.16 - lr: 0.000030
2021-06-21 23:44:59,305 epoch 40 - iter 6/14 - loss 0.30065195 - samples/sec: 76.27 - lr: 0.000030
2021-06-21 23:44:59,706 epoch 40 - iter 7/14 - loss 0.29032915 - samples/sec: 79.89 - lr: 0.000030
2021-06-21 23:45:00,115 epoch 40 - iter 8/14 - loss 0.29162461 - samples/sec: 78.34 - lr: 0.000030
2021-06-21 23:45:00,537 epoch 40 - iter 9/14 - loss 0.29964836 - samples/sec: 75.91 - lr: 0.000030
2021-06-21 23:45:00,945 epoch 40 - iter 10/14 - loss 0.28302852 - samples/sec: 78.45 - lr: 0.000030
2021-06-21 23:45:01,355 epoch 40 - iter 11/14 - loss 0.30220368 - samples/sec: 78.24 - lr: 0.000030
2021-06-21 23:45:01,789 epoch 40 - iter 12/14 - loss 0.30494857 - samples/sec: 73.79 - lr: 0.000030
2021-06-21 23:45:02,211 epoch 40 - iter 13/14 - loss 0.30227467 - samples/sec: 75.92 - lr: 0.000030
2021-06-21 23:45:02,533 epoch 40 - iter 14/14 - loss 0.29416572 - samples/sec: 99.41 - lr: 0.000030
2021-06-21 23:45:02,534 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:02,534 EPOCH 40 done: loss 0.2942 - lr 0.0000300
2021-06-21 23:45:03,009 DEV : loss 0.7929957509040833 - score 0.8383
Epoch    40: reducing learning rate of group 0 to 1.5000e-05.
2021-06-21 23:45:03,016 BAD EPOCHS (no improvement): 4
2021-06-21 23:45:03,415 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:03,415 Testing using best model ...
2021-06-21 23:45:03,415 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/best-model.pt
2021-06-21 23:45:06,714 0.9057	0.7273	0.8067
2021-06-21 23:45:06,714 
Results:
- F1-score (micro) 0.8067
- F1-score (macro) 0.8067

By class:
SENT       tp: 96 - fp: 10 - fn: 36 - precision: 0.9057 - recall: 0.7273 - f1-score: 0.8067
2021-06-21 23:45:06,714 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/
2021-06-21 23:45:06,725 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis
2021-06-21 23:45:06,725 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/sent_train.txt
2021-06-21 23:45:06,726 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/sent_dev.txt
2021-06-21 23:45:06,728 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/sent_test.txt
Corpus: 1092 train + 243 dev + 249 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-21 23:45:10,295 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:10,296 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-21 23:45:10,296 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:10,296 Corpus: "Corpus: 1092 train + 243 dev + 249 test sentences"
2021-06-21 23:45:10,296 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:10,296 Parameters:
2021-06-21 23:45:10,296  - learning_rate: "3e-05"
2021-06-21 23:45:10,296  - mini_batch_size: "32"
2021-06-21 23:45:10,296  - patience: "3"
2021-06-21 23:45:10,296  - anneal_factor: "0.5"
2021-06-21 23:45:10,296  - max_epochs: "40"
2021-06-21 23:45:10,296  - shuffle: "True"
2021-06-21 23:45:10,296  - train_with_dev: "False"
2021-06-21 23:45:10,296  - batch_growth_annealing: "False"
2021-06-21 23:45:10,296 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:10,296 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis"
2021-06-21 23:45:10,296 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:10,296 Device: cuda:0
2021-06-21 23:45:10,296 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:10,296 Embeddings storage mode: cpu
2021-06-21 23:45:10,297 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:12,419 epoch 1 - iter 3/35 - loss 5.19225661 - samples/sec: 45.25 - lr: 0.000030
2021-06-21 23:45:14,569 epoch 1 - iter 6/35 - loss 4.60140689 - samples/sec: 44.66 - lr: 0.000030
2021-06-21 23:45:16,695 epoch 1 - iter 9/35 - loss 4.39516317 - samples/sec: 45.17 - lr: 0.000030
2021-06-21 23:45:18,858 epoch 1 - iter 12/35 - loss 4.33215316 - samples/sec: 44.38 - lr: 0.000030
2021-06-21 23:45:20,999 epoch 1 - iter 15/35 - loss 4.12709072 - samples/sec: 44.85 - lr: 0.000030
2021-06-21 23:45:23,113 epoch 1 - iter 18/35 - loss 3.98436509 - samples/sec: 45.42 - lr: 0.000030
2021-06-21 23:45:25,259 epoch 1 - iter 21/35 - loss 3.94019159 - samples/sec: 44.75 - lr: 0.000030
2021-06-21 23:45:27,385 epoch 1 - iter 24/35 - loss 3.80904812 - samples/sec: 45.16 - lr: 0.000030
2021-06-21 23:45:29,510 epoch 1 - iter 27/35 - loss 3.67585503 - samples/sec: 45.20 - lr: 0.000030
2021-06-21 23:45:31,669 epoch 1 - iter 30/35 - loss 3.66207587 - samples/sec: 44.47 - lr: 0.000030
2021-06-21 23:45:33,786 epoch 1 - iter 33/35 - loss 3.56423167 - samples/sec: 45.36 - lr: 0.000030
2021-06-21 23:45:34,770 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:34,770 EPOCH 1 done: loss 3.4935 - lr 0.0000300
2021-06-21 23:45:37,875 DEV : loss 2.4999263286590576 - score 0.2338
2021-06-21 23:45:37,892 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:45:38,415 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:39,788 epoch 2 - iter 3/35 - loss 2.41221571 - samples/sec: 69.92 - lr: 0.000030
2021-06-21 23:45:41,169 epoch 2 - iter 6/35 - loss 2.32390835 - samples/sec: 69.57 - lr: 0.000030
2021-06-21 23:45:42,533 epoch 2 - iter 9/35 - loss 2.17889814 - samples/sec: 70.39 - lr: 0.000030
2021-06-21 23:45:43,903 epoch 2 - iter 12/35 - loss 2.23335257 - samples/sec: 70.12 - lr: 0.000030
2021-06-21 23:45:45,288 epoch 2 - iter 15/35 - loss 2.10955777 - samples/sec: 69.34 - lr: 0.000030
2021-06-21 23:45:46,689 epoch 2 - iter 18/35 - loss 2.03662390 - samples/sec: 68.52 - lr: 0.000030
2021-06-21 23:45:48,062 epoch 2 - iter 21/35 - loss 2.01516985 - samples/sec: 69.97 - lr: 0.000030
2021-06-21 23:45:49,453 epoch 2 - iter 24/35 - loss 1.98379121 - samples/sec: 69.02 - lr: 0.000030
2021-06-21 23:45:50,804 epoch 2 - iter 27/35 - loss 1.91535634 - samples/sec: 71.08 - lr: 0.000030
2021-06-21 23:45:52,161 epoch 2 - iter 30/35 - loss 1.86796548 - samples/sec: 70.81 - lr: 0.000030
2021-06-21 23:45:53,531 epoch 2 - iter 33/35 - loss 1.84083793 - samples/sec: 70.07 - lr: 0.000030
2021-06-21 23:45:54,058 ----------------------------------------------------------------------------------------------------
2021-06-21 23:45:54,059 EPOCH 2 done: loss 1.8213 - lr 0.0000300
2021-06-21 23:45:55,288 DEV : loss 0.8710880279541016 - score 0.8514
2021-06-21 23:45:55,305 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:46:00,944 ----------------------------------------------------------------------------------------------------
2021-06-21 23:46:02,323 epoch 3 - iter 3/35 - loss 1.24768341 - samples/sec: 69.64 - lr: 0.000030
2021-06-21 23:46:03,694 epoch 3 - iter 6/35 - loss 1.28005362 - samples/sec: 70.07 - lr: 0.000030
2021-06-21 23:46:05,018 epoch 3 - iter 9/35 - loss 1.19401620 - samples/sec: 72.52 - lr: 0.000030
2021-06-21 23:46:06,395 epoch 3 - iter 12/35 - loss 1.19077680 - samples/sec: 69.76 - lr: 0.000030
2021-06-21 23:46:07,750 epoch 3 - iter 15/35 - loss 1.11348296 - samples/sec: 70.86 - lr: 0.000030
2021-06-21 23:46:09,125 epoch 3 - iter 18/35 - loss 1.10223286 - samples/sec: 69.85 - lr: 0.000030
2021-06-21 23:46:10,512 epoch 3 - iter 21/35 - loss 1.08831172 - samples/sec: 69.25 - lr: 0.000030
2021-06-21 23:46:11,889 epoch 3 - iter 24/35 - loss 1.04657240 - samples/sec: 69.75 - lr: 0.000030
2021-06-21 23:46:13,269 epoch 3 - iter 27/35 - loss 1.01769627 - samples/sec: 69.55 - lr: 0.000030
2021-06-21 23:46:14,669 epoch 3 - iter 30/35 - loss 1.01828687 - samples/sec: 68.61 - lr: 0.000030
2021-06-21 23:46:16,045 epoch 3 - iter 33/35 - loss 1.00184497 - samples/sec: 69.79 - lr: 0.000030
2021-06-21 23:46:16,610 ----------------------------------------------------------------------------------------------------
2021-06-21 23:46:16,610 EPOCH 3 done: loss 1.0224 - lr 0.0000300
2021-06-21 23:46:17,826 DEV : loss 0.46736446022987366 - score 0.9283
2021-06-21 23:46:17,842 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:46:23,504 ----------------------------------------------------------------------------------------------------
2021-06-21 23:46:24,983 epoch 4 - iter 3/35 - loss 0.94867881 - samples/sec: 64.94 - lr: 0.000030
2021-06-21 23:46:26,358 epoch 4 - iter 6/35 - loss 0.92888792 - samples/sec: 69.86 - lr: 0.000030
2021-06-21 23:46:27,754 epoch 4 - iter 9/35 - loss 0.89014210 - samples/sec: 68.79 - lr: 0.000030
2021-06-21 23:46:29,121 epoch 4 - iter 12/35 - loss 0.79348434 - samples/sec: 70.25 - lr: 0.000030
2021-06-21 23:46:30,487 epoch 4 - iter 15/35 - loss 0.76441726 - samples/sec: 70.30 - lr: 0.000030
2021-06-21 23:46:31,845 epoch 4 - iter 18/35 - loss 0.76767634 - samples/sec: 70.74 - lr: 0.000030
2021-06-21 23:46:33,204 epoch 4 - iter 21/35 - loss 0.74687158 - samples/sec: 70.62 - lr: 0.000030
2021-06-21 23:46:34,583 epoch 4 - iter 24/35 - loss 0.70382328 - samples/sec: 69.67 - lr: 0.000030
2021-06-21 23:46:35,937 epoch 4 - iter 27/35 - loss 0.69350319 - samples/sec: 70.92 - lr: 0.000030
2021-06-21 23:46:37,309 epoch 4 - iter 30/35 - loss 0.69071814 - samples/sec: 69.99 - lr: 0.000030
2021-06-21 23:46:38,635 epoch 4 - iter 33/35 - loss 0.69941080 - samples/sec: 72.43 - lr: 0.000030
2021-06-21 23:46:39,189 ----------------------------------------------------------------------------------------------------
2021-06-21 23:46:39,189 EPOCH 4 done: loss 0.7269 - lr 0.0000300
2021-06-21 23:46:40,409 DEV : loss 0.3728390634059906 - score 0.9386
2021-06-21 23:46:40,426 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:46:45,899 ----------------------------------------------------------------------------------------------------
2021-06-21 23:46:47,239 epoch 5 - iter 3/35 - loss 0.71196318 - samples/sec: 71.66 - lr: 0.000030
2021-06-21 23:46:48,619 epoch 5 - iter 6/35 - loss 0.63497185 - samples/sec: 69.59 - lr: 0.000030
2021-06-21 23:46:49,974 epoch 5 - iter 9/35 - loss 0.63217646 - samples/sec: 70.90 - lr: 0.000030
2021-06-21 23:46:51,336 epoch 5 - iter 12/35 - loss 0.56742169 - samples/sec: 70.51 - lr: 0.000030
2021-06-21 23:46:52,705 epoch 5 - iter 15/35 - loss 0.55420793 - samples/sec: 70.15 - lr: 0.000030
2021-06-21 23:46:54,071 epoch 5 - iter 18/35 - loss 0.54842911 - samples/sec: 70.27 - lr: 0.000030
2021-06-21 23:46:55,439 epoch 5 - iter 21/35 - loss 0.61184515 - samples/sec: 70.22 - lr: 0.000030
2021-06-21 23:46:56,778 epoch 5 - iter 24/35 - loss 0.60292565 - samples/sec: 71.73 - lr: 0.000030
2021-06-21 23:46:58,107 epoch 5 - iter 27/35 - loss 0.61344705 - samples/sec: 72.24 - lr: 0.000030
2021-06-21 23:46:59,474 epoch 5 - iter 30/35 - loss 0.62839616 - samples/sec: 70.30 - lr: 0.000030
2021-06-21 23:47:00,858 epoch 5 - iter 33/35 - loss 0.63967039 - samples/sec: 69.34 - lr: 0.000030
2021-06-21 23:47:01,424 ----------------------------------------------------------------------------------------------------
2021-06-21 23:47:01,425 EPOCH 5 done: loss 0.6355 - lr 0.0000300
2021-06-21 23:47:02,639 DEV : loss 0.33283066749572754 - score 0.9536
2021-06-21 23:47:02,655 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:47:08,251 ----------------------------------------------------------------------------------------------------
2021-06-21 23:47:09,611 epoch 6 - iter 3/35 - loss 0.33150216 - samples/sec: 70.64 - lr: 0.000030
2021-06-21 23:47:10,989 epoch 6 - iter 6/35 - loss 0.44337370 - samples/sec: 69.69 - lr: 0.000030
2021-06-21 23:47:12,330 epoch 6 - iter 9/35 - loss 0.43963440 - samples/sec: 71.59 - lr: 0.000030
2021-06-21 23:47:13,693 epoch 6 - iter 12/35 - loss 0.49604304 - samples/sec: 70.47 - lr: 0.000030
2021-06-21 23:47:15,064 epoch 6 - iter 15/35 - loss 0.49708685 - samples/sec: 70.07 - lr: 0.000030
2021-06-21 23:47:16,403 epoch 6 - iter 18/35 - loss 0.50163224 - samples/sec: 71.71 - lr: 0.000030
2021-06-21 23:47:17,761 epoch 6 - iter 21/35 - loss 0.51152950 - samples/sec: 70.72 - lr: 0.000030
2021-06-21 23:47:19,144 epoch 6 - iter 24/35 - loss 0.50755475 - samples/sec: 69.44 - lr: 0.000030
2021-06-21 23:47:20,499 epoch 6 - iter 27/35 - loss 0.50603518 - samples/sec: 70.88 - lr: 0.000030
2021-06-21 23:47:21,880 epoch 6 - iter 30/35 - loss 0.52905456 - samples/sec: 69.54 - lr: 0.000030
2021-06-21 23:47:23,222 epoch 6 - iter 33/35 - loss 0.51465570 - samples/sec: 71.55 - lr: 0.000030
2021-06-21 23:47:23,750 ----------------------------------------------------------------------------------------------------
2021-06-21 23:47:23,751 EPOCH 6 done: loss 0.5025 - lr 0.0000300
2021-06-21 23:47:24,966 DEV : loss 0.3060701787471771 - score 0.9513
2021-06-21 23:47:24,983 BAD EPOCHS (no improvement): 1
2021-06-21 23:47:24,983 ----------------------------------------------------------------------------------------------------
2021-06-21 23:47:26,332 epoch 7 - iter 3/35 - loss 0.39735128 - samples/sec: 71.22 - lr: 0.000030
2021-06-21 23:47:27,727 epoch 7 - iter 6/35 - loss 0.50900087 - samples/sec: 68.81 - lr: 0.000030
2021-06-21 23:47:29,090 epoch 7 - iter 9/35 - loss 0.56577627 - samples/sec: 70.46 - lr: 0.000030
2021-06-21 23:47:30,428 epoch 7 - iter 12/35 - loss 0.52321181 - samples/sec: 71.80 - lr: 0.000030
2021-06-21 23:47:31,799 epoch 7 - iter 15/35 - loss 0.53160056 - samples/sec: 70.04 - lr: 0.000030
2021-06-21 23:47:33,168 epoch 7 - iter 18/35 - loss 0.51468808 - samples/sec: 70.15 - lr: 0.000030
2021-06-21 23:47:34,534 epoch 7 - iter 21/35 - loss 0.51191161 - samples/sec: 70.32 - lr: 0.000030
2021-06-21 23:47:35,901 epoch 7 - iter 24/35 - loss 0.49213866 - samples/sec: 70.26 - lr: 0.000030
2021-06-21 23:47:37,236 epoch 7 - iter 27/35 - loss 0.47618321 - samples/sec: 71.92 - lr: 0.000030
2021-06-21 23:47:38,620 epoch 7 - iter 30/35 - loss 0.50093638 - samples/sec: 69.39 - lr: 0.000030
2021-06-21 23:47:40,015 epoch 7 - iter 33/35 - loss 0.50308003 - samples/sec: 68.85 - lr: 0.000030
2021-06-21 23:47:40,566 ----------------------------------------------------------------------------------------------------
2021-06-21 23:47:40,566 EPOCH 7 done: loss 0.5147 - lr 0.0000300
2021-06-21 23:47:41,789 DEV : loss 0.29114246368408203 - score 0.9513
2021-06-21 23:47:41,805 BAD EPOCHS (no improvement): 2
2021-06-21 23:47:41,806 ----------------------------------------------------------------------------------------------------
2021-06-21 23:47:43,169 epoch 8 - iter 3/35 - loss 0.50458123 - samples/sec: 70.42 - lr: 0.000030
2021-06-21 23:47:44,530 epoch 8 - iter 6/35 - loss 0.49643767 - samples/sec: 70.57 - lr: 0.000030
2021-06-21 23:47:45,902 epoch 8 - iter 9/35 - loss 0.46146217 - samples/sec: 69.99 - lr: 0.000030
2021-06-21 23:47:47,399 epoch 8 - iter 12/35 - loss 0.46477118 - samples/sec: 64.16 - lr: 0.000030
2021-06-21 23:47:48,781 epoch 8 - iter 15/35 - loss 0.45449869 - samples/sec: 69.51 - lr: 0.000030
2021-06-21 23:47:50,154 epoch 8 - iter 18/35 - loss 0.45509459 - samples/sec: 69.93 - lr: 0.000030
2021-06-21 23:47:51,522 epoch 8 - iter 21/35 - loss 0.44278117 - samples/sec: 70.19 - lr: 0.000030
2021-06-21 23:47:52,897 epoch 8 - iter 24/35 - loss 0.43558909 - samples/sec: 69.85 - lr: 0.000030
2021-06-21 23:47:54,235 epoch 8 - iter 27/35 - loss 0.43515630 - samples/sec: 71.80 - lr: 0.000030
2021-06-21 23:47:55,603 epoch 8 - iter 30/35 - loss 0.44821691 - samples/sec: 70.18 - lr: 0.000030
2021-06-21 23:47:56,976 epoch 8 - iter 33/35 - loss 0.44579666 - samples/sec: 69.95 - lr: 0.000030
2021-06-21 23:47:57,534 ----------------------------------------------------------------------------------------------------
2021-06-21 23:47:57,534 EPOCH 8 done: loss 0.4427 - lr 0.0000300
2021-06-21 23:47:58,757 DEV : loss 0.26511669158935547 - score 0.9511
2021-06-21 23:47:58,774 BAD EPOCHS (no improvement): 3
2021-06-21 23:47:58,775 ----------------------------------------------------------------------------------------------------
2021-06-21 23:48:00,155 epoch 9 - iter 3/35 - loss 0.43248864 - samples/sec: 69.56 - lr: 0.000030
2021-06-21 23:48:01,511 epoch 9 - iter 6/35 - loss 0.43979995 - samples/sec: 70.85 - lr: 0.000030
2021-06-21 23:48:02,876 epoch 9 - iter 9/35 - loss 0.41770096 - samples/sec: 70.32 - lr: 0.000030
2021-06-21 23:48:04,251 epoch 9 - iter 12/35 - loss 0.47027674 - samples/sec: 69.87 - lr: 0.000030
2021-06-21 23:48:05,615 epoch 9 - iter 15/35 - loss 0.41981356 - samples/sec: 70.43 - lr: 0.000030
2021-06-21 23:48:06,983 epoch 9 - iter 18/35 - loss 0.40679837 - samples/sec: 70.17 - lr: 0.000030
2021-06-21 23:48:08,359 epoch 9 - iter 21/35 - loss 0.45932344 - samples/sec: 69.79 - lr: 0.000030
2021-06-21 23:48:09,716 epoch 9 - iter 24/35 - loss 0.43753011 - samples/sec: 70.80 - lr: 0.000030
2021-06-21 23:48:11,099 epoch 9 - iter 27/35 - loss 0.43740913 - samples/sec: 69.40 - lr: 0.000030
2021-06-21 23:48:12,458 epoch 9 - iter 30/35 - loss 0.43719468 - samples/sec: 70.68 - lr: 0.000030
2021-06-21 23:48:13,805 epoch 9 - iter 33/35 - loss 0.42812832 - samples/sec: 71.30 - lr: 0.000030
2021-06-21 23:48:14,354 ----------------------------------------------------------------------------------------------------
2021-06-21 23:48:14,354 EPOCH 9 done: loss 0.4226 - lr 0.0000300
2021-06-21 23:48:15,578 DEV : loss 0.2572321891784668 - score 0.9558
2021-06-21 23:48:15,595 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:48:21,058 ----------------------------------------------------------------------------------------------------
2021-06-21 23:48:22,415 epoch 10 - iter 3/35 - loss 0.48402214 - samples/sec: 70.78 - lr: 0.000030
2021-06-21 23:48:23,772 epoch 10 - iter 6/35 - loss 0.42560780 - samples/sec: 70.76 - lr: 0.000030
2021-06-21 23:48:25,125 epoch 10 - iter 9/35 - loss 0.41227789 - samples/sec: 71.00 - lr: 0.000030
2021-06-21 23:48:26,488 epoch 10 - iter 12/35 - loss 0.39960833 - samples/sec: 70.44 - lr: 0.000030
2021-06-21 23:48:27,868 epoch 10 - iter 15/35 - loss 0.38203714 - samples/sec: 69.58 - lr: 0.000030
2021-06-21 23:48:29,246 epoch 10 - iter 18/35 - loss 0.40828691 - samples/sec: 69.71 - lr: 0.000030
2021-06-21 23:48:30,642 epoch 10 - iter 21/35 - loss 0.39086019 - samples/sec: 68.81 - lr: 0.000030
2021-06-21 23:48:32,022 epoch 10 - iter 24/35 - loss 0.38793517 - samples/sec: 69.55 - lr: 0.000030
2021-06-21 23:48:33,391 epoch 10 - iter 27/35 - loss 0.39227995 - samples/sec: 70.19 - lr: 0.000030
2021-06-21 23:48:34,761 epoch 10 - iter 30/35 - loss 0.39643947 - samples/sec: 70.07 - lr: 0.000030
2021-06-21 23:48:36,115 epoch 10 - iter 33/35 - loss 0.39325182 - samples/sec: 70.92 - lr: 0.000030
2021-06-21 23:48:36,670 ----------------------------------------------------------------------------------------------------
2021-06-21 23:48:36,671 EPOCH 10 done: loss 0.3817 - lr 0.0000300
2021-06-21 23:48:37,893 DEV : loss 0.24104465544223785 - score 0.9584
2021-06-21 23:48:37,910 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:48:43,267 ----------------------------------------------------------------------------------------------------
2021-06-21 23:48:44,656 epoch 11 - iter 3/35 - loss 0.22187654 - samples/sec: 69.18 - lr: 0.000030
2021-06-21 23:48:46,002 epoch 11 - iter 6/35 - loss 0.32476677 - samples/sec: 71.35 - lr: 0.000030
2021-06-21 23:48:47,358 epoch 11 - iter 9/35 - loss 0.35819002 - samples/sec: 70.83 - lr: 0.000030
2021-06-21 23:48:48,710 epoch 11 - iter 12/35 - loss 0.34958619 - samples/sec: 71.00 - lr: 0.000030
2021-06-21 23:48:50,084 epoch 11 - iter 15/35 - loss 0.39409760 - samples/sec: 69.91 - lr: 0.000030
2021-06-21 23:48:51,464 epoch 11 - iter 18/35 - loss 0.35628261 - samples/sec: 69.61 - lr: 0.000030
2021-06-21 23:48:52,823 epoch 11 - iter 21/35 - loss 0.35785299 - samples/sec: 70.62 - lr: 0.000030
2021-06-21 23:48:54,201 epoch 11 - iter 24/35 - loss 0.37331564 - samples/sec: 69.69 - lr: 0.000030
2021-06-21 23:48:55,574 epoch 11 - iter 27/35 - loss 0.37188752 - samples/sec: 69.95 - lr: 0.000030
2021-06-21 23:48:56,956 epoch 11 - iter 30/35 - loss 0.37015635 - samples/sec: 69.49 - lr: 0.000030
2021-06-21 23:48:58,326 epoch 11 - iter 33/35 - loss 0.37101352 - samples/sec: 70.09 - lr: 0.000030
2021-06-21 23:48:58,887 ----------------------------------------------------------------------------------------------------
2021-06-21 23:48:58,887 EPOCH 11 done: loss 0.3653 - lr 0.0000300
2021-06-21 23:49:00,107 DEV : loss 0.22665634751319885 - score 0.9584
2021-06-21 23:49:00,124 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:49:05,595 ----------------------------------------------------------------------------------------------------
2021-06-21 23:49:06,953 epoch 12 - iter 3/35 - loss 0.26572673 - samples/sec: 70.76 - lr: 0.000030
2021-06-21 23:49:08,279 epoch 12 - iter 6/35 - loss 0.27103298 - samples/sec: 72.42 - lr: 0.000030
2021-06-21 23:49:09,638 epoch 12 - iter 9/35 - loss 0.27695158 - samples/sec: 70.63 - lr: 0.000030
2021-06-21 23:49:11,006 epoch 12 - iter 12/35 - loss 0.30997303 - samples/sec: 70.19 - lr: 0.000030
2021-06-21 23:49:12,365 epoch 12 - iter 15/35 - loss 0.30957958 - samples/sec: 70.70 - lr: 0.000030
2021-06-21 23:49:13,748 epoch 12 - iter 18/35 - loss 0.29212861 - samples/sec: 69.44 - lr: 0.000030
2021-06-21 23:49:15,129 epoch 12 - iter 21/35 - loss 0.28612094 - samples/sec: 69.55 - lr: 0.000030
2021-06-21 23:49:16,496 epoch 12 - iter 24/35 - loss 0.29139470 - samples/sec: 70.24 - lr: 0.000030
2021-06-21 23:49:17,847 epoch 12 - iter 27/35 - loss 0.29470763 - samples/sec: 71.10 - lr: 0.000030
2021-06-21 23:49:19,226 epoch 12 - iter 30/35 - loss 0.30342236 - samples/sec: 69.63 - lr: 0.000030
2021-06-21 23:49:20,625 epoch 12 - iter 33/35 - loss 0.31101777 - samples/sec: 68.66 - lr: 0.000030
2021-06-21 23:49:21,191 ----------------------------------------------------------------------------------------------------
2021-06-21 23:49:21,191 EPOCH 12 done: loss 0.3056 - lr 0.0000300
2021-06-21 23:49:22,546 DEV : loss 0.2119680494070053 - score 0.9605
2021-06-21 23:49:22,563 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:49:28,233 ----------------------------------------------------------------------------------------------------
2021-06-21 23:49:29,591 epoch 13 - iter 3/35 - loss 0.18918661 - samples/sec: 70.72 - lr: 0.000030
2021-06-21 23:49:30,941 epoch 13 - iter 6/35 - loss 0.21264271 - samples/sec: 71.15 - lr: 0.000030
2021-06-21 23:49:32,305 epoch 13 - iter 9/35 - loss 0.18678622 - samples/sec: 70.41 - lr: 0.000030
2021-06-21 23:49:33,677 epoch 13 - iter 12/35 - loss 0.22413884 - samples/sec: 70.03 - lr: 0.000030
2021-06-21 23:49:35,061 epoch 13 - iter 15/35 - loss 0.26789550 - samples/sec: 69.38 - lr: 0.000030
2021-06-21 23:49:36,431 epoch 13 - iter 18/35 - loss 0.28444899 - samples/sec: 70.10 - lr: 0.000030
2021-06-21 23:49:37,795 epoch 13 - iter 21/35 - loss 0.28836820 - samples/sec: 70.41 - lr: 0.000030
2021-06-21 23:49:39,158 epoch 13 - iter 24/35 - loss 0.28726690 - samples/sec: 70.44 - lr: 0.000030
2021-06-21 23:49:40,536 epoch 13 - iter 27/35 - loss 0.27866900 - samples/sec: 69.72 - lr: 0.000030
2021-06-21 23:49:41,923 epoch 13 - iter 30/35 - loss 0.27296522 - samples/sec: 69.23 - lr: 0.000030
2021-06-21 23:49:43,289 epoch 13 - iter 33/35 - loss 0.27451915 - samples/sec: 70.27 - lr: 0.000030
2021-06-21 23:49:43,840 ----------------------------------------------------------------------------------------------------
2021-06-21 23:49:43,840 EPOCH 13 done: loss 0.2728 - lr 0.0000300
2021-06-21 23:49:45,063 DEV : loss 0.20693139731884003 - score 0.9605
2021-06-21 23:49:45,080 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:49:50,670 ----------------------------------------------------------------------------------------------------
2021-06-21 23:49:52,033 epoch 14 - iter 3/35 - loss 0.28965310 - samples/sec: 70.49 - lr: 0.000030
2021-06-21 23:49:53,405 epoch 14 - iter 6/35 - loss 0.27866660 - samples/sec: 70.02 - lr: 0.000030
2021-06-21 23:49:54,778 epoch 14 - iter 9/35 - loss 0.28242384 - samples/sec: 69.94 - lr: 0.000030
2021-06-21 23:49:56,133 epoch 14 - iter 12/35 - loss 0.31311862 - samples/sec: 70.89 - lr: 0.000030
2021-06-21 23:49:57,510 epoch 14 - iter 15/35 - loss 0.30011588 - samples/sec: 69.72 - lr: 0.000030
2021-06-21 23:49:58,879 epoch 14 - iter 18/35 - loss 0.28463526 - samples/sec: 70.17 - lr: 0.000030
2021-06-21 23:50:00,245 epoch 14 - iter 21/35 - loss 0.28725413 - samples/sec: 70.26 - lr: 0.000030
2021-06-21 23:50:01,610 epoch 14 - iter 24/35 - loss 0.26948786 - samples/sec: 70.37 - lr: 0.000030
2021-06-21 23:50:02,993 epoch 14 - iter 27/35 - loss 0.26798925 - samples/sec: 69.44 - lr: 0.000030
2021-06-21 23:50:04,354 epoch 14 - iter 30/35 - loss 0.26930486 - samples/sec: 70.60 - lr: 0.000030
2021-06-21 23:50:05,716 epoch 14 - iter 33/35 - loss 0.27326963 - samples/sec: 70.51 - lr: 0.000030
2021-06-21 23:50:06,262 ----------------------------------------------------------------------------------------------------
2021-06-21 23:50:06,262 EPOCH 14 done: loss 0.2835 - lr 0.0000300
2021-06-21 23:50:07,483 DEV : loss 0.19830222427845 - score 0.9646
2021-06-21 23:50:07,500 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:50:12,976 ----------------------------------------------------------------------------------------------------
2021-06-21 23:50:14,326 epoch 15 - iter 3/35 - loss 0.18259599 - samples/sec: 71.11 - lr: 0.000030
2021-06-21 23:50:15,696 epoch 15 - iter 6/35 - loss 0.24608718 - samples/sec: 70.11 - lr: 0.000030
2021-06-21 23:50:17,041 epoch 15 - iter 9/35 - loss 0.27662580 - samples/sec: 71.40 - lr: 0.000030
2021-06-21 23:50:18,393 epoch 15 - iter 12/35 - loss 0.27247239 - samples/sec: 71.04 - lr: 0.000030
2021-06-21 23:50:19,765 epoch 15 - iter 15/35 - loss 0.25361133 - samples/sec: 70.02 - lr: 0.000030
2021-06-21 23:50:21,107 epoch 15 - iter 18/35 - loss 0.27430296 - samples/sec: 71.53 - lr: 0.000030
2021-06-21 23:50:22,489 epoch 15 - iter 21/35 - loss 0.25651838 - samples/sec: 69.51 - lr: 0.000030
2021-06-21 23:50:23,854 epoch 15 - iter 24/35 - loss 0.26538386 - samples/sec: 70.34 - lr: 0.000030
2021-06-21 23:50:25,229 epoch 15 - iter 27/35 - loss 0.26964515 - samples/sec: 69.84 - lr: 0.000030
2021-06-21 23:50:26,618 epoch 15 - iter 30/35 - loss 0.26397234 - samples/sec: 69.16 - lr: 0.000030
2021-06-21 23:50:27,983 epoch 15 - iter 33/35 - loss 0.26233820 - samples/sec: 70.32 - lr: 0.000030
2021-06-21 23:50:28,539 ----------------------------------------------------------------------------------------------------
2021-06-21 23:50:28,539 EPOCH 15 done: loss 0.2584 - lr 0.0000300
2021-06-21 23:50:29,755 DEV : loss 0.18936166167259216 - score 0.9623
2021-06-21 23:50:29,772 BAD EPOCHS (no improvement): 1
2021-06-21 23:50:29,772 ----------------------------------------------------------------------------------------------------
2021-06-21 23:50:31,106 epoch 16 - iter 3/35 - loss 0.13075266 - samples/sec: 72.01 - lr: 0.000030
2021-06-21 23:50:32,481 epoch 16 - iter 6/35 - loss 0.22173811 - samples/sec: 69.82 - lr: 0.000030
2021-06-21 23:50:33,854 epoch 16 - iter 9/35 - loss 0.22120366 - samples/sec: 69.94 - lr: 0.000030
2021-06-21 23:50:35,255 epoch 16 - iter 12/35 - loss 0.22113678 - samples/sec: 68.59 - lr: 0.000030
2021-06-21 23:50:36,633 epoch 16 - iter 15/35 - loss 0.24357635 - samples/sec: 69.66 - lr: 0.000030
2021-06-21 23:50:37,986 epoch 16 - iter 18/35 - loss 0.23089197 - samples/sec: 70.97 - lr: 0.000030
2021-06-21 23:50:39,355 epoch 16 - iter 21/35 - loss 0.22584366 - samples/sec: 70.16 - lr: 0.000030
2021-06-21 23:50:40,746 epoch 16 - iter 24/35 - loss 0.22654794 - samples/sec: 69.03 - lr: 0.000030
2021-06-21 23:50:42,101 epoch 16 - iter 27/35 - loss 0.23279132 - samples/sec: 70.88 - lr: 0.000030
2021-06-21 23:50:43,467 epoch 16 - iter 30/35 - loss 0.22749406 - samples/sec: 70.30 - lr: 0.000030
2021-06-21 23:50:44,817 epoch 16 - iter 33/35 - loss 0.21589012 - samples/sec: 71.14 - lr: 0.000030
2021-06-21 23:50:45,373 ----------------------------------------------------------------------------------------------------
2021-06-21 23:50:45,374 EPOCH 16 done: loss 0.2105 - lr 0.0000300
2021-06-21 23:50:46,726 DEV : loss 0.19072195887565613 - score 0.9644
2021-06-21 23:50:46,743 BAD EPOCHS (no improvement): 2
2021-06-21 23:50:46,743 ----------------------------------------------------------------------------------------------------
2021-06-21 23:50:48,110 epoch 17 - iter 3/35 - loss 0.20127106 - samples/sec: 70.28 - lr: 0.000030
2021-06-21 23:50:49,452 epoch 17 - iter 6/35 - loss 0.19503449 - samples/sec: 71.56 - lr: 0.000030
2021-06-21 23:50:50,828 epoch 17 - iter 9/35 - loss 0.20974701 - samples/sec: 69.76 - lr: 0.000030
2021-06-21 23:50:52,206 epoch 17 - iter 12/35 - loss 0.20141839 - samples/sec: 69.70 - lr: 0.000030
2021-06-21 23:50:53,573 epoch 17 - iter 15/35 - loss 0.20015293 - samples/sec: 70.27 - lr: 0.000030
2021-06-21 23:50:54,938 epoch 17 - iter 18/35 - loss 0.20935344 - samples/sec: 70.35 - lr: 0.000030
2021-06-21 23:50:56,299 epoch 17 - iter 21/35 - loss 0.21188093 - samples/sec: 70.58 - lr: 0.000030
2021-06-21 23:50:57,681 epoch 17 - iter 24/35 - loss 0.20919473 - samples/sec: 69.45 - lr: 0.000030
2021-06-21 23:50:59,064 epoch 17 - iter 27/35 - loss 0.22014715 - samples/sec: 69.45 - lr: 0.000030
2021-06-21 23:51:00,427 epoch 17 - iter 30/35 - loss 0.21405623 - samples/sec: 70.47 - lr: 0.000030
2021-06-21 23:51:01,797 epoch 17 - iter 33/35 - loss 0.21733529 - samples/sec: 70.12 - lr: 0.000030
2021-06-21 23:51:02,355 ----------------------------------------------------------------------------------------------------
2021-06-21 23:51:02,355 EPOCH 17 done: loss 0.2589 - lr 0.0000300
2021-06-21 23:51:03,575 DEV : loss 0.18188142776489258 - score 0.9621
2021-06-21 23:51:03,592 BAD EPOCHS (no improvement): 3
2021-06-21 23:51:03,593 ----------------------------------------------------------------------------------------------------
2021-06-21 23:51:04,946 epoch 18 - iter 3/35 - loss 0.30414581 - samples/sec: 70.97 - lr: 0.000030
2021-06-21 23:51:06,322 epoch 18 - iter 6/35 - loss 0.27840385 - samples/sec: 69.76 - lr: 0.000030
2021-06-21 23:51:07,684 epoch 18 - iter 9/35 - loss 0.25425236 - samples/sec: 70.56 - lr: 0.000030
2021-06-21 23:51:09,037 epoch 18 - iter 12/35 - loss 0.24307441 - samples/sec: 70.96 - lr: 0.000030
2021-06-21 23:51:10,414 epoch 18 - iter 15/35 - loss 0.24184608 - samples/sec: 69.75 - lr: 0.000030
2021-06-21 23:51:11,813 epoch 18 - iter 18/35 - loss 0.23967438 - samples/sec: 68.60 - lr: 0.000030
2021-06-21 23:51:13,161 epoch 18 - iter 21/35 - loss 0.23576262 - samples/sec: 71.24 - lr: 0.000030
2021-06-21 23:51:14,518 epoch 18 - iter 24/35 - loss 0.22264002 - samples/sec: 70.80 - lr: 0.000030
2021-06-21 23:51:15,884 epoch 18 - iter 27/35 - loss 0.22075539 - samples/sec: 70.31 - lr: 0.000030
2021-06-21 23:51:17,280 epoch 18 - iter 30/35 - loss 0.20895204 - samples/sec: 68.77 - lr: 0.000030
2021-06-21 23:51:18,664 epoch 18 - iter 33/35 - loss 0.20581362 - samples/sec: 69.38 - lr: 0.000030
2021-06-21 23:51:19,215 ----------------------------------------------------------------------------------------------------
2021-06-21 23:51:19,215 EPOCH 18 done: loss 0.2041 - lr 0.0000300
2021-06-21 23:51:20,434 DEV : loss 0.17553871870040894 - score 0.9644
Epoch    18: reducing learning rate of group 0 to 1.5000e-05.
2021-06-21 23:51:20,451 BAD EPOCHS (no improvement): 4
2021-06-21 23:51:20,451 ----------------------------------------------------------------------------------------------------
2021-06-21 23:51:21,805 epoch 19 - iter 3/35 - loss 0.13761571 - samples/sec: 70.94 - lr: 0.000015
2021-06-21 23:51:23,167 epoch 19 - iter 6/35 - loss 0.22291768 - samples/sec: 70.50 - lr: 0.000015
2021-06-21 23:51:24,551 epoch 19 - iter 9/35 - loss 0.20511025 - samples/sec: 69.40 - lr: 0.000015
2021-06-21 23:51:25,921 epoch 19 - iter 12/35 - loss 0.24550742 - samples/sec: 70.09 - lr: 0.000015
2021-06-21 23:51:27,234 epoch 19 - iter 15/35 - loss 0.24505214 - samples/sec: 73.16 - lr: 0.000015
2021-06-21 23:51:28,580 epoch 19 - iter 18/35 - loss 0.24032095 - samples/sec: 71.36 - lr: 0.000015
2021-06-21 23:51:29,954 epoch 19 - iter 21/35 - loss 0.22866439 - samples/sec: 69.89 - lr: 0.000015
2021-06-21 23:51:31,331 epoch 19 - iter 24/35 - loss 0.21853456 - samples/sec: 69.71 - lr: 0.000015
2021-06-21 23:51:32,710 epoch 19 - iter 27/35 - loss 0.21048852 - samples/sec: 69.66 - lr: 0.000015
2021-06-21 23:51:34,078 epoch 19 - iter 30/35 - loss 0.21073067 - samples/sec: 70.17 - lr: 0.000015
2021-06-21 23:51:35,461 epoch 19 - iter 33/35 - loss 0.20602581 - samples/sec: 69.48 - lr: 0.000015
2021-06-21 23:51:36,021 ----------------------------------------------------------------------------------------------------
2021-06-21 23:51:36,021 EPOCH 19 done: loss 0.2048 - lr 0.0000150
2021-06-21 23:51:37,244 DEV : loss 0.17738229036331177 - score 0.9646
2021-06-21 23:51:37,261 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:51:42,707 ----------------------------------------------------------------------------------------------------
2021-06-21 23:51:44,067 epoch 20 - iter 3/35 - loss 0.18420850 - samples/sec: 70.67 - lr: 0.000015
2021-06-21 23:51:45,444 epoch 20 - iter 6/35 - loss 0.19857782 - samples/sec: 69.72 - lr: 0.000015
2021-06-21 23:51:46,811 epoch 20 - iter 9/35 - loss 0.19348511 - samples/sec: 70.25 - lr: 0.000015
2021-06-21 23:51:48,192 epoch 20 - iter 12/35 - loss 0.17437539 - samples/sec: 69.53 - lr: 0.000015
2021-06-21 23:51:49,573 epoch 20 - iter 15/35 - loss 0.17396902 - samples/sec: 69.55 - lr: 0.000015
2021-06-21 23:51:50,947 epoch 20 - iter 18/35 - loss 0.16573182 - samples/sec: 69.89 - lr: 0.000015
2021-06-21 23:51:52,318 epoch 20 - iter 21/35 - loss 0.16492530 - samples/sec: 70.05 - lr: 0.000015
2021-06-21 23:51:53,698 epoch 20 - iter 24/35 - loss 0.16676958 - samples/sec: 69.60 - lr: 0.000015
2021-06-21 23:51:55,076 epoch 20 - iter 27/35 - loss 0.16757797 - samples/sec: 69.70 - lr: 0.000015
2021-06-21 23:51:56,418 epoch 20 - iter 30/35 - loss 0.16349460 - samples/sec: 71.54 - lr: 0.000015
2021-06-21 23:51:57,788 epoch 20 - iter 33/35 - loss 0.16881565 - samples/sec: 70.11 - lr: 0.000015
2021-06-21 23:51:58,352 ----------------------------------------------------------------------------------------------------
2021-06-21 23:51:58,353 EPOCH 20 done: loss 0.1634 - lr 0.0000150
2021-06-21 23:51:59,704 DEV : loss 0.17851926386356354 - score 0.9644
2021-06-21 23:51:59,721 BAD EPOCHS (no improvement): 1
2021-06-21 23:51:59,721 ----------------------------------------------------------------------------------------------------
2021-06-21 23:52:01,075 epoch 21 - iter 3/35 - loss 0.17587497 - samples/sec: 70.94 - lr: 0.000015
2021-06-21 23:52:02,434 epoch 21 - iter 6/35 - loss 0.19988805 - samples/sec: 70.70 - lr: 0.000015
2021-06-21 23:52:03,774 epoch 21 - iter 9/35 - loss 0.16856957 - samples/sec: 71.62 - lr: 0.000015
2021-06-21 23:52:05,158 epoch 21 - iter 12/35 - loss 0.17191587 - samples/sec: 69.41 - lr: 0.000015
2021-06-21 23:52:06,546 epoch 21 - iter 15/35 - loss 0.18266216 - samples/sec: 69.17 - lr: 0.000015
2021-06-21 23:52:07,928 epoch 21 - iter 18/35 - loss 0.17402759 - samples/sec: 69.51 - lr: 0.000015
2021-06-21 23:52:09,301 epoch 21 - iter 21/35 - loss 0.16489949 - samples/sec: 69.94 - lr: 0.000015
2021-06-21 23:52:10,662 epoch 21 - iter 24/35 - loss 0.15972056 - samples/sec: 70.57 - lr: 0.000015
2021-06-21 23:52:12,050 epoch 21 - iter 27/35 - loss 0.16366032 - samples/sec: 69.17 - lr: 0.000015
2021-06-21 23:52:13,434 epoch 21 - iter 30/35 - loss 0.16404195 - samples/sec: 69.40 - lr: 0.000015
2021-06-21 23:52:14,827 epoch 21 - iter 33/35 - loss 0.17120025 - samples/sec: 68.97 - lr: 0.000015
2021-06-21 23:52:15,382 ----------------------------------------------------------------------------------------------------
2021-06-21 23:52:15,382 EPOCH 21 done: loss 0.1670 - lr 0.0000150
2021-06-21 23:52:16,606 DEV : loss 0.1804816722869873 - score 0.9643
2021-06-21 23:52:16,623 BAD EPOCHS (no improvement): 2
2021-06-21 23:52:16,624 ----------------------------------------------------------------------------------------------------
2021-06-21 23:52:17,995 epoch 22 - iter 3/35 - loss 0.08277800 - samples/sec: 70.03 - lr: 0.000015
2021-06-21 23:52:19,389 epoch 22 - iter 6/35 - loss 0.12086865 - samples/sec: 68.88 - lr: 0.000015
2021-06-21 23:52:20,750 epoch 22 - iter 9/35 - loss 0.11775628 - samples/sec: 70.58 - lr: 0.000015
2021-06-21 23:52:22,127 epoch 22 - iter 12/35 - loss 0.12965189 - samples/sec: 69.76 - lr: 0.000015
2021-06-21 23:52:23,485 epoch 22 - iter 15/35 - loss 0.13977997 - samples/sec: 70.68 - lr: 0.000015
2021-06-21 23:52:24,874 epoch 22 - iter 18/35 - loss 0.14415274 - samples/sec: 69.16 - lr: 0.000015
2021-06-21 23:52:26,261 epoch 22 - iter 21/35 - loss 0.14948340 - samples/sec: 69.27 - lr: 0.000015
2021-06-21 23:52:27,644 epoch 22 - iter 24/35 - loss 0.17162414 - samples/sec: 69.41 - lr: 0.000015
2021-06-21 23:52:29,000 epoch 22 - iter 27/35 - loss 0.17347360 - samples/sec: 70.82 - lr: 0.000015
2021-06-21 23:52:30,362 epoch 22 - iter 30/35 - loss 0.17494325 - samples/sec: 70.51 - lr: 0.000015
2021-06-21 23:52:31,741 epoch 22 - iter 33/35 - loss 0.17728759 - samples/sec: 69.68 - lr: 0.000015
2021-06-21 23:52:32,276 ----------------------------------------------------------------------------------------------------
2021-06-21 23:52:32,276 EPOCH 22 done: loss 0.1731 - lr 0.0000150
2021-06-21 23:52:33,498 DEV : loss 0.1811070293188095 - score 0.9667
2021-06-21 23:52:33,515 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:52:38,852 ----------------------------------------------------------------------------------------------------
2021-06-21 23:52:40,221 epoch 23 - iter 3/35 - loss 0.09812562 - samples/sec: 70.20 - lr: 0.000015
2021-06-21 23:52:41,605 epoch 23 - iter 6/35 - loss 0.10764177 - samples/sec: 69.39 - lr: 0.000015
2021-06-21 23:52:42,956 epoch 23 - iter 9/35 - loss 0.11312246 - samples/sec: 71.09 - lr: 0.000015
2021-06-21 23:52:44,317 epoch 23 - iter 12/35 - loss 0.14117636 - samples/sec: 70.52 - lr: 0.000015
2021-06-21 23:52:45,677 epoch 23 - iter 15/35 - loss 0.12516852 - samples/sec: 70.61 - lr: 0.000015
2021-06-21 23:52:47,053 epoch 23 - iter 18/35 - loss 0.13525464 - samples/sec: 69.84 - lr: 0.000015
2021-06-21 23:52:48,444 epoch 23 - iter 21/35 - loss 0.13139675 - samples/sec: 69.00 - lr: 0.000015
2021-06-21 23:52:49,802 epoch 23 - iter 24/35 - loss 0.13529528 - samples/sec: 70.75 - lr: 0.000015
2021-06-21 23:52:51,189 epoch 23 - iter 27/35 - loss 0.14418995 - samples/sec: 69.22 - lr: 0.000015
2021-06-21 23:52:52,576 epoch 23 - iter 30/35 - loss 0.14624225 - samples/sec: 69.24 - lr: 0.000015
2021-06-21 23:52:53,951 epoch 23 - iter 33/35 - loss 0.14172061 - samples/sec: 69.84 - lr: 0.000015
2021-06-21 23:52:54,514 ----------------------------------------------------------------------------------------------------
2021-06-21 23:52:54,514 EPOCH 23 done: loss 0.1360 - lr 0.0000150
2021-06-21 23:52:55,735 DEV : loss 0.18253648281097412 - score 0.9643
2021-06-21 23:52:55,752 BAD EPOCHS (no improvement): 1
2021-06-21 23:52:55,752 ----------------------------------------------------------------------------------------------------
2021-06-21 23:52:57,114 epoch 24 - iter 3/35 - loss 0.14721765 - samples/sec: 70.52 - lr: 0.000015
2021-06-21 23:52:58,489 epoch 24 - iter 6/35 - loss 0.13946543 - samples/sec: 69.85 - lr: 0.000015
2021-06-21 23:52:59,873 epoch 24 - iter 9/35 - loss 0.12309974 - samples/sec: 69.38 - lr: 0.000015
2021-06-21 23:53:01,238 epoch 24 - iter 12/35 - loss 0.13737863 - samples/sec: 70.40 - lr: 0.000015
2021-06-21 23:53:02,605 epoch 24 - iter 15/35 - loss 0.14052196 - samples/sec: 70.22 - lr: 0.000015
2021-06-21 23:53:03,974 epoch 24 - iter 18/35 - loss 0.14291691 - samples/sec: 70.15 - lr: 0.000015
2021-06-21 23:53:05,355 epoch 24 - iter 21/35 - loss 0.13442442 - samples/sec: 69.56 - lr: 0.000015
2021-06-21 23:53:06,707 epoch 24 - iter 24/35 - loss 0.13157933 - samples/sec: 71.00 - lr: 0.000015
2021-06-21 23:53:08,086 epoch 24 - iter 27/35 - loss 0.12757273 - samples/sec: 69.68 - lr: 0.000015
2021-06-21 23:53:09,473 epoch 24 - iter 30/35 - loss 0.13279899 - samples/sec: 69.23 - lr: 0.000015
2021-06-21 23:53:10,842 epoch 24 - iter 33/35 - loss 0.13142145 - samples/sec: 70.14 - lr: 0.000015
2021-06-21 23:53:11,391 ----------------------------------------------------------------------------------------------------
2021-06-21 23:53:11,391 EPOCH 24 done: loss 0.1321 - lr 0.0000150
2021-06-21 23:53:12,743 DEV : loss 0.18106262385845184 - score 0.9643
2021-06-21 23:53:12,760 BAD EPOCHS (no improvement): 2
2021-06-21 23:53:12,760 ----------------------------------------------------------------------------------------------------
2021-06-21 23:53:14,119 epoch 25 - iter 3/35 - loss 0.15833900 - samples/sec: 70.66 - lr: 0.000015
2021-06-21 23:53:15,493 epoch 25 - iter 6/35 - loss 0.16052998 - samples/sec: 69.92 - lr: 0.000015
2021-06-21 23:53:16,860 epoch 25 - iter 9/35 - loss 0.16254300 - samples/sec: 70.24 - lr: 0.000015
2021-06-21 23:53:18,237 epoch 25 - iter 12/35 - loss 0.14978048 - samples/sec: 69.76 - lr: 0.000015
2021-06-21 23:53:19,605 epoch 25 - iter 15/35 - loss 0.13907714 - samples/sec: 70.16 - lr: 0.000015
2021-06-21 23:53:20,976 epoch 25 - iter 18/35 - loss 0.13239060 - samples/sec: 70.05 - lr: 0.000015
2021-06-21 23:53:22,348 epoch 25 - iter 21/35 - loss 0.12447580 - samples/sec: 70.00 - lr: 0.000015
2021-06-21 23:53:23,716 epoch 25 - iter 24/35 - loss 0.12540952 - samples/sec: 70.21 - lr: 0.000015
2021-06-21 23:53:25,083 epoch 25 - iter 27/35 - loss 0.12543590 - samples/sec: 70.25 - lr: 0.000015
2021-06-21 23:53:26,465 epoch 25 - iter 30/35 - loss 0.12721706 - samples/sec: 69.52 - lr: 0.000015
2021-06-21 23:53:27,842 epoch 25 - iter 33/35 - loss 0.12873941 - samples/sec: 69.72 - lr: 0.000015
2021-06-21 23:53:28,393 ----------------------------------------------------------------------------------------------------
2021-06-21 23:53:28,393 EPOCH 25 done: loss 0.1264 - lr 0.0000150
2021-06-21 23:53:29,611 DEV : loss 0.18132652342319489 - score 0.9643
2021-06-21 23:53:29,628 BAD EPOCHS (no improvement): 3
2021-06-21 23:53:29,628 ----------------------------------------------------------------------------------------------------
2021-06-21 23:53:31,004 epoch 26 - iter 3/35 - loss 0.20364910 - samples/sec: 69.80 - lr: 0.000015
2021-06-21 23:53:32,365 epoch 26 - iter 6/35 - loss 0.18313588 - samples/sec: 70.58 - lr: 0.000015
2021-06-21 23:53:33,744 epoch 26 - iter 9/35 - loss 0.19735569 - samples/sec: 69.62 - lr: 0.000015
2021-06-21 23:53:35,129 epoch 26 - iter 12/35 - loss 0.16419789 - samples/sec: 69.36 - lr: 0.000015
2021-06-21 23:53:36,490 epoch 26 - iter 15/35 - loss 0.14574987 - samples/sec: 70.56 - lr: 0.000015
2021-06-21 23:53:37,876 epoch 26 - iter 18/35 - loss 0.16026986 - samples/sec: 69.30 - lr: 0.000015
2021-06-21 23:53:39,244 epoch 26 - iter 21/35 - loss 0.15657823 - samples/sec: 70.21 - lr: 0.000015
2021-06-21 23:53:40,626 epoch 26 - iter 24/35 - loss 0.15543225 - samples/sec: 69.48 - lr: 0.000015
2021-06-21 23:53:41,962 epoch 26 - iter 27/35 - loss 0.15275002 - samples/sec: 71.86 - lr: 0.000015
2021-06-21 23:53:43,328 epoch 26 - iter 30/35 - loss 0.14886578 - samples/sec: 70.30 - lr: 0.000015
2021-06-21 23:53:44,698 epoch 26 - iter 33/35 - loss 0.14591002 - samples/sec: 70.09 - lr: 0.000015
2021-06-21 23:53:45,258 ----------------------------------------------------------------------------------------------------
2021-06-21 23:53:45,258 EPOCH 26 done: loss 0.1407 - lr 0.0000150
2021-06-21 23:53:46,476 DEV : loss 0.18775302171707153 - score 0.9643
Epoch    26: reducing learning rate of group 0 to 7.5000e-06.
2021-06-21 23:53:46,493 BAD EPOCHS (no improvement): 4
2021-06-21 23:53:46,494 ----------------------------------------------------------------------------------------------------
2021-06-21 23:53:47,859 epoch 27 - iter 3/35 - loss 0.06094269 - samples/sec: 70.35 - lr: 0.000008
2021-06-21 23:53:49,237 epoch 27 - iter 6/35 - loss 0.13855052 - samples/sec: 69.67 - lr: 0.000008
2021-06-21 23:53:50,609 epoch 27 - iter 9/35 - loss 0.14521553 - samples/sec: 70.01 - lr: 0.000008
2021-06-21 23:53:51,990 epoch 27 - iter 12/35 - loss 0.12983024 - samples/sec: 69.52 - lr: 0.000008
2021-06-21 23:53:53,354 epoch 27 - iter 15/35 - loss 0.13350222 - samples/sec: 70.45 - lr: 0.000008
2021-06-21 23:53:54,712 epoch 27 - iter 18/35 - loss 0.14336903 - samples/sec: 70.68 - lr: 0.000008
2021-06-21 23:53:56,096 epoch 27 - iter 21/35 - loss 0.14076305 - samples/sec: 69.40 - lr: 0.000008
2021-06-21 23:53:57,476 epoch 27 - iter 24/35 - loss 0.14246925 - samples/sec: 69.60 - lr: 0.000008
2021-06-21 23:53:58,851 epoch 27 - iter 27/35 - loss 0.13873043 - samples/sec: 69.85 - lr: 0.000008
2021-06-21 23:54:00,226 epoch 27 - iter 30/35 - loss 0.13707512 - samples/sec: 69.85 - lr: 0.000008
2021-06-21 23:54:01,594 epoch 27 - iter 33/35 - loss 0.13534137 - samples/sec: 70.20 - lr: 0.000008
2021-06-21 23:54:02,133 ----------------------------------------------------------------------------------------------------
2021-06-21 23:54:02,133 EPOCH 27 done: loss 0.1305 - lr 0.0000075
2021-06-21 23:54:03,354 DEV : loss 0.17993634939193726 - score 0.9643
2021-06-21 23:54:03,371 BAD EPOCHS (no improvement): 1
2021-06-21 23:54:03,371 ----------------------------------------------------------------------------------------------------
2021-06-21 23:54:04,736 epoch 28 - iter 3/35 - loss 0.14569237 - samples/sec: 70.36 - lr: 0.000008
2021-06-21 23:54:06,103 epoch 28 - iter 6/35 - loss 0.14515084 - samples/sec: 70.25 - lr: 0.000008
2021-06-21 23:54:07,476 epoch 28 - iter 9/35 - loss 0.12858567 - samples/sec: 69.95 - lr: 0.000008
2021-06-21 23:54:08,838 epoch 28 - iter 12/35 - loss 0.11935724 - samples/sec: 70.51 - lr: 0.000008
2021-06-21 23:54:10,223 epoch 28 - iter 15/35 - loss 0.11086187 - samples/sec: 69.34 - lr: 0.000008
2021-06-21 23:54:11,598 epoch 28 - iter 18/35 - loss 0.11206388 - samples/sec: 69.84 - lr: 0.000008
2021-06-21 23:54:12,985 epoch 28 - iter 21/35 - loss 0.11756795 - samples/sec: 69.25 - lr: 0.000008
2021-06-21 23:54:14,337 epoch 28 - iter 24/35 - loss 0.11853156 - samples/sec: 71.02 - lr: 0.000008
2021-06-21 23:54:15,710 epoch 28 - iter 27/35 - loss 0.12429113 - samples/sec: 69.98 - lr: 0.000008
2021-06-21 23:54:17,063 epoch 28 - iter 30/35 - loss 0.12550470 - samples/sec: 70.98 - lr: 0.000008
2021-06-21 23:54:18,440 epoch 28 - iter 33/35 - loss 0.12239614 - samples/sec: 69.73 - lr: 0.000008
2021-06-21 23:54:19,007 ----------------------------------------------------------------------------------------------------
2021-06-21 23:54:19,007 EPOCH 28 done: loss 0.1227 - lr 0.0000075
2021-06-21 23:54:20,358 DEV : loss 0.17731022834777832 - score 0.9666
2021-06-21 23:54:20,375 BAD EPOCHS (no improvement): 2
2021-06-21 23:54:20,375 ----------------------------------------------------------------------------------------------------
2021-06-21 23:54:21,737 epoch 29 - iter 3/35 - loss 0.07613722 - samples/sec: 70.53 - lr: 0.000008
2021-06-21 23:54:23,107 epoch 29 - iter 6/35 - loss 0.08287227 - samples/sec: 70.10 - lr: 0.000008
2021-06-21 23:54:24,483 epoch 29 - iter 9/35 - loss 0.11014374 - samples/sec: 69.77 - lr: 0.000008
2021-06-21 23:54:25,872 epoch 29 - iter 12/35 - loss 0.11188899 - samples/sec: 69.16 - lr: 0.000008
2021-06-21 23:54:27,250 epoch 29 - iter 15/35 - loss 0.12300828 - samples/sec: 69.70 - lr: 0.000008
2021-06-21 23:54:28,607 epoch 29 - iter 18/35 - loss 0.13325805 - samples/sec: 70.78 - lr: 0.000008
2021-06-21 23:54:29,993 epoch 29 - iter 21/35 - loss 0.13217665 - samples/sec: 69.29 - lr: 0.000008
2021-06-21 23:54:31,375 epoch 29 - iter 24/35 - loss 0.13455648 - samples/sec: 69.47 - lr: 0.000008
2021-06-21 23:54:32,740 epoch 29 - iter 27/35 - loss 0.12682683 - samples/sec: 70.37 - lr: 0.000008
2021-06-21 23:54:34,109 epoch 29 - iter 30/35 - loss 0.12511986 - samples/sec: 70.15 - lr: 0.000008
2021-06-21 23:54:35,486 epoch 29 - iter 33/35 - loss 0.13801363 - samples/sec: 69.75 - lr: 0.000008
2021-06-21 23:54:36,060 ----------------------------------------------------------------------------------------------------
2021-06-21 23:54:36,060 EPOCH 29 done: loss 0.1365 - lr 0.0000075
2021-06-21 23:54:37,278 DEV : loss 0.17941796779632568 - score 0.9643
2021-06-21 23:54:37,295 BAD EPOCHS (no improvement): 3
2021-06-21 23:54:37,295 ----------------------------------------------------------------------------------------------------
2021-06-21 23:54:38,666 epoch 30 - iter 3/35 - loss 0.08787866 - samples/sec: 70.08 - lr: 0.000008
2021-06-21 23:54:40,053 epoch 30 - iter 6/35 - loss 0.12126423 - samples/sec: 69.24 - lr: 0.000008
2021-06-21 23:54:41,442 epoch 30 - iter 9/35 - loss 0.11496486 - samples/sec: 69.15 - lr: 0.000008
2021-06-21 23:54:42,838 epoch 30 - iter 12/35 - loss 0.09931793 - samples/sec: 68.76 - lr: 0.000008
2021-06-21 23:54:44,178 epoch 30 - iter 15/35 - loss 0.10000352 - samples/sec: 71.71 - lr: 0.000008
2021-06-21 23:54:45,558 epoch 30 - iter 18/35 - loss 0.10779794 - samples/sec: 69.55 - lr: 0.000008
2021-06-21 23:54:46,920 epoch 30 - iter 21/35 - loss 0.10845233 - samples/sec: 70.54 - lr: 0.000008
2021-06-21 23:54:48,283 epoch 30 - iter 24/35 - loss 0.11097049 - samples/sec: 70.44 - lr: 0.000008
2021-06-21 23:54:49,661 epoch 30 - iter 27/35 - loss 0.10872740 - samples/sec: 69.69 - lr: 0.000008
2021-06-21 23:54:51,029 epoch 30 - iter 30/35 - loss 0.11771262 - samples/sec: 70.20 - lr: 0.000008
2021-06-21 23:54:52,405 epoch 30 - iter 33/35 - loss 0.11268023 - samples/sec: 69.79 - lr: 0.000008
2021-06-21 23:54:52,954 ----------------------------------------------------------------------------------------------------
2021-06-21 23:54:52,954 EPOCH 30 done: loss 0.1117 - lr 0.0000075
2021-06-21 23:54:54,174 DEV : loss 0.1798594444990158 - score 0.9643
Epoch    30: reducing learning rate of group 0 to 3.7500e-06.
2021-06-21 23:54:54,191 BAD EPOCHS (no improvement): 4
2021-06-21 23:54:54,191 ----------------------------------------------------------------------------------------------------
2021-06-21 23:54:55,549 epoch 31 - iter 3/35 - loss 0.11657484 - samples/sec: 70.74 - lr: 0.000004
2021-06-21 23:54:56,902 epoch 31 - iter 6/35 - loss 0.09710753 - samples/sec: 70.97 - lr: 0.000004
2021-06-21 23:54:58,282 epoch 31 - iter 9/35 - loss 0.12188976 - samples/sec: 69.60 - lr: 0.000004
2021-06-21 23:54:59,668 epoch 31 - iter 12/35 - loss 0.13632130 - samples/sec: 69.27 - lr: 0.000004
2021-06-21 23:55:01,034 epoch 31 - iter 15/35 - loss 0.14065975 - samples/sec: 70.30 - lr: 0.000004
2021-06-21 23:55:02,421 epoch 31 - iter 18/35 - loss 0.13840443 - samples/sec: 69.25 - lr: 0.000004
2021-06-21 23:55:03,809 epoch 31 - iter 21/35 - loss 0.14483080 - samples/sec: 69.18 - lr: 0.000004
2021-06-21 23:55:05,173 epoch 31 - iter 24/35 - loss 0.13813018 - samples/sec: 70.42 - lr: 0.000004
2021-06-21 23:55:06,561 epoch 31 - iter 27/35 - loss 0.13167820 - samples/sec: 69.17 - lr: 0.000004
2021-06-21 23:55:07,948 epoch 31 - iter 30/35 - loss 0.12585432 - samples/sec: 69.24 - lr: 0.000004
2021-06-21 23:55:09,310 epoch 31 - iter 33/35 - loss 0.12188800 - samples/sec: 70.52 - lr: 0.000004
2021-06-21 23:55:09,855 ----------------------------------------------------------------------------------------------------
2021-06-21 23:55:09,856 EPOCH 31 done: loss 0.1320 - lr 0.0000038
2021-06-21 23:55:11,072 DEV : loss 0.17800650000572205 - score 0.9666
2021-06-21 23:55:11,089 BAD EPOCHS (no improvement): 1
2021-06-21 23:55:11,089 ----------------------------------------------------------------------------------------------------
2021-06-21 23:55:12,462 epoch 32 - iter 3/35 - loss 0.14085746 - samples/sec: 69.94 - lr: 0.000004
2021-06-21 23:55:13,861 epoch 32 - iter 6/35 - loss 0.14164396 - samples/sec: 68.64 - lr: 0.000004
2021-06-21 23:55:15,190 epoch 32 - iter 9/35 - loss 0.18906111 - samples/sec: 72.27 - lr: 0.000004
2021-06-21 23:55:16,574 epoch 32 - iter 12/35 - loss 0.17810055 - samples/sec: 69.41 - lr: 0.000004
2021-06-21 23:55:17,937 epoch 32 - iter 15/35 - loss 0.17523708 - samples/sec: 70.43 - lr: 0.000004
2021-06-21 23:55:19,317 epoch 32 - iter 18/35 - loss 0.16893801 - samples/sec: 69.60 - lr: 0.000004
2021-06-21 23:55:20,706 epoch 32 - iter 21/35 - loss 0.16511890 - samples/sec: 69.14 - lr: 0.000004
2021-06-21 23:55:22,094 epoch 32 - iter 24/35 - loss 0.16371306 - samples/sec: 69.20 - lr: 0.000004
2021-06-21 23:55:23,446 epoch 32 - iter 27/35 - loss 0.16563826 - samples/sec: 71.01 - lr: 0.000004
2021-06-21 23:55:24,801 epoch 32 - iter 30/35 - loss 0.15445477 - samples/sec: 70.90 - lr: 0.000004
2021-06-21 23:55:26,142 epoch 32 - iter 33/35 - loss 0.14899422 - samples/sec: 71.60 - lr: 0.000004
2021-06-21 23:55:26,701 ----------------------------------------------------------------------------------------------------
2021-06-21 23:55:26,701 EPOCH 32 done: loss 0.1457 - lr 0.0000038
2021-06-21 23:55:28,050 DEV : loss 0.17756733298301697 - score 0.9643
2021-06-21 23:55:28,067 BAD EPOCHS (no improvement): 2
2021-06-21 23:55:28,067 ----------------------------------------------------------------------------------------------------
2021-06-21 23:55:29,440 epoch 33 - iter 3/35 - loss 0.08772387 - samples/sec: 69.93 - lr: 0.000004
2021-06-21 23:55:30,808 epoch 33 - iter 6/35 - loss 0.08468661 - samples/sec: 70.23 - lr: 0.000004
2021-06-21 23:55:32,170 epoch 33 - iter 9/35 - loss 0.11211587 - samples/sec: 70.50 - lr: 0.000004
2021-06-21 23:55:33,546 epoch 33 - iter 12/35 - loss 0.11225174 - samples/sec: 69.79 - lr: 0.000004
2021-06-21 23:55:34,937 epoch 33 - iter 15/35 - loss 0.11228058 - samples/sec: 69.03 - lr: 0.000004
2021-06-21 23:55:36,302 epoch 33 - iter 18/35 - loss 0.10966273 - samples/sec: 70.37 - lr: 0.000004
2021-06-21 23:55:37,648 epoch 33 - iter 21/35 - loss 0.10984437 - samples/sec: 71.37 - lr: 0.000004
2021-06-21 23:55:39,028 epoch 33 - iter 24/35 - loss 0.10939508 - samples/sec: 69.57 - lr: 0.000004
2021-06-21 23:55:40,399 epoch 33 - iter 27/35 - loss 0.10613050 - samples/sec: 70.05 - lr: 0.000004
2021-06-21 23:55:41,770 epoch 33 - iter 30/35 - loss 0.11191512 - samples/sec: 70.05 - lr: 0.000004
2021-06-21 23:55:43,135 epoch 33 - iter 33/35 - loss 0.11049991 - samples/sec: 70.32 - lr: 0.000004
2021-06-21 23:55:43,685 ----------------------------------------------------------------------------------------------------
2021-06-21 23:55:43,686 EPOCH 33 done: loss 0.1057 - lr 0.0000038
2021-06-21 23:55:44,904 DEV : loss 0.1771698296070099 - score 0.9643
2021-06-21 23:55:44,921 BAD EPOCHS (no improvement): 3
2021-06-21 23:55:44,922 ----------------------------------------------------------------------------------------------------
2021-06-21 23:55:46,258 epoch 34 - iter 3/35 - loss 0.09083124 - samples/sec: 71.84 - lr: 0.000004
2021-06-21 23:55:47,649 epoch 34 - iter 6/35 - loss 0.12941366 - samples/sec: 69.07 - lr: 0.000004
2021-06-21 23:55:48,996 epoch 34 - iter 9/35 - loss 0.13462179 - samples/sec: 71.29 - lr: 0.000004
2021-06-21 23:55:50,372 epoch 34 - iter 12/35 - loss 0.12683669 - samples/sec: 69.78 - lr: 0.000004
2021-06-21 23:55:51,737 epoch 34 - iter 15/35 - loss 0.11694679 - samples/sec: 70.39 - lr: 0.000004
2021-06-21 23:55:53,129 epoch 34 - iter 18/35 - loss 0.12695128 - samples/sec: 68.97 - lr: 0.000004
2021-06-21 23:55:54,497 epoch 34 - iter 21/35 - loss 0.12300626 - samples/sec: 70.20 - lr: 0.000004
2021-06-21 23:55:55,874 epoch 34 - iter 24/35 - loss 0.11602565 - samples/sec: 69.77 - lr: 0.000004
2021-06-21 23:55:57,234 epoch 34 - iter 27/35 - loss 0.11980938 - samples/sec: 70.60 - lr: 0.000004
2021-06-21 23:55:58,605 epoch 34 - iter 30/35 - loss 0.11506720 - samples/sec: 70.07 - lr: 0.000004
2021-06-21 23:55:59,974 epoch 34 - iter 33/35 - loss 0.12593266 - samples/sec: 70.12 - lr: 0.000004
2021-06-21 23:56:00,531 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:00,531 EPOCH 34 done: loss 0.1301 - lr 0.0000038
2021-06-21 23:56:01,750 DEV : loss 0.17357183992862701 - score 0.9643
Epoch    34: reducing learning rate of group 0 to 1.8750e-06.
2021-06-21 23:56:01,767 BAD EPOCHS (no improvement): 4
2021-06-21 23:56:01,767 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:01,767 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:01,767 learning rate too small - quitting training!
2021-06-21 23:56:01,767 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:02,299 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:02,299 Testing using best model ...
2021-06-21 23:56:02,299 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/best-model.pt
2021-06-21 23:56:05,878 0.9163	0.9858	0.9498
2021-06-21 23:56:05,879 
Results:
- F1-score (micro) 0.9498
- F1-score (macro) 0.9498

By class:
SENT       tp: 208 - fp: 19 - fn: 3 - precision: 0.9163 - recall: 0.9858 - f1-score: 0.9498
2021-06-21 23:56:05,879 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/
2021-06-21 23:56:05,890 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert
2021-06-21 23:56:05,892 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/sent_train.txt
2021-06-21 23:56:05,892 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/sent_dev.txt
2021-06-21 23:56:05,892 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/sent_test.txt
Corpus: 1046 train + 371 dev + 330 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-21 23:56:27,247 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:27,248 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(50099, 768, padding_idx=3)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-21 23:56:27,248 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:27,248 Corpus: "Corpus: 1046 train + 371 dev + 330 test sentences"
2021-06-21 23:56:27,248 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:27,248 Parameters:
2021-06-21 23:56:27,249  - learning_rate: "3e-05"
2021-06-21 23:56:27,249  - mini_batch_size: "32"
2021-06-21 23:56:27,249  - patience: "3"
2021-06-21 23:56:27,249  - anneal_factor: "0.5"
2021-06-21 23:56:27,249  - max_epochs: "40"
2021-06-21 23:56:27,249  - shuffle: "True"
2021-06-21 23:56:27,249  - train_with_dev: "False"
2021-06-21 23:56:27,249  - batch_growth_annealing: "False"
2021-06-21 23:56:27,249 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:27,249 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert"
2021-06-21 23:56:27,249 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:27,249 Device: cuda:0
2021-06-21 23:56:27,249 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:27,249 Embeddings storage mode: cpu
2021-06-21 23:56:27,250 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:30,035 epoch 1 - iter 3/33 - loss 22.42417717 - samples/sec: 34.47 - lr: 0.000030
2021-06-21 23:56:32,766 epoch 1 - iter 6/33 - loss 19.00230138 - samples/sec: 35.16 - lr: 0.000030
2021-06-21 23:56:35,500 epoch 1 - iter 9/33 - loss 16.44543637 - samples/sec: 35.12 - lr: 0.000030
2021-06-21 23:56:38,373 epoch 1 - iter 12/33 - loss 14.47259041 - samples/sec: 33.41 - lr: 0.000030
2021-06-21 23:56:41,130 epoch 1 - iter 15/33 - loss 12.76851848 - samples/sec: 34.83 - lr: 0.000030
2021-06-21 23:56:43,859 epoch 1 - iter 18/33 - loss 11.45631022 - samples/sec: 35.18 - lr: 0.000030
2021-06-21 23:56:46,604 epoch 1 - iter 21/33 - loss 10.45989888 - samples/sec: 34.98 - lr: 0.000030
2021-06-21 23:56:49,343 epoch 1 - iter 24/33 - loss 9.62240485 - samples/sec: 35.06 - lr: 0.000030
2021-06-21 23:56:52,134 epoch 1 - iter 27/33 - loss 8.97956194 - samples/sec: 34.39 - lr: 0.000030
2021-06-21 23:56:54,913 epoch 1 - iter 30/33 - loss 8.40483798 - samples/sec: 34.56 - lr: 0.000030
2021-06-21 23:56:57,438 epoch 1 - iter 33/33 - loss 7.89991335 - samples/sec: 38.01 - lr: 0.000030
2021-06-21 23:56:57,439 ----------------------------------------------------------------------------------------------------
2021-06-21 23:56:57,439 EPOCH 1 done: loss 7.8999 - lr 0.0000300
2021-06-21 23:57:03,871 DEV : loss 2.2288050651550293 - score 0.0
2021-06-21 23:57:03,897 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:57:04,354 ----------------------------------------------------------------------------------------------------
2021-06-21 23:57:05,740 epoch 2 - iter 3/33 - loss 2.51508554 - samples/sec: 69.28 - lr: 0.000030
2021-06-21 23:57:07,142 epoch 2 - iter 6/33 - loss 2.47944331 - samples/sec: 68.54 - lr: 0.000030
2021-06-21 23:57:08,556 epoch 2 - iter 9/33 - loss 2.37794314 - samples/sec: 67.91 - lr: 0.000030
2021-06-21 23:57:10,142 epoch 2 - iter 12/33 - loss 2.23402560 - samples/sec: 60.54 - lr: 0.000030
2021-06-21 23:57:11,563 epoch 2 - iter 15/33 - loss 2.12700934 - samples/sec: 67.60 - lr: 0.000030
2021-06-21 23:57:12,991 epoch 2 - iter 18/33 - loss 2.06028894 - samples/sec: 67.24 - lr: 0.000030
2021-06-21 23:57:14,405 epoch 2 - iter 21/33 - loss 1.92735853 - samples/sec: 67.89 - lr: 0.000030
2021-06-21 23:57:15,824 epoch 2 - iter 24/33 - loss 1.85173774 - samples/sec: 67.70 - lr: 0.000030
2021-06-21 23:57:17,239 epoch 2 - iter 27/33 - loss 1.76809080 - samples/sec: 67.86 - lr: 0.000030
2021-06-21 23:57:18,662 epoch 2 - iter 30/33 - loss 1.70260690 - samples/sec: 67.51 - lr: 0.000030
2021-06-21 23:57:19,955 epoch 2 - iter 33/33 - loss 1.64659775 - samples/sec: 74.24 - lr: 0.000030
2021-06-21 23:57:19,956 ----------------------------------------------------------------------------------------------------
2021-06-21 23:57:19,956 EPOCH 2 done: loss 1.6466 - lr 0.0000300
2021-06-21 23:57:21,858 DEV : loss 0.6303268671035767 - score 0.9024
2021-06-21 23:57:21,884 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:57:26,850 ----------------------------------------------------------------------------------------------------
2021-06-21 23:57:28,259 epoch 3 - iter 3/33 - loss 1.03302463 - samples/sec: 68.18 - lr: 0.000030
2021-06-21 23:57:29,703 epoch 3 - iter 6/33 - loss 0.95008453 - samples/sec: 66.52 - lr: 0.000030
2021-06-21 23:57:31,112 epoch 3 - iter 9/33 - loss 0.91127144 - samples/sec: 68.17 - lr: 0.000030
2021-06-21 23:57:32,534 epoch 3 - iter 12/33 - loss 0.87508738 - samples/sec: 67.51 - lr: 0.000030
2021-06-21 23:57:33,916 epoch 3 - iter 15/33 - loss 0.85468361 - samples/sec: 69.49 - lr: 0.000030
2021-06-21 23:57:35,319 epoch 3 - iter 18/33 - loss 0.81951282 - samples/sec: 68.49 - lr: 0.000030
2021-06-21 23:57:36,704 epoch 3 - iter 21/33 - loss 0.78629269 - samples/sec: 69.31 - lr: 0.000030
2021-06-21 23:57:38,126 epoch 3 - iter 24/33 - loss 0.76998329 - samples/sec: 67.57 - lr: 0.000030
2021-06-21 23:57:39,528 epoch 3 - iter 27/33 - loss 0.76675838 - samples/sec: 68.50 - lr: 0.000030
2021-06-21 23:57:40,967 epoch 3 - iter 30/33 - loss 0.76266033 - samples/sec: 66.71 - lr: 0.000030
2021-06-21 23:57:42,250 epoch 3 - iter 33/33 - loss 0.76087490 - samples/sec: 74.86 - lr: 0.000030
2021-06-21 23:57:42,251 ----------------------------------------------------------------------------------------------------
2021-06-21 23:57:42,251 EPOCH 3 done: loss 0.7609 - lr 0.0000300
2021-06-21 23:57:44,147 DEV : loss 0.4068230390548706 - score 0.9337
2021-06-21 23:57:44,172 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:57:49,355 ----------------------------------------------------------------------------------------------------
2021-06-21 23:57:50,773 epoch 4 - iter 3/33 - loss 0.61420204 - samples/sec: 67.73 - lr: 0.000030
2021-06-21 23:57:52,211 epoch 4 - iter 6/33 - loss 0.54484265 - samples/sec: 66.79 - lr: 0.000030
2021-06-21 23:57:53,612 epoch 4 - iter 9/33 - loss 0.54073578 - samples/sec: 68.54 - lr: 0.000030
2021-06-21 23:57:55,004 epoch 4 - iter 12/33 - loss 0.53490652 - samples/sec: 69.02 - lr: 0.000030
2021-06-21 23:57:56,417 epoch 4 - iter 15/33 - loss 0.57222243 - samples/sec: 67.96 - lr: 0.000030
2021-06-21 23:57:57,818 epoch 4 - iter 18/33 - loss 0.55410789 - samples/sec: 68.52 - lr: 0.000030
2021-06-21 23:57:59,215 epoch 4 - iter 21/33 - loss 0.56041624 - samples/sec: 68.78 - lr: 0.000030
2021-06-21 23:58:00,634 epoch 4 - iter 24/33 - loss 0.56420835 - samples/sec: 67.67 - lr: 0.000030
2021-06-21 23:58:02,061 epoch 4 - iter 27/33 - loss 0.57376290 - samples/sec: 67.31 - lr: 0.000030
2021-06-21 23:58:03,424 epoch 4 - iter 30/33 - loss 0.55290202 - samples/sec: 70.45 - lr: 0.000030
2021-06-21 23:58:04,696 epoch 4 - iter 33/33 - loss 0.55169226 - samples/sec: 75.50 - lr: 0.000030
2021-06-21 23:58:04,696 ----------------------------------------------------------------------------------------------------
2021-06-21 23:58:04,696 EPOCH 4 done: loss 0.5517 - lr 0.0000300
2021-06-21 23:58:06,594 DEV : loss 0.3603627681732178 - score 0.9363
2021-06-21 23:58:06,620 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:58:11,667 ----------------------------------------------------------------------------------------------------
2021-06-21 23:58:13,072 epoch 5 - iter 3/33 - loss 0.36484035 - samples/sec: 68.41 - lr: 0.000030
2021-06-21 23:58:14,502 epoch 5 - iter 6/33 - loss 0.40075777 - samples/sec: 67.13 - lr: 0.000030
2021-06-21 23:58:15,910 epoch 5 - iter 9/33 - loss 0.43606287 - samples/sec: 68.22 - lr: 0.000030
2021-06-21 23:58:17,317 epoch 5 - iter 12/33 - loss 0.41501477 - samples/sec: 68.27 - lr: 0.000030
2021-06-21 23:58:18,722 epoch 5 - iter 15/33 - loss 0.43896746 - samples/sec: 68.33 - lr: 0.000030
2021-06-21 23:58:20,260 epoch 5 - iter 18/33 - loss 0.44483823 - samples/sec: 62.44 - lr: 0.000030
2021-06-21 23:58:21,684 epoch 5 - iter 21/33 - loss 0.43972306 - samples/sec: 67.42 - lr: 0.000030
2021-06-21 23:58:23,071 epoch 5 - iter 24/33 - loss 0.43070150 - samples/sec: 69.27 - lr: 0.000030
2021-06-21 23:58:24,462 epoch 5 - iter 27/33 - loss 0.42619823 - samples/sec: 69.05 - lr: 0.000030
2021-06-21 23:58:25,878 epoch 5 - iter 30/33 - loss 0.43140604 - samples/sec: 67.79 - lr: 0.000030
2021-06-21 23:58:27,145 epoch 5 - iter 33/33 - loss 0.42720028 - samples/sec: 75.81 - lr: 0.000030
2021-06-21 23:58:27,145 ----------------------------------------------------------------------------------------------------
2021-06-21 23:58:27,146 EPOCH 5 done: loss 0.4272 - lr 0.0000300
2021-06-21 23:58:29,048 DEV : loss 0.31121546030044556 - score 0.9438
2021-06-21 23:58:29,074 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:58:34,145 ----------------------------------------------------------------------------------------------------
2021-06-21 23:58:35,535 epoch 6 - iter 3/33 - loss 0.38946702 - samples/sec: 69.09 - lr: 0.000030
2021-06-21 23:58:36,905 epoch 6 - iter 6/33 - loss 0.34901361 - samples/sec: 70.09 - lr: 0.000030
2021-06-21 23:58:38,310 epoch 6 - iter 9/33 - loss 0.36704237 - samples/sec: 68.38 - lr: 0.000030
2021-06-21 23:58:39,690 epoch 6 - iter 12/33 - loss 0.37988040 - samples/sec: 69.57 - lr: 0.000030
2021-06-21 23:58:41,121 epoch 6 - iter 15/33 - loss 0.37913063 - samples/sec: 67.14 - lr: 0.000030
2021-06-21 23:58:42,517 epoch 6 - iter 18/33 - loss 0.41171148 - samples/sec: 68.80 - lr: 0.000030
2021-06-21 23:58:43,900 epoch 6 - iter 21/33 - loss 0.41123106 - samples/sec: 69.40 - lr: 0.000030
2021-06-21 23:58:45,325 epoch 6 - iter 24/33 - loss 0.40580854 - samples/sec: 67.39 - lr: 0.000030
2021-06-21 23:58:46,726 epoch 6 - iter 27/33 - loss 0.39854455 - samples/sec: 68.58 - lr: 0.000030
2021-06-21 23:58:48,148 epoch 6 - iter 30/33 - loss 0.38790848 - samples/sec: 67.50 - lr: 0.000030
2021-06-21 23:58:49,424 epoch 6 - iter 33/33 - loss 0.40449499 - samples/sec: 75.28 - lr: 0.000030
2021-06-21 23:58:49,424 ----------------------------------------------------------------------------------------------------
2021-06-21 23:58:49,424 EPOCH 6 done: loss 0.4045 - lr 0.0000300
2021-06-21 23:58:51,330 DEV : loss 0.2724846601486206 - score 0.9533
2021-06-21 23:58:51,356 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:58:56,410 ----------------------------------------------------------------------------------------------------
2021-06-21 23:58:57,796 epoch 7 - iter 3/33 - loss 0.38798894 - samples/sec: 69.31 - lr: 0.000030
2021-06-21 23:58:59,200 epoch 7 - iter 6/33 - loss 0.35743214 - samples/sec: 68.37 - lr: 0.000030
2021-06-21 23:59:00,610 epoch 7 - iter 9/33 - loss 0.38421083 - samples/sec: 68.10 - lr: 0.000030
2021-06-21 23:59:02,016 epoch 7 - iter 12/33 - loss 0.36572373 - samples/sec: 68.33 - lr: 0.000030
2021-06-21 23:59:03,435 epoch 7 - iter 15/33 - loss 0.37906094 - samples/sec: 67.66 - lr: 0.000030
2021-06-21 23:59:04,827 epoch 7 - iter 18/33 - loss 0.38196519 - samples/sec: 69.01 - lr: 0.000030
2021-06-21 23:59:06,227 epoch 7 - iter 21/33 - loss 0.37002071 - samples/sec: 68.62 - lr: 0.000030
2021-06-21 23:59:07,637 epoch 7 - iter 24/33 - loss 0.36129247 - samples/sec: 68.10 - lr: 0.000030
2021-06-21 23:59:09,045 epoch 7 - iter 27/33 - loss 0.35347771 - samples/sec: 68.20 - lr: 0.000030
2021-06-21 23:59:10,446 epoch 7 - iter 30/33 - loss 0.35207104 - samples/sec: 68.54 - lr: 0.000030
2021-06-21 23:59:11,725 epoch 7 - iter 33/33 - loss 0.35492443 - samples/sec: 75.09 - lr: 0.000030
2021-06-21 23:59:11,725 ----------------------------------------------------------------------------------------------------
2021-06-21 23:59:11,725 EPOCH 7 done: loss 0.3549 - lr 0.0000300
2021-06-21 23:59:13,625 DEV : loss 0.24786391854286194 - score 0.9559
2021-06-21 23:59:13,651 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:59:18,720 ----------------------------------------------------------------------------------------------------
2021-06-21 23:59:20,123 epoch 8 - iter 3/33 - loss 0.31387242 - samples/sec: 68.45 - lr: 0.000030
2021-06-21 23:59:21,535 epoch 8 - iter 6/33 - loss 0.29995235 - samples/sec: 68.03 - lr: 0.000030
2021-06-21 23:59:22,962 epoch 8 - iter 9/33 - loss 0.30037281 - samples/sec: 67.31 - lr: 0.000030
2021-06-21 23:59:24,341 epoch 8 - iter 12/33 - loss 0.28507394 - samples/sec: 69.65 - lr: 0.000030
2021-06-21 23:59:25,735 epoch 8 - iter 15/33 - loss 0.28635474 - samples/sec: 68.88 - lr: 0.000030
2021-06-21 23:59:27,143 epoch 8 - iter 18/33 - loss 0.29280544 - samples/sec: 68.20 - lr: 0.000030
2021-06-21 23:59:28,555 epoch 8 - iter 21/33 - loss 0.29983565 - samples/sec: 68.00 - lr: 0.000030
2021-06-21 23:59:29,964 epoch 8 - iter 24/33 - loss 0.30215515 - samples/sec: 68.17 - lr: 0.000030
2021-06-21 23:59:31,370 epoch 8 - iter 27/33 - loss 0.30526307 - samples/sec: 68.31 - lr: 0.000030
2021-06-21 23:59:32,774 epoch 8 - iter 30/33 - loss 0.30092369 - samples/sec: 68.40 - lr: 0.000030
2021-06-21 23:59:34,056 epoch 8 - iter 33/33 - loss 0.29388834 - samples/sec: 74.92 - lr: 0.000030
2021-06-21 23:59:34,056 ----------------------------------------------------------------------------------------------------
2021-06-21 23:59:34,056 EPOCH 8 done: loss 0.2939 - lr 0.0000300
2021-06-21 23:59:36,106 DEV : loss 0.24932315945625305 - score 0.954
2021-06-21 23:59:36,132 BAD EPOCHS (no improvement): 1
2021-06-21 23:59:36,133 ----------------------------------------------------------------------------------------------------
2021-06-21 23:59:37,546 epoch 9 - iter 3/33 - loss 0.28563925 - samples/sec: 67.94 - lr: 0.000030
2021-06-21 23:59:38,955 epoch 9 - iter 6/33 - loss 0.27653152 - samples/sec: 68.17 - lr: 0.000030
2021-06-21 23:59:40,353 epoch 9 - iter 9/33 - loss 0.26974719 - samples/sec: 68.71 - lr: 0.000030
2021-06-21 23:59:41,740 epoch 9 - iter 12/33 - loss 0.26747579 - samples/sec: 69.22 - lr: 0.000030
2021-06-21 23:59:43,167 epoch 9 - iter 15/33 - loss 0.27258441 - samples/sec: 67.30 - lr: 0.000030
2021-06-21 23:59:44,575 epoch 9 - iter 18/33 - loss 0.29303054 - samples/sec: 68.20 - lr: 0.000030
2021-06-21 23:59:45,954 epoch 9 - iter 21/33 - loss 0.28776902 - samples/sec: 69.65 - lr: 0.000030
2021-06-21 23:59:47,358 epoch 9 - iter 24/33 - loss 0.28334900 - samples/sec: 68.41 - lr: 0.000030
2021-06-21 23:59:48,759 epoch 9 - iter 27/33 - loss 0.28553847 - samples/sec: 68.56 - lr: 0.000030
2021-06-21 23:59:50,168 epoch 9 - iter 30/33 - loss 0.28513239 - samples/sec: 68.15 - lr: 0.000030
2021-06-21 23:59:51,436 epoch 9 - iter 33/33 - loss 0.27548839 - samples/sec: 75.74 - lr: 0.000030
2021-06-21 23:59:51,436 ----------------------------------------------------------------------------------------------------
2021-06-21 23:59:51,437 EPOCH 9 done: loss 0.2755 - lr 0.0000300
2021-06-21 23:59:53,339 DEV : loss 0.2059350311756134 - score 0.9632
2021-06-21 23:59:53,365 BAD EPOCHS (no improvement): 0
saving best model
2021-06-21 23:59:58,420 ----------------------------------------------------------------------------------------------------
2021-06-21 23:59:59,828 epoch 10 - iter 3/33 - loss 0.17393704 - samples/sec: 68.25 - lr: 0.000030
2021-06-22 00:00:01,252 epoch 10 - iter 6/33 - loss 0.22895785 - samples/sec: 67.41 - lr: 0.000030
2021-06-22 00:00:02,660 epoch 10 - iter 9/33 - loss 0.23812587 - samples/sec: 68.22 - lr: 0.000030
2021-06-22 00:00:04,055 epoch 10 - iter 12/33 - loss 0.24934526 - samples/sec: 68.86 - lr: 0.000030
2021-06-22 00:00:05,471 epoch 10 - iter 15/33 - loss 0.24070187 - samples/sec: 67.82 - lr: 0.000030
2021-06-22 00:00:06,880 epoch 10 - iter 18/33 - loss 0.25511509 - samples/sec: 68.13 - lr: 0.000030
2021-06-22 00:00:08,290 epoch 10 - iter 21/33 - loss 0.24964076 - samples/sec: 68.11 - lr: 0.000030
2021-06-22 00:00:09,682 epoch 10 - iter 24/33 - loss 0.25429136 - samples/sec: 69.02 - lr: 0.000030
2021-06-22 00:00:11,033 epoch 10 - iter 27/33 - loss 0.25055166 - samples/sec: 71.06 - lr: 0.000030
2021-06-22 00:00:12,442 epoch 10 - iter 30/33 - loss 0.25701709 - samples/sec: 68.18 - lr: 0.000030
2021-06-22 00:00:13,741 epoch 10 - iter 33/33 - loss 0.25833374 - samples/sec: 73.92 - lr: 0.000030
2021-06-22 00:00:13,741 ----------------------------------------------------------------------------------------------------
2021-06-22 00:00:13,742 EPOCH 10 done: loss 0.2583 - lr 0.0000300
2021-06-22 00:00:15,644 DEV : loss 0.20107004046440125 - score 0.9647
2021-06-22 00:00:15,670 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:00:20,740 ----------------------------------------------------------------------------------------------------
2021-06-22 00:00:22,106 epoch 11 - iter 3/33 - loss 0.19553360 - samples/sec: 70.34 - lr: 0.000030
2021-06-22 00:00:23,517 epoch 11 - iter 6/33 - loss 0.21409077 - samples/sec: 68.07 - lr: 0.000030
2021-06-22 00:00:24,928 epoch 11 - iter 9/33 - loss 0.22165438 - samples/sec: 68.03 - lr: 0.000030
2021-06-22 00:00:26,340 epoch 11 - iter 12/33 - loss 0.21278916 - samples/sec: 68.01 - lr: 0.000030
2021-06-22 00:00:27,738 epoch 11 - iter 15/33 - loss 0.19779659 - samples/sec: 68.73 - lr: 0.000030
2021-06-22 00:00:29,142 epoch 11 - iter 18/33 - loss 0.20559492 - samples/sec: 68.36 - lr: 0.000030
2021-06-22 00:00:30,546 epoch 11 - iter 21/33 - loss 0.20221842 - samples/sec: 68.40 - lr: 0.000030
2021-06-22 00:00:31,968 epoch 11 - iter 24/33 - loss 0.19979101 - samples/sec: 67.55 - lr: 0.000030
2021-06-22 00:00:33,372 epoch 11 - iter 27/33 - loss 0.20176357 - samples/sec: 68.39 - lr: 0.000030
2021-06-22 00:00:34,795 epoch 11 - iter 30/33 - loss 0.20693069 - samples/sec: 67.50 - lr: 0.000030
2021-06-22 00:00:36,044 epoch 11 - iter 33/33 - loss 0.20358936 - samples/sec: 76.89 - lr: 0.000030
2021-06-22 00:00:36,044 ----------------------------------------------------------------------------------------------------
2021-06-22 00:00:36,045 EPOCH 11 done: loss 0.2036 - lr 0.0000300
2021-06-22 00:00:38,097 DEV : loss 0.1877976953983307 - score 0.9659
2021-06-22 00:00:38,123 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:00:43,148 ----------------------------------------------------------------------------------------------------
2021-06-22 00:00:44,528 epoch 12 - iter 3/33 - loss 0.21890627 - samples/sec: 69.65 - lr: 0.000030
2021-06-22 00:00:45,931 epoch 12 - iter 6/33 - loss 0.21199451 - samples/sec: 68.42 - lr: 0.000030
2021-06-22 00:00:47,365 epoch 12 - iter 9/33 - loss 0.19897288 - samples/sec: 66.97 - lr: 0.000030
2021-06-22 00:00:48,801 epoch 12 - iter 12/33 - loss 0.19330632 - samples/sec: 66.90 - lr: 0.000030
2021-06-22 00:00:50,179 epoch 12 - iter 15/33 - loss 0.18671123 - samples/sec: 69.69 - lr: 0.000030
2021-06-22 00:00:51,611 epoch 12 - iter 18/33 - loss 0.18585757 - samples/sec: 67.05 - lr: 0.000030
2021-06-22 00:00:53,018 epoch 12 - iter 21/33 - loss 0.18284761 - samples/sec: 68.27 - lr: 0.000030
2021-06-22 00:00:54,393 epoch 12 - iter 24/33 - loss 0.17924842 - samples/sec: 69.82 - lr: 0.000030
2021-06-22 00:00:55,800 epoch 12 - iter 27/33 - loss 0.17744618 - samples/sec: 68.25 - lr: 0.000030
2021-06-22 00:00:57,205 epoch 12 - iter 30/33 - loss 0.17884663 - samples/sec: 68.38 - lr: 0.000030
2021-06-22 00:00:58,465 epoch 12 - iter 33/33 - loss 0.18189913 - samples/sec: 76.23 - lr: 0.000030
2021-06-22 00:00:58,465 ----------------------------------------------------------------------------------------------------
2021-06-22 00:00:58,465 EPOCH 12 done: loss 0.1819 - lr 0.0000300
2021-06-22 00:01:00,370 DEV : loss 0.18132641911506653 - score 0.966
2021-06-22 00:01:00,396 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:01:05,556 ----------------------------------------------------------------------------------------------------
2021-06-22 00:01:06,969 epoch 13 - iter 3/33 - loss 0.20802989 - samples/sec: 67.96 - lr: 0.000030
2021-06-22 00:01:08,378 epoch 13 - iter 6/33 - loss 0.16071879 - samples/sec: 68.15 - lr: 0.000030
2021-06-22 00:01:09,752 epoch 13 - iter 9/33 - loss 0.17397261 - samples/sec: 69.94 - lr: 0.000030
2021-06-22 00:01:11,168 epoch 13 - iter 12/33 - loss 0.16947881 - samples/sec: 67.79 - lr: 0.000030
2021-06-22 00:01:12,566 epoch 13 - iter 15/33 - loss 0.16178301 - samples/sec: 68.71 - lr: 0.000030
2021-06-22 00:01:13,973 epoch 13 - iter 18/33 - loss 0.16420775 - samples/sec: 68.23 - lr: 0.000030
2021-06-22 00:01:15,369 epoch 13 - iter 21/33 - loss 0.17574776 - samples/sec: 68.83 - lr: 0.000030
2021-06-22 00:01:16,789 epoch 13 - iter 24/33 - loss 0.17678372 - samples/sec: 67.59 - lr: 0.000030
2021-06-22 00:01:18,190 epoch 13 - iter 27/33 - loss 0.18754828 - samples/sec: 68.55 - lr: 0.000030
2021-06-22 00:01:19,597 epoch 13 - iter 30/33 - loss 0.18612135 - samples/sec: 68.30 - lr: 0.000030
2021-06-22 00:01:20,874 epoch 13 - iter 33/33 - loss 0.18596616 - samples/sec: 75.17 - lr: 0.000030
2021-06-22 00:01:20,875 ----------------------------------------------------------------------------------------------------
2021-06-22 00:01:20,875 EPOCH 13 done: loss 0.1860 - lr 0.0000300
2021-06-22 00:01:22,779 DEV : loss 0.1723918914794922 - score 0.9674
2021-06-22 00:01:22,805 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:01:27,879 ----------------------------------------------------------------------------------------------------
2021-06-22 00:01:29,270 epoch 14 - iter 3/33 - loss 0.22084388 - samples/sec: 69.08 - lr: 0.000030
2021-06-22 00:01:30,670 epoch 14 - iter 6/33 - loss 0.16761905 - samples/sec: 68.61 - lr: 0.000030
2021-06-22 00:01:32,069 epoch 14 - iter 9/33 - loss 0.16980376 - samples/sec: 68.62 - lr: 0.000030
2021-06-22 00:01:33,450 epoch 14 - iter 12/33 - loss 0.15990999 - samples/sec: 69.53 - lr: 0.000030
2021-06-22 00:01:34,869 epoch 14 - iter 15/33 - loss 0.16022681 - samples/sec: 67.70 - lr: 0.000030
2021-06-22 00:01:36,264 epoch 14 - iter 18/33 - loss 0.15708622 - samples/sec: 68.82 - lr: 0.000030
2021-06-22 00:01:37,677 epoch 14 - iter 21/33 - loss 0.15063344 - samples/sec: 67.98 - lr: 0.000030
2021-06-22 00:01:39,086 epoch 14 - iter 24/33 - loss 0.14860970 - samples/sec: 68.15 - lr: 0.000030
2021-06-22 00:01:40,497 epoch 14 - iter 27/33 - loss 0.14637322 - samples/sec: 68.08 - lr: 0.000030
2021-06-22 00:01:41,913 epoch 14 - iter 30/33 - loss 0.14817165 - samples/sec: 67.80 - lr: 0.000030
2021-06-22 00:01:43,205 epoch 14 - iter 33/33 - loss 0.15206851 - samples/sec: 74.37 - lr: 0.000030
2021-06-22 00:01:43,205 ----------------------------------------------------------------------------------------------------
2021-06-22 00:01:43,205 EPOCH 14 done: loss 0.1521 - lr 0.0000300
2021-06-22 00:01:45,255 DEV : loss 0.16592761874198914 - score 0.97
2021-06-22 00:01:45,281 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:01:50,253 ----------------------------------------------------------------------------------------------------
2021-06-22 00:01:51,660 epoch 15 - iter 3/33 - loss 0.15166140 - samples/sec: 68.29 - lr: 0.000030
2021-06-22 00:01:53,070 epoch 15 - iter 6/33 - loss 0.17633470 - samples/sec: 68.11 - lr: 0.000030
2021-06-22 00:01:54,460 epoch 15 - iter 9/33 - loss 0.16248360 - samples/sec: 69.10 - lr: 0.000030
2021-06-22 00:01:55,847 epoch 15 - iter 12/33 - loss 0.15475759 - samples/sec: 69.22 - lr: 0.000030
2021-06-22 00:01:57,276 epoch 15 - iter 15/33 - loss 0.16682281 - samples/sec: 67.22 - lr: 0.000030
2021-06-22 00:01:58,676 epoch 15 - iter 18/33 - loss 0.16824091 - samples/sec: 68.59 - lr: 0.000030
2021-06-22 00:02:00,102 epoch 15 - iter 21/33 - loss 0.16631624 - samples/sec: 67.32 - lr: 0.000030
2021-06-22 00:02:01,518 epoch 15 - iter 24/33 - loss 0.16292722 - samples/sec: 67.85 - lr: 0.000030
2021-06-22 00:02:02,913 epoch 15 - iter 27/33 - loss 0.16170524 - samples/sec: 68.80 - lr: 0.000030
2021-06-22 00:02:04,321 epoch 15 - iter 30/33 - loss 0.16004910 - samples/sec: 68.22 - lr: 0.000030
2021-06-22 00:02:05,588 epoch 15 - iter 33/33 - loss 0.15900686 - samples/sec: 75.83 - lr: 0.000030
2021-06-22 00:02:05,588 ----------------------------------------------------------------------------------------------------
2021-06-22 00:02:05,588 EPOCH 15 done: loss 0.1590 - lr 0.0000300
2021-06-22 00:02:07,493 DEV : loss 0.16176149249076843 - score 0.97
2021-06-22 00:02:07,518 BAD EPOCHS (no improvement): 1
2021-06-22 00:02:07,519 ----------------------------------------------------------------------------------------------------
2021-06-22 00:02:08,935 epoch 16 - iter 3/33 - loss 0.14446998 - samples/sec: 67.80 - lr: 0.000030
2021-06-22 00:02:10,314 epoch 16 - iter 6/33 - loss 0.17372303 - samples/sec: 69.63 - lr: 0.000030
2021-06-22 00:02:11,726 epoch 16 - iter 9/33 - loss 0.15008697 - samples/sec: 68.03 - lr: 0.000030
2021-06-22 00:02:13,134 epoch 16 - iter 12/33 - loss 0.13240952 - samples/sec: 68.20 - lr: 0.000030
2021-06-22 00:02:14,578 epoch 16 - iter 15/33 - loss 0.13534047 - samples/sec: 66.53 - lr: 0.000030
2021-06-22 00:02:15,963 epoch 16 - iter 18/33 - loss 0.14668368 - samples/sec: 69.32 - lr: 0.000030
2021-06-22 00:02:17,370 epoch 16 - iter 21/33 - loss 0.14471552 - samples/sec: 68.23 - lr: 0.000030
2021-06-22 00:02:18,781 epoch 16 - iter 24/33 - loss 0.14182523 - samples/sec: 68.08 - lr: 0.000030
2021-06-22 00:02:20,167 epoch 16 - iter 27/33 - loss 0.14180801 - samples/sec: 69.30 - lr: 0.000030
2021-06-22 00:02:21,554 epoch 16 - iter 30/33 - loss 0.14373514 - samples/sec: 69.24 - lr: 0.000030
2021-06-22 00:02:22,822 epoch 16 - iter 33/33 - loss 0.14204649 - samples/sec: 75.71 - lr: 0.000030
2021-06-22 00:02:22,823 ----------------------------------------------------------------------------------------------------
2021-06-22 00:02:22,823 EPOCH 16 done: loss 0.1420 - lr 0.0000300
2021-06-22 00:02:24,726 DEV : loss 0.15772050619125366 - score 0.9713
2021-06-22 00:02:24,752 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:02:30,022 ----------------------------------------------------------------------------------------------------
2021-06-22 00:02:31,433 epoch 17 - iter 3/33 - loss 0.12028291 - samples/sec: 68.08 - lr: 0.000030
2021-06-22 00:02:32,851 epoch 17 - iter 6/33 - loss 0.12003163 - samples/sec: 67.74 - lr: 0.000030
2021-06-22 00:02:34,275 epoch 17 - iter 9/33 - loss 0.12375177 - samples/sec: 67.42 - lr: 0.000030
2021-06-22 00:02:35,690 epoch 17 - iter 12/33 - loss 0.11627077 - samples/sec: 67.87 - lr: 0.000030
2021-06-22 00:02:37,093 epoch 17 - iter 15/33 - loss 0.11329086 - samples/sec: 68.47 - lr: 0.000030
2021-06-22 00:02:38,498 epoch 17 - iter 18/33 - loss 0.11856101 - samples/sec: 68.37 - lr: 0.000030
2021-06-22 00:02:39,896 epoch 17 - iter 21/33 - loss 0.12019884 - samples/sec: 68.68 - lr: 0.000030
2021-06-22 00:02:41,300 epoch 17 - iter 24/33 - loss 0.12406963 - samples/sec: 68.38 - lr: 0.000030
2021-06-22 00:02:42,720 epoch 17 - iter 27/33 - loss 0.12230506 - samples/sec: 67.64 - lr: 0.000030
2021-06-22 00:02:44,101 epoch 17 - iter 30/33 - loss 0.11847917 - samples/sec: 69.56 - lr: 0.000030
2021-06-22 00:02:45,356 epoch 17 - iter 33/33 - loss 0.11664251 - samples/sec: 76.49 - lr: 0.000030
2021-06-22 00:02:45,357 ----------------------------------------------------------------------------------------------------
2021-06-22 00:02:45,357 EPOCH 17 done: loss 0.1166 - lr 0.0000300
2021-06-22 00:02:47,260 DEV : loss 0.1599629819393158 - score 0.9688
2021-06-22 00:02:47,286 BAD EPOCHS (no improvement): 1
2021-06-22 00:02:47,286 ----------------------------------------------------------------------------------------------------
2021-06-22 00:02:48,700 epoch 18 - iter 3/33 - loss 0.16721940 - samples/sec: 67.91 - lr: 0.000030
2021-06-22 00:02:50,246 epoch 18 - iter 6/33 - loss 0.13568026 - samples/sec: 62.14 - lr: 0.000030
2021-06-22 00:02:51,641 epoch 18 - iter 9/33 - loss 0.14221489 - samples/sec: 68.84 - lr: 0.000030
2021-06-22 00:02:53,019 epoch 18 - iter 12/33 - loss 0.14355674 - samples/sec: 69.68 - lr: 0.000030
2021-06-22 00:02:54,426 epoch 18 - iter 15/33 - loss 0.13469625 - samples/sec: 68.25 - lr: 0.000030
2021-06-22 00:02:55,851 epoch 18 - iter 18/33 - loss 0.13175112 - samples/sec: 67.43 - lr: 0.000030
2021-06-22 00:02:57,278 epoch 18 - iter 21/33 - loss 0.14129268 - samples/sec: 67.29 - lr: 0.000030
2021-06-22 00:02:58,655 epoch 18 - iter 24/33 - loss 0.13452044 - samples/sec: 69.74 - lr: 0.000030
2021-06-22 00:03:00,068 epoch 18 - iter 27/33 - loss 0.12994723 - samples/sec: 67.95 - lr: 0.000030
2021-06-22 00:03:01,463 epoch 18 - iter 30/33 - loss 0.12479139 - samples/sec: 68.86 - lr: 0.000030
2021-06-22 00:03:02,746 epoch 18 - iter 33/33 - loss 0.12220972 - samples/sec: 74.86 - lr: 0.000030
2021-06-22 00:03:02,746 ----------------------------------------------------------------------------------------------------
2021-06-22 00:03:02,746 EPOCH 18 done: loss 0.1222 - lr 0.0000300
2021-06-22 00:03:04,647 DEV : loss 0.1541166752576828 - score 0.9714
2021-06-22 00:03:04,673 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:03:09,849 ----------------------------------------------------------------------------------------------------
2021-06-22 00:03:11,246 epoch 19 - iter 3/33 - loss 0.08251858 - samples/sec: 68.78 - lr: 0.000030
2021-06-22 00:03:12,614 epoch 19 - iter 6/33 - loss 0.09477188 - samples/sec: 70.21 - lr: 0.000030
2021-06-22 00:03:14,018 epoch 19 - iter 9/33 - loss 0.10412293 - samples/sec: 68.37 - lr: 0.000030
2021-06-22 00:03:15,444 epoch 19 - iter 12/33 - loss 0.10339028 - samples/sec: 67.36 - lr: 0.000030
2021-06-22 00:03:16,821 epoch 19 - iter 15/33 - loss 0.10790009 - samples/sec: 69.74 - lr: 0.000030
2021-06-22 00:03:18,244 epoch 19 - iter 18/33 - loss 0.11788181 - samples/sec: 67.49 - lr: 0.000030
2021-06-22 00:03:19,649 epoch 19 - iter 21/33 - loss 0.11487871 - samples/sec: 68.31 - lr: 0.000030
2021-06-22 00:03:21,068 epoch 19 - iter 24/33 - loss 0.11267023 - samples/sec: 67.70 - lr: 0.000030
2021-06-22 00:03:22,466 epoch 19 - iter 27/33 - loss 0.11502051 - samples/sec: 68.70 - lr: 0.000030
2021-06-22 00:03:23,881 epoch 19 - iter 30/33 - loss 0.11559104 - samples/sec: 67.88 - lr: 0.000030
2021-06-22 00:03:25,166 epoch 19 - iter 33/33 - loss 0.11459333 - samples/sec: 74.74 - lr: 0.000030
2021-06-22 00:03:25,166 ----------------------------------------------------------------------------------------------------
2021-06-22 00:03:25,166 EPOCH 19 done: loss 0.1146 - lr 0.0000300
2021-06-22 00:03:27,065 DEV : loss 0.1515955775976181 - score 0.973
2021-06-22 00:03:27,091 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:03:32,265 ----------------------------------------------------------------------------------------------------
2021-06-22 00:03:33,685 epoch 20 - iter 3/33 - loss 0.08549356 - samples/sec: 67.63 - lr: 0.000030
2021-06-22 00:03:35,114 epoch 20 - iter 6/33 - loss 0.11499919 - samples/sec: 67.19 - lr: 0.000030
2021-06-22 00:03:36,528 epoch 20 - iter 9/33 - loss 0.09669849 - samples/sec: 67.96 - lr: 0.000030
2021-06-22 00:03:37,943 epoch 20 - iter 12/33 - loss 0.09592196 - samples/sec: 67.83 - lr: 0.000030
2021-06-22 00:03:39,370 epoch 20 - iter 15/33 - loss 0.10094661 - samples/sec: 67.32 - lr: 0.000030
2021-06-22 00:03:40,739 epoch 20 - iter 18/33 - loss 0.09410854 - samples/sec: 70.14 - lr: 0.000030
2021-06-22 00:03:42,147 epoch 20 - iter 21/33 - loss 0.09900822 - samples/sec: 68.22 - lr: 0.000030
2021-06-22 00:03:43,573 epoch 20 - iter 24/33 - loss 0.09439593 - samples/sec: 67.33 - lr: 0.000030
2021-06-22 00:03:44,996 epoch 20 - iter 27/33 - loss 0.10352708 - samples/sec: 67.50 - lr: 0.000030
2021-06-22 00:03:46,415 epoch 20 - iter 30/33 - loss 0.10184094 - samples/sec: 67.66 - lr: 0.000030
2021-06-22 00:03:47,689 epoch 20 - iter 33/33 - loss 0.10727617 - samples/sec: 75.42 - lr: 0.000030
2021-06-22 00:03:47,689 ----------------------------------------------------------------------------------------------------
2021-06-22 00:03:47,689 EPOCH 20 done: loss 0.1073 - lr 0.0000300
2021-06-22 00:03:49,599 DEV : loss 0.1513354629278183 - score 0.973
2021-06-22 00:03:49,626 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:03:54,748 ----------------------------------------------------------------------------------------------------
2021-06-22 00:03:56,168 epoch 21 - iter 3/33 - loss 0.08873955 - samples/sec: 67.65 - lr: 0.000030
2021-06-22 00:03:57,597 epoch 21 - iter 6/33 - loss 0.09781507 - samples/sec: 67.23 - lr: 0.000030
2021-06-22 00:03:59,005 epoch 21 - iter 9/33 - loss 0.08897412 - samples/sec: 68.18 - lr: 0.000030
2021-06-22 00:04:00,413 epoch 21 - iter 12/33 - loss 0.10120073 - samples/sec: 68.20 - lr: 0.000030
2021-06-22 00:04:01,831 epoch 21 - iter 15/33 - loss 0.09748980 - samples/sec: 67.75 - lr: 0.000030
2021-06-22 00:04:03,231 epoch 21 - iter 18/33 - loss 0.09147391 - samples/sec: 68.56 - lr: 0.000030
2021-06-22 00:04:04,672 epoch 21 - iter 21/33 - loss 0.09156991 - samples/sec: 66.65 - lr: 0.000030
2021-06-22 00:04:06,088 epoch 21 - iter 24/33 - loss 0.09774706 - samples/sec: 67.86 - lr: 0.000030
2021-06-22 00:04:07,503 epoch 21 - iter 27/33 - loss 0.10486856 - samples/sec: 67.86 - lr: 0.000030
2021-06-22 00:04:08,906 epoch 21 - iter 30/33 - loss 0.09910697 - samples/sec: 68.46 - lr: 0.000030
2021-06-22 00:04:10,182 epoch 21 - iter 33/33 - loss 0.09689376 - samples/sec: 75.28 - lr: 0.000030
2021-06-22 00:04:10,182 ----------------------------------------------------------------------------------------------------
2021-06-22 00:04:10,182 EPOCH 21 done: loss 0.0969 - lr 0.0000300
2021-06-22 00:04:12,240 DEV : loss 0.14560994505882263 - score 0.9716
2021-06-22 00:04:12,266 BAD EPOCHS (no improvement): 1
2021-06-22 00:04:12,266 ----------------------------------------------------------------------------------------------------
2021-06-22 00:04:13,695 epoch 22 - iter 3/33 - loss 0.16866708 - samples/sec: 67.22 - lr: 0.000030
2021-06-22 00:04:15,118 epoch 22 - iter 6/33 - loss 0.13873222 - samples/sec: 67.51 - lr: 0.000030
2021-06-22 00:04:16,534 epoch 22 - iter 9/33 - loss 0.12034899 - samples/sec: 67.79 - lr: 0.000030
2021-06-22 00:04:17,914 epoch 22 - iter 12/33 - loss 0.12037331 - samples/sec: 69.59 - lr: 0.000030
2021-06-22 00:04:19,352 epoch 22 - iter 15/33 - loss 0.11305035 - samples/sec: 66.80 - lr: 0.000030
2021-06-22 00:04:20,773 epoch 22 - iter 18/33 - loss 0.11125973 - samples/sec: 67.56 - lr: 0.000030
2021-06-22 00:04:22,191 epoch 22 - iter 21/33 - loss 0.11243830 - samples/sec: 67.72 - lr: 0.000030
2021-06-22 00:04:23,622 epoch 22 - iter 24/33 - loss 0.11337133 - samples/sec: 67.13 - lr: 0.000030
2021-06-22 00:04:25,046 epoch 22 - iter 27/33 - loss 0.11615371 - samples/sec: 67.45 - lr: 0.000030
2021-06-22 00:04:26,400 epoch 22 - iter 30/33 - loss 0.11385767 - samples/sec: 70.90 - lr: 0.000030
2021-06-22 00:04:27,693 epoch 22 - iter 33/33 - loss 0.11754009 - samples/sec: 74.27 - lr: 0.000030
2021-06-22 00:04:27,694 ----------------------------------------------------------------------------------------------------
2021-06-22 00:04:27,694 EPOCH 22 done: loss 0.1175 - lr 0.0000300
2021-06-22 00:04:29,602 DEV : loss 0.1471976339817047 - score 0.973
2021-06-22 00:04:29,628 BAD EPOCHS (no improvement): 2
2021-06-22 00:04:29,628 ----------------------------------------------------------------------------------------------------
2021-06-22 00:04:31,055 epoch 23 - iter 3/33 - loss 0.09572566 - samples/sec: 67.32 - lr: 0.000030
2021-06-22 00:04:32,448 epoch 23 - iter 6/33 - loss 0.10528771 - samples/sec: 68.90 - lr: 0.000030
2021-06-22 00:04:33,854 epoch 23 - iter 9/33 - loss 0.10673083 - samples/sec: 68.35 - lr: 0.000030
2021-06-22 00:04:35,279 epoch 23 - iter 12/33 - loss 0.10508784 - samples/sec: 67.35 - lr: 0.000030
2021-06-22 00:04:36,685 epoch 23 - iter 15/33 - loss 0.09588256 - samples/sec: 68.33 - lr: 0.000030
2021-06-22 00:04:38,082 epoch 23 - iter 18/33 - loss 0.09070201 - samples/sec: 68.76 - lr: 0.000030
2021-06-22 00:04:39,500 epoch 23 - iter 21/33 - loss 0.10193724 - samples/sec: 67.72 - lr: 0.000030
2021-06-22 00:04:40,915 epoch 23 - iter 24/33 - loss 0.10624181 - samples/sec: 67.84 - lr: 0.000030
2021-06-22 00:04:42,338 epoch 23 - iter 27/33 - loss 0.10330860 - samples/sec: 67.51 - lr: 0.000030
2021-06-22 00:04:43,755 epoch 23 - iter 30/33 - loss 0.10527866 - samples/sec: 67.75 - lr: 0.000030
2021-06-22 00:04:45,020 epoch 23 - iter 33/33 - loss 0.10201721 - samples/sec: 75.91 - lr: 0.000030
2021-06-22 00:04:45,021 ----------------------------------------------------------------------------------------------------
2021-06-22 00:04:45,021 EPOCH 23 done: loss 0.1020 - lr 0.0000300
2021-06-22 00:04:46,932 DEV : loss 0.14783161878585815 - score 0.9745
2021-06-22 00:04:46,959 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:04:52,039 ----------------------------------------------------------------------------------------------------
2021-06-22 00:04:53,447 epoch 24 - iter 3/33 - loss 0.08471914 - samples/sec: 68.20 - lr: 0.000030
2021-06-22 00:04:54,859 epoch 24 - iter 6/33 - loss 0.10528547 - samples/sec: 68.03 - lr: 0.000030
2021-06-22 00:04:56,242 epoch 24 - iter 9/33 - loss 0.11083666 - samples/sec: 69.41 - lr: 0.000030
2021-06-22 00:04:57,662 epoch 24 - iter 12/33 - loss 0.10378934 - samples/sec: 67.64 - lr: 0.000030
2021-06-22 00:04:59,062 epoch 24 - iter 15/33 - loss 0.09805570 - samples/sec: 68.61 - lr: 0.000030
2021-06-22 00:05:00,488 epoch 24 - iter 18/33 - loss 0.09305922 - samples/sec: 67.36 - lr: 0.000030
2021-06-22 00:05:01,890 epoch 24 - iter 21/33 - loss 0.09496354 - samples/sec: 68.50 - lr: 0.000030
2021-06-22 00:05:03,317 epoch 24 - iter 24/33 - loss 0.09110410 - samples/sec: 67.28 - lr: 0.000030
2021-06-22 00:05:04,716 epoch 24 - iter 27/33 - loss 0.09157688 - samples/sec: 68.67 - lr: 0.000030
2021-06-22 00:05:06,147 epoch 24 - iter 30/33 - loss 0.08860109 - samples/sec: 67.08 - lr: 0.000030
2021-06-22 00:05:07,424 epoch 24 - iter 33/33 - loss 0.08706618 - samples/sec: 75.24 - lr: 0.000030
2021-06-22 00:05:07,424 ----------------------------------------------------------------------------------------------------
2021-06-22 00:05:07,424 EPOCH 24 done: loss 0.0871 - lr 0.0000300
2021-06-22 00:05:09,485 DEV : loss 0.14125820994377136 - score 0.9744
2021-06-22 00:05:09,511 BAD EPOCHS (no improvement): 1
2021-06-22 00:05:09,512 ----------------------------------------------------------------------------------------------------
2021-06-22 00:05:10,927 epoch 25 - iter 3/33 - loss 0.05435514 - samples/sec: 67.83 - lr: 0.000030
2021-06-22 00:05:12,364 epoch 25 - iter 6/33 - loss 0.04714159 - samples/sec: 66.85 - lr: 0.000030
2021-06-22 00:05:13,779 epoch 25 - iter 9/33 - loss 0.05154694 - samples/sec: 67.88 - lr: 0.000030
2021-06-22 00:05:15,202 epoch 25 - iter 12/33 - loss 0.05410947 - samples/sec: 67.45 - lr: 0.000030
2021-06-22 00:05:16,623 epoch 25 - iter 15/33 - loss 0.06039350 - samples/sec: 67.61 - lr: 0.000030
2021-06-22 00:05:18,042 epoch 25 - iter 18/33 - loss 0.06622307 - samples/sec: 67.68 - lr: 0.000030
2021-06-22 00:05:19,421 epoch 25 - iter 21/33 - loss 0.06623029 - samples/sec: 69.63 - lr: 0.000030
2021-06-22 00:05:20,833 epoch 25 - iter 24/33 - loss 0.06873024 - samples/sec: 67.99 - lr: 0.000030
2021-06-22 00:05:22,238 epoch 25 - iter 27/33 - loss 0.07347521 - samples/sec: 68.37 - lr: 0.000030
2021-06-22 00:05:23,636 epoch 25 - iter 30/33 - loss 0.07435845 - samples/sec: 68.72 - lr: 0.000030
2021-06-22 00:05:24,897 epoch 25 - iter 33/33 - loss 0.07874366 - samples/sec: 76.14 - lr: 0.000030
2021-06-22 00:05:24,898 ----------------------------------------------------------------------------------------------------
2021-06-22 00:05:24,898 EPOCH 25 done: loss 0.0787 - lr 0.0000300
2021-06-22 00:05:26,791 DEV : loss 0.13613958656787872 - score 0.9757
2021-06-22 00:05:26,817 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:05:31,946 ----------------------------------------------------------------------------------------------------
2021-06-22 00:05:33,356 epoch 26 - iter 3/33 - loss 0.08970823 - samples/sec: 68.15 - lr: 0.000030
2021-06-22 00:05:34,733 epoch 26 - iter 6/33 - loss 0.09772649 - samples/sec: 69.76 - lr: 0.000030
2021-06-22 00:05:36,145 epoch 26 - iter 9/33 - loss 0.09468870 - samples/sec: 67.99 - lr: 0.000030
2021-06-22 00:05:37,566 epoch 26 - iter 12/33 - loss 0.08889709 - samples/sec: 67.58 - lr: 0.000030
2021-06-22 00:05:38,970 epoch 26 - iter 15/33 - loss 0.08635440 - samples/sec: 68.39 - lr: 0.000030
2021-06-22 00:05:40,371 epoch 26 - iter 18/33 - loss 0.08487597 - samples/sec: 68.58 - lr: 0.000030
2021-06-22 00:05:41,774 epoch 26 - iter 21/33 - loss 0.08224756 - samples/sec: 68.41 - lr: 0.000030
2021-06-22 00:05:43,189 epoch 26 - iter 24/33 - loss 0.08202404 - samples/sec: 67.91 - lr: 0.000030
2021-06-22 00:05:44,594 epoch 26 - iter 27/33 - loss 0.07874975 - samples/sec: 68.32 - lr: 0.000030
2021-06-22 00:05:46,029 epoch 26 - iter 30/33 - loss 0.07681398 - samples/sec: 66.95 - lr: 0.000030
2021-06-22 00:05:47,322 epoch 26 - iter 33/33 - loss 0.08028672 - samples/sec: 74.26 - lr: 0.000030
2021-06-22 00:05:47,322 ----------------------------------------------------------------------------------------------------
2021-06-22 00:05:47,323 EPOCH 26 done: loss 0.0803 - lr 0.0000300
2021-06-22 00:05:49,220 DEV : loss 0.13575808703899384 - score 0.9744
2021-06-22 00:05:49,246 BAD EPOCHS (no improvement): 1
2021-06-22 00:05:49,246 ----------------------------------------------------------------------------------------------------
2021-06-22 00:05:50,650 epoch 27 - iter 3/33 - loss 0.07012594 - samples/sec: 68.40 - lr: 0.000030
2021-06-22 00:05:52,082 epoch 27 - iter 6/33 - loss 0.07464951 - samples/sec: 67.09 - lr: 0.000030
2021-06-22 00:05:53,490 epoch 27 - iter 9/33 - loss 0.07690978 - samples/sec: 68.18 - lr: 0.000030
2021-06-22 00:05:54,905 epoch 27 - iter 12/33 - loss 0.07827030 - samples/sec: 67.87 - lr: 0.000030
2021-06-22 00:05:56,303 epoch 27 - iter 15/33 - loss 0.07985667 - samples/sec: 68.70 - lr: 0.000030
2021-06-22 00:05:57,742 epoch 27 - iter 18/33 - loss 0.08232857 - samples/sec: 66.72 - lr: 0.000030
2021-06-22 00:05:59,121 epoch 27 - iter 21/33 - loss 0.07766831 - samples/sec: 69.65 - lr: 0.000030
2021-06-22 00:06:00,540 epoch 27 - iter 24/33 - loss 0.07329377 - samples/sec: 67.70 - lr: 0.000030
2021-06-22 00:06:01,983 epoch 27 - iter 27/33 - loss 0.07971786 - samples/sec: 66.54 - lr: 0.000030
2021-06-22 00:06:03,400 epoch 27 - iter 30/33 - loss 0.08258440 - samples/sec: 67.76 - lr: 0.000030
2021-06-22 00:06:04,655 epoch 27 - iter 33/33 - loss 0.07968157 - samples/sec: 76.54 - lr: 0.000030
2021-06-22 00:06:04,655 ----------------------------------------------------------------------------------------------------
2021-06-22 00:06:04,655 EPOCH 27 done: loss 0.0797 - lr 0.0000300
2021-06-22 00:06:06,552 DEV : loss 0.13444654643535614 - score 0.9757
2021-06-22 00:06:06,579 BAD EPOCHS (no improvement): 2
2021-06-22 00:06:06,579 ----------------------------------------------------------------------------------------------------
2021-06-22 00:06:08,122 epoch 28 - iter 3/33 - loss 0.07527274 - samples/sec: 62.24 - lr: 0.000030
2021-06-22 00:06:09,536 epoch 28 - iter 6/33 - loss 0.07550028 - samples/sec: 67.91 - lr: 0.000030
2021-06-22 00:06:10,946 epoch 28 - iter 9/33 - loss 0.07708862 - samples/sec: 68.13 - lr: 0.000030
2021-06-22 00:06:12,375 epoch 28 - iter 12/33 - loss 0.07093579 - samples/sec: 67.21 - lr: 0.000030
2021-06-22 00:06:13,800 epoch 28 - iter 15/33 - loss 0.08185837 - samples/sec: 67.39 - lr: 0.000030
2021-06-22 00:06:15,176 epoch 28 - iter 18/33 - loss 0.07585263 - samples/sec: 69.78 - lr: 0.000030
2021-06-22 00:06:16,610 epoch 28 - iter 21/33 - loss 0.08009624 - samples/sec: 66.95 - lr: 0.000030
2021-06-22 00:06:18,003 epoch 28 - iter 24/33 - loss 0.08134133 - samples/sec: 68.94 - lr: 0.000030
2021-06-22 00:06:19,392 epoch 28 - iter 27/33 - loss 0.07882809 - samples/sec: 69.18 - lr: 0.000030
2021-06-22 00:06:20,826 epoch 28 - iter 30/33 - loss 0.07831795 - samples/sec: 66.97 - lr: 0.000030
2021-06-22 00:06:22,151 epoch 28 - iter 33/33 - loss 0.07941300 - samples/sec: 72.43 - lr: 0.000030
2021-06-22 00:06:22,152 ----------------------------------------------------------------------------------------------------
2021-06-22 00:06:22,152 EPOCH 28 done: loss 0.0794 - lr 0.0000300
2021-06-22 00:06:24,048 DEV : loss 0.12998729944229126 - score 0.9756
2021-06-22 00:06:24,074 BAD EPOCHS (no improvement): 3
2021-06-22 00:06:24,075 ----------------------------------------------------------------------------------------------------
2021-06-22 00:06:25,482 epoch 29 - iter 3/33 - loss 0.05579245 - samples/sec: 68.26 - lr: 0.000030
2021-06-22 00:06:26,892 epoch 29 - iter 6/33 - loss 0.05837357 - samples/sec: 68.11 - lr: 0.000030
2021-06-22 00:06:28,310 epoch 29 - iter 9/33 - loss 0.06261517 - samples/sec: 67.70 - lr: 0.000030
2021-06-22 00:06:29,753 epoch 29 - iter 12/33 - loss 0.06158055 - samples/sec: 66.54 - lr: 0.000030
2021-06-22 00:06:31,154 epoch 29 - iter 15/33 - loss 0.06104514 - samples/sec: 68.59 - lr: 0.000030
2021-06-22 00:06:32,551 epoch 29 - iter 18/33 - loss 0.06279763 - samples/sec: 68.71 - lr: 0.000030
2021-06-22 00:06:33,993 epoch 29 - iter 21/33 - loss 0.06492909 - samples/sec: 66.62 - lr: 0.000030
2021-06-22 00:06:35,419 epoch 29 - iter 24/33 - loss 0.07033950 - samples/sec: 67.31 - lr: 0.000030
2021-06-22 00:06:36,838 epoch 29 - iter 27/33 - loss 0.06755054 - samples/sec: 67.69 - lr: 0.000030
2021-06-22 00:06:38,218 epoch 29 - iter 30/33 - loss 0.06911455 - samples/sec: 69.58 - lr: 0.000030
2021-06-22 00:06:39,485 epoch 29 - iter 33/33 - loss 0.06935757 - samples/sec: 75.83 - lr: 0.000030
2021-06-22 00:06:39,485 ----------------------------------------------------------------------------------------------------
2021-06-22 00:06:39,485 EPOCH 29 done: loss 0.0694 - lr 0.0000300
2021-06-22 00:06:41,388 DEV : loss 0.13457292318344116 - score 0.9744
Epoch    29: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 00:06:41,414 BAD EPOCHS (no improvement): 4
2021-06-22 00:06:41,414 ----------------------------------------------------------------------------------------------------
2021-06-22 00:06:42,822 epoch 30 - iter 3/33 - loss 0.06560679 - samples/sec: 68.23 - lr: 0.000015
2021-06-22 00:06:44,244 epoch 30 - iter 6/33 - loss 0.07661269 - samples/sec: 67.53 - lr: 0.000015
2021-06-22 00:06:45,659 epoch 30 - iter 9/33 - loss 0.06464939 - samples/sec: 67.89 - lr: 0.000015
2021-06-22 00:06:47,079 epoch 30 - iter 12/33 - loss 0.06577109 - samples/sec: 67.60 - lr: 0.000015
2021-06-22 00:06:48,501 epoch 30 - iter 15/33 - loss 0.06109702 - samples/sec: 67.53 - lr: 0.000015
2021-06-22 00:06:49,919 epoch 30 - iter 18/33 - loss 0.07064379 - samples/sec: 67.74 - lr: 0.000015
2021-06-22 00:06:51,323 epoch 30 - iter 21/33 - loss 0.07652820 - samples/sec: 68.37 - lr: 0.000015
2021-06-22 00:06:52,738 epoch 30 - iter 24/33 - loss 0.07882561 - samples/sec: 67.91 - lr: 0.000015
2021-06-22 00:06:54,107 epoch 30 - iter 27/33 - loss 0.07391324 - samples/sec: 70.11 - lr: 0.000015
2021-06-22 00:06:55,514 epoch 30 - iter 30/33 - loss 0.07070782 - samples/sec: 68.29 - lr: 0.000015
2021-06-22 00:06:56,800 epoch 30 - iter 33/33 - loss 0.07044708 - samples/sec: 74.65 - lr: 0.000015
2021-06-22 00:06:56,801 ----------------------------------------------------------------------------------------------------
2021-06-22 00:06:56,801 EPOCH 30 done: loss 0.0704 - lr 0.0000150
2021-06-22 00:06:58,701 DEV : loss 0.1325901746749878 - score 0.9743
2021-06-22 00:06:58,727 BAD EPOCHS (no improvement): 1
2021-06-22 00:06:58,727 ----------------------------------------------------------------------------------------------------
2021-06-22 00:07:00,285 epoch 31 - iter 3/33 - loss 0.06544475 - samples/sec: 61.65 - lr: 0.000015
2021-06-22 00:07:01,706 epoch 31 - iter 6/33 - loss 0.06319582 - samples/sec: 67.57 - lr: 0.000015
2021-06-22 00:07:03,112 epoch 31 - iter 9/33 - loss 0.06296672 - samples/sec: 68.29 - lr: 0.000015
2021-06-22 00:07:04,479 epoch 31 - iter 12/33 - loss 0.07136368 - samples/sec: 70.29 - lr: 0.000015
2021-06-22 00:07:05,875 epoch 31 - iter 15/33 - loss 0.07057018 - samples/sec: 68.79 - lr: 0.000015
2021-06-22 00:07:07,287 epoch 31 - iter 18/33 - loss 0.06907392 - samples/sec: 67.99 - lr: 0.000015
2021-06-22 00:07:08,688 epoch 31 - iter 21/33 - loss 0.06340369 - samples/sec: 68.54 - lr: 0.000015
2021-06-22 00:07:10,073 epoch 31 - iter 24/33 - loss 0.05958424 - samples/sec: 69.36 - lr: 0.000015
2021-06-22 00:07:11,457 epoch 31 - iter 27/33 - loss 0.05816774 - samples/sec: 69.39 - lr: 0.000015
2021-06-22 00:07:12,855 epoch 31 - iter 30/33 - loss 0.05942313 - samples/sec: 68.70 - lr: 0.000015
2021-06-22 00:07:14,109 epoch 31 - iter 33/33 - loss 0.06073743 - samples/sec: 76.55 - lr: 0.000015
2021-06-22 00:07:14,110 ----------------------------------------------------------------------------------------------------
2021-06-22 00:07:14,110 EPOCH 31 done: loss 0.0607 - lr 0.0000150
2021-06-22 00:07:16,014 DEV : loss 0.13169683516025543 - score 0.9729
2021-06-22 00:07:16,040 BAD EPOCHS (no improvement): 2
2021-06-22 00:07:16,041 ----------------------------------------------------------------------------------------------------
2021-06-22 00:07:17,405 epoch 32 - iter 3/33 - loss 0.04625845 - samples/sec: 70.41 - lr: 0.000015
2021-06-22 00:07:18,819 epoch 32 - iter 6/33 - loss 0.04188556 - samples/sec: 67.92 - lr: 0.000015
2021-06-22 00:07:20,201 epoch 32 - iter 9/33 - loss 0.04565543 - samples/sec: 69.48 - lr: 0.000015
2021-06-22 00:07:21,627 epoch 32 - iter 12/33 - loss 0.05525965 - samples/sec: 67.34 - lr: 0.000015
2021-06-22 00:07:23,055 epoch 32 - iter 15/33 - loss 0.05895773 - samples/sec: 67.27 - lr: 0.000015
2021-06-22 00:07:24,462 epoch 32 - iter 18/33 - loss 0.06594694 - samples/sec: 68.26 - lr: 0.000015
2021-06-22 00:07:25,877 epoch 32 - iter 21/33 - loss 0.07097680 - samples/sec: 67.86 - lr: 0.000015
2021-06-22 00:07:27,295 epoch 32 - iter 24/33 - loss 0.06761776 - samples/sec: 67.70 - lr: 0.000015
2021-06-22 00:07:28,710 epoch 32 - iter 27/33 - loss 0.06468463 - samples/sec: 67.86 - lr: 0.000015
2021-06-22 00:07:30,114 epoch 32 - iter 30/33 - loss 0.06454918 - samples/sec: 68.40 - lr: 0.000015
2021-06-22 00:07:31,398 epoch 32 - iter 33/33 - loss 0.06618451 - samples/sec: 74.83 - lr: 0.000015
2021-06-22 00:07:31,398 ----------------------------------------------------------------------------------------------------
2021-06-22 00:07:31,398 EPOCH 32 done: loss 0.0662 - lr 0.0000150
2021-06-22 00:07:33,299 DEV : loss 0.13028539717197418 - score 0.9742
2021-06-22 00:07:33,325 BAD EPOCHS (no improvement): 3
2021-06-22 00:07:33,326 ----------------------------------------------------------------------------------------------------
2021-06-22 00:07:34,753 epoch 33 - iter 3/33 - loss 0.05930060 - samples/sec: 67.30 - lr: 0.000015
2021-06-22 00:07:36,167 epoch 33 - iter 6/33 - loss 0.06415208 - samples/sec: 67.91 - lr: 0.000015
2021-06-22 00:07:37,566 epoch 33 - iter 9/33 - loss 0.06755432 - samples/sec: 68.62 - lr: 0.000015
2021-06-22 00:07:38,948 epoch 33 - iter 12/33 - loss 0.07417332 - samples/sec: 69.49 - lr: 0.000015
2021-06-22 00:07:40,369 epoch 33 - iter 15/33 - loss 0.07328227 - samples/sec: 67.59 - lr: 0.000015
2021-06-22 00:07:41,782 epoch 33 - iter 18/33 - loss 0.06963895 - samples/sec: 67.98 - lr: 0.000015
2021-06-22 00:07:43,159 epoch 33 - iter 21/33 - loss 0.07268577 - samples/sec: 69.74 - lr: 0.000015
2021-06-22 00:07:44,577 epoch 33 - iter 24/33 - loss 0.06891551 - samples/sec: 67.73 - lr: 0.000015
2021-06-22 00:07:45,991 epoch 33 - iter 27/33 - loss 0.06477946 - samples/sec: 67.90 - lr: 0.000015
2021-06-22 00:07:47,410 epoch 33 - iter 30/33 - loss 0.06139091 - samples/sec: 67.68 - lr: 0.000015
2021-06-22 00:07:48,708 epoch 33 - iter 33/33 - loss 0.05974173 - samples/sec: 73.99 - lr: 0.000015
2021-06-22 00:07:48,708 ----------------------------------------------------------------------------------------------------
2021-06-22 00:07:48,708 EPOCH 33 done: loss 0.0597 - lr 0.0000150
2021-06-22 00:07:50,611 DEV : loss 0.1234731525182724 - score 0.9771
2021-06-22 00:07:50,637 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:07:55,700 ----------------------------------------------------------------------------------------------------
2021-06-22 00:07:57,105 epoch 34 - iter 3/33 - loss 0.05209214 - samples/sec: 68.35 - lr: 0.000015
2021-06-22 00:07:58,522 epoch 34 - iter 6/33 - loss 0.04791339 - samples/sec: 67.79 - lr: 0.000015
2021-06-22 00:07:59,929 epoch 34 - iter 9/33 - loss 0.05337658 - samples/sec: 68.23 - lr: 0.000015
2021-06-22 00:08:01,359 epoch 34 - iter 12/33 - loss 0.05092367 - samples/sec: 67.18 - lr: 0.000015
2021-06-22 00:08:02,756 epoch 34 - iter 15/33 - loss 0.05127743 - samples/sec: 68.75 - lr: 0.000015
2021-06-22 00:08:04,167 epoch 34 - iter 18/33 - loss 0.04858469 - samples/sec: 68.07 - lr: 0.000015
2021-06-22 00:08:05,594 epoch 34 - iter 21/33 - loss 0.05055445 - samples/sec: 67.27 - lr: 0.000015
2021-06-22 00:08:06,987 epoch 34 - iter 24/33 - loss 0.05271036 - samples/sec: 68.97 - lr: 0.000015
2021-06-22 00:08:08,405 epoch 34 - iter 27/33 - loss 0.05251069 - samples/sec: 67.71 - lr: 0.000015
2021-06-22 00:08:09,967 epoch 34 - iter 30/33 - loss 0.05367023 - samples/sec: 61.48 - lr: 0.000015
2021-06-22 00:08:11,234 epoch 34 - iter 33/33 - loss 0.05536945 - samples/sec: 75.78 - lr: 0.000015
2021-06-22 00:08:11,234 ----------------------------------------------------------------------------------------------------
2021-06-22 00:08:11,235 EPOCH 34 done: loss 0.0554 - lr 0.0000150
2021-06-22 00:08:13,144 DEV : loss 0.12200185656547546 - score 0.9771
2021-06-22 00:08:13,170 BAD EPOCHS (no improvement): 1
2021-06-22 00:08:13,171 ----------------------------------------------------------------------------------------------------
2021-06-22 00:08:14,524 epoch 35 - iter 3/33 - loss 0.04421529 - samples/sec: 70.96 - lr: 0.000015
2021-06-22 00:08:15,929 epoch 35 - iter 6/33 - loss 0.04436631 - samples/sec: 68.35 - lr: 0.000015
2021-06-22 00:08:17,353 epoch 35 - iter 9/33 - loss 0.05354894 - samples/sec: 67.45 - lr: 0.000015
2021-06-22 00:08:18,734 epoch 35 - iter 12/33 - loss 0.05470936 - samples/sec: 69.54 - lr: 0.000015
2021-06-22 00:08:20,172 epoch 35 - iter 15/33 - loss 0.05368863 - samples/sec: 66.78 - lr: 0.000015
2021-06-22 00:08:21,611 epoch 35 - iter 18/33 - loss 0.05711657 - samples/sec: 66.73 - lr: 0.000015
2021-06-22 00:08:23,016 epoch 35 - iter 21/33 - loss 0.05517328 - samples/sec: 68.36 - lr: 0.000015
2021-06-22 00:08:24,422 epoch 35 - iter 24/33 - loss 0.05433118 - samples/sec: 68.28 - lr: 0.000015
2021-06-22 00:08:25,828 epoch 35 - iter 27/33 - loss 0.05184132 - samples/sec: 68.29 - lr: 0.000015
2021-06-22 00:08:27,248 epoch 35 - iter 30/33 - loss 0.05558975 - samples/sec: 67.65 - lr: 0.000015
2021-06-22 00:08:28,529 epoch 35 - iter 33/33 - loss 0.05407883 - samples/sec: 74.98 - lr: 0.000015
2021-06-22 00:08:28,529 ----------------------------------------------------------------------------------------------------
2021-06-22 00:08:28,529 EPOCH 35 done: loss 0.0541 - lr 0.0000150
2021-06-22 00:08:30,429 DEV : loss 0.12211456149816513 - score 0.9786
2021-06-22 00:08:30,456 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:08:35,490 ----------------------------------------------------------------------------------------------------
2021-06-22 00:08:36,889 epoch 36 - iter 3/33 - loss 0.08319481 - samples/sec: 68.63 - lr: 0.000015
2021-06-22 00:08:38,312 epoch 36 - iter 6/33 - loss 0.07047414 - samples/sec: 67.48 - lr: 0.000015
2021-06-22 00:08:39,730 epoch 36 - iter 9/33 - loss 0.05829568 - samples/sec: 67.74 - lr: 0.000015
2021-06-22 00:08:41,126 epoch 36 - iter 12/33 - loss 0.05056529 - samples/sec: 68.79 - lr: 0.000015
2021-06-22 00:08:42,546 epoch 36 - iter 15/33 - loss 0.04596565 - samples/sec: 67.65 - lr: 0.000015
2021-06-22 00:08:43,936 epoch 36 - iter 18/33 - loss 0.04473204 - samples/sec: 69.05 - lr: 0.000015
2021-06-22 00:08:45,331 epoch 36 - iter 21/33 - loss 0.05265266 - samples/sec: 68.84 - lr: 0.000015
2021-06-22 00:08:46,754 epoch 36 - iter 24/33 - loss 0.05738818 - samples/sec: 67.52 - lr: 0.000015
2021-06-22 00:08:48,176 epoch 36 - iter 27/33 - loss 0.06038498 - samples/sec: 67.51 - lr: 0.000015
2021-06-22 00:08:49,598 epoch 36 - iter 30/33 - loss 0.06362219 - samples/sec: 67.55 - lr: 0.000015
2021-06-22 00:08:50,891 epoch 36 - iter 33/33 - loss 0.06269879 - samples/sec: 74.24 - lr: 0.000015
2021-06-22 00:08:50,892 ----------------------------------------------------------------------------------------------------
2021-06-22 00:08:50,892 EPOCH 36 done: loss 0.0627 - lr 0.0000150
2021-06-22 00:08:52,795 DEV : loss 0.12523344159126282 - score 0.9787
2021-06-22 00:08:52,821 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:08:57,947 ----------------------------------------------------------------------------------------------------
2021-06-22 00:08:59,384 epoch 37 - iter 3/33 - loss 0.06579932 - samples/sec: 66.86 - lr: 0.000015
2021-06-22 00:09:00,814 epoch 37 - iter 6/33 - loss 0.07485251 - samples/sec: 67.20 - lr: 0.000015
2021-06-22 00:09:02,386 epoch 37 - iter 9/33 - loss 0.06601701 - samples/sec: 61.09 - lr: 0.000015
2021-06-22 00:09:03,784 epoch 37 - iter 12/33 - loss 0.05743278 - samples/sec: 68.66 - lr: 0.000015
2021-06-22 00:09:05,211 epoch 37 - iter 15/33 - loss 0.05316698 - samples/sec: 67.33 - lr: 0.000015
2021-06-22 00:09:06,624 epoch 37 - iter 18/33 - loss 0.05654094 - samples/sec: 67.93 - lr: 0.000015
2021-06-22 00:09:08,020 epoch 37 - iter 21/33 - loss 0.05838788 - samples/sec: 68.80 - lr: 0.000015
2021-06-22 00:09:09,427 epoch 37 - iter 24/33 - loss 0.06036011 - samples/sec: 68.28 - lr: 0.000015
2021-06-22 00:09:10,815 epoch 37 - iter 27/33 - loss 0.06065974 - samples/sec: 69.19 - lr: 0.000015
2021-06-22 00:09:12,227 epoch 37 - iter 30/33 - loss 0.05823016 - samples/sec: 68.00 - lr: 0.000015
2021-06-22 00:09:13,511 epoch 37 - iter 33/33 - loss 0.06031092 - samples/sec: 74.79 - lr: 0.000015
2021-06-22 00:09:13,512 ----------------------------------------------------------------------------------------------------
2021-06-22 00:09:13,512 EPOCH 37 done: loss 0.0603 - lr 0.0000150
2021-06-22 00:09:15,411 DEV : loss 0.12196674197912216 - score 0.9785
2021-06-22 00:09:15,437 BAD EPOCHS (no improvement): 1
2021-06-22 00:09:15,437 ----------------------------------------------------------------------------------------------------
2021-06-22 00:09:16,866 epoch 38 - iter 3/33 - loss 0.04656748 - samples/sec: 67.20 - lr: 0.000015
2021-06-22 00:09:18,282 epoch 38 - iter 6/33 - loss 0.06549646 - samples/sec: 67.81 - lr: 0.000015
2021-06-22 00:09:19,675 epoch 38 - iter 9/33 - loss 0.05408040 - samples/sec: 68.98 - lr: 0.000015
2021-06-22 00:09:21,106 epoch 38 - iter 12/33 - loss 0.04842494 - samples/sec: 67.09 - lr: 0.000015
2021-06-22 00:09:22,519 epoch 38 - iter 15/33 - loss 0.06833541 - samples/sec: 67.97 - lr: 0.000015
2021-06-22 00:09:23,934 epoch 38 - iter 18/33 - loss 0.06211465 - samples/sec: 67.86 - lr: 0.000015
2021-06-22 00:09:25,339 epoch 38 - iter 21/33 - loss 0.05893470 - samples/sec: 68.37 - lr: 0.000015
2021-06-22 00:09:26,759 epoch 38 - iter 24/33 - loss 0.05834329 - samples/sec: 67.62 - lr: 0.000015
2021-06-22 00:09:28,132 epoch 38 - iter 27/33 - loss 0.05717896 - samples/sec: 69.93 - lr: 0.000015
2021-06-22 00:09:29,548 epoch 38 - iter 30/33 - loss 0.05670803 - samples/sec: 67.83 - lr: 0.000015
2021-06-22 00:09:30,840 epoch 38 - iter 33/33 - loss 0.05522933 - samples/sec: 74.37 - lr: 0.000015
2021-06-22 00:09:30,840 ----------------------------------------------------------------------------------------------------
2021-06-22 00:09:30,840 EPOCH 38 done: loss 0.0552 - lr 0.0000150
2021-06-22 00:09:32,738 DEV : loss 0.1248369812965393 - score 0.9787
2021-06-22 00:09:32,764 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:09:37,902 ----------------------------------------------------------------------------------------------------
2021-06-22 00:09:39,310 epoch 39 - iter 3/33 - loss 0.05059703 - samples/sec: 68.20 - lr: 0.000015
2021-06-22 00:09:40,749 epoch 39 - iter 6/33 - loss 0.05128359 - samples/sec: 66.74 - lr: 0.000015
2021-06-22 00:09:42,143 epoch 39 - iter 9/33 - loss 0.04833887 - samples/sec: 68.91 - lr: 0.000015
2021-06-22 00:09:43,538 epoch 39 - iter 12/33 - loss 0.04497106 - samples/sec: 68.82 - lr: 0.000015
2021-06-22 00:09:44,961 epoch 39 - iter 15/33 - loss 0.04594170 - samples/sec: 67.52 - lr: 0.000015
2021-06-22 00:09:46,373 epoch 39 - iter 18/33 - loss 0.04554015 - samples/sec: 68.01 - lr: 0.000015
2021-06-22 00:09:47,758 epoch 39 - iter 21/33 - loss 0.04586762 - samples/sec: 69.35 - lr: 0.000015
2021-06-22 00:09:49,180 epoch 39 - iter 24/33 - loss 0.04417051 - samples/sec: 67.52 - lr: 0.000015
2021-06-22 00:09:50,608 epoch 39 - iter 27/33 - loss 0.05426048 - samples/sec: 67.22 - lr: 0.000015
2021-06-22 00:09:52,010 epoch 39 - iter 30/33 - loss 0.05373980 - samples/sec: 68.54 - lr: 0.000015
2021-06-22 00:09:53,289 epoch 39 - iter 33/33 - loss 0.05646400 - samples/sec: 75.05 - lr: 0.000015
2021-06-22 00:09:53,290 ----------------------------------------------------------------------------------------------------
2021-06-22 00:09:53,290 EPOCH 39 done: loss 0.0565 - lr 0.0000150
2021-06-22 00:09:55,191 DEV : loss 0.12497111409902573 - score 0.9772
2021-06-22 00:09:55,216 BAD EPOCHS (no improvement): 1
2021-06-22 00:09:55,217 ----------------------------------------------------------------------------------------------------
2021-06-22 00:09:56,605 epoch 40 - iter 3/33 - loss 0.05008473 - samples/sec: 69.19 - lr: 0.000015
2021-06-22 00:09:58,039 epoch 40 - iter 6/33 - loss 0.04801375 - samples/sec: 66.95 - lr: 0.000015
2021-06-22 00:09:59,465 epoch 40 - iter 9/33 - loss 0.04476016 - samples/sec: 67.36 - lr: 0.000015
2021-06-22 00:10:01,015 epoch 40 - iter 12/33 - loss 0.04351588 - samples/sec: 61.96 - lr: 0.000015
2021-06-22 00:10:02,414 epoch 40 - iter 15/33 - loss 0.04896279 - samples/sec: 68.63 - lr: 0.000015
2021-06-22 00:10:03,842 epoch 40 - iter 18/33 - loss 0.05595486 - samples/sec: 67.27 - lr: 0.000015
2021-06-22 00:10:05,261 epoch 40 - iter 21/33 - loss 0.05289120 - samples/sec: 67.67 - lr: 0.000015
2021-06-22 00:10:06,674 epoch 40 - iter 24/33 - loss 0.04911642 - samples/sec: 67.95 - lr: 0.000015
2021-06-22 00:10:08,089 epoch 40 - iter 27/33 - loss 0.04899477 - samples/sec: 67.85 - lr: 0.000015
2021-06-22 00:10:09,500 epoch 40 - iter 30/33 - loss 0.04996687 - samples/sec: 68.10 - lr: 0.000015
2021-06-22 00:10:10,767 epoch 40 - iter 33/33 - loss 0.05184369 - samples/sec: 75.77 - lr: 0.000015
2021-06-22 00:10:10,768 ----------------------------------------------------------------------------------------------------
2021-06-22 00:10:10,768 EPOCH 40 done: loss 0.0518 - lr 0.0000150
2021-06-22 00:10:12,669 DEV : loss 0.12453912943601608 - score 0.9786
2021-06-22 00:10:12,695 BAD EPOCHS (no improvement): 2
2021-06-22 00:10:13,151 ----------------------------------------------------------------------------------------------------
2021-06-22 00:10:13,151 Testing using best model ...
2021-06-22 00:10:13,151 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/best-model.pt
2021-06-22 00:10:19,638 0.9692	0.9844	0.9767
2021-06-22 00:10:19,638 
Results:
- F1-score (micro) 0.9767
- F1-score (macro) 0.9767

By class:
SENT       tp: 315 - fp: 10 - fn: 5 - precision: 0.9692 - recall: 0.9844 - f1-score: 0.9767
2021-06-22 00:10:19,638 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/
2021-06-22 00:10:19,656 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb
2021-06-22 00:10:19,656 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/sent_train.txt
2021-06-22 00:10:19,658 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/sent_dev.txt
2021-06-22 00:10:19,659 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/sent_test.txt
Corpus: 51481 train + 1929 dev + 2695 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 00:11:09,979 ----------------------------------------------------------------------------------------------------
2021-06-22 00:11:09,982 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50265, 1024, padding_idx=1)
          (position_embeddings): Embedding(514, 1024, padding_idx=1)
          (token_type_embeddings): Embedding(1, 1024)
          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (12): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (13): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (14): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (15): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (16): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (17): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (18): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (19): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (20): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (21): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (22): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (23): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4146, out_features=4146, bias=True)
  (rnn): LSTM(4146, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 00:11:09,982 ----------------------------------------------------------------------------------------------------
2021-06-22 00:11:09,982 Corpus: "Corpus: 51481 train + 1929 dev + 2695 test sentences"
2021-06-22 00:11:09,982 ----------------------------------------------------------------------------------------------------
2021-06-22 00:11:09,982 Parameters:
2021-06-22 00:11:09,982  - learning_rate: "3e-05"
2021-06-22 00:11:09,982  - mini_batch_size: "32"
2021-06-22 00:11:09,982  - patience: "3"
2021-06-22 00:11:09,983  - anneal_factor: "0.5"
2021-06-22 00:11:09,983  - max_epochs: "40"
2021-06-22 00:11:09,983  - shuffle: "True"
2021-06-22 00:11:09,983  - train_with_dev: "False"
2021-06-22 00:11:09,983  - batch_growth_annealing: "False"
2021-06-22 00:11:09,983 ----------------------------------------------------------------------------------------------------
2021-06-22 00:11:09,983 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb"
2021-06-22 00:11:09,983 ----------------------------------------------------------------------------------------------------
2021-06-22 00:11:09,983 Device: cuda:0
2021-06-22 00:11:09,983 ----------------------------------------------------------------------------------------------------
2021-06-22 00:11:09,983 Embeddings storage mode: cpu
2021-06-22 00:11:09,984 ----------------------------------------------------------------------------------------------------
2021-06-22 00:14:36,713 epoch 1 - iter 160/1609 - loss 1.91292356 - samples/sec: 24.77 - lr: 0.000030
2021-06-22 00:18:02,532 epoch 1 - iter 320/1609 - loss 1.26592382 - samples/sec: 24.88 - lr: 0.000030
2021-06-22 00:21:28,759 epoch 1 - iter 480/1609 - loss 0.99954745 - samples/sec: 24.83 - lr: 0.000030
2021-06-22 00:24:55,048 epoch 1 - iter 640/1609 - loss 0.84508706 - samples/sec: 24.82 - lr: 0.000030
2021-06-22 00:28:21,749 epoch 1 - iter 800/1609 - loss 0.74446246 - samples/sec: 24.77 - lr: 0.000030
2021-06-22 00:31:48,449 epoch 1 - iter 960/1609 - loss 0.67504573 - samples/sec: 24.77 - lr: 0.000030
2021-06-22 00:35:15,087 epoch 1 - iter 1120/1609 - loss 0.62124274 - samples/sec: 24.78 - lr: 0.000030
2021-06-22 00:38:44,230 epoch 1 - iter 1280/1609 - loss 0.58022201 - samples/sec: 24.48 - lr: 0.000030
2021-06-22 00:42:10,873 epoch 1 - iter 1440/1609 - loss 0.55043612 - samples/sec: 24.78 - lr: 0.000030
2021-06-22 00:45:36,932 epoch 1 - iter 1600/1609 - loss 0.52504861 - samples/sec: 24.85 - lr: 0.000030
2021-06-22 00:45:48,274 ----------------------------------------------------------------------------------------------------
2021-06-22 00:45:48,274 EPOCH 1 done: loss 0.5242 - lr 0.0000300
2021-06-22 00:46:39,345 DEV : loss 0.16602051258087158 - score 0.9652
2021-06-22 00:46:39,478 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:46:40,598 ----------------------------------------------------------------------------------------------------
2021-06-22 00:47:56,968 epoch 2 - iter 160/1609 - loss 0.24971492 - samples/sec: 67.05 - lr: 0.000030
2021-06-22 00:49:13,707 epoch 2 - iter 320/1609 - loss 0.26494967 - samples/sec: 66.73 - lr: 0.000030
2021-06-22 00:50:30,491 epoch 2 - iter 480/1609 - loss 0.25758415 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 00:51:47,189 epoch 2 - iter 640/1609 - loss 0.25905722 - samples/sec: 66.76 - lr: 0.000030
2021-06-22 00:53:04,074 epoch 2 - iter 800/1609 - loss 0.25696822 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 00:54:20,855 epoch 2 - iter 960/1609 - loss 0.25663115 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 00:55:37,595 epoch 2 - iter 1120/1609 - loss 0.25462808 - samples/sec: 66.73 - lr: 0.000030
2021-06-22 00:56:54,325 epoch 2 - iter 1280/1609 - loss 0.25181893 - samples/sec: 66.73 - lr: 0.000030
2021-06-22 00:58:10,853 epoch 2 - iter 1440/1609 - loss 0.24930560 - samples/sec: 66.91 - lr: 0.000030
2021-06-22 00:59:27,262 epoch 2 - iter 1600/1609 - loss 0.24754241 - samples/sec: 67.01 - lr: 0.000030
2021-06-22 00:59:31,496 ----------------------------------------------------------------------------------------------------
2021-06-22 00:59:31,497 EPOCH 2 done: loss 0.2472 - lr 0.0000300
2021-06-22 00:59:41,251 DEV : loss 0.13234080374240875 - score 0.9728
2021-06-22 00:59:41,386 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 00:59:56,090 ----------------------------------------------------------------------------------------------------
2021-06-22 01:01:13,106 epoch 3 - iter 160/1609 - loss 0.24815944 - samples/sec: 66.49 - lr: 0.000030
2021-06-22 01:02:30,013 epoch 3 - iter 320/1609 - loss 0.23919079 - samples/sec: 66.58 - lr: 0.000030
2021-06-22 01:03:47,155 epoch 3 - iter 480/1609 - loss 0.23021963 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 01:05:04,427 epoch 3 - iter 640/1609 - loss 0.22386462 - samples/sec: 66.27 - lr: 0.000030
2021-06-22 01:06:21,485 epoch 3 - iter 800/1609 - loss 0.22233579 - samples/sec: 66.45 - lr: 0.000030
2021-06-22 01:07:38,401 epoch 3 - iter 960/1609 - loss 0.21990003 - samples/sec: 66.57 - lr: 0.000030
2021-06-22 01:08:55,594 epoch 3 - iter 1120/1609 - loss 0.22014479 - samples/sec: 66.33 - lr: 0.000030
2021-06-22 01:10:12,691 epoch 3 - iter 1280/1609 - loss 0.21631284 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 01:11:29,621 epoch 3 - iter 1440/1609 - loss 0.21419257 - samples/sec: 66.56 - lr: 0.000030
2021-06-22 01:12:46,652 epoch 3 - iter 1600/1609 - loss 0.21442471 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 01:12:50,940 ----------------------------------------------------------------------------------------------------
2021-06-22 01:12:50,940 EPOCH 3 done: loss 0.2142 - lr 0.0000300
2021-06-22 01:13:00,680 DEV : loss 0.12129706889390945 - score 0.9774
2021-06-22 01:13:00,815 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 01:13:15,332 ----------------------------------------------------------------------------------------------------
2021-06-22 01:14:32,470 epoch 4 - iter 160/1609 - loss 0.17767057 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 01:15:49,531 epoch 4 - iter 320/1609 - loss 0.18428919 - samples/sec: 66.45 - lr: 0.000030
2021-06-22 01:17:06,222 epoch 4 - iter 480/1609 - loss 0.18202733 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 01:18:22,977 epoch 4 - iter 640/1609 - loss 0.18541146 - samples/sec: 66.71 - lr: 0.000030
2021-06-22 01:19:42,692 epoch 4 - iter 800/1609 - loss 0.18823272 - samples/sec: 64.24 - lr: 0.000030
2021-06-22 01:20:59,563 epoch 4 - iter 960/1609 - loss 0.18691909 - samples/sec: 66.61 - lr: 0.000030
2021-06-22 01:22:16,516 epoch 4 - iter 1120/1609 - loss 0.18840452 - samples/sec: 66.54 - lr: 0.000030
2021-06-22 01:23:33,477 epoch 4 - iter 1280/1609 - loss 0.18926083 - samples/sec: 66.53 - lr: 0.000030
2021-06-22 01:24:50,506 epoch 4 - iter 1440/1609 - loss 0.18908426 - samples/sec: 66.48 - lr: 0.000030
2021-06-22 01:26:06,911 epoch 4 - iter 1600/1609 - loss 0.18917378 - samples/sec: 67.02 - lr: 0.000030
2021-06-22 01:26:11,123 ----------------------------------------------------------------------------------------------------
2021-06-22 01:26:11,123 EPOCH 4 done: loss 0.1888 - lr 0.0000300
2021-06-22 01:26:20,878 DEV : loss 0.11652369797229767 - score 0.9774
2021-06-22 01:26:21,013 BAD EPOCHS (no improvement): 1
2021-06-22 01:26:21,014 ----------------------------------------------------------------------------------------------------
2021-06-22 01:27:38,376 epoch 5 - iter 160/1609 - loss 0.18488598 - samples/sec: 66.19 - lr: 0.000030
2021-06-22 01:28:55,625 epoch 5 - iter 320/1609 - loss 0.17459119 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 01:30:12,758 epoch 5 - iter 480/1609 - loss 0.17634313 - samples/sec: 66.39 - lr: 0.000030
2021-06-22 01:31:29,397 epoch 5 - iter 640/1609 - loss 0.18063436 - samples/sec: 66.81 - lr: 0.000030
2021-06-22 01:32:46,193 epoch 5 - iter 800/1609 - loss 0.18351542 - samples/sec: 66.68 - lr: 0.000030
2021-06-22 01:34:02,687 epoch 5 - iter 960/1609 - loss 0.17870850 - samples/sec: 66.94 - lr: 0.000030
2021-06-22 01:35:19,126 epoch 5 - iter 1120/1609 - loss 0.17655337 - samples/sec: 66.99 - lr: 0.000030
2021-06-22 01:36:36,009 epoch 5 - iter 1280/1609 - loss 0.17657109 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 01:37:52,785 epoch 5 - iter 1440/1609 - loss 0.17479017 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 01:39:09,450 epoch 5 - iter 1600/1609 - loss 0.17350259 - samples/sec: 66.79 - lr: 0.000030
2021-06-22 01:39:13,700 ----------------------------------------------------------------------------------------------------
2021-06-22 01:39:13,700 EPOCH 5 done: loss 0.1733 - lr 0.0000300
2021-06-22 01:39:23,472 DEV : loss 0.11414352059364319 - score 0.9778
2021-06-22 01:39:23,608 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 01:39:38,831 ----------------------------------------------------------------------------------------------------
2021-06-22 01:40:55,761 epoch 6 - iter 160/1609 - loss 0.16396947 - samples/sec: 66.56 - lr: 0.000030
2021-06-22 01:42:12,621 epoch 6 - iter 320/1609 - loss 0.15994940 - samples/sec: 66.62 - lr: 0.000030
2021-06-22 01:43:29,473 epoch 6 - iter 480/1609 - loss 0.16131497 - samples/sec: 66.63 - lr: 0.000030
2021-06-22 01:44:46,358 epoch 6 - iter 640/1609 - loss 0.15708012 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 01:46:03,360 epoch 6 - iter 800/1609 - loss 0.15692685 - samples/sec: 66.50 - lr: 0.000030
2021-06-22 01:47:20,441 epoch 6 - iter 960/1609 - loss 0.15632548 - samples/sec: 66.43 - lr: 0.000030
2021-06-22 01:48:37,487 epoch 6 - iter 1120/1609 - loss 0.15802925 - samples/sec: 66.46 - lr: 0.000030
2021-06-22 01:49:54,388 epoch 6 - iter 1280/1609 - loss 0.16018090 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 01:51:11,601 epoch 6 - iter 1440/1609 - loss 0.15939102 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 01:52:28,601 epoch 6 - iter 1600/1609 - loss 0.16134171 - samples/sec: 66.50 - lr: 0.000030
2021-06-22 01:52:32,833 ----------------------------------------------------------------------------------------------------
2021-06-22 01:52:32,834 EPOCH 6 done: loss 0.1616 - lr 0.0000300
2021-06-22 01:52:42,594 DEV : loss 0.11389899253845215 - score 0.9773
2021-06-22 01:52:42,728 BAD EPOCHS (no improvement): 1
2021-06-22 01:52:42,728 ----------------------------------------------------------------------------------------------------
2021-06-22 01:53:59,614 epoch 7 - iter 160/1609 - loss 0.15413519 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 01:55:16,525 epoch 7 - iter 320/1609 - loss 0.15837134 - samples/sec: 66.58 - lr: 0.000030
2021-06-22 01:56:33,475 epoch 7 - iter 480/1609 - loss 0.15852782 - samples/sec: 66.54 - lr: 0.000030
2021-06-22 01:57:50,484 epoch 7 - iter 640/1609 - loss 0.15229894 - samples/sec: 66.49 - lr: 0.000030
2021-06-22 01:59:07,463 epoch 7 - iter 800/1609 - loss 0.15022805 - samples/sec: 66.52 - lr: 0.000030
2021-06-22 02:00:24,456 epoch 7 - iter 960/1609 - loss 0.14876552 - samples/sec: 66.51 - lr: 0.000030
2021-06-22 02:01:41,223 epoch 7 - iter 1120/1609 - loss 0.14905839 - samples/sec: 66.70 - lr: 0.000030
2021-06-22 02:02:57,921 epoch 7 - iter 1280/1609 - loss 0.15006437 - samples/sec: 66.76 - lr: 0.000030
2021-06-22 02:04:15,046 epoch 7 - iter 1440/1609 - loss 0.15034893 - samples/sec: 66.39 - lr: 0.000030
2021-06-22 02:05:31,909 epoch 7 - iter 1600/1609 - loss 0.14901464 - samples/sec: 66.62 - lr: 0.000030
2021-06-22 02:05:36,212 ----------------------------------------------------------------------------------------------------
2021-06-22 02:05:36,212 EPOCH 7 done: loss 0.1495 - lr 0.0000300
2021-06-22 02:05:45,982 DEV : loss 0.10614980012178421 - score 0.9789
2021-06-22 02:05:46,118 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 02:06:01,072 ----------------------------------------------------------------------------------------------------
2021-06-22 02:07:18,361 epoch 8 - iter 160/1609 - loss 0.14408353 - samples/sec: 66.25 - lr: 0.000030
2021-06-22 02:08:35,520 epoch 8 - iter 320/1609 - loss 0.14757222 - samples/sec: 66.36 - lr: 0.000030
2021-06-22 02:09:52,732 epoch 8 - iter 480/1609 - loss 0.14733848 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 02:11:10,124 epoch 8 - iter 640/1609 - loss 0.14694846 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 02:12:27,260 epoch 8 - iter 800/1609 - loss 0.14815571 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 02:13:44,536 epoch 8 - iter 960/1609 - loss 0.14689479 - samples/sec: 66.26 - lr: 0.000030
2021-06-22 02:15:01,530 epoch 8 - iter 1120/1609 - loss 0.14649731 - samples/sec: 66.51 - lr: 0.000030
2021-06-22 02:16:18,592 epoch 8 - iter 1280/1609 - loss 0.14222050 - samples/sec: 66.45 - lr: 0.000030
2021-06-22 02:17:35,713 epoch 8 - iter 1440/1609 - loss 0.14166056 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 02:18:52,792 epoch 8 - iter 1600/1609 - loss 0.14051200 - samples/sec: 66.43 - lr: 0.000030
2021-06-22 02:18:57,046 ----------------------------------------------------------------------------------------------------
2021-06-22 02:18:57,046 EPOCH 8 done: loss 0.1405 - lr 0.0000300
2021-06-22 02:19:09,611 DEV : loss 0.10028094798326492 - score 0.9801
2021-06-22 02:19:09,749 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 02:19:24,580 ----------------------------------------------------------------------------------------------------
2021-06-22 02:20:41,621 epoch 9 - iter 160/1609 - loss 0.12578267 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 02:21:58,397 epoch 9 - iter 320/1609 - loss 0.12974121 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 02:23:15,546 epoch 9 - iter 480/1609 - loss 0.13666558 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 02:24:32,374 epoch 9 - iter 640/1609 - loss 0.13413449 - samples/sec: 66.65 - lr: 0.000030
2021-06-22 02:25:49,145 epoch 9 - iter 800/1609 - loss 0.13269280 - samples/sec: 66.70 - lr: 0.000030
2021-06-22 02:27:06,028 epoch 9 - iter 960/1609 - loss 0.13098381 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 02:28:23,011 epoch 9 - iter 1120/1609 - loss 0.13025688 - samples/sec: 66.52 - lr: 0.000030
2021-06-22 02:29:39,990 epoch 9 - iter 1280/1609 - loss 0.13038153 - samples/sec: 66.52 - lr: 0.000030
2021-06-22 02:30:56,769 epoch 9 - iter 1440/1609 - loss 0.13256582 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 02:32:13,622 epoch 9 - iter 1600/1609 - loss 0.13311494 - samples/sec: 66.63 - lr: 0.000030
2021-06-22 02:32:17,855 ----------------------------------------------------------------------------------------------------
2021-06-22 02:32:17,856 EPOCH 9 done: loss 0.1333 - lr 0.0000300
2021-06-22 02:32:27,647 DEV : loss 0.11220083385705948 - score 0.9786
2021-06-22 02:32:27,783 BAD EPOCHS (no improvement): 1
2021-06-22 02:32:27,784 ----------------------------------------------------------------------------------------------------
2021-06-22 02:33:45,165 epoch 10 - iter 160/1609 - loss 0.13752609 - samples/sec: 66.17 - lr: 0.000030
2021-06-22 02:35:02,298 epoch 10 - iter 320/1609 - loss 0.13261062 - samples/sec: 66.39 - lr: 0.000030
2021-06-22 02:36:19,561 epoch 10 - iter 480/1609 - loss 0.13275817 - samples/sec: 66.27 - lr: 0.000030
2021-06-22 02:37:36,700 epoch 10 - iter 640/1609 - loss 0.13325733 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 02:38:53,801 epoch 10 - iter 800/1609 - loss 0.13056216 - samples/sec: 66.41 - lr: 0.000030
2021-06-22 02:40:10,900 epoch 10 - iter 960/1609 - loss 0.12934738 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 02:41:28,025 epoch 10 - iter 1120/1609 - loss 0.12739894 - samples/sec: 66.39 - lr: 0.000030
2021-06-22 02:42:45,240 epoch 10 - iter 1280/1609 - loss 0.12761657 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 02:44:02,526 epoch 10 - iter 1440/1609 - loss 0.12756392 - samples/sec: 66.25 - lr: 0.000030
2021-06-22 02:45:19,496 epoch 10 - iter 1600/1609 - loss 0.12615708 - samples/sec: 66.53 - lr: 0.000030
2021-06-22 02:45:23,725 ----------------------------------------------------------------------------------------------------
2021-06-22 02:45:23,725 EPOCH 10 done: loss 0.1264 - lr 0.0000300
2021-06-22 02:45:33,516 DEV : loss 0.1058872789144516 - score 0.9796
2021-06-22 02:45:33,652 BAD EPOCHS (no improvement): 2
2021-06-22 02:45:33,652 ----------------------------------------------------------------------------------------------------
2021-06-22 02:46:50,806 epoch 11 - iter 160/1609 - loss 0.13318562 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 02:48:08,059 epoch 11 - iter 320/1609 - loss 0.12522333 - samples/sec: 66.28 - lr: 0.000030
2021-06-22 02:49:25,463 epoch 11 - iter 480/1609 - loss 0.12326258 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 02:50:42,609 epoch 11 - iter 640/1609 - loss 0.12517774 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 02:51:59,837 epoch 11 - iter 800/1609 - loss 0.12237858 - samples/sec: 66.30 - lr: 0.000030
2021-06-22 02:53:15,973 epoch 11 - iter 960/1609 - loss 0.11818642 - samples/sec: 67.26 - lr: 0.000030
2021-06-22 02:54:33,130 epoch 11 - iter 1120/1609 - loss 0.11985778 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 02:55:50,472 epoch 11 - iter 1280/1609 - loss 0.11992682 - samples/sec: 66.21 - lr: 0.000030
2021-06-22 02:57:07,794 epoch 11 - iter 1440/1609 - loss 0.11947649 - samples/sec: 66.22 - lr: 0.000030
2021-06-22 02:58:25,051 epoch 11 - iter 1600/1609 - loss 0.11990469 - samples/sec: 66.28 - lr: 0.000030
2021-06-22 02:58:29,312 ----------------------------------------------------------------------------------------------------
2021-06-22 02:58:29,313 EPOCH 11 done: loss 0.1199 - lr 0.0000300
2021-06-22 02:58:39,120 DEV : loss 0.09950821846723557 - score 0.9812
2021-06-22 02:58:39,257 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 02:58:53,880 ----------------------------------------------------------------------------------------------------
2021-06-22 03:00:11,239 epoch 12 - iter 160/1609 - loss 0.12446913 - samples/sec: 66.19 - lr: 0.000030
2021-06-22 03:01:28,429 epoch 12 - iter 320/1609 - loss 0.11888389 - samples/sec: 66.34 - lr: 0.000030
2021-06-22 03:02:45,609 epoch 12 - iter 480/1609 - loss 0.11948347 - samples/sec: 66.35 - lr: 0.000030
2021-06-22 03:04:02,766 epoch 12 - iter 640/1609 - loss 0.11708597 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 03:05:19,947 epoch 12 - iter 800/1609 - loss 0.12129145 - samples/sec: 66.34 - lr: 0.000030
2021-06-22 03:06:36,977 epoch 12 - iter 960/1609 - loss 0.12027389 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 03:07:53,976 epoch 12 - iter 1120/1609 - loss 0.12011205 - samples/sec: 66.50 - lr: 0.000030
2021-06-22 03:09:11,081 epoch 12 - iter 1280/1609 - loss 0.11942703 - samples/sec: 66.41 - lr: 0.000030
2021-06-22 03:10:28,155 epoch 12 - iter 1440/1609 - loss 0.11981813 - samples/sec: 66.44 - lr: 0.000030
2021-06-22 03:11:45,017 epoch 12 - iter 1600/1609 - loss 0.12060624 - samples/sec: 66.62 - lr: 0.000030
2021-06-22 03:11:49,250 ----------------------------------------------------------------------------------------------------
2021-06-22 03:11:49,250 EPOCH 12 done: loss 0.1203 - lr 0.0000300
2021-06-22 03:11:59,053 DEV : loss 0.09797235578298569 - score 0.9816
2021-06-22 03:11:59,191 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 03:12:13,598 ----------------------------------------------------------------------------------------------------
2021-06-22 03:13:30,820 epoch 13 - iter 160/1609 - loss 0.09749204 - samples/sec: 66.31 - lr: 0.000030
2021-06-22 03:14:47,720 epoch 13 - iter 320/1609 - loss 0.10454387 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 03:16:05,091 epoch 13 - iter 480/1609 - loss 0.10857996 - samples/sec: 66.18 - lr: 0.000030
2021-06-22 03:17:22,323 epoch 13 - iter 640/1609 - loss 0.10902470 - samples/sec: 66.30 - lr: 0.000030
2021-06-22 03:18:39,576 epoch 13 - iter 800/1609 - loss 0.10983981 - samples/sec: 66.28 - lr: 0.000030
2021-06-22 03:19:56,930 epoch 13 - iter 960/1609 - loss 0.10921648 - samples/sec: 66.20 - lr: 0.000030
2021-06-22 03:21:14,246 epoch 13 - iter 1120/1609 - loss 0.10916747 - samples/sec: 66.23 - lr: 0.000030
2021-06-22 03:22:31,578 epoch 13 - iter 1280/1609 - loss 0.11075649 - samples/sec: 66.22 - lr: 0.000030
2021-06-22 03:23:48,890 epoch 13 - iter 1440/1609 - loss 0.10995760 - samples/sec: 66.23 - lr: 0.000030
2021-06-22 03:25:05,323 epoch 13 - iter 1600/1609 - loss 0.10979736 - samples/sec: 66.99 - lr: 0.000030
2021-06-22 03:25:09,573 ----------------------------------------------------------------------------------------------------
2021-06-22 03:25:09,574 EPOCH 13 done: loss 0.1096 - lr 0.0000300
2021-06-22 03:25:19,361 DEV : loss 0.10051904618740082 - score 0.9812
2021-06-22 03:25:19,497 BAD EPOCHS (no improvement): 1
2021-06-22 03:25:19,497 ----------------------------------------------------------------------------------------------------
2021-06-22 03:26:36,444 epoch 14 - iter 160/1609 - loss 0.11098154 - samples/sec: 66.55 - lr: 0.000030
2021-06-22 03:27:53,611 epoch 14 - iter 320/1609 - loss 0.10942387 - samples/sec: 66.36 - lr: 0.000030
2021-06-22 03:29:13,390 epoch 14 - iter 480/1609 - loss 0.10639155 - samples/sec: 64.18 - lr: 0.000030
2021-06-22 03:30:30,462 epoch 14 - iter 640/1609 - loss 0.10578374 - samples/sec: 66.44 - lr: 0.000030
2021-06-22 03:31:47,442 epoch 14 - iter 800/1609 - loss 0.10495584 - samples/sec: 66.52 - lr: 0.000030
2021-06-22 03:33:04,511 epoch 14 - iter 960/1609 - loss 0.10616273 - samples/sec: 66.44 - lr: 0.000030
2021-06-22 03:34:21,655 epoch 14 - iter 1120/1609 - loss 0.10412237 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 03:35:38,594 epoch 14 - iter 1280/1609 - loss 0.10566999 - samples/sec: 66.55 - lr: 0.000030
2021-06-22 03:36:55,492 epoch 14 - iter 1440/1609 - loss 0.10575595 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 03:38:12,329 epoch 14 - iter 1600/1609 - loss 0.10648418 - samples/sec: 66.64 - lr: 0.000030
2021-06-22 03:38:16,585 ----------------------------------------------------------------------------------------------------
2021-06-22 03:38:16,585 EPOCH 14 done: loss 0.1065 - lr 0.0000300
2021-06-22 03:38:26,404 DEV : loss 0.10155890136957169 - score 0.981
2021-06-22 03:38:26,543 BAD EPOCHS (no improvement): 2
2021-06-22 03:38:26,543 ----------------------------------------------------------------------------------------------------
2021-06-22 03:39:43,454 epoch 15 - iter 160/1609 - loss 0.09437316 - samples/sec: 66.58 - lr: 0.000030
2021-06-22 03:41:00,163 epoch 15 - iter 320/1609 - loss 0.09564501 - samples/sec: 66.75 - lr: 0.000030
2021-06-22 03:42:16,854 epoch 15 - iter 480/1609 - loss 0.10345811 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 03:43:33,545 epoch 15 - iter 640/1609 - loss 0.10557060 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 03:44:50,636 epoch 15 - iter 800/1609 - loss 0.10160464 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 03:46:07,638 epoch 15 - iter 960/1609 - loss 0.10286400 - samples/sec: 66.50 - lr: 0.000030
2021-06-22 03:47:24,760 epoch 15 - iter 1120/1609 - loss 0.10240083 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 03:48:41,820 epoch 15 - iter 1280/1609 - loss 0.10198226 - samples/sec: 66.45 - lr: 0.000030
2021-06-22 03:49:59,160 epoch 15 - iter 1440/1609 - loss 0.10229025 - samples/sec: 66.21 - lr: 0.000030
2021-06-22 03:51:16,090 epoch 15 - iter 1600/1609 - loss 0.10200105 - samples/sec: 66.56 - lr: 0.000030
2021-06-22 03:51:20,361 ----------------------------------------------------------------------------------------------------
2021-06-22 03:51:20,361 EPOCH 15 done: loss 0.1021 - lr 0.0000300
2021-06-22 03:51:30,145 DEV : loss 0.10867301374673843 - score 0.9795
2021-06-22 03:51:30,283 BAD EPOCHS (no improvement): 3
2021-06-22 03:51:30,283 ----------------------------------------------------------------------------------------------------
2021-06-22 03:52:47,111 epoch 16 - iter 160/1609 - loss 0.10915675 - samples/sec: 66.65 - lr: 0.000030
2021-06-22 03:54:03,903 epoch 16 - iter 320/1609 - loss 0.09999563 - samples/sec: 66.68 - lr: 0.000030
2021-06-22 03:55:20,626 epoch 16 - iter 480/1609 - loss 0.09475681 - samples/sec: 66.74 - lr: 0.000030
2021-06-22 03:56:37,318 epoch 16 - iter 640/1609 - loss 0.09458270 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 03:57:53,933 epoch 16 - iter 800/1609 - loss 0.09879248 - samples/sec: 66.83 - lr: 0.000030
2021-06-22 03:59:10,735 epoch 16 - iter 960/1609 - loss 0.09825255 - samples/sec: 66.67 - lr: 0.000030
2021-06-22 04:00:27,414 epoch 16 - iter 1120/1609 - loss 0.09902458 - samples/sec: 66.78 - lr: 0.000030
2021-06-22 04:01:44,261 epoch 16 - iter 1280/1609 - loss 0.09894271 - samples/sec: 66.63 - lr: 0.000030
2021-06-22 04:03:01,449 epoch 16 - iter 1440/1609 - loss 0.09877716 - samples/sec: 66.34 - lr: 0.000030
2021-06-22 04:04:18,706 epoch 16 - iter 1600/1609 - loss 0.09868581 - samples/sec: 66.28 - lr: 0.000030
2021-06-22 04:04:22,969 ----------------------------------------------------------------------------------------------------
2021-06-22 04:04:22,969 EPOCH 16 done: loss 0.0989 - lr 0.0000300
2021-06-22 04:04:32,782 DEV : loss 0.10214244574308395 - score 0.9827
2021-06-22 04:04:32,918 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 04:04:47,552 ----------------------------------------------------------------------------------------------------
2021-06-22 04:06:04,965 epoch 17 - iter 160/1609 - loss 0.08561493 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 04:07:22,188 epoch 17 - iter 320/1609 - loss 0.08438530 - samples/sec: 66.31 - lr: 0.000030
2021-06-22 04:08:39,661 epoch 17 - iter 480/1609 - loss 0.08533453 - samples/sec: 66.09 - lr: 0.000030
2021-06-22 04:09:56,970 epoch 17 - iter 640/1609 - loss 0.08858045 - samples/sec: 66.23 - lr: 0.000030
2021-06-22 04:11:14,387 epoch 17 - iter 800/1609 - loss 0.08928064 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 04:12:31,805 epoch 17 - iter 960/1609 - loss 0.08965964 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 04:13:48,280 epoch 17 - iter 1120/1609 - loss 0.09027484 - samples/sec: 66.96 - lr: 0.000030
2021-06-22 04:15:05,492 epoch 17 - iter 1280/1609 - loss 0.08941341 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 04:16:22,710 epoch 17 - iter 1440/1609 - loss 0.09046887 - samples/sec: 66.31 - lr: 0.000030
2021-06-22 04:17:40,035 epoch 17 - iter 1600/1609 - loss 0.09086402 - samples/sec: 66.22 - lr: 0.000030
2021-06-22 04:17:44,318 ----------------------------------------------------------------------------------------------------
2021-06-22 04:17:44,319 EPOCH 17 done: loss 0.0909 - lr 0.0000300
2021-06-22 04:17:54,124 DEV : loss 0.10200386494398117 - score 0.9818
2021-06-22 04:17:54,262 BAD EPOCHS (no improvement): 1
2021-06-22 04:17:54,263 ----------------------------------------------------------------------------------------------------
2021-06-22 04:19:11,720 epoch 18 - iter 160/1609 - loss 0.09135629 - samples/sec: 66.11 - lr: 0.000030
2021-06-22 04:20:29,143 epoch 18 - iter 320/1609 - loss 0.08687874 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 04:21:46,596 epoch 18 - iter 480/1609 - loss 0.08798635 - samples/sec: 66.11 - lr: 0.000030
2021-06-22 04:23:04,026 epoch 18 - iter 640/1609 - loss 0.08476414 - samples/sec: 66.13 - lr: 0.000030
2021-06-22 04:24:21,511 epoch 18 - iter 800/1609 - loss 0.08729275 - samples/sec: 66.08 - lr: 0.000030
2021-06-22 04:25:38,920 epoch 18 - iter 960/1609 - loss 0.08809704 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 04:26:56,062 epoch 18 - iter 1120/1609 - loss 0.08734554 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 04:28:13,147 epoch 18 - iter 1280/1609 - loss 0.08791066 - samples/sec: 66.43 - lr: 0.000030
2021-06-22 04:29:30,350 epoch 18 - iter 1440/1609 - loss 0.08882200 - samples/sec: 66.33 - lr: 0.000030
2021-06-22 04:30:47,760 epoch 18 - iter 1600/1609 - loss 0.09085188 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 04:30:52,040 ----------------------------------------------------------------------------------------------------
2021-06-22 04:30:52,040 EPOCH 18 done: loss 0.0909 - lr 0.0000300
2021-06-22 04:31:01,858 DEV : loss 0.1064019724726677 - score 0.9815
2021-06-22 04:31:01,997 BAD EPOCHS (no improvement): 2
2021-06-22 04:31:01,997 ----------------------------------------------------------------------------------------------------
2021-06-22 04:32:19,281 epoch 19 - iter 160/1609 - loss 0.09339332 - samples/sec: 66.26 - lr: 0.000030
2021-06-22 04:33:36,757 epoch 19 - iter 320/1609 - loss 0.08595678 - samples/sec: 66.09 - lr: 0.000030
2021-06-22 04:34:54,256 epoch 19 - iter 480/1609 - loss 0.08677704 - samples/sec: 66.07 - lr: 0.000030
2021-06-22 04:36:11,761 epoch 19 - iter 640/1609 - loss 0.08762343 - samples/sec: 66.07 - lr: 0.000030
2021-06-22 04:37:29,254 epoch 19 - iter 800/1609 - loss 0.08686427 - samples/sec: 66.08 - lr: 0.000030
2021-06-22 04:38:46,740 epoch 19 - iter 960/1609 - loss 0.08712961 - samples/sec: 66.08 - lr: 0.000030
2021-06-22 04:40:04,291 epoch 19 - iter 1120/1609 - loss 0.08879478 - samples/sec: 66.03 - lr: 0.000030
2021-06-22 04:41:24,426 epoch 19 - iter 1280/1609 - loss 0.08855600 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 04:42:41,825 epoch 19 - iter 1440/1609 - loss 0.08874386 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 04:43:58,923 epoch 19 - iter 1600/1609 - loss 0.08822750 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 04:44:03,185 ----------------------------------------------------------------------------------------------------
2021-06-22 04:44:03,186 EPOCH 19 done: loss 0.0883 - lr 0.0000300
2021-06-22 04:44:12,977 DEV : loss 0.10576938092708588 - score 0.982
2021-06-22 04:44:13,114 BAD EPOCHS (no improvement): 3
2021-06-22 04:44:13,114 ----------------------------------------------------------------------------------------------------
2021-06-22 04:45:30,511 epoch 20 - iter 160/1609 - loss 0.08540184 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 04:46:47,775 epoch 20 - iter 320/1609 - loss 0.08593424 - samples/sec: 66.27 - lr: 0.000030
2021-06-22 04:48:04,629 epoch 20 - iter 480/1609 - loss 0.08342326 - samples/sec: 66.63 - lr: 0.000030
2021-06-22 04:49:21,134 epoch 20 - iter 640/1609 - loss 0.08398559 - samples/sec: 66.93 - lr: 0.000030
2021-06-22 04:50:37,972 epoch 20 - iter 800/1609 - loss 0.08153493 - samples/sec: 66.64 - lr: 0.000030
2021-06-22 04:51:54,439 epoch 20 - iter 960/1609 - loss 0.08057368 - samples/sec: 66.96 - lr: 0.000030
2021-06-22 04:53:11,546 epoch 20 - iter 1120/1609 - loss 0.08268338 - samples/sec: 66.41 - lr: 0.000030
2021-06-22 04:54:28,733 epoch 20 - iter 1280/1609 - loss 0.08194444 - samples/sec: 66.34 - lr: 0.000030
2021-06-22 04:55:45,904 epoch 20 - iter 1440/1609 - loss 0.08277648 - samples/sec: 66.35 - lr: 0.000030
2021-06-22 04:57:02,943 epoch 20 - iter 1600/1609 - loss 0.08228370 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 04:57:07,205 ----------------------------------------------------------------------------------------------------
2021-06-22 04:57:07,206 EPOCH 20 done: loss 0.0823 - lr 0.0000300
2021-06-22 04:57:17,015 DEV : loss 0.10814362019300461 - score 0.981
Epoch    20: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 04:57:17,154 BAD EPOCHS (no improvement): 4
2021-06-22 04:57:17,154 ----------------------------------------------------------------------------------------------------
2021-06-22 04:58:34,099 epoch 21 - iter 160/1609 - loss 0.07758429 - samples/sec: 66.55 - lr: 0.000015
2021-06-22 04:59:50,745 epoch 21 - iter 320/1609 - loss 0.07345777 - samples/sec: 66.81 - lr: 0.000015
2021-06-22 05:01:07,577 epoch 21 - iter 480/1609 - loss 0.07507053 - samples/sec: 66.65 - lr: 0.000015
2021-06-22 05:02:24,466 epoch 21 - iter 640/1609 - loss 0.07449970 - samples/sec: 66.60 - lr: 0.000015
2021-06-22 05:03:41,165 epoch 21 - iter 800/1609 - loss 0.07228014 - samples/sec: 66.76 - lr: 0.000015
2021-06-22 05:04:58,067 epoch 21 - iter 960/1609 - loss 0.07215071 - samples/sec: 66.59 - lr: 0.000015
2021-06-22 05:06:15,022 epoch 21 - iter 1120/1609 - loss 0.07303628 - samples/sec: 66.54 - lr: 0.000015
2021-06-22 05:07:31,818 epoch 21 - iter 1280/1609 - loss 0.07319120 - samples/sec: 66.68 - lr: 0.000015
2021-06-22 05:08:48,598 epoch 21 - iter 1440/1609 - loss 0.07387954 - samples/sec: 66.69 - lr: 0.000015
2021-06-22 05:10:05,800 epoch 21 - iter 1600/1609 - loss 0.07409330 - samples/sec: 66.33 - lr: 0.000015
2021-06-22 05:10:10,051 ----------------------------------------------------------------------------------------------------
2021-06-22 05:10:10,051 EPOCH 21 done: loss 0.0742 - lr 0.0000150
2021-06-22 05:10:19,856 DEV : loss 0.10376980155706406 - score 0.9823
2021-06-22 05:10:19,993 BAD EPOCHS (no improvement): 1
2021-06-22 05:10:19,993 ----------------------------------------------------------------------------------------------------
2021-06-22 05:11:36,955 epoch 22 - iter 160/1609 - loss 0.07433588 - samples/sec: 66.53 - lr: 0.000015
2021-06-22 05:12:53,774 epoch 22 - iter 320/1609 - loss 0.06683816 - samples/sec: 66.66 - lr: 0.000015
2021-06-22 05:14:10,562 epoch 22 - iter 480/1609 - loss 0.07181591 - samples/sec: 66.68 - lr: 0.000015
2021-06-22 05:15:27,729 epoch 22 - iter 640/1609 - loss 0.06956680 - samples/sec: 66.36 - lr: 0.000015
2021-06-22 05:16:44,763 epoch 22 - iter 800/1609 - loss 0.06954556 - samples/sec: 66.47 - lr: 0.000015
2021-06-22 05:18:01,826 epoch 22 - iter 960/1609 - loss 0.07092545 - samples/sec: 66.45 - lr: 0.000015
2021-06-22 05:19:18,996 epoch 22 - iter 1120/1609 - loss 0.06970751 - samples/sec: 66.35 - lr: 0.000015
2021-06-22 05:20:36,003 epoch 22 - iter 1280/1609 - loss 0.06985536 - samples/sec: 66.49 - lr: 0.000015
2021-06-22 05:21:52,993 epoch 22 - iter 1440/1609 - loss 0.07040831 - samples/sec: 66.51 - lr: 0.000015
2021-06-22 05:23:10,019 epoch 22 - iter 1600/1609 - loss 0.06988638 - samples/sec: 66.48 - lr: 0.000015
2021-06-22 05:23:14,270 ----------------------------------------------------------------------------------------------------
2021-06-22 05:23:14,271 EPOCH 22 done: loss 0.0697 - lr 0.0000150
2021-06-22 05:23:24,103 DEV : loss 0.11077087372541428 - score 0.9803
2021-06-22 05:23:24,241 BAD EPOCHS (no improvement): 2
2021-06-22 05:23:24,242 ----------------------------------------------------------------------------------------------------
2021-06-22 05:24:40,957 epoch 23 - iter 160/1609 - loss 0.06712633 - samples/sec: 66.75 - lr: 0.000015
2021-06-22 05:25:57,747 epoch 23 - iter 320/1609 - loss 0.06558837 - samples/sec: 66.68 - lr: 0.000015
2021-06-22 05:27:14,682 epoch 23 - iter 480/1609 - loss 0.06283381 - samples/sec: 66.56 - lr: 0.000015
2021-06-22 05:28:31,678 epoch 23 - iter 640/1609 - loss 0.06200830 - samples/sec: 66.50 - lr: 0.000015
2021-06-22 05:29:48,619 epoch 23 - iter 800/1609 - loss 0.06429921 - samples/sec: 66.55 - lr: 0.000015
2021-06-22 05:31:05,358 epoch 23 - iter 960/1609 - loss 0.06419676 - samples/sec: 66.73 - lr: 0.000015
2021-06-22 05:32:22,077 epoch 23 - iter 1120/1609 - loss 0.06486440 - samples/sec: 66.74 - lr: 0.000015
2021-06-22 05:33:38,841 epoch 23 - iter 1280/1609 - loss 0.06621378 - samples/sec: 66.70 - lr: 0.000015
2021-06-22 05:34:55,842 epoch 23 - iter 1440/1609 - loss 0.06725089 - samples/sec: 66.50 - lr: 0.000015
2021-06-22 05:36:12,739 epoch 23 - iter 1600/1609 - loss 0.06666885 - samples/sec: 66.59 - lr: 0.000015
2021-06-22 05:36:17,024 ----------------------------------------------------------------------------------------------------
2021-06-22 05:36:17,025 EPOCH 23 done: loss 0.0667 - lr 0.0000150
2021-06-22 05:36:26,818 DEV : loss 0.10226807743310928 - score 0.983
2021-06-22 05:36:26,955 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 05:36:42,193 ----------------------------------------------------------------------------------------------------
2021-06-22 05:37:59,317 epoch 24 - iter 160/1609 - loss 0.06440338 - samples/sec: 66.40 - lr: 0.000015
2021-06-22 05:39:16,301 epoch 24 - iter 320/1609 - loss 0.06358126 - samples/sec: 66.51 - lr: 0.000015
2021-06-22 05:40:33,409 epoch 24 - iter 480/1609 - loss 0.06454884 - samples/sec: 66.41 - lr: 0.000015
2021-06-22 05:41:50,388 epoch 24 - iter 640/1609 - loss 0.06153265 - samples/sec: 66.52 - lr: 0.000015
2021-06-22 05:43:07,766 epoch 24 - iter 800/1609 - loss 0.06204272 - samples/sec: 66.18 - lr: 0.000015
2021-06-22 05:44:27,796 epoch 24 - iter 960/1609 - loss 0.06161815 - samples/sec: 63.98 - lr: 0.000015
2021-06-22 05:45:44,746 epoch 24 - iter 1120/1609 - loss 0.06237033 - samples/sec: 66.54 - lr: 0.000015
2021-06-22 05:47:01,941 epoch 24 - iter 1280/1609 - loss 0.06285294 - samples/sec: 66.33 - lr: 0.000015
2021-06-22 05:48:19,075 epoch 24 - iter 1440/1609 - loss 0.06339321 - samples/sec: 66.38 - lr: 0.000015
2021-06-22 05:49:36,154 epoch 24 - iter 1600/1609 - loss 0.06439353 - samples/sec: 66.43 - lr: 0.000015
2021-06-22 05:49:40,373 ----------------------------------------------------------------------------------------------------
2021-06-22 05:49:40,374 EPOCH 24 done: loss 0.0645 - lr 0.0000150
2021-06-22 05:49:50,157 DEV : loss 0.10676134377717972 - score 0.9821
2021-06-22 05:49:50,293 BAD EPOCHS (no improvement): 1
2021-06-22 05:49:50,293 ----------------------------------------------------------------------------------------------------
2021-06-22 05:51:07,211 epoch 25 - iter 160/1609 - loss 0.05211000 - samples/sec: 66.57 - lr: 0.000015
2021-06-22 05:52:24,304 epoch 25 - iter 320/1609 - loss 0.05487189 - samples/sec: 66.42 - lr: 0.000015
2021-06-22 05:53:41,145 epoch 25 - iter 480/1609 - loss 0.05755754 - samples/sec: 66.64 - lr: 0.000015
2021-06-22 05:54:57,856 epoch 25 - iter 640/1609 - loss 0.06232413 - samples/sec: 66.75 - lr: 0.000015
2021-06-22 05:56:14,834 epoch 25 - iter 800/1609 - loss 0.06293989 - samples/sec: 66.52 - lr: 0.000015
2021-06-22 05:57:32,193 epoch 25 - iter 960/1609 - loss 0.06206426 - samples/sec: 66.19 - lr: 0.000015
2021-06-22 05:58:49,444 epoch 25 - iter 1120/1609 - loss 0.06320270 - samples/sec: 66.28 - lr: 0.000015
2021-06-22 06:00:06,747 epoch 25 - iter 1280/1609 - loss 0.06360818 - samples/sec: 66.24 - lr: 0.000015
2021-06-22 06:01:23,926 epoch 25 - iter 1440/1609 - loss 0.06343041 - samples/sec: 66.35 - lr: 0.000015
2021-06-22 06:02:41,028 epoch 25 - iter 1600/1609 - loss 0.06271100 - samples/sec: 66.41 - lr: 0.000015
2021-06-22 06:02:45,270 ----------------------------------------------------------------------------------------------------
2021-06-22 06:02:45,270 EPOCH 25 done: loss 0.0627 - lr 0.0000150
2021-06-22 06:02:55,074 DEV : loss 0.1078776940703392 - score 0.983
2021-06-22 06:02:55,211 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 06:03:10,036 ----------------------------------------------------------------------------------------------------
2021-06-22 06:04:27,354 epoch 26 - iter 160/1609 - loss 0.04828469 - samples/sec: 66.23 - lr: 0.000015
2021-06-22 06:05:44,584 epoch 26 - iter 320/1609 - loss 0.05220084 - samples/sec: 66.30 - lr: 0.000015
2021-06-22 06:07:01,569 epoch 26 - iter 480/1609 - loss 0.05522789 - samples/sec: 66.51 - lr: 0.000015
2021-06-22 06:08:18,683 epoch 26 - iter 640/1609 - loss 0.05763931 - samples/sec: 66.40 - lr: 0.000015
2021-06-22 06:09:35,608 epoch 26 - iter 800/1609 - loss 0.05745697 - samples/sec: 66.57 - lr: 0.000015
2021-06-22 06:10:52,819 epoch 26 - iter 960/1609 - loss 0.05787936 - samples/sec: 66.32 - lr: 0.000015
2021-06-22 06:12:09,971 epoch 26 - iter 1120/1609 - loss 0.05824127 - samples/sec: 66.37 - lr: 0.000015
2021-06-22 06:13:27,584 epoch 26 - iter 1280/1609 - loss 0.05948314 - samples/sec: 65.97 - lr: 0.000015
2021-06-22 06:14:44,945 epoch 26 - iter 1440/1609 - loss 0.06025247 - samples/sec: 66.19 - lr: 0.000015
2021-06-22 06:16:02,048 epoch 26 - iter 1600/1609 - loss 0.06059568 - samples/sec: 66.41 - lr: 0.000015
2021-06-22 06:16:06,309 ----------------------------------------------------------------------------------------------------
2021-06-22 06:16:06,309 EPOCH 26 done: loss 0.0605 - lr 0.0000150
2021-06-22 06:16:16,118 DEV : loss 0.10998920351266861 - score 0.9812
2021-06-22 06:16:16,254 BAD EPOCHS (no improvement): 1
2021-06-22 06:16:16,255 ----------------------------------------------------------------------------------------------------
2021-06-22 06:17:33,221 epoch 27 - iter 160/1609 - loss 0.06100103 - samples/sec: 66.53 - lr: 0.000015
2021-06-22 06:18:50,188 epoch 27 - iter 320/1609 - loss 0.05956909 - samples/sec: 66.53 - lr: 0.000015
2021-06-22 06:20:06,999 epoch 27 - iter 480/1609 - loss 0.05878809 - samples/sec: 66.66 - lr: 0.000015
2021-06-22 06:21:23,816 epoch 27 - iter 640/1609 - loss 0.05841098 - samples/sec: 66.66 - lr: 0.000015
2021-06-22 06:22:40,577 epoch 27 - iter 800/1609 - loss 0.05951615 - samples/sec: 66.71 - lr: 0.000015
2021-06-22 06:23:57,319 epoch 27 - iter 960/1609 - loss 0.05804333 - samples/sec: 66.72 - lr: 0.000015
2021-06-22 06:25:14,028 epoch 27 - iter 1120/1609 - loss 0.05907853 - samples/sec: 66.75 - lr: 0.000015
2021-06-22 06:26:30,853 epoch 27 - iter 1280/1609 - loss 0.05942137 - samples/sec: 66.65 - lr: 0.000015
2021-06-22 06:27:47,665 epoch 27 - iter 1440/1609 - loss 0.05943314 - samples/sec: 66.66 - lr: 0.000015
2021-06-22 06:29:04,434 epoch 27 - iter 1600/1609 - loss 0.05894245 - samples/sec: 66.70 - lr: 0.000015
2021-06-22 06:29:08,598 ----------------------------------------------------------------------------------------------------
2021-06-22 06:29:08,598 EPOCH 27 done: loss 0.0590 - lr 0.0000150
2021-06-22 06:29:18,410 DEV : loss 0.10966315865516663 - score 0.9818
2021-06-22 06:29:18,548 BAD EPOCHS (no improvement): 2
2021-06-22 06:29:18,548 ----------------------------------------------------------------------------------------------------
2021-06-22 06:30:35,305 epoch 28 - iter 160/1609 - loss 0.05991556 - samples/sec: 66.71 - lr: 0.000015
2021-06-22 06:31:52,285 epoch 28 - iter 320/1609 - loss 0.05719812 - samples/sec: 66.52 - lr: 0.000015
2021-06-22 06:33:09,095 epoch 28 - iter 480/1609 - loss 0.05864983 - samples/sec: 66.66 - lr: 0.000015
2021-06-22 06:34:25,897 epoch 28 - iter 640/1609 - loss 0.05808235 - samples/sec: 66.67 - lr: 0.000015
2021-06-22 06:35:42,767 epoch 28 - iter 800/1609 - loss 0.05931281 - samples/sec: 66.61 - lr: 0.000015
2021-06-22 06:36:59,600 epoch 28 - iter 960/1609 - loss 0.05987902 - samples/sec: 66.64 - lr: 0.000015
2021-06-22 06:38:16,385 epoch 28 - iter 1120/1609 - loss 0.05934396 - samples/sec: 66.69 - lr: 0.000015
2021-06-22 06:39:33,451 epoch 28 - iter 1280/1609 - loss 0.05875515 - samples/sec: 66.44 - lr: 0.000015
2021-06-22 06:40:50,496 epoch 28 - iter 1440/1609 - loss 0.05761277 - samples/sec: 66.46 - lr: 0.000015
2021-06-22 06:42:07,618 epoch 28 - iter 1600/1609 - loss 0.05727655 - samples/sec: 66.40 - lr: 0.000015
2021-06-22 06:42:11,853 ----------------------------------------------------------------------------------------------------
2021-06-22 06:42:11,853 EPOCH 28 done: loss 0.0572 - lr 0.0000150
2021-06-22 06:42:21,657 DEV : loss 0.10900592058897018 - score 0.9833
2021-06-22 06:42:21,796 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 06:42:36,580 ----------------------------------------------------------------------------------------------------
2021-06-22 06:43:56,246 epoch 29 - iter 160/1609 - loss 0.04228603 - samples/sec: 64.28 - lr: 0.000015
2021-06-22 06:45:13,306 epoch 29 - iter 320/1609 - loss 0.04739477 - samples/sec: 66.45 - lr: 0.000015
2021-06-22 06:46:30,631 epoch 29 - iter 480/1609 - loss 0.04930175 - samples/sec: 66.22 - lr: 0.000015
2021-06-22 06:47:48,017 epoch 29 - iter 640/1609 - loss 0.04989499 - samples/sec: 66.17 - lr: 0.000015
2021-06-22 06:49:05,265 epoch 29 - iter 800/1609 - loss 0.05036085 - samples/sec: 66.29 - lr: 0.000015
2021-06-22 06:50:22,605 epoch 29 - iter 960/1609 - loss 0.05016187 - samples/sec: 66.21 - lr: 0.000015
2021-06-22 06:51:39,656 epoch 29 - iter 1120/1609 - loss 0.05075427 - samples/sec: 66.46 - lr: 0.000015
2021-06-22 06:52:56,405 epoch 29 - iter 1280/1609 - loss 0.05226178 - samples/sec: 66.72 - lr: 0.000015
2021-06-22 06:54:13,346 epoch 29 - iter 1440/1609 - loss 0.05220812 - samples/sec: 66.55 - lr: 0.000015
2021-06-22 06:55:30,617 epoch 29 - iter 1600/1609 - loss 0.05288617 - samples/sec: 66.27 - lr: 0.000015
2021-06-22 06:55:34,862 ----------------------------------------------------------------------------------------------------
2021-06-22 06:55:34,862 EPOCH 29 done: loss 0.0528 - lr 0.0000150
2021-06-22 06:55:44,674 DEV : loss 0.11705933511257172 - score 0.9818
2021-06-22 06:55:44,811 BAD EPOCHS (no improvement): 1
2021-06-22 06:55:44,811 ----------------------------------------------------------------------------------------------------
2021-06-22 06:57:01,780 epoch 30 - iter 160/1609 - loss 0.05050606 - samples/sec: 66.53 - lr: 0.000015
2021-06-22 06:58:18,658 epoch 30 - iter 320/1609 - loss 0.05138945 - samples/sec: 66.61 - lr: 0.000015
2021-06-22 06:59:35,449 epoch 30 - iter 480/1609 - loss 0.05298837 - samples/sec: 66.68 - lr: 0.000015
2021-06-22 07:00:52,112 epoch 30 - iter 640/1609 - loss 0.05293488 - samples/sec: 66.79 - lr: 0.000015
2021-06-22 07:02:09,031 epoch 30 - iter 800/1609 - loss 0.05485547 - samples/sec: 66.57 - lr: 0.000015
2021-06-22 07:03:26,271 epoch 30 - iter 960/1609 - loss 0.05503518 - samples/sec: 66.29 - lr: 0.000015
2021-06-22 07:04:43,385 epoch 30 - iter 1120/1609 - loss 0.05540484 - samples/sec: 66.40 - lr: 0.000015
2021-06-22 07:06:00,485 epoch 30 - iter 1280/1609 - loss 0.05564708 - samples/sec: 66.41 - lr: 0.000015
2021-06-22 07:07:17,429 epoch 30 - iter 1440/1609 - loss 0.05534649 - samples/sec: 66.55 - lr: 0.000015
2021-06-22 07:08:34,460 epoch 30 - iter 1600/1609 - loss 0.05463463 - samples/sec: 66.47 - lr: 0.000015
2021-06-22 07:08:38,697 ----------------------------------------------------------------------------------------------------
2021-06-22 07:08:38,697 EPOCH 30 done: loss 0.0545 - lr 0.0000150
2021-06-22 07:08:48,502 DEV : loss 0.11104562878608704 - score 0.9812
2021-06-22 07:08:48,639 BAD EPOCHS (no improvement): 2
2021-06-22 07:08:48,640 ----------------------------------------------------------------------------------------------------
2021-06-22 07:10:05,390 epoch 31 - iter 160/1609 - loss 0.05005273 - samples/sec: 66.72 - lr: 0.000015
2021-06-22 07:11:22,028 epoch 31 - iter 320/1609 - loss 0.04819016 - samples/sec: 66.81 - lr: 0.000015
2021-06-22 07:12:38,661 epoch 31 - iter 480/1609 - loss 0.04870831 - samples/sec: 66.82 - lr: 0.000015
2021-06-22 07:13:55,512 epoch 31 - iter 640/1609 - loss 0.04937735 - samples/sec: 66.63 - lr: 0.000015
2021-06-22 07:15:12,183 epoch 31 - iter 800/1609 - loss 0.04843803 - samples/sec: 66.79 - lr: 0.000015
2021-06-22 07:16:29,025 epoch 31 - iter 960/1609 - loss 0.04945220 - samples/sec: 66.64 - lr: 0.000015
2021-06-22 07:17:46,098 epoch 31 - iter 1120/1609 - loss 0.04968665 - samples/sec: 66.44 - lr: 0.000015
2021-06-22 07:19:03,270 epoch 31 - iter 1280/1609 - loss 0.05005949 - samples/sec: 66.35 - lr: 0.000015
2021-06-22 07:20:20,024 epoch 31 - iter 1440/1609 - loss 0.05066953 - samples/sec: 66.71 - lr: 0.000015
2021-06-22 07:21:36,914 epoch 31 - iter 1600/1609 - loss 0.05043875 - samples/sec: 66.60 - lr: 0.000015
2021-06-22 07:21:41,155 ----------------------------------------------------------------------------------------------------
2021-06-22 07:21:41,156 EPOCH 31 done: loss 0.0505 - lr 0.0000150
2021-06-22 07:21:50,964 DEV : loss 0.10828480124473572 - score 0.9827
2021-06-22 07:21:51,101 BAD EPOCHS (no improvement): 3
2021-06-22 07:21:51,101 ----------------------------------------------------------------------------------------------------
2021-06-22 07:23:07,873 epoch 32 - iter 160/1609 - loss 0.05320144 - samples/sec: 66.70 - lr: 0.000015
2021-06-22 07:24:24,413 epoch 32 - iter 320/1609 - loss 0.05199649 - samples/sec: 66.90 - lr: 0.000015
2021-06-22 07:25:41,537 epoch 32 - iter 480/1609 - loss 0.05196560 - samples/sec: 66.39 - lr: 0.000015
2021-06-22 07:26:58,350 epoch 32 - iter 640/1609 - loss 0.05056217 - samples/sec: 66.66 - lr: 0.000015
2021-06-22 07:28:15,630 epoch 32 - iter 800/1609 - loss 0.05002376 - samples/sec: 66.26 - lr: 0.000015
2021-06-22 07:29:32,484 epoch 32 - iter 960/1609 - loss 0.04954989 - samples/sec: 66.63 - lr: 0.000015
2021-06-22 07:30:49,688 epoch 32 - iter 1120/1609 - loss 0.05085816 - samples/sec: 66.32 - lr: 0.000015
2021-06-22 07:32:06,864 epoch 32 - iter 1280/1609 - loss 0.05123342 - samples/sec: 66.35 - lr: 0.000015
2021-06-22 07:33:24,052 epoch 32 - iter 1440/1609 - loss 0.05066537 - samples/sec: 66.34 - lr: 0.000015
2021-06-22 07:34:41,210 epoch 32 - iter 1600/1609 - loss 0.05088707 - samples/sec: 66.36 - lr: 0.000015
2021-06-22 07:34:45,441 ----------------------------------------------------------------------------------------------------
2021-06-22 07:34:45,441 EPOCH 32 done: loss 0.0508 - lr 0.0000150
2021-06-22 07:34:55,256 DEV : loss 0.11453165113925934 - score 0.9815
Epoch    32: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 07:34:55,394 BAD EPOCHS (no improvement): 4
2021-06-22 07:34:55,394 ----------------------------------------------------------------------------------------------------
2021-06-22 07:36:12,337 epoch 33 - iter 160/1609 - loss 0.04931502 - samples/sec: 66.55 - lr: 0.000008
2021-06-22 07:37:29,332 epoch 33 - iter 320/1609 - loss 0.04472408 - samples/sec: 66.50 - lr: 0.000008
2021-06-22 07:38:46,420 epoch 33 - iter 480/1609 - loss 0.04397429 - samples/sec: 66.42 - lr: 0.000008
2021-06-22 07:40:03,427 epoch 33 - iter 640/1609 - loss 0.04478047 - samples/sec: 66.49 - lr: 0.000008
2021-06-22 07:41:20,745 epoch 33 - iter 800/1609 - loss 0.04447580 - samples/sec: 66.23 - lr: 0.000008
2021-06-22 07:42:37,615 epoch 33 - iter 960/1609 - loss 0.04526475 - samples/sec: 66.61 - lr: 0.000008
2021-06-22 07:43:54,379 epoch 33 - iter 1120/1609 - loss 0.04506738 - samples/sec: 66.70 - lr: 0.000008
2021-06-22 07:45:11,145 epoch 33 - iter 1280/1609 - loss 0.04506431 - samples/sec: 66.70 - lr: 0.000008
2021-06-22 07:46:27,881 epoch 33 - iter 1440/1609 - loss 0.04466843 - samples/sec: 66.73 - lr: 0.000008
2021-06-22 07:47:44,577 epoch 33 - iter 1600/1609 - loss 0.04502984 - samples/sec: 66.76 - lr: 0.000008
2021-06-22 07:47:48,812 ----------------------------------------------------------------------------------------------------
2021-06-22 07:47:48,813 EPOCH 33 done: loss 0.0451 - lr 0.0000075
2021-06-22 07:48:01,433 DEV : loss 0.11269750446081161 - score 0.9827
2021-06-22 07:48:01,573 BAD EPOCHS (no improvement): 1
2021-06-22 07:48:01,573 ----------------------------------------------------------------------------------------------------
2021-06-22 07:49:18,434 epoch 34 - iter 160/1609 - loss 0.04495627 - samples/sec: 66.62 - lr: 0.000008
2021-06-22 07:50:35,172 epoch 34 - iter 320/1609 - loss 0.04694067 - samples/sec: 66.73 - lr: 0.000008
2021-06-22 07:51:51,990 epoch 34 - iter 480/1609 - loss 0.04562863 - samples/sec: 66.66 - lr: 0.000008
2021-06-22 07:53:08,723 epoch 34 - iter 640/1609 - loss 0.04371404 - samples/sec: 66.73 - lr: 0.000008
2021-06-22 07:54:25,754 epoch 34 - iter 800/1609 - loss 0.04490245 - samples/sec: 66.47 - lr: 0.000008
2021-06-22 07:55:43,001 epoch 34 - iter 960/1609 - loss 0.04501924 - samples/sec: 66.29 - lr: 0.000008
2021-06-22 07:57:00,070 epoch 34 - iter 1120/1609 - loss 0.04501156 - samples/sec: 66.44 - lr: 0.000008
2021-06-22 07:58:17,039 epoch 34 - iter 1280/1609 - loss 0.04559293 - samples/sec: 66.53 - lr: 0.000008
2021-06-22 07:59:34,274 epoch 34 - iter 1440/1609 - loss 0.04612024 - samples/sec: 66.30 - lr: 0.000008
2021-06-22 08:00:51,413 epoch 34 - iter 1600/1609 - loss 0.04570713 - samples/sec: 66.38 - lr: 0.000008
2021-06-22 08:00:55,666 ----------------------------------------------------------------------------------------------------
2021-06-22 08:00:55,667 EPOCH 34 done: loss 0.0461 - lr 0.0000075
2021-06-22 08:01:05,479 DEV : loss 0.11793071776628494 - score 0.9821
2021-06-22 08:01:05,617 BAD EPOCHS (no improvement): 2
2021-06-22 08:01:05,617 ----------------------------------------------------------------------------------------------------
2021-06-22 08:02:22,628 epoch 35 - iter 160/1609 - loss 0.04155421 - samples/sec: 66.49 - lr: 0.000008
2021-06-22 08:03:39,834 epoch 35 - iter 320/1609 - loss 0.03975785 - samples/sec: 66.32 - lr: 0.000008
2021-06-22 08:04:57,065 epoch 35 - iter 480/1609 - loss 0.04260666 - samples/sec: 66.30 - lr: 0.000008
2021-06-22 08:06:14,532 epoch 35 - iter 640/1609 - loss 0.04319223 - samples/sec: 66.10 - lr: 0.000008
2021-06-22 08:07:31,883 epoch 35 - iter 800/1609 - loss 0.04312402 - samples/sec: 66.20 - lr: 0.000008
2021-06-22 08:08:49,087 epoch 35 - iter 960/1609 - loss 0.04260666 - samples/sec: 66.33 - lr: 0.000008
2021-06-22 08:10:06,317 epoch 35 - iter 1120/1609 - loss 0.04267948 - samples/sec: 66.30 - lr: 0.000008
2021-06-22 08:11:23,467 epoch 35 - iter 1280/1609 - loss 0.04276064 - samples/sec: 66.37 - lr: 0.000008
2021-06-22 08:12:40,767 epoch 35 - iter 1440/1609 - loss 0.04308166 - samples/sec: 66.24 - lr: 0.000008
2021-06-22 08:13:58,088 epoch 35 - iter 1600/1609 - loss 0.04278609 - samples/sec: 66.22 - lr: 0.000008
2021-06-22 08:14:02,322 ----------------------------------------------------------------------------------------------------
2021-06-22 08:14:02,323 EPOCH 35 done: loss 0.0430 - lr 0.0000075
2021-06-22 08:14:12,118 DEV : loss 0.11470093578100204 - score 0.9821
2021-06-22 08:14:12,255 BAD EPOCHS (no improvement): 3
2021-06-22 08:14:12,255 ----------------------------------------------------------------------------------------------------
2021-06-22 08:15:29,261 epoch 36 - iter 160/1609 - loss 0.04247164 - samples/sec: 66.50 - lr: 0.000008
2021-06-22 08:16:46,638 epoch 36 - iter 320/1609 - loss 0.04244377 - samples/sec: 66.18 - lr: 0.000008
2021-06-22 08:18:03,929 epoch 36 - iter 480/1609 - loss 0.04445989 - samples/sec: 66.25 - lr: 0.000008
2021-06-22 08:19:21,086 epoch 36 - iter 640/1609 - loss 0.04475380 - samples/sec: 66.36 - lr: 0.000008
2021-06-22 08:20:38,136 epoch 36 - iter 800/1609 - loss 0.04438874 - samples/sec: 66.46 - lr: 0.000008
2021-06-22 08:21:55,139 epoch 36 - iter 960/1609 - loss 0.04414667 - samples/sec: 66.50 - lr: 0.000008
2021-06-22 08:23:12,175 epoch 36 - iter 1120/1609 - loss 0.04388703 - samples/sec: 66.47 - lr: 0.000008
2021-06-22 08:24:29,364 epoch 36 - iter 1280/1609 - loss 0.04367754 - samples/sec: 66.34 - lr: 0.000008
2021-06-22 08:25:46,367 epoch 36 - iter 1440/1609 - loss 0.04409231 - samples/sec: 66.50 - lr: 0.000008
2021-06-22 08:27:03,136 epoch 36 - iter 1600/1609 - loss 0.04399719 - samples/sec: 66.70 - lr: 0.000008
2021-06-22 08:27:07,395 ----------------------------------------------------------------------------------------------------
2021-06-22 08:27:07,396 EPOCH 36 done: loss 0.0442 - lr 0.0000075
2021-06-22 08:27:17,206 DEV : loss 0.11813122034072876 - score 0.9824
Epoch    36: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 08:27:17,345 BAD EPOCHS (no improvement): 4
2021-06-22 08:27:17,345 ----------------------------------------------------------------------------------------------------
2021-06-22 08:28:34,086 epoch 37 - iter 160/1609 - loss 0.04890743 - samples/sec: 66.73 - lr: 0.000004
2021-06-22 08:29:51,056 epoch 37 - iter 320/1609 - loss 0.04343148 - samples/sec: 66.53 - lr: 0.000004
2021-06-22 08:31:08,058 epoch 37 - iter 480/1609 - loss 0.04332839 - samples/sec: 66.50 - lr: 0.000004
2021-06-22 08:32:25,131 epoch 37 - iter 640/1609 - loss 0.04403946 - samples/sec: 66.44 - lr: 0.000004
2021-06-22 08:33:41,958 epoch 37 - iter 800/1609 - loss 0.04423727 - samples/sec: 66.65 - lr: 0.000004
2021-06-22 08:34:59,035 epoch 37 - iter 960/1609 - loss 0.04299003 - samples/sec: 66.43 - lr: 0.000004
2021-06-22 08:36:16,182 epoch 37 - iter 1120/1609 - loss 0.04331759 - samples/sec: 66.37 - lr: 0.000004
2021-06-22 08:37:33,452 epoch 37 - iter 1280/1609 - loss 0.04399093 - samples/sec: 66.27 - lr: 0.000004
2021-06-22 08:38:50,752 epoch 37 - iter 1440/1609 - loss 0.04297974 - samples/sec: 66.24 - lr: 0.000004
2021-06-22 08:40:07,890 epoch 37 - iter 1600/1609 - loss 0.04362206 - samples/sec: 66.38 - lr: 0.000004
2021-06-22 08:40:12,161 ----------------------------------------------------------------------------------------------------
2021-06-22 08:40:12,161 EPOCH 37 done: loss 0.0436 - lr 0.0000038
2021-06-22 08:40:21,979 DEV : loss 0.1176275834441185 - score 0.9824
2021-06-22 08:40:22,118 BAD EPOCHS (no improvement): 1
2021-06-22 08:40:22,118 ----------------------------------------------------------------------------------------------------
2021-06-22 08:41:39,267 epoch 38 - iter 160/1609 - loss 0.04115576 - samples/sec: 66.37 - lr: 0.000004
2021-06-22 08:42:56,328 epoch 38 - iter 320/1609 - loss 0.04044633 - samples/sec: 66.45 - lr: 0.000004
2021-06-22 08:44:13,608 epoch 38 - iter 480/1609 - loss 0.03918674 - samples/sec: 66.26 - lr: 0.000004
2021-06-22 08:45:30,778 epoch 38 - iter 640/1609 - loss 0.04005947 - samples/sec: 66.35 - lr: 0.000004
2021-06-22 08:46:47,890 epoch 38 - iter 800/1609 - loss 0.03915298 - samples/sec: 66.40 - lr: 0.000004
2021-06-22 08:48:05,342 epoch 38 - iter 960/1609 - loss 0.04025697 - samples/sec: 66.11 - lr: 0.000004
2021-06-22 08:49:22,858 epoch 38 - iter 1120/1609 - loss 0.03987369 - samples/sec: 66.06 - lr: 0.000004
2021-06-22 08:50:40,399 epoch 38 - iter 1280/1609 - loss 0.04085433 - samples/sec: 66.04 - lr: 0.000004
2021-06-22 08:51:57,860 epoch 38 - iter 1440/1609 - loss 0.04126768 - samples/sec: 66.10 - lr: 0.000004
2021-06-22 08:53:18,012 epoch 38 - iter 1600/1609 - loss 0.04151630 - samples/sec: 63.88 - lr: 0.000004
2021-06-22 08:53:22,246 ----------------------------------------------------------------------------------------------------
2021-06-22 08:53:22,246 EPOCH 38 done: loss 0.0414 - lr 0.0000038
2021-06-22 08:53:32,035 DEV : loss 0.11824869364500046 - score 0.9824
2021-06-22 08:53:32,171 BAD EPOCHS (no improvement): 2
2021-06-22 08:53:32,171 ----------------------------------------------------------------------------------------------------
2021-06-22 08:54:49,468 epoch 39 - iter 160/1609 - loss 0.03923027 - samples/sec: 66.25 - lr: 0.000004
2021-06-22 08:56:06,622 epoch 39 - iter 320/1609 - loss 0.04263843 - samples/sec: 66.37 - lr: 0.000004
2021-06-22 08:57:23,762 epoch 39 - iter 480/1609 - loss 0.04193577 - samples/sec: 66.38 - lr: 0.000004
2021-06-22 08:58:40,841 epoch 39 - iter 640/1609 - loss 0.03962945 - samples/sec: 66.43 - lr: 0.000004
2021-06-22 08:59:57,694 epoch 39 - iter 800/1609 - loss 0.03895390 - samples/sec: 66.63 - lr: 0.000004
2021-06-22 09:01:14,255 epoch 39 - iter 960/1609 - loss 0.03986854 - samples/sec: 66.88 - lr: 0.000004
2021-06-22 09:02:31,492 epoch 39 - iter 1120/1609 - loss 0.03994126 - samples/sec: 66.30 - lr: 0.000004
2021-06-22 09:03:48,772 epoch 39 - iter 1280/1609 - loss 0.03985918 - samples/sec: 66.26 - lr: 0.000004
2021-06-22 09:05:05,908 epoch 39 - iter 1440/1609 - loss 0.03968586 - samples/sec: 66.38 - lr: 0.000004
2021-06-22 09:06:23,191 epoch 39 - iter 1600/1609 - loss 0.03939506 - samples/sec: 66.26 - lr: 0.000004
2021-06-22 09:06:27,460 ----------------------------------------------------------------------------------------------------
2021-06-22 09:06:27,460 EPOCH 39 done: loss 0.0393 - lr 0.0000038
2021-06-22 09:06:37,275 DEV : loss 0.11978579312562943 - score 0.9818
2021-06-22 09:06:37,412 BAD EPOCHS (no improvement): 3
2021-06-22 09:06:37,412 ----------------------------------------------------------------------------------------------------
2021-06-22 09:07:54,486 epoch 40 - iter 160/1609 - loss 0.03720685 - samples/sec: 66.44 - lr: 0.000004
2021-06-22 09:09:11,432 epoch 40 - iter 320/1609 - loss 0.03827197 - samples/sec: 66.55 - lr: 0.000004
2021-06-22 09:10:28,194 epoch 40 - iter 480/1609 - loss 0.03621606 - samples/sec: 66.71 - lr: 0.000004
2021-06-22 09:11:45,490 epoch 40 - iter 640/1609 - loss 0.03760514 - samples/sec: 66.25 - lr: 0.000004
2021-06-22 09:13:02,827 epoch 40 - iter 800/1609 - loss 0.03659237 - samples/sec: 66.21 - lr: 0.000004
2021-06-22 09:14:20,044 epoch 40 - iter 960/1609 - loss 0.03721619 - samples/sec: 66.31 - lr: 0.000004
2021-06-22 09:15:36,796 epoch 40 - iter 1120/1609 - loss 0.03787732 - samples/sec: 66.72 - lr: 0.000004
2021-06-22 09:16:54,068 epoch 40 - iter 1280/1609 - loss 0.03803820 - samples/sec: 66.27 - lr: 0.000004
2021-06-22 09:18:11,077 epoch 40 - iter 1440/1609 - loss 0.03813674 - samples/sec: 66.49 - lr: 0.000004
2021-06-22 09:19:28,220 epoch 40 - iter 1600/1609 - loss 0.03857644 - samples/sec: 66.38 - lr: 0.000004
2021-06-22 09:19:32,485 ----------------------------------------------------------------------------------------------------
2021-06-22 09:19:32,485 EPOCH 40 done: loss 0.0389 - lr 0.0000038
2021-06-22 09:19:42,290 DEV : loss 0.11965814977884293 - score 0.9824
Epoch    40: reducing learning rate of group 0 to 1.8750e-06.
2021-06-22 09:19:42,426 BAD EPOCHS (no improvement): 4
2021-06-22 09:19:43,545 ----------------------------------------------------------------------------------------------------
2021-06-22 09:19:43,545 Testing using best model ...
2021-06-22 09:19:43,545 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/best-model.pt
2021-06-22 09:20:51,911 0.9724	0.9700	0.9712
2021-06-22 09:20:51,911 
Results:
- F1-score (micro) 0.9712
- F1-score (macro) 0.9712

By class:
SENT       tp: 2293 - fp: 65 - fn: 71 - precision: 0.9724 - recall: 0.9700 - f1-score: 0.9712
2021-06-22 09:20:51,911 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/
2021-06-22 09:20:51,944 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum
2021-06-22 09:20:51,945 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/sent_train.txt
2021-06-22 09:20:51,947 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/sent_dev.txt
2021-06-22 09:20:51,947 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/sent_test.txt
Corpus: 3228 train + 752 dev + 767 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 09:20:59,347 ----------------------------------------------------------------------------------------------------
2021-06-22 09:20:59,350 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50265, 1024, padding_idx=1)
          (position_embeddings): Embedding(514, 1024, padding_idx=1)
          (token_type_embeddings): Embedding(1, 1024)
          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (12): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (13): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (14): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (15): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (16): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (17): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (18): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (19): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (20): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (21): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (22): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (23): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4146, out_features=4146, bias=True)
  (rnn): LSTM(4146, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 09:20:59,350 ----------------------------------------------------------------------------------------------------
2021-06-22 09:20:59,350 Corpus: "Corpus: 3228 train + 752 dev + 767 test sentences"
2021-06-22 09:20:59,350 ----------------------------------------------------------------------------------------------------
2021-06-22 09:20:59,350 Parameters:
2021-06-22 09:20:59,350  - learning_rate: "3e-05"
2021-06-22 09:20:59,350  - mini_batch_size: "32"
2021-06-22 09:20:59,350  - patience: "3"
2021-06-22 09:20:59,350  - anneal_factor: "0.5"
2021-06-22 09:20:59,350  - max_epochs: "40"
2021-06-22 09:20:59,350  - shuffle: "True"
2021-06-22 09:20:59,350  - train_with_dev: "False"
2021-06-22 09:20:59,350  - batch_growth_annealing: "False"
2021-06-22 09:20:59,350 ----------------------------------------------------------------------------------------------------
2021-06-22 09:20:59,351 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum"
2021-06-22 09:20:59,351 ----------------------------------------------------------------------------------------------------
2021-06-22 09:20:59,351 Device: cuda:0
2021-06-22 09:20:59,351 ----------------------------------------------------------------------------------------------------
2021-06-22 09:20:59,351 Embeddings storage mode: cpu
2021-06-22 09:20:59,352 ----------------------------------------------------------------------------------------------------
2021-06-22 09:21:12,782 epoch 1 - iter 10/101 - loss 14.93536873 - samples/sec: 23.83 - lr: 0.000030
2021-06-22 09:21:26,024 epoch 1 - iter 20/101 - loss 10.25480580 - samples/sec: 24.17 - lr: 0.000030
2021-06-22 09:21:39,188 epoch 1 - iter 30/101 - loss 8.28363252 - samples/sec: 24.31 - lr: 0.000030
2021-06-22 09:21:52,277 epoch 1 - iter 40/101 - loss 7.00287247 - samples/sec: 24.45 - lr: 0.000030
2021-06-22 09:22:05,402 epoch 1 - iter 50/101 - loss 6.05590298 - samples/sec: 24.38 - lr: 0.000030
2021-06-22 09:22:18,487 epoch 1 - iter 60/101 - loss 5.33205810 - samples/sec: 24.46 - lr: 0.000030
2021-06-22 09:22:31,538 epoch 1 - iter 70/101 - loss 4.78132756 - samples/sec: 24.52 - lr: 0.000030
2021-06-22 09:22:44,572 epoch 1 - iter 80/101 - loss 4.32682062 - samples/sec: 24.55 - lr: 0.000030
2021-06-22 09:22:57,554 epoch 1 - iter 90/101 - loss 3.96350898 - samples/sec: 24.65 - lr: 0.000030
2021-06-22 09:23:10,525 epoch 1 - iter 100/101 - loss 3.67735477 - samples/sec: 24.67 - lr: 0.000030
2021-06-22 09:23:11,669 ----------------------------------------------------------------------------------------------------
2021-06-22 09:23:11,669 EPOCH 1 done: loss 3.6537 - lr 0.0000300
2021-06-22 09:23:31,384 DEV : loss 0.648250937461853 - score 0.8976
2021-06-22 09:23:31,437 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:23:32,542 ----------------------------------------------------------------------------------------------------
2021-06-22 09:23:37,327 epoch 2 - iter 10/101 - loss 1.06804793 - samples/sec: 66.89 - lr: 0.000030
2021-06-22 09:23:42,114 epoch 2 - iter 20/101 - loss 1.06148038 - samples/sec: 66.86 - lr: 0.000030
2021-06-22 09:23:46,910 epoch 2 - iter 30/101 - loss 1.01631601 - samples/sec: 66.73 - lr: 0.000030
2021-06-22 09:23:51,682 epoch 2 - iter 40/101 - loss 0.95750061 - samples/sec: 67.06 - lr: 0.000030
2021-06-22 09:23:56,471 epoch 2 - iter 50/101 - loss 0.95503840 - samples/sec: 66.84 - lr: 0.000030
2021-06-22 09:24:01,222 epoch 2 - iter 60/101 - loss 0.96647509 - samples/sec: 67.35 - lr: 0.000030
2021-06-22 09:24:06,017 epoch 2 - iter 70/101 - loss 0.95374430 - samples/sec: 66.75 - lr: 0.000030
2021-06-22 09:24:10,811 epoch 2 - iter 80/101 - loss 0.92327513 - samples/sec: 66.76 - lr: 0.000030
2021-06-22 09:24:15,583 epoch 2 - iter 90/101 - loss 0.91048271 - samples/sec: 67.07 - lr: 0.000030
2021-06-22 09:24:20,369 epoch 2 - iter 100/101 - loss 0.90008995 - samples/sec: 66.88 - lr: 0.000030
2021-06-22 09:24:20,792 ----------------------------------------------------------------------------------------------------
2021-06-22 09:24:20,793 EPOCH 2 done: loss 0.8988 - lr 0.0000300
2021-06-22 09:24:24,593 DEV : loss 0.49353712797164917 - score 0.9201
2021-06-22 09:24:24,645 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:24:39,656 ----------------------------------------------------------------------------------------------------
2021-06-22 09:24:44,451 epoch 3 - iter 10/101 - loss 0.76047949 - samples/sec: 66.76 - lr: 0.000030
2021-06-22 09:24:49,257 epoch 3 - iter 20/101 - loss 0.80169942 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 09:24:54,087 epoch 3 - iter 30/101 - loss 0.74978141 - samples/sec: 66.26 - lr: 0.000030
2021-06-22 09:24:58,909 epoch 3 - iter 40/101 - loss 0.74502663 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 09:25:03,726 epoch 3 - iter 50/101 - loss 0.72150027 - samples/sec: 66.44 - lr: 0.000030
2021-06-22 09:25:08,511 epoch 3 - iter 60/101 - loss 0.75934381 - samples/sec: 66.90 - lr: 0.000030
2021-06-22 09:25:13,308 epoch 3 - iter 70/101 - loss 0.74681938 - samples/sec: 66.71 - lr: 0.000030
2021-06-22 09:25:18,097 epoch 3 - iter 80/101 - loss 0.73038110 - samples/sec: 66.83 - lr: 0.000030
2021-06-22 09:25:22,890 epoch 3 - iter 90/101 - loss 0.72948338 - samples/sec: 66.78 - lr: 0.000030
2021-06-22 09:25:27,680 epoch 3 - iter 100/101 - loss 0.71763895 - samples/sec: 66.81 - lr: 0.000030
2021-06-22 09:25:28,095 ----------------------------------------------------------------------------------------------------
2021-06-22 09:25:28,095 EPOCH 3 done: loss 0.7174 - lr 0.0000300
2021-06-22 09:25:42,304 DEV : loss 0.4359842538833618 - score 0.922
2021-06-22 09:25:42,357 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:25:58,023 ----------------------------------------------------------------------------------------------------
2021-06-22 09:26:02,948 epoch 4 - iter 10/101 - loss 0.68607084 - samples/sec: 65.00 - lr: 0.000030
2021-06-22 09:26:07,881 epoch 4 - iter 20/101 - loss 0.61289873 - samples/sec: 64.89 - lr: 0.000030
2021-06-22 09:26:12,791 epoch 4 - iter 30/101 - loss 0.62186947 - samples/sec: 65.18 - lr: 0.000030
2021-06-22 09:26:17,697 epoch 4 - iter 40/101 - loss 0.62526606 - samples/sec: 65.24 - lr: 0.000030
2021-06-22 09:26:22,609 epoch 4 - iter 50/101 - loss 0.63626083 - samples/sec: 65.15 - lr: 0.000030
2021-06-22 09:26:27,520 epoch 4 - iter 60/101 - loss 0.63194175 - samples/sec: 65.17 - lr: 0.000030
2021-06-22 09:26:32,463 epoch 4 - iter 70/101 - loss 0.62058002 - samples/sec: 64.75 - lr: 0.000030
2021-06-22 09:26:37,351 epoch 4 - iter 80/101 - loss 0.61006247 - samples/sec: 65.47 - lr: 0.000030
2021-06-22 09:26:42,280 epoch 4 - iter 90/101 - loss 0.61039946 - samples/sec: 64.94 - lr: 0.000030
2021-06-22 09:26:47,185 epoch 4 - iter 100/101 - loss 0.61623111 - samples/sec: 65.26 - lr: 0.000030
2021-06-22 09:26:47,625 ----------------------------------------------------------------------------------------------------
2021-06-22 09:26:47,625 EPOCH 4 done: loss 0.6162 - lr 0.0000300
2021-06-22 09:26:51,499 DEV : loss 0.37777814269065857 - score 0.9386
2021-06-22 09:26:51,553 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:27:04,878 ----------------------------------------------------------------------------------------------------
2021-06-22 09:27:09,775 epoch 5 - iter 10/101 - loss 0.62106545 - samples/sec: 65.37 - lr: 0.000030
2021-06-22 09:27:14,692 epoch 5 - iter 20/101 - loss 0.57040705 - samples/sec: 65.09 - lr: 0.000030
2021-06-22 09:27:19,633 epoch 5 - iter 30/101 - loss 0.56492597 - samples/sec: 64.78 - lr: 0.000030
2021-06-22 09:27:24,537 epoch 5 - iter 40/101 - loss 0.56282567 - samples/sec: 65.26 - lr: 0.000030
2021-06-22 09:27:29,482 epoch 5 - iter 50/101 - loss 0.56917967 - samples/sec: 64.73 - lr: 0.000030
2021-06-22 09:27:34,391 epoch 5 - iter 60/101 - loss 0.55820699 - samples/sec: 65.20 - lr: 0.000030
2021-06-22 09:27:39,270 epoch 5 - iter 70/101 - loss 0.53424364 - samples/sec: 65.60 - lr: 0.000030
2021-06-22 09:27:44,178 epoch 5 - iter 80/101 - loss 0.53493779 - samples/sec: 65.21 - lr: 0.000030
2021-06-22 09:27:49,083 epoch 5 - iter 90/101 - loss 0.53646241 - samples/sec: 65.25 - lr: 0.000030
2021-06-22 09:27:53,998 epoch 5 - iter 100/101 - loss 0.53371631 - samples/sec: 65.12 - lr: 0.000030
2021-06-22 09:27:54,430 ----------------------------------------------------------------------------------------------------
2021-06-22 09:27:54,430 EPOCH 5 done: loss 0.5320 - lr 0.0000300
2021-06-22 09:27:58,307 DEV : loss 0.3425742983818054 - score 0.9466
2021-06-22 09:27:58,361 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:28:07,183 ----------------------------------------------------------------------------------------------------
2021-06-22 09:28:12,118 epoch 6 - iter 10/101 - loss 0.54598625 - samples/sec: 64.87 - lr: 0.000030
2021-06-22 09:28:17,023 epoch 6 - iter 20/101 - loss 0.50663576 - samples/sec: 65.25 - lr: 0.000030
2021-06-22 09:28:21,953 epoch 6 - iter 30/101 - loss 0.49890891 - samples/sec: 64.92 - lr: 0.000030
2021-06-22 09:28:26,878 epoch 6 - iter 40/101 - loss 0.49707419 - samples/sec: 64.99 - lr: 0.000030
2021-06-22 09:28:31,786 epoch 6 - iter 50/101 - loss 0.48187059 - samples/sec: 65.21 - lr: 0.000030
2021-06-22 09:28:36,653 epoch 6 - iter 60/101 - loss 0.48789627 - samples/sec: 65.77 - lr: 0.000030
2021-06-22 09:28:41,562 epoch 6 - iter 70/101 - loss 0.49178772 - samples/sec: 65.19 - lr: 0.000030
2021-06-22 09:28:46,504 epoch 6 - iter 80/101 - loss 0.49215472 - samples/sec: 64.77 - lr: 0.000030
2021-06-22 09:28:51,409 epoch 6 - iter 90/101 - loss 0.49160471 - samples/sec: 65.25 - lr: 0.000030
2021-06-22 09:28:56,323 epoch 6 - iter 100/101 - loss 0.50360621 - samples/sec: 65.13 - lr: 0.000030
2021-06-22 09:28:56,763 ----------------------------------------------------------------------------------------------------
2021-06-22 09:28:56,763 EPOCH 6 done: loss 0.5025 - lr 0.0000300
2021-06-22 09:29:00,922 DEV : loss 0.3256060481071472 - score 0.9484
2021-06-22 09:29:00,975 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:29:09,724 ----------------------------------------------------------------------------------------------------
2021-06-22 09:29:14,657 epoch 7 - iter 10/101 - loss 0.38242233 - samples/sec: 64.88 - lr: 0.000030
2021-06-22 09:29:19,581 epoch 7 - iter 20/101 - loss 0.43745434 - samples/sec: 65.00 - lr: 0.000030
2021-06-22 09:29:24,506 epoch 7 - iter 30/101 - loss 0.44181897 - samples/sec: 64.98 - lr: 0.000030
2021-06-22 09:29:29,438 epoch 7 - iter 40/101 - loss 0.45892369 - samples/sec: 64.90 - lr: 0.000030
2021-06-22 09:29:34,348 epoch 7 - iter 50/101 - loss 0.45444414 - samples/sec: 65.18 - lr: 0.000030
2021-06-22 09:29:39,280 epoch 7 - iter 60/101 - loss 0.45197755 - samples/sec: 64.90 - lr: 0.000030
2021-06-22 09:29:44,159 epoch 7 - iter 70/101 - loss 0.45147817 - samples/sec: 65.60 - lr: 0.000030
2021-06-22 09:29:49,088 epoch 7 - iter 80/101 - loss 0.45422746 - samples/sec: 64.94 - lr: 0.000030
2021-06-22 09:29:54,012 epoch 7 - iter 90/101 - loss 0.45347313 - samples/sec: 64.99 - lr: 0.000030
2021-06-22 09:29:58,918 epoch 7 - iter 100/101 - loss 0.44901154 - samples/sec: 65.24 - lr: 0.000030
2021-06-22 09:29:59,362 ----------------------------------------------------------------------------------------------------
2021-06-22 09:29:59,363 EPOCH 7 done: loss 0.4503 - lr 0.0000300
2021-06-22 09:30:03,248 DEV : loss 0.3077046871185303 - score 0.9503
2021-06-22 09:30:03,302 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:30:12,180 ----------------------------------------------------------------------------------------------------
2021-06-22 09:30:17,096 epoch 8 - iter 10/101 - loss 0.38355272 - samples/sec: 65.12 - lr: 0.000030
2021-06-22 09:30:22,004 epoch 8 - iter 20/101 - loss 0.41045206 - samples/sec: 65.21 - lr: 0.000030
2021-06-22 09:30:26,932 epoch 8 - iter 30/101 - loss 0.44808996 - samples/sec: 64.96 - lr: 0.000030
2021-06-22 09:30:31,859 epoch 8 - iter 40/101 - loss 0.41911063 - samples/sec: 64.96 - lr: 0.000030
2021-06-22 09:30:36,795 epoch 8 - iter 50/101 - loss 0.39828877 - samples/sec: 64.84 - lr: 0.000030
2021-06-22 09:30:41,711 epoch 8 - iter 60/101 - loss 0.40095598 - samples/sec: 65.11 - lr: 0.000030
2021-06-22 09:30:46,678 epoch 8 - iter 70/101 - loss 0.41016134 - samples/sec: 64.43 - lr: 0.000030
2021-06-22 09:30:51,569 epoch 8 - iter 80/101 - loss 0.41423601 - samples/sec: 65.45 - lr: 0.000030
2021-06-22 09:30:56,523 epoch 8 - iter 90/101 - loss 0.41995074 - samples/sec: 64.60 - lr: 0.000030
2021-06-22 09:31:01,436 epoch 8 - iter 100/101 - loss 0.42210101 - samples/sec: 65.14 - lr: 0.000030
2021-06-22 09:31:01,877 ----------------------------------------------------------------------------------------------------
2021-06-22 09:31:01,877 EPOCH 8 done: loss 0.4216 - lr 0.0000300
2021-06-22 09:31:05,761 DEV : loss 0.2995925545692444 - score 0.9544
2021-06-22 09:31:05,816 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:31:14,384 ----------------------------------------------------------------------------------------------------
2021-06-22 09:31:19,280 epoch 9 - iter 10/101 - loss 0.39557592 - samples/sec: 65.38 - lr: 0.000030
2021-06-22 09:31:24,151 epoch 9 - iter 20/101 - loss 0.37254559 - samples/sec: 65.71 - lr: 0.000030
2021-06-22 09:31:29,098 epoch 9 - iter 30/101 - loss 0.39246444 - samples/sec: 64.69 - lr: 0.000030
2021-06-22 09:31:34,010 epoch 9 - iter 40/101 - loss 0.36535625 - samples/sec: 65.16 - lr: 0.000030
2021-06-22 09:31:38,904 epoch 9 - iter 50/101 - loss 0.37516510 - samples/sec: 65.40 - lr: 0.000030
2021-06-22 09:31:43,811 epoch 9 - iter 60/101 - loss 0.38759657 - samples/sec: 65.22 - lr: 0.000030
2021-06-22 09:31:48,763 epoch 9 - iter 70/101 - loss 0.38862295 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 09:31:53,703 epoch 9 - iter 80/101 - loss 0.39273287 - samples/sec: 64.79 - lr: 0.000030
2021-06-22 09:31:58,655 epoch 9 - iter 90/101 - loss 0.39450699 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 09:32:03,598 epoch 9 - iter 100/101 - loss 0.40284425 - samples/sec: 64.75 - lr: 0.000030
2021-06-22 09:32:04,042 ----------------------------------------------------------------------------------------------------
2021-06-22 09:32:04,042 EPOCH 9 done: loss 0.4011 - lr 0.0000300
2021-06-22 09:32:08,196 DEV : loss 0.28504741191864014 - score 0.959
2021-06-22 09:32:08,251 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:32:16,962 ----------------------------------------------------------------------------------------------------
2021-06-22 09:32:21,880 epoch 10 - iter 10/101 - loss 0.34131028 - samples/sec: 65.09 - lr: 0.000030
2021-06-22 09:32:26,818 epoch 10 - iter 20/101 - loss 0.36585739 - samples/sec: 64.82 - lr: 0.000030
2021-06-22 09:32:31,743 epoch 10 - iter 30/101 - loss 0.35148641 - samples/sec: 64.98 - lr: 0.000030
2021-06-22 09:32:36,673 epoch 10 - iter 40/101 - loss 0.37027143 - samples/sec: 64.93 - lr: 0.000030
2021-06-22 09:32:41,608 epoch 10 - iter 50/101 - loss 0.38431003 - samples/sec: 64.85 - lr: 0.000030
2021-06-22 09:32:46,518 epoch 10 - iter 60/101 - loss 0.38641079 - samples/sec: 65.19 - lr: 0.000030
2021-06-22 09:32:51,452 epoch 10 - iter 70/101 - loss 0.37561683 - samples/sec: 64.87 - lr: 0.000030
2021-06-22 09:32:56,372 epoch 10 - iter 80/101 - loss 0.37452390 - samples/sec: 65.05 - lr: 0.000030
2021-06-22 09:33:01,275 epoch 10 - iter 90/101 - loss 0.37061513 - samples/sec: 65.27 - lr: 0.000030
2021-06-22 09:33:06,204 epoch 10 - iter 100/101 - loss 0.36118186 - samples/sec: 64.94 - lr: 0.000030
2021-06-22 09:33:06,641 ----------------------------------------------------------------------------------------------------
2021-06-22 09:33:06,641 EPOCH 10 done: loss 0.3603 - lr 0.0000300
2021-06-22 09:33:10,533 DEV : loss 0.2860691249370575 - score 0.9579
2021-06-22 09:33:10,587 BAD EPOCHS (no improvement): 1
2021-06-22 09:33:10,587 ----------------------------------------------------------------------------------------------------
2021-06-22 09:33:15,533 epoch 11 - iter 10/101 - loss 0.33908058 - samples/sec: 64.71 - lr: 0.000030
2021-06-22 09:33:20,487 epoch 11 - iter 20/101 - loss 0.31352994 - samples/sec: 64.61 - lr: 0.000030
2021-06-22 09:33:25,416 epoch 11 - iter 30/101 - loss 0.34539958 - samples/sec: 64.93 - lr: 0.000030
2021-06-22 09:33:30,367 epoch 11 - iter 40/101 - loss 0.35670258 - samples/sec: 64.65 - lr: 0.000030
2021-06-22 09:33:35,286 epoch 11 - iter 50/101 - loss 0.34499456 - samples/sec: 65.06 - lr: 0.000030
2021-06-22 09:33:40,159 epoch 11 - iter 60/101 - loss 0.33586086 - samples/sec: 65.68 - lr: 0.000030
2021-06-22 09:33:45,082 epoch 11 - iter 70/101 - loss 0.33643589 - samples/sec: 65.02 - lr: 0.000030
2021-06-22 09:33:50,024 epoch 11 - iter 80/101 - loss 0.33756168 - samples/sec: 64.76 - lr: 0.000030
2021-06-22 09:33:54,918 epoch 11 - iter 90/101 - loss 0.34138412 - samples/sec: 65.40 - lr: 0.000030
2021-06-22 09:33:59,788 epoch 11 - iter 100/101 - loss 0.34855873 - samples/sec: 65.71 - lr: 0.000030
2021-06-22 09:34:00,232 ----------------------------------------------------------------------------------------------------
2021-06-22 09:34:00,233 EPOCH 11 done: loss 0.3494 - lr 0.0000300
2021-06-22 09:34:04,128 DEV : loss 0.2856210470199585 - score 0.9595
2021-06-22 09:34:04,183 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:34:12,701 ----------------------------------------------------------------------------------------------------
2021-06-22 09:34:17,615 epoch 12 - iter 10/101 - loss 0.33087310 - samples/sec: 65.14 - lr: 0.000030
2021-06-22 09:34:22,533 epoch 12 - iter 20/101 - loss 0.36449882 - samples/sec: 65.08 - lr: 0.000030
2021-06-22 09:34:27,495 epoch 12 - iter 30/101 - loss 0.34894453 - samples/sec: 64.51 - lr: 0.000030
2021-06-22 09:34:32,418 epoch 12 - iter 40/101 - loss 0.32735233 - samples/sec: 65.01 - lr: 0.000030
2021-06-22 09:34:37,317 epoch 12 - iter 50/101 - loss 0.32037932 - samples/sec: 65.32 - lr: 0.000030
2021-06-22 09:34:42,251 epoch 12 - iter 60/101 - loss 0.31406038 - samples/sec: 64.87 - lr: 0.000030
2021-06-22 09:34:47,197 epoch 12 - iter 70/101 - loss 0.31981147 - samples/sec: 64.71 - lr: 0.000030
2021-06-22 09:34:52,116 epoch 12 - iter 80/101 - loss 0.32645978 - samples/sec: 65.06 - lr: 0.000030
2021-06-22 09:34:57,051 epoch 12 - iter 90/101 - loss 0.32880708 - samples/sec: 64.85 - lr: 0.000030
2021-06-22 09:35:01,996 epoch 12 - iter 100/101 - loss 0.33053883 - samples/sec: 64.73 - lr: 0.000030
2021-06-22 09:35:02,436 ----------------------------------------------------------------------------------------------------
2021-06-22 09:35:02,437 EPOCH 12 done: loss 0.3312 - lr 0.0000300
2021-06-22 09:35:06,327 DEV : loss 0.27908575534820557 - score 0.9587
2021-06-22 09:35:06,383 BAD EPOCHS (no improvement): 1
2021-06-22 09:35:06,383 ----------------------------------------------------------------------------------------------------
2021-06-22 09:35:11,655 epoch 13 - iter 10/101 - loss 0.38783477 - samples/sec: 60.71 - lr: 0.000030
2021-06-22 09:35:16,583 epoch 13 - iter 20/101 - loss 0.35493329 - samples/sec: 64.95 - lr: 0.000030
2021-06-22 09:35:21,506 epoch 13 - iter 30/101 - loss 0.31860304 - samples/sec: 65.01 - lr: 0.000030
2021-06-22 09:35:26,403 epoch 13 - iter 40/101 - loss 0.32585162 - samples/sec: 65.36 - lr: 0.000030
2021-06-22 09:35:31,342 epoch 13 - iter 50/101 - loss 0.31148143 - samples/sec: 64.79 - lr: 0.000030
2021-06-22 09:35:36,298 epoch 13 - iter 60/101 - loss 0.31326445 - samples/sec: 64.58 - lr: 0.000030
2021-06-22 09:35:41,226 epoch 13 - iter 70/101 - loss 0.31006233 - samples/sec: 64.95 - lr: 0.000030
2021-06-22 09:35:46,170 epoch 13 - iter 80/101 - loss 0.30857930 - samples/sec: 64.75 - lr: 0.000030
2021-06-22 09:35:51,105 epoch 13 - iter 90/101 - loss 0.30741032 - samples/sec: 64.85 - lr: 0.000030
2021-06-22 09:35:56,036 epoch 13 - iter 100/101 - loss 0.30595014 - samples/sec: 64.90 - lr: 0.000030
2021-06-22 09:35:56,473 ----------------------------------------------------------------------------------------------------
2021-06-22 09:35:56,473 EPOCH 13 done: loss 0.3061 - lr 0.0000300
2021-06-22 09:36:00,371 DEV : loss 0.2872799336910248 - score 0.9595
2021-06-22 09:36:00,427 BAD EPOCHS (no improvement): 2
2021-06-22 09:36:00,427 ----------------------------------------------------------------------------------------------------
2021-06-22 09:36:05,361 epoch 14 - iter 10/101 - loss 0.28727491 - samples/sec: 64.87 - lr: 0.000030
2021-06-22 09:36:10,312 epoch 14 - iter 20/101 - loss 0.27914602 - samples/sec: 64.65 - lr: 0.000030
2021-06-22 09:36:15,236 epoch 14 - iter 30/101 - loss 0.26985707 - samples/sec: 65.00 - lr: 0.000030
2021-06-22 09:36:20,173 epoch 14 - iter 40/101 - loss 0.28532596 - samples/sec: 64.83 - lr: 0.000030
2021-06-22 09:36:25,086 epoch 14 - iter 50/101 - loss 0.28270317 - samples/sec: 65.15 - lr: 0.000030
2021-06-22 09:36:29,997 epoch 14 - iter 60/101 - loss 0.30332344 - samples/sec: 65.18 - lr: 0.000030
2021-06-22 09:36:34,949 epoch 14 - iter 70/101 - loss 0.30630998 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 09:36:39,904 epoch 14 - iter 80/101 - loss 0.30930673 - samples/sec: 64.59 - lr: 0.000030
2021-06-22 09:36:44,827 epoch 14 - iter 90/101 - loss 0.31209483 - samples/sec: 65.01 - lr: 0.000030
2021-06-22 09:36:49,737 epoch 14 - iter 100/101 - loss 0.30511039 - samples/sec: 65.19 - lr: 0.000030
2021-06-22 09:36:50,169 ----------------------------------------------------------------------------------------------------
2021-06-22 09:36:50,169 EPOCH 14 done: loss 0.3073 - lr 0.0000300
2021-06-22 09:36:54,066 DEV : loss 0.28160393238067627 - score 0.9557
2021-06-22 09:36:54,121 BAD EPOCHS (no improvement): 3
2021-06-22 09:36:54,121 ----------------------------------------------------------------------------------------------------
2021-06-22 09:36:59,052 epoch 15 - iter 10/101 - loss 0.29360473 - samples/sec: 64.91 - lr: 0.000030
2021-06-22 09:37:04,014 epoch 15 - iter 20/101 - loss 0.25005308 - samples/sec: 64.51 - lr: 0.000030
2021-06-22 09:37:08,937 epoch 15 - iter 30/101 - loss 0.27409659 - samples/sec: 65.01 - lr: 0.000030
2021-06-22 09:37:13,877 epoch 15 - iter 40/101 - loss 0.27708335 - samples/sec: 64.79 - lr: 0.000030
2021-06-22 09:37:18,836 epoch 15 - iter 50/101 - loss 0.26657153 - samples/sec: 64.53 - lr: 0.000030
2021-06-22 09:37:23,744 epoch 15 - iter 60/101 - loss 0.27251226 - samples/sec: 65.22 - lr: 0.000030
2021-06-22 09:37:28,697 epoch 15 - iter 70/101 - loss 0.26012867 - samples/sec: 64.62 - lr: 0.000030
2021-06-22 09:37:33,616 epoch 15 - iter 80/101 - loss 0.27463036 - samples/sec: 65.06 - lr: 0.000030
2021-06-22 09:37:38,551 epoch 15 - iter 90/101 - loss 0.28279349 - samples/sec: 64.86 - lr: 0.000030
2021-06-22 09:37:43,502 epoch 15 - iter 100/101 - loss 0.28352968 - samples/sec: 64.65 - lr: 0.000030
2021-06-22 09:37:43,937 ----------------------------------------------------------------------------------------------------
2021-06-22 09:37:43,937 EPOCH 15 done: loss 0.2844 - lr 0.0000300
2021-06-22 09:37:48,129 DEV : loss 0.2675350606441498 - score 0.9596
2021-06-22 09:37:48,186 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:37:56,819 ----------------------------------------------------------------------------------------------------
2021-06-22 09:38:01,705 epoch 16 - iter 10/101 - loss 0.26458923 - samples/sec: 65.52 - lr: 0.000030
2021-06-22 09:38:06,586 epoch 16 - iter 20/101 - loss 0.25246251 - samples/sec: 65.57 - lr: 0.000030
2021-06-22 09:38:11,506 epoch 16 - iter 30/101 - loss 0.24244055 - samples/sec: 65.05 - lr: 0.000030
2021-06-22 09:38:16,453 epoch 16 - iter 40/101 - loss 0.26257405 - samples/sec: 64.71 - lr: 0.000030
2021-06-22 09:38:21,398 epoch 16 - iter 50/101 - loss 0.25671530 - samples/sec: 64.72 - lr: 0.000030
2021-06-22 09:38:26,333 epoch 16 - iter 60/101 - loss 0.26150884 - samples/sec: 64.85 - lr: 0.000030
2021-06-22 09:38:31,299 epoch 16 - iter 70/101 - loss 0.26532020 - samples/sec: 64.45 - lr: 0.000030
2021-06-22 09:38:36,257 epoch 16 - iter 80/101 - loss 0.27063333 - samples/sec: 64.55 - lr: 0.000030
2021-06-22 09:38:41,150 epoch 16 - iter 90/101 - loss 0.26852161 - samples/sec: 65.41 - lr: 0.000030
2021-06-22 09:38:46,091 epoch 16 - iter 100/101 - loss 0.26542317 - samples/sec: 64.79 - lr: 0.000030
2021-06-22 09:38:46,533 ----------------------------------------------------------------------------------------------------
2021-06-22 09:38:46,533 EPOCH 16 done: loss 0.2658 - lr 0.0000300
2021-06-22 09:38:50,431 DEV : loss 0.27275702357292175 - score 0.9589
2021-06-22 09:38:50,487 BAD EPOCHS (no improvement): 1
2021-06-22 09:38:50,487 ----------------------------------------------------------------------------------------------------
2021-06-22 09:38:55,448 epoch 17 - iter 10/101 - loss 0.24953667 - samples/sec: 64.52 - lr: 0.000030
2021-06-22 09:39:00,352 epoch 17 - iter 20/101 - loss 0.30099913 - samples/sec: 65.26 - lr: 0.000030
2021-06-22 09:39:05,317 epoch 17 - iter 30/101 - loss 0.28306682 - samples/sec: 64.46 - lr: 0.000030
2021-06-22 09:39:10,291 epoch 17 - iter 40/101 - loss 0.29182820 - samples/sec: 64.35 - lr: 0.000030
2021-06-22 09:39:15,260 epoch 17 - iter 50/101 - loss 0.28194689 - samples/sec: 64.41 - lr: 0.000030
2021-06-22 09:39:20,205 epoch 17 - iter 60/101 - loss 0.27234759 - samples/sec: 64.73 - lr: 0.000030
2021-06-22 09:39:25,127 epoch 17 - iter 70/101 - loss 0.26945890 - samples/sec: 65.03 - lr: 0.000030
2021-06-22 09:39:30,050 epoch 17 - iter 80/101 - loss 0.26065897 - samples/sec: 65.00 - lr: 0.000030
2021-06-22 09:39:34,982 epoch 17 - iter 90/101 - loss 0.25934651 - samples/sec: 64.90 - lr: 0.000030
2021-06-22 09:39:39,919 epoch 17 - iter 100/101 - loss 0.26185917 - samples/sec: 64.83 - lr: 0.000030
2021-06-22 09:39:40,358 ----------------------------------------------------------------------------------------------------
2021-06-22 09:39:40,359 EPOCH 17 done: loss 0.2618 - lr 0.0000300
2021-06-22 09:39:44,265 DEV : loss 0.2732692360877991 - score 0.9573
2021-06-22 09:39:44,321 BAD EPOCHS (no improvement): 2
2021-06-22 09:39:44,322 ----------------------------------------------------------------------------------------------------
2021-06-22 09:39:49,295 epoch 18 - iter 10/101 - loss 0.34802626 - samples/sec: 64.35 - lr: 0.000030
2021-06-22 09:39:54,231 epoch 18 - iter 20/101 - loss 0.28070034 - samples/sec: 64.84 - lr: 0.000030
2021-06-22 09:39:59,156 epoch 18 - iter 30/101 - loss 0.27620419 - samples/sec: 64.99 - lr: 0.000030
2021-06-22 09:40:04,073 epoch 18 - iter 40/101 - loss 0.25876640 - samples/sec: 65.09 - lr: 0.000030
2021-06-22 09:40:09,032 epoch 18 - iter 50/101 - loss 0.25624752 - samples/sec: 64.54 - lr: 0.000030
2021-06-22 09:40:13,964 epoch 18 - iter 60/101 - loss 0.25410999 - samples/sec: 64.89 - lr: 0.000030
2021-06-22 09:40:18,922 epoch 18 - iter 70/101 - loss 0.26022251 - samples/sec: 64.55 - lr: 0.000030
2021-06-22 09:40:23,888 epoch 18 - iter 80/101 - loss 0.25911547 - samples/sec: 64.46 - lr: 0.000030
2021-06-22 09:40:28,852 epoch 18 - iter 90/101 - loss 0.25311622 - samples/sec: 64.48 - lr: 0.000030
2021-06-22 09:40:33,788 epoch 18 - iter 100/101 - loss 0.25216093 - samples/sec: 64.84 - lr: 0.000030
2021-06-22 09:40:34,223 ----------------------------------------------------------------------------------------------------
2021-06-22 09:40:34,224 EPOCH 18 done: loss 0.2529 - lr 0.0000300
2021-06-22 09:40:38,428 DEV : loss 0.27613550424575806 - score 0.9604
2021-06-22 09:40:38,484 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:40:48,341 ----------------------------------------------------------------------------------------------------
2021-06-22 09:40:53,283 epoch 19 - iter 10/101 - loss 0.24192645 - samples/sec: 64.77 - lr: 0.000030
2021-06-22 09:40:58,194 epoch 19 - iter 20/101 - loss 0.24427067 - samples/sec: 65.18 - lr: 0.000030
2021-06-22 09:41:03,128 epoch 19 - iter 30/101 - loss 0.23652206 - samples/sec: 64.86 - lr: 0.000030
2021-06-22 09:41:08,047 epoch 19 - iter 40/101 - loss 0.26536449 - samples/sec: 65.07 - lr: 0.000030
2021-06-22 09:41:13,005 epoch 19 - iter 50/101 - loss 0.26568496 - samples/sec: 64.56 - lr: 0.000030
2021-06-22 09:41:17,986 epoch 19 - iter 60/101 - loss 0.25534238 - samples/sec: 64.25 - lr: 0.000030
2021-06-22 09:41:22,928 epoch 19 - iter 70/101 - loss 0.25770158 - samples/sec: 64.77 - lr: 0.000030
2021-06-22 09:41:27,843 epoch 19 - iter 80/101 - loss 0.26104257 - samples/sec: 65.12 - lr: 0.000030
2021-06-22 09:41:32,787 epoch 19 - iter 90/101 - loss 0.25709093 - samples/sec: 64.74 - lr: 0.000030
2021-06-22 09:41:37,737 epoch 19 - iter 100/101 - loss 0.25727636 - samples/sec: 64.65 - lr: 0.000030
2021-06-22 09:41:38,166 ----------------------------------------------------------------------------------------------------
2021-06-22 09:41:38,166 EPOCH 19 done: loss 0.2568 - lr 0.0000300
2021-06-22 09:41:42,060 DEV : loss 0.282012403011322 - score 0.9628
2021-06-22 09:41:42,114 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:41:50,539 ----------------------------------------------------------------------------------------------------
2021-06-22 09:41:55,484 epoch 20 - iter 10/101 - loss 0.27422465 - samples/sec: 64.73 - lr: 0.000030
2021-06-22 09:42:00,431 epoch 20 - iter 20/101 - loss 0.27240689 - samples/sec: 64.70 - lr: 0.000030
2021-06-22 09:42:05,400 epoch 20 - iter 30/101 - loss 0.23990235 - samples/sec: 64.41 - lr: 0.000030
2021-06-22 09:42:10,318 epoch 20 - iter 40/101 - loss 0.23686501 - samples/sec: 65.07 - lr: 0.000030
2021-06-22 09:42:15,233 epoch 20 - iter 50/101 - loss 0.23410637 - samples/sec: 65.13 - lr: 0.000030
2021-06-22 09:42:20,203 epoch 20 - iter 60/101 - loss 0.23265408 - samples/sec: 64.39 - lr: 0.000030
2021-06-22 09:42:25,127 epoch 20 - iter 70/101 - loss 0.22409215 - samples/sec: 65.00 - lr: 0.000030
2021-06-22 09:42:30,044 epoch 20 - iter 80/101 - loss 0.22119581 - samples/sec: 65.09 - lr: 0.000030
2021-06-22 09:42:35,000 epoch 20 - iter 90/101 - loss 0.22218433 - samples/sec: 64.59 - lr: 0.000030
2021-06-22 09:42:39,942 epoch 20 - iter 100/101 - loss 0.22445874 - samples/sec: 64.76 - lr: 0.000030
2021-06-22 09:42:40,375 ----------------------------------------------------------------------------------------------------
2021-06-22 09:42:40,375 EPOCH 20 done: loss 0.2253 - lr 0.0000300
2021-06-22 09:42:44,274 DEV : loss 0.2855794429779053 - score 0.9577
2021-06-22 09:42:44,330 BAD EPOCHS (no improvement): 1
2021-06-22 09:42:44,331 ----------------------------------------------------------------------------------------------------
2021-06-22 09:42:49,262 epoch 21 - iter 10/101 - loss 0.22820215 - samples/sec: 64.91 - lr: 0.000030
2021-06-22 09:42:54,186 epoch 21 - iter 20/101 - loss 0.21677951 - samples/sec: 64.99 - lr: 0.000030
2021-06-22 09:42:59,137 epoch 21 - iter 30/101 - loss 0.20898259 - samples/sec: 64.65 - lr: 0.000030
2021-06-22 09:43:04,101 epoch 21 - iter 40/101 - loss 0.21173711 - samples/sec: 64.47 - lr: 0.000030
2021-06-22 09:43:09,021 epoch 21 - iter 50/101 - loss 0.22565724 - samples/sec: 65.06 - lr: 0.000030
2021-06-22 09:43:13,985 epoch 21 - iter 60/101 - loss 0.22821074 - samples/sec: 64.46 - lr: 0.000030
2021-06-22 09:43:18,891 epoch 21 - iter 70/101 - loss 0.23167816 - samples/sec: 65.24 - lr: 0.000030
2021-06-22 09:43:23,809 epoch 21 - iter 80/101 - loss 0.23372104 - samples/sec: 65.08 - lr: 0.000030
2021-06-22 09:43:28,732 epoch 21 - iter 90/101 - loss 0.23169381 - samples/sec: 65.01 - lr: 0.000030
2021-06-22 09:43:33,654 epoch 21 - iter 100/101 - loss 0.23408922 - samples/sec: 65.02 - lr: 0.000030
2021-06-22 09:43:34,099 ----------------------------------------------------------------------------------------------------
2021-06-22 09:43:34,099 EPOCH 21 done: loss 0.2325 - lr 0.0000300
2021-06-22 09:43:38,289 DEV : loss 0.2750528156757355 - score 0.9588
2021-06-22 09:43:38,344 BAD EPOCHS (no improvement): 2
2021-06-22 09:43:38,345 ----------------------------------------------------------------------------------------------------
2021-06-22 09:43:43,294 epoch 22 - iter 10/101 - loss 0.23023264 - samples/sec: 64.66 - lr: 0.000030
2021-06-22 09:43:48,199 epoch 22 - iter 20/101 - loss 0.22413062 - samples/sec: 65.26 - lr: 0.000030
2021-06-22 09:43:53,132 epoch 22 - iter 30/101 - loss 0.23872188 - samples/sec: 64.88 - lr: 0.000030
2021-06-22 09:43:58,060 epoch 22 - iter 40/101 - loss 0.23039317 - samples/sec: 64.95 - lr: 0.000030
2021-06-22 09:44:03,017 epoch 22 - iter 50/101 - loss 0.23221532 - samples/sec: 64.56 - lr: 0.000030
2021-06-22 09:44:07,944 epoch 22 - iter 60/101 - loss 0.23664699 - samples/sec: 64.97 - lr: 0.000030
2021-06-22 09:44:12,887 epoch 22 - iter 70/101 - loss 0.23958136 - samples/sec: 64.74 - lr: 0.000030
2021-06-22 09:44:17,824 epoch 22 - iter 80/101 - loss 0.24314909 - samples/sec: 64.84 - lr: 0.000030
2021-06-22 09:44:22,737 epoch 22 - iter 90/101 - loss 0.23846622 - samples/sec: 65.14 - lr: 0.000030
2021-06-22 09:44:27,654 epoch 22 - iter 100/101 - loss 0.23123107 - samples/sec: 65.09 - lr: 0.000030
2021-06-22 09:44:28,094 ----------------------------------------------------------------------------------------------------
2021-06-22 09:44:28,094 EPOCH 22 done: loss 0.2300 - lr 0.0000300
2021-06-22 09:44:31,985 DEV : loss 0.2708032727241516 - score 0.9586
2021-06-22 09:44:32,041 BAD EPOCHS (no improvement): 3
2021-06-22 09:44:32,041 ----------------------------------------------------------------------------------------------------
2021-06-22 09:44:36,970 epoch 23 - iter 10/101 - loss 0.17479849 - samples/sec: 64.93 - lr: 0.000030
2021-06-22 09:44:41,903 epoch 23 - iter 20/101 - loss 0.16294872 - samples/sec: 64.88 - lr: 0.000030
2021-06-22 09:44:46,832 epoch 23 - iter 30/101 - loss 0.18486300 - samples/sec: 64.93 - lr: 0.000030
2021-06-22 09:44:51,778 epoch 23 - iter 40/101 - loss 0.18321156 - samples/sec: 64.72 - lr: 0.000030
2021-06-22 09:44:56,693 epoch 23 - iter 50/101 - loss 0.18865901 - samples/sec: 65.11 - lr: 0.000030
2021-06-22 09:45:01,613 epoch 23 - iter 60/101 - loss 0.19806736 - samples/sec: 65.06 - lr: 0.000030
2021-06-22 09:45:06,564 epoch 23 - iter 70/101 - loss 0.19666305 - samples/sec: 64.64 - lr: 0.000030
2021-06-22 09:45:11,467 epoch 23 - iter 80/101 - loss 0.20390234 - samples/sec: 65.29 - lr: 0.000030
2021-06-22 09:45:16,403 epoch 23 - iter 90/101 - loss 0.20249475 - samples/sec: 64.84 - lr: 0.000030
2021-06-22 09:45:21,325 epoch 23 - iter 100/101 - loss 0.20255886 - samples/sec: 65.03 - lr: 0.000030
2021-06-22 09:45:21,768 ----------------------------------------------------------------------------------------------------
2021-06-22 09:45:21,768 EPOCH 23 done: loss 0.2014 - lr 0.0000300
2021-06-22 09:45:25,657 DEV : loss 0.27278488874435425 - score 0.9624
Epoch    23: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 09:45:25,713 BAD EPOCHS (no improvement): 4
2021-06-22 09:45:25,713 ----------------------------------------------------------------------------------------------------
2021-06-22 09:45:30,659 epoch 24 - iter 10/101 - loss 0.21488912 - samples/sec: 64.71 - lr: 0.000015
2021-06-22 09:45:35,586 epoch 24 - iter 20/101 - loss 0.19050019 - samples/sec: 64.96 - lr: 0.000015
2021-06-22 09:45:40,535 epoch 24 - iter 30/101 - loss 0.20780336 - samples/sec: 64.68 - lr: 0.000015
2021-06-22 09:45:45,462 epoch 24 - iter 40/101 - loss 0.19519269 - samples/sec: 64.96 - lr: 0.000015
2021-06-22 09:45:50,390 epoch 24 - iter 50/101 - loss 0.19382942 - samples/sec: 64.94 - lr: 0.000015
2021-06-22 09:45:55,338 epoch 24 - iter 60/101 - loss 0.19809749 - samples/sec: 64.68 - lr: 0.000015
2021-06-22 09:46:00,232 epoch 24 - iter 70/101 - loss 0.19415330 - samples/sec: 65.40 - lr: 0.000015
2021-06-22 09:46:05,131 epoch 24 - iter 80/101 - loss 0.19109334 - samples/sec: 65.32 - lr: 0.000015
2021-06-22 09:46:10,305 epoch 24 - iter 90/101 - loss 0.19428375 - samples/sec: 61.87 - lr: 0.000015
2021-06-22 09:46:15,207 epoch 24 - iter 100/101 - loss 0.19360941 - samples/sec: 65.29 - lr: 0.000015
2021-06-22 09:46:15,636 ----------------------------------------------------------------------------------------------------
2021-06-22 09:46:15,637 EPOCH 24 done: loss 0.1931 - lr 0.0000150
2021-06-22 09:46:19,533 DEV : loss 0.286970317363739 - score 0.9616
2021-06-22 09:46:19,589 BAD EPOCHS (no improvement): 1
2021-06-22 09:46:19,590 ----------------------------------------------------------------------------------------------------
2021-06-22 09:46:24,504 epoch 25 - iter 10/101 - loss 0.15468506 - samples/sec: 65.13 - lr: 0.000015
2021-06-22 09:46:29,417 epoch 25 - iter 20/101 - loss 0.17198264 - samples/sec: 65.15 - lr: 0.000015
2021-06-22 09:46:34,310 epoch 25 - iter 30/101 - loss 0.17571802 - samples/sec: 65.41 - lr: 0.000015
2021-06-22 09:46:39,246 epoch 25 - iter 40/101 - loss 0.17488438 - samples/sec: 64.85 - lr: 0.000015
2021-06-22 09:46:44,148 epoch 25 - iter 50/101 - loss 0.17931372 - samples/sec: 65.29 - lr: 0.000015
2021-06-22 09:46:49,056 epoch 25 - iter 60/101 - loss 0.17339495 - samples/sec: 65.21 - lr: 0.000015
2021-06-22 09:46:53,945 epoch 25 - iter 70/101 - loss 0.17248438 - samples/sec: 65.46 - lr: 0.000015
2021-06-22 09:46:58,849 epoch 25 - iter 80/101 - loss 0.17738490 - samples/sec: 65.27 - lr: 0.000015
2021-06-22 09:47:03,795 epoch 25 - iter 90/101 - loss 0.17807192 - samples/sec: 64.71 - lr: 0.000015
2021-06-22 09:47:08,742 epoch 25 - iter 100/101 - loss 0.17784590 - samples/sec: 64.69 - lr: 0.000015
2021-06-22 09:47:09,185 ----------------------------------------------------------------------------------------------------
2021-06-22 09:47:09,185 EPOCH 25 done: loss 0.1783 - lr 0.0000150
2021-06-22 09:47:13,082 DEV : loss 0.29985231161117554 - score 0.9562
2021-06-22 09:47:13,138 BAD EPOCHS (no improvement): 2
2021-06-22 09:47:13,139 ----------------------------------------------------------------------------------------------------
2021-06-22 09:47:18,050 epoch 26 - iter 10/101 - loss 0.12931306 - samples/sec: 65.17 - lr: 0.000015
2021-06-22 09:47:22,938 epoch 26 - iter 20/101 - loss 0.16810816 - samples/sec: 65.47 - lr: 0.000015
2021-06-22 09:47:27,883 epoch 26 - iter 30/101 - loss 0.19362655 - samples/sec: 64.73 - lr: 0.000015
2021-06-22 09:47:32,803 epoch 26 - iter 40/101 - loss 0.20669089 - samples/sec: 65.05 - lr: 0.000015
2021-06-22 09:47:37,718 epoch 26 - iter 50/101 - loss 0.20125904 - samples/sec: 65.11 - lr: 0.000015
2021-06-22 09:47:42,639 epoch 26 - iter 60/101 - loss 0.20117964 - samples/sec: 65.04 - lr: 0.000015
2021-06-22 09:47:47,619 epoch 26 - iter 70/101 - loss 0.19810351 - samples/sec: 64.27 - lr: 0.000015
2021-06-22 09:47:52,540 epoch 26 - iter 80/101 - loss 0.19497588 - samples/sec: 65.03 - lr: 0.000015
2021-06-22 09:47:57,496 epoch 26 - iter 90/101 - loss 0.19194000 - samples/sec: 64.59 - lr: 0.000015
2021-06-22 09:48:02,472 epoch 26 - iter 100/101 - loss 0.18913809 - samples/sec: 64.32 - lr: 0.000015
2021-06-22 09:48:02,911 ----------------------------------------------------------------------------------------------------
2021-06-22 09:48:02,911 EPOCH 26 done: loss 0.1893 - lr 0.0000150
2021-06-22 09:48:06,809 DEV : loss 0.294996440410614 - score 0.9576
2021-06-22 09:48:06,865 BAD EPOCHS (no improvement): 3
2021-06-22 09:48:06,865 ----------------------------------------------------------------------------------------------------
2021-06-22 09:48:11,771 epoch 27 - iter 10/101 - loss 0.16400462 - samples/sec: 65.23 - lr: 0.000015
2021-06-22 09:48:16,705 epoch 27 - iter 20/101 - loss 0.18826247 - samples/sec: 64.88 - lr: 0.000015
2021-06-22 09:48:21,661 epoch 27 - iter 30/101 - loss 0.19919026 - samples/sec: 64.58 - lr: 0.000015
2021-06-22 09:48:26,584 epoch 27 - iter 40/101 - loss 0.19981796 - samples/sec: 65.01 - lr: 0.000015
2021-06-22 09:48:31,577 epoch 27 - iter 50/101 - loss 0.20041695 - samples/sec: 64.11 - lr: 0.000015
2021-06-22 09:48:36,556 epoch 27 - iter 60/101 - loss 0.18984739 - samples/sec: 64.28 - lr: 0.000015
2021-06-22 09:48:41,500 epoch 27 - iter 70/101 - loss 0.18180949 - samples/sec: 64.74 - lr: 0.000015
2021-06-22 09:48:46,466 epoch 27 - iter 80/101 - loss 0.18492856 - samples/sec: 64.44 - lr: 0.000015
2021-06-22 09:48:51,400 epoch 27 - iter 90/101 - loss 0.18543236 - samples/sec: 64.87 - lr: 0.000015
2021-06-22 09:48:56,376 epoch 27 - iter 100/101 - loss 0.18301518 - samples/sec: 64.32 - lr: 0.000015
2021-06-22 09:48:56,814 ----------------------------------------------------------------------------------------------------
2021-06-22 09:48:56,814 EPOCH 27 done: loss 0.1826 - lr 0.0000150
2021-06-22 09:49:01,019 DEV : loss 0.28740638494491577 - score 0.9616
Epoch    27: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 09:49:01,075 BAD EPOCHS (no improvement): 4
2021-06-22 09:49:01,076 ----------------------------------------------------------------------------------------------------
2021-06-22 09:49:06,002 epoch 28 - iter 10/101 - loss 0.16997435 - samples/sec: 64.96 - lr: 0.000008
2021-06-22 09:49:10,959 epoch 28 - iter 20/101 - loss 0.14970566 - samples/sec: 64.57 - lr: 0.000008
2021-06-22 09:49:15,914 epoch 28 - iter 30/101 - loss 0.15529003 - samples/sec: 64.60 - lr: 0.000008
2021-06-22 09:49:20,892 epoch 28 - iter 40/101 - loss 0.16039723 - samples/sec: 64.29 - lr: 0.000008
2021-06-22 09:49:25,881 epoch 28 - iter 50/101 - loss 0.16880386 - samples/sec: 64.16 - lr: 0.000008
2021-06-22 09:49:30,823 epoch 28 - iter 60/101 - loss 0.16172369 - samples/sec: 64.76 - lr: 0.000008
2021-06-22 09:49:35,803 epoch 28 - iter 70/101 - loss 0.15852466 - samples/sec: 64.26 - lr: 0.000008
2021-06-22 09:49:40,742 epoch 28 - iter 80/101 - loss 0.15753665 - samples/sec: 64.81 - lr: 0.000008
2021-06-22 09:49:45,709 epoch 28 - iter 90/101 - loss 0.15697513 - samples/sec: 64.44 - lr: 0.000008
2021-06-22 09:49:50,647 epoch 28 - iter 100/101 - loss 0.15980418 - samples/sec: 64.81 - lr: 0.000008
2021-06-22 09:49:51,084 ----------------------------------------------------------------------------------------------------
2021-06-22 09:49:51,084 EPOCH 28 done: loss 0.1623 - lr 0.0000075
2021-06-22 09:49:54,989 DEV : loss 0.298805832862854 - score 0.9564
2021-06-22 09:49:55,045 BAD EPOCHS (no improvement): 1
2021-06-22 09:49:55,046 ----------------------------------------------------------------------------------------------------
2021-06-22 09:50:00,001 epoch 29 - iter 10/101 - loss 0.16469861 - samples/sec: 64.59 - lr: 0.000008
2021-06-22 09:50:04,976 epoch 29 - iter 20/101 - loss 0.14672640 - samples/sec: 64.33 - lr: 0.000008
2021-06-22 09:50:09,920 epoch 29 - iter 30/101 - loss 0.15293712 - samples/sec: 64.74 - lr: 0.000008
2021-06-22 09:50:14,848 epoch 29 - iter 40/101 - loss 0.16847658 - samples/sec: 64.94 - lr: 0.000008
2021-06-22 09:50:19,788 epoch 29 - iter 50/101 - loss 0.16641412 - samples/sec: 64.79 - lr: 0.000008
2021-06-22 09:50:24,765 epoch 29 - iter 60/101 - loss 0.15968255 - samples/sec: 64.31 - lr: 0.000008
2021-06-22 09:50:29,674 epoch 29 - iter 70/101 - loss 0.15987458 - samples/sec: 65.20 - lr: 0.000008
2021-06-22 09:50:34,622 epoch 29 - iter 80/101 - loss 0.16711131 - samples/sec: 64.69 - lr: 0.000008
2021-06-22 09:50:39,603 epoch 29 - iter 90/101 - loss 0.16260977 - samples/sec: 64.26 - lr: 0.000008
2021-06-22 09:50:44,552 epoch 29 - iter 100/101 - loss 0.16274572 - samples/sec: 64.67 - lr: 0.000008
2021-06-22 09:50:44,985 ----------------------------------------------------------------------------------------------------
2021-06-22 09:50:44,985 EPOCH 29 done: loss 0.1619 - lr 0.0000075
2021-06-22 09:50:48,885 DEV : loss 0.2976425588130951 - score 0.9563
2021-06-22 09:50:48,940 BAD EPOCHS (no improvement): 2
2021-06-22 09:50:48,941 ----------------------------------------------------------------------------------------------------
2021-06-22 09:50:53,916 epoch 30 - iter 10/101 - loss 0.11306784 - samples/sec: 64.33 - lr: 0.000008
2021-06-22 09:50:58,873 epoch 30 - iter 20/101 - loss 0.15630098 - samples/sec: 64.57 - lr: 0.000008
2021-06-22 09:51:03,832 epoch 30 - iter 30/101 - loss 0.14715646 - samples/sec: 64.54 - lr: 0.000008
2021-06-22 09:51:08,811 epoch 30 - iter 40/101 - loss 0.17264114 - samples/sec: 64.29 - lr: 0.000008
2021-06-22 09:51:13,742 epoch 30 - iter 50/101 - loss 0.16940943 - samples/sec: 64.90 - lr: 0.000008
2021-06-22 09:51:18,699 epoch 30 - iter 60/101 - loss 0.16706724 - samples/sec: 64.57 - lr: 0.000008
2021-06-22 09:51:23,658 epoch 30 - iter 70/101 - loss 0.17363973 - samples/sec: 64.54 - lr: 0.000008
2021-06-22 09:51:28,608 epoch 30 - iter 80/101 - loss 0.17997556 - samples/sec: 64.66 - lr: 0.000008
2021-06-22 09:51:33,575 epoch 30 - iter 90/101 - loss 0.17931116 - samples/sec: 64.44 - lr: 0.000008
2021-06-22 09:51:38,529 epoch 30 - iter 100/101 - loss 0.17259121 - samples/sec: 64.61 - lr: 0.000008
2021-06-22 09:51:38,972 ----------------------------------------------------------------------------------------------------
2021-06-22 09:51:38,972 EPOCH 30 done: loss 0.1717 - lr 0.0000075
2021-06-22 09:51:43,175 DEV : loss 0.2933528423309326 - score 0.9604
2021-06-22 09:51:43,232 BAD EPOCHS (no improvement): 3
2021-06-22 09:51:43,233 ----------------------------------------------------------------------------------------------------
2021-06-22 09:51:48,177 epoch 31 - iter 10/101 - loss 0.18194435 - samples/sec: 64.73 - lr: 0.000008
2021-06-22 09:51:53,128 epoch 31 - iter 20/101 - loss 0.17288371 - samples/sec: 64.65 - lr: 0.000008
2021-06-22 09:51:58,106 epoch 31 - iter 30/101 - loss 0.16099704 - samples/sec: 64.29 - lr: 0.000008
2021-06-22 09:52:03,031 epoch 31 - iter 40/101 - loss 0.15404370 - samples/sec: 64.99 - lr: 0.000008
2021-06-22 09:52:08,012 epoch 31 - iter 50/101 - loss 0.14891342 - samples/sec: 64.26 - lr: 0.000008
2021-06-22 09:52:12,957 epoch 31 - iter 60/101 - loss 0.15041905 - samples/sec: 64.72 - lr: 0.000008
2021-06-22 09:52:17,854 epoch 31 - iter 70/101 - loss 0.15615251 - samples/sec: 65.36 - lr: 0.000008
2021-06-22 09:52:22,809 epoch 31 - iter 80/101 - loss 0.15477061 - samples/sec: 64.58 - lr: 0.000008
2021-06-22 09:52:27,739 epoch 31 - iter 90/101 - loss 0.15583020 - samples/sec: 64.93 - lr: 0.000008
2021-06-22 09:52:32,723 epoch 31 - iter 100/101 - loss 0.15594373 - samples/sec: 64.22 - lr: 0.000008
2021-06-22 09:52:33,167 ----------------------------------------------------------------------------------------------------
2021-06-22 09:52:33,167 EPOCH 31 done: loss 0.1558 - lr 0.0000075
2021-06-22 09:52:37,067 DEV : loss 0.28953075408935547 - score 0.9611
Epoch    31: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 09:52:37,122 BAD EPOCHS (no improvement): 4
2021-06-22 09:52:37,123 ----------------------------------------------------------------------------------------------------
2021-06-22 09:52:42,062 epoch 32 - iter 10/101 - loss 0.14208973 - samples/sec: 64.80 - lr: 0.000004
2021-06-22 09:52:47,031 epoch 32 - iter 20/101 - loss 0.12479245 - samples/sec: 64.41 - lr: 0.000004
2021-06-22 09:52:51,987 epoch 32 - iter 30/101 - loss 0.14637125 - samples/sec: 64.58 - lr: 0.000004
2021-06-22 09:52:56,935 epoch 32 - iter 40/101 - loss 0.14949716 - samples/sec: 64.69 - lr: 0.000004
2021-06-22 09:53:01,884 epoch 32 - iter 50/101 - loss 0.15340979 - samples/sec: 64.66 - lr: 0.000004
2021-06-22 09:53:06,838 epoch 32 - iter 60/101 - loss 0.15120567 - samples/sec: 64.61 - lr: 0.000004
2021-06-22 09:53:11,765 epoch 32 - iter 70/101 - loss 0.15070180 - samples/sec: 64.96 - lr: 0.000004
2021-06-22 09:53:16,701 epoch 32 - iter 80/101 - loss 0.15271363 - samples/sec: 64.84 - lr: 0.000004
2021-06-22 09:53:21,639 epoch 32 - iter 90/101 - loss 0.14775080 - samples/sec: 64.82 - lr: 0.000004
2021-06-22 09:53:26,621 epoch 32 - iter 100/101 - loss 0.14873480 - samples/sec: 64.25 - lr: 0.000004
2021-06-22 09:53:27,059 ----------------------------------------------------------------------------------------------------
2021-06-22 09:53:27,060 EPOCH 32 done: loss 0.1483 - lr 0.0000038
2021-06-22 09:53:30,958 DEV : loss 0.2959601879119873 - score 0.9602
2021-06-22 09:53:31,014 BAD EPOCHS (no improvement): 1
2021-06-22 09:53:31,015 ----------------------------------------------------------------------------------------------------
2021-06-22 09:53:35,975 epoch 33 - iter 10/101 - loss 0.11817203 - samples/sec: 64.53 - lr: 0.000004
2021-06-22 09:53:40,884 epoch 33 - iter 20/101 - loss 0.14048591 - samples/sec: 65.20 - lr: 0.000004
2021-06-22 09:53:45,832 epoch 33 - iter 30/101 - loss 0.15114250 - samples/sec: 64.68 - lr: 0.000004
2021-06-22 09:53:50,801 epoch 33 - iter 40/101 - loss 0.15223802 - samples/sec: 64.41 - lr: 0.000004
2021-06-22 09:53:55,756 epoch 33 - iter 50/101 - loss 0.14943187 - samples/sec: 64.59 - lr: 0.000004
2021-06-22 09:54:00,711 epoch 33 - iter 60/101 - loss 0.14752459 - samples/sec: 64.60 - lr: 0.000004
2021-06-22 09:54:05,988 epoch 33 - iter 70/101 - loss 0.14798236 - samples/sec: 60.64 - lr: 0.000004
2021-06-22 09:54:10,936 epoch 33 - iter 80/101 - loss 0.14562474 - samples/sec: 64.70 - lr: 0.000004
2021-06-22 09:54:15,867 epoch 33 - iter 90/101 - loss 0.14910489 - samples/sec: 64.90 - lr: 0.000004
2021-06-22 09:54:20,822 epoch 33 - iter 100/101 - loss 0.14925233 - samples/sec: 64.60 - lr: 0.000004
2021-06-22 09:54:21,261 ----------------------------------------------------------------------------------------------------
2021-06-22 09:54:21,262 EPOCH 33 done: loss 0.1483 - lr 0.0000038
2021-06-22 09:54:25,153 DEV : loss 0.2963963449001312 - score 0.9608
2021-06-22 09:54:25,209 BAD EPOCHS (no improvement): 2
2021-06-22 09:54:25,209 ----------------------------------------------------------------------------------------------------
2021-06-22 09:54:30,187 epoch 34 - iter 10/101 - loss 0.15618797 - samples/sec: 64.29 - lr: 0.000004
2021-06-22 09:54:35,155 epoch 34 - iter 20/101 - loss 0.15077440 - samples/sec: 64.42 - lr: 0.000004
2021-06-22 09:54:40,120 epoch 34 - iter 30/101 - loss 0.15332602 - samples/sec: 64.47 - lr: 0.000004
2021-06-22 09:54:45,039 epoch 34 - iter 40/101 - loss 0.14639597 - samples/sec: 65.06 - lr: 0.000004
2021-06-22 09:54:49,996 epoch 34 - iter 50/101 - loss 0.15275854 - samples/sec: 64.58 - lr: 0.000004
2021-06-22 09:54:54,961 epoch 34 - iter 60/101 - loss 0.15856100 - samples/sec: 64.46 - lr: 0.000004
2021-06-22 09:54:59,907 epoch 34 - iter 70/101 - loss 0.16213972 - samples/sec: 64.71 - lr: 0.000004
2021-06-22 09:55:04,857 epoch 34 - iter 80/101 - loss 0.15694951 - samples/sec: 64.66 - lr: 0.000004
2021-06-22 09:55:09,809 epoch 34 - iter 90/101 - loss 0.15916695 - samples/sec: 64.63 - lr: 0.000004
2021-06-22 09:55:14,747 epoch 34 - iter 100/101 - loss 0.15873794 - samples/sec: 64.81 - lr: 0.000004
2021-06-22 09:55:15,183 ----------------------------------------------------------------------------------------------------
2021-06-22 09:55:15,184 EPOCH 34 done: loss 0.1585 - lr 0.0000038
2021-06-22 09:55:19,068 DEV : loss 0.2925657033920288 - score 0.9622
2021-06-22 09:55:19,123 BAD EPOCHS (no improvement): 3
2021-06-22 09:55:19,124 ----------------------------------------------------------------------------------------------------
2021-06-22 09:55:24,057 epoch 35 - iter 10/101 - loss 0.12998246 - samples/sec: 64.88 - lr: 0.000004
2021-06-22 09:55:28,999 epoch 35 - iter 20/101 - loss 0.12571035 - samples/sec: 64.76 - lr: 0.000004
2021-06-22 09:55:33,961 epoch 35 - iter 30/101 - loss 0.13485039 - samples/sec: 64.50 - lr: 0.000004
2021-06-22 09:55:38,889 epoch 35 - iter 40/101 - loss 0.13165024 - samples/sec: 64.95 - lr: 0.000004
2021-06-22 09:55:43,806 epoch 35 - iter 50/101 - loss 0.13375047 - samples/sec: 65.09 - lr: 0.000004
2021-06-22 09:55:48,758 epoch 35 - iter 60/101 - loss 0.13128402 - samples/sec: 64.63 - lr: 0.000004
2021-06-22 09:55:53,670 epoch 35 - iter 70/101 - loss 0.13196952 - samples/sec: 65.16 - lr: 0.000004
2021-06-22 09:55:58,643 epoch 35 - iter 80/101 - loss 0.13606295 - samples/sec: 64.35 - lr: 0.000004
2021-06-22 09:56:03,592 epoch 35 - iter 90/101 - loss 0.13781145 - samples/sec: 64.67 - lr: 0.000004
2021-06-22 09:56:08,541 epoch 35 - iter 100/101 - loss 0.14061625 - samples/sec: 64.68 - lr: 0.000004
2021-06-22 09:56:08,982 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:08,982 EPOCH 35 done: loss 0.1395 - lr 0.0000038
2021-06-22 09:56:12,868 DEV : loss 0.29410436749458313 - score 0.9609
Epoch    35: reducing learning rate of group 0 to 1.8750e-06.
2021-06-22 09:56:12,924 BAD EPOCHS (no improvement): 4
2021-06-22 09:56:12,924 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:12,924 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:12,924 learning rate too small - quitting training!
2021-06-22 09:56:12,924 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:14,041 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:14,042 Testing using best model ...
2021-06-22 09:56:14,042 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/best-model.pt
2021-06-22 09:56:35,001 0.9555	0.9404	0.9479
2021-06-22 09:56:35,001 
Results:
- F1-score (micro) 0.9479
- F1-score (macro) 0.9479

By class:
SENT       tp: 837 - fp: 39 - fn: 53 - precision: 0.9555 - recall: 0.9404 - f1-score: 0.9479
2021-06-22 09:56:35,001 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/
2021-06-22 09:56:35,031 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt
2021-06-22 09:56:35,033 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/sent_train.txt
2021-06-22 09:56:35,035 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/sent_dev.txt
2021-06-22 09:56:35,037 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/sent_test.txt
Corpus: 865 train + 186 dev + 176 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 09:56:38,109 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:38,110 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 09:56:38,110 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:38,110 Corpus: "Corpus: 865 train + 186 dev + 176 test sentences"
2021-06-22 09:56:38,110 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:38,110 Parameters:
2021-06-22 09:56:38,110  - learning_rate: "3e-05"
2021-06-22 09:56:38,110  - mini_batch_size: "32"
2021-06-22 09:56:38,110  - patience: "3"
2021-06-22 09:56:38,110  - anneal_factor: "0.5"
2021-06-22 09:56:38,110  - max_epochs: "40"
2021-06-22 09:56:38,111  - shuffle: "True"
2021-06-22 09:56:38,111  - train_with_dev: "False"
2021-06-22 09:56:38,111  - batch_growth_annealing: "False"
2021-06-22 09:56:38,111 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:38,111 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt"
2021-06-22 09:56:38,111 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:38,111 Device: cuda:0
2021-06-22 09:56:38,111 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:38,111 Embeddings storage mode: cpu
2021-06-22 09:56:38,115 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:39,631 epoch 1 - iter 2/28 - loss 24.17247200 - samples/sec: 42.22 - lr: 0.000030
2021-06-22 09:56:41,150 epoch 1 - iter 4/28 - loss 20.90943623 - samples/sec: 42.15 - lr: 0.000030
2021-06-22 09:56:42,643 epoch 1 - iter 6/28 - loss 18.57896328 - samples/sec: 42.88 - lr: 0.000030
2021-06-22 09:56:44,135 epoch 1 - iter 8/28 - loss 16.59993196 - samples/sec: 42.90 - lr: 0.000030
2021-06-22 09:56:45,621 epoch 1 - iter 10/28 - loss 14.99294024 - samples/sec: 43.09 - lr: 0.000030
2021-06-22 09:56:47,159 epoch 1 - iter 12/28 - loss 13.71502292 - samples/sec: 41.63 - lr: 0.000030
2021-06-22 09:56:48,658 epoch 1 - iter 14/28 - loss 12.62150519 - samples/sec: 42.70 - lr: 0.000030
2021-06-22 09:56:50,160 epoch 1 - iter 16/28 - loss 11.76817927 - samples/sec: 42.62 - lr: 0.000030
2021-06-22 09:56:51,649 epoch 1 - iter 18/28 - loss 11.04438088 - samples/sec: 42.98 - lr: 0.000030
2021-06-22 09:56:53,187 epoch 1 - iter 20/28 - loss 10.44434061 - samples/sec: 41.62 - lr: 0.000030
2021-06-22 09:56:54,667 epoch 1 - iter 22/28 - loss 9.93577251 - samples/sec: 43.25 - lr: 0.000030
2021-06-22 09:56:56,158 epoch 1 - iter 24/28 - loss 9.49351023 - samples/sec: 42.93 - lr: 0.000030
2021-06-22 09:56:58,553 epoch 1 - iter 26/28 - loss 9.08660799 - samples/sec: 26.73 - lr: 0.000030
2021-06-22 09:56:59,379 epoch 1 - iter 28/28 - loss 8.82998487 - samples/sec: 77.54 - lr: 0.000030
2021-06-22 09:56:59,379 ----------------------------------------------------------------------------------------------------
2021-06-22 09:56:59,379 EPOCH 1 done: loss 8.8300 - lr 0.0000300
2021-06-22 09:57:01,812 DEV : loss 3.314277172088623 - score 0.0
2021-06-22 09:57:01,826 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:57:02,341 ----------------------------------------------------------------------------------------------------
2021-06-22 09:57:03,286 epoch 2 - iter 2/28 - loss 3.80138040 - samples/sec: 67.78 - lr: 0.000030
2021-06-22 09:57:04,236 epoch 2 - iter 4/28 - loss 3.70094657 - samples/sec: 67.40 - lr: 0.000030
2021-06-22 09:57:05,176 epoch 2 - iter 6/28 - loss 3.49045904 - samples/sec: 68.16 - lr: 0.000030
2021-06-22 09:57:06,092 epoch 2 - iter 8/28 - loss 3.29472631 - samples/sec: 69.87 - lr: 0.000030
2021-06-22 09:57:07,043 epoch 2 - iter 10/28 - loss 3.16250515 - samples/sec: 67.38 - lr: 0.000030
2021-06-22 09:57:08,014 epoch 2 - iter 12/28 - loss 3.09368324 - samples/sec: 65.91 - lr: 0.000030
2021-06-22 09:57:08,971 epoch 2 - iter 14/28 - loss 2.98480010 - samples/sec: 66.95 - lr: 0.000030
2021-06-22 09:57:09,930 epoch 2 - iter 16/28 - loss 2.88961771 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 09:57:10,883 epoch 2 - iter 18/28 - loss 2.79289989 - samples/sec: 67.21 - lr: 0.000030
2021-06-22 09:57:11,839 epoch 2 - iter 20/28 - loss 2.70058886 - samples/sec: 66.94 - lr: 0.000030
2021-06-22 09:57:12,807 epoch 2 - iter 22/28 - loss 2.61220274 - samples/sec: 66.18 - lr: 0.000030
2021-06-22 09:57:13,775 epoch 2 - iter 24/28 - loss 2.58091282 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 09:57:14,738 epoch 2 - iter 26/28 - loss 2.48413065 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 09:57:15,282 epoch 2 - iter 28/28 - loss 2.37880536 - samples/sec: 117.86 - lr: 0.000030
2021-06-22 09:57:15,282 ----------------------------------------------------------------------------------------------------
2021-06-22 09:57:15,282 EPOCH 2 done: loss 2.3788 - lr 0.0000300
2021-06-22 09:57:16,239 DEV : loss 1.0837098360061646 - score 0.8928
2021-06-22 09:57:16,253 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:57:21,791 ----------------------------------------------------------------------------------------------------
2021-06-22 09:57:22,748 epoch 3 - iter 2/28 - loss 1.69109893 - samples/sec: 66.93 - lr: 0.000030
2021-06-22 09:57:23,708 epoch 3 - iter 4/28 - loss 1.50616342 - samples/sec: 66.71 - lr: 0.000030
2021-06-22 09:57:24,679 epoch 3 - iter 6/28 - loss 1.42720797 - samples/sec: 65.94 - lr: 0.000030
2021-06-22 09:57:25,639 epoch 3 - iter 8/28 - loss 1.34528014 - samples/sec: 66.71 - lr: 0.000030
2021-06-22 09:57:26,607 epoch 3 - iter 10/28 - loss 1.30941827 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 09:57:27,575 epoch 3 - iter 12/28 - loss 1.29926454 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 09:57:28,538 epoch 3 - iter 14/28 - loss 1.24744949 - samples/sec: 66.48 - lr: 0.000030
2021-06-22 09:57:29,487 epoch 3 - iter 16/28 - loss 1.23158406 - samples/sec: 67.49 - lr: 0.000030
2021-06-22 09:57:30,480 epoch 3 - iter 18/28 - loss 1.20973503 - samples/sec: 64.50 - lr: 0.000030
2021-06-22 09:57:31,420 epoch 3 - iter 20/28 - loss 1.16750579 - samples/sec: 68.06 - lr: 0.000030
2021-06-22 09:57:32,397 epoch 3 - iter 22/28 - loss 1.11974643 - samples/sec: 65.59 - lr: 0.000030
2021-06-22 09:57:33,344 epoch 3 - iter 24/28 - loss 1.09884730 - samples/sec: 67.60 - lr: 0.000030
2021-06-22 09:57:34,288 epoch 3 - iter 26/28 - loss 1.07179768 - samples/sec: 67.82 - lr: 0.000030
2021-06-22 09:57:34,848 epoch 3 - iter 28/28 - loss 1.01714038 - samples/sec: 114.39 - lr: 0.000030
2021-06-22 09:57:34,848 ----------------------------------------------------------------------------------------------------
2021-06-22 09:57:34,849 EPOCH 3 done: loss 1.0171 - lr 0.0000300
2021-06-22 09:57:35,808 DEV : loss 0.7357549071311951 - score 0.9105
2021-06-22 09:57:35,822 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:57:41,248 ----------------------------------------------------------------------------------------------------
2021-06-22 09:57:42,207 epoch 4 - iter 2/28 - loss 0.86834025 - samples/sec: 66.79 - lr: 0.000030
2021-06-22 09:57:43,182 epoch 4 - iter 4/28 - loss 0.87228775 - samples/sec: 65.67 - lr: 0.000030
2021-06-22 09:57:44,115 epoch 4 - iter 6/28 - loss 0.81763601 - samples/sec: 68.64 - lr: 0.000030
2021-06-22 09:57:45,076 epoch 4 - iter 8/28 - loss 0.82216359 - samples/sec: 66.64 - lr: 0.000030
2021-06-22 09:57:46,048 epoch 4 - iter 10/28 - loss 0.85278332 - samples/sec: 65.88 - lr: 0.000030
2021-06-22 09:57:46,999 epoch 4 - iter 12/28 - loss 0.83874976 - samples/sec: 67.32 - lr: 0.000030
2021-06-22 09:57:47,964 epoch 4 - iter 14/28 - loss 0.82394548 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 09:57:48,933 epoch 4 - iter 16/28 - loss 0.81546416 - samples/sec: 66.02 - lr: 0.000030
2021-06-22 09:57:49,910 epoch 4 - iter 18/28 - loss 0.80438192 - samples/sec: 65.56 - lr: 0.000030
2021-06-22 09:57:50,864 epoch 4 - iter 20/28 - loss 0.80957770 - samples/sec: 67.11 - lr: 0.000030
2021-06-22 09:57:51,804 epoch 4 - iter 22/28 - loss 0.80844196 - samples/sec: 68.17 - lr: 0.000030
2021-06-22 09:57:52,786 epoch 4 - iter 24/28 - loss 0.81276412 - samples/sec: 65.15 - lr: 0.000030
2021-06-22 09:57:53,745 epoch 4 - iter 26/28 - loss 0.80880173 - samples/sec: 66.80 - lr: 0.000030
2021-06-22 09:57:54,299 epoch 4 - iter 28/28 - loss 0.78342542 - samples/sec: 115.63 - lr: 0.000030
2021-06-22 09:57:54,299 ----------------------------------------------------------------------------------------------------
2021-06-22 09:57:54,299 EPOCH 4 done: loss 0.7834 - lr 0.0000300
2021-06-22 09:57:55,369 DEV : loss 0.6476513147354126 - score 0.9228
2021-06-22 09:57:55,383 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:58:00,832 ----------------------------------------------------------------------------------------------------
2021-06-22 09:58:01,790 epoch 5 - iter 2/28 - loss 0.86243451 - samples/sec: 66.83 - lr: 0.000030
2021-06-22 09:58:02,770 epoch 5 - iter 4/28 - loss 0.74580404 - samples/sec: 65.34 - lr: 0.000030
2021-06-22 09:58:03,736 epoch 5 - iter 6/28 - loss 0.67991528 - samples/sec: 66.31 - lr: 0.000030
2021-06-22 09:58:04,680 epoch 5 - iter 8/28 - loss 0.70433184 - samples/sec: 67.82 - lr: 0.000030
2021-06-22 09:58:05,656 epoch 5 - iter 10/28 - loss 0.72216265 - samples/sec: 65.62 - lr: 0.000030
2021-06-22 09:58:06,622 epoch 5 - iter 12/28 - loss 0.71313923 - samples/sec: 66.27 - lr: 0.000030
2021-06-22 09:58:07,598 epoch 5 - iter 14/28 - loss 0.72149980 - samples/sec: 65.62 - lr: 0.000030
2021-06-22 09:58:08,561 epoch 5 - iter 16/28 - loss 0.72451062 - samples/sec: 66.51 - lr: 0.000030
2021-06-22 09:58:09,522 epoch 5 - iter 18/28 - loss 0.71080484 - samples/sec: 66.64 - lr: 0.000030
2021-06-22 09:58:10,488 epoch 5 - iter 20/28 - loss 0.71999312 - samples/sec: 66.25 - lr: 0.000030
2021-06-22 09:58:11,451 epoch 5 - iter 22/28 - loss 0.70203324 - samples/sec: 66.52 - lr: 0.000030
2021-06-22 09:58:12,399 epoch 5 - iter 24/28 - loss 0.71531934 - samples/sec: 67.50 - lr: 0.000030
2021-06-22 09:58:13,329 epoch 5 - iter 26/28 - loss 0.71523111 - samples/sec: 68.93 - lr: 0.000030
2021-06-22 09:58:13,879 epoch 5 - iter 28/28 - loss 0.68703630 - samples/sec: 116.46 - lr: 0.000030
2021-06-22 09:58:13,879 ----------------------------------------------------------------------------------------------------
2021-06-22 09:58:13,879 EPOCH 5 done: loss 0.6870 - lr 0.0000300
2021-06-22 09:58:14,839 DEV : loss 0.641441822052002 - score 0.916
2021-06-22 09:58:14,853 BAD EPOCHS (no improvement): 1
2021-06-22 09:58:14,853 ----------------------------------------------------------------------------------------------------
2021-06-22 09:58:15,825 epoch 6 - iter 2/28 - loss 0.65344846 - samples/sec: 65.90 - lr: 0.000030
2021-06-22 09:58:16,788 epoch 6 - iter 4/28 - loss 0.67141911 - samples/sec: 66.49 - lr: 0.000030
2021-06-22 09:58:17,758 epoch 6 - iter 6/28 - loss 0.74918407 - samples/sec: 66.01 - lr: 0.000030
2021-06-22 09:58:18,712 epoch 6 - iter 8/28 - loss 0.71812408 - samples/sec: 67.12 - lr: 0.000030
2021-06-22 09:58:19,670 epoch 6 - iter 10/28 - loss 0.74450791 - samples/sec: 66.82 - lr: 0.000030
2021-06-22 09:58:20,623 epoch 6 - iter 12/28 - loss 0.72351022 - samples/sec: 67.19 - lr: 0.000030
2021-06-22 09:58:21,578 epoch 6 - iter 14/28 - loss 0.69637019 - samples/sec: 67.07 - lr: 0.000030
2021-06-22 09:58:22,549 epoch 6 - iter 16/28 - loss 0.66973241 - samples/sec: 65.92 - lr: 0.000030
2021-06-22 09:58:23,506 epoch 6 - iter 18/28 - loss 0.65403001 - samples/sec: 66.94 - lr: 0.000030
2021-06-22 09:58:24,489 epoch 6 - iter 20/28 - loss 0.66346056 - samples/sec: 65.13 - lr: 0.000030
2021-06-22 09:58:25,419 epoch 6 - iter 22/28 - loss 0.64644635 - samples/sec: 68.86 - lr: 0.000030
2021-06-22 09:58:26,356 epoch 6 - iter 24/28 - loss 0.63264246 - samples/sec: 68.34 - lr: 0.000030
2021-06-22 09:58:27,315 epoch 6 - iter 26/28 - loss 0.62386382 - samples/sec: 66.78 - lr: 0.000030
2021-06-22 09:58:27,871 epoch 6 - iter 28/28 - loss 0.61170706 - samples/sec: 115.22 - lr: 0.000030
2021-06-22 09:58:27,871 ----------------------------------------------------------------------------------------------------
2021-06-22 09:58:27,871 EPOCH 6 done: loss 0.6117 - lr 0.0000300
2021-06-22 09:58:28,832 DEV : loss 0.6443419456481934 - score 0.916
2021-06-22 09:58:28,846 BAD EPOCHS (no improvement): 2
2021-06-22 09:58:28,846 ----------------------------------------------------------------------------------------------------
2021-06-22 09:58:29,764 epoch 7 - iter 2/28 - loss 0.70413706 - samples/sec: 69.74 - lr: 0.000030
2021-06-22 09:58:30,727 epoch 7 - iter 4/28 - loss 0.54263808 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 09:58:31,683 epoch 7 - iter 6/28 - loss 0.51524820 - samples/sec: 67.03 - lr: 0.000030
2021-06-22 09:58:32,636 epoch 7 - iter 8/28 - loss 0.54226362 - samples/sec: 67.16 - lr: 0.000030
2021-06-22 09:58:33,611 epoch 7 - iter 10/28 - loss 0.57298631 - samples/sec: 65.69 - lr: 0.000030
2021-06-22 09:58:34,581 epoch 7 - iter 12/28 - loss 0.59543580 - samples/sec: 66.03 - lr: 0.000030
2021-06-22 09:58:35,522 epoch 7 - iter 14/28 - loss 0.61916254 - samples/sec: 68.01 - lr: 0.000030
2021-06-22 09:58:36,508 epoch 7 - iter 16/28 - loss 0.61831599 - samples/sec: 64.98 - lr: 0.000030
2021-06-22 09:58:37,456 epoch 7 - iter 18/28 - loss 0.60521215 - samples/sec: 67.49 - lr: 0.000030
2021-06-22 09:58:38,415 epoch 7 - iter 20/28 - loss 0.64815544 - samples/sec: 66.78 - lr: 0.000030
2021-06-22 09:58:39,379 epoch 7 - iter 22/28 - loss 0.63283702 - samples/sec: 66.46 - lr: 0.000030
2021-06-22 09:58:40,345 epoch 7 - iter 24/28 - loss 0.61776268 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 09:58:41,298 epoch 7 - iter 26/28 - loss 0.63374225 - samples/sec: 67.18 - lr: 0.000030
2021-06-22 09:58:41,834 epoch 7 - iter 28/28 - loss 0.61401700 - samples/sec: 119.59 - lr: 0.000030
2021-06-22 09:58:41,834 ----------------------------------------------------------------------------------------------------
2021-06-22 09:58:41,834 EPOCH 7 done: loss 0.6140 - lr 0.0000300
2021-06-22 09:58:42,794 DEV : loss 0.6476322412490845 - score 0.9135
2021-06-22 09:58:42,808 BAD EPOCHS (no improvement): 3
2021-06-22 09:58:42,808 ----------------------------------------------------------------------------------------------------
2021-06-22 09:58:43,728 epoch 8 - iter 2/28 - loss 0.58284831 - samples/sec: 69.60 - lr: 0.000030
2021-06-22 09:58:44,685 epoch 8 - iter 4/28 - loss 0.55336869 - samples/sec: 66.94 - lr: 0.000030
2021-06-22 09:58:45,658 epoch 8 - iter 6/28 - loss 0.60842119 - samples/sec: 65.79 - lr: 0.000030
2021-06-22 09:58:46,626 epoch 8 - iter 8/28 - loss 0.61022200 - samples/sec: 66.12 - lr: 0.000030
2021-06-22 09:58:47,588 epoch 8 - iter 10/28 - loss 0.56968195 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 09:58:48,562 epoch 8 - iter 12/28 - loss 0.61295901 - samples/sec: 65.76 - lr: 0.000030
2021-06-22 09:58:49,528 epoch 8 - iter 14/28 - loss 0.58096848 - samples/sec: 66.26 - lr: 0.000030
2021-06-22 09:58:50,479 epoch 8 - iter 16/28 - loss 0.56647465 - samples/sec: 67.33 - lr: 0.000030
2021-06-22 09:58:51,459 epoch 8 - iter 18/28 - loss 0.56476735 - samples/sec: 65.33 - lr: 0.000030
2021-06-22 09:58:52,414 epoch 8 - iter 20/28 - loss 0.56683292 - samples/sec: 67.08 - lr: 0.000030
2021-06-22 09:58:53,370 epoch 8 - iter 22/28 - loss 0.57145379 - samples/sec: 66.96 - lr: 0.000030
2021-06-22 09:58:54,327 epoch 8 - iter 24/28 - loss 0.56781871 - samples/sec: 66.93 - lr: 0.000030
2021-06-22 09:58:55,297 epoch 8 - iter 26/28 - loss 0.54646837 - samples/sec: 66.03 - lr: 0.000030
2021-06-22 09:58:55,822 epoch 8 - iter 28/28 - loss 0.53635788 - samples/sec: 121.89 - lr: 0.000030
2021-06-22 09:58:55,823 ----------------------------------------------------------------------------------------------------
2021-06-22 09:58:55,823 EPOCH 8 done: loss 0.5364 - lr 0.0000300
2021-06-22 09:58:56,907 DEV : loss 0.5783761143684387 - score 0.9251
2021-06-22 09:58:56,920 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 09:59:02,346 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:03,304 epoch 9 - iter 2/28 - loss 0.53090516 - samples/sec: 66.92 - lr: 0.000030
2021-06-22 09:59:04,262 epoch 9 - iter 4/28 - loss 0.49459691 - samples/sec: 66.85 - lr: 0.000030
2021-06-22 09:59:05,210 epoch 9 - iter 6/28 - loss 0.55504411 - samples/sec: 67.50 - lr: 0.000030
2021-06-22 09:59:06,164 epoch 9 - iter 8/28 - loss 0.51007140 - samples/sec: 67.11 - lr: 0.000030
2021-06-22 09:59:07,116 epoch 9 - iter 10/28 - loss 0.53783782 - samples/sec: 67.32 - lr: 0.000030
2021-06-22 09:59:08,061 epoch 9 - iter 12/28 - loss 0.53620808 - samples/sec: 67.71 - lr: 0.000030
2021-06-22 09:59:08,996 epoch 9 - iter 14/28 - loss 0.51560108 - samples/sec: 68.49 - lr: 0.000030
2021-06-22 09:59:09,951 epoch 9 - iter 16/28 - loss 0.50142635 - samples/sec: 67.09 - lr: 0.000030
2021-06-22 09:59:10,928 epoch 9 - iter 18/28 - loss 0.49545838 - samples/sec: 65.51 - lr: 0.000030
2021-06-22 09:59:11,875 epoch 9 - iter 20/28 - loss 0.51284841 - samples/sec: 67.60 - lr: 0.000030
2021-06-22 09:59:12,844 epoch 9 - iter 22/28 - loss 0.51533397 - samples/sec: 66.09 - lr: 0.000030
2021-06-22 09:59:13,793 epoch 9 - iter 24/28 - loss 0.51424060 - samples/sec: 67.50 - lr: 0.000030
2021-06-22 09:59:14,763 epoch 9 - iter 26/28 - loss 0.51727556 - samples/sec: 66.03 - lr: 0.000030
2021-06-22 09:59:15,325 epoch 9 - iter 28/28 - loss 0.49182369 - samples/sec: 113.83 - lr: 0.000030
2021-06-22 09:59:15,326 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:15,326 EPOCH 9 done: loss 0.4918 - lr 0.0000300
2021-06-22 09:59:16,287 DEV : loss 0.5751835107803345 - score 0.9216
2021-06-22 09:59:16,300 BAD EPOCHS (no improvement): 1
2021-06-22 09:59:16,301 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:17,269 epoch 10 - iter 2/28 - loss 0.39978707 - samples/sec: 66.12 - lr: 0.000030
2021-06-22 09:59:18,220 epoch 10 - iter 4/28 - loss 0.40879442 - samples/sec: 67.36 - lr: 0.000030
2021-06-22 09:59:19,186 epoch 10 - iter 6/28 - loss 0.36553340 - samples/sec: 66.24 - lr: 0.000030
2021-06-22 09:59:20,089 epoch 10 - iter 8/28 - loss 0.34816478 - samples/sec: 70.98 - lr: 0.000030
2021-06-22 09:59:21,039 epoch 10 - iter 10/28 - loss 0.40391004 - samples/sec: 67.36 - lr: 0.000030
2021-06-22 09:59:22,019 epoch 10 - iter 12/28 - loss 0.44500174 - samples/sec: 65.38 - lr: 0.000030
2021-06-22 09:59:22,998 epoch 10 - iter 14/28 - loss 0.43413511 - samples/sec: 65.41 - lr: 0.000030
2021-06-22 09:59:23,962 epoch 10 - iter 16/28 - loss 0.43456557 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 09:59:24,891 epoch 10 - iter 18/28 - loss 0.43302624 - samples/sec: 68.90 - lr: 0.000030
2021-06-22 09:59:25,856 epoch 10 - iter 20/28 - loss 0.44921919 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 09:59:26,819 epoch 10 - iter 22/28 - loss 0.46564491 - samples/sec: 66.45 - lr: 0.000030
2021-06-22 09:59:27,800 epoch 10 - iter 24/28 - loss 0.45022461 - samples/sec: 65.30 - lr: 0.000030
2021-06-22 09:59:28,754 epoch 10 - iter 26/28 - loss 0.45506715 - samples/sec: 67.14 - lr: 0.000030
2021-06-22 09:59:29,312 epoch 10 - iter 28/28 - loss 0.44514499 - samples/sec: 114.80 - lr: 0.000030
2021-06-22 09:59:29,312 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:29,312 EPOCH 10 done: loss 0.4451 - lr 0.0000300
2021-06-22 09:59:30,274 DEV : loss 0.6332817077636719 - score 0.9132
2021-06-22 09:59:30,288 BAD EPOCHS (no improvement): 2
2021-06-22 09:59:30,288 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:31,238 epoch 11 - iter 2/28 - loss 0.51584114 - samples/sec: 67.42 - lr: 0.000030
2021-06-22 09:59:32,212 epoch 11 - iter 4/28 - loss 0.59868566 - samples/sec: 65.69 - lr: 0.000030
2021-06-22 09:59:33,163 epoch 11 - iter 6/28 - loss 0.53542077 - samples/sec: 67.39 - lr: 0.000030
2021-06-22 09:59:34,137 epoch 11 - iter 8/28 - loss 0.48206867 - samples/sec: 65.71 - lr: 0.000030
2021-06-22 09:59:35,091 epoch 11 - iter 10/28 - loss 0.46174431 - samples/sec: 67.15 - lr: 0.000030
2021-06-22 09:59:36,075 epoch 11 - iter 12/28 - loss 0.44282504 - samples/sec: 65.03 - lr: 0.000030
2021-06-22 09:59:37,053 epoch 11 - iter 14/28 - loss 0.43469935 - samples/sec: 65.47 - lr: 0.000030
2021-06-22 09:59:38,017 epoch 11 - iter 16/28 - loss 0.43221384 - samples/sec: 66.44 - lr: 0.000030
2021-06-22 09:59:38,981 epoch 11 - iter 18/28 - loss 0.43359242 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 09:59:39,963 epoch 11 - iter 20/28 - loss 0.43251770 - samples/sec: 65.17 - lr: 0.000030
2021-06-22 09:59:40,931 epoch 11 - iter 22/28 - loss 0.42320080 - samples/sec: 66.18 - lr: 0.000030
2021-06-22 09:59:41,899 epoch 11 - iter 24/28 - loss 0.42217072 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 09:59:42,845 epoch 11 - iter 26/28 - loss 0.42055041 - samples/sec: 67.66 - lr: 0.000030
2021-06-22 09:59:43,374 epoch 11 - iter 28/28 - loss 0.43637966 - samples/sec: 121.18 - lr: 0.000030
2021-06-22 09:59:43,374 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:43,374 EPOCH 11 done: loss 0.4364 - lr 0.0000300
2021-06-22 09:59:44,335 DEV : loss 0.573421835899353 - score 0.9205
2021-06-22 09:59:44,349 BAD EPOCHS (no improvement): 3
2021-06-22 09:59:44,349 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:45,313 epoch 12 - iter 2/28 - loss 0.41314393 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 09:59:46,263 epoch 12 - iter 4/28 - loss 0.42160787 - samples/sec: 67.35 - lr: 0.000030
2021-06-22 09:59:47,220 epoch 12 - iter 6/28 - loss 0.44957927 - samples/sec: 66.93 - lr: 0.000030
2021-06-22 09:59:48,168 epoch 12 - iter 8/28 - loss 0.42830248 - samples/sec: 67.56 - lr: 0.000030
2021-06-22 09:59:49,139 epoch 12 - iter 10/28 - loss 0.41723980 - samples/sec: 65.90 - lr: 0.000030
2021-06-22 09:59:50,106 epoch 12 - iter 12/28 - loss 0.42166036 - samples/sec: 66.23 - lr: 0.000030
2021-06-22 09:59:51,083 epoch 12 - iter 14/28 - loss 0.42454332 - samples/sec: 65.57 - lr: 0.000030
2021-06-22 09:59:52,056 epoch 12 - iter 16/28 - loss 0.41492607 - samples/sec: 65.82 - lr: 0.000030
2021-06-22 09:59:53,005 epoch 12 - iter 18/28 - loss 0.40290735 - samples/sec: 67.45 - lr: 0.000030
2021-06-22 09:59:53,977 epoch 12 - iter 20/28 - loss 0.38237151 - samples/sec: 65.89 - lr: 0.000030
2021-06-22 09:59:54,959 epoch 12 - iter 22/28 - loss 0.37775003 - samples/sec: 65.23 - lr: 0.000030
2021-06-22 09:59:55,935 epoch 12 - iter 24/28 - loss 0.36889541 - samples/sec: 65.61 - lr: 0.000030
2021-06-22 09:59:56,886 epoch 12 - iter 26/28 - loss 0.38662347 - samples/sec: 67.33 - lr: 0.000030
2021-06-22 09:59:57,427 epoch 12 - iter 28/28 - loss 0.36695118 - samples/sec: 118.40 - lr: 0.000030
2021-06-22 09:59:57,427 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:57,427 EPOCH 12 done: loss 0.3670 - lr 0.0000300
2021-06-22 09:59:58,389 DEV : loss 0.6036906242370605 - score 0.9153
Epoch    12: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 09:59:58,403 BAD EPOCHS (no improvement): 4
2021-06-22 09:59:58,404 ----------------------------------------------------------------------------------------------------
2021-06-22 09:59:59,360 epoch 13 - iter 2/28 - loss 0.43910407 - samples/sec: 66.95 - lr: 0.000015
2021-06-22 10:00:00,331 epoch 13 - iter 4/28 - loss 0.44271112 - samples/sec: 65.91 - lr: 0.000015
2021-06-22 10:00:01,303 epoch 13 - iter 6/28 - loss 0.40528832 - samples/sec: 65.90 - lr: 0.000015
2021-06-22 10:00:02,274 epoch 13 - iter 8/28 - loss 0.40676161 - samples/sec: 65.97 - lr: 0.000015
2021-06-22 10:00:03,242 epoch 13 - iter 10/28 - loss 0.38535772 - samples/sec: 66.11 - lr: 0.000015
2021-06-22 10:00:04,221 epoch 13 - iter 12/28 - loss 0.39707304 - samples/sec: 65.46 - lr: 0.000015
2021-06-22 10:00:05,164 epoch 13 - iter 14/28 - loss 0.37672092 - samples/sec: 67.85 - lr: 0.000015
2021-06-22 10:00:06,147 epoch 13 - iter 16/28 - loss 0.37297207 - samples/sec: 65.14 - lr: 0.000015
2021-06-22 10:00:07,100 epoch 13 - iter 18/28 - loss 0.37252023 - samples/sec: 67.25 - lr: 0.000015
2021-06-22 10:00:08,078 epoch 13 - iter 20/28 - loss 0.37560963 - samples/sec: 65.44 - lr: 0.000015
2021-06-22 10:00:09,058 epoch 13 - iter 22/28 - loss 0.37528462 - samples/sec: 65.35 - lr: 0.000015
2021-06-22 10:00:10,011 epoch 13 - iter 24/28 - loss 0.36438229 - samples/sec: 67.17 - lr: 0.000015
2021-06-22 10:00:10,966 epoch 13 - iter 26/28 - loss 0.36069884 - samples/sec: 67.06 - lr: 0.000015
2021-06-22 10:00:11,511 epoch 13 - iter 28/28 - loss 0.35018648 - samples/sec: 117.58 - lr: 0.000015
2021-06-22 10:00:11,511 ----------------------------------------------------------------------------------------------------
2021-06-22 10:00:11,511 EPOCH 13 done: loss 0.3502 - lr 0.0000150
2021-06-22 10:00:12,600 DEV : loss 0.6067675352096558 - score 0.9149
2021-06-22 10:00:12,614 BAD EPOCHS (no improvement): 1
2021-06-22 10:00:12,614 ----------------------------------------------------------------------------------------------------
2021-06-22 10:00:13,579 epoch 14 - iter 2/28 - loss 0.33295727 - samples/sec: 66.37 - lr: 0.000015
2021-06-22 10:00:14,552 epoch 14 - iter 4/28 - loss 0.30473176 - samples/sec: 65.79 - lr: 0.000015
2021-06-22 10:00:15,519 epoch 14 - iter 6/28 - loss 0.32826504 - samples/sec: 66.20 - lr: 0.000015
2021-06-22 10:00:16,478 epoch 14 - iter 8/28 - loss 0.34800357 - samples/sec: 66.78 - lr: 0.000015
2021-06-22 10:00:17,444 epoch 14 - iter 10/28 - loss 0.33232333 - samples/sec: 66.31 - lr: 0.000015
2021-06-22 10:00:18,432 epoch 14 - iter 12/28 - loss 0.34235940 - samples/sec: 64.83 - lr: 0.000015
2021-06-22 10:00:19,383 epoch 14 - iter 14/28 - loss 0.33407088 - samples/sec: 67.32 - lr: 0.000015
2021-06-22 10:00:20,336 epoch 14 - iter 16/28 - loss 0.32323856 - samples/sec: 67.17 - lr: 0.000015
2021-06-22 10:00:21,300 epoch 14 - iter 18/28 - loss 0.33189032 - samples/sec: 66.44 - lr: 0.000015
2021-06-22 10:00:22,270 epoch 14 - iter 20/28 - loss 0.31625772 - samples/sec: 65.99 - lr: 0.000015
2021-06-22 10:00:23,236 epoch 14 - iter 22/28 - loss 0.31477666 - samples/sec: 66.30 - lr: 0.000015
2021-06-22 10:00:24,201 epoch 14 - iter 24/28 - loss 0.34852301 - samples/sec: 66.38 - lr: 0.000015
2021-06-22 10:00:25,157 epoch 14 - iter 26/28 - loss 0.34887480 - samples/sec: 66.93 - lr: 0.000015
2021-06-22 10:00:25,712 epoch 14 - iter 28/28 - loss 0.47367447 - samples/sec: 115.58 - lr: 0.000015
2021-06-22 10:00:25,712 ----------------------------------------------------------------------------------------------------
2021-06-22 10:00:25,712 EPOCH 14 done: loss 0.4737 - lr 0.0000150
2021-06-22 10:00:26,673 DEV : loss 0.5891619920730591 - score 0.9202
2021-06-22 10:00:26,687 BAD EPOCHS (no improvement): 2
2021-06-22 10:00:26,687 ----------------------------------------------------------------------------------------------------
2021-06-22 10:00:27,634 epoch 15 - iter 2/28 - loss 0.37119356 - samples/sec: 67.59 - lr: 0.000015
2021-06-22 10:00:28,607 epoch 15 - iter 4/28 - loss 0.37778690 - samples/sec: 65.85 - lr: 0.000015
2021-06-22 10:00:29,561 epoch 15 - iter 6/28 - loss 0.35137217 - samples/sec: 67.11 - lr: 0.000015
2021-06-22 10:00:30,519 epoch 15 - iter 8/28 - loss 0.37903981 - samples/sec: 66.83 - lr: 0.000015
2021-06-22 10:00:31,484 epoch 15 - iter 10/28 - loss 0.36371531 - samples/sec: 66.38 - lr: 0.000015
2021-06-22 10:00:32,464 epoch 15 - iter 12/28 - loss 0.33768780 - samples/sec: 65.33 - lr: 0.000015
2021-06-22 10:00:33,430 epoch 15 - iter 14/28 - loss 0.32273570 - samples/sec: 66.29 - lr: 0.000015
2021-06-22 10:00:34,401 epoch 15 - iter 16/28 - loss 0.32924853 - samples/sec: 65.97 - lr: 0.000015
2021-06-22 10:00:35,363 epoch 15 - iter 18/28 - loss 0.32800373 - samples/sec: 66.54 - lr: 0.000015
2021-06-22 10:00:36,305 epoch 15 - iter 20/28 - loss 0.31620006 - samples/sec: 67.98 - lr: 0.000015
2021-06-22 10:00:37,284 epoch 15 - iter 22/28 - loss 0.34607659 - samples/sec: 65.44 - lr: 0.000015
2021-06-22 10:00:38,258 epoch 15 - iter 24/28 - loss 0.35610644 - samples/sec: 65.68 - lr: 0.000015
2021-06-22 10:00:39,217 epoch 15 - iter 26/28 - loss 0.36076645 - samples/sec: 66.80 - lr: 0.000015
2021-06-22 10:00:39,777 epoch 15 - iter 28/28 - loss 0.34772116 - samples/sec: 114.47 - lr: 0.000015
2021-06-22 10:00:39,777 ----------------------------------------------------------------------------------------------------
2021-06-22 10:00:39,777 EPOCH 15 done: loss 0.3477 - lr 0.0000150
2021-06-22 10:00:40,741 DEV : loss 0.5504068732261658 - score 0.9219
2021-06-22 10:00:40,755 BAD EPOCHS (no improvement): 3
2021-06-22 10:00:40,755 ----------------------------------------------------------------------------------------------------
2021-06-22 10:00:41,713 epoch 16 - iter 2/28 - loss 0.56371081 - samples/sec: 66.88 - lr: 0.000015
2021-06-22 10:00:42,663 epoch 16 - iter 4/28 - loss 0.36195645 - samples/sec: 67.36 - lr: 0.000015
2021-06-22 10:00:43,649 epoch 16 - iter 6/28 - loss 0.33022449 - samples/sec: 64.99 - lr: 0.000015
2021-06-22 10:00:44,622 epoch 16 - iter 8/28 - loss 0.31629610 - samples/sec: 65.78 - lr: 0.000015
2021-06-22 10:00:45,595 epoch 16 - iter 10/28 - loss 0.30264951 - samples/sec: 65.84 - lr: 0.000015
2021-06-22 10:00:46,551 epoch 16 - iter 12/28 - loss 0.30155820 - samples/sec: 66.96 - lr: 0.000015
2021-06-22 10:00:47,529 epoch 16 - iter 14/28 - loss 0.30105765 - samples/sec: 65.48 - lr: 0.000015
2021-06-22 10:00:48,491 epoch 16 - iter 16/28 - loss 0.29816385 - samples/sec: 66.55 - lr: 0.000015
2021-06-22 10:00:49,457 epoch 16 - iter 18/28 - loss 0.30525369 - samples/sec: 66.34 - lr: 0.000015
2021-06-22 10:00:50,395 epoch 16 - iter 20/28 - loss 0.30641604 - samples/sec: 68.23 - lr: 0.000015
2021-06-22 10:00:51,359 epoch 16 - iter 22/28 - loss 0.30817237 - samples/sec: 66.45 - lr: 0.000015
2021-06-22 10:00:52,336 epoch 16 - iter 24/28 - loss 0.31189298 - samples/sec: 65.54 - lr: 0.000015
2021-06-22 10:00:53,311 epoch 16 - iter 26/28 - loss 0.30357240 - samples/sec: 65.66 - lr: 0.000015
2021-06-22 10:00:53,871 epoch 16 - iter 28/28 - loss 0.30015287 - samples/sec: 114.50 - lr: 0.000015
2021-06-22 10:00:53,871 ----------------------------------------------------------------------------------------------------
2021-06-22 10:00:53,871 EPOCH 16 done: loss 0.3002 - lr 0.0000150
2021-06-22 10:00:54,833 DEV : loss 0.5723783373832703 - score 0.9202
Epoch    16: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 10:00:54,847 BAD EPOCHS (no improvement): 4
2021-06-22 10:00:54,847 ----------------------------------------------------------------------------------------------------
2021-06-22 10:00:55,815 epoch 17 - iter 2/28 - loss 0.29830074 - samples/sec: 66.16 - lr: 0.000008
2021-06-22 10:00:56,784 epoch 17 - iter 4/28 - loss 0.31953773 - samples/sec: 66.06 - lr: 0.000008
2021-06-22 10:00:57,766 epoch 17 - iter 6/28 - loss 0.29621448 - samples/sec: 65.22 - lr: 0.000008
2021-06-22 10:00:58,695 epoch 17 - iter 8/28 - loss 0.30534381 - samples/sec: 68.94 - lr: 0.000008
2021-06-22 10:00:59,680 epoch 17 - iter 10/28 - loss 0.30697601 - samples/sec: 64.96 - lr: 0.000008
2021-06-22 10:01:00,642 epoch 17 - iter 12/28 - loss 0.28434669 - samples/sec: 66.57 - lr: 0.000008
2021-06-22 10:01:01,608 epoch 17 - iter 14/28 - loss 0.29464076 - samples/sec: 66.32 - lr: 0.000008
2021-06-22 10:01:02,580 epoch 17 - iter 16/28 - loss 0.30394343 - samples/sec: 65.86 - lr: 0.000008
2021-06-22 10:01:03,550 epoch 17 - iter 18/28 - loss 0.29430238 - samples/sec: 66.00 - lr: 0.000008
2021-06-22 10:01:04,507 epoch 17 - iter 20/28 - loss 0.29917786 - samples/sec: 66.91 - lr: 0.000008
2021-06-22 10:01:05,459 epoch 17 - iter 22/28 - loss 0.29403263 - samples/sec: 67.27 - lr: 0.000008
2021-06-22 10:01:06,427 epoch 17 - iter 24/28 - loss 0.29071893 - samples/sec: 66.17 - lr: 0.000008
2021-06-22 10:01:07,393 epoch 17 - iter 26/28 - loss 0.30018410 - samples/sec: 66.25 - lr: 0.000008
2021-06-22 10:01:07,949 epoch 17 - iter 28/28 - loss 0.29211477 - samples/sec: 115.36 - lr: 0.000008
2021-06-22 10:01:07,949 ----------------------------------------------------------------------------------------------------
2021-06-22 10:01:07,949 EPOCH 17 done: loss 0.2921 - lr 0.0000075
2021-06-22 10:01:08,909 DEV : loss 0.5483714938163757 - score 0.9219
2021-06-22 10:01:08,923 BAD EPOCHS (no improvement): 1
2021-06-22 10:01:08,924 ----------------------------------------------------------------------------------------------------
2021-06-22 10:01:09,890 epoch 18 - iter 2/28 - loss 0.28303236 - samples/sec: 66.24 - lr: 0.000008
2021-06-22 10:01:10,960 epoch 18 - iter 4/28 - loss 0.33200264 - samples/sec: 59.84 - lr: 0.000008
2021-06-22 10:01:11,923 epoch 18 - iter 6/28 - loss 0.30816869 - samples/sec: 66.50 - lr: 0.000008
2021-06-22 10:01:12,890 epoch 18 - iter 8/28 - loss 0.27828817 - samples/sec: 66.26 - lr: 0.000008
2021-06-22 10:01:13,875 epoch 18 - iter 10/28 - loss 0.27467550 - samples/sec: 64.98 - lr: 0.000008
2021-06-22 10:01:14,843 epoch 18 - iter 12/28 - loss 0.27639925 - samples/sec: 66.20 - lr: 0.000008
2021-06-22 10:01:15,795 epoch 18 - iter 14/28 - loss 0.27266634 - samples/sec: 67.24 - lr: 0.000008
2021-06-22 10:01:16,752 epoch 18 - iter 16/28 - loss 0.27256875 - samples/sec: 66.92 - lr: 0.000008
2021-06-22 10:01:17,699 epoch 18 - iter 18/28 - loss 0.29355991 - samples/sec: 67.59 - lr: 0.000008
2021-06-22 10:01:18,679 epoch 18 - iter 20/28 - loss 0.29095867 - samples/sec: 65.36 - lr: 0.000008
2021-06-22 10:01:19,642 epoch 18 - iter 22/28 - loss 0.30483931 - samples/sec: 66.49 - lr: 0.000008
2021-06-22 10:01:20,619 epoch 18 - iter 24/28 - loss 0.29830371 - samples/sec: 65.51 - lr: 0.000008
2021-06-22 10:01:21,597 epoch 18 - iter 26/28 - loss 0.29361027 - samples/sec: 65.47 - lr: 0.000008
2021-06-22 10:01:22,152 epoch 18 - iter 28/28 - loss 0.28701352 - samples/sec: 115.44 - lr: 0.000008
2021-06-22 10:01:22,153 ----------------------------------------------------------------------------------------------------
2021-06-22 10:01:22,153 EPOCH 18 done: loss 0.2870 - lr 0.0000075
2021-06-22 10:01:23,117 DEV : loss 0.5408754348754883 - score 0.9219
2021-06-22 10:01:23,131 BAD EPOCHS (no improvement): 2
2021-06-22 10:01:23,131 ----------------------------------------------------------------------------------------------------
2021-06-22 10:01:24,087 epoch 19 - iter 2/28 - loss 0.23306620 - samples/sec: 66.99 - lr: 0.000008
2021-06-22 10:01:25,044 epoch 19 - iter 4/28 - loss 0.30131444 - samples/sec: 66.92 - lr: 0.000008
2021-06-22 10:01:26,012 epoch 19 - iter 6/28 - loss 0.32837642 - samples/sec: 66.13 - lr: 0.000008
2021-06-22 10:01:26,990 epoch 19 - iter 8/28 - loss 0.30393223 - samples/sec: 65.47 - lr: 0.000008
2021-06-22 10:01:27,971 epoch 19 - iter 10/28 - loss 0.32822565 - samples/sec: 65.29 - lr: 0.000008
2021-06-22 10:01:28,943 epoch 19 - iter 12/28 - loss 0.30630179 - samples/sec: 65.93 - lr: 0.000008
2021-06-22 10:01:29,912 epoch 19 - iter 14/28 - loss 0.29816780 - samples/sec: 66.06 - lr: 0.000008
2021-06-22 10:01:30,870 epoch 19 - iter 16/28 - loss 0.30548300 - samples/sec: 66.82 - lr: 0.000008
2021-06-22 10:01:31,824 epoch 19 - iter 18/28 - loss 0.30009406 - samples/sec: 67.15 - lr: 0.000008
2021-06-22 10:01:32,787 epoch 19 - iter 20/28 - loss 0.30416277 - samples/sec: 66.47 - lr: 0.000008
2021-06-22 10:01:33,771 epoch 19 - iter 22/28 - loss 0.29644405 - samples/sec: 65.09 - lr: 0.000008
2021-06-22 10:01:34,745 epoch 19 - iter 24/28 - loss 0.29362574 - samples/sec: 65.72 - lr: 0.000008
2021-06-22 10:01:35,706 epoch 19 - iter 26/28 - loss 0.30254664 - samples/sec: 66.64 - lr: 0.000008
2021-06-22 10:01:36,233 epoch 19 - iter 28/28 - loss 0.30709761 - samples/sec: 121.60 - lr: 0.000008
2021-06-22 10:01:36,233 ----------------------------------------------------------------------------------------------------
2021-06-22 10:01:36,233 EPOCH 19 done: loss 0.3071 - lr 0.0000075
2021-06-22 10:01:37,193 DEV : loss 0.5269510746002197 - score 0.9254
2021-06-22 10:01:37,207 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:01:42,738 ----------------------------------------------------------------------------------------------------
2021-06-22 10:01:43,679 epoch 20 - iter 2/28 - loss 0.28089547 - samples/sec: 68.10 - lr: 0.000008
2021-06-22 10:01:44,643 epoch 20 - iter 4/28 - loss 0.27342844 - samples/sec: 66.43 - lr: 0.000008
2021-06-22 10:01:45,619 epoch 20 - iter 6/28 - loss 0.26176284 - samples/sec: 65.64 - lr: 0.000008
2021-06-22 10:01:46,583 epoch 20 - iter 8/28 - loss 0.28935489 - samples/sec: 66.38 - lr: 0.000008
2021-06-22 10:01:47,555 epoch 20 - iter 10/28 - loss 0.30268753 - samples/sec: 65.88 - lr: 0.000008
2021-06-22 10:01:48,518 epoch 20 - iter 12/28 - loss 0.28970449 - samples/sec: 66.51 - lr: 0.000008
2021-06-22 10:01:49,482 epoch 20 - iter 14/28 - loss 0.30387874 - samples/sec: 66.44 - lr: 0.000008
2021-06-22 10:01:50,451 epoch 20 - iter 16/28 - loss 0.30871679 - samples/sec: 66.11 - lr: 0.000008
2021-06-22 10:01:51,422 epoch 20 - iter 18/28 - loss 0.30623829 - samples/sec: 65.93 - lr: 0.000008
2021-06-22 10:01:52,385 epoch 20 - iter 20/28 - loss 0.29677053 - samples/sec: 66.47 - lr: 0.000008
2021-06-22 10:01:53,366 epoch 20 - iter 22/28 - loss 0.29818035 - samples/sec: 65.28 - lr: 0.000008
2021-06-22 10:01:54,324 epoch 20 - iter 24/28 - loss 0.30384867 - samples/sec: 66.85 - lr: 0.000008
2021-06-22 10:01:55,293 epoch 20 - iter 26/28 - loss 0.30178069 - samples/sec: 66.04 - lr: 0.000008
2021-06-22 10:01:55,791 epoch 20 - iter 28/28 - loss 0.29262209 - samples/sec: 128.88 - lr: 0.000008
2021-06-22 10:01:55,791 ----------------------------------------------------------------------------------------------------
2021-06-22 10:01:55,791 EPOCH 20 done: loss 0.2926 - lr 0.0000075
2021-06-22 10:01:56,752 DEV : loss 0.5377187728881836 - score 0.924
2021-06-22 10:01:56,765 BAD EPOCHS (no improvement): 1
2021-06-22 10:01:56,766 ----------------------------------------------------------------------------------------------------
2021-06-22 10:01:57,699 epoch 21 - iter 2/28 - loss 0.25707963 - samples/sec: 68.63 - lr: 0.000008
2021-06-22 10:01:58,676 epoch 21 - iter 4/28 - loss 0.30001445 - samples/sec: 65.51 - lr: 0.000008
2021-06-22 10:01:59,628 epoch 21 - iter 6/28 - loss 0.27111151 - samples/sec: 67.29 - lr: 0.000008
2021-06-22 10:02:00,621 epoch 21 - iter 8/28 - loss 0.25343449 - samples/sec: 64.46 - lr: 0.000008
2021-06-22 10:02:01,604 epoch 21 - iter 10/28 - loss 0.25160547 - samples/sec: 65.14 - lr: 0.000008
2021-06-22 10:02:02,566 epoch 21 - iter 12/28 - loss 0.24975581 - samples/sec: 66.59 - lr: 0.000008
2021-06-22 10:02:03,532 epoch 21 - iter 14/28 - loss 0.24246807 - samples/sec: 66.29 - lr: 0.000008
2021-06-22 10:02:04,513 epoch 21 - iter 16/28 - loss 0.23700194 - samples/sec: 65.25 - lr: 0.000008
2021-06-22 10:02:05,480 epoch 21 - iter 18/28 - loss 0.25857755 - samples/sec: 66.19 - lr: 0.000008
2021-06-22 10:02:06,432 epoch 21 - iter 20/28 - loss 0.25613670 - samples/sec: 67.32 - lr: 0.000008
2021-06-22 10:02:07,393 epoch 21 - iter 22/28 - loss 0.26136396 - samples/sec: 66.60 - lr: 0.000008
2021-06-22 10:02:08,356 epoch 21 - iter 24/28 - loss 0.26837465 - samples/sec: 66.51 - lr: 0.000008
2021-06-22 10:02:09,304 epoch 21 - iter 26/28 - loss 0.27382446 - samples/sec: 67.51 - lr: 0.000008
2021-06-22 10:02:09,852 epoch 21 - iter 28/28 - loss 0.26321556 - samples/sec: 116.96 - lr: 0.000008
2021-06-22 10:02:09,852 ----------------------------------------------------------------------------------------------------
2021-06-22 10:02:09,852 EPOCH 21 done: loss 0.2632 - lr 0.0000075
2021-06-22 10:02:10,814 DEV : loss 0.5490028262138367 - score 0.9219
2021-06-22 10:02:10,827 BAD EPOCHS (no improvement): 2
2021-06-22 10:02:10,828 ----------------------------------------------------------------------------------------------------
2021-06-22 10:02:11,767 epoch 22 - iter 2/28 - loss 0.32781902 - samples/sec: 68.18 - lr: 0.000008
2021-06-22 10:02:12,730 epoch 22 - iter 4/28 - loss 0.27006130 - samples/sec: 66.46 - lr: 0.000008
2021-06-22 10:02:13,700 epoch 22 - iter 6/28 - loss 0.27051555 - samples/sec: 66.02 - lr: 0.000008
2021-06-22 10:02:14,681 epoch 22 - iter 8/28 - loss 0.25171257 - samples/sec: 65.32 - lr: 0.000008
2021-06-22 10:02:15,639 epoch 22 - iter 10/28 - loss 0.25109793 - samples/sec: 66.82 - lr: 0.000008
2021-06-22 10:02:16,601 epoch 22 - iter 12/28 - loss 0.26649842 - samples/sec: 66.57 - lr: 0.000008
2021-06-22 10:02:17,551 epoch 22 - iter 14/28 - loss 0.26684938 - samples/sec: 67.42 - lr: 0.000008
2021-06-22 10:02:18,507 epoch 22 - iter 16/28 - loss 0.26512667 - samples/sec: 66.93 - lr: 0.000008
2021-06-22 10:02:19,467 epoch 22 - iter 18/28 - loss 0.26130130 - samples/sec: 66.75 - lr: 0.000008
2021-06-22 10:02:20,454 epoch 22 - iter 20/28 - loss 0.27107892 - samples/sec: 64.83 - lr: 0.000008
2021-06-22 10:02:21,432 epoch 22 - iter 22/28 - loss 0.26470747 - samples/sec: 65.52 - lr: 0.000008
2021-06-22 10:02:22,390 epoch 22 - iter 24/28 - loss 0.26986216 - samples/sec: 66.81 - lr: 0.000008
2021-06-22 10:02:23,358 epoch 22 - iter 26/28 - loss 0.26908789 - samples/sec: 66.17 - lr: 0.000008
2021-06-22 10:02:23,914 epoch 22 - iter 28/28 - loss 0.26847788 - samples/sec: 115.18 - lr: 0.000008
2021-06-22 10:02:23,914 ----------------------------------------------------------------------------------------------------
2021-06-22 10:02:23,915 EPOCH 22 done: loss 0.2685 - lr 0.0000075
2021-06-22 10:02:24,998 DEV : loss 0.5552952289581299 - score 0.9257
2021-06-22 10:02:25,012 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:02:30,531 ----------------------------------------------------------------------------------------------------
2021-06-22 10:02:31,467 epoch 23 - iter 2/28 - loss 0.25011656 - samples/sec: 68.41 - lr: 0.000008
2021-06-22 10:02:32,434 epoch 23 - iter 4/28 - loss 0.36091369 - samples/sec: 66.25 - lr: 0.000008
2021-06-22 10:02:33,407 epoch 23 - iter 6/28 - loss 0.34617554 - samples/sec: 65.83 - lr: 0.000008
2021-06-22 10:02:34,369 epoch 23 - iter 8/28 - loss 0.29071806 - samples/sec: 66.54 - lr: 0.000008
2021-06-22 10:02:35,325 epoch 23 - iter 10/28 - loss 0.33189859 - samples/sec: 66.97 - lr: 0.000008
2021-06-22 10:02:36,295 epoch 23 - iter 12/28 - loss 0.30801555 - samples/sec: 66.04 - lr: 0.000008
2021-06-22 10:02:37,273 epoch 23 - iter 14/28 - loss 0.30141819 - samples/sec: 65.46 - lr: 0.000008
2021-06-22 10:02:38,235 epoch 23 - iter 16/28 - loss 0.29927070 - samples/sec: 66.58 - lr: 0.000008
2021-06-22 10:02:39,216 epoch 23 - iter 18/28 - loss 0.29422748 - samples/sec: 65.27 - lr: 0.000008
2021-06-22 10:02:40,200 epoch 23 - iter 20/28 - loss 0.28764511 - samples/sec: 65.09 - lr: 0.000008
2021-06-22 10:02:41,182 epoch 23 - iter 22/28 - loss 0.28255163 - samples/sec: 65.21 - lr: 0.000008
2021-06-22 10:02:42,125 epoch 23 - iter 24/28 - loss 0.27945669 - samples/sec: 67.91 - lr: 0.000008
2021-06-22 10:02:43,086 epoch 23 - iter 26/28 - loss 0.27112471 - samples/sec: 66.62 - lr: 0.000008
2021-06-22 10:02:43,640 epoch 23 - iter 28/28 - loss 0.26832747 - samples/sec: 115.49 - lr: 0.000008
2021-06-22 10:02:43,641 ----------------------------------------------------------------------------------------------------
2021-06-22 10:02:43,641 EPOCH 23 done: loss 0.2683 - lr 0.0000075
2021-06-22 10:02:44,603 DEV : loss 0.5366324782371521 - score 0.9272
2021-06-22 10:02:44,617 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:02:50,159 ----------------------------------------------------------------------------------------------------
2021-06-22 10:02:51,080 epoch 24 - iter 2/28 - loss 0.34794152 - samples/sec: 69.59 - lr: 0.000008
2021-06-22 10:02:52,033 epoch 24 - iter 4/28 - loss 0.36317036 - samples/sec: 67.15 - lr: 0.000008
2021-06-22 10:02:52,978 epoch 24 - iter 6/28 - loss 0.35510605 - samples/sec: 67.78 - lr: 0.000008
2021-06-22 10:02:53,938 epoch 24 - iter 8/28 - loss 0.32581333 - samples/sec: 66.74 - lr: 0.000008
2021-06-22 10:02:54,889 epoch 24 - iter 10/28 - loss 0.30356505 - samples/sec: 67.33 - lr: 0.000008
2021-06-22 10:02:55,826 epoch 24 - iter 12/28 - loss 0.29701636 - samples/sec: 68.31 - lr: 0.000008
2021-06-22 10:02:56,762 epoch 24 - iter 14/28 - loss 0.28381719 - samples/sec: 68.43 - lr: 0.000008
2021-06-22 10:02:57,715 epoch 24 - iter 16/28 - loss 0.26529802 - samples/sec: 67.16 - lr: 0.000008
2021-06-22 10:02:58,666 epoch 24 - iter 18/28 - loss 0.27299077 - samples/sec: 67.35 - lr: 0.000008
2021-06-22 10:02:59,611 epoch 24 - iter 20/28 - loss 0.28283330 - samples/sec: 67.74 - lr: 0.000008
2021-06-22 10:03:00,573 epoch 24 - iter 22/28 - loss 0.28146206 - samples/sec: 66.61 - lr: 0.000008
2021-06-22 10:03:01,505 epoch 24 - iter 24/28 - loss 0.29997675 - samples/sec: 68.66 - lr: 0.000008
2021-06-22 10:03:02,454 epoch 24 - iter 26/28 - loss 0.29444436 - samples/sec: 67.48 - lr: 0.000008
2021-06-22 10:03:02,973 epoch 24 - iter 28/28 - loss 0.29563710 - samples/sec: 123.52 - lr: 0.000008
2021-06-22 10:03:02,973 ----------------------------------------------------------------------------------------------------
2021-06-22 10:03:02,973 EPOCH 24 done: loss 0.2956 - lr 0.0000075
2021-06-22 10:03:03,926 DEV : loss 0.5337551236152649 - score 0.9275
2021-06-22 10:03:03,939 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:03:09,459 ----------------------------------------------------------------------------------------------------
2021-06-22 10:03:10,394 epoch 25 - iter 2/28 - loss 0.28141829 - samples/sec: 68.53 - lr: 0.000008
2021-06-22 10:03:11,350 epoch 25 - iter 4/28 - loss 0.28553949 - samples/sec: 66.95 - lr: 0.000008
2021-06-22 10:03:12,293 epoch 25 - iter 6/28 - loss 0.34149585 - samples/sec: 67.90 - lr: 0.000008
2021-06-22 10:03:13,235 epoch 25 - iter 8/28 - loss 0.31014492 - samples/sec: 67.99 - lr: 0.000008
2021-06-22 10:03:14,158 epoch 25 - iter 10/28 - loss 0.29645505 - samples/sec: 69.41 - lr: 0.000008
2021-06-22 10:03:15,096 epoch 25 - iter 12/28 - loss 0.30214658 - samples/sec: 68.27 - lr: 0.000008
2021-06-22 10:03:16,056 epoch 25 - iter 14/28 - loss 0.28407933 - samples/sec: 66.65 - lr: 0.000008
2021-06-22 10:03:16,999 epoch 25 - iter 16/28 - loss 0.28355349 - samples/sec: 67.91 - lr: 0.000008
2021-06-22 10:03:17,947 epoch 25 - iter 18/28 - loss 0.27859020 - samples/sec: 67.56 - lr: 0.000008
2021-06-22 10:03:18,908 epoch 25 - iter 20/28 - loss 0.29087487 - samples/sec: 66.66 - lr: 0.000008
2021-06-22 10:03:19,863 epoch 25 - iter 22/28 - loss 0.30275568 - samples/sec: 67.07 - lr: 0.000008
2021-06-22 10:03:20,821 epoch 25 - iter 24/28 - loss 0.29856954 - samples/sec: 66.83 - lr: 0.000008
2021-06-22 10:03:21,752 epoch 25 - iter 26/28 - loss 0.29241232 - samples/sec: 68.79 - lr: 0.000008
2021-06-22 10:03:22,297 epoch 25 - iter 28/28 - loss 0.28486275 - samples/sec: 117.56 - lr: 0.000008
2021-06-22 10:03:22,297 ----------------------------------------------------------------------------------------------------
2021-06-22 10:03:22,297 EPOCH 25 done: loss 0.2849 - lr 0.0000075
2021-06-22 10:03:23,258 DEV : loss 0.5173656344413757 - score 0.929
2021-06-22 10:03:23,272 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:03:28,711 ----------------------------------------------------------------------------------------------------
2021-06-22 10:03:29,650 epoch 26 - iter 2/28 - loss 0.21532948 - samples/sec: 68.22 - lr: 0.000008
2021-06-22 10:03:30,581 epoch 26 - iter 4/28 - loss 0.20426745 - samples/sec: 68.80 - lr: 0.000008
2021-06-22 10:03:31,523 epoch 26 - iter 6/28 - loss 0.26421333 - samples/sec: 68.01 - lr: 0.000008
2021-06-22 10:03:32,476 epoch 26 - iter 8/28 - loss 0.29148966 - samples/sec: 67.17 - lr: 0.000008
2021-06-22 10:03:33,457 epoch 26 - iter 10/28 - loss 0.29261967 - samples/sec: 65.24 - lr: 0.000008
2021-06-22 10:03:34,425 epoch 26 - iter 12/28 - loss 0.30147837 - samples/sec: 66.18 - lr: 0.000008
2021-06-22 10:03:35,404 epoch 26 - iter 14/28 - loss 0.28968238 - samples/sec: 65.41 - lr: 0.000008
2021-06-22 10:03:36,382 epoch 26 - iter 16/28 - loss 0.28324322 - samples/sec: 65.46 - lr: 0.000008
2021-06-22 10:03:37,331 epoch 26 - iter 18/28 - loss 0.30188754 - samples/sec: 67.47 - lr: 0.000008
2021-06-22 10:03:38,300 epoch 26 - iter 20/28 - loss 0.30531318 - samples/sec: 66.10 - lr: 0.000008
2021-06-22 10:03:39,255 epoch 26 - iter 22/28 - loss 0.29508582 - samples/sec: 67.08 - lr: 0.000008
2021-06-22 10:03:40,212 epoch 26 - iter 24/28 - loss 0.29267034 - samples/sec: 66.91 - lr: 0.000008
2021-06-22 10:03:41,180 epoch 26 - iter 26/28 - loss 0.28766902 - samples/sec: 66.12 - lr: 0.000008
2021-06-22 10:03:41,739 epoch 26 - iter 28/28 - loss 0.30188754 - samples/sec: 114.65 - lr: 0.000008
2021-06-22 10:03:41,739 ----------------------------------------------------------------------------------------------------
2021-06-22 10:03:41,739 EPOCH 26 done: loss 0.3019 - lr 0.0000075
2021-06-22 10:03:42,816 DEV : loss 0.5458593964576721 - score 0.9254
2021-06-22 10:03:42,830 BAD EPOCHS (no improvement): 1
2021-06-22 10:03:42,830 ----------------------------------------------------------------------------------------------------
2021-06-22 10:03:43,786 epoch 27 - iter 2/28 - loss 0.12273166 - samples/sec: 66.96 - lr: 0.000008
2021-06-22 10:03:44,766 epoch 27 - iter 4/28 - loss 0.16159835 - samples/sec: 65.40 - lr: 0.000008
2021-06-22 10:03:45,740 epoch 27 - iter 6/28 - loss 0.20409981 - samples/sec: 65.72 - lr: 0.000008
2021-06-22 10:03:46,675 epoch 27 - iter 8/28 - loss 0.21635261 - samples/sec: 68.51 - lr: 0.000008
2021-06-22 10:03:47,639 epoch 27 - iter 10/28 - loss 0.26833269 - samples/sec: 66.38 - lr: 0.000008
2021-06-22 10:03:48,603 epoch 27 - iter 12/28 - loss 0.25915462 - samples/sec: 66.48 - lr: 0.000008
2021-06-22 10:03:49,557 epoch 27 - iter 14/28 - loss 0.26819873 - samples/sec: 67.07 - lr: 0.000008
2021-06-22 10:03:50,529 epoch 27 - iter 16/28 - loss 0.26540300 - samples/sec: 65.89 - lr: 0.000008
2021-06-22 10:03:51,484 epoch 27 - iter 18/28 - loss 0.26993945 - samples/sec: 67.07 - lr: 0.000008
2021-06-22 10:03:52,434 epoch 27 - iter 20/28 - loss 0.27671913 - samples/sec: 67.40 - lr: 0.000008
2021-06-22 10:03:53,406 epoch 27 - iter 22/28 - loss 0.28368534 - samples/sec: 65.91 - lr: 0.000008
2021-06-22 10:03:54,353 epoch 27 - iter 24/28 - loss 0.28673750 - samples/sec: 67.58 - lr: 0.000008
2021-06-22 10:03:55,313 epoch 27 - iter 26/28 - loss 0.29059083 - samples/sec: 66.71 - lr: 0.000008
2021-06-22 10:03:55,864 epoch 27 - iter 28/28 - loss 0.27723630 - samples/sec: 116.35 - lr: 0.000008
2021-06-22 10:03:55,864 ----------------------------------------------------------------------------------------------------
2021-06-22 10:03:55,864 EPOCH 27 done: loss 0.2772 - lr 0.0000075
2021-06-22 10:03:56,820 DEV : loss 0.5393804907798767 - score 0.9254
2021-06-22 10:03:56,834 BAD EPOCHS (no improvement): 2
2021-06-22 10:03:56,834 ----------------------------------------------------------------------------------------------------
2021-06-22 10:03:57,791 epoch 28 - iter 2/28 - loss 0.30797859 - samples/sec: 66.90 - lr: 0.000008
2021-06-22 10:03:58,771 epoch 28 - iter 4/28 - loss 0.23277245 - samples/sec: 65.36 - lr: 0.000008
2021-06-22 10:03:59,724 epoch 28 - iter 6/28 - loss 0.23438924 - samples/sec: 67.16 - lr: 0.000008
2021-06-22 10:04:00,677 epoch 28 - iter 8/28 - loss 0.23578132 - samples/sec: 67.18 - lr: 0.000008
2021-06-22 10:04:01,649 epoch 28 - iter 10/28 - loss 0.24457763 - samples/sec: 65.91 - lr: 0.000008
2021-06-22 10:04:02,623 epoch 28 - iter 12/28 - loss 0.27309919 - samples/sec: 65.75 - lr: 0.000008
2021-06-22 10:04:03,591 epoch 28 - iter 14/28 - loss 0.26602879 - samples/sec: 66.12 - lr: 0.000008
2021-06-22 10:04:04,557 epoch 28 - iter 16/28 - loss 0.26222888 - samples/sec: 66.32 - lr: 0.000008
2021-06-22 10:04:05,537 epoch 28 - iter 18/28 - loss 0.26374343 - samples/sec: 65.29 - lr: 0.000008
2021-06-22 10:04:06,498 epoch 28 - iter 20/28 - loss 0.25425970 - samples/sec: 66.67 - lr: 0.000008
2021-06-22 10:04:07,444 epoch 28 - iter 22/28 - loss 0.25366292 - samples/sec: 67.65 - lr: 0.000008
2021-06-22 10:04:08,416 epoch 28 - iter 24/28 - loss 0.25424044 - samples/sec: 65.91 - lr: 0.000008
2021-06-22 10:04:09,390 epoch 28 - iter 26/28 - loss 0.24919614 - samples/sec: 65.76 - lr: 0.000008
2021-06-22 10:04:09,904 epoch 28 - iter 28/28 - loss 0.23694868 - samples/sec: 124.64 - lr: 0.000008
2021-06-22 10:04:09,904 ----------------------------------------------------------------------------------------------------
2021-06-22 10:04:09,904 EPOCH 28 done: loss 0.2369 - lr 0.0000075
2021-06-22 10:04:10,862 DEV : loss 0.5385936498641968 - score 0.9275
2021-06-22 10:04:10,876 BAD EPOCHS (no improvement): 3
2021-06-22 10:04:10,876 ----------------------------------------------------------------------------------------------------
2021-06-22 10:04:11,827 epoch 29 - iter 2/28 - loss 0.12993607 - samples/sec: 67.34 - lr: 0.000008
2021-06-22 10:04:12,818 epoch 29 - iter 4/28 - loss 0.19596218 - samples/sec: 64.58 - lr: 0.000008
2021-06-22 10:04:13,764 epoch 29 - iter 6/28 - loss 0.23059600 - samples/sec: 67.74 - lr: 0.000008
2021-06-22 10:04:14,719 epoch 29 - iter 8/28 - loss 0.22853698 - samples/sec: 67.03 - lr: 0.000008
2021-06-22 10:04:15,678 epoch 29 - iter 10/28 - loss 0.25512561 - samples/sec: 66.73 - lr: 0.000008
2021-06-22 10:04:16,642 epoch 29 - iter 12/28 - loss 0.24037513 - samples/sec: 66.48 - lr: 0.000008
2021-06-22 10:04:17,624 epoch 29 - iter 14/28 - loss 0.24579909 - samples/sec: 65.22 - lr: 0.000008
2021-06-22 10:04:18,603 epoch 29 - iter 16/28 - loss 0.27302033 - samples/sec: 65.38 - lr: 0.000008
2021-06-22 10:04:19,542 epoch 29 - iter 18/28 - loss 0.28694185 - samples/sec: 68.19 - lr: 0.000008
2021-06-22 10:04:20,515 epoch 29 - iter 20/28 - loss 0.27209652 - samples/sec: 65.81 - lr: 0.000008
2021-06-22 10:04:21,487 epoch 29 - iter 22/28 - loss 0.27000906 - samples/sec: 65.84 - lr: 0.000008
2021-06-22 10:04:22,454 epoch 29 - iter 24/28 - loss 0.26066530 - samples/sec: 66.28 - lr: 0.000008
2021-06-22 10:04:23,405 epoch 29 - iter 26/28 - loss 0.25509051 - samples/sec: 67.30 - lr: 0.000008
2021-06-22 10:04:23,940 epoch 29 - iter 28/28 - loss 0.24708311 - samples/sec: 119.68 - lr: 0.000008
2021-06-22 10:04:23,941 ----------------------------------------------------------------------------------------------------
2021-06-22 10:04:23,941 EPOCH 29 done: loss 0.2471 - lr 0.0000075
2021-06-22 10:04:24,901 DEV : loss 0.5107324719429016 - score 0.9308
2021-06-22 10:04:24,915 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:04:30,357 ----------------------------------------------------------------------------------------------------
2021-06-22 10:04:31,298 epoch 30 - iter 2/28 - loss 0.17874271 - samples/sec: 68.06 - lr: 0.000008
2021-06-22 10:04:32,249 epoch 30 - iter 4/28 - loss 0.24302539 - samples/sec: 67.35 - lr: 0.000008
2021-06-22 10:04:33,214 epoch 30 - iter 6/28 - loss 0.24639510 - samples/sec: 66.34 - lr: 0.000008
2021-06-22 10:04:34,191 epoch 30 - iter 8/28 - loss 0.26328607 - samples/sec: 65.51 - lr: 0.000008
2021-06-22 10:04:35,168 epoch 30 - iter 10/28 - loss 0.26277783 - samples/sec: 65.58 - lr: 0.000008
2021-06-22 10:04:36,105 epoch 30 - iter 12/28 - loss 0.28243727 - samples/sec: 68.30 - lr: 0.000008
2021-06-22 10:04:37,071 epoch 30 - iter 14/28 - loss 0.26603808 - samples/sec: 66.33 - lr: 0.000008
2021-06-22 10:04:38,034 epoch 30 - iter 16/28 - loss 0.26453550 - samples/sec: 66.47 - lr: 0.000008
2021-06-22 10:04:38,991 epoch 30 - iter 18/28 - loss 0.27844049 - samples/sec: 66.92 - lr: 0.000008
2021-06-22 10:04:39,952 epoch 30 - iter 20/28 - loss 0.26570596 - samples/sec: 66.66 - lr: 0.000008
2021-06-22 10:04:40,924 epoch 30 - iter 22/28 - loss 0.27135158 - samples/sec: 65.83 - lr: 0.000008
2021-06-22 10:04:41,898 epoch 30 - iter 24/28 - loss 0.26599725 - samples/sec: 65.77 - lr: 0.000008
2021-06-22 10:04:42,869 epoch 30 - iter 26/28 - loss 0.26064233 - samples/sec: 65.93 - lr: 0.000008
2021-06-22 10:04:43,421 epoch 30 - iter 28/28 - loss 0.25210148 - samples/sec: 116.14 - lr: 0.000008
2021-06-22 10:04:43,421 ----------------------------------------------------------------------------------------------------
2021-06-22 10:04:43,421 EPOCH 30 done: loss 0.2521 - lr 0.0000075
2021-06-22 10:04:44,376 DEV : loss 0.5180288553237915 - score 0.9308
2021-06-22 10:04:44,390 BAD EPOCHS (no improvement): 1
2021-06-22 10:04:44,390 ----------------------------------------------------------------------------------------------------
2021-06-22 10:04:45,350 epoch 31 - iter 2/28 - loss 0.41001588 - samples/sec: 66.67 - lr: 0.000008
2021-06-22 10:04:46,315 epoch 31 - iter 4/28 - loss 0.29086757 - samples/sec: 66.36 - lr: 0.000008
2021-06-22 10:04:47,411 epoch 31 - iter 6/28 - loss 0.26081938 - samples/sec: 58.42 - lr: 0.000008
2021-06-22 10:04:48,362 epoch 31 - iter 8/28 - loss 0.23359044 - samples/sec: 67.32 - lr: 0.000008
2021-06-22 10:04:49,307 epoch 31 - iter 10/28 - loss 0.24784756 - samples/sec: 67.79 - lr: 0.000008
2021-06-22 10:04:50,288 epoch 31 - iter 12/28 - loss 0.24113510 - samples/sec: 65.29 - lr: 0.000008
2021-06-22 10:04:51,251 epoch 31 - iter 14/28 - loss 0.24489610 - samples/sec: 66.51 - lr: 0.000008
2021-06-22 10:04:52,200 epoch 31 - iter 16/28 - loss 0.25223295 - samples/sec: 67.46 - lr: 0.000008
2021-06-22 10:04:53,177 epoch 31 - iter 18/28 - loss 0.24618723 - samples/sec: 65.55 - lr: 0.000008
2021-06-22 10:04:54,139 epoch 31 - iter 20/28 - loss 0.25192525 - samples/sec: 66.56 - lr: 0.000008
2021-06-22 10:04:55,108 epoch 31 - iter 22/28 - loss 0.25486952 - samples/sec: 66.06 - lr: 0.000008
2021-06-22 10:04:56,090 epoch 31 - iter 24/28 - loss 0.25311809 - samples/sec: 65.21 - lr: 0.000008
2021-06-22 10:04:57,072 epoch 31 - iter 26/28 - loss 0.24843422 - samples/sec: 65.23 - lr: 0.000008
2021-06-22 10:04:57,580 epoch 31 - iter 28/28 - loss 0.24492309 - samples/sec: 126.15 - lr: 0.000008
2021-06-22 10:04:57,580 ----------------------------------------------------------------------------------------------------
2021-06-22 10:04:57,580 EPOCH 31 done: loss 0.2449 - lr 0.0000075
2021-06-22 10:04:58,539 DEV : loss 0.5071240663528442 - score 0.9308
2021-06-22 10:04:58,553 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:05:04,100 ----------------------------------------------------------------------------------------------------
2021-06-22 10:05:05,057 epoch 32 - iter 2/28 - loss 0.26660511 - samples/sec: 66.87 - lr: 0.000008
2021-06-22 10:05:06,012 epoch 32 - iter 4/28 - loss 0.24685819 - samples/sec: 67.12 - lr: 0.000008
2021-06-22 10:05:06,975 epoch 32 - iter 6/28 - loss 0.25813032 - samples/sec: 66.47 - lr: 0.000008
2021-06-22 10:05:07,933 epoch 32 - iter 8/28 - loss 0.25232393 - samples/sec: 66.81 - lr: 0.000008
2021-06-22 10:05:08,883 epoch 32 - iter 10/28 - loss 0.23497438 - samples/sec: 67.41 - lr: 0.000008
2021-06-22 10:05:09,851 epoch 32 - iter 12/28 - loss 0.24211049 - samples/sec: 66.16 - lr: 0.000008
2021-06-22 10:05:10,825 epoch 32 - iter 14/28 - loss 0.23297959 - samples/sec: 65.77 - lr: 0.000008
2021-06-22 10:05:11,780 epoch 32 - iter 16/28 - loss 0.22204084 - samples/sec: 67.03 - lr: 0.000008
2021-06-22 10:05:12,731 epoch 32 - iter 18/28 - loss 0.21459967 - samples/sec: 67.31 - lr: 0.000008
2021-06-22 10:05:13,686 epoch 32 - iter 20/28 - loss 0.22714709 - samples/sec: 67.09 - lr: 0.000008
2021-06-22 10:05:14,666 epoch 32 - iter 22/28 - loss 0.22705736 - samples/sec: 65.30 - lr: 0.000008
2021-06-22 10:05:15,618 epoch 32 - iter 24/28 - loss 0.22893993 - samples/sec: 67.31 - lr: 0.000008
2021-06-22 10:05:16,583 epoch 32 - iter 26/28 - loss 0.22456955 - samples/sec: 66.38 - lr: 0.000008
2021-06-22 10:05:17,132 epoch 32 - iter 28/28 - loss 0.22554825 - samples/sec: 116.67 - lr: 0.000008
2021-06-22 10:05:17,132 ----------------------------------------------------------------------------------------------------
2021-06-22 10:05:17,132 EPOCH 32 done: loss 0.2255 - lr 0.0000075
2021-06-22 10:05:18,084 DEV : loss 0.515938401222229 - score 0.929
2021-06-22 10:05:18,098 BAD EPOCHS (no improvement): 1
2021-06-22 10:05:18,098 ----------------------------------------------------------------------------------------------------
2021-06-22 10:05:19,064 epoch 33 - iter 2/28 - loss 0.25233424 - samples/sec: 66.29 - lr: 0.000008
2021-06-22 10:05:20,034 epoch 33 - iter 4/28 - loss 0.31444216 - samples/sec: 66.02 - lr: 0.000008
2021-06-22 10:05:20,991 epoch 33 - iter 6/28 - loss 0.27687694 - samples/sec: 66.88 - lr: 0.000008
2021-06-22 10:05:21,919 epoch 33 - iter 8/28 - loss 0.26791780 - samples/sec: 69.02 - lr: 0.000008
2021-06-22 10:05:22,859 epoch 33 - iter 10/28 - loss 0.25960395 - samples/sec: 68.10 - lr: 0.000008
2021-06-22 10:05:23,814 epoch 33 - iter 12/28 - loss 0.25686397 - samples/sec: 67.05 - lr: 0.000008
2021-06-22 10:05:24,784 epoch 33 - iter 14/28 - loss 0.24327992 - samples/sec: 66.04 - lr: 0.000008
2021-06-22 10:05:25,750 epoch 33 - iter 16/28 - loss 0.23863950 - samples/sec: 66.26 - lr: 0.000008
2021-06-22 10:05:26,702 epoch 33 - iter 18/28 - loss 0.24181275 - samples/sec: 67.27 - lr: 0.000008
2021-06-22 10:05:27,666 epoch 33 - iter 20/28 - loss 0.23451059 - samples/sec: 66.44 - lr: 0.000008
2021-06-22 10:05:28,637 epoch 33 - iter 22/28 - loss 0.23423811 - samples/sec: 65.96 - lr: 0.000008
2021-06-22 10:05:29,604 epoch 33 - iter 24/28 - loss 0.22664425 - samples/sec: 66.24 - lr: 0.000008
2021-06-22 10:05:30,551 epoch 33 - iter 26/28 - loss 0.22500027 - samples/sec: 67.58 - lr: 0.000008
2021-06-22 10:05:31,101 epoch 33 - iter 28/28 - loss 0.22326768 - samples/sec: 116.63 - lr: 0.000008
2021-06-22 10:05:31,101 ----------------------------------------------------------------------------------------------------
2021-06-22 10:05:31,101 EPOCH 33 done: loss 0.2233 - lr 0.0000075
2021-06-22 10:05:32,063 DEV : loss 0.5274301767349243 - score 0.929
2021-06-22 10:05:32,077 BAD EPOCHS (no improvement): 2
2021-06-22 10:05:32,077 ----------------------------------------------------------------------------------------------------
2021-06-22 10:05:33,033 epoch 34 - iter 2/28 - loss 0.17689563 - samples/sec: 67.02 - lr: 0.000008
2021-06-22 10:05:34,021 epoch 34 - iter 4/28 - loss 0.14260728 - samples/sec: 64.82 - lr: 0.000008
2021-06-22 10:05:34,972 epoch 34 - iter 6/28 - loss 0.17644374 - samples/sec: 67.32 - lr: 0.000008
2021-06-22 10:05:35,946 epoch 34 - iter 8/28 - loss 0.18879806 - samples/sec: 65.76 - lr: 0.000008
2021-06-22 10:05:36,897 epoch 34 - iter 10/28 - loss 0.21127555 - samples/sec: 67.29 - lr: 0.000008
2021-06-22 10:05:37,823 epoch 34 - iter 12/28 - loss 0.20972083 - samples/sec: 69.20 - lr: 0.000008
2021-06-22 10:05:38,782 epoch 34 - iter 14/28 - loss 0.20643231 - samples/sec: 66.76 - lr: 0.000008
2021-06-22 10:05:39,751 epoch 34 - iter 16/28 - loss 0.21038331 - samples/sec: 66.08 - lr: 0.000008
2021-06-22 10:05:40,694 epoch 34 - iter 18/28 - loss 0.21003700 - samples/sec: 67.90 - lr: 0.000008
2021-06-22 10:05:41,652 epoch 34 - iter 20/28 - loss 0.20823093 - samples/sec: 66.86 - lr: 0.000008
2021-06-22 10:05:42,629 epoch 34 - iter 22/28 - loss 0.21908493 - samples/sec: 65.55 - lr: 0.000008
2021-06-22 10:05:43,558 epoch 34 - iter 24/28 - loss 0.21591273 - samples/sec: 68.91 - lr: 0.000008
2021-06-22 10:05:44,522 epoch 34 - iter 26/28 - loss 0.22245704 - samples/sec: 66.44 - lr: 0.000008
2021-06-22 10:05:45,076 epoch 34 - iter 28/28 - loss 0.21497424 - samples/sec: 115.58 - lr: 0.000008
2021-06-22 10:05:45,076 ----------------------------------------------------------------------------------------------------
2021-06-22 10:05:45,076 EPOCH 34 done: loss 0.2150 - lr 0.0000075
2021-06-22 10:05:46,036 DEV : loss 0.5474655628204346 - score 0.9254
2021-06-22 10:05:46,050 BAD EPOCHS (no improvement): 3
2021-06-22 10:05:46,050 ----------------------------------------------------------------------------------------------------
2021-06-22 10:05:47,004 epoch 35 - iter 2/28 - loss 0.21108334 - samples/sec: 67.12 - lr: 0.000008
2021-06-22 10:05:47,951 epoch 35 - iter 4/28 - loss 0.20375112 - samples/sec: 67.58 - lr: 0.000008
2021-06-22 10:05:48,880 epoch 35 - iter 6/28 - loss 0.20464095 - samples/sec: 68.93 - lr: 0.000008
2021-06-22 10:05:49,842 epoch 35 - iter 8/28 - loss 0.18283492 - samples/sec: 66.61 - lr: 0.000008
2021-06-22 10:05:50,796 epoch 35 - iter 10/28 - loss 0.21498440 - samples/sec: 67.12 - lr: 0.000008
2021-06-22 10:05:51,762 epoch 35 - iter 12/28 - loss 0.20923142 - samples/sec: 66.26 - lr: 0.000008
2021-06-22 10:05:52,745 epoch 35 - iter 14/28 - loss 0.21234654 - samples/sec: 65.13 - lr: 0.000008
2021-06-22 10:05:53,712 epoch 35 - iter 16/28 - loss 0.22279691 - samples/sec: 66.24 - lr: 0.000008
2021-06-22 10:05:54,684 epoch 35 - iter 18/28 - loss 0.23108256 - samples/sec: 65.90 - lr: 0.000008
2021-06-22 10:05:55,628 epoch 35 - iter 20/28 - loss 0.23151242 - samples/sec: 67.81 - lr: 0.000008
2021-06-22 10:05:56,603 epoch 35 - iter 22/28 - loss 0.22626637 - samples/sec: 65.72 - lr: 0.000008
2021-06-22 10:05:57,574 epoch 35 - iter 24/28 - loss 0.22409436 - samples/sec: 65.90 - lr: 0.000008
2021-06-22 10:05:58,525 epoch 35 - iter 26/28 - loss 0.23989334 - samples/sec: 67.34 - lr: 0.000008
2021-06-22 10:05:59,070 epoch 35 - iter 28/28 - loss 0.25346490 - samples/sec: 117.70 - lr: 0.000008
2021-06-22 10:05:59,070 ----------------------------------------------------------------------------------------------------
2021-06-22 10:05:59,070 EPOCH 35 done: loss 0.2535 - lr 0.0000075
2021-06-22 10:06:00,030 DEV : loss 0.5637058019638062 - score 0.9298
Epoch    35: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 10:06:00,044 BAD EPOCHS (no improvement): 4
2021-06-22 10:06:00,044 ----------------------------------------------------------------------------------------------------
2021-06-22 10:06:01,110 epoch 36 - iter 2/28 - loss 0.19306867 - samples/sec: 60.07 - lr: 0.000004
2021-06-22 10:06:02,071 epoch 36 - iter 4/28 - loss 0.23047296 - samples/sec: 66.59 - lr: 0.000004
2021-06-22 10:06:03,038 epoch 36 - iter 6/28 - loss 0.22549387 - samples/sec: 66.22 - lr: 0.000004
2021-06-22 10:06:04,004 epoch 36 - iter 8/28 - loss 0.21650504 - samples/sec: 66.33 - lr: 0.000004
2021-06-22 10:06:04,954 epoch 36 - iter 10/28 - loss 0.23919414 - samples/sec: 67.40 - lr: 0.000004
2021-06-22 10:06:05,930 epoch 36 - iter 12/28 - loss 0.24398552 - samples/sec: 65.56 - lr: 0.000004
2021-06-22 10:06:06,895 epoch 36 - iter 14/28 - loss 0.23634471 - samples/sec: 66.41 - lr: 0.000004
2021-06-22 10:06:07,872 epoch 36 - iter 16/28 - loss 0.25182337 - samples/sec: 65.50 - lr: 0.000004
2021-06-22 10:06:08,815 epoch 36 - iter 18/28 - loss 0.24716753 - samples/sec: 67.94 - lr: 0.000004
2021-06-22 10:06:09,766 epoch 36 - iter 20/28 - loss 0.23562128 - samples/sec: 67.34 - lr: 0.000004
2021-06-22 10:06:10,736 epoch 36 - iter 22/28 - loss 0.23574502 - samples/sec: 66.00 - lr: 0.000004
2021-06-22 10:06:11,698 epoch 36 - iter 24/28 - loss 0.23605755 - samples/sec: 66.57 - lr: 0.000004
2021-06-22 10:06:12,639 epoch 36 - iter 26/28 - loss 0.23844050 - samples/sec: 68.05 - lr: 0.000004
2021-06-22 10:06:13,176 epoch 36 - iter 28/28 - loss 0.22841436 - samples/sec: 119.33 - lr: 0.000004
2021-06-22 10:06:13,176 ----------------------------------------------------------------------------------------------------
2021-06-22 10:06:13,176 EPOCH 36 done: loss 0.2284 - lr 0.0000038
2021-06-22 10:06:14,135 DEV : loss 0.5227028727531433 - score 0.9308
2021-06-22 10:06:14,149 BAD EPOCHS (no improvement): 1
2021-06-22 10:06:14,149 ----------------------------------------------------------------------------------------------------
2021-06-22 10:06:15,114 epoch 37 - iter 2/28 - loss 0.39123428 - samples/sec: 66.35 - lr: 0.000004
2021-06-22 10:06:16,071 epoch 37 - iter 4/28 - loss 0.33438377 - samples/sec: 66.90 - lr: 0.000004
2021-06-22 10:06:17,049 epoch 37 - iter 6/28 - loss 0.31451834 - samples/sec: 65.48 - lr: 0.000004
2021-06-22 10:06:18,007 epoch 37 - iter 8/28 - loss 0.28593751 - samples/sec: 66.85 - lr: 0.000004
2021-06-22 10:06:18,956 epoch 37 - iter 10/28 - loss 0.27064366 - samples/sec: 67.46 - lr: 0.000004
2021-06-22 10:06:19,918 epoch 37 - iter 12/28 - loss 0.25685726 - samples/sec: 66.55 - lr: 0.000004
2021-06-22 10:06:20,847 epoch 37 - iter 14/28 - loss 0.25255990 - samples/sec: 68.98 - lr: 0.000004
2021-06-22 10:06:21,796 epoch 37 - iter 16/28 - loss 0.23994747 - samples/sec: 67.45 - lr: 0.000004
2021-06-22 10:06:22,752 epoch 37 - iter 18/28 - loss 0.22969937 - samples/sec: 66.97 - lr: 0.000004
2021-06-22 10:06:23,729 epoch 37 - iter 20/28 - loss 0.22143288 - samples/sec: 65.55 - lr: 0.000004
2021-06-22 10:06:24,703 epoch 37 - iter 22/28 - loss 0.21984124 - samples/sec: 65.79 - lr: 0.000004
2021-06-22 10:06:25,669 epoch 37 - iter 24/28 - loss 0.21968346 - samples/sec: 66.29 - lr: 0.000004
2021-06-22 10:06:26,621 epoch 37 - iter 26/28 - loss 0.22275390 - samples/sec: 67.24 - lr: 0.000004
2021-06-22 10:06:27,170 epoch 37 - iter 28/28 - loss 0.21953999 - samples/sec: 116.78 - lr: 0.000004
2021-06-22 10:06:27,170 ----------------------------------------------------------------------------------------------------
2021-06-22 10:06:27,170 EPOCH 37 done: loss 0.2195 - lr 0.0000038
2021-06-22 10:06:28,128 DEV : loss 0.5243309140205383 - score 0.9308
2021-06-22 10:06:28,142 BAD EPOCHS (no improvement): 2
2021-06-22 10:06:28,143 ----------------------------------------------------------------------------------------------------
2021-06-22 10:06:29,100 epoch 38 - iter 2/28 - loss 0.16558671 - samples/sec: 66.86 - lr: 0.000004
2021-06-22 10:06:30,030 epoch 38 - iter 4/28 - loss 0.24231904 - samples/sec: 68.90 - lr: 0.000004
2021-06-22 10:06:30,987 epoch 38 - iter 6/28 - loss 0.29113090 - samples/sec: 66.88 - lr: 0.000004
2021-06-22 10:06:31,935 epoch 38 - iter 8/28 - loss 0.26948994 - samples/sec: 67.55 - lr: 0.000004
2021-06-22 10:06:32,890 epoch 38 - iter 10/28 - loss 0.25648369 - samples/sec: 67.02 - lr: 0.000004
2021-06-22 10:06:33,831 epoch 38 - iter 12/28 - loss 0.25574880 - samples/sec: 68.11 - lr: 0.000004
2021-06-22 10:06:34,786 epoch 38 - iter 14/28 - loss 0.23981517 - samples/sec: 67.01 - lr: 0.000004
2021-06-22 10:06:35,744 epoch 38 - iter 16/28 - loss 0.23405603 - samples/sec: 66.87 - lr: 0.000004
2021-06-22 10:06:36,694 epoch 38 - iter 18/28 - loss 0.22369908 - samples/sec: 67.40 - lr: 0.000004
2021-06-22 10:06:37,657 epoch 38 - iter 20/28 - loss 0.22533192 - samples/sec: 66.47 - lr: 0.000004
2021-06-22 10:06:38,596 epoch 38 - iter 22/28 - loss 0.22745589 - samples/sec: 68.21 - lr: 0.000004
2021-06-22 10:06:39,555 epoch 38 - iter 24/28 - loss 0.22724321 - samples/sec: 66.79 - lr: 0.000004
2021-06-22 10:06:40,531 epoch 38 - iter 26/28 - loss 0.22252205 - samples/sec: 65.56 - lr: 0.000004
2021-06-22 10:06:41,074 epoch 38 - iter 28/28 - loss 0.21944305 - samples/sec: 118.10 - lr: 0.000004
2021-06-22 10:06:41,074 ----------------------------------------------------------------------------------------------------
2021-06-22 10:06:41,074 EPOCH 38 done: loss 0.2194 - lr 0.0000038
2021-06-22 10:06:42,033 DEV : loss 0.5127161741256714 - score 0.9308
2021-06-22 10:06:42,047 BAD EPOCHS (no improvement): 3
2021-06-22 10:06:42,047 ----------------------------------------------------------------------------------------------------
2021-06-22 10:06:42,999 epoch 39 - iter 2/28 - loss 0.32874846 - samples/sec: 67.26 - lr: 0.000004
2021-06-22 10:06:43,946 epoch 39 - iter 4/28 - loss 0.30554923 - samples/sec: 67.66 - lr: 0.000004
2021-06-22 10:06:44,888 epoch 39 - iter 6/28 - loss 0.34871836 - samples/sec: 67.97 - lr: 0.000004
2021-06-22 10:06:45,860 epoch 39 - iter 8/28 - loss 0.32334205 - samples/sec: 65.85 - lr: 0.000004
2021-06-22 10:06:46,815 epoch 39 - iter 10/28 - loss 0.29455229 - samples/sec: 67.08 - lr: 0.000004
2021-06-22 10:06:47,776 epoch 39 - iter 12/28 - loss 0.27537305 - samples/sec: 66.62 - lr: 0.000004
2021-06-22 10:06:48,712 epoch 39 - iter 14/28 - loss 0.27585751 - samples/sec: 68.45 - lr: 0.000004
2021-06-22 10:06:49,685 epoch 39 - iter 16/28 - loss 0.25847116 - samples/sec: 65.81 - lr: 0.000004
2021-06-22 10:06:50,646 epoch 39 - iter 18/28 - loss 0.24185402 - samples/sec: 66.61 - lr: 0.000004
2021-06-22 10:06:51,612 epoch 39 - iter 20/28 - loss 0.23723509 - samples/sec: 66.25 - lr: 0.000004
2021-06-22 10:06:52,577 epoch 39 - iter 22/28 - loss 0.22948948 - samples/sec: 66.40 - lr: 0.000004
2021-06-22 10:06:53,522 epoch 39 - iter 24/28 - loss 0.22378602 - samples/sec: 67.78 - lr: 0.000004
2021-06-22 10:06:54,493 epoch 39 - iter 26/28 - loss 0.22350095 - samples/sec: 65.91 - lr: 0.000004
2021-06-22 10:06:55,049 epoch 39 - iter 28/28 - loss 0.21202478 - samples/sec: 115.19 - lr: 0.000004
2021-06-22 10:06:55,050 ----------------------------------------------------------------------------------------------------
2021-06-22 10:06:55,050 EPOCH 39 done: loss 0.2120 - lr 0.0000038
2021-06-22 10:06:56,007 DEV : loss 0.5059040784835815 - score 0.9308
2021-06-22 10:06:56,021 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:07:01,563 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:02,518 epoch 40 - iter 2/28 - loss 0.25481665 - samples/sec: 67.12 - lr: 0.000004
2021-06-22 10:07:03,605 epoch 40 - iter 4/28 - loss 0.19827148 - samples/sec: 58.89 - lr: 0.000004
2021-06-22 10:07:04,568 epoch 40 - iter 6/28 - loss 0.22740236 - samples/sec: 66.53 - lr: 0.000004
2021-06-22 10:07:05,503 epoch 40 - iter 8/28 - loss 0.21193736 - samples/sec: 68.46 - lr: 0.000004
2021-06-22 10:07:06,475 epoch 40 - iter 10/28 - loss 0.22729052 - samples/sec: 65.90 - lr: 0.000004
2021-06-22 10:07:07,441 epoch 40 - iter 12/28 - loss 0.22794998 - samples/sec: 66.28 - lr: 0.000004
2021-06-22 10:07:08,423 epoch 40 - iter 14/28 - loss 0.22823590 - samples/sec: 65.21 - lr: 0.000004
2021-06-22 10:07:09,365 epoch 40 - iter 16/28 - loss 0.21709070 - samples/sec: 67.96 - lr: 0.000004
2021-06-22 10:07:10,327 epoch 40 - iter 18/28 - loss 0.20709407 - samples/sec: 66.59 - lr: 0.000004
2021-06-22 10:07:11,275 epoch 40 - iter 20/28 - loss 0.20525947 - samples/sec: 67.55 - lr: 0.000004
2021-06-22 10:07:12,235 epoch 40 - iter 22/28 - loss 0.20113609 - samples/sec: 66.68 - lr: 0.000004
2021-06-22 10:07:13,206 epoch 40 - iter 24/28 - loss 0.20293217 - samples/sec: 65.94 - lr: 0.000004
2021-06-22 10:07:14,155 epoch 40 - iter 26/28 - loss 0.21236593 - samples/sec: 67.49 - lr: 0.000004
2021-06-22 10:07:14,699 epoch 40 - iter 28/28 - loss 0.20541794 - samples/sec: 117.77 - lr: 0.000004
2021-06-22 10:07:14,699 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:14,699 EPOCH 40 done: loss 0.2054 - lr 0.0000038
2021-06-22 10:07:15,658 DEV : loss 0.5179224014282227 - score 0.929
2021-06-22 10:07:15,672 BAD EPOCHS (no improvement): 1
2021-06-22 10:07:16,181 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:16,181 Testing using best model ...
2021-06-22 10:07:16,182 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/best-model.pt
2021-06-22 10:07:19,049 0.9331	0.9556	0.9442
2021-06-22 10:07:19,049 
Results:
- F1-score (micro) 0.9442
- F1-score (macro) 0.9442

By class:
SENT       tp: 237 - fp: 17 - fn: 11 - precision: 0.9331 - recall: 0.9556 - f1-score: 0.9442
2021-06-22 10:07:19,049 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/
2021-06-22 10:07:19,067 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn
2021-06-22 10:07:19,069 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/sent_train.txt
2021-06-22 10:07:19,069 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/sent_dev.txt
2021-06-22 10:07:19,069 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/sent_test.txt
Corpus: 2031 train + 282 dev + 164 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 10:07:35,348 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:35,349 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(29794, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 10:07:35,349 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:35,350 Corpus: "Corpus: 2031 train + 282 dev + 164 test sentences"
2021-06-22 10:07:35,350 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:35,350 Parameters:
2021-06-22 10:07:35,350  - learning_rate: "3e-05"
2021-06-22 10:07:35,350  - mini_batch_size: "32"
2021-06-22 10:07:35,350  - patience: "3"
2021-06-22 10:07:35,350  - anneal_factor: "0.5"
2021-06-22 10:07:35,350  - max_epochs: "40"
2021-06-22 10:07:35,350  - shuffle: "True"
2021-06-22 10:07:35,350  - train_with_dev: "False"
2021-06-22 10:07:35,350  - batch_growth_annealing: "False"
2021-06-22 10:07:35,350 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:35,350 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn"
2021-06-22 10:07:35,350 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:35,350 Device: cuda:0
2021-06-22 10:07:35,350 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:35,350 Embeddings storage mode: cpu
2021-06-22 10:07:35,351 ----------------------------------------------------------------------------------------------------
2021-06-22 10:07:41,030 epoch 1 - iter 6/64 - loss 20.76873191 - samples/sec: 33.81 - lr: 0.000030
2021-06-22 10:07:46,763 epoch 1 - iter 12/64 - loss 15.16547426 - samples/sec: 33.49 - lr: 0.000030
2021-06-22 10:07:52,455 epoch 1 - iter 18/64 - loss 11.74542907 - samples/sec: 33.74 - lr: 0.000030
2021-06-22 10:07:58,136 epoch 1 - iter 24/64 - loss 9.73114210 - samples/sec: 33.80 - lr: 0.000030
2021-06-22 10:08:03,849 epoch 1 - iter 30/64 - loss 8.53020282 - samples/sec: 33.61 - lr: 0.000030
2021-06-22 10:08:09,716 epoch 1 - iter 36/64 - loss 7.62721367 - samples/sec: 32.73 - lr: 0.000030
2021-06-22 10:08:15,422 epoch 1 - iter 42/64 - loss 6.90185475 - samples/sec: 33.65 - lr: 0.000030
2021-06-22 10:08:21,148 epoch 1 - iter 48/64 - loss 6.33491481 - samples/sec: 33.53 - lr: 0.000030
2021-06-22 10:08:26,799 epoch 1 - iter 54/64 - loss 5.82247893 - samples/sec: 33.98 - lr: 0.000030
2021-06-22 10:08:32,520 epoch 1 - iter 60/64 - loss 5.37818882 - samples/sec: 33.56 - lr: 0.000030
2021-06-22 10:08:35,821 ----------------------------------------------------------------------------------------------------
2021-06-22 10:08:35,822 EPOCH 1 done: loss 5.1288 - lr 0.0000300
2021-06-22 10:08:40,640 DEV : loss 0.944182276725769 - score 0.7021
2021-06-22 10:08:40,660 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:08:41,067 ----------------------------------------------------------------------------------------------------
2021-06-22 10:08:43,903 epoch 2 - iter 6/64 - loss 1.10130952 - samples/sec: 67.73 - lr: 0.000030
2021-06-22 10:08:46,791 epoch 2 - iter 12/64 - loss 1.02689677 - samples/sec: 66.48 - lr: 0.000030
2021-06-22 10:08:49,704 epoch 2 - iter 18/64 - loss 0.97555510 - samples/sec: 65.94 - lr: 0.000030
2021-06-22 10:08:52,536 epoch 2 - iter 24/64 - loss 0.94521758 - samples/sec: 67.80 - lr: 0.000030
2021-06-22 10:08:55,436 epoch 2 - iter 30/64 - loss 0.89253432 - samples/sec: 66.22 - lr: 0.000030
2021-06-22 10:08:58,342 epoch 2 - iter 36/64 - loss 0.87960347 - samples/sec: 66.10 - lr: 0.000030
2021-06-22 10:09:01,196 epoch 2 - iter 42/64 - loss 0.86329792 - samples/sec: 67.28 - lr: 0.000030
2021-06-22 10:09:04,081 epoch 2 - iter 48/64 - loss 0.84100258 - samples/sec: 66.57 - lr: 0.000030
2021-06-22 10:09:06,968 epoch 2 - iter 54/64 - loss 0.82234497 - samples/sec: 66.51 - lr: 0.000030
2021-06-22 10:09:09,836 epoch 2 - iter 60/64 - loss 0.81047694 - samples/sec: 66.97 - lr: 0.000030
2021-06-22 10:09:11,531 ----------------------------------------------------------------------------------------------------
2021-06-22 10:09:11,531 EPOCH 2 done: loss 0.7989 - lr 0.0000300
2021-06-22 10:09:12,974 DEV : loss 0.34789684414863586 - score 0.9437
2021-06-22 10:09:12,995 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:09:17,491 ----------------------------------------------------------------------------------------------------
2021-06-22 10:09:20,572 epoch 3 - iter 6/64 - loss 0.50405397 - samples/sec: 62.35 - lr: 0.000030
2021-06-22 10:09:23,421 epoch 3 - iter 12/64 - loss 0.53313919 - samples/sec: 67.40 - lr: 0.000030
2021-06-22 10:09:26,299 epoch 3 - iter 18/64 - loss 0.56481990 - samples/sec: 66.75 - lr: 0.000030
2021-06-22 10:09:29,208 epoch 3 - iter 24/64 - loss 0.57072258 - samples/sec: 66.02 - lr: 0.000030
2021-06-22 10:09:32,120 epoch 3 - iter 30/64 - loss 0.57943704 - samples/sec: 65.94 - lr: 0.000030
2021-06-22 10:09:35,000 epoch 3 - iter 36/64 - loss 0.57547542 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 10:09:37,877 epoch 3 - iter 42/64 - loss 0.57644426 - samples/sec: 66.76 - lr: 0.000030
2021-06-22 10:09:40,770 epoch 3 - iter 48/64 - loss 0.56008188 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 10:09:43,618 epoch 3 - iter 54/64 - loss 0.55201292 - samples/sec: 67.43 - lr: 0.000030
2021-06-22 10:09:46,542 epoch 3 - iter 60/64 - loss 0.55855488 - samples/sec: 65.68 - lr: 0.000030
2021-06-22 10:09:48,230 ----------------------------------------------------------------------------------------------------
2021-06-22 10:09:48,230 EPOCH 3 done: loss 0.5510 - lr 0.0000300
2021-06-22 10:09:49,672 DEV : loss 0.26192808151245117 - score 0.959
2021-06-22 10:09:49,693 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:09:54,189 ----------------------------------------------------------------------------------------------------
2021-06-22 10:09:57,088 epoch 4 - iter 6/64 - loss 0.39749176 - samples/sec: 66.25 - lr: 0.000030
2021-06-22 10:09:59,963 epoch 4 - iter 12/64 - loss 0.43803852 - samples/sec: 66.81 - lr: 0.000030
2021-06-22 10:10:02,812 epoch 4 - iter 18/64 - loss 0.45602100 - samples/sec: 67.40 - lr: 0.000030
2021-06-22 10:10:05,687 epoch 4 - iter 24/64 - loss 0.44646131 - samples/sec: 66.80 - lr: 0.000030
2021-06-22 10:10:08,538 epoch 4 - iter 30/64 - loss 0.45702385 - samples/sec: 67.36 - lr: 0.000030
2021-06-22 10:10:11,441 epoch 4 - iter 36/64 - loss 0.44192583 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 10:10:14,319 epoch 4 - iter 42/64 - loss 0.43431154 - samples/sec: 66.75 - lr: 0.000030
2021-06-22 10:10:17,205 epoch 4 - iter 48/64 - loss 0.43536625 - samples/sec: 66.53 - lr: 0.000030
2021-06-22 10:10:20,067 epoch 4 - iter 54/64 - loss 0.43720306 - samples/sec: 67.10 - lr: 0.000030
2021-06-22 10:10:22,922 epoch 4 - iter 60/64 - loss 0.42523253 - samples/sec: 67.28 - lr: 0.000030
2021-06-22 10:10:24,643 ----------------------------------------------------------------------------------------------------
2021-06-22 10:10:24,644 EPOCH 4 done: loss 0.4173 - lr 0.0000300
2021-06-22 10:10:26,083 DEV : loss 0.22003073990345 - score 0.9717
2021-06-22 10:10:26,104 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:10:30,607 ----------------------------------------------------------------------------------------------------
2021-06-22 10:10:33,500 epoch 5 - iter 6/64 - loss 0.40412136 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 10:10:36,385 epoch 5 - iter 12/64 - loss 0.34192492 - samples/sec: 66.57 - lr: 0.000030
2021-06-22 10:10:39,252 epoch 5 - iter 18/64 - loss 0.35430103 - samples/sec: 66.97 - lr: 0.000030
2021-06-22 10:10:42,125 epoch 5 - iter 24/64 - loss 0.33982223 - samples/sec: 66.85 - lr: 0.000030
2021-06-22 10:10:44,996 epoch 5 - iter 30/64 - loss 0.33678984 - samples/sec: 66.89 - lr: 0.000030
2021-06-22 10:10:47,875 epoch 5 - iter 36/64 - loss 0.34635958 - samples/sec: 66.71 - lr: 0.000030
2021-06-22 10:10:50,743 epoch 5 - iter 42/64 - loss 0.36380347 - samples/sec: 66.97 - lr: 0.000030
2021-06-22 10:10:53,622 epoch 5 - iter 48/64 - loss 0.35814924 - samples/sec: 66.70 - lr: 0.000030
2021-06-22 10:10:56,478 epoch 5 - iter 54/64 - loss 0.35879302 - samples/sec: 67.25 - lr: 0.000030
2021-06-22 10:10:59,385 epoch 5 - iter 60/64 - loss 0.35374548 - samples/sec: 66.06 - lr: 0.000030
2021-06-22 10:11:01,070 ----------------------------------------------------------------------------------------------------
2021-06-22 10:11:01,070 EPOCH 5 done: loss 0.3502 - lr 0.0000300
2021-06-22 10:11:02,509 DEV : loss 0.2003321349620819 - score 0.976
2021-06-22 10:11:02,529 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:11:07,101 ----------------------------------------------------------------------------------------------------
2021-06-22 10:11:09,993 epoch 6 - iter 6/64 - loss 0.30794558 - samples/sec: 66.41 - lr: 0.000030
2021-06-22 10:11:12,893 epoch 6 - iter 12/64 - loss 0.32321608 - samples/sec: 66.21 - lr: 0.000030
2021-06-22 10:11:15,795 epoch 6 - iter 18/64 - loss 0.32975255 - samples/sec: 66.18 - lr: 0.000030
2021-06-22 10:11:18,645 epoch 6 - iter 24/64 - loss 0.31862743 - samples/sec: 67.38 - lr: 0.000030
2021-06-22 10:11:21,508 epoch 6 - iter 30/64 - loss 0.29806417 - samples/sec: 67.07 - lr: 0.000030
2021-06-22 10:11:24,385 epoch 6 - iter 36/64 - loss 0.29197225 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 10:11:27,271 epoch 6 - iter 42/64 - loss 0.29028837 - samples/sec: 66.53 - lr: 0.000030
2021-06-22 10:11:30,154 epoch 6 - iter 48/64 - loss 0.29243921 - samples/sec: 66.62 - lr: 0.000030
2021-06-22 10:11:33,022 epoch 6 - iter 54/64 - loss 0.28882734 - samples/sec: 66.96 - lr: 0.000030
2021-06-22 10:11:35,911 epoch 6 - iter 60/64 - loss 0.28621848 - samples/sec: 66.48 - lr: 0.000030
2021-06-22 10:11:37,584 ----------------------------------------------------------------------------------------------------
2021-06-22 10:11:37,585 EPOCH 6 done: loss 0.2873 - lr 0.0000300
2021-06-22 10:11:39,026 DEV : loss 0.1885496824979782 - score 0.9783
2021-06-22 10:11:39,047 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:11:43,630 ----------------------------------------------------------------------------------------------------
2021-06-22 10:11:46,516 epoch 7 - iter 6/64 - loss 0.32286586 - samples/sec: 66.55 - lr: 0.000030
2021-06-22 10:11:49,372 epoch 7 - iter 12/64 - loss 0.24919603 - samples/sec: 67.24 - lr: 0.000030
2021-06-22 10:11:52,240 epoch 7 - iter 18/64 - loss 0.23562056 - samples/sec: 66.96 - lr: 0.000030
2021-06-22 10:11:55,140 epoch 7 - iter 24/64 - loss 0.23763630 - samples/sec: 66.24 - lr: 0.000030
2021-06-22 10:11:58,034 epoch 7 - iter 30/64 - loss 0.24290340 - samples/sec: 66.35 - lr: 0.000030
2021-06-22 10:12:00,909 epoch 7 - iter 36/64 - loss 0.25151351 - samples/sec: 66.79 - lr: 0.000030
2021-06-22 10:12:03,746 epoch 7 - iter 42/64 - loss 0.25722516 - samples/sec: 67.71 - lr: 0.000030
2021-06-22 10:12:06,610 epoch 7 - iter 48/64 - loss 0.25905509 - samples/sec: 67.05 - lr: 0.000030
2021-06-22 10:12:09,460 epoch 7 - iter 54/64 - loss 0.25541259 - samples/sec: 67.38 - lr: 0.000030
2021-06-22 10:12:12,349 epoch 7 - iter 60/64 - loss 0.25068834 - samples/sec: 66.48 - lr: 0.000030
2021-06-22 10:12:14,038 ----------------------------------------------------------------------------------------------------
2021-06-22 10:12:14,038 EPOCH 7 done: loss 0.2542 - lr 0.0000300
2021-06-22 10:12:15,665 DEV : loss 0.18149664998054504 - score 0.9783
2021-06-22 10:12:15,686 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:12:20,181 ----------------------------------------------------------------------------------------------------
2021-06-22 10:12:23,086 epoch 8 - iter 6/64 - loss 0.23449037 - samples/sec: 66.13 - lr: 0.000030
2021-06-22 10:12:25,937 epoch 8 - iter 12/64 - loss 0.23248855 - samples/sec: 67.37 - lr: 0.000030
2021-06-22 10:12:28,778 epoch 8 - iter 18/64 - loss 0.23337958 - samples/sec: 67.60 - lr: 0.000030
2021-06-22 10:12:31,648 epoch 8 - iter 24/64 - loss 0.22731158 - samples/sec: 66.91 - lr: 0.000030
2021-06-22 10:12:34,533 epoch 8 - iter 30/64 - loss 0.22457729 - samples/sec: 66.56 - lr: 0.000030
2021-06-22 10:12:37,446 epoch 8 - iter 36/64 - loss 0.24280822 - samples/sec: 65.94 - lr: 0.000030
2021-06-22 10:12:40,315 epoch 8 - iter 42/64 - loss 0.23969285 - samples/sec: 66.94 - lr: 0.000030
2021-06-22 10:12:43,177 epoch 8 - iter 48/64 - loss 0.22980188 - samples/sec: 67.09 - lr: 0.000030
2021-06-22 10:12:46,056 epoch 8 - iter 54/64 - loss 0.23304120 - samples/sec: 66.71 - lr: 0.000030
2021-06-22 10:12:48,964 epoch 8 - iter 60/64 - loss 0.23376862 - samples/sec: 66.03 - lr: 0.000030
2021-06-22 10:12:50,624 ----------------------------------------------------------------------------------------------------
2021-06-22 10:12:50,624 EPOCH 8 done: loss 0.2297 - lr 0.0000300
2021-06-22 10:12:52,059 DEV : loss 0.1813245564699173 - score 0.9784
2021-06-22 10:12:52,080 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:12:56,557 ----------------------------------------------------------------------------------------------------
2021-06-22 10:12:59,453 epoch 9 - iter 6/64 - loss 0.20278687 - samples/sec: 66.35 - lr: 0.000030
2021-06-22 10:13:02,326 epoch 9 - iter 12/64 - loss 0.17636170 - samples/sec: 66.84 - lr: 0.000030
2021-06-22 10:13:05,200 epoch 9 - iter 18/64 - loss 0.18214062 - samples/sec: 66.82 - lr: 0.000030
2021-06-22 10:13:08,057 epoch 9 - iter 24/64 - loss 0.20731693 - samples/sec: 67.22 - lr: 0.000030
2021-06-22 10:13:10,950 epoch 9 - iter 30/64 - loss 0.22520309 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 10:13:13,828 epoch 9 - iter 36/64 - loss 0.21655997 - samples/sec: 66.75 - lr: 0.000030
2021-06-22 10:13:16,688 epoch 9 - iter 42/64 - loss 0.21086916 - samples/sec: 67.15 - lr: 0.000030
2021-06-22 10:13:19,547 epoch 9 - iter 48/64 - loss 0.20608296 - samples/sec: 67.17 - lr: 0.000030
2021-06-22 10:13:22,431 epoch 9 - iter 54/64 - loss 0.20864749 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 10:13:25,273 epoch 9 - iter 60/64 - loss 0.20312673 - samples/sec: 67.59 - lr: 0.000030
2021-06-22 10:13:26,978 ----------------------------------------------------------------------------------------------------
2021-06-22 10:13:26,978 EPOCH 9 done: loss 0.1970 - lr 0.0000300
2021-06-22 10:13:28,415 DEV : loss 0.18235379457473755 - score 0.9784
2021-06-22 10:13:28,436 BAD EPOCHS (no improvement): 1
2021-06-22 10:13:28,436 ----------------------------------------------------------------------------------------------------
2021-06-22 10:13:31,291 epoch 10 - iter 6/64 - loss 0.18086061 - samples/sec: 67.28 - lr: 0.000030
2021-06-22 10:13:34,165 epoch 10 - iter 12/64 - loss 0.18010667 - samples/sec: 66.82 - lr: 0.000030
2021-06-22 10:13:37,055 epoch 10 - iter 18/64 - loss 0.15212026 - samples/sec: 66.45 - lr: 0.000030
2021-06-22 10:13:39,963 epoch 10 - iter 24/64 - loss 0.14646205 - samples/sec: 66.03 - lr: 0.000030
2021-06-22 10:13:42,833 epoch 10 - iter 30/64 - loss 0.15257574 - samples/sec: 66.92 - lr: 0.000030
2021-06-22 10:13:45,726 epoch 10 - iter 36/64 - loss 0.16128323 - samples/sec: 66.39 - lr: 0.000030
2021-06-22 10:13:48,630 epoch 10 - iter 42/64 - loss 0.15827980 - samples/sec: 66.13 - lr: 0.000030
2021-06-22 10:13:51,526 epoch 10 - iter 48/64 - loss 0.16506219 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 10:13:54,390 epoch 10 - iter 54/64 - loss 0.18202101 - samples/sec: 67.04 - lr: 0.000030
2021-06-22 10:13:57,250 epoch 10 - iter 60/64 - loss 0.18215041 - samples/sec: 67.15 - lr: 0.000030
2021-06-22 10:13:58,949 ----------------------------------------------------------------------------------------------------
2021-06-22 10:13:58,950 EPOCH 10 done: loss 0.1821 - lr 0.0000300
2021-06-22 10:14:00,388 DEV : loss 0.17173545062541962 - score 0.9783
2021-06-22 10:14:00,409 BAD EPOCHS (no improvement): 2
2021-06-22 10:14:00,410 ----------------------------------------------------------------------------------------------------
2021-06-22 10:14:03,327 epoch 11 - iter 6/64 - loss 0.18624983 - samples/sec: 65.82 - lr: 0.000030
2021-06-22 10:14:06,211 epoch 11 - iter 12/64 - loss 0.19176216 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 10:14:09,071 epoch 11 - iter 18/64 - loss 0.17472085 - samples/sec: 67.15 - lr: 0.000030
2021-06-22 10:14:11,918 epoch 11 - iter 24/64 - loss 0.17277710 - samples/sec: 67.46 - lr: 0.000030
2021-06-22 10:14:14,815 epoch 11 - iter 30/64 - loss 0.18340922 - samples/sec: 66.28 - lr: 0.000030
2021-06-22 10:14:17,718 epoch 11 - iter 36/64 - loss 0.17452110 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 10:14:20,622 epoch 11 - iter 42/64 - loss 0.17676371 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 10:14:23,537 epoch 11 - iter 48/64 - loss 0.17546875 - samples/sec: 65.86 - lr: 0.000030
2021-06-22 10:14:26,392 epoch 11 - iter 54/64 - loss 0.17298204 - samples/sec: 67.27 - lr: 0.000030
2021-06-22 10:14:29,290 epoch 11 - iter 60/64 - loss 0.17280253 - samples/sec: 66.27 - lr: 0.000030
2021-06-22 10:14:30,982 ----------------------------------------------------------------------------------------------------
2021-06-22 10:14:30,982 EPOCH 11 done: loss 0.1698 - lr 0.0000300
2021-06-22 10:14:32,420 DEV : loss 0.1749064326286316 - score 0.9805
2021-06-22 10:14:32,441 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:14:36,939 ----------------------------------------------------------------------------------------------------
2021-06-22 10:14:39,965 epoch 12 - iter 6/64 - loss 0.12475353 - samples/sec: 63.49 - lr: 0.000030
2021-06-22 10:14:42,890 epoch 12 - iter 12/64 - loss 0.13895651 - samples/sec: 65.66 - lr: 0.000030
2021-06-22 10:14:45,786 epoch 12 - iter 18/64 - loss 0.13770212 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 10:14:48,682 epoch 12 - iter 24/64 - loss 0.12536579 - samples/sec: 66.30 - lr: 0.000030
2021-06-22 10:14:51,606 epoch 12 - iter 30/64 - loss 0.12091934 - samples/sec: 65.68 - lr: 0.000030
2021-06-22 10:14:54,527 epoch 12 - iter 36/64 - loss 0.13906057 - samples/sec: 65.77 - lr: 0.000030
2021-06-22 10:14:57,393 epoch 12 - iter 42/64 - loss 0.14237345 - samples/sec: 67.00 - lr: 0.000030
2021-06-22 10:15:00,260 epoch 12 - iter 48/64 - loss 0.15407780 - samples/sec: 66.97 - lr: 0.000030
2021-06-22 10:15:03,193 epoch 12 - iter 54/64 - loss 0.15142145 - samples/sec: 65.49 - lr: 0.000030
2021-06-22 10:15:06,087 epoch 12 - iter 60/64 - loss 0.14972735 - samples/sec: 66.35 - lr: 0.000030
2021-06-22 10:15:07,787 ----------------------------------------------------------------------------------------------------
2021-06-22 10:15:07,787 EPOCH 12 done: loss 0.1452 - lr 0.0000300
2021-06-22 10:15:09,225 DEV : loss 0.18000651895999908 - score 0.9783
2021-06-22 10:15:09,245 BAD EPOCHS (no improvement): 1
2021-06-22 10:15:09,246 ----------------------------------------------------------------------------------------------------
2021-06-22 10:15:12,115 epoch 13 - iter 6/64 - loss 0.06269628 - samples/sec: 66.93 - lr: 0.000030
2021-06-22 10:15:15,011 epoch 13 - iter 12/64 - loss 0.12058198 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 10:15:17,926 epoch 13 - iter 18/64 - loss 0.11856943 - samples/sec: 65.88 - lr: 0.000030
2021-06-22 10:15:20,783 epoch 13 - iter 24/64 - loss 0.12520732 - samples/sec: 67.23 - lr: 0.000030
2021-06-22 10:15:23,640 epoch 13 - iter 30/64 - loss 0.13766599 - samples/sec: 67.22 - lr: 0.000030
2021-06-22 10:15:26,572 epoch 13 - iter 36/64 - loss 0.14388423 - samples/sec: 65.49 - lr: 0.000030
2021-06-22 10:15:29,468 epoch 13 - iter 42/64 - loss 0.14386694 - samples/sec: 66.31 - lr: 0.000030
2021-06-22 10:15:32,376 epoch 13 - iter 48/64 - loss 0.15035447 - samples/sec: 66.05 - lr: 0.000030
2021-06-22 10:15:35,279 epoch 13 - iter 54/64 - loss 0.14719221 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 10:15:38,183 epoch 13 - iter 60/64 - loss 0.15179433 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 10:15:39,900 ----------------------------------------------------------------------------------------------------
2021-06-22 10:15:39,901 EPOCH 13 done: loss 0.1484 - lr 0.0000300
2021-06-22 10:15:41,336 DEV : loss 0.17690438032150269 - score 0.9827
2021-06-22 10:15:41,357 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:15:46,053 ----------------------------------------------------------------------------------------------------
2021-06-22 10:15:48,928 epoch 14 - iter 6/64 - loss 0.17507361 - samples/sec: 66.82 - lr: 0.000030
2021-06-22 10:15:51,820 epoch 14 - iter 12/64 - loss 0.15275610 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 10:15:54,716 epoch 14 - iter 18/64 - loss 0.15189242 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 10:15:57,583 epoch 14 - iter 24/64 - loss 0.13360026 - samples/sec: 66.98 - lr: 0.000030
2021-06-22 10:16:00,450 epoch 14 - iter 30/64 - loss 0.13894175 - samples/sec: 66.99 - lr: 0.000030
2021-06-22 10:16:03,389 epoch 14 - iter 36/64 - loss 0.13373036 - samples/sec: 65.34 - lr: 0.000030
2021-06-22 10:16:06,269 epoch 14 - iter 42/64 - loss 0.14268934 - samples/sec: 66.70 - lr: 0.000030
2021-06-22 10:16:09,120 epoch 14 - iter 48/64 - loss 0.14132068 - samples/sec: 67.36 - lr: 0.000030
2021-06-22 10:16:11,985 epoch 14 - iter 54/64 - loss 0.13874385 - samples/sec: 67.03 - lr: 0.000030
2021-06-22 10:16:14,906 epoch 14 - iter 60/64 - loss 0.14260592 - samples/sec: 65.75 - lr: 0.000030
2021-06-22 10:16:16,624 ----------------------------------------------------------------------------------------------------
2021-06-22 10:16:16,624 EPOCH 14 done: loss 0.1394 - lr 0.0000300
2021-06-22 10:16:18,059 DEV : loss 0.17692476511001587 - score 0.9806
2021-06-22 10:16:18,080 BAD EPOCHS (no improvement): 1
2021-06-22 10:16:18,080 ----------------------------------------------------------------------------------------------------
2021-06-22 10:16:20,956 epoch 15 - iter 6/64 - loss 0.11278937 - samples/sec: 66.80 - lr: 0.000030
2021-06-22 10:16:23,868 epoch 15 - iter 12/64 - loss 0.13120774 - samples/sec: 65.95 - lr: 0.000030
2021-06-22 10:16:26,743 epoch 15 - iter 18/64 - loss 0.13438745 - samples/sec: 66.79 - lr: 0.000030
2021-06-22 10:16:29,619 epoch 15 - iter 24/64 - loss 0.13047311 - samples/sec: 66.78 - lr: 0.000030
2021-06-22 10:16:32,514 epoch 15 - iter 30/64 - loss 0.13688483 - samples/sec: 66.35 - lr: 0.000030
2021-06-22 10:16:35,403 epoch 15 - iter 36/64 - loss 0.13668827 - samples/sec: 66.46 - lr: 0.000030
2021-06-22 10:16:38,318 epoch 15 - iter 42/64 - loss 0.14378400 - samples/sec: 65.88 - lr: 0.000030
2021-06-22 10:16:41,172 epoch 15 - iter 48/64 - loss 0.14620073 - samples/sec: 67.28 - lr: 0.000030
2021-06-22 10:16:44,010 epoch 15 - iter 54/64 - loss 0.13952895 - samples/sec: 67.68 - lr: 0.000030
2021-06-22 10:16:46,881 epoch 15 - iter 60/64 - loss 0.13579489 - samples/sec: 66.90 - lr: 0.000030
2021-06-22 10:16:48,569 ----------------------------------------------------------------------------------------------------
2021-06-22 10:16:48,569 EPOCH 15 done: loss 0.1335 - lr 0.0000300
2021-06-22 10:16:50,004 DEV : loss 0.1777968555688858 - score 0.9784
2021-06-22 10:16:50,025 BAD EPOCHS (no improvement): 2
2021-06-22 10:16:50,025 ----------------------------------------------------------------------------------------------------
2021-06-22 10:16:53,051 epoch 16 - iter 6/64 - loss 0.11951681 - samples/sec: 63.47 - lr: 0.000030
2021-06-22 10:16:55,907 epoch 16 - iter 12/64 - loss 0.10561150 - samples/sec: 67.25 - lr: 0.000030
2021-06-22 10:16:58,762 epoch 16 - iter 18/64 - loss 0.11048468 - samples/sec: 67.27 - lr: 0.000030
2021-06-22 10:17:01,638 epoch 16 - iter 24/64 - loss 0.10814304 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 10:17:04,510 epoch 16 - iter 30/64 - loss 0.10977916 - samples/sec: 66.87 - lr: 0.000030
2021-06-22 10:17:07,355 epoch 16 - iter 36/64 - loss 0.10381485 - samples/sec: 67.51 - lr: 0.000030
2021-06-22 10:17:10,178 epoch 16 - iter 42/64 - loss 0.11062849 - samples/sec: 68.02 - lr: 0.000030
2021-06-22 10:17:13,015 epoch 16 - iter 48/64 - loss 0.11161975 - samples/sec: 67.70 - lr: 0.000030
2021-06-22 10:17:15,864 epoch 16 - iter 54/64 - loss 0.10469935 - samples/sec: 67.41 - lr: 0.000030
2021-06-22 10:17:18,720 epoch 16 - iter 60/64 - loss 0.10327659 - samples/sec: 67.23 - lr: 0.000030
2021-06-22 10:17:20,385 ----------------------------------------------------------------------------------------------------
2021-06-22 10:17:20,385 EPOCH 16 done: loss 0.1014 - lr 0.0000300
2021-06-22 10:17:21,821 DEV : loss 0.1790941059589386 - score 0.9804
2021-06-22 10:17:21,842 BAD EPOCHS (no improvement): 3
2021-06-22 10:17:21,843 ----------------------------------------------------------------------------------------------------
2021-06-22 10:17:24,681 epoch 17 - iter 6/64 - loss 0.07629503 - samples/sec: 67.66 - lr: 0.000030
2021-06-22 10:17:27,540 epoch 17 - iter 12/64 - loss 0.08045677 - samples/sec: 67.18 - lr: 0.000030
2021-06-22 10:17:30,371 epoch 17 - iter 18/64 - loss 0.08652970 - samples/sec: 67.84 - lr: 0.000030
2021-06-22 10:17:33,196 epoch 17 - iter 24/64 - loss 0.09735127 - samples/sec: 67.96 - lr: 0.000030
2021-06-22 10:17:36,073 epoch 17 - iter 30/64 - loss 0.09610831 - samples/sec: 66.75 - lr: 0.000030
2021-06-22 10:17:38,932 epoch 17 - iter 36/64 - loss 0.11543826 - samples/sec: 67.19 - lr: 0.000030
2021-06-22 10:17:41,748 epoch 17 - iter 42/64 - loss 0.11410190 - samples/sec: 68.18 - lr: 0.000030
2021-06-22 10:17:44,550 epoch 17 - iter 48/64 - loss 0.11380596 - samples/sec: 68.56 - lr: 0.000030
2021-06-22 10:17:47,397 epoch 17 - iter 54/64 - loss 0.11248990 - samples/sec: 67.44 - lr: 0.000030
2021-06-22 10:17:50,233 epoch 17 - iter 60/64 - loss 0.11362027 - samples/sec: 67.74 - lr: 0.000030
2021-06-22 10:17:51,891 ----------------------------------------------------------------------------------------------------
2021-06-22 10:17:51,891 EPOCH 17 done: loss 0.1200 - lr 0.0000300
2021-06-22 10:17:53,327 DEV : loss 0.17777617275714874 - score 0.9784
Epoch    17: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 10:17:53,348 BAD EPOCHS (no improvement): 4
2021-06-22 10:17:53,348 ----------------------------------------------------------------------------------------------------
2021-06-22 10:17:56,174 epoch 18 - iter 6/64 - loss 0.10903574 - samples/sec: 67.96 - lr: 0.000015
2021-06-22 10:17:59,016 epoch 18 - iter 12/64 - loss 0.12801484 - samples/sec: 67.57 - lr: 0.000015
2021-06-22 10:18:01,842 epoch 18 - iter 18/64 - loss 0.13004787 - samples/sec: 67.95 - lr: 0.000015
2021-06-22 10:18:04,687 epoch 18 - iter 24/64 - loss 0.12408043 - samples/sec: 67.51 - lr: 0.000015
2021-06-22 10:18:07,588 epoch 18 - iter 30/64 - loss 0.11446094 - samples/sec: 66.20 - lr: 0.000015
2021-06-22 10:18:10,466 epoch 18 - iter 36/64 - loss 0.11750576 - samples/sec: 66.72 - lr: 0.000015
2021-06-22 10:18:13,323 epoch 18 - iter 42/64 - loss 0.11969971 - samples/sec: 67.22 - lr: 0.000015
2021-06-22 10:18:16,128 epoch 18 - iter 48/64 - loss 0.11558648 - samples/sec: 68.49 - lr: 0.000015
2021-06-22 10:18:18,979 epoch 18 - iter 54/64 - loss 0.11329218 - samples/sec: 67.35 - lr: 0.000015
2021-06-22 10:18:21,815 epoch 18 - iter 60/64 - loss 0.10922366 - samples/sec: 67.73 - lr: 0.000015
2021-06-22 10:18:23,494 ----------------------------------------------------------------------------------------------------
2021-06-22 10:18:23,494 EPOCH 18 done: loss 0.1101 - lr 0.0000150
2021-06-22 10:18:24,931 DEV : loss 0.17009076476097107 - score 0.9848
2021-06-22 10:18:24,952 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:18:29,555 ----------------------------------------------------------------------------------------------------
2021-06-22 10:18:32,373 epoch 19 - iter 6/64 - loss 0.09863819 - samples/sec: 68.17 - lr: 0.000015
2021-06-22 10:18:35,244 epoch 19 - iter 12/64 - loss 0.09340151 - samples/sec: 66.88 - lr: 0.000015
2021-06-22 10:18:38,078 epoch 19 - iter 18/64 - loss 0.09880995 - samples/sec: 67.78 - lr: 0.000015
2021-06-22 10:18:40,886 epoch 19 - iter 24/64 - loss 0.10670584 - samples/sec: 68.39 - lr: 0.000015
2021-06-22 10:18:43,738 epoch 19 - iter 30/64 - loss 0.10359713 - samples/sec: 67.33 - lr: 0.000015
2021-06-22 10:18:46,606 epoch 19 - iter 36/64 - loss 0.09724616 - samples/sec: 66.96 - lr: 0.000015
2021-06-22 10:18:49,446 epoch 19 - iter 42/64 - loss 0.10285924 - samples/sec: 67.63 - lr: 0.000015
2021-06-22 10:18:52,300 epoch 19 - iter 48/64 - loss 0.10079789 - samples/sec: 67.28 - lr: 0.000015
2021-06-22 10:18:55,187 epoch 19 - iter 54/64 - loss 0.09965549 - samples/sec: 66.52 - lr: 0.000015
2021-06-22 10:18:58,095 epoch 19 - iter 60/64 - loss 0.10243578 - samples/sec: 66.04 - lr: 0.000015
2021-06-22 10:18:59,801 ----------------------------------------------------------------------------------------------------
2021-06-22 10:18:59,801 EPOCH 19 done: loss 0.0997 - lr 0.0000150
2021-06-22 10:19:01,239 DEV : loss 0.1710314154624939 - score 0.9848
2021-06-22 10:19:01,260 BAD EPOCHS (no improvement): 1
2021-06-22 10:19:01,261 ----------------------------------------------------------------------------------------------------
2021-06-22 10:19:04,152 epoch 20 - iter 6/64 - loss 0.08718841 - samples/sec: 66.41 - lr: 0.000015
2021-06-22 10:19:07,230 epoch 20 - iter 12/64 - loss 0.09444309 - samples/sec: 62.41 - lr: 0.000015
2021-06-22 10:19:10,128 epoch 20 - iter 18/64 - loss 0.10617617 - samples/sec: 66.27 - lr: 0.000015
2021-06-22 10:19:13,000 epoch 20 - iter 24/64 - loss 0.10467975 - samples/sec: 66.85 - lr: 0.000015
2021-06-22 10:19:15,857 epoch 20 - iter 30/64 - loss 0.10557180 - samples/sec: 67.24 - lr: 0.000015
2021-06-22 10:19:18,757 epoch 20 - iter 36/64 - loss 0.10007955 - samples/sec: 66.23 - lr: 0.000015
2021-06-22 10:19:21,622 epoch 20 - iter 42/64 - loss 0.09551200 - samples/sec: 67.01 - lr: 0.000015
2021-06-22 10:19:24,549 epoch 20 - iter 48/64 - loss 0.09404377 - samples/sec: 65.62 - lr: 0.000015
2021-06-22 10:19:27,449 epoch 20 - iter 54/64 - loss 0.09421087 - samples/sec: 66.23 - lr: 0.000015
2021-06-22 10:19:30,356 epoch 20 - iter 60/64 - loss 0.09338411 - samples/sec: 66.06 - lr: 0.000015
2021-06-22 10:19:32,033 ----------------------------------------------------------------------------------------------------
2021-06-22 10:19:32,034 EPOCH 20 done: loss 0.0943 - lr 0.0000150
2021-06-22 10:19:33,473 DEV : loss 0.17545850574970245 - score 0.9848
2021-06-22 10:19:33,494 BAD EPOCHS (no improvement): 2
2021-06-22 10:19:33,494 ----------------------------------------------------------------------------------------------------
2021-06-22 10:19:36,377 epoch 21 - iter 6/64 - loss 0.08132561 - samples/sec: 66.62 - lr: 0.000015
2021-06-22 10:19:39,307 epoch 21 - iter 12/64 - loss 0.07880602 - samples/sec: 65.54 - lr: 0.000015
2021-06-22 10:19:42,197 epoch 21 - iter 18/64 - loss 0.08913559 - samples/sec: 66.45 - lr: 0.000015
2021-06-22 10:19:45,093 epoch 21 - iter 24/64 - loss 0.08877156 - samples/sec: 66.33 - lr: 0.000015
2021-06-22 10:19:47,938 epoch 21 - iter 30/64 - loss 0.08563910 - samples/sec: 67.50 - lr: 0.000015
2021-06-22 10:19:50,774 epoch 21 - iter 36/64 - loss 0.09755515 - samples/sec: 67.71 - lr: 0.000015
2021-06-22 10:19:53,636 epoch 21 - iter 42/64 - loss 0.10094822 - samples/sec: 67.08 - lr: 0.000015
2021-06-22 10:19:56,474 epoch 21 - iter 48/64 - loss 0.09891123 - samples/sec: 67.68 - lr: 0.000015
2021-06-22 10:19:59,273 epoch 21 - iter 54/64 - loss 0.09993915 - samples/sec: 68.61 - lr: 0.000015
2021-06-22 10:20:02,095 epoch 21 - iter 60/64 - loss 0.10153582 - samples/sec: 68.05 - lr: 0.000015
2021-06-22 10:20:03,771 ----------------------------------------------------------------------------------------------------
2021-06-22 10:20:03,771 EPOCH 21 done: loss 0.1066 - lr 0.0000150
2021-06-22 10:20:05,210 DEV : loss 0.17630712687969208 - score 0.9848
2021-06-22 10:20:05,232 BAD EPOCHS (no improvement): 3
2021-06-22 10:20:05,232 ----------------------------------------------------------------------------------------------------
2021-06-22 10:20:08,065 epoch 22 - iter 6/64 - loss 0.09230565 - samples/sec: 67.79 - lr: 0.000015
2021-06-22 10:20:10,959 epoch 22 - iter 12/64 - loss 0.10631964 - samples/sec: 66.36 - lr: 0.000015
2021-06-22 10:20:13,831 epoch 22 - iter 18/64 - loss 0.09499939 - samples/sec: 66.88 - lr: 0.000015
2021-06-22 10:20:16,656 epoch 22 - iter 24/64 - loss 0.09237614 - samples/sec: 67.98 - lr: 0.000015
2021-06-22 10:20:19,502 epoch 22 - iter 30/64 - loss 0.10248955 - samples/sec: 67.47 - lr: 0.000015
2021-06-22 10:20:22,382 epoch 22 - iter 36/64 - loss 0.10032565 - samples/sec: 66.69 - lr: 0.000015
2021-06-22 10:20:25,277 epoch 22 - iter 42/64 - loss 0.09756826 - samples/sec: 66.33 - lr: 0.000015
2021-06-22 10:20:28,172 epoch 22 - iter 48/64 - loss 0.09403986 - samples/sec: 66.35 - lr: 0.000015
2021-06-22 10:20:31,021 epoch 22 - iter 54/64 - loss 0.09052231 - samples/sec: 67.41 - lr: 0.000015
2021-06-22 10:20:33,896 epoch 22 - iter 60/64 - loss 0.08934153 - samples/sec: 66.79 - lr: 0.000015
2021-06-22 10:20:35,574 ----------------------------------------------------------------------------------------------------
2021-06-22 10:20:35,574 EPOCH 22 done: loss 0.0863 - lr 0.0000150
2021-06-22 10:20:37,010 DEV : loss 0.17733882367610931 - score 0.9848
Epoch    22: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 10:20:37,031 BAD EPOCHS (no improvement): 4
2021-06-22 10:20:37,031 ----------------------------------------------------------------------------------------------------
2021-06-22 10:20:39,914 epoch 23 - iter 6/64 - loss 0.07435831 - samples/sec: 66.61 - lr: 0.000008
2021-06-22 10:20:42,796 epoch 23 - iter 12/64 - loss 0.09223047 - samples/sec: 66.64 - lr: 0.000008
2021-06-22 10:20:45,679 epoch 23 - iter 18/64 - loss 0.08330905 - samples/sec: 66.62 - lr: 0.000008
2021-06-22 10:20:48,560 epoch 23 - iter 24/64 - loss 0.08664974 - samples/sec: 66.66 - lr: 0.000008
2021-06-22 10:20:51,441 epoch 23 - iter 30/64 - loss 0.08384946 - samples/sec: 66.67 - lr: 0.000008
2021-06-22 10:20:54,275 epoch 23 - iter 36/64 - loss 0.08598225 - samples/sec: 67.75 - lr: 0.000008
2021-06-22 10:20:57,150 epoch 23 - iter 42/64 - loss 0.08332029 - samples/sec: 66.81 - lr: 0.000008
2021-06-22 10:21:00,071 epoch 23 - iter 48/64 - loss 0.08606049 - samples/sec: 65.74 - lr: 0.000008
2021-06-22 10:21:02,976 epoch 23 - iter 54/64 - loss 0.08524062 - samples/sec: 66.10 - lr: 0.000008
2021-06-22 10:21:05,852 epoch 23 - iter 60/64 - loss 0.08488413 - samples/sec: 66.78 - lr: 0.000008
2021-06-22 10:21:07,549 ----------------------------------------------------------------------------------------------------
2021-06-22 10:21:07,550 EPOCH 23 done: loss 0.0892 - lr 0.0000075
2021-06-22 10:21:08,986 DEV : loss 0.17713554203510284 - score 0.9848
2021-06-22 10:21:09,007 BAD EPOCHS (no improvement): 1
2021-06-22 10:21:09,007 ----------------------------------------------------------------------------------------------------
2021-06-22 10:21:11,876 epoch 24 - iter 6/64 - loss 0.10044378 - samples/sec: 66.93 - lr: 0.000008
2021-06-22 10:21:14,952 epoch 24 - iter 12/64 - loss 0.10588147 - samples/sec: 62.44 - lr: 0.000008
2021-06-22 10:21:17,822 epoch 24 - iter 18/64 - loss 0.09055344 - samples/sec: 66.93 - lr: 0.000008
2021-06-22 10:21:20,707 epoch 24 - iter 24/64 - loss 0.10388670 - samples/sec: 66.56 - lr: 0.000008
2021-06-22 10:21:23,591 epoch 24 - iter 30/64 - loss 0.09739358 - samples/sec: 66.60 - lr: 0.000008
2021-06-22 10:21:26,528 epoch 24 - iter 36/64 - loss 0.09677295 - samples/sec: 65.37 - lr: 0.000008
2021-06-22 10:21:29,385 epoch 24 - iter 42/64 - loss 0.09176677 - samples/sec: 67.23 - lr: 0.000008
2021-06-22 10:21:32,301 epoch 24 - iter 48/64 - loss 0.08800474 - samples/sec: 65.86 - lr: 0.000008
2021-06-22 10:21:35,168 epoch 24 - iter 54/64 - loss 0.08587629 - samples/sec: 66.98 - lr: 0.000008
2021-06-22 10:21:38,031 epoch 24 - iter 60/64 - loss 0.08442688 - samples/sec: 67.09 - lr: 0.000008
2021-06-22 10:21:39,733 ----------------------------------------------------------------------------------------------------
2021-06-22 10:21:39,733 EPOCH 24 done: loss 0.0839 - lr 0.0000075
2021-06-22 10:21:41,170 DEV : loss 0.1776137351989746 - score 0.9848
2021-06-22 10:21:41,191 BAD EPOCHS (no improvement): 2
2021-06-22 10:21:41,192 ----------------------------------------------------------------------------------------------------
2021-06-22 10:21:44,043 epoch 25 - iter 6/64 - loss 0.09824900 - samples/sec: 67.34 - lr: 0.000008
2021-06-22 10:21:46,951 epoch 25 - iter 12/64 - loss 0.09105214 - samples/sec: 66.05 - lr: 0.000008
2021-06-22 10:21:49,824 epoch 25 - iter 18/64 - loss 0.09300669 - samples/sec: 66.84 - lr: 0.000008
2021-06-22 10:21:52,694 epoch 25 - iter 24/64 - loss 0.09151045 - samples/sec: 66.91 - lr: 0.000008
2021-06-22 10:21:55,565 epoch 25 - iter 30/64 - loss 0.09046184 - samples/sec: 66.90 - lr: 0.000008
2021-06-22 10:21:58,405 epoch 25 - iter 36/64 - loss 0.08809818 - samples/sec: 67.63 - lr: 0.000008
2021-06-22 10:22:01,313 epoch 25 - iter 42/64 - loss 0.08585478 - samples/sec: 66.04 - lr: 0.000008
2021-06-22 10:22:04,186 epoch 25 - iter 48/64 - loss 0.08362397 - samples/sec: 66.84 - lr: 0.000008
2021-06-22 10:22:07,074 epoch 25 - iter 54/64 - loss 0.08032717 - samples/sec: 66.50 - lr: 0.000008
2021-06-22 10:22:09,984 epoch 25 - iter 60/64 - loss 0.08487660 - samples/sec: 65.98 - lr: 0.000008
2021-06-22 10:22:11,688 ----------------------------------------------------------------------------------------------------
2021-06-22 10:22:11,689 EPOCH 25 done: loss 0.0854 - lr 0.0000075
2021-06-22 10:22:13,125 DEV : loss 0.17680692672729492 - score 0.9848
2021-06-22 10:22:13,146 BAD EPOCHS (no improvement): 3
2021-06-22 10:22:13,147 ----------------------------------------------------------------------------------------------------
2021-06-22 10:22:16,024 epoch 26 - iter 6/64 - loss 0.07229974 - samples/sec: 66.75 - lr: 0.000008
2021-06-22 10:22:18,895 epoch 26 - iter 12/64 - loss 0.07727422 - samples/sec: 66.89 - lr: 0.000008
2021-06-22 10:22:21,766 epoch 26 - iter 18/64 - loss 0.07750490 - samples/sec: 66.88 - lr: 0.000008
2021-06-22 10:22:24,687 epoch 26 - iter 24/64 - loss 0.07829246 - samples/sec: 65.75 - lr: 0.000008
2021-06-22 10:22:27,581 epoch 26 - iter 30/64 - loss 0.07677496 - samples/sec: 66.37 - lr: 0.000008
2021-06-22 10:22:30,461 epoch 26 - iter 36/64 - loss 0.08235139 - samples/sec: 66.69 - lr: 0.000008
2021-06-22 10:22:33,328 epoch 26 - iter 42/64 - loss 0.08821972 - samples/sec: 66.98 - lr: 0.000008
2021-06-22 10:22:36,188 epoch 26 - iter 48/64 - loss 0.08943581 - samples/sec: 67.14 - lr: 0.000008
2021-06-22 10:22:39,096 epoch 26 - iter 54/64 - loss 0.08821550 - samples/sec: 66.06 - lr: 0.000008
2021-06-22 10:22:41,939 epoch 26 - iter 60/64 - loss 0.08678064 - samples/sec: 67.54 - lr: 0.000008
2021-06-22 10:22:43,645 ----------------------------------------------------------------------------------------------------
2021-06-22 10:22:43,645 EPOCH 26 done: loss 0.0849 - lr 0.0000075
2021-06-22 10:22:45,082 DEV : loss 0.1817786544561386 - score 0.9848
Epoch    26: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 10:22:45,103 BAD EPOCHS (no improvement): 4
2021-06-22 10:22:45,103 ----------------------------------------------------------------------------------------------------
2021-06-22 10:22:47,951 epoch 27 - iter 6/64 - loss 0.04901908 - samples/sec: 67.45 - lr: 0.000004
2021-06-22 10:22:50,842 epoch 27 - iter 12/64 - loss 0.06956688 - samples/sec: 66.41 - lr: 0.000004
2021-06-22 10:22:53,739 epoch 27 - iter 18/64 - loss 0.07689447 - samples/sec: 66.29 - lr: 0.000004
2021-06-22 10:22:56,622 epoch 27 - iter 24/64 - loss 0.07796114 - samples/sec: 66.62 - lr: 0.000004
2021-06-22 10:22:59,480 epoch 27 - iter 30/64 - loss 0.08018565 - samples/sec: 67.20 - lr: 0.000004
2021-06-22 10:23:02,406 epoch 27 - iter 36/64 - loss 0.08553446 - samples/sec: 65.63 - lr: 0.000004
2021-06-22 10:23:05,283 epoch 27 - iter 42/64 - loss 0.09068079 - samples/sec: 66.75 - lr: 0.000004
2021-06-22 10:23:08,181 epoch 27 - iter 48/64 - loss 0.08781744 - samples/sec: 66.28 - lr: 0.000004
2021-06-22 10:23:11,094 epoch 27 - iter 54/64 - loss 0.08286413 - samples/sec: 65.91 - lr: 0.000004
2021-06-22 10:23:13,963 epoch 27 - iter 60/64 - loss 0.08277182 - samples/sec: 66.95 - lr: 0.000004
2021-06-22 10:23:15,661 ----------------------------------------------------------------------------------------------------
2021-06-22 10:23:15,661 EPOCH 27 done: loss 0.0842 - lr 0.0000038
2021-06-22 10:23:17,101 DEV : loss 0.17898350954055786 - score 0.9848
2021-06-22 10:23:17,123 BAD EPOCHS (no improvement): 1
2021-06-22 10:23:17,123 ----------------------------------------------------------------------------------------------------
2021-06-22 10:23:19,983 epoch 28 - iter 6/64 - loss 0.06176228 - samples/sec: 67.15 - lr: 0.000004
2021-06-22 10:23:23,062 epoch 28 - iter 12/64 - loss 0.08110167 - samples/sec: 62.36 - lr: 0.000004
2021-06-22 10:23:25,928 epoch 28 - iter 18/64 - loss 0.06754465 - samples/sec: 67.01 - lr: 0.000004
2021-06-22 10:23:28,845 epoch 28 - iter 24/64 - loss 0.07827038 - samples/sec: 65.86 - lr: 0.000004
2021-06-22 10:23:31,747 epoch 28 - iter 30/64 - loss 0.08431524 - samples/sec: 66.16 - lr: 0.000004
2021-06-22 10:23:34,637 epoch 28 - iter 36/64 - loss 0.08704766 - samples/sec: 66.47 - lr: 0.000004
2021-06-22 10:23:37,498 epoch 28 - iter 42/64 - loss 0.08465256 - samples/sec: 67.10 - lr: 0.000004
2021-06-22 10:23:40,385 epoch 28 - iter 48/64 - loss 0.08334860 - samples/sec: 66.54 - lr: 0.000004
2021-06-22 10:23:43,290 epoch 28 - iter 54/64 - loss 0.08570071 - samples/sec: 66.09 - lr: 0.000004
2021-06-22 10:23:46,174 epoch 28 - iter 60/64 - loss 0.08719478 - samples/sec: 66.59 - lr: 0.000004
2021-06-22 10:23:47,842 ----------------------------------------------------------------------------------------------------
2021-06-22 10:23:47,843 EPOCH 28 done: loss 0.0857 - lr 0.0000038
2021-06-22 10:23:49,282 DEV : loss 0.17837221920490265 - score 0.9848
2021-06-22 10:23:49,303 BAD EPOCHS (no improvement): 2
2021-06-22 10:23:49,303 ----------------------------------------------------------------------------------------------------
2021-06-22 10:23:52,172 epoch 29 - iter 6/64 - loss 0.09980576 - samples/sec: 66.95 - lr: 0.000004
2021-06-22 10:23:55,059 epoch 29 - iter 12/64 - loss 0.08833935 - samples/sec: 66.51 - lr: 0.000004
2021-06-22 10:23:57,964 epoch 29 - iter 18/64 - loss 0.10576627 - samples/sec: 66.13 - lr: 0.000004
2021-06-22 10:24:00,842 epoch 29 - iter 24/64 - loss 0.10203431 - samples/sec: 66.71 - lr: 0.000004
2021-06-22 10:24:03,713 epoch 29 - iter 30/64 - loss 0.09989871 - samples/sec: 66.90 - lr: 0.000004
2021-06-22 10:24:06,596 epoch 29 - iter 36/64 - loss 0.09416940 - samples/sec: 66.60 - lr: 0.000004
2021-06-22 10:24:09,462 epoch 29 - iter 42/64 - loss 0.09012036 - samples/sec: 67.01 - lr: 0.000004
2021-06-22 10:24:12,356 epoch 29 - iter 48/64 - loss 0.08707663 - samples/sec: 66.36 - lr: 0.000004
2021-06-22 10:24:15,234 epoch 29 - iter 54/64 - loss 0.08100404 - samples/sec: 66.73 - lr: 0.000004
2021-06-22 10:24:18,105 epoch 29 - iter 60/64 - loss 0.07933935 - samples/sec: 66.90 - lr: 0.000004
2021-06-22 10:24:19,805 ----------------------------------------------------------------------------------------------------
2021-06-22 10:24:19,806 EPOCH 29 done: loss 0.0798 - lr 0.0000038
2021-06-22 10:24:21,244 DEV : loss 0.17919376492500305 - score 0.9848
2021-06-22 10:24:21,265 BAD EPOCHS (no improvement): 3
2021-06-22 10:24:21,266 ----------------------------------------------------------------------------------------------------
2021-06-22 10:24:24,160 epoch 30 - iter 6/64 - loss 0.08731560 - samples/sec: 66.35 - lr: 0.000004
2021-06-22 10:24:27,032 epoch 30 - iter 12/64 - loss 0.10441633 - samples/sec: 66.86 - lr: 0.000004
2021-06-22 10:24:29,937 epoch 30 - iter 18/64 - loss 0.09367278 - samples/sec: 66.13 - lr: 0.000004
2021-06-22 10:24:32,807 epoch 30 - iter 24/64 - loss 0.09598923 - samples/sec: 66.91 - lr: 0.000004
2021-06-22 10:24:35,701 epoch 30 - iter 30/64 - loss 0.09616562 - samples/sec: 66.35 - lr: 0.000004
2021-06-22 10:24:38,603 epoch 30 - iter 36/64 - loss 0.09424881 - samples/sec: 66.19 - lr: 0.000004
2021-06-22 10:24:41,482 epoch 30 - iter 42/64 - loss 0.08874484 - samples/sec: 66.69 - lr: 0.000004
2021-06-22 10:24:44,369 epoch 30 - iter 48/64 - loss 0.08503913 - samples/sec: 66.53 - lr: 0.000004
2021-06-22 10:24:47,254 epoch 30 - iter 54/64 - loss 0.08251671 - samples/sec: 66.56 - lr: 0.000004
2021-06-22 10:24:50,125 epoch 30 - iter 60/64 - loss 0.08099185 - samples/sec: 66.90 - lr: 0.000004
2021-06-22 10:24:51,810 ----------------------------------------------------------------------------------------------------
2021-06-22 10:24:51,810 EPOCH 30 done: loss 0.0832 - lr 0.0000038
2021-06-22 10:24:53,249 DEV : loss 0.17887914180755615 - score 0.9848
Epoch    30: reducing learning rate of group 0 to 1.8750e-06.
2021-06-22 10:24:53,270 BAD EPOCHS (no improvement): 4
2021-06-22 10:24:53,270 ----------------------------------------------------------------------------------------------------
2021-06-22 10:24:53,270 ----------------------------------------------------------------------------------------------------
2021-06-22 10:24:53,270 learning rate too small - quitting training!
2021-06-22 10:24:53,270 ----------------------------------------------------------------------------------------------------
2021-06-22 10:24:53,683 ----------------------------------------------------------------------------------------------------
2021-06-22 10:24:53,683 Testing using best model ...
2021-06-22 10:24:53,683 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/best-model.pt
2021-06-22 10:24:57,542 0.9840	1.0000	0.9919
2021-06-22 10:24:57,542 
Results:
- F1-score (micro) 0.9919
- F1-score (macro) 0.9919

By class:
SENT       tp: 123 - fp: 2 - fn: 0 - precision: 0.9840 - recall: 1.0000 - f1-score: 0.9919
2021-06-22 10:24:57,542 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/
2021-06-22 10:24:57,559 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb
2021-06-22 10:24:57,559 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/sent_train.txt
2021-06-22 10:24:57,561 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/sent_dev.txt
2021-06-22 10:24:57,563 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/sent_test.txt
Corpus: 18701 train + 2362 dev + 2245 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 10:25:22,719 ----------------------------------------------------------------------------------------------------
2021-06-22 10:25:22,721 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(32000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 10:25:22,721 ----------------------------------------------------------------------------------------------------
2021-06-22 10:25:22,721 Corpus: "Corpus: 18701 train + 2362 dev + 2245 test sentences"
2021-06-22 10:25:22,721 ----------------------------------------------------------------------------------------------------
2021-06-22 10:25:22,721 Parameters:
2021-06-22 10:25:22,722  - learning_rate: "3e-05"
2021-06-22 10:25:22,722  - mini_batch_size: "32"
2021-06-22 10:25:22,722  - patience: "3"
2021-06-22 10:25:22,722  - anneal_factor: "0.5"
2021-06-22 10:25:22,722  - max_epochs: "40"
2021-06-22 10:25:22,722  - shuffle: "True"
2021-06-22 10:25:22,722  - train_with_dev: "False"
2021-06-22 10:25:22,722  - batch_growth_annealing: "False"
2021-06-22 10:25:22,722 ----------------------------------------------------------------------------------------------------
2021-06-22 10:25:22,722 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb"
2021-06-22 10:25:22,722 ----------------------------------------------------------------------------------------------------
2021-06-22 10:25:22,722 Device: cuda:0
2021-06-22 10:25:22,722 ----------------------------------------------------------------------------------------------------
2021-06-22 10:25:22,722 Embeddings storage mode: cpu
2021-06-22 10:25:22,723 ----------------------------------------------------------------------------------------------------
2021-06-22 10:26:19,699 epoch 1 - iter 58/585 - loss 5.62748093 - samples/sec: 32.58 - lr: 0.000030
2021-06-22 10:27:16,153 epoch 1 - iter 116/585 - loss 3.68640669 - samples/sec: 32.88 - lr: 0.000030
2021-06-22 10:28:15,166 epoch 1 - iter 174/585 - loss 2.83324107 - samples/sec: 31.45 - lr: 0.000030
2021-06-22 10:29:15,603 epoch 1 - iter 232/585 - loss 2.36192057 - samples/sec: 30.71 - lr: 0.000030
2021-06-22 10:30:15,084 epoch 1 - iter 290/585 - loss 2.05233369 - samples/sec: 31.20 - lr: 0.000030
2021-06-22 10:31:14,478 epoch 1 - iter 348/585 - loss 1.82634007 - samples/sec: 31.25 - lr: 0.000030
2021-06-22 10:32:13,853 epoch 1 - iter 406/585 - loss 1.66159499 - samples/sec: 31.26 - lr: 0.000030
2021-06-22 10:33:13,207 epoch 1 - iter 464/585 - loss 1.52963161 - samples/sec: 31.27 - lr: 0.000030
2021-06-22 10:34:12,604 epoch 1 - iter 522/585 - loss 1.42922070 - samples/sec: 31.25 - lr: 0.000030
2021-06-22 10:35:11,887 epoch 1 - iter 580/585 - loss 1.34212283 - samples/sec: 31.31 - lr: 0.000030
2021-06-22 10:35:16,406 ----------------------------------------------------------------------------------------------------
2021-06-22 10:35:16,407 EPOCH 1 done: loss 1.3350 - lr 0.0000300
2021-06-22 10:35:59,353 DEV : loss 0.41054487228393555 - score 0.9507
2021-06-22 10:35:59,532 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:35:59,981 ----------------------------------------------------------------------------------------------------
2021-06-22 10:36:29,522 epoch 2 - iter 58/585 - loss 0.51412655 - samples/sec: 62.84 - lr: 0.000030
2021-06-22 10:36:59,033 epoch 2 - iter 116/585 - loss 0.51128633 - samples/sec: 62.90 - lr: 0.000030
2021-06-22 10:37:28,626 epoch 2 - iter 174/585 - loss 0.48723717 - samples/sec: 62.72 - lr: 0.000030
2021-06-22 10:37:58,198 epoch 2 - iter 232/585 - loss 0.49628617 - samples/sec: 62.77 - lr: 0.000030
2021-06-22 10:38:27,726 epoch 2 - iter 290/585 - loss 0.48818412 - samples/sec: 62.86 - lr: 0.000030
2021-06-22 10:38:57,266 epoch 2 - iter 348/585 - loss 0.48493106 - samples/sec: 62.84 - lr: 0.000030
2021-06-22 10:39:26,765 epoch 2 - iter 406/585 - loss 0.48018854 - samples/sec: 62.92 - lr: 0.000030
2021-06-22 10:39:56,260 epoch 2 - iter 464/585 - loss 0.47200110 - samples/sec: 62.93 - lr: 0.000030
2021-06-22 10:40:25,803 epoch 2 - iter 522/585 - loss 0.46352434 - samples/sec: 62.83 - lr: 0.000030
2021-06-22 10:40:55,290 epoch 2 - iter 580/585 - loss 0.45573825 - samples/sec: 62.95 - lr: 0.000030
2021-06-22 10:40:57,568 ----------------------------------------------------------------------------------------------------
2021-06-22 10:40:57,569 EPOCH 2 done: loss 0.4546 - lr 0.0000300
2021-06-22 10:41:10,055 DEV : loss 0.3411041796207428 - score 0.957
2021-06-22 10:41:10,231 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:41:14,892 ----------------------------------------------------------------------------------------------------
2021-06-22 10:41:44,110 epoch 3 - iter 58/585 - loss 0.37085783 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 10:42:13,333 epoch 3 - iter 116/585 - loss 0.36262192 - samples/sec: 63.52 - lr: 0.000030
2021-06-22 10:42:42,678 epoch 3 - iter 174/585 - loss 0.36988044 - samples/sec: 63.25 - lr: 0.000030
2021-06-22 10:43:12,114 epoch 3 - iter 232/585 - loss 0.36679630 - samples/sec: 63.06 - lr: 0.000030
2021-06-22 10:43:41,606 epoch 3 - iter 290/585 - loss 0.36793432 - samples/sec: 62.94 - lr: 0.000030
2021-06-22 10:44:11,105 epoch 3 - iter 348/585 - loss 0.36439481 - samples/sec: 62.92 - lr: 0.000030
2021-06-22 10:44:40,590 epoch 3 - iter 406/585 - loss 0.36586767 - samples/sec: 62.95 - lr: 0.000030
2021-06-22 10:45:10,027 epoch 3 - iter 464/585 - loss 0.37122301 - samples/sec: 63.06 - lr: 0.000030
2021-06-22 10:45:39,492 epoch 3 - iter 522/585 - loss 0.36883530 - samples/sec: 63.00 - lr: 0.000030
2021-06-22 10:46:08,857 epoch 3 - iter 580/585 - loss 0.37159945 - samples/sec: 63.21 - lr: 0.000030
2021-06-22 10:46:11,129 ----------------------------------------------------------------------------------------------------
2021-06-22 10:46:11,130 EPOCH 3 done: loss 0.3721 - lr 0.0000300
2021-06-22 10:46:23,500 DEV : loss 0.30418524146080017 - score 0.9611
2021-06-22 10:46:23,676 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:46:28,309 ----------------------------------------------------------------------------------------------------
2021-06-22 10:46:57,620 epoch 4 - iter 58/585 - loss 0.33756815 - samples/sec: 63.33 - lr: 0.000030
2021-06-22 10:47:26,887 epoch 4 - iter 116/585 - loss 0.33978575 - samples/sec: 63.42 - lr: 0.000030
2021-06-22 10:47:56,157 epoch 4 - iter 174/585 - loss 0.33746686 - samples/sec: 63.42 - lr: 0.000030
2021-06-22 10:48:25,462 epoch 4 - iter 232/585 - loss 0.34331910 - samples/sec: 63.34 - lr: 0.000030
2021-06-22 10:48:54,695 epoch 4 - iter 290/585 - loss 0.34283904 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 10:49:23,992 epoch 4 - iter 348/585 - loss 0.34044919 - samples/sec: 63.36 - lr: 0.000030
2021-06-22 10:49:53,297 epoch 4 - iter 406/585 - loss 0.33493197 - samples/sec: 63.34 - lr: 0.000030
2021-06-22 10:50:22,515 epoch 4 - iter 464/585 - loss 0.32993279 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 10:50:51,759 epoch 4 - iter 522/585 - loss 0.32863245 - samples/sec: 63.47 - lr: 0.000030
2021-06-22 10:51:21,125 epoch 4 - iter 580/585 - loss 0.32884749 - samples/sec: 63.21 - lr: 0.000030
2021-06-22 10:51:23,383 ----------------------------------------------------------------------------------------------------
2021-06-22 10:51:23,383 EPOCH 4 done: loss 0.3294 - lr 0.0000300
2021-06-22 10:51:37,081 DEV : loss 0.2896363437175751 - score 0.9621
2021-06-22 10:51:37,258 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:51:42,115 ----------------------------------------------------------------------------------------------------
2021-06-22 10:52:11,224 epoch 5 - iter 58/585 - loss 0.31455523 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 10:52:40,347 epoch 5 - iter 116/585 - loss 0.31379309 - samples/sec: 63.73 - lr: 0.000030
2021-06-22 10:53:09,565 epoch 5 - iter 174/585 - loss 0.30643142 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 10:53:38,706 epoch 5 - iter 232/585 - loss 0.30035614 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 10:54:07,797 epoch 5 - iter 290/585 - loss 0.29744153 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 10:54:36,937 epoch 5 - iter 348/585 - loss 0.29426715 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 10:55:06,078 epoch 5 - iter 406/585 - loss 0.29186653 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 10:55:35,155 epoch 5 - iter 464/585 - loss 0.28968967 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 10:56:04,232 epoch 5 - iter 522/585 - loss 0.29071603 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 10:56:33,324 epoch 5 - iter 580/585 - loss 0.29366422 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 10:56:35,572 ----------------------------------------------------------------------------------------------------
2021-06-22 10:56:35,573 EPOCH 5 done: loss 0.2936 - lr 0.0000300
2021-06-22 10:56:48,001 DEV : loss 0.2762416899204254 - score 0.9647
2021-06-22 10:56:48,178 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 10:56:53,029 ----------------------------------------------------------------------------------------------------
2021-06-22 10:57:22,147 epoch 6 - iter 58/585 - loss 0.27233620 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 10:57:51,304 epoch 6 - iter 116/585 - loss 0.28611315 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 10:58:20,447 epoch 6 - iter 174/585 - loss 0.28049409 - samples/sec: 63.69 - lr: 0.000030
2021-06-22 10:58:49,496 epoch 6 - iter 232/585 - loss 0.27129977 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 10:59:18,583 epoch 6 - iter 290/585 - loss 0.27467582 - samples/sec: 63.82 - lr: 0.000030
2021-06-22 10:59:47,763 epoch 6 - iter 348/585 - loss 0.27266800 - samples/sec: 63.61 - lr: 0.000030
2021-06-22 11:00:16,916 epoch 6 - iter 406/585 - loss 0.27264808 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 11:00:45,977 epoch 6 - iter 464/585 - loss 0.27419034 - samples/sec: 63.87 - lr: 0.000030
2021-06-22 11:01:15,011 epoch 6 - iter 522/585 - loss 0.27594094 - samples/sec: 63.93 - lr: 0.000030
2021-06-22 11:01:44,035 epoch 6 - iter 580/585 - loss 0.27232106 - samples/sec: 63.95 - lr: 0.000030
2021-06-22 11:01:46,278 ----------------------------------------------------------------------------------------------------
2021-06-22 11:01:46,278 EPOCH 6 done: loss 0.2725 - lr 0.0000300
2021-06-22 11:01:58,721 DEV : loss 0.27614012360572815 - score 0.9635
2021-06-22 11:01:58,898 BAD EPOCHS (no improvement): 1
2021-06-22 11:01:58,899 ----------------------------------------------------------------------------------------------------
2021-06-22 11:02:27,947 epoch 7 - iter 58/585 - loss 0.26165084 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 11:02:57,028 epoch 7 - iter 116/585 - loss 0.27168719 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 11:03:26,006 epoch 7 - iter 174/585 - loss 0.26041721 - samples/sec: 64.06 - lr: 0.000030
2021-06-22 11:03:55,002 epoch 7 - iter 232/585 - loss 0.26171159 - samples/sec: 64.01 - lr: 0.000030
2021-06-22 11:04:24,046 epoch 7 - iter 290/585 - loss 0.25674350 - samples/sec: 63.91 - lr: 0.000030
2021-06-22 11:04:53,152 epoch 7 - iter 348/585 - loss 0.25997869 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 11:05:22,203 epoch 7 - iter 406/585 - loss 0.26078861 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 11:05:51,216 epoch 7 - iter 464/585 - loss 0.25714041 - samples/sec: 63.98 - lr: 0.000030
2021-06-22 11:06:20,240 epoch 7 - iter 522/585 - loss 0.25891515 - samples/sec: 63.95 - lr: 0.000030
2021-06-22 11:06:49,265 epoch 7 - iter 580/585 - loss 0.25972816 - samples/sec: 63.95 - lr: 0.000030
2021-06-22 11:06:51,489 ----------------------------------------------------------------------------------------------------
2021-06-22 11:06:51,489 EPOCH 7 done: loss 0.2605 - lr 0.0000300
2021-06-22 11:07:05,229 DEV : loss 0.2731574475765228 - score 0.9628
2021-06-22 11:07:05,407 BAD EPOCHS (no improvement): 2
2021-06-22 11:07:05,407 ----------------------------------------------------------------------------------------------------
2021-06-22 11:07:34,478 epoch 8 - iter 58/585 - loss 0.23450087 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 11:08:03,613 epoch 8 - iter 116/585 - loss 0.24515016 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 11:08:32,660 epoch 8 - iter 174/585 - loss 0.24327552 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 11:09:01,594 epoch 8 - iter 232/585 - loss 0.24516820 - samples/sec: 64.15 - lr: 0.000030
2021-06-22 11:09:30,661 epoch 8 - iter 290/585 - loss 0.23924804 - samples/sec: 63.86 - lr: 0.000030
2021-06-22 11:09:59,691 epoch 8 - iter 348/585 - loss 0.24274061 - samples/sec: 63.94 - lr: 0.000030
2021-06-22 11:10:28,795 epoch 8 - iter 406/585 - loss 0.24422015 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 11:10:57,905 epoch 8 - iter 464/585 - loss 0.24766682 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 11:11:27,041 epoch 8 - iter 522/585 - loss 0.24608825 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 11:11:56,171 epoch 8 - iter 580/585 - loss 0.24790705 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 11:11:58,411 ----------------------------------------------------------------------------------------------------
2021-06-22 11:11:58,411 EPOCH 8 done: loss 0.2474 - lr 0.0000300
2021-06-22 11:12:10,798 DEV : loss 0.26851609349250793 - score 0.9652
2021-06-22 11:12:10,981 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 11:12:15,839 ----------------------------------------------------------------------------------------------------
2021-06-22 11:12:45,005 epoch 9 - iter 58/585 - loss 0.23769567 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 11:13:14,125 epoch 9 - iter 116/585 - loss 0.23052146 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 11:13:43,213 epoch 9 - iter 174/585 - loss 0.22765113 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 11:14:12,310 epoch 9 - iter 232/585 - loss 0.22505027 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 11:14:41,451 epoch 9 - iter 290/585 - loss 0.22909358 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 11:15:10,594 epoch 9 - iter 348/585 - loss 0.22943633 - samples/sec: 63.69 - lr: 0.000030
2021-06-22 11:15:39,684 epoch 9 - iter 406/585 - loss 0.23048514 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 11:16:08,748 epoch 9 - iter 464/585 - loss 0.22958229 - samples/sec: 63.87 - lr: 0.000030
2021-06-22 11:16:37,770 epoch 9 - iter 522/585 - loss 0.23067793 - samples/sec: 63.96 - lr: 0.000030
2021-06-22 11:17:06,894 epoch 9 - iter 580/585 - loss 0.22852865 - samples/sec: 63.73 - lr: 0.000030
2021-06-22 11:17:09,141 ----------------------------------------------------------------------------------------------------
2021-06-22 11:17:09,141 EPOCH 9 done: loss 0.2289 - lr 0.0000300
2021-06-22 11:17:21,520 DEV : loss 0.2674693465232849 - score 0.9649
2021-06-22 11:17:21,698 BAD EPOCHS (no improvement): 1
2021-06-22 11:17:21,698 ----------------------------------------------------------------------------------------------------
2021-06-22 11:17:50,716 epoch 10 - iter 58/585 - loss 0.20558993 - samples/sec: 63.97 - lr: 0.000030
2021-06-22 11:18:19,794 epoch 10 - iter 116/585 - loss 0.19762566 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 11:18:48,818 epoch 10 - iter 174/585 - loss 0.20593531 - samples/sec: 63.95 - lr: 0.000030
2021-06-22 11:19:17,876 epoch 10 - iter 232/585 - loss 0.21109353 - samples/sec: 63.88 - lr: 0.000030
2021-06-22 11:19:47,029 epoch 10 - iter 290/585 - loss 0.20981292 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 11:20:16,194 epoch 10 - iter 348/585 - loss 0.20976450 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 11:20:45,299 epoch 10 - iter 406/585 - loss 0.21616950 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 11:21:14,484 epoch 10 - iter 464/585 - loss 0.21465691 - samples/sec: 63.60 - lr: 0.000030
2021-06-22 11:21:43,653 epoch 10 - iter 522/585 - loss 0.21420558 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 11:22:12,743 epoch 10 - iter 580/585 - loss 0.21563781 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 11:22:14,991 ----------------------------------------------------------------------------------------------------
2021-06-22 11:22:14,991 EPOCH 10 done: loss 0.2154 - lr 0.0000300
2021-06-22 11:22:27,356 DEV : loss 0.2597463130950928 - score 0.9665
2021-06-22 11:22:27,535 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 11:22:32,691 ----------------------------------------------------------------------------------------------------
2021-06-22 11:23:01,720 epoch 11 - iter 58/585 - loss 0.21300189 - samples/sec: 63.94 - lr: 0.000030
2021-06-22 11:23:30,800 epoch 11 - iter 116/585 - loss 0.21274824 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 11:23:59,910 epoch 11 - iter 174/585 - loss 0.20908869 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 11:24:28,805 epoch 11 - iter 232/585 - loss 0.21236066 - samples/sec: 64.24 - lr: 0.000030
2021-06-22 11:24:57,305 epoch 11 - iter 290/585 - loss 0.21025099 - samples/sec: 65.13 - lr: 0.000030
2021-06-22 11:25:26,119 epoch 11 - iter 348/585 - loss 0.20742950 - samples/sec: 64.42 - lr: 0.000030
2021-06-22 11:25:55,187 epoch 11 - iter 406/585 - loss 0.20639892 - samples/sec: 63.86 - lr: 0.000030
2021-06-22 11:26:24,351 epoch 11 - iter 464/585 - loss 0.20634877 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 11:26:53,433 epoch 11 - iter 522/585 - loss 0.20656545 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 11:27:22,447 epoch 11 - iter 580/585 - loss 0.20664135 - samples/sec: 63.98 - lr: 0.000030
2021-06-22 11:27:24,701 ----------------------------------------------------------------------------------------------------
2021-06-22 11:27:24,702 EPOCH 11 done: loss 0.2066 - lr 0.0000300
2021-06-22 11:27:38,452 DEV : loss 0.2665199935436249 - score 0.965
2021-06-22 11:27:38,631 BAD EPOCHS (no improvement): 1
2021-06-22 11:27:38,631 ----------------------------------------------------------------------------------------------------
2021-06-22 11:28:07,744 epoch 12 - iter 58/585 - loss 0.22018239 - samples/sec: 63.76 - lr: 0.000030
2021-06-22 11:28:36,839 epoch 12 - iter 116/585 - loss 0.20628717 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 11:29:05,964 epoch 12 - iter 174/585 - loss 0.19707571 - samples/sec: 63.73 - lr: 0.000030
2021-06-22 11:29:35,081 epoch 12 - iter 232/585 - loss 0.19857255 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 11:30:04,286 epoch 12 - iter 290/585 - loss 0.19890419 - samples/sec: 63.56 - lr: 0.000030
2021-06-22 11:30:33,302 epoch 12 - iter 348/585 - loss 0.19829406 - samples/sec: 63.97 - lr: 0.000030
2021-06-22 11:31:02,312 epoch 12 - iter 406/585 - loss 0.19878560 - samples/sec: 63.98 - lr: 0.000030
2021-06-22 11:31:31,396 epoch 12 - iter 464/585 - loss 0.19772396 - samples/sec: 63.82 - lr: 0.000030
2021-06-22 11:32:00,457 epoch 12 - iter 522/585 - loss 0.19777873 - samples/sec: 63.87 - lr: 0.000030
2021-06-22 11:32:29,537 epoch 12 - iter 580/585 - loss 0.19711594 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 11:32:31,793 ----------------------------------------------------------------------------------------------------
2021-06-22 11:32:31,793 EPOCH 12 done: loss 0.1974 - lr 0.0000300
2021-06-22 11:32:44,167 DEV : loss 0.2620196044445038 - score 0.9652
2021-06-22 11:32:44,343 BAD EPOCHS (no improvement): 2
2021-06-22 11:32:44,343 ----------------------------------------------------------------------------------------------------
2021-06-22 11:33:13,324 epoch 13 - iter 58/585 - loss 0.15963615 - samples/sec: 64.05 - lr: 0.000030
2021-06-22 11:33:42,429 epoch 13 - iter 116/585 - loss 0.17814889 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 11:34:11,530 epoch 13 - iter 174/585 - loss 0.18573094 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 11:34:40,667 epoch 13 - iter 232/585 - loss 0.18478148 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 11:35:09,784 epoch 13 - iter 290/585 - loss 0.18766090 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 11:35:38,937 epoch 13 - iter 348/585 - loss 0.18750886 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 11:36:08,049 epoch 13 - iter 406/585 - loss 0.18796235 - samples/sec: 63.76 - lr: 0.000030
2021-06-22 11:36:37,148 epoch 13 - iter 464/585 - loss 0.18794334 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 11:37:06,206 epoch 13 - iter 522/585 - loss 0.19102328 - samples/sec: 63.88 - lr: 0.000030
2021-06-22 11:37:35,316 epoch 13 - iter 580/585 - loss 0.19078460 - samples/sec: 63.76 - lr: 0.000030
2021-06-22 11:37:37,563 ----------------------------------------------------------------------------------------------------
2021-06-22 11:37:37,563 EPOCH 13 done: loss 0.1904 - lr 0.0000300
2021-06-22 11:37:49,935 DEV : loss 0.2586125433444977 - score 0.9673
2021-06-22 11:37:50,115 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 11:37:54,868 ----------------------------------------------------------------------------------------------------
2021-06-22 11:38:24,055 epoch 14 - iter 58/585 - loss 0.14490856 - samples/sec: 63.60 - lr: 0.000030
2021-06-22 11:38:53,077 epoch 14 - iter 116/585 - loss 0.16763018 - samples/sec: 63.96 - lr: 0.000030
2021-06-22 11:39:22,018 epoch 14 - iter 174/585 - loss 0.16997630 - samples/sec: 64.14 - lr: 0.000030
2021-06-22 11:39:51,100 epoch 14 - iter 232/585 - loss 0.17551721 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 11:40:20,173 epoch 14 - iter 290/585 - loss 0.17521690 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 11:40:49,280 epoch 14 - iter 348/585 - loss 0.17729101 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 11:41:18,334 epoch 14 - iter 406/585 - loss 0.17841819 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 11:41:47,432 epoch 14 - iter 464/585 - loss 0.17774913 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 11:42:16,548 epoch 14 - iter 522/585 - loss 0.17729735 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 11:42:45,601 epoch 14 - iter 580/585 - loss 0.17746086 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 11:42:47,843 ----------------------------------------------------------------------------------------------------
2021-06-22 11:42:47,844 EPOCH 14 done: loss 0.1784 - lr 0.0000300
2021-06-22 11:43:00,244 DEV : loss 0.2633507549762726 - score 0.9662
2021-06-22 11:43:00,422 BAD EPOCHS (no improvement): 1
2021-06-22 11:43:00,423 ----------------------------------------------------------------------------------------------------
2021-06-22 11:43:29,475 epoch 15 - iter 58/585 - loss 0.17162305 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 11:43:58,598 epoch 15 - iter 116/585 - loss 0.16549266 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 11:44:27,732 epoch 15 - iter 174/585 - loss 0.16407275 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 11:44:56,847 epoch 15 - iter 232/585 - loss 0.16878863 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 11:45:26,046 epoch 15 - iter 290/585 - loss 0.17018761 - samples/sec: 63.57 - lr: 0.000030
2021-06-22 11:45:55,166 epoch 15 - iter 348/585 - loss 0.17171590 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 11:46:24,304 epoch 15 - iter 406/585 - loss 0.16845635 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 11:46:53,413 epoch 15 - iter 464/585 - loss 0.16713998 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 11:47:22,519 epoch 15 - iter 522/585 - loss 0.16783145 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 11:47:51,680 epoch 15 - iter 580/585 - loss 0.16659101 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 11:47:53,932 ----------------------------------------------------------------------------------------------------
2021-06-22 11:47:53,933 EPOCH 15 done: loss 0.1668 - lr 0.0000300
2021-06-22 11:48:07,614 DEV : loss 0.26242321729660034 - score 0.9648
2021-06-22 11:48:07,793 BAD EPOCHS (no improvement): 2
2021-06-22 11:48:07,793 ----------------------------------------------------------------------------------------------------
2021-06-22 11:48:36,909 epoch 16 - iter 58/585 - loss 0.16673301 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 11:49:05,991 epoch 16 - iter 116/585 - loss 0.17098625 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 11:49:35,113 epoch 16 - iter 174/585 - loss 0.17474534 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 11:50:04,088 epoch 16 - iter 232/585 - loss 0.16708807 - samples/sec: 64.06 - lr: 0.000030
2021-06-22 11:50:33,193 epoch 16 - iter 290/585 - loss 0.16726675 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 11:51:02,308 epoch 16 - iter 348/585 - loss 0.16384722 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 11:51:31,446 epoch 16 - iter 406/585 - loss 0.16213250 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 11:52:00,481 epoch 16 - iter 464/585 - loss 0.16256998 - samples/sec: 63.93 - lr: 0.000030
2021-06-22 11:52:29,637 epoch 16 - iter 522/585 - loss 0.16291535 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 11:52:58,790 epoch 16 - iter 580/585 - loss 0.16572171 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 11:53:01,032 ----------------------------------------------------------------------------------------------------
2021-06-22 11:53:01,032 EPOCH 16 done: loss 0.1660 - lr 0.0000300
2021-06-22 11:53:13,405 DEV : loss 0.2599959373474121 - score 0.9678
2021-06-22 11:53:13,585 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 11:53:18,430 ----------------------------------------------------------------------------------------------------
2021-06-22 11:53:47,659 epoch 17 - iter 58/585 - loss 0.14317084 - samples/sec: 63.61 - lr: 0.000030
2021-06-22 11:54:16,730 epoch 17 - iter 116/585 - loss 0.14548383 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 11:54:45,861 epoch 17 - iter 174/585 - loss 0.15010450 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 11:55:14,983 epoch 17 - iter 232/585 - loss 0.15563763 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 11:55:44,053 epoch 17 - iter 290/585 - loss 0.15614351 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 11:56:13,173 epoch 17 - iter 348/585 - loss 0.15271612 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 11:56:42,269 epoch 17 - iter 406/585 - loss 0.15500859 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 11:57:11,403 epoch 17 - iter 464/585 - loss 0.15565854 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 11:57:40,552 epoch 17 - iter 522/585 - loss 0.15492130 - samples/sec: 63.68 - lr: 0.000030
2021-06-22 11:58:09,669 epoch 17 - iter 580/585 - loss 0.15358384 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 11:58:11,904 ----------------------------------------------------------------------------------------------------
2021-06-22 11:58:11,904 EPOCH 17 done: loss 0.1536 - lr 0.0000300
2021-06-22 11:58:24,290 DEV : loss 0.260162889957428 - score 0.9674
2021-06-22 11:58:24,470 BAD EPOCHS (no improvement): 1
2021-06-22 11:58:24,471 ----------------------------------------------------------------------------------------------------
2021-06-22 11:58:53,578 epoch 18 - iter 58/585 - loss 0.14297661 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 11:59:22,715 epoch 18 - iter 116/585 - loss 0.15294740 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 11:59:51,867 epoch 18 - iter 174/585 - loss 0.14633468 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 12:00:20,989 epoch 18 - iter 232/585 - loss 0.14668779 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 12:00:50,077 epoch 18 - iter 290/585 - loss 0.14972478 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 12:01:19,146 epoch 18 - iter 348/585 - loss 0.14870373 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 12:01:48,294 epoch 18 - iter 406/585 - loss 0.14932680 - samples/sec: 63.68 - lr: 0.000030
2021-06-22 12:02:17,509 epoch 18 - iter 464/585 - loss 0.15080795 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 12:02:46,626 epoch 18 - iter 522/585 - loss 0.15152104 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 12:03:15,748 epoch 18 - iter 580/585 - loss 0.15080371 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 12:03:17,991 ----------------------------------------------------------------------------------------------------
2021-06-22 12:03:17,991 EPOCH 18 done: loss 0.1508 - lr 0.0000300
2021-06-22 12:03:31,674 DEV : loss 0.26315805315971375 - score 0.9677
2021-06-22 12:03:31,853 BAD EPOCHS (no improvement): 2
2021-06-22 12:03:31,853 ----------------------------------------------------------------------------------------------------
2021-06-22 12:04:01,030 epoch 19 - iter 58/585 - loss 0.11314079 - samples/sec: 63.62 - lr: 0.000030
2021-06-22 12:04:30,128 epoch 19 - iter 116/585 - loss 0.13502381 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 12:04:59,243 epoch 19 - iter 174/585 - loss 0.13906631 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 12:05:28,298 epoch 19 - iter 232/585 - loss 0.14034813 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 12:05:57,394 epoch 19 - iter 290/585 - loss 0.14168465 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 12:06:26,499 epoch 19 - iter 348/585 - loss 0.14198159 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 12:06:55,660 epoch 19 - iter 406/585 - loss 0.14460691 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 12:07:24,735 epoch 19 - iter 464/585 - loss 0.14576948 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 12:07:53,762 epoch 19 - iter 522/585 - loss 0.14484602 - samples/sec: 63.95 - lr: 0.000030
2021-06-22 12:08:22,956 epoch 19 - iter 580/585 - loss 0.14499979 - samples/sec: 63.58 - lr: 0.000030
2021-06-22 12:08:25,199 ----------------------------------------------------------------------------------------------------
2021-06-22 12:08:25,199 EPOCH 19 done: loss 0.1451 - lr 0.0000300
2021-06-22 12:08:37,567 DEV : loss 0.2627330720424652 - score 0.9672
2021-06-22 12:08:37,745 BAD EPOCHS (no improvement): 3
2021-06-22 12:08:37,745 ----------------------------------------------------------------------------------------------------
2021-06-22 12:09:06,935 epoch 20 - iter 58/585 - loss 0.12102070 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 12:09:36,025 epoch 20 - iter 116/585 - loss 0.12735138 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 12:10:05,197 epoch 20 - iter 174/585 - loss 0.13596114 - samples/sec: 63.63 - lr: 0.000030
2021-06-22 12:10:34,381 epoch 20 - iter 232/585 - loss 0.14230508 - samples/sec: 63.60 - lr: 0.000030
2021-06-22 12:11:03,539 epoch 20 - iter 290/585 - loss 0.13973112 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 12:11:32,700 epoch 20 - iter 348/585 - loss 0.14250717 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 12:12:01,776 epoch 20 - iter 406/585 - loss 0.14127978 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 12:12:30,811 epoch 20 - iter 464/585 - loss 0.14159298 - samples/sec: 63.93 - lr: 0.000030
2021-06-22 12:12:59,954 epoch 20 - iter 522/585 - loss 0.14006747 - samples/sec: 63.69 - lr: 0.000030
2021-06-22 12:13:29,126 epoch 20 - iter 580/585 - loss 0.13898105 - samples/sec: 63.63 - lr: 0.000030
2021-06-22 12:13:31,372 ----------------------------------------------------------------------------------------------------
2021-06-22 12:13:31,372 EPOCH 20 done: loss 0.1389 - lr 0.0000300
2021-06-22 12:13:43,754 DEV : loss 0.26047950983047485 - score 0.9679
2021-06-22 12:13:43,936 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 12:13:48,559 ----------------------------------------------------------------------------------------------------
2021-06-22 12:14:17,703 epoch 21 - iter 58/585 - loss 0.14652806 - samples/sec: 63.69 - lr: 0.000030
2021-06-22 12:14:46,874 epoch 21 - iter 116/585 - loss 0.12935116 - samples/sec: 63.63 - lr: 0.000030
2021-06-22 12:15:15,999 epoch 21 - iter 174/585 - loss 0.13510095 - samples/sec: 63.73 - lr: 0.000030
2021-06-22 12:15:45,188 epoch 21 - iter 232/585 - loss 0.13744322 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 12:16:14,329 epoch 21 - iter 290/585 - loss 0.13592802 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 12:16:43,415 epoch 21 - iter 348/585 - loss 0.13766302 - samples/sec: 63.82 - lr: 0.000030
2021-06-22 12:17:12,532 epoch 21 - iter 406/585 - loss 0.13523942 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 12:17:41,605 epoch 21 - iter 464/585 - loss 0.13659174 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 12:18:10,766 epoch 21 - iter 522/585 - loss 0.13678399 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 12:18:39,853 epoch 21 - iter 580/585 - loss 0.13624296 - samples/sec: 63.82 - lr: 0.000030
2021-06-22 12:18:42,104 ----------------------------------------------------------------------------------------------------
2021-06-22 12:18:42,104 EPOCH 21 done: loss 0.1364 - lr 0.0000300
2021-06-22 12:18:54,508 DEV : loss 0.2652275264263153 - score 0.9664
2021-06-22 12:18:54,688 BAD EPOCHS (no improvement): 1
2021-06-22 12:18:54,688 ----------------------------------------------------------------------------------------------------
2021-06-22 12:19:23,859 epoch 22 - iter 58/585 - loss 0.12660475 - samples/sec: 63.63 - lr: 0.000030
2021-06-22 12:19:53,054 epoch 22 - iter 116/585 - loss 0.12551181 - samples/sec: 63.58 - lr: 0.000030
2021-06-22 12:20:22,208 epoch 22 - iter 174/585 - loss 0.12521780 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 12:20:51,368 epoch 22 - iter 232/585 - loss 0.12094031 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 12:21:20,635 epoch 22 - iter 290/585 - loss 0.12115914 - samples/sec: 63.42 - lr: 0.000030
2021-06-22 12:21:51,130 epoch 22 - iter 348/585 - loss 0.11987716 - samples/sec: 60.87 - lr: 0.000030
2021-06-22 12:22:20,380 epoch 22 - iter 406/585 - loss 0.12209290 - samples/sec: 63.46 - lr: 0.000030
2021-06-22 12:22:49,569 epoch 22 - iter 464/585 - loss 0.12429266 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 12:23:18,771 epoch 22 - iter 522/585 - loss 0.12501472 - samples/sec: 63.56 - lr: 0.000030
2021-06-22 12:23:47,917 epoch 22 - iter 580/585 - loss 0.12408938 - samples/sec: 63.69 - lr: 0.000030
2021-06-22 12:23:50,164 ----------------------------------------------------------------------------------------------------
2021-06-22 12:23:50,164 EPOCH 22 done: loss 0.1241 - lr 0.0000300
2021-06-22 12:24:02,552 DEV : loss 0.2772989571094513 - score 0.9647
2021-06-22 12:24:02,732 BAD EPOCHS (no improvement): 2
2021-06-22 12:24:02,733 ----------------------------------------------------------------------------------------------------
2021-06-22 12:24:31,848 epoch 23 - iter 58/585 - loss 0.12916796 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 12:25:01,086 epoch 23 - iter 116/585 - loss 0.12210389 - samples/sec: 63.48 - lr: 0.000030
2021-06-22 12:25:30,287 epoch 23 - iter 174/585 - loss 0.12340753 - samples/sec: 63.57 - lr: 0.000030
2021-06-22 12:25:59,474 epoch 23 - iter 232/585 - loss 0.12365315 - samples/sec: 63.60 - lr: 0.000030
2021-06-22 12:26:28,651 epoch 23 - iter 290/585 - loss 0.12350829 - samples/sec: 63.62 - lr: 0.000030
2021-06-22 12:26:57,842 epoch 23 - iter 348/585 - loss 0.12026009 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 12:27:27,060 epoch 23 - iter 406/585 - loss 0.11945593 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 12:27:56,208 epoch 23 - iter 464/585 - loss 0.11909081 - samples/sec: 63.68 - lr: 0.000030
2021-06-22 12:28:25,312 epoch 23 - iter 522/585 - loss 0.12109843 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 12:28:54,545 epoch 23 - iter 580/585 - loss 0.12227419 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 12:28:56,782 ----------------------------------------------------------------------------------------------------
2021-06-22 12:28:56,783 EPOCH 23 done: loss 0.1229 - lr 0.0000300
2021-06-22 12:29:09,187 DEV : loss 0.2697562575340271 - score 0.9664
2021-06-22 12:29:09,367 BAD EPOCHS (no improvement): 3
2021-06-22 12:29:09,367 ----------------------------------------------------------------------------------------------------
2021-06-22 12:29:38,626 epoch 24 - iter 58/585 - loss 0.11090359 - samples/sec: 63.44 - lr: 0.000030
2021-06-22 12:30:07,878 epoch 24 - iter 116/585 - loss 0.10916133 - samples/sec: 63.46 - lr: 0.000030
2021-06-22 12:30:37,092 epoch 24 - iter 174/585 - loss 0.11501864 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 12:31:06,269 epoch 24 - iter 232/585 - loss 0.11596065 - samples/sec: 63.62 - lr: 0.000030
2021-06-22 12:31:35,527 epoch 24 - iter 290/585 - loss 0.11689257 - samples/sec: 63.44 - lr: 0.000030
2021-06-22 12:32:04,756 epoch 24 - iter 348/585 - loss 0.11792323 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 12:32:33,968 epoch 24 - iter 406/585 - loss 0.11853720 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 12:33:03,153 epoch 24 - iter 464/585 - loss 0.11789859 - samples/sec: 63.60 - lr: 0.000030
2021-06-22 12:33:32,416 epoch 24 - iter 522/585 - loss 0.11893744 - samples/sec: 63.43 - lr: 0.000030
2021-06-22 12:34:01,620 epoch 24 - iter 580/585 - loss 0.11834668 - samples/sec: 63.56 - lr: 0.000030
2021-06-22 12:34:03,891 ----------------------------------------------------------------------------------------------------
2021-06-22 12:34:03,891 EPOCH 24 done: loss 0.1182 - lr 0.0000300
2021-06-22 12:34:16,288 DEV : loss 0.2701869010925293 - score 0.9675
Epoch    24: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 12:34:16,469 BAD EPOCHS (no improvement): 4
2021-06-22 12:34:16,469 ----------------------------------------------------------------------------------------------------
2021-06-22 12:34:45,486 epoch 25 - iter 58/585 - loss 0.12349982 - samples/sec: 63.97 - lr: 0.000015
2021-06-22 12:35:14,669 epoch 25 - iter 116/585 - loss 0.11316467 - samples/sec: 63.61 - lr: 0.000015
2021-06-22 12:35:43,928 epoch 25 - iter 174/585 - loss 0.11315218 - samples/sec: 63.44 - lr: 0.000015
2021-06-22 12:36:13,108 epoch 25 - iter 232/585 - loss 0.10830047 - samples/sec: 63.61 - lr: 0.000015
2021-06-22 12:36:42,251 epoch 25 - iter 290/585 - loss 0.10891365 - samples/sec: 63.69 - lr: 0.000015
2021-06-22 12:37:12,868 epoch 25 - iter 348/585 - loss 0.10768778 - samples/sec: 60.63 - lr: 0.000015
2021-06-22 12:37:41,972 epoch 25 - iter 406/585 - loss 0.10750361 - samples/sec: 63.78 - lr: 0.000015
2021-06-22 12:38:11,080 epoch 25 - iter 464/585 - loss 0.10603677 - samples/sec: 63.77 - lr: 0.000015
2021-06-22 12:38:40,176 epoch 25 - iter 522/585 - loss 0.10639705 - samples/sec: 63.80 - lr: 0.000015
2021-06-22 12:39:09,376 epoch 25 - iter 580/585 - loss 0.10615028 - samples/sec: 63.57 - lr: 0.000015
2021-06-22 12:39:11,642 ----------------------------------------------------------------------------------------------------
2021-06-22 12:39:11,642 EPOCH 25 done: loss 0.1058 - lr 0.0000150
2021-06-22 12:39:24,047 DEV : loss 0.2789117395877838 - score 0.9664
2021-06-22 12:39:24,225 BAD EPOCHS (no improvement): 1
2021-06-22 12:39:24,225 ----------------------------------------------------------------------------------------------------
2021-06-22 12:39:53,507 epoch 26 - iter 58/585 - loss 0.10288675 - samples/sec: 63.39 - lr: 0.000015
2021-06-22 12:40:22,773 epoch 26 - iter 116/585 - loss 0.10194904 - samples/sec: 63.42 - lr: 0.000015
2021-06-22 12:40:52,068 epoch 26 - iter 174/585 - loss 0.10106389 - samples/sec: 63.36 - lr: 0.000015
2021-06-22 12:41:21,258 epoch 26 - iter 232/585 - loss 0.09871868 - samples/sec: 63.59 - lr: 0.000015
2021-06-22 12:41:50,576 epoch 26 - iter 290/585 - loss 0.09763817 - samples/sec: 63.31 - lr: 0.000015
2021-06-22 12:42:19,801 epoch 26 - iter 348/585 - loss 0.10003187 - samples/sec: 63.52 - lr: 0.000015
2021-06-22 12:42:49,086 epoch 26 - iter 406/585 - loss 0.09989402 - samples/sec: 63.38 - lr: 0.000015
2021-06-22 12:43:18,326 epoch 26 - iter 464/585 - loss 0.10290818 - samples/sec: 63.48 - lr: 0.000015
2021-06-22 12:43:47,597 epoch 26 - iter 522/585 - loss 0.10202426 - samples/sec: 63.41 - lr: 0.000015
2021-06-22 12:44:16,866 epoch 26 - iter 580/585 - loss 0.10273635 - samples/sec: 63.42 - lr: 0.000015
2021-06-22 12:44:19,113 ----------------------------------------------------------------------------------------------------
2021-06-22 12:44:19,113 EPOCH 26 done: loss 0.1025 - lr 0.0000150
2021-06-22 12:44:31,556 DEV : loss 0.27307429909706116 - score 0.9671
2021-06-22 12:44:31,738 BAD EPOCHS (no improvement): 2
2021-06-22 12:44:31,738 ----------------------------------------------------------------------------------------------------
2021-06-22 12:45:00,783 epoch 27 - iter 58/585 - loss 0.09265542 - samples/sec: 63.91 - lr: 0.000015
2021-06-22 12:45:29,931 epoch 27 - iter 116/585 - loss 0.09622731 - samples/sec: 63.68 - lr: 0.000015
2021-06-22 12:45:59,118 epoch 27 - iter 174/585 - loss 0.10058697 - samples/sec: 63.60 - lr: 0.000015
2021-06-22 12:46:28,154 epoch 27 - iter 232/585 - loss 0.09829276 - samples/sec: 63.93 - lr: 0.000015
2021-06-22 12:46:57,206 epoch 27 - iter 290/585 - loss 0.10009505 - samples/sec: 63.89 - lr: 0.000015
2021-06-22 12:47:26,224 epoch 27 - iter 348/585 - loss 0.09849629 - samples/sec: 63.97 - lr: 0.000015
2021-06-22 12:47:55,213 epoch 27 - iter 406/585 - loss 0.10034674 - samples/sec: 64.03 - lr: 0.000015
2021-06-22 12:48:24,258 epoch 27 - iter 464/585 - loss 0.10035761 - samples/sec: 63.91 - lr: 0.000015
2021-06-22 12:48:53,385 epoch 27 - iter 522/585 - loss 0.10028210 - samples/sec: 63.73 - lr: 0.000015
2021-06-22 12:49:22,378 epoch 27 - iter 580/585 - loss 0.10159206 - samples/sec: 64.02 - lr: 0.000015
2021-06-22 12:49:24,609 ----------------------------------------------------------------------------------------------------
2021-06-22 12:49:24,610 EPOCH 27 done: loss 0.1020 - lr 0.0000150
2021-06-22 12:49:37,044 DEV : loss 0.2778380215167999 - score 0.9668
2021-06-22 12:49:37,225 BAD EPOCHS (no improvement): 3
2021-06-22 12:49:37,225 ----------------------------------------------------------------------------------------------------
2021-06-22 12:50:06,248 epoch 28 - iter 58/585 - loss 0.09571110 - samples/sec: 63.96 - lr: 0.000015
2021-06-22 12:50:35,276 epoch 28 - iter 116/585 - loss 0.09533851 - samples/sec: 63.95 - lr: 0.000015
2021-06-22 12:51:04,297 epoch 28 - iter 174/585 - loss 0.09554044 - samples/sec: 63.96 - lr: 0.000015
2021-06-22 12:51:33,342 epoch 28 - iter 232/585 - loss 0.09691225 - samples/sec: 63.91 - lr: 0.000015
2021-06-22 12:52:02,235 epoch 28 - iter 290/585 - loss 0.09413842 - samples/sec: 64.24 - lr: 0.000015
2021-06-22 12:52:31,251 epoch 28 - iter 348/585 - loss 0.09554529 - samples/sec: 63.97 - lr: 0.000015
2021-06-22 12:53:00,266 epoch 28 - iter 406/585 - loss 0.09697943 - samples/sec: 63.97 - lr: 0.000015
2021-06-22 12:53:29,309 epoch 28 - iter 464/585 - loss 0.09760476 - samples/sec: 63.91 - lr: 0.000015
2021-06-22 12:53:58,339 epoch 28 - iter 522/585 - loss 0.09715452 - samples/sec: 63.94 - lr: 0.000015
2021-06-22 12:54:27,349 epoch 28 - iter 580/585 - loss 0.09847520 - samples/sec: 63.98 - lr: 0.000015
2021-06-22 12:54:29,588 ----------------------------------------------------------------------------------------------------
2021-06-22 12:54:29,588 EPOCH 28 done: loss 0.0983 - lr 0.0000150
2021-06-22 12:54:42,027 DEV : loss 0.28433358669281006 - score 0.9672
Epoch    28: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 12:54:42,209 BAD EPOCHS (no improvement): 4
2021-06-22 12:54:42,209 ----------------------------------------------------------------------------------------------------
2021-06-22 12:55:12,595 epoch 29 - iter 58/585 - loss 0.09109806 - samples/sec: 61.09 - lr: 0.000008
2021-06-22 12:55:41,804 epoch 29 - iter 116/585 - loss 0.09747784 - samples/sec: 63.55 - lr: 0.000008
2021-06-22 12:56:10,993 epoch 29 - iter 174/585 - loss 0.08971984 - samples/sec: 63.59 - lr: 0.000008
2021-06-22 12:56:40,120 epoch 29 - iter 232/585 - loss 0.08840123 - samples/sec: 63.73 - lr: 0.000008
2021-06-22 12:57:09,206 epoch 29 - iter 290/585 - loss 0.09173636 - samples/sec: 63.82 - lr: 0.000008
2021-06-22 12:57:38,409 epoch 29 - iter 348/585 - loss 0.09434263 - samples/sec: 63.56 - lr: 0.000008
2021-06-22 12:58:07,590 epoch 29 - iter 406/585 - loss 0.09229923 - samples/sec: 63.61 - lr: 0.000008
2021-06-22 12:58:36,731 epoch 29 - iter 464/585 - loss 0.09326810 - samples/sec: 63.70 - lr: 0.000008
2021-06-22 12:59:05,943 epoch 29 - iter 522/585 - loss 0.09259459 - samples/sec: 63.54 - lr: 0.000008
2021-06-22 12:59:35,109 epoch 29 - iter 580/585 - loss 0.09382246 - samples/sec: 63.64 - lr: 0.000008
2021-06-22 12:59:37,344 ----------------------------------------------------------------------------------------------------
2021-06-22 12:59:37,345 EPOCH 29 done: loss 0.0938 - lr 0.0000075
2021-06-22 12:59:49,763 DEV : loss 0.27888351678848267 - score 0.9671
2021-06-22 12:59:49,944 BAD EPOCHS (no improvement): 1
2021-06-22 12:59:49,944 ----------------------------------------------------------------------------------------------------
2021-06-22 13:00:19,065 epoch 30 - iter 58/585 - loss 0.07641811 - samples/sec: 63.74 - lr: 0.000008
2021-06-22 13:00:48,209 epoch 30 - iter 116/585 - loss 0.08321539 - samples/sec: 63.69 - lr: 0.000008
2021-06-22 13:01:17,330 epoch 30 - iter 174/585 - loss 0.08534803 - samples/sec: 63.74 - lr: 0.000008
2021-06-22 13:01:46,431 epoch 30 - iter 232/585 - loss 0.08931207 - samples/sec: 63.78 - lr: 0.000008
2021-06-22 13:02:15,500 epoch 30 - iter 290/585 - loss 0.08767604 - samples/sec: 63.85 - lr: 0.000008
2021-06-22 13:02:44,545 epoch 30 - iter 348/585 - loss 0.08803595 - samples/sec: 63.91 - lr: 0.000008
2021-06-22 13:03:13,641 epoch 30 - iter 406/585 - loss 0.08717328 - samples/sec: 63.80 - lr: 0.000008
2021-06-22 13:03:42,766 epoch 30 - iter 464/585 - loss 0.08727982 - samples/sec: 63.73 - lr: 0.000008
2021-06-22 13:04:12,000 epoch 30 - iter 522/585 - loss 0.08919577 - samples/sec: 63.49 - lr: 0.000008
2021-06-22 13:04:40,999 epoch 30 - iter 580/585 - loss 0.08993043 - samples/sec: 64.01 - lr: 0.000008
2021-06-22 13:04:43,250 ----------------------------------------------------------------------------------------------------
2021-06-22 13:04:43,251 EPOCH 30 done: loss 0.0901 - lr 0.0000075
2021-06-22 13:04:55,674 DEV : loss 0.28790122270584106 - score 0.9659
2021-06-22 13:04:55,854 BAD EPOCHS (no improvement): 2
2021-06-22 13:04:55,854 ----------------------------------------------------------------------------------------------------
2021-06-22 13:05:24,910 epoch 31 - iter 58/585 - loss 0.09155563 - samples/sec: 63.89 - lr: 0.000008
2021-06-22 13:05:54,012 epoch 31 - iter 116/585 - loss 0.09625186 - samples/sec: 63.78 - lr: 0.000008
2021-06-22 13:06:23,040 epoch 31 - iter 174/585 - loss 0.09432033 - samples/sec: 63.94 - lr: 0.000008
2021-06-22 13:06:52,124 epoch 31 - iter 232/585 - loss 0.09185138 - samples/sec: 63.82 - lr: 0.000008
2021-06-22 13:07:21,202 epoch 31 - iter 290/585 - loss 0.09245395 - samples/sec: 63.84 - lr: 0.000008
2021-06-22 13:07:50,250 epoch 31 - iter 348/585 - loss 0.08950873 - samples/sec: 63.90 - lr: 0.000008
2021-06-22 13:08:19,268 epoch 31 - iter 406/585 - loss 0.08996135 - samples/sec: 63.97 - lr: 0.000008
2021-06-22 13:08:48,271 epoch 31 - iter 464/585 - loss 0.08957871 - samples/sec: 64.00 - lr: 0.000008
2021-06-22 13:09:17,351 epoch 31 - iter 522/585 - loss 0.08977604 - samples/sec: 63.83 - lr: 0.000008
2021-06-22 13:09:46,413 epoch 31 - iter 580/585 - loss 0.09056059 - samples/sec: 63.87 - lr: 0.000008
2021-06-22 13:09:48,639 ----------------------------------------------------------------------------------------------------
2021-06-22 13:09:48,639 EPOCH 31 done: loss 0.0905 - lr 0.0000075
2021-06-22 13:10:01,045 DEV : loss 0.28861987590789795 - score 0.9665
2021-06-22 13:10:01,228 BAD EPOCHS (no improvement): 3
2021-06-22 13:10:01,228 ----------------------------------------------------------------------------------------------------
2021-06-22 13:10:31,610 epoch 32 - iter 58/585 - loss 0.09679861 - samples/sec: 61.10 - lr: 0.000008
2021-06-22 13:11:00,692 epoch 32 - iter 116/585 - loss 0.08720619 - samples/sec: 63.83 - lr: 0.000008
2021-06-22 13:11:29,721 epoch 32 - iter 174/585 - loss 0.08995879 - samples/sec: 63.94 - lr: 0.000008
2021-06-22 13:11:58,727 epoch 32 - iter 232/585 - loss 0.08665305 - samples/sec: 63.99 - lr: 0.000008
2021-06-22 13:12:27,785 epoch 32 - iter 290/585 - loss 0.08507557 - samples/sec: 63.88 - lr: 0.000008
2021-06-22 13:12:56,794 epoch 32 - iter 348/585 - loss 0.08309516 - samples/sec: 63.99 - lr: 0.000008
2021-06-22 13:13:25,814 epoch 32 - iter 406/585 - loss 0.08339484 - samples/sec: 63.96 - lr: 0.000008
2021-06-22 13:13:54,937 epoch 32 - iter 464/585 - loss 0.08341480 - samples/sec: 63.74 - lr: 0.000008
2021-06-22 13:14:24,062 epoch 32 - iter 522/585 - loss 0.08450240 - samples/sec: 63.73 - lr: 0.000008
2021-06-22 13:14:53,081 epoch 32 - iter 580/585 - loss 0.08595808 - samples/sec: 63.97 - lr: 0.000008
2021-06-22 13:14:55,334 ----------------------------------------------------------------------------------------------------
2021-06-22 13:14:55,334 EPOCH 32 done: loss 0.0860 - lr 0.0000075
2021-06-22 13:15:07,757 DEV : loss 0.2886334955692291 - score 0.967
Epoch    32: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 13:15:07,939 BAD EPOCHS (no improvement): 4
2021-06-22 13:15:07,939 ----------------------------------------------------------------------------------------------------
2021-06-22 13:15:37,000 epoch 33 - iter 58/585 - loss 0.09078466 - samples/sec: 63.87 - lr: 0.000004
2021-06-22 13:16:06,026 epoch 33 - iter 116/585 - loss 0.08204073 - samples/sec: 63.95 - lr: 0.000004
2021-06-22 13:16:35,016 epoch 33 - iter 174/585 - loss 0.08381577 - samples/sec: 64.03 - lr: 0.000004
2021-06-22 13:17:04,109 epoch 33 - iter 232/585 - loss 0.08598424 - samples/sec: 63.80 - lr: 0.000004
2021-06-22 13:17:33,198 epoch 33 - iter 290/585 - loss 0.08734316 - samples/sec: 63.81 - lr: 0.000004
2021-06-22 13:18:02,216 epoch 33 - iter 348/585 - loss 0.09107149 - samples/sec: 63.97 - lr: 0.000004
2021-06-22 13:18:31,202 epoch 33 - iter 406/585 - loss 0.09011892 - samples/sec: 64.04 - lr: 0.000004
2021-06-22 13:19:00,182 epoch 33 - iter 464/585 - loss 0.08962085 - samples/sec: 64.05 - lr: 0.000004
2021-06-22 13:19:29,283 epoch 33 - iter 522/585 - loss 0.08964080 - samples/sec: 63.78 - lr: 0.000004
2021-06-22 13:19:58,286 epoch 33 - iter 580/585 - loss 0.08883416 - samples/sec: 64.00 - lr: 0.000004
2021-06-22 13:20:00,537 ----------------------------------------------------------------------------------------------------
2021-06-22 13:20:00,538 EPOCH 33 done: loss 0.0884 - lr 0.0000038
2021-06-22 13:20:12,956 DEV : loss 0.28820836544036865 - score 0.967
2021-06-22 13:20:13,136 BAD EPOCHS (no improvement): 1
2021-06-22 13:20:13,137 ----------------------------------------------------------------------------------------------------
2021-06-22 13:20:42,192 epoch 34 - iter 58/585 - loss 0.08909234 - samples/sec: 63.88 - lr: 0.000004
2021-06-22 13:21:11,282 epoch 34 - iter 116/585 - loss 0.08124357 - samples/sec: 63.81 - lr: 0.000004
2021-06-22 13:21:40,258 epoch 34 - iter 174/585 - loss 0.08126023 - samples/sec: 64.06 - lr: 0.000004
2021-06-22 13:22:09,230 epoch 34 - iter 232/585 - loss 0.08088083 - samples/sec: 64.07 - lr: 0.000004
2021-06-22 13:22:38,290 epoch 34 - iter 290/585 - loss 0.08340134 - samples/sec: 63.87 - lr: 0.000004
2021-06-22 13:23:07,340 epoch 34 - iter 348/585 - loss 0.08197589 - samples/sec: 63.90 - lr: 0.000004
2021-06-22 13:23:36,451 epoch 34 - iter 406/585 - loss 0.08345088 - samples/sec: 63.76 - lr: 0.000004
2021-06-22 13:24:05,678 epoch 34 - iter 464/585 - loss 0.08394293 - samples/sec: 63.51 - lr: 0.000004
2021-06-22 13:24:34,846 epoch 34 - iter 522/585 - loss 0.08318355 - samples/sec: 63.64 - lr: 0.000004
2021-06-22 13:25:04,001 epoch 34 - iter 580/585 - loss 0.08193055 - samples/sec: 63.67 - lr: 0.000004
2021-06-22 13:25:06,244 ----------------------------------------------------------------------------------------------------
2021-06-22 13:25:06,245 EPOCH 34 done: loss 0.0819 - lr 0.0000038
2021-06-22 13:25:18,665 DEV : loss 0.29188141226768494 - score 0.9672
2021-06-22 13:25:18,845 BAD EPOCHS (no improvement): 2
2021-06-22 13:25:18,846 ----------------------------------------------------------------------------------------------------
2021-06-22 13:25:47,845 epoch 35 - iter 58/585 - loss 0.07416619 - samples/sec: 64.01 - lr: 0.000004
2021-06-22 13:26:16,880 epoch 35 - iter 116/585 - loss 0.08461668 - samples/sec: 63.93 - lr: 0.000004
2021-06-22 13:26:45,981 epoch 35 - iter 174/585 - loss 0.07906198 - samples/sec: 63.78 - lr: 0.000004
2021-06-22 13:27:15,038 epoch 35 - iter 232/585 - loss 0.07943477 - samples/sec: 63.88 - lr: 0.000004
2021-06-22 13:27:44,067 epoch 35 - iter 290/585 - loss 0.08095964 - samples/sec: 63.94 - lr: 0.000004
2021-06-22 13:28:13,102 epoch 35 - iter 348/585 - loss 0.08245573 - samples/sec: 63.93 - lr: 0.000004
2021-06-22 13:28:42,216 epoch 35 - iter 406/585 - loss 0.08445926 - samples/sec: 63.76 - lr: 0.000004
2021-06-22 13:29:11,356 epoch 35 - iter 464/585 - loss 0.08414231 - samples/sec: 63.70 - lr: 0.000004
2021-06-22 13:29:40,422 epoch 35 - iter 522/585 - loss 0.08393793 - samples/sec: 63.86 - lr: 0.000004
2021-06-22 13:30:09,521 epoch 35 - iter 580/585 - loss 0.08283224 - samples/sec: 63.79 - lr: 0.000004
2021-06-22 13:30:11,760 ----------------------------------------------------------------------------------------------------
2021-06-22 13:30:11,760 EPOCH 35 done: loss 0.0828 - lr 0.0000038
2021-06-22 13:30:25,548 DEV : loss 0.2902565896511078 - score 0.9679
2021-06-22 13:30:25,731 BAD EPOCHS (no improvement): 3
2021-06-22 13:30:25,731 ----------------------------------------------------------------------------------------------------
2021-06-22 13:30:54,916 epoch 36 - iter 58/585 - loss 0.09459106 - samples/sec: 63.60 - lr: 0.000004
2021-06-22 13:31:24,009 epoch 36 - iter 116/585 - loss 0.08292712 - samples/sec: 63.80 - lr: 0.000004
2021-06-22 13:31:53,127 epoch 36 - iter 174/585 - loss 0.08361089 - samples/sec: 63.75 - lr: 0.000004
2021-06-22 13:32:22,285 epoch 36 - iter 232/585 - loss 0.08036801 - samples/sec: 63.66 - lr: 0.000004
2021-06-22 13:32:51,434 epoch 36 - iter 290/585 - loss 0.08068370 - samples/sec: 63.68 - lr: 0.000004
2021-06-22 13:33:20,570 epoch 36 - iter 348/585 - loss 0.08095506 - samples/sec: 63.71 - lr: 0.000004
2021-06-22 13:33:49,646 epoch 36 - iter 406/585 - loss 0.08180866 - samples/sec: 63.84 - lr: 0.000004
2021-06-22 13:34:18,736 epoch 36 - iter 464/585 - loss 0.08143026 - samples/sec: 63.81 - lr: 0.000004
2021-06-22 13:34:47,872 epoch 36 - iter 522/585 - loss 0.08037463 - samples/sec: 63.71 - lr: 0.000004
2021-06-22 13:35:16,905 epoch 36 - iter 580/585 - loss 0.08040088 - samples/sec: 63.93 - lr: 0.000004
2021-06-22 13:35:19,145 ----------------------------------------------------------------------------------------------------
2021-06-22 13:35:19,145 EPOCH 36 done: loss 0.0802 - lr 0.0000038
2021-06-22 13:35:31,581 DEV : loss 0.2883678376674652 - score 0.9677
Epoch    36: reducing learning rate of group 0 to 1.8750e-06.
2021-06-22 13:35:31,762 BAD EPOCHS (no improvement): 4
2021-06-22 13:35:31,762 ----------------------------------------------------------------------------------------------------
2021-06-22 13:35:31,762 ----------------------------------------------------------------------------------------------------
2021-06-22 13:35:31,762 learning rate too small - quitting training!
2021-06-22 13:35:31,762 ----------------------------------------------------------------------------------------------------
2021-06-22 13:35:32,213 ----------------------------------------------------------------------------------------------------
2021-06-22 13:35:32,213 Testing using best model ...
2021-06-22 13:35:32,213 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/best-model.pt
2021-06-22 13:36:11,871 0.9673	0.9656	0.9664
2021-06-22 13:36:11,871 
Results:
- F1-score (micro) 0.9664
- F1-score (macro) 0.9664

By class:
SENT       tp: 2836 - fp: 96 - fn: 101 - precision: 0.9673 - recall: 0.9656 - f1-score: 0.9664
2021-06-22 13:36:11,871 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/
2021-06-22 13:36:11,882 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac
2021-06-22 13:36:11,882 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/sent_train.txt
2021-06-22 13:36:11,885 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/sent_dev.txt
2021-06-22 13:36:11,886 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/sent_test.txt
Corpus: 1751 train + 228 dev + 315 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 13:36:18,587 ----------------------------------------------------------------------------------------------------
2021-06-22 13:36:18,590 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50265, 1024, padding_idx=1)
          (position_embeddings): Embedding(514, 1024, padding_idx=1)
          (token_type_embeddings): Embedding(1, 1024)
          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (12): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (13): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (14): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (15): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (16): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (17): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (18): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (19): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (20): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (21): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (22): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (23): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4146, out_features=4146, bias=True)
  (rnn): LSTM(4146, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 13:36:18,590 ----------------------------------------------------------------------------------------------------
2021-06-22 13:36:18,590 Corpus: "Corpus: 1751 train + 228 dev + 315 test sentences"
2021-06-22 13:36:18,590 ----------------------------------------------------------------------------------------------------
2021-06-22 13:36:18,590 Parameters:
2021-06-22 13:36:18,590  - learning_rate: "3e-05"
2021-06-22 13:36:18,590  - mini_batch_size: "32"
2021-06-22 13:36:18,590  - patience: "3"
2021-06-22 13:36:18,590  - anneal_factor: "0.5"
2021-06-22 13:36:18,590  - max_epochs: "40"
2021-06-22 13:36:18,591  - shuffle: "True"
2021-06-22 13:36:18,591  - train_with_dev: "False"
2021-06-22 13:36:18,591  - batch_growth_annealing: "False"
2021-06-22 13:36:18,591 ----------------------------------------------------------------------------------------------------
2021-06-22 13:36:18,591 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac"
2021-06-22 13:36:18,591 ----------------------------------------------------------------------------------------------------
2021-06-22 13:36:18,591 Device: cuda:0
2021-06-22 13:36:18,591 ----------------------------------------------------------------------------------------------------
2021-06-22 13:36:18,591 Embeddings storage mode: cpu
2021-06-22 13:36:18,592 ----------------------------------------------------------------------------------------------------
2021-06-22 13:36:25,692 epoch 1 - iter 5/55 - loss 17.08872375 - samples/sec: 22.54 - lr: 0.000030
2021-06-22 13:36:32,865 epoch 1 - iter 10/55 - loss 14.79187422 - samples/sec: 22.31 - lr: 0.000030
2021-06-22 13:36:39,852 epoch 1 - iter 15/55 - loss 13.49067542 - samples/sec: 22.90 - lr: 0.000030
2021-06-22 13:36:46,623 epoch 1 - iter 20/55 - loss 12.51248913 - samples/sec: 23.63 - lr: 0.000030
2021-06-22 13:36:53,377 epoch 1 - iter 25/55 - loss 11.69804472 - samples/sec: 23.69 - lr: 0.000030
2021-06-22 13:37:00,155 epoch 1 - iter 30/55 - loss 11.05687874 - samples/sec: 23.61 - lr: 0.000030
2021-06-22 13:37:06,930 epoch 1 - iter 35/55 - loss 10.47583888 - samples/sec: 23.62 - lr: 0.000030
2021-06-22 13:37:13,705 epoch 1 - iter 40/55 - loss 9.98268052 - samples/sec: 23.62 - lr: 0.000030
2021-06-22 13:37:20,484 epoch 1 - iter 45/55 - loss 9.54277857 - samples/sec: 23.60 - lr: 0.000030
2021-06-22 13:37:27,258 epoch 1 - iter 50/55 - loss 9.18451344 - samples/sec: 23.62 - lr: 0.000030
2021-06-22 13:37:33,669 epoch 1 - iter 55/55 - loss 8.85782637 - samples/sec: 24.96 - lr: 0.000030
2021-06-22 13:37:33,669 ----------------------------------------------------------------------------------------------------
2021-06-22 13:37:33,669 EPOCH 1 done: loss 8.8578 - lr 0.0000300
2021-06-22 13:37:39,550 DEV : loss 4.464956760406494 - score 0.7905
2021-06-22 13:37:39,567 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:37:40,791 ----------------------------------------------------------------------------------------------------
2021-06-22 13:37:43,179 epoch 2 - iter 5/55 - loss 5.57057562 - samples/sec: 67.02 - lr: 0.000030
2021-06-22 13:37:45,576 epoch 2 - iter 10/55 - loss 5.38324947 - samples/sec: 66.78 - lr: 0.000030
2021-06-22 13:37:47,968 epoch 2 - iter 15/55 - loss 5.25595601 - samples/sec: 66.89 - lr: 0.000030
2021-06-22 13:37:50,381 epoch 2 - iter 20/55 - loss 5.20387912 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 13:37:52,766 epoch 2 - iter 25/55 - loss 5.20959116 - samples/sec: 67.11 - lr: 0.000030
2021-06-22 13:37:55,155 epoch 2 - iter 30/55 - loss 5.10424945 - samples/sec: 67.01 - lr: 0.000030
2021-06-22 13:37:57,535 epoch 2 - iter 35/55 - loss 5.09642591 - samples/sec: 67.25 - lr: 0.000030
2021-06-22 13:37:59,922 epoch 2 - iter 40/55 - loss 5.04522274 - samples/sec: 67.03 - lr: 0.000030
2021-06-22 13:38:02,320 epoch 2 - iter 45/55 - loss 4.97949497 - samples/sec: 66.75 - lr: 0.000030
2021-06-22 13:38:04,720 epoch 2 - iter 50/55 - loss 4.97457414 - samples/sec: 66.68 - lr: 0.000030
2021-06-22 13:38:07,001 epoch 2 - iter 55/55 - loss 4.93384708 - samples/sec: 70.16 - lr: 0.000030
2021-06-22 13:38:07,001 ----------------------------------------------------------------------------------------------------
2021-06-22 13:38:07,001 EPOCH 2 done: loss 4.9338 - lr 0.0000300
2021-06-22 13:38:12,780 DEV : loss 3.453662157058716 - score 0.844
2021-06-22 13:38:12,798 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:38:39,943 ----------------------------------------------------------------------------------------------------
2021-06-22 13:38:42,364 epoch 3 - iter 5/55 - loss 4.51682796 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 13:38:44,771 epoch 3 - iter 10/55 - loss 4.38138080 - samples/sec: 66.49 - lr: 0.000030
2021-06-22 13:38:47,184 epoch 3 - iter 15/55 - loss 4.41482863 - samples/sec: 66.33 - lr: 0.000030
2021-06-22 13:38:49,597 epoch 3 - iter 20/55 - loss 4.42655672 - samples/sec: 66.31 - lr: 0.000030
2021-06-22 13:38:52,004 epoch 3 - iter 25/55 - loss 4.40292553 - samples/sec: 66.50 - lr: 0.000030
2021-06-22 13:38:54,426 epoch 3 - iter 30/55 - loss 4.44959116 - samples/sec: 66.07 - lr: 0.000030
2021-06-22 13:38:56,828 epoch 3 - iter 35/55 - loss 4.46387051 - samples/sec: 66.65 - lr: 0.000030
2021-06-22 13:38:59,239 epoch 3 - iter 40/55 - loss 4.44956443 - samples/sec: 66.36 - lr: 0.000030
2021-06-22 13:39:01,658 epoch 3 - iter 45/55 - loss 4.43632246 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 13:39:04,094 epoch 3 - iter 50/55 - loss 4.43738418 - samples/sec: 65.71 - lr: 0.000030
2021-06-22 13:39:06,388 epoch 3 - iter 55/55 - loss 4.42190713 - samples/sec: 69.76 - lr: 0.000030
2021-06-22 13:39:06,388 ----------------------------------------------------------------------------------------------------
2021-06-22 13:39:06,389 EPOCH 3 done: loss 4.4219 - lr 0.0000300
2021-06-22 13:39:07,576 DEV : loss 3.1550536155700684 - score 0.8615
2021-06-22 13:39:07,593 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:39:22,356 ----------------------------------------------------------------------------------------------------
2021-06-22 13:39:24,785 epoch 4 - iter 5/55 - loss 3.91151810 - samples/sec: 65.92 - lr: 0.000030
2021-06-22 13:39:27,169 epoch 4 - iter 10/55 - loss 4.12400601 - samples/sec: 67.12 - lr: 0.000030
2021-06-22 13:39:29,578 epoch 4 - iter 15/55 - loss 4.09826808 - samples/sec: 66.44 - lr: 0.000030
2021-06-22 13:39:31,973 epoch 4 - iter 20/55 - loss 4.13651164 - samples/sec: 66.82 - lr: 0.000030
2021-06-22 13:39:34,390 epoch 4 - iter 25/55 - loss 4.15632481 - samples/sec: 66.22 - lr: 0.000030
2021-06-22 13:39:36,794 epoch 4 - iter 30/55 - loss 4.14085544 - samples/sec: 66.57 - lr: 0.000030
2021-06-22 13:39:39,212 epoch 4 - iter 35/55 - loss 4.14720182 - samples/sec: 66.21 - lr: 0.000030
2021-06-22 13:39:41,635 epoch 4 - iter 40/55 - loss 4.14554213 - samples/sec: 66.04 - lr: 0.000030
2021-06-22 13:39:44,063 epoch 4 - iter 45/55 - loss 4.17077925 - samples/sec: 65.93 - lr: 0.000030
2021-06-22 13:39:46,473 epoch 4 - iter 50/55 - loss 4.13342732 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 13:39:48,763 epoch 4 - iter 55/55 - loss 4.13223981 - samples/sec: 69.88 - lr: 0.000030
2021-06-22 13:39:48,764 ----------------------------------------------------------------------------------------------------
2021-06-22 13:39:48,764 EPOCH 4 done: loss 4.1322 - lr 0.0000300
2021-06-22 13:39:49,951 DEV : loss 3.084900140762329 - score 0.8678
2021-06-22 13:39:49,969 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:40:04,623 ----------------------------------------------------------------------------------------------------
2021-06-22 13:40:07,052 epoch 5 - iter 5/55 - loss 4.04782495 - samples/sec: 65.92 - lr: 0.000030
2021-06-22 13:40:09,460 epoch 5 - iter 10/55 - loss 3.99974649 - samples/sec: 66.46 - lr: 0.000030
2021-06-22 13:40:11,866 epoch 5 - iter 15/55 - loss 4.05838755 - samples/sec: 66.51 - lr: 0.000030
2021-06-22 13:40:14,269 epoch 5 - iter 20/55 - loss 4.02481353 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 13:40:16,672 epoch 5 - iter 25/55 - loss 3.97162783 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 13:40:19,092 epoch 5 - iter 30/55 - loss 3.98568052 - samples/sec: 66.15 - lr: 0.000030
2021-06-22 13:40:21,495 epoch 5 - iter 35/55 - loss 3.92430592 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 13:40:23,902 epoch 5 - iter 40/55 - loss 3.93016753 - samples/sec: 66.50 - lr: 0.000030
2021-06-22 13:40:26,316 epoch 5 - iter 45/55 - loss 3.91193743 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 13:40:28,739 epoch 5 - iter 50/55 - loss 3.94611068 - samples/sec: 66.05 - lr: 0.000030
2021-06-22 13:40:31,014 epoch 5 - iter 55/55 - loss 3.92431335 - samples/sec: 70.34 - lr: 0.000030
2021-06-22 13:40:31,015 ----------------------------------------------------------------------------------------------------
2021-06-22 13:40:31,015 EPOCH 5 done: loss 3.9243 - lr 0.0000300
2021-06-22 13:40:32,198 DEV : loss 2.888967275619507 - score 0.8717
2021-06-22 13:40:32,215 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:40:46,856 ----------------------------------------------------------------------------------------------------
2021-06-22 13:40:49,269 epoch 6 - iter 5/55 - loss 3.94106221 - samples/sec: 66.34 - lr: 0.000030
2021-06-22 13:40:51,674 epoch 6 - iter 10/55 - loss 3.86789145 - samples/sec: 66.55 - lr: 0.000030
2021-06-22 13:40:54,096 epoch 6 - iter 15/55 - loss 3.87505136 - samples/sec: 66.08 - lr: 0.000030
2021-06-22 13:40:56,494 epoch 6 - iter 20/55 - loss 3.85804129 - samples/sec: 66.75 - lr: 0.000030
2021-06-22 13:40:58,886 epoch 6 - iter 25/55 - loss 3.89307218 - samples/sec: 66.91 - lr: 0.000030
2021-06-22 13:41:01,300 epoch 6 - iter 30/55 - loss 3.84847240 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 13:41:03,715 epoch 6 - iter 35/55 - loss 3.88543454 - samples/sec: 66.26 - lr: 0.000030
2021-06-22 13:41:06,133 epoch 6 - iter 40/55 - loss 3.87268968 - samples/sec: 66.19 - lr: 0.000030
2021-06-22 13:41:08,542 epoch 6 - iter 45/55 - loss 3.87014802 - samples/sec: 66.45 - lr: 0.000030
2021-06-22 13:41:10,967 epoch 6 - iter 50/55 - loss 3.83607769 - samples/sec: 66.00 - lr: 0.000030
2021-06-22 13:41:13,280 epoch 6 - iter 55/55 - loss 3.83121591 - samples/sec: 69.17 - lr: 0.000030
2021-06-22 13:41:13,281 ----------------------------------------------------------------------------------------------------
2021-06-22 13:41:13,281 EPOCH 6 done: loss 3.8312 - lr 0.0000300
2021-06-22 13:41:14,464 DEV : loss 2.8376803398132324 - score 0.8721
2021-06-22 13:41:14,481 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:41:29,182 ----------------------------------------------------------------------------------------------------
2021-06-22 13:41:31,604 epoch 7 - iter 5/55 - loss 3.78265157 - samples/sec: 66.12 - lr: 0.000030
2021-06-22 13:41:33,998 epoch 7 - iter 10/55 - loss 3.76575623 - samples/sec: 66.85 - lr: 0.000030
2021-06-22 13:41:36,400 epoch 7 - iter 15/55 - loss 3.74114777 - samples/sec: 66.63 - lr: 0.000030
2021-06-22 13:41:38,800 epoch 7 - iter 20/55 - loss 3.66902184 - samples/sec: 66.67 - lr: 0.000030
2021-06-22 13:41:41,193 epoch 7 - iter 25/55 - loss 3.69255965 - samples/sec: 66.89 - lr: 0.000030
2021-06-22 13:41:43,611 epoch 7 - iter 30/55 - loss 3.72368395 - samples/sec: 66.17 - lr: 0.000030
2021-06-22 13:41:46,014 epoch 7 - iter 35/55 - loss 3.68461375 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 13:41:48,426 epoch 7 - iter 40/55 - loss 3.69772707 - samples/sec: 66.36 - lr: 0.000030
2021-06-22 13:41:50,830 epoch 7 - iter 45/55 - loss 3.66837082 - samples/sec: 66.57 - lr: 0.000030
2021-06-22 13:41:53,245 epoch 7 - iter 50/55 - loss 3.68384939 - samples/sec: 66.28 - lr: 0.000030
2021-06-22 13:41:55,554 epoch 7 - iter 55/55 - loss 3.67787277 - samples/sec: 69.32 - lr: 0.000030
2021-06-22 13:41:55,554 ----------------------------------------------------------------------------------------------------
2021-06-22 13:41:55,554 EPOCH 7 done: loss 3.6779 - lr 0.0000300
2021-06-22 13:41:56,739 DEV : loss 2.7843761444091797 - score 0.8798
2021-06-22 13:41:56,757 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:42:11,462 ----------------------------------------------------------------------------------------------------
2021-06-22 13:42:13,860 epoch 8 - iter 5/55 - loss 3.43501101 - samples/sec: 66.76 - lr: 0.000030
2021-06-22 13:42:16,271 epoch 8 - iter 10/55 - loss 3.42668262 - samples/sec: 66.39 - lr: 0.000030
2021-06-22 13:42:18,686 epoch 8 - iter 15/55 - loss 3.44757559 - samples/sec: 66.26 - lr: 0.000030
2021-06-22 13:42:21,110 epoch 8 - iter 20/55 - loss 3.54122020 - samples/sec: 66.02 - lr: 0.000030
2021-06-22 13:42:23,513 epoch 8 - iter 25/55 - loss 3.55550468 - samples/sec: 66.61 - lr: 0.000030
2021-06-22 13:42:25,956 epoch 8 - iter 30/55 - loss 3.53072499 - samples/sec: 65.51 - lr: 0.000030
2021-06-22 13:42:28,377 epoch 8 - iter 35/55 - loss 3.56146648 - samples/sec: 66.12 - lr: 0.000030
2021-06-22 13:42:30,787 epoch 8 - iter 40/55 - loss 3.56064668 - samples/sec: 66.39 - lr: 0.000030
2021-06-22 13:42:33,206 epoch 8 - iter 45/55 - loss 3.59033267 - samples/sec: 66.18 - lr: 0.000030
2021-06-22 13:42:35,628 epoch 8 - iter 50/55 - loss 3.60903347 - samples/sec: 66.07 - lr: 0.000030
2021-06-22 13:42:37,920 epoch 8 - iter 55/55 - loss 3.58690380 - samples/sec: 69.82 - lr: 0.000030
2021-06-22 13:42:37,921 ----------------------------------------------------------------------------------------------------
2021-06-22 13:42:37,921 EPOCH 8 done: loss 3.5869 - lr 0.0000300
2021-06-22 13:42:39,106 DEV : loss 2.799407482147217 - score 0.8789
2021-06-22 13:42:39,124 BAD EPOCHS (no improvement): 1
2021-06-22 13:42:39,124 ----------------------------------------------------------------------------------------------------
2021-06-22 13:42:41,526 epoch 9 - iter 5/55 - loss 3.41628537 - samples/sec: 66.62 - lr: 0.000030
2021-06-22 13:42:43,931 epoch 9 - iter 10/55 - loss 3.38345628 - samples/sec: 66.55 - lr: 0.000030
2021-06-22 13:42:46,335 epoch 9 - iter 15/55 - loss 3.51789301 - samples/sec: 66.57 - lr: 0.000030
2021-06-22 13:42:48,746 epoch 9 - iter 20/55 - loss 3.50960277 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 13:42:51,150 epoch 9 - iter 25/55 - loss 3.52584324 - samples/sec: 66.55 - lr: 0.000030
2021-06-22 13:42:53,549 epoch 9 - iter 30/55 - loss 3.54742188 - samples/sec: 66.73 - lr: 0.000030
2021-06-22 13:42:55,945 epoch 9 - iter 35/55 - loss 3.51580272 - samples/sec: 66.80 - lr: 0.000030
2021-06-22 13:42:58,335 epoch 9 - iter 40/55 - loss 3.51763690 - samples/sec: 66.96 - lr: 0.000030
2021-06-22 13:43:00,747 epoch 9 - iter 45/55 - loss 3.54267882 - samples/sec: 66.34 - lr: 0.000030
2021-06-22 13:43:03,162 epoch 9 - iter 50/55 - loss 3.51876400 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 13:43:05,451 epoch 9 - iter 55/55 - loss 3.51602819 - samples/sec: 69.91 - lr: 0.000030
2021-06-22 13:43:05,452 ----------------------------------------------------------------------------------------------------
2021-06-22 13:43:05,452 EPOCH 9 done: loss 3.5160 - lr 0.0000300
2021-06-22 13:43:06,637 DEV : loss 2.6330106258392334 - score 0.8726
2021-06-22 13:43:06,654 BAD EPOCHS (no improvement): 2
2021-06-22 13:43:06,654 ----------------------------------------------------------------------------------------------------
2021-06-22 13:43:09,058 epoch 10 - iter 5/55 - loss 3.38443017 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 13:43:11,441 epoch 10 - iter 10/55 - loss 3.39445002 - samples/sec: 67.15 - lr: 0.000030
2021-06-22 13:43:13,843 epoch 10 - iter 15/55 - loss 3.44602888 - samples/sec: 66.62 - lr: 0.000030
2021-06-22 13:43:16,258 epoch 10 - iter 20/55 - loss 3.30773282 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 13:43:18,661 epoch 10 - iter 25/55 - loss 3.29824877 - samples/sec: 66.58 - lr: 0.000030
2021-06-22 13:43:21,054 epoch 10 - iter 30/55 - loss 3.36678487 - samples/sec: 66.90 - lr: 0.000030
2021-06-22 13:43:23,458 epoch 10 - iter 35/55 - loss 3.37073844 - samples/sec: 66.56 - lr: 0.000030
2021-06-22 13:43:25,855 epoch 10 - iter 40/55 - loss 3.38677737 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 13:43:28,253 epoch 10 - iter 45/55 - loss 3.43424462 - samples/sec: 66.74 - lr: 0.000030
2021-06-22 13:43:30,653 epoch 10 - iter 50/55 - loss 3.45016714 - samples/sec: 66.70 - lr: 0.000030
2021-06-22 13:43:32,955 epoch 10 - iter 55/55 - loss 3.45585100 - samples/sec: 69.52 - lr: 0.000030
2021-06-22 13:43:32,955 ----------------------------------------------------------------------------------------------------
2021-06-22 13:43:32,955 EPOCH 10 done: loss 3.4559 - lr 0.0000300
2021-06-22 13:43:34,141 DEV : loss 2.634594202041626 - score 0.8793
2021-06-22 13:43:34,159 BAD EPOCHS (no improvement): 3
2021-06-22 13:43:34,159 ----------------------------------------------------------------------------------------------------
2021-06-22 13:43:36,578 epoch 11 - iter 5/55 - loss 3.50903234 - samples/sec: 66.17 - lr: 0.000030
2021-06-22 13:43:38,981 epoch 11 - iter 10/55 - loss 3.36348565 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 13:43:41,390 epoch 11 - iter 15/55 - loss 3.43586297 - samples/sec: 66.41 - lr: 0.000030
2021-06-22 13:43:43,792 epoch 11 - iter 20/55 - loss 3.39821459 - samples/sec: 66.64 - lr: 0.000030
2021-06-22 13:43:46,202 epoch 11 - iter 25/55 - loss 3.43344821 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 13:43:48,605 epoch 11 - iter 30/55 - loss 3.45617035 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 13:43:51,018 epoch 11 - iter 35/55 - loss 3.41109630 - samples/sec: 66.32 - lr: 0.000030
2021-06-22 13:43:53,431 epoch 11 - iter 40/55 - loss 3.35358230 - samples/sec: 66.34 - lr: 0.000030
2021-06-22 13:43:55,825 epoch 11 - iter 45/55 - loss 3.35900477 - samples/sec: 66.84 - lr: 0.000030
2021-06-22 13:43:58,373 epoch 11 - iter 50/55 - loss 3.35498870 - samples/sec: 62.82 - lr: 0.000030
2021-06-22 13:44:00,659 epoch 11 - iter 55/55 - loss 3.36010349 - samples/sec: 70.00 - lr: 0.000030
2021-06-22 13:44:00,660 ----------------------------------------------------------------------------------------------------
2021-06-22 13:44:00,660 EPOCH 11 done: loss 3.3601 - lr 0.0000300
2021-06-22 13:44:01,847 DEV : loss 2.5911037921905518 - score 0.8816
2021-06-22 13:44:01,865 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:44:17,097 ----------------------------------------------------------------------------------------------------
2021-06-22 13:44:19,492 epoch 12 - iter 5/55 - loss 3.17296095 - samples/sec: 66.84 - lr: 0.000030
2021-06-22 13:44:21,912 epoch 12 - iter 10/55 - loss 3.26703222 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 13:44:24,337 epoch 12 - iter 15/55 - loss 3.29307075 - samples/sec: 66.00 - lr: 0.000030
2021-06-22 13:44:26,730 epoch 12 - iter 20/55 - loss 3.23471459 - samples/sec: 66.89 - lr: 0.000030
2021-06-22 13:44:29,123 epoch 12 - iter 25/55 - loss 3.23363681 - samples/sec: 66.86 - lr: 0.000030
2021-06-22 13:44:31,529 epoch 12 - iter 30/55 - loss 3.25385091 - samples/sec: 66.54 - lr: 0.000030
2021-06-22 13:44:33,931 epoch 12 - iter 35/55 - loss 3.25517616 - samples/sec: 66.63 - lr: 0.000030
2021-06-22 13:44:36,336 epoch 12 - iter 40/55 - loss 3.29311050 - samples/sec: 66.56 - lr: 0.000030
2021-06-22 13:44:38,728 epoch 12 - iter 45/55 - loss 3.30557220 - samples/sec: 66.90 - lr: 0.000030
2021-06-22 13:44:41,142 epoch 12 - iter 50/55 - loss 3.31657266 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 13:44:43,445 epoch 12 - iter 55/55 - loss 3.29627129 - samples/sec: 69.49 - lr: 0.000030
2021-06-22 13:44:43,446 ----------------------------------------------------------------------------------------------------
2021-06-22 13:44:43,446 EPOCH 12 done: loss 3.2963 - lr 0.0000300
2021-06-22 13:44:44,642 DEV : loss 2.5299229621887207 - score 0.8823
2021-06-22 13:44:44,660 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:44:59,071 ----------------------------------------------------------------------------------------------------
2021-06-22 13:45:01,483 epoch 13 - iter 5/55 - loss 2.93085866 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 13:45:03,897 epoch 13 - iter 10/55 - loss 3.11070185 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 13:45:06,300 epoch 13 - iter 15/55 - loss 3.12086116 - samples/sec: 66.61 - lr: 0.000030
2021-06-22 13:45:08,686 epoch 13 - iter 20/55 - loss 3.12310681 - samples/sec: 67.05 - lr: 0.000030
2021-06-22 13:45:11,092 epoch 13 - iter 25/55 - loss 3.11213061 - samples/sec: 66.53 - lr: 0.000030
2021-06-22 13:45:13,500 epoch 13 - iter 30/55 - loss 3.13428671 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 13:45:15,896 epoch 13 - iter 35/55 - loss 3.17654151 - samples/sec: 66.80 - lr: 0.000030
2021-06-22 13:45:18,294 epoch 13 - iter 40/55 - loss 3.17969154 - samples/sec: 66.74 - lr: 0.000030
2021-06-22 13:45:20,705 epoch 13 - iter 45/55 - loss 3.19369615 - samples/sec: 66.36 - lr: 0.000030
2021-06-22 13:45:23,095 epoch 13 - iter 50/55 - loss 3.19124833 - samples/sec: 66.96 - lr: 0.000030
2021-06-22 13:45:25,379 epoch 13 - iter 55/55 - loss 3.21219444 - samples/sec: 70.09 - lr: 0.000030
2021-06-22 13:45:25,379 ----------------------------------------------------------------------------------------------------
2021-06-22 13:45:25,379 EPOCH 13 done: loss 3.2122 - lr 0.0000300
2021-06-22 13:45:26,564 DEV : loss 2.4990172386169434 - score 0.8848
2021-06-22 13:45:26,581 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:45:35,074 ----------------------------------------------------------------------------------------------------
2021-06-22 13:45:37,488 epoch 14 - iter 5/55 - loss 2.80610933 - samples/sec: 66.31 - lr: 0.000030
2021-06-22 13:45:39,912 epoch 14 - iter 10/55 - loss 3.05420759 - samples/sec: 66.02 - lr: 0.000030
2021-06-22 13:45:42,312 epoch 14 - iter 15/55 - loss 3.06912738 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 13:45:44,706 epoch 14 - iter 20/55 - loss 3.11800301 - samples/sec: 66.86 - lr: 0.000030
2021-06-22 13:45:47,092 epoch 14 - iter 25/55 - loss 3.17518665 - samples/sec: 67.07 - lr: 0.000030
2021-06-22 13:45:49,489 epoch 14 - iter 30/55 - loss 3.13691088 - samples/sec: 66.79 - lr: 0.000030
2021-06-22 13:45:51,887 epoch 14 - iter 35/55 - loss 3.11562074 - samples/sec: 66.72 - lr: 0.000030
2021-06-22 13:45:54,298 epoch 14 - iter 40/55 - loss 3.12553573 - samples/sec: 66.39 - lr: 0.000030
2021-06-22 13:45:56,717 epoch 14 - iter 45/55 - loss 3.08871909 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 13:45:59,106 epoch 14 - iter 50/55 - loss 3.09149103 - samples/sec: 66.98 - lr: 0.000030
2021-06-22 13:46:01,394 epoch 14 - iter 55/55 - loss 3.10424086 - samples/sec: 69.95 - lr: 0.000030
2021-06-22 13:46:01,395 ----------------------------------------------------------------------------------------------------
2021-06-22 13:46:01,395 EPOCH 14 done: loss 3.1042 - lr 0.0000300
2021-06-22 13:46:02,584 DEV : loss 2.57517671585083 - score 0.8833
2021-06-22 13:46:02,601 BAD EPOCHS (no improvement): 1
2021-06-22 13:46:02,602 ----------------------------------------------------------------------------------------------------
2021-06-22 13:46:05,013 epoch 15 - iter 5/55 - loss 3.24271054 - samples/sec: 66.37 - lr: 0.000030
2021-06-22 13:46:07,399 epoch 15 - iter 10/55 - loss 3.14767542 - samples/sec: 67.08 - lr: 0.000030
2021-06-22 13:46:09,787 epoch 15 - iter 15/55 - loss 3.14716382 - samples/sec: 67.02 - lr: 0.000030
2021-06-22 13:46:12,199 epoch 15 - iter 20/55 - loss 3.12035506 - samples/sec: 66.36 - lr: 0.000030
2021-06-22 13:46:14,614 epoch 15 - iter 25/55 - loss 3.12069752 - samples/sec: 66.27 - lr: 0.000030
2021-06-22 13:46:17,013 epoch 15 - iter 30/55 - loss 3.09584173 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 13:46:19,422 epoch 15 - iter 35/55 - loss 3.10156787 - samples/sec: 66.44 - lr: 0.000030
2021-06-22 13:46:21,830 epoch 15 - iter 40/55 - loss 3.09937537 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 13:46:24,222 epoch 15 - iter 45/55 - loss 3.09972629 - samples/sec: 66.92 - lr: 0.000030
2021-06-22 13:46:26,638 epoch 15 - iter 50/55 - loss 3.07857529 - samples/sec: 66.23 - lr: 0.000030
2021-06-22 13:46:28,921 epoch 15 - iter 55/55 - loss 3.09475724 - samples/sec: 70.12 - lr: 0.000030
2021-06-22 13:46:28,921 ----------------------------------------------------------------------------------------------------
2021-06-22 13:46:28,921 EPOCH 15 done: loss 3.0948 - lr 0.0000300
2021-06-22 13:46:30,273 DEV : loss 2.4178714752197266 - score 0.8888
2021-06-22 13:46:30,290 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:46:38,888 ----------------------------------------------------------------------------------------------------
2021-06-22 13:46:41,286 epoch 16 - iter 5/55 - loss 3.03758836 - samples/sec: 66.74 - lr: 0.000030
2021-06-22 13:46:43,678 epoch 16 - iter 10/55 - loss 2.90783854 - samples/sec: 66.90 - lr: 0.000030
2021-06-22 13:46:46,098 epoch 16 - iter 15/55 - loss 3.00055574 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 13:46:48,490 epoch 16 - iter 20/55 - loss 3.03612916 - samples/sec: 66.91 - lr: 0.000030
2021-06-22 13:46:50,897 epoch 16 - iter 25/55 - loss 3.08939181 - samples/sec: 66.49 - lr: 0.000030
2021-06-22 13:46:53,307 epoch 16 - iter 30/55 - loss 3.08252391 - samples/sec: 66.43 - lr: 0.000030
2021-06-22 13:46:55,714 epoch 16 - iter 35/55 - loss 3.10045417 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 13:46:58,117 epoch 16 - iter 40/55 - loss 3.07889611 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 13:47:00,521 epoch 16 - iter 45/55 - loss 3.04314559 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 13:47:02,932 epoch 16 - iter 50/55 - loss 3.07987011 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 13:47:05,211 epoch 16 - iter 55/55 - loss 3.06719314 - samples/sec: 70.22 - lr: 0.000030
2021-06-22 13:47:05,211 ----------------------------------------------------------------------------------------------------
2021-06-22 13:47:05,211 EPOCH 16 done: loss 3.0672 - lr 0.0000300
2021-06-22 13:47:06,398 DEV : loss 2.5041377544403076 - score 0.8812
2021-06-22 13:47:06,416 BAD EPOCHS (no improvement): 1
2021-06-22 13:47:06,416 ----------------------------------------------------------------------------------------------------
2021-06-22 13:47:08,819 epoch 17 - iter 5/55 - loss 2.94812107 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 13:47:11,215 epoch 17 - iter 10/55 - loss 2.96452703 - samples/sec: 66.79 - lr: 0.000030
2021-06-22 13:47:13,612 epoch 17 - iter 15/55 - loss 2.92238135 - samples/sec: 66.78 - lr: 0.000030
2021-06-22 13:47:16,020 epoch 17 - iter 20/55 - loss 2.91303121 - samples/sec: 66.46 - lr: 0.000030
2021-06-22 13:47:18,436 epoch 17 - iter 25/55 - loss 2.92299995 - samples/sec: 66.25 - lr: 0.000030
2021-06-22 13:47:20,845 epoch 17 - iter 30/55 - loss 2.92485389 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 13:47:23,242 epoch 17 - iter 35/55 - loss 2.94644081 - samples/sec: 66.77 - lr: 0.000030
2021-06-22 13:47:25,640 epoch 17 - iter 40/55 - loss 2.95980679 - samples/sec: 66.76 - lr: 0.000030
2021-06-22 13:47:28,026 epoch 17 - iter 45/55 - loss 2.98852876 - samples/sec: 67.08 - lr: 0.000030
2021-06-22 13:47:30,428 epoch 17 - iter 50/55 - loss 2.98473859 - samples/sec: 66.63 - lr: 0.000030
2021-06-22 13:47:32,708 epoch 17 - iter 55/55 - loss 2.99198042 - samples/sec: 70.19 - lr: 0.000030
2021-06-22 13:47:32,708 ----------------------------------------------------------------------------------------------------
2021-06-22 13:47:32,708 EPOCH 17 done: loss 2.9920 - lr 0.0000300
2021-06-22 13:47:33,893 DEV : loss 2.4052014350891113 - score 0.883
2021-06-22 13:47:33,911 BAD EPOCHS (no improvement): 2
2021-06-22 13:47:33,911 ----------------------------------------------------------------------------------------------------
2021-06-22 13:47:36,324 epoch 18 - iter 5/55 - loss 3.21169853 - samples/sec: 66.31 - lr: 0.000030
2021-06-22 13:47:38,714 epoch 18 - iter 10/55 - loss 3.07097034 - samples/sec: 66.97 - lr: 0.000030
2021-06-22 13:47:41,116 epoch 18 - iter 15/55 - loss 2.99602280 - samples/sec: 66.64 - lr: 0.000030
2021-06-22 13:47:43,519 epoch 18 - iter 20/55 - loss 3.04915937 - samples/sec: 66.61 - lr: 0.000030
2021-06-22 13:47:45,927 epoch 18 - iter 25/55 - loss 3.04757887 - samples/sec: 66.44 - lr: 0.000030
2021-06-22 13:47:48,348 epoch 18 - iter 30/55 - loss 3.05644884 - samples/sec: 66.12 - lr: 0.000030
2021-06-22 13:47:50,744 epoch 18 - iter 35/55 - loss 3.04022226 - samples/sec: 66.80 - lr: 0.000030
2021-06-22 13:47:53,144 epoch 18 - iter 40/55 - loss 3.01697836 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 13:47:55,555 epoch 18 - iter 45/55 - loss 2.99197818 - samples/sec: 66.38 - lr: 0.000030
2021-06-22 13:47:57,946 epoch 18 - iter 50/55 - loss 2.93321095 - samples/sec: 66.92 - lr: 0.000030
2021-06-22 13:48:00,224 epoch 18 - iter 55/55 - loss 2.94712373 - samples/sec: 70.26 - lr: 0.000030
2021-06-22 13:48:00,225 ----------------------------------------------------------------------------------------------------
2021-06-22 13:48:00,225 EPOCH 18 done: loss 2.9471 - lr 0.0000300
2021-06-22 13:48:01,411 DEV : loss 2.3732497692108154 - score 0.8884
2021-06-22 13:48:01,429 BAD EPOCHS (no improvement): 3
2021-06-22 13:48:01,429 ----------------------------------------------------------------------------------------------------
2021-06-22 13:48:03,816 epoch 19 - iter 5/55 - loss 2.67464561 - samples/sec: 67.04 - lr: 0.000030
2021-06-22 13:48:06,221 epoch 19 - iter 10/55 - loss 2.79636095 - samples/sec: 66.54 - lr: 0.000030
2021-06-22 13:48:08,638 epoch 19 - iter 15/55 - loss 2.93495537 - samples/sec: 66.21 - lr: 0.000030
2021-06-22 13:48:11,042 epoch 19 - iter 20/55 - loss 2.85335962 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 13:48:13,460 epoch 19 - iter 25/55 - loss 2.86259027 - samples/sec: 66.19 - lr: 0.000030
2021-06-22 13:48:15,868 epoch 19 - iter 30/55 - loss 2.84375572 - samples/sec: 66.46 - lr: 0.000030
2021-06-22 13:48:18,272 epoch 19 - iter 35/55 - loss 2.90098538 - samples/sec: 66.57 - lr: 0.000030
2021-06-22 13:48:20,691 epoch 19 - iter 40/55 - loss 2.89248431 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 13:48:23,100 epoch 19 - iter 45/55 - loss 2.92871733 - samples/sec: 66.45 - lr: 0.000030
2021-06-22 13:48:25,523 epoch 19 - iter 50/55 - loss 2.95403800 - samples/sec: 66.03 - lr: 0.000030
2021-06-22 13:48:27,808 epoch 19 - iter 55/55 - loss 2.92972463 - samples/sec: 70.06 - lr: 0.000030
2021-06-22 13:48:27,808 ----------------------------------------------------------------------------------------------------
2021-06-22 13:48:27,808 EPOCH 19 done: loss 2.9297 - lr 0.0000300
2021-06-22 13:48:28,993 DEV : loss 2.3929386138916016 - score 0.8842
Epoch    19: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 13:48:29,010 BAD EPOCHS (no improvement): 4
2021-06-22 13:48:29,010 ----------------------------------------------------------------------------------------------------
2021-06-22 13:48:31,421 epoch 20 - iter 5/55 - loss 3.00989313 - samples/sec: 66.40 - lr: 0.000015
2021-06-22 13:48:33,842 epoch 20 - iter 10/55 - loss 2.88659101 - samples/sec: 66.11 - lr: 0.000015
2021-06-22 13:48:36,247 epoch 20 - iter 15/55 - loss 2.88354438 - samples/sec: 66.53 - lr: 0.000015
2021-06-22 13:48:38,661 epoch 20 - iter 20/55 - loss 2.92233162 - samples/sec: 66.31 - lr: 0.000015
2021-06-22 13:48:41,079 epoch 20 - iter 25/55 - loss 2.88619422 - samples/sec: 66.18 - lr: 0.000015
2021-06-22 13:48:43,500 epoch 20 - iter 30/55 - loss 2.86553432 - samples/sec: 66.11 - lr: 0.000015
2021-06-22 13:48:45,915 epoch 20 - iter 35/55 - loss 2.87218932 - samples/sec: 66.27 - lr: 0.000015
2021-06-22 13:48:48,305 epoch 20 - iter 40/55 - loss 2.87834624 - samples/sec: 66.97 - lr: 0.000015
2021-06-22 13:48:50,708 epoch 20 - iter 45/55 - loss 2.89608655 - samples/sec: 66.58 - lr: 0.000015
2021-06-22 13:48:53,119 epoch 20 - iter 50/55 - loss 2.87305863 - samples/sec: 66.38 - lr: 0.000015
2021-06-22 13:48:55,597 epoch 20 - iter 55/55 - loss 2.87328954 - samples/sec: 64.60 - lr: 0.000015
2021-06-22 13:48:55,597 ----------------------------------------------------------------------------------------------------
2021-06-22 13:48:55,597 EPOCH 20 done: loss 2.8733 - lr 0.0000150
2021-06-22 13:48:56,781 DEV : loss 2.396907091140747 - score 0.8831
2021-06-22 13:48:56,798 BAD EPOCHS (no improvement): 1
2021-06-22 13:48:56,799 ----------------------------------------------------------------------------------------------------
2021-06-22 13:48:59,213 epoch 21 - iter 5/55 - loss 2.86738153 - samples/sec: 66.30 - lr: 0.000015
2021-06-22 13:49:01,615 epoch 21 - iter 10/55 - loss 2.82947719 - samples/sec: 66.63 - lr: 0.000015
2021-06-22 13:49:04,039 epoch 21 - iter 15/55 - loss 2.85274250 - samples/sec: 66.03 - lr: 0.000015
2021-06-22 13:49:06,451 epoch 21 - iter 20/55 - loss 2.79414506 - samples/sec: 66.34 - lr: 0.000015
2021-06-22 13:49:08,878 epoch 21 - iter 25/55 - loss 2.75341506 - samples/sec: 65.95 - lr: 0.000015
2021-06-22 13:49:11,312 epoch 21 - iter 30/55 - loss 2.75799626 - samples/sec: 65.75 - lr: 0.000015
2021-06-22 13:49:13,734 epoch 21 - iter 35/55 - loss 2.77076896 - samples/sec: 66.09 - lr: 0.000015
2021-06-22 13:49:16,123 epoch 21 - iter 40/55 - loss 2.79232194 - samples/sec: 66.99 - lr: 0.000015
2021-06-22 13:49:18,573 epoch 21 - iter 45/55 - loss 2.78934088 - samples/sec: 65.33 - lr: 0.000015
2021-06-22 13:49:20,974 epoch 21 - iter 50/55 - loss 2.80362052 - samples/sec: 66.64 - lr: 0.000015
2021-06-22 13:49:23,259 epoch 21 - iter 55/55 - loss 2.83021221 - samples/sec: 70.06 - lr: 0.000015
2021-06-22 13:49:23,259 ----------------------------------------------------------------------------------------------------
2021-06-22 13:49:23,259 EPOCH 21 done: loss 2.8302 - lr 0.0000150
2021-06-22 13:49:24,442 DEV : loss 2.3558945655822754 - score 0.8856
2021-06-22 13:49:24,460 BAD EPOCHS (no improvement): 2
2021-06-22 13:49:24,460 ----------------------------------------------------------------------------------------------------
2021-06-22 13:49:26,861 epoch 22 - iter 5/55 - loss 2.62201161 - samples/sec: 66.66 - lr: 0.000015
2021-06-22 13:49:29,270 epoch 22 - iter 10/55 - loss 2.76947553 - samples/sec: 66.43 - lr: 0.000015
2021-06-22 13:49:31,692 epoch 22 - iter 15/55 - loss 2.83784178 - samples/sec: 66.08 - lr: 0.000015
2021-06-22 13:49:34,098 epoch 22 - iter 20/55 - loss 2.83208480 - samples/sec: 66.52 - lr: 0.000015
2021-06-22 13:49:36,527 epoch 22 - iter 25/55 - loss 2.83538944 - samples/sec: 65.90 - lr: 0.000015
2021-06-22 13:49:38,951 epoch 22 - iter 30/55 - loss 2.85305722 - samples/sec: 66.04 - lr: 0.000015
2021-06-22 13:49:41,346 epoch 22 - iter 35/55 - loss 2.83038381 - samples/sec: 66.80 - lr: 0.000015
2021-06-22 13:49:43,743 epoch 22 - iter 40/55 - loss 2.82892573 - samples/sec: 66.77 - lr: 0.000015
2021-06-22 13:49:46,160 epoch 22 - iter 45/55 - loss 2.80028195 - samples/sec: 66.23 - lr: 0.000015
2021-06-22 13:49:48,580 epoch 22 - iter 50/55 - loss 2.82058809 - samples/sec: 66.15 - lr: 0.000015
2021-06-22 13:49:50,865 epoch 22 - iter 55/55 - loss 2.85663325 - samples/sec: 70.04 - lr: 0.000015
2021-06-22 13:49:50,865 ----------------------------------------------------------------------------------------------------
2021-06-22 13:49:50,865 EPOCH 22 done: loss 2.8566 - lr 0.0000150
2021-06-22 13:49:52,049 DEV : loss 2.4111814498901367 - score 0.8832
2021-06-22 13:49:52,066 BAD EPOCHS (no improvement): 3
2021-06-22 13:49:52,067 ----------------------------------------------------------------------------------------------------
2021-06-22 13:49:54,476 epoch 23 - iter 5/55 - loss 2.81986480 - samples/sec: 66.41 - lr: 0.000015
2021-06-22 13:49:56,906 epoch 23 - iter 10/55 - loss 2.82321029 - samples/sec: 65.88 - lr: 0.000015
2021-06-22 13:49:59,310 epoch 23 - iter 15/55 - loss 2.80646329 - samples/sec: 66.58 - lr: 0.000015
2021-06-22 13:50:01,731 epoch 23 - iter 20/55 - loss 2.76603993 - samples/sec: 66.10 - lr: 0.000015
2021-06-22 13:50:04,141 epoch 23 - iter 25/55 - loss 2.75353258 - samples/sec: 66.41 - lr: 0.000015
2021-06-22 13:50:06,539 epoch 23 - iter 30/55 - loss 2.78806400 - samples/sec: 66.74 - lr: 0.000015
2021-06-22 13:50:08,955 epoch 23 - iter 35/55 - loss 2.80951290 - samples/sec: 66.24 - lr: 0.000015
2021-06-22 13:50:11,376 epoch 23 - iter 40/55 - loss 2.79967446 - samples/sec: 66.12 - lr: 0.000015
2021-06-22 13:50:13,770 epoch 23 - iter 45/55 - loss 2.78977213 - samples/sec: 66.86 - lr: 0.000015
2021-06-22 13:50:16,187 epoch 23 - iter 50/55 - loss 2.78678059 - samples/sec: 66.20 - lr: 0.000015
2021-06-22 13:50:18,486 epoch 23 - iter 55/55 - loss 2.79443376 - samples/sec: 69.62 - lr: 0.000015
2021-06-22 13:50:18,487 ----------------------------------------------------------------------------------------------------
2021-06-22 13:50:18,487 EPOCH 23 done: loss 2.7944 - lr 0.0000150
2021-06-22 13:50:19,672 DEV : loss 2.3516035079956055 - score 0.8868
Epoch    23: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 13:50:19,689 BAD EPOCHS (no improvement): 4
2021-06-22 13:50:19,690 ----------------------------------------------------------------------------------------------------
2021-06-22 13:50:22,070 epoch 24 - iter 5/55 - loss 2.79213657 - samples/sec: 67.25 - lr: 0.000008
2021-06-22 13:50:24,498 epoch 24 - iter 10/55 - loss 2.71785123 - samples/sec: 65.90 - lr: 0.000008
2021-06-22 13:50:26,931 epoch 24 - iter 15/55 - loss 2.75073120 - samples/sec: 65.77 - lr: 0.000008
2021-06-22 13:50:29,343 epoch 24 - iter 20/55 - loss 2.73142372 - samples/sec: 66.36 - lr: 0.000008
2021-06-22 13:50:31,755 epoch 24 - iter 25/55 - loss 2.76216044 - samples/sec: 66.37 - lr: 0.000008
2021-06-22 13:50:34,171 epoch 24 - iter 30/55 - loss 2.77768758 - samples/sec: 66.24 - lr: 0.000008
2021-06-22 13:50:36,586 epoch 24 - iter 35/55 - loss 2.73806998 - samples/sec: 66.27 - lr: 0.000008
2021-06-22 13:50:39,001 epoch 24 - iter 40/55 - loss 2.76179588 - samples/sec: 66.27 - lr: 0.000008
2021-06-22 13:50:41,414 epoch 24 - iter 45/55 - loss 2.75781350 - samples/sec: 66.33 - lr: 0.000008
2021-06-22 13:50:43,824 epoch 24 - iter 50/55 - loss 2.77719128 - samples/sec: 66.42 - lr: 0.000008
2021-06-22 13:50:46,121 epoch 24 - iter 55/55 - loss 2.78186395 - samples/sec: 69.66 - lr: 0.000008
2021-06-22 13:50:46,122 ----------------------------------------------------------------------------------------------------
2021-06-22 13:50:46,122 EPOCH 24 done: loss 2.7819 - lr 0.0000075
2021-06-22 13:50:47,304 DEV : loss 2.370375394821167 - score 0.886
2021-06-22 13:50:47,321 BAD EPOCHS (no improvement): 1
2021-06-22 13:50:47,322 ----------------------------------------------------------------------------------------------------
2021-06-22 13:50:49,915 epoch 25 - iter 5/55 - loss 2.65055985 - samples/sec: 61.72 - lr: 0.000008
2021-06-22 13:50:52,328 epoch 25 - iter 10/55 - loss 2.68425219 - samples/sec: 66.32 - lr: 0.000008
2021-06-22 13:50:54,732 epoch 25 - iter 15/55 - loss 2.67983748 - samples/sec: 66.58 - lr: 0.000008
2021-06-22 13:50:57,145 epoch 25 - iter 20/55 - loss 2.66242292 - samples/sec: 66.33 - lr: 0.000008
2021-06-22 13:50:59,566 epoch 25 - iter 25/55 - loss 2.73519711 - samples/sec: 66.10 - lr: 0.000008
2021-06-22 13:51:01,979 epoch 25 - iter 30/55 - loss 2.70447628 - samples/sec: 66.33 - lr: 0.000008
2021-06-22 13:51:04,380 epoch 25 - iter 35/55 - loss 2.69836723 - samples/sec: 66.64 - lr: 0.000008
2021-06-22 13:51:06,792 epoch 25 - iter 40/55 - loss 2.66936642 - samples/sec: 66.38 - lr: 0.000008
2021-06-22 13:51:09,223 epoch 25 - iter 45/55 - loss 2.71030242 - samples/sec: 65.82 - lr: 0.000008
2021-06-22 13:51:11,641 epoch 25 - iter 50/55 - loss 2.72561001 - samples/sec: 66.20 - lr: 0.000008
2021-06-22 13:51:13,936 epoch 25 - iter 55/55 - loss 2.73627705 - samples/sec: 69.72 - lr: 0.000008
2021-06-22 13:51:13,937 ----------------------------------------------------------------------------------------------------
2021-06-22 13:51:13,937 EPOCH 25 done: loss 2.7363 - lr 0.0000075
2021-06-22 13:51:15,121 DEV : loss 2.3695833683013916 - score 0.8843
2021-06-22 13:51:15,139 BAD EPOCHS (no improvement): 2
2021-06-22 13:51:15,139 ----------------------------------------------------------------------------------------------------
2021-06-22 13:51:17,538 epoch 26 - iter 5/55 - loss 2.75532570 - samples/sec: 66.73 - lr: 0.000008
2021-06-22 13:51:19,945 epoch 26 - iter 10/55 - loss 2.66944668 - samples/sec: 66.47 - lr: 0.000008
2021-06-22 13:51:22,352 epoch 26 - iter 15/55 - loss 2.59144746 - samples/sec: 66.50 - lr: 0.000008
2021-06-22 13:51:24,761 epoch 26 - iter 20/55 - loss 2.65150986 - samples/sec: 66.43 - lr: 0.000008
2021-06-22 13:51:27,173 epoch 26 - iter 25/55 - loss 2.64256995 - samples/sec: 66.37 - lr: 0.000008
2021-06-22 13:51:29,578 epoch 26 - iter 30/55 - loss 2.63601759 - samples/sec: 66.53 - lr: 0.000008
2021-06-22 13:51:31,990 epoch 26 - iter 35/55 - loss 2.66111426 - samples/sec: 66.35 - lr: 0.000008
2021-06-22 13:51:34,419 epoch 26 - iter 40/55 - loss 2.67958378 - samples/sec: 65.91 - lr: 0.000008
2021-06-22 13:51:36,829 epoch 26 - iter 45/55 - loss 2.68205854 - samples/sec: 66.40 - lr: 0.000008
2021-06-22 13:51:39,262 epoch 26 - iter 50/55 - loss 2.70211029 - samples/sec: 65.78 - lr: 0.000008
2021-06-22 13:51:41,545 epoch 26 - iter 55/55 - loss 2.68994613 - samples/sec: 70.10 - lr: 0.000008
2021-06-22 13:51:41,545 ----------------------------------------------------------------------------------------------------
2021-06-22 13:51:41,545 EPOCH 26 done: loss 2.6899 - lr 0.0000075
2021-06-22 13:51:42,730 DEV : loss 2.3770079612731934 - score 0.8837
2021-06-22 13:51:42,748 BAD EPOCHS (no improvement): 3
2021-06-22 13:51:42,748 ----------------------------------------------------------------------------------------------------
2021-06-22 13:51:45,128 epoch 27 - iter 5/55 - loss 2.72929101 - samples/sec: 67.24 - lr: 0.000008
2021-06-22 13:51:47,526 epoch 27 - iter 10/55 - loss 2.55903730 - samples/sec: 66.75 - lr: 0.000008
2021-06-22 13:51:49,943 epoch 27 - iter 15/55 - loss 2.64074910 - samples/sec: 66.21 - lr: 0.000008
2021-06-22 13:51:52,371 epoch 27 - iter 20/55 - loss 2.64355183 - samples/sec: 65.93 - lr: 0.000008
2021-06-22 13:51:54,795 epoch 27 - iter 25/55 - loss 2.65143505 - samples/sec: 66.01 - lr: 0.000008
2021-06-22 13:51:57,188 epoch 27 - iter 30/55 - loss 2.70270908 - samples/sec: 66.87 - lr: 0.000008
2021-06-22 13:51:59,614 epoch 27 - iter 35/55 - loss 2.71411670 - samples/sec: 65.97 - lr: 0.000008
2021-06-22 13:52:02,055 epoch 27 - iter 40/55 - loss 2.69952060 - samples/sec: 65.58 - lr: 0.000008
2021-06-22 13:52:04,450 epoch 27 - iter 45/55 - loss 2.72707721 - samples/sec: 66.82 - lr: 0.000008
2021-06-22 13:52:06,864 epoch 27 - iter 50/55 - loss 2.71730143 - samples/sec: 66.30 - lr: 0.000008
2021-06-22 13:52:09,172 epoch 27 - iter 55/55 - loss 2.72563226 - samples/sec: 69.35 - lr: 0.000008
2021-06-22 13:52:09,172 ----------------------------------------------------------------------------------------------------
2021-06-22 13:52:09,172 EPOCH 27 done: loss 2.7256 - lr 0.0000075
2021-06-22 13:52:10,357 DEV : loss 2.3595848083496094 - score 0.8856
Epoch    27: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 13:52:10,374 BAD EPOCHS (no improvement): 4
2021-06-22 13:52:10,375 ----------------------------------------------------------------------------------------------------
2021-06-22 13:52:12,788 epoch 28 - iter 5/55 - loss 2.51478095 - samples/sec: 66.30 - lr: 0.000004
2021-06-22 13:52:15,201 epoch 28 - iter 10/55 - loss 2.60716233 - samples/sec: 66.33 - lr: 0.000004
2021-06-22 13:52:17,593 epoch 28 - iter 15/55 - loss 2.59824940 - samples/sec: 66.91 - lr: 0.000004
2021-06-22 13:52:20,008 epoch 28 - iter 20/55 - loss 2.59265695 - samples/sec: 66.27 - lr: 0.000004
2021-06-22 13:52:22,411 epoch 28 - iter 25/55 - loss 2.65240711 - samples/sec: 66.60 - lr: 0.000004
2021-06-22 13:52:24,809 epoch 28 - iter 30/55 - loss 2.68092233 - samples/sec: 66.76 - lr: 0.000004
2021-06-22 13:52:27,216 epoch 28 - iter 35/55 - loss 2.65649793 - samples/sec: 66.48 - lr: 0.000004
2021-06-22 13:52:29,621 epoch 28 - iter 40/55 - loss 2.63699287 - samples/sec: 66.53 - lr: 0.000004
2021-06-22 13:52:32,027 epoch 28 - iter 45/55 - loss 2.62898863 - samples/sec: 66.52 - lr: 0.000004
2021-06-22 13:52:34,428 epoch 28 - iter 50/55 - loss 2.62786984 - samples/sec: 66.67 - lr: 0.000004
2021-06-22 13:52:36,701 epoch 28 - iter 55/55 - loss 2.66882285 - samples/sec: 70.40 - lr: 0.000004
2021-06-22 13:52:36,702 ----------------------------------------------------------------------------------------------------
2021-06-22 13:52:36,702 EPOCH 28 done: loss 2.6688 - lr 0.0000038
2021-06-22 13:52:37,895 DEV : loss 2.3530173301696777 - score 0.8853
2021-06-22 13:52:37,913 BAD EPOCHS (no improvement): 1
2021-06-22 13:52:37,913 ----------------------------------------------------------------------------------------------------
2021-06-22 13:52:40,293 epoch 29 - iter 5/55 - loss 2.48413205 - samples/sec: 67.25 - lr: 0.000004
2021-06-22 13:52:42,684 epoch 29 - iter 10/55 - loss 2.50441556 - samples/sec: 66.94 - lr: 0.000004
2021-06-22 13:52:45,077 epoch 29 - iter 15/55 - loss 2.47688812 - samples/sec: 66.88 - lr: 0.000004
2021-06-22 13:52:47,492 epoch 29 - iter 20/55 - loss 2.55436219 - samples/sec: 66.28 - lr: 0.000004
2021-06-22 13:52:49,897 epoch 29 - iter 25/55 - loss 2.58312144 - samples/sec: 66.54 - lr: 0.000004
2021-06-22 13:52:52,323 epoch 29 - iter 30/55 - loss 2.61499008 - samples/sec: 65.98 - lr: 0.000004
2021-06-22 13:52:54,752 epoch 29 - iter 35/55 - loss 2.61024422 - samples/sec: 65.88 - lr: 0.000004
2021-06-22 13:52:57,163 epoch 29 - iter 40/55 - loss 2.59942499 - samples/sec: 66.37 - lr: 0.000004
2021-06-22 13:52:59,561 epoch 29 - iter 45/55 - loss 2.59914006 - samples/sec: 66.76 - lr: 0.000004
2021-06-22 13:53:02,143 epoch 29 - iter 50/55 - loss 2.59941764 - samples/sec: 61.98 - lr: 0.000004
2021-06-22 13:53:04,420 epoch 29 - iter 55/55 - loss 2.63375602 - samples/sec: 70.29 - lr: 0.000004
2021-06-22 13:53:04,420 ----------------------------------------------------------------------------------------------------
2021-06-22 13:53:04,420 EPOCH 29 done: loss 2.6338 - lr 0.0000038
2021-06-22 13:53:05,604 DEV : loss 2.3548433780670166 - score 0.8857
2021-06-22 13:53:05,622 BAD EPOCHS (no improvement): 2
2021-06-22 13:53:05,622 ----------------------------------------------------------------------------------------------------
2021-06-22 13:53:08,032 epoch 30 - iter 5/55 - loss 2.95425491 - samples/sec: 66.40 - lr: 0.000004
2021-06-22 13:53:10,432 epoch 30 - iter 10/55 - loss 2.65765934 - samples/sec: 66.69 - lr: 0.000004
2021-06-22 13:53:12,842 epoch 30 - iter 15/55 - loss 2.70764542 - samples/sec: 66.40 - lr: 0.000004
2021-06-22 13:53:15,255 epoch 30 - iter 20/55 - loss 2.61859661 - samples/sec: 66.34 - lr: 0.000004
2021-06-22 13:53:17,670 epoch 30 - iter 25/55 - loss 2.64558702 - samples/sec: 66.28 - lr: 0.000004
2021-06-22 13:53:20,064 epoch 30 - iter 30/55 - loss 2.64043047 - samples/sec: 66.84 - lr: 0.000004
2021-06-22 13:53:22,462 epoch 30 - iter 35/55 - loss 2.63875112 - samples/sec: 66.74 - lr: 0.000004
2021-06-22 13:53:24,844 epoch 30 - iter 40/55 - loss 2.64835790 - samples/sec: 67.18 - lr: 0.000004
2021-06-22 13:53:27,247 epoch 30 - iter 45/55 - loss 2.65914220 - samples/sec: 66.61 - lr: 0.000004
2021-06-22 13:53:29,653 epoch 30 - iter 50/55 - loss 2.65488037 - samples/sec: 66.54 - lr: 0.000004
2021-06-22 13:53:31,911 epoch 30 - iter 55/55 - loss 2.66268181 - samples/sec: 70.86 - lr: 0.000004
2021-06-22 13:53:31,912 ----------------------------------------------------------------------------------------------------
2021-06-22 13:53:31,912 EPOCH 30 done: loss 2.6627 - lr 0.0000038
2021-06-22 13:53:33,096 DEV : loss 2.357065200805664 - score 0.8848
2021-06-22 13:53:33,114 BAD EPOCHS (no improvement): 3
2021-06-22 13:53:33,114 ----------------------------------------------------------------------------------------------------
2021-06-22 13:53:35,509 epoch 31 - iter 5/55 - loss 2.66904945 - samples/sec: 66.82 - lr: 0.000004
2021-06-22 13:53:37,918 epoch 31 - iter 10/55 - loss 2.63729508 - samples/sec: 66.42 - lr: 0.000004
2021-06-22 13:53:40,338 epoch 31 - iter 15/55 - loss 2.72855906 - samples/sec: 66.14 - lr: 0.000004
2021-06-22 13:53:42,733 epoch 31 - iter 20/55 - loss 2.65772827 - samples/sec: 66.83 - lr: 0.000004
2021-06-22 13:53:45,115 epoch 31 - iter 25/55 - loss 2.68522846 - samples/sec: 67.20 - lr: 0.000004
2021-06-22 13:53:47,511 epoch 31 - iter 30/55 - loss 2.66300337 - samples/sec: 66.78 - lr: 0.000004
2021-06-22 13:53:49,873 epoch 31 - iter 35/55 - loss 2.67143860 - samples/sec: 67.78 - lr: 0.000004
2021-06-22 13:53:52,251 epoch 31 - iter 40/55 - loss 2.66902298 - samples/sec: 67.28 - lr: 0.000004
2021-06-22 13:53:54,654 epoch 31 - iter 45/55 - loss 2.66464906 - samples/sec: 66.60 - lr: 0.000004
2021-06-22 13:53:57,036 epoch 31 - iter 50/55 - loss 2.66809240 - samples/sec: 67.19 - lr: 0.000004
2021-06-22 13:53:59,325 epoch 31 - iter 55/55 - loss 2.66006748 - samples/sec: 69.92 - lr: 0.000004
2021-06-22 13:53:59,326 ----------------------------------------------------------------------------------------------------
2021-06-22 13:53:59,326 EPOCH 31 done: loss 2.6601 - lr 0.0000038
2021-06-22 13:54:00,512 DEV : loss 2.3605716228485107 - score 0.8846
Epoch    31: reducing learning rate of group 0 to 1.8750e-06.
2021-06-22 13:54:00,529 BAD EPOCHS (no improvement): 4
2021-06-22 13:54:00,529 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:00,530 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:00,530 learning rate too small - quitting training!
2021-06-22 13:54:00,530 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:01,694 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:01,694 Testing using best model ...
2021-06-22 13:54:01,695 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/best-model.pt
2021-06-22 13:54:10,683 0.8753	0.8630	0.8691
2021-06-22 13:54:10,684 
Results:
- F1-score (micro) 0.8691
- F1-score (macro) 0.8691

By class:
SENT       tp: 1165 - fp: 166 - fn: 185 - precision: 0.8753 - recall: 0.8630 - f1-score: 0.8691
2021-06-22 13:54:10,684 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/
2021-06-22 13:54:10,703 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb
2021-06-22 13:54:10,703 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/sent_train.txt
2021-06-22 13:54:10,706 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/sent_dev.txt
2021-06-22 13:54:10,708 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/sent_test.txt
Corpus: 501 train + 119 dev + 186 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 13:54:14,122 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:14,124 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 13:54:14,124 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:14,124 Corpus: "Corpus: 501 train + 119 dev + 186 test sentences"
2021-06-22 13:54:14,124 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:14,124 Parameters:
2021-06-22 13:54:14,124  - learning_rate: "3e-05"
2021-06-22 13:54:14,124  - mini_batch_size: "32"
2021-06-22 13:54:14,124  - patience: "3"
2021-06-22 13:54:14,124  - anneal_factor: "0.5"
2021-06-22 13:54:14,125  - max_epochs: "40"
2021-06-22 13:54:14,125  - shuffle: "True"
2021-06-22 13:54:14,125  - train_with_dev: "False"
2021-06-22 13:54:14,125  - batch_growth_annealing: "False"
2021-06-22 13:54:14,125 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:14,125 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb"
2021-06-22 13:54:14,125 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:14,125 Device: cuda:0
2021-06-22 13:54:14,125 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:14,125 Embeddings storage mode: cpu
2021-06-22 13:54:14,126 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:15,073 epoch 1 - iter 1/16 - loss 31.22527695 - samples/sec: 33.78 - lr: 0.000030
2021-06-22 13:54:16,036 epoch 1 - iter 2/16 - loss 29.74654007 - samples/sec: 33.26 - lr: 0.000030
2021-06-22 13:54:17,003 epoch 1 - iter 3/16 - loss 27.61595090 - samples/sec: 33.08 - lr: 0.000030
2021-06-22 13:54:17,973 epoch 1 - iter 4/16 - loss 25.46886683 - samples/sec: 33.02 - lr: 0.000030
2021-06-22 13:54:18,944 epoch 1 - iter 5/16 - loss 23.77529716 - samples/sec: 32.96 - lr: 0.000030
2021-06-22 13:54:19,890 epoch 1 - iter 6/16 - loss 22.00124200 - samples/sec: 33.83 - lr: 0.000030
2021-06-22 13:54:20,859 epoch 1 - iter 7/16 - loss 20.57935606 - samples/sec: 33.02 - lr: 0.000030
2021-06-22 13:54:21,829 epoch 1 - iter 8/16 - loss 19.11499023 - samples/sec: 33.02 - lr: 0.000030
2021-06-22 13:54:22,791 epoch 1 - iter 9/16 - loss 17.95448017 - samples/sec: 33.28 - lr: 0.000030
2021-06-22 13:54:23,746 epoch 1 - iter 10/16 - loss 16.90721259 - samples/sec: 33.52 - lr: 0.000030
2021-06-22 13:54:24,695 epoch 1 - iter 11/16 - loss 15.94566813 - samples/sec: 33.70 - lr: 0.000030
2021-06-22 13:54:25,663 epoch 1 - iter 12/16 - loss 15.11861046 - samples/sec: 33.08 - lr: 0.000030
2021-06-22 13:54:26,636 epoch 1 - iter 13/16 - loss 14.33812266 - samples/sec: 32.89 - lr: 0.000030
2021-06-22 13:54:27,599 epoch 1 - iter 14/16 - loss 13.68451302 - samples/sec: 33.25 - lr: 0.000030
2021-06-22 13:54:28,544 epoch 1 - iter 15/16 - loss 13.06085583 - samples/sec: 33.88 - lr: 0.000030
2021-06-22 13:54:29,190 epoch 1 - iter 16/16 - loss 12.50974345 - samples/sec: 49.55 - lr: 0.000030
2021-06-22 13:54:29,190 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:29,190 EPOCH 1 done: loss 12.5097 - lr 0.0000300
2021-06-22 13:54:31,247 DEV : loss 3.379373550415039 - score 0.0
2021-06-22 13:54:31,256 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:54:31,789 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:32,273 epoch 2 - iter 1/16 - loss 3.86554933 - samples/sec: 66.22 - lr: 0.000030
2021-06-22 13:54:32,772 epoch 2 - iter 2/16 - loss 3.63958395 - samples/sec: 64.15 - lr: 0.000030
2021-06-22 13:54:33,257 epoch 2 - iter 3/16 - loss 3.44899917 - samples/sec: 65.99 - lr: 0.000030
2021-06-22 13:54:33,752 epoch 2 - iter 4/16 - loss 3.44424295 - samples/sec: 64.68 - lr: 0.000030
2021-06-22 13:54:34,239 epoch 2 - iter 5/16 - loss 3.44878769 - samples/sec: 65.79 - lr: 0.000030
2021-06-22 13:54:34,732 epoch 2 - iter 6/16 - loss 3.42823605 - samples/sec: 65.01 - lr: 0.000030
2021-06-22 13:54:35,229 epoch 2 - iter 7/16 - loss 3.48184187 - samples/sec: 64.44 - lr: 0.000030
2021-06-22 13:54:35,721 epoch 2 - iter 8/16 - loss 3.51871231 - samples/sec: 65.05 - lr: 0.000030
2021-06-22 13:54:36,209 epoch 2 - iter 9/16 - loss 3.55889834 - samples/sec: 65.69 - lr: 0.000030
2021-06-22 13:54:36,698 epoch 2 - iter 10/16 - loss 3.51065965 - samples/sec: 65.46 - lr: 0.000030
2021-06-22 13:54:37,177 epoch 2 - iter 11/16 - loss 3.47788260 - samples/sec: 66.87 - lr: 0.000030
2021-06-22 13:54:37,651 epoch 2 - iter 12/16 - loss 3.36999496 - samples/sec: 67.60 - lr: 0.000030
2021-06-22 13:54:38,128 epoch 2 - iter 13/16 - loss 3.31270695 - samples/sec: 67.20 - lr: 0.000030
2021-06-22 13:54:38,629 epoch 2 - iter 14/16 - loss 3.30747141 - samples/sec: 63.93 - lr: 0.000030
2021-06-22 13:54:39,108 epoch 2 - iter 15/16 - loss 3.25407343 - samples/sec: 66.86 - lr: 0.000030
2021-06-22 13:54:39,438 epoch 2 - iter 16/16 - loss 3.20514445 - samples/sec: 97.16 - lr: 0.000030
2021-06-22 13:54:39,438 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:39,438 EPOCH 2 done: loss 3.2051 - lr 0.0000300
2021-06-22 13:54:40,058 DEV : loss 2.231515884399414 - score 0.0
2021-06-22 13:54:40,067 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:54:42,939 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:43,433 epoch 3 - iter 1/16 - loss 2.57202673 - samples/sec: 64.82 - lr: 0.000030
2021-06-22 13:54:43,922 epoch 3 - iter 2/16 - loss 2.51497960 - samples/sec: 65.50 - lr: 0.000030
2021-06-22 13:54:44,391 epoch 3 - iter 3/16 - loss 2.39595302 - samples/sec: 68.29 - lr: 0.000030
2021-06-22 13:54:44,882 epoch 3 - iter 4/16 - loss 2.40062273 - samples/sec: 65.36 - lr: 0.000030
2021-06-22 13:54:45,360 epoch 3 - iter 5/16 - loss 2.40685015 - samples/sec: 66.93 - lr: 0.000030
2021-06-22 13:54:45,852 epoch 3 - iter 6/16 - loss 2.37946633 - samples/sec: 65.07 - lr: 0.000030
2021-06-22 13:54:46,331 epoch 3 - iter 7/16 - loss 2.32084291 - samples/sec: 66.87 - lr: 0.000030
2021-06-22 13:54:46,822 epoch 3 - iter 8/16 - loss 2.31913483 - samples/sec: 65.35 - lr: 0.000030
2021-06-22 13:54:47,320 epoch 3 - iter 9/16 - loss 2.29490913 - samples/sec: 64.23 - lr: 0.000030
2021-06-22 13:54:47,814 epoch 3 - iter 10/16 - loss 2.24707284 - samples/sec: 64.81 - lr: 0.000030
2021-06-22 13:54:48,300 epoch 3 - iter 11/16 - loss 2.21128204 - samples/sec: 65.91 - lr: 0.000030
2021-06-22 13:54:48,794 epoch 3 - iter 12/16 - loss 2.19285191 - samples/sec: 64.88 - lr: 0.000030
2021-06-22 13:54:49,265 epoch 3 - iter 13/16 - loss 2.16757779 - samples/sec: 68.03 - lr: 0.000030
2021-06-22 13:54:49,758 epoch 3 - iter 14/16 - loss 2.13662299 - samples/sec: 65.00 - lr: 0.000030
2021-06-22 13:54:50,245 epoch 3 - iter 15/16 - loss 2.09632832 - samples/sec: 65.78 - lr: 0.000030
2021-06-22 13:54:50,590 epoch 3 - iter 16/16 - loss 2.05008376 - samples/sec: 92.86 - lr: 0.000030
2021-06-22 13:54:50,590 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:50,590 EPOCH 3 done: loss 2.0501 - lr 0.0000300
2021-06-22 13:54:51,206 DEV : loss 1.2477662563323975 - score 0.15
2021-06-22 13:54:51,214 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:54:54,128 ----------------------------------------------------------------------------------------------------
2021-06-22 13:54:54,617 epoch 4 - iter 1/16 - loss 1.86171961 - samples/sec: 65.59 - lr: 0.000030
2021-06-22 13:54:55,093 epoch 4 - iter 2/16 - loss 1.71415591 - samples/sec: 67.23 - lr: 0.000030
2021-06-22 13:54:55,594 epoch 4 - iter 3/16 - loss 1.58666448 - samples/sec: 63.97 - lr: 0.000030
2021-06-22 13:54:56,080 epoch 4 - iter 4/16 - loss 1.54477730 - samples/sec: 65.88 - lr: 0.000030
2021-06-22 13:54:56,557 epoch 4 - iter 5/16 - loss 1.47036169 - samples/sec: 67.11 - lr: 0.000030
2021-06-22 13:54:57,039 epoch 4 - iter 6/16 - loss 1.43093189 - samples/sec: 66.55 - lr: 0.000030
2021-06-22 13:54:57,520 epoch 4 - iter 7/16 - loss 1.46227373 - samples/sec: 66.56 - lr: 0.000030
2021-06-22 13:54:58,005 epoch 4 - iter 8/16 - loss 1.42401597 - samples/sec: 65.96 - lr: 0.000030
2021-06-22 13:54:58,496 epoch 4 - iter 9/16 - loss 1.38136003 - samples/sec: 65.26 - lr: 0.000030
2021-06-22 13:54:58,988 epoch 4 - iter 10/16 - loss 1.35095398 - samples/sec: 65.08 - lr: 0.000030
2021-06-22 13:54:59,474 epoch 4 - iter 11/16 - loss 1.33906278 - samples/sec: 66.02 - lr: 0.000030
2021-06-22 13:54:59,972 epoch 4 - iter 12/16 - loss 1.30241243 - samples/sec: 64.32 - lr: 0.000030
2021-06-22 13:55:00,458 epoch 4 - iter 13/16 - loss 1.31339553 - samples/sec: 65.80 - lr: 0.000030
2021-06-22 13:55:00,961 epoch 4 - iter 14/16 - loss 1.31371221 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 13:55:01,449 epoch 4 - iter 15/16 - loss 1.30748653 - samples/sec: 65.64 - lr: 0.000030
2021-06-22 13:55:01,795 epoch 4 - iter 16/16 - loss 1.29736026 - samples/sec: 92.62 - lr: 0.000030
2021-06-22 13:55:01,796 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:01,796 EPOCH 4 done: loss 1.2974 - lr 0.0000300
2021-06-22 13:55:02,415 DEV : loss 0.7032022476196289 - score 0.7402
2021-06-22 13:55:02,424 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:55:05,198 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:05,689 epoch 5 - iter 1/16 - loss 1.10465384 - samples/sec: 65.21 - lr: 0.000030
2021-06-22 13:55:06,161 epoch 5 - iter 2/16 - loss 0.96789360 - samples/sec: 67.90 - lr: 0.000030
2021-06-22 13:55:06,651 epoch 5 - iter 3/16 - loss 1.01880884 - samples/sec: 65.35 - lr: 0.000030
2021-06-22 13:55:07,149 epoch 5 - iter 4/16 - loss 1.01138237 - samples/sec: 64.37 - lr: 0.000030
2021-06-22 13:55:07,641 epoch 5 - iter 5/16 - loss 1.03278680 - samples/sec: 65.15 - lr: 0.000030
2021-06-22 13:55:08,128 epoch 5 - iter 6/16 - loss 0.99404665 - samples/sec: 65.72 - lr: 0.000030
2021-06-22 13:55:08,626 epoch 5 - iter 7/16 - loss 0.98735635 - samples/sec: 64.26 - lr: 0.000030
2021-06-22 13:55:09,107 epoch 5 - iter 8/16 - loss 0.97925455 - samples/sec: 66.68 - lr: 0.000030
2021-06-22 13:55:09,607 epoch 5 - iter 9/16 - loss 0.96967262 - samples/sec: 63.97 - lr: 0.000030
2021-06-22 13:55:10,109 epoch 5 - iter 10/16 - loss 0.96489812 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 13:55:10,587 epoch 5 - iter 11/16 - loss 0.94278206 - samples/sec: 67.11 - lr: 0.000030
2021-06-22 13:55:11,069 epoch 5 - iter 12/16 - loss 0.93303189 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 13:55:11,559 epoch 5 - iter 13/16 - loss 0.92101553 - samples/sec: 65.34 - lr: 0.000030
2021-06-22 13:55:12,047 epoch 5 - iter 14/16 - loss 0.91262619 - samples/sec: 65.62 - lr: 0.000030
2021-06-22 13:55:12,523 epoch 5 - iter 15/16 - loss 0.91582974 - samples/sec: 67.33 - lr: 0.000030
2021-06-22 13:55:12,866 epoch 5 - iter 16/16 - loss 0.90352480 - samples/sec: 93.45 - lr: 0.000030
2021-06-22 13:55:12,866 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:12,866 EPOCH 5 done: loss 0.9035 - lr 0.0000300
2021-06-22 13:55:13,482 DEV : loss 0.47507724165916443 - score 0.8451
2021-06-22 13:55:13,491 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:55:16,400 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:16,893 epoch 6 - iter 1/16 - loss 0.98542571 - samples/sec: 64.98 - lr: 0.000030
2021-06-22 13:55:17,381 epoch 6 - iter 2/16 - loss 0.88731259 - samples/sec: 65.67 - lr: 0.000030
2021-06-22 13:55:17,858 epoch 6 - iter 3/16 - loss 0.82592809 - samples/sec: 67.15 - lr: 0.000030
2021-06-22 13:55:18,356 epoch 6 - iter 4/16 - loss 0.77823487 - samples/sec: 64.27 - lr: 0.000030
2021-06-22 13:55:18,850 epoch 6 - iter 5/16 - loss 0.72909689 - samples/sec: 64.82 - lr: 0.000030
2021-06-22 13:55:19,347 epoch 6 - iter 6/16 - loss 0.73278960 - samples/sec: 64.55 - lr: 0.000030
2021-06-22 13:55:19,842 epoch 6 - iter 7/16 - loss 0.71120838 - samples/sec: 64.61 - lr: 0.000030
2021-06-22 13:55:20,317 epoch 6 - iter 8/16 - loss 0.68712427 - samples/sec: 67.49 - lr: 0.000030
2021-06-22 13:55:20,814 epoch 6 - iter 9/16 - loss 0.70198033 - samples/sec: 64.52 - lr: 0.000030
2021-06-22 13:55:21,289 epoch 6 - iter 10/16 - loss 0.70880195 - samples/sec: 67.34 - lr: 0.000030
2021-06-22 13:55:21,773 epoch 6 - iter 11/16 - loss 0.71605752 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 13:55:22,273 epoch 6 - iter 12/16 - loss 0.71274724 - samples/sec: 64.16 - lr: 0.000030
2021-06-22 13:55:22,746 epoch 6 - iter 13/16 - loss 0.70742984 - samples/sec: 67.61 - lr: 0.000030
2021-06-22 13:55:23,227 epoch 6 - iter 14/16 - loss 0.70845932 - samples/sec: 66.66 - lr: 0.000030
2021-06-22 13:55:23,718 epoch 6 - iter 15/16 - loss 0.68918065 - samples/sec: 65.19 - lr: 0.000030
2021-06-22 13:55:24,059 epoch 6 - iter 16/16 - loss 0.68014482 - samples/sec: 94.05 - lr: 0.000030
2021-06-22 13:55:24,059 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:24,059 EPOCH 6 done: loss 0.6801 - lr 0.0000300
2021-06-22 13:55:24,679 DEV : loss 0.38772115111351013 - score 0.8758
2021-06-22 13:55:24,687 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:55:27,705 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:28,198 epoch 7 - iter 1/16 - loss 0.43401670 - samples/sec: 65.07 - lr: 0.000030
2021-06-22 13:55:28,683 epoch 7 - iter 2/16 - loss 0.45304862 - samples/sec: 66.04 - lr: 0.000030
2021-06-22 13:55:29,176 epoch 7 - iter 3/16 - loss 0.55648353 - samples/sec: 64.88 - lr: 0.000030
2021-06-22 13:55:29,655 epoch 7 - iter 4/16 - loss 0.51574925 - samples/sec: 66.94 - lr: 0.000030
2021-06-22 13:55:30,149 epoch 7 - iter 5/16 - loss 0.60277166 - samples/sec: 64.84 - lr: 0.000030
2021-06-22 13:55:30,638 epoch 7 - iter 6/16 - loss 0.66185151 - samples/sec: 65.47 - lr: 0.000030
2021-06-22 13:55:31,123 epoch 7 - iter 7/16 - loss 0.62195146 - samples/sec: 66.01 - lr: 0.000030
2021-06-22 13:55:31,585 epoch 7 - iter 8/16 - loss 0.61412656 - samples/sec: 69.36 - lr: 0.000030
2021-06-22 13:55:32,060 epoch 7 - iter 9/16 - loss 0.58562287 - samples/sec: 67.51 - lr: 0.000030
2021-06-22 13:55:32,544 epoch 7 - iter 10/16 - loss 0.57752148 - samples/sec: 66.13 - lr: 0.000030
2021-06-22 13:55:33,040 epoch 7 - iter 11/16 - loss 0.58048939 - samples/sec: 64.55 - lr: 0.000030
2021-06-22 13:55:33,533 epoch 7 - iter 12/16 - loss 0.57371131 - samples/sec: 65.03 - lr: 0.000030
2021-06-22 13:55:34,015 epoch 7 - iter 13/16 - loss 0.57639872 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 13:55:34,500 epoch 7 - iter 14/16 - loss 0.58738260 - samples/sec: 66.08 - lr: 0.000030
2021-06-22 13:55:34,997 epoch 7 - iter 15/16 - loss 0.58005871 - samples/sec: 64.43 - lr: 0.000030
2021-06-22 13:55:35,346 epoch 7 - iter 16/16 - loss 0.57083136 - samples/sec: 91.86 - lr: 0.000030
2021-06-22 13:55:35,346 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:35,346 EPOCH 7 done: loss 0.5708 - lr 0.0000300
2021-06-22 13:55:36,052 DEV : loss 0.332785040140152 - score 0.8816
2021-06-22 13:55:36,061 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:55:38,886 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:39,367 epoch 8 - iter 1/16 - loss 0.48847276 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 13:55:39,847 epoch 8 - iter 2/16 - loss 0.50497925 - samples/sec: 66.79 - lr: 0.000030
2021-06-22 13:55:40,327 epoch 8 - iter 3/16 - loss 0.61181623 - samples/sec: 66.74 - lr: 0.000030
2021-06-22 13:55:40,810 epoch 8 - iter 4/16 - loss 0.63008136 - samples/sec: 66.22 - lr: 0.000030
2021-06-22 13:55:41,298 epoch 8 - iter 5/16 - loss 0.62399688 - samples/sec: 65.71 - lr: 0.000030
2021-06-22 13:55:41,789 epoch 8 - iter 6/16 - loss 0.58027983 - samples/sec: 65.15 - lr: 0.000030
2021-06-22 13:55:42,286 epoch 8 - iter 7/16 - loss 0.54661294 - samples/sec: 64.57 - lr: 0.000030
2021-06-22 13:55:42,788 epoch 8 - iter 8/16 - loss 0.55520594 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 13:55:43,280 epoch 8 - iter 9/16 - loss 0.56435374 - samples/sec: 65.10 - lr: 0.000030
2021-06-22 13:55:43,778 epoch 8 - iter 10/16 - loss 0.54572638 - samples/sec: 64.27 - lr: 0.000030
2021-06-22 13:55:44,265 epoch 8 - iter 11/16 - loss 0.53779987 - samples/sec: 65.76 - lr: 0.000030
2021-06-22 13:55:44,756 epoch 8 - iter 12/16 - loss 0.52900499 - samples/sec: 65.30 - lr: 0.000030
2021-06-22 13:55:45,253 epoch 8 - iter 13/16 - loss 0.51373923 - samples/sec: 64.34 - lr: 0.000030
2021-06-22 13:55:45,732 epoch 8 - iter 14/16 - loss 0.50317034 - samples/sec: 66.89 - lr: 0.000030
2021-06-22 13:55:46,231 epoch 8 - iter 15/16 - loss 0.50438868 - samples/sec: 64.20 - lr: 0.000030
2021-06-22 13:55:46,576 epoch 8 - iter 16/16 - loss 0.51944375 - samples/sec: 92.84 - lr: 0.000030
2021-06-22 13:55:46,577 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:46,577 EPOCH 8 done: loss 0.5194 - lr 0.0000300
2021-06-22 13:55:47,195 DEV : loss 0.30041763186454773 - score 0.902
2021-06-22 13:55:47,204 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:55:49,945 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:50,423 epoch 9 - iter 1/16 - loss 0.41538134 - samples/sec: 67.07 - lr: 0.000030
2021-06-22 13:55:50,912 epoch 9 - iter 2/16 - loss 0.40002795 - samples/sec: 65.47 - lr: 0.000030
2021-06-22 13:55:51,399 epoch 9 - iter 3/16 - loss 0.39188269 - samples/sec: 65.74 - lr: 0.000030
2021-06-22 13:55:51,888 epoch 9 - iter 4/16 - loss 0.43275850 - samples/sec: 65.63 - lr: 0.000030
2021-06-22 13:55:52,380 epoch 9 - iter 5/16 - loss 0.46420167 - samples/sec: 65.10 - lr: 0.000030
2021-06-22 13:55:52,876 epoch 9 - iter 6/16 - loss 0.43394282 - samples/sec: 64.58 - lr: 0.000030
2021-06-22 13:55:53,372 epoch 9 - iter 7/16 - loss 0.41397604 - samples/sec: 64.55 - lr: 0.000030
2021-06-22 13:55:53,861 epoch 9 - iter 8/16 - loss 0.42768456 - samples/sec: 65.40 - lr: 0.000030
2021-06-22 13:55:54,351 epoch 9 - iter 9/16 - loss 0.40514791 - samples/sec: 65.41 - lr: 0.000030
2021-06-22 13:55:54,831 epoch 9 - iter 10/16 - loss 0.41020071 - samples/sec: 66.76 - lr: 0.000030
2021-06-22 13:55:55,327 epoch 9 - iter 11/16 - loss 0.41041502 - samples/sec: 64.64 - lr: 0.000030
2021-06-22 13:55:55,823 epoch 9 - iter 12/16 - loss 0.42007025 - samples/sec: 64.49 - lr: 0.000030
2021-06-22 13:55:56,314 epoch 9 - iter 13/16 - loss 0.42592105 - samples/sec: 65.31 - lr: 0.000030
2021-06-22 13:55:56,776 epoch 9 - iter 14/16 - loss 0.41743878 - samples/sec: 69.32 - lr: 0.000030
2021-06-22 13:55:57,262 epoch 9 - iter 15/16 - loss 0.43802368 - samples/sec: 65.93 - lr: 0.000030
2021-06-22 13:55:57,606 epoch 9 - iter 16/16 - loss 0.42172785 - samples/sec: 92.96 - lr: 0.000030
2021-06-22 13:55:57,607 ----------------------------------------------------------------------------------------------------
2021-06-22 13:55:57,607 EPOCH 9 done: loss 0.4217 - lr 0.0000300
2021-06-22 13:55:58,222 DEV : loss 0.2781752347946167 - score 0.9079
2021-06-22 13:55:58,231 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:56:01,176 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:01,664 epoch 10 - iter 1/16 - loss 0.37763476 - samples/sec: 65.61 - lr: 0.000030
2021-06-22 13:56:02,153 epoch 10 - iter 2/16 - loss 0.36591075 - samples/sec: 65.53 - lr: 0.000030
2021-06-22 13:56:02,648 epoch 10 - iter 3/16 - loss 0.48297468 - samples/sec: 64.78 - lr: 0.000030
2021-06-22 13:56:03,132 epoch 10 - iter 4/16 - loss 0.44980928 - samples/sec: 66.10 - lr: 0.000030
2021-06-22 13:56:03,625 epoch 10 - iter 5/16 - loss 0.40303065 - samples/sec: 65.02 - lr: 0.000030
2021-06-22 13:56:04,113 epoch 10 - iter 6/16 - loss 0.40893109 - samples/sec: 65.60 - lr: 0.000030
2021-06-22 13:56:04,581 epoch 10 - iter 7/16 - loss 0.40591990 - samples/sec: 68.53 - lr: 0.000030
2021-06-22 13:56:05,076 epoch 10 - iter 8/16 - loss 0.39019683 - samples/sec: 64.67 - lr: 0.000030
2021-06-22 13:56:05,573 epoch 10 - iter 9/16 - loss 0.40120263 - samples/sec: 64.42 - lr: 0.000030
2021-06-22 13:56:06,047 epoch 10 - iter 10/16 - loss 0.40037593 - samples/sec: 67.53 - lr: 0.000030
2021-06-22 13:56:06,537 epoch 10 - iter 11/16 - loss 0.40354892 - samples/sec: 65.43 - lr: 0.000030
2021-06-22 13:56:07,019 epoch 10 - iter 12/16 - loss 0.41797252 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 13:56:07,501 epoch 10 - iter 13/16 - loss 0.41110284 - samples/sec: 66.43 - lr: 0.000030
2021-06-22 13:56:07,993 epoch 10 - iter 14/16 - loss 0.39868155 - samples/sec: 65.15 - lr: 0.000030
2021-06-22 13:56:08,481 epoch 10 - iter 15/16 - loss 0.39664981 - samples/sec: 65.68 - lr: 0.000030
2021-06-22 13:56:08,807 epoch 10 - iter 16/16 - loss 0.39822893 - samples/sec: 98.32 - lr: 0.000030
2021-06-22 13:56:08,807 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:08,807 EPOCH 10 done: loss 0.3982 - lr 0.0000300
2021-06-22 13:56:09,424 DEV : loss 0.2702593207359314 - score 0.915
2021-06-22 13:56:09,433 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:56:12,192 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:12,684 epoch 11 - iter 1/16 - loss 0.37559420 - samples/sec: 65.15 - lr: 0.000030
2021-06-22 13:56:13,175 epoch 11 - iter 2/16 - loss 0.41419980 - samples/sec: 65.19 - lr: 0.000030
2021-06-22 13:56:13,671 epoch 11 - iter 3/16 - loss 0.34905607 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 13:56:14,162 epoch 11 - iter 4/16 - loss 0.42849983 - samples/sec: 65.19 - lr: 0.000030
2021-06-22 13:56:14,657 epoch 11 - iter 5/16 - loss 0.42033650 - samples/sec: 64.74 - lr: 0.000030
2021-06-22 13:56:15,146 epoch 11 - iter 6/16 - loss 0.42403516 - samples/sec: 65.47 - lr: 0.000030
2021-06-22 13:56:15,637 epoch 11 - iter 7/16 - loss 0.40863964 - samples/sec: 65.32 - lr: 0.000030
2021-06-22 13:56:16,110 epoch 11 - iter 8/16 - loss 0.39439326 - samples/sec: 67.69 - lr: 0.000030
2021-06-22 13:56:16,597 epoch 11 - iter 9/16 - loss 0.40712433 - samples/sec: 65.82 - lr: 0.000030
2021-06-22 13:56:17,089 epoch 11 - iter 10/16 - loss 0.40283846 - samples/sec: 65.00 - lr: 0.000030
2021-06-22 13:56:17,560 epoch 11 - iter 11/16 - loss 0.40019518 - samples/sec: 68.10 - lr: 0.000030
2021-06-22 13:56:18,030 epoch 11 - iter 12/16 - loss 0.38923108 - samples/sec: 68.12 - lr: 0.000030
2021-06-22 13:56:18,509 epoch 11 - iter 13/16 - loss 0.38718475 - samples/sec: 66.82 - lr: 0.000030
2021-06-22 13:56:18,981 epoch 11 - iter 14/16 - loss 0.38521876 - samples/sec: 67.92 - lr: 0.000030
2021-06-22 13:56:19,459 epoch 11 - iter 15/16 - loss 0.38732172 - samples/sec: 66.98 - lr: 0.000030
2021-06-22 13:56:19,799 epoch 11 - iter 16/16 - loss 0.38549144 - samples/sec: 94.30 - lr: 0.000030
2021-06-22 13:56:19,799 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:19,800 EPOCH 11 done: loss 0.3855 - lr 0.0000300
2021-06-22 13:56:20,416 DEV : loss 0.2605242431163788 - score 0.9211
2021-06-22 13:56:20,424 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:56:23,311 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:23,833 epoch 12 - iter 1/16 - loss 0.25877380 - samples/sec: 64.54 - lr: 0.000030
2021-06-22 13:56:24,303 epoch 12 - iter 2/16 - loss 0.35552147 - samples/sec: 68.13 - lr: 0.000030
2021-06-22 13:56:24,783 epoch 12 - iter 3/16 - loss 0.34439739 - samples/sec: 66.74 - lr: 0.000030
2021-06-22 13:56:25,268 epoch 12 - iter 4/16 - loss 0.40619564 - samples/sec: 66.07 - lr: 0.000030
2021-06-22 13:56:25,766 epoch 12 - iter 5/16 - loss 0.35881677 - samples/sec: 64.39 - lr: 0.000030
2021-06-22 13:56:26,251 epoch 12 - iter 6/16 - loss 0.35201501 - samples/sec: 65.99 - lr: 0.000030
2021-06-22 13:56:26,737 epoch 12 - iter 7/16 - loss 0.36627619 - samples/sec: 65.91 - lr: 0.000030
2021-06-22 13:56:27,218 epoch 12 - iter 8/16 - loss 0.40028415 - samples/sec: 66.57 - lr: 0.000030
2021-06-22 13:56:27,698 epoch 12 - iter 9/16 - loss 0.39813749 - samples/sec: 66.71 - lr: 0.000030
2021-06-22 13:56:28,182 epoch 12 - iter 10/16 - loss 0.41298088 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 13:56:28,660 epoch 12 - iter 11/16 - loss 0.39379038 - samples/sec: 66.88 - lr: 0.000030
2021-06-22 13:56:29,156 epoch 12 - iter 12/16 - loss 0.37989148 - samples/sec: 64.65 - lr: 0.000030
2021-06-22 13:56:29,650 epoch 12 - iter 13/16 - loss 0.37543854 - samples/sec: 64.86 - lr: 0.000030
2021-06-22 13:56:30,133 epoch 12 - iter 14/16 - loss 0.37202496 - samples/sec: 66.29 - lr: 0.000030
2021-06-22 13:56:30,620 epoch 12 - iter 15/16 - loss 0.36633501 - samples/sec: 65.78 - lr: 0.000030
2021-06-22 13:56:30,956 epoch 12 - iter 16/16 - loss 0.35770551 - samples/sec: 95.25 - lr: 0.000030
2021-06-22 13:56:30,957 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:30,957 EPOCH 12 done: loss 0.3577 - lr 0.0000300
2021-06-22 13:56:31,573 DEV : loss 0.26255935430526733 - score 0.9351
2021-06-22 13:56:31,582 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:56:34,563 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:35,054 epoch 13 - iter 1/16 - loss 0.39361644 - samples/sec: 65.38 - lr: 0.000030
2021-06-22 13:56:35,520 epoch 13 - iter 2/16 - loss 0.35266870 - samples/sec: 68.64 - lr: 0.000030
2021-06-22 13:56:36,103 epoch 13 - iter 3/16 - loss 0.37099421 - samples/sec: 54.91 - lr: 0.000030
2021-06-22 13:56:36,596 epoch 13 - iter 4/16 - loss 0.34886977 - samples/sec: 65.02 - lr: 0.000030
2021-06-22 13:56:37,085 epoch 13 - iter 5/16 - loss 0.37580400 - samples/sec: 65.56 - lr: 0.000030
2021-06-22 13:56:37,585 epoch 13 - iter 6/16 - loss 0.35950172 - samples/sec: 64.00 - lr: 0.000030
2021-06-22 13:56:38,081 epoch 13 - iter 7/16 - loss 0.34675982 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 13:56:38,580 epoch 13 - iter 8/16 - loss 0.34281744 - samples/sec: 64.14 - lr: 0.000030
2021-06-22 13:56:39,076 epoch 13 - iter 9/16 - loss 0.35313677 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 13:56:39,561 epoch 13 - iter 10/16 - loss 0.34406984 - samples/sec: 65.94 - lr: 0.000030
2021-06-22 13:56:40,045 epoch 13 - iter 11/16 - loss 0.35140009 - samples/sec: 66.22 - lr: 0.000030
2021-06-22 13:56:40,542 epoch 13 - iter 12/16 - loss 0.35202251 - samples/sec: 64.45 - lr: 0.000030
2021-06-22 13:56:41,041 epoch 13 - iter 13/16 - loss 0.34048125 - samples/sec: 64.27 - lr: 0.000030
2021-06-22 13:56:41,530 epoch 13 - iter 14/16 - loss 0.34851950 - samples/sec: 65.46 - lr: 0.000030
2021-06-22 13:56:42,032 epoch 13 - iter 15/16 - loss 0.35147416 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 13:56:42,381 epoch 13 - iter 16/16 - loss 0.34863941 - samples/sec: 91.63 - lr: 0.000030
2021-06-22 13:56:42,382 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:42,382 EPOCH 13 done: loss 0.3486 - lr 0.0000300
2021-06-22 13:56:43,000 DEV : loss 0.25272560119628906 - score 0.9351
2021-06-22 13:56:43,009 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 13:56:45,830 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:46,308 epoch 14 - iter 1/16 - loss 0.23965460 - samples/sec: 67.11 - lr: 0.000030
2021-06-22 13:56:46,787 epoch 14 - iter 2/16 - loss 0.19985025 - samples/sec: 66.88 - lr: 0.000030
2021-06-22 13:56:47,283 epoch 14 - iter 3/16 - loss 0.27552941 - samples/sec: 64.55 - lr: 0.000030
2021-06-22 13:56:47,777 epoch 14 - iter 4/16 - loss 0.26333212 - samples/sec: 64.86 - lr: 0.000030
2021-06-22 13:56:48,272 epoch 14 - iter 5/16 - loss 0.27553381 - samples/sec: 64.72 - lr: 0.000030
2021-06-22 13:56:48,776 epoch 14 - iter 6/16 - loss 0.27283136 - samples/sec: 63.55 - lr: 0.000030
2021-06-22 13:56:49,257 epoch 14 - iter 7/16 - loss 0.26748379 - samples/sec: 66.61 - lr: 0.000030
2021-06-22 13:56:49,752 epoch 14 - iter 8/16 - loss 0.25034438 - samples/sec: 64.70 - lr: 0.000030
2021-06-22 13:56:50,249 epoch 14 - iter 9/16 - loss 0.26906807 - samples/sec: 64.50 - lr: 0.000030
2021-06-22 13:56:50,752 epoch 14 - iter 10/16 - loss 0.26220494 - samples/sec: 63.63 - lr: 0.000030
2021-06-22 13:56:51,246 epoch 14 - iter 11/16 - loss 0.25616105 - samples/sec: 64.82 - lr: 0.000030
2021-06-22 13:56:51,744 epoch 14 - iter 12/16 - loss 0.26038047 - samples/sec: 64.34 - lr: 0.000030
2021-06-22 13:56:52,242 epoch 14 - iter 13/16 - loss 0.27042445 - samples/sec: 64.33 - lr: 0.000030
2021-06-22 13:56:52,733 epoch 14 - iter 14/16 - loss 0.26746183 - samples/sec: 65.22 - lr: 0.000030
2021-06-22 13:56:53,213 epoch 14 - iter 15/16 - loss 0.26513405 - samples/sec: 66.70 - lr: 0.000030
2021-06-22 13:56:53,559 epoch 14 - iter 16/16 - loss 0.26975016 - samples/sec: 92.76 - lr: 0.000030
2021-06-22 13:56:53,559 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:53,559 EPOCH 14 done: loss 0.2698 - lr 0.0000300
2021-06-22 13:56:54,176 DEV : loss 0.23641592264175415 - score 0.9116
2021-06-22 13:56:54,184 BAD EPOCHS (no improvement): 1
2021-06-22 13:56:54,184 ----------------------------------------------------------------------------------------------------
2021-06-22 13:56:54,676 epoch 15 - iter 1/16 - loss 0.21401429 - samples/sec: 65.10 - lr: 0.000030
2021-06-22 13:56:55,172 epoch 15 - iter 2/16 - loss 0.21068943 - samples/sec: 64.68 - lr: 0.000030
2021-06-22 13:56:55,660 epoch 15 - iter 3/16 - loss 0.26197875 - samples/sec: 65.58 - lr: 0.000030
2021-06-22 13:56:56,157 epoch 15 - iter 4/16 - loss 0.26251063 - samples/sec: 64.46 - lr: 0.000030
2021-06-22 13:56:56,648 epoch 15 - iter 5/16 - loss 0.24666727 - samples/sec: 65.21 - lr: 0.000030
2021-06-22 13:56:57,134 epoch 15 - iter 6/16 - loss 0.24838016 - samples/sec: 65.89 - lr: 0.000030
2021-06-22 13:56:57,627 epoch 15 - iter 7/16 - loss 0.25985702 - samples/sec: 64.98 - lr: 0.000030
2021-06-22 13:56:58,116 epoch 15 - iter 8/16 - loss 0.25898780 - samples/sec: 65.54 - lr: 0.000030
2021-06-22 13:56:58,596 epoch 15 - iter 9/16 - loss 0.25336491 - samples/sec: 66.73 - lr: 0.000030
2021-06-22 13:56:59,076 epoch 15 - iter 10/16 - loss 0.25828347 - samples/sec: 66.73 - lr: 0.000030
2021-06-22 13:56:59,563 epoch 15 - iter 11/16 - loss 0.24459690 - samples/sec: 65.82 - lr: 0.000030
2021-06-22 13:57:00,070 epoch 15 - iter 12/16 - loss 0.24543920 - samples/sec: 63.12 - lr: 0.000030
2021-06-22 13:57:00,560 epoch 15 - iter 13/16 - loss 0.24503921 - samples/sec: 65.31 - lr: 0.000030
2021-06-22 13:57:01,051 epoch 15 - iter 14/16 - loss 0.25343570 - samples/sec: 65.25 - lr: 0.000030
2021-06-22 13:57:01,551 epoch 15 - iter 15/16 - loss 0.26242943 - samples/sec: 64.05 - lr: 0.000030
2021-06-22 13:57:01,903 epoch 15 - iter 16/16 - loss 0.25751885 - samples/sec: 91.26 - lr: 0.000030
2021-06-22 13:57:01,903 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:01,903 EPOCH 15 done: loss 0.2575 - lr 0.0000300
2021-06-22 13:57:02,524 DEV : loss 0.244157075881958 - score 0.929
2021-06-22 13:57:02,533 BAD EPOCHS (no improvement): 2
2021-06-22 13:57:02,533 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:03,029 epoch 16 - iter 1/16 - loss 0.28767347 - samples/sec: 64.59 - lr: 0.000030
2021-06-22 13:57:03,515 epoch 16 - iter 2/16 - loss 0.19997478 - samples/sec: 65.83 - lr: 0.000030
2021-06-22 13:57:04,013 epoch 16 - iter 3/16 - loss 0.27071571 - samples/sec: 64.28 - lr: 0.000030
2021-06-22 13:57:04,511 epoch 16 - iter 4/16 - loss 0.26779214 - samples/sec: 64.35 - lr: 0.000030
2021-06-22 13:57:05,005 epoch 16 - iter 5/16 - loss 0.24001536 - samples/sec: 64.90 - lr: 0.000030
2021-06-22 13:57:05,490 epoch 16 - iter 6/16 - loss 0.23436780 - samples/sec: 66.06 - lr: 0.000030
2021-06-22 13:57:05,966 epoch 16 - iter 7/16 - loss 0.25192588 - samples/sec: 67.29 - lr: 0.000030
2021-06-22 13:57:06,463 epoch 16 - iter 8/16 - loss 0.27033702 - samples/sec: 64.41 - lr: 0.000030
2021-06-22 13:57:06,948 epoch 16 - iter 9/16 - loss 0.26167013 - samples/sec: 65.98 - lr: 0.000030
2021-06-22 13:57:07,449 epoch 16 - iter 10/16 - loss 0.28529550 - samples/sec: 63.99 - lr: 0.000030
2021-06-22 13:57:07,947 epoch 16 - iter 11/16 - loss 0.28641648 - samples/sec: 64.35 - lr: 0.000030
2021-06-22 13:57:08,446 epoch 16 - iter 12/16 - loss 0.28452541 - samples/sec: 64.11 - lr: 0.000030
2021-06-22 13:57:08,940 epoch 16 - iter 13/16 - loss 0.27916658 - samples/sec: 64.93 - lr: 0.000030
2021-06-22 13:57:09,422 epoch 16 - iter 14/16 - loss 0.27652583 - samples/sec: 66.50 - lr: 0.000030
2021-06-22 13:57:09,902 epoch 16 - iter 15/16 - loss 0.27545838 - samples/sec: 66.62 - lr: 0.000030
2021-06-22 13:57:10,250 epoch 16 - iter 16/16 - loss 0.26899503 - samples/sec: 92.23 - lr: 0.000030
2021-06-22 13:57:10,250 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:10,250 EPOCH 16 done: loss 0.2690 - lr 0.0000300
2021-06-22 13:57:10,867 DEV : loss 0.23449115455150604 - score 0.9189
2021-06-22 13:57:10,876 BAD EPOCHS (no improvement): 3
2021-06-22 13:57:10,876 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:11,365 epoch 17 - iter 1/16 - loss 0.37248111 - samples/sec: 65.57 - lr: 0.000030
2021-06-22 13:57:11,860 epoch 17 - iter 2/16 - loss 0.25630581 - samples/sec: 64.67 - lr: 0.000030
2021-06-22 13:57:12,340 epoch 17 - iter 3/16 - loss 0.26005333 - samples/sec: 66.72 - lr: 0.000030
2021-06-22 13:57:12,828 epoch 17 - iter 4/16 - loss 0.22996199 - samples/sec: 65.69 - lr: 0.000030
2021-06-22 13:57:13,302 epoch 17 - iter 5/16 - loss 0.21010712 - samples/sec: 67.57 - lr: 0.000030
2021-06-22 13:57:13,806 epoch 17 - iter 6/16 - loss 0.20093889 - samples/sec: 63.56 - lr: 0.000030
2021-06-22 13:57:14,290 epoch 17 - iter 7/16 - loss 0.23951559 - samples/sec: 66.14 - lr: 0.000030
2021-06-22 13:57:14,782 epoch 17 - iter 8/16 - loss 0.25127703 - samples/sec: 65.08 - lr: 0.000030
2021-06-22 13:57:15,260 epoch 17 - iter 9/16 - loss 0.25040727 - samples/sec: 67.01 - lr: 0.000030
2021-06-22 13:57:15,761 epoch 17 - iter 10/16 - loss 0.24811864 - samples/sec: 63.99 - lr: 0.000030
2021-06-22 13:57:16,264 epoch 17 - iter 11/16 - loss 0.24126345 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 13:57:16,772 epoch 17 - iter 12/16 - loss 0.25358114 - samples/sec: 63.07 - lr: 0.000030
2021-06-22 13:57:17,269 epoch 17 - iter 13/16 - loss 0.25672175 - samples/sec: 64.44 - lr: 0.000030
2021-06-22 13:57:17,768 epoch 17 - iter 14/16 - loss 0.26726969 - samples/sec: 64.28 - lr: 0.000030
2021-06-22 13:57:18,265 epoch 17 - iter 15/16 - loss 0.26334897 - samples/sec: 64.43 - lr: 0.000030
2021-06-22 13:57:18,589 epoch 17 - iter 16/16 - loss 0.27677783 - samples/sec: 98.70 - lr: 0.000030
2021-06-22 13:57:18,590 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:18,590 EPOCH 17 done: loss 0.2768 - lr 0.0000300
2021-06-22 13:57:19,206 DEV : loss 0.23320521414279938 - score 0.92
Epoch    17: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 13:57:19,215 BAD EPOCHS (no improvement): 4
2021-06-22 13:57:19,215 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:19,695 epoch 18 - iter 1/16 - loss 0.11870348 - samples/sec: 66.66 - lr: 0.000015
2021-06-22 13:57:20,196 epoch 18 - iter 2/16 - loss 0.17720348 - samples/sec: 64.01 - lr: 0.000015
2021-06-22 13:57:20,692 epoch 18 - iter 3/16 - loss 0.19102617 - samples/sec: 64.51 - lr: 0.000015
2021-06-22 13:57:21,185 epoch 18 - iter 4/16 - loss 0.21401957 - samples/sec: 65.07 - lr: 0.000015
2021-06-22 13:57:21,670 epoch 18 - iter 5/16 - loss 0.20291112 - samples/sec: 65.98 - lr: 0.000015
2021-06-22 13:57:22,165 epoch 18 - iter 6/16 - loss 0.19987969 - samples/sec: 64.65 - lr: 0.000015
2021-06-22 13:57:22,668 epoch 18 - iter 7/16 - loss 0.19864028 - samples/sec: 63.71 - lr: 0.000015
2021-06-22 13:57:23,160 epoch 18 - iter 8/16 - loss 0.20389052 - samples/sec: 65.08 - lr: 0.000015
2021-06-22 13:57:23,656 epoch 18 - iter 9/16 - loss 0.21185299 - samples/sec: 64.63 - lr: 0.000015
2021-06-22 13:57:24,161 epoch 18 - iter 10/16 - loss 0.20816571 - samples/sec: 63.49 - lr: 0.000015
2021-06-22 13:57:24,639 epoch 18 - iter 11/16 - loss 0.21681256 - samples/sec: 66.98 - lr: 0.000015
2021-06-22 13:57:25,131 epoch 18 - iter 12/16 - loss 0.22807798 - samples/sec: 65.06 - lr: 0.000015
2021-06-22 13:57:25,620 epoch 18 - iter 13/16 - loss 0.23396608 - samples/sec: 65.49 - lr: 0.000015
2021-06-22 13:57:26,112 epoch 18 - iter 14/16 - loss 0.22973386 - samples/sec: 65.16 - lr: 0.000015
2021-06-22 13:57:26,602 epoch 18 - iter 15/16 - loss 0.22466088 - samples/sec: 65.40 - lr: 0.000015
2021-06-22 13:57:26,953 epoch 18 - iter 16/16 - loss 0.21803364 - samples/sec: 91.27 - lr: 0.000015
2021-06-22 13:57:26,953 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:26,953 EPOCH 18 done: loss 0.2180 - lr 0.0000150
2021-06-22 13:57:27,571 DEV : loss 0.24233496189117432 - score 0.9281
2021-06-22 13:57:27,579 BAD EPOCHS (no improvement): 1
2021-06-22 13:57:27,579 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:28,064 epoch 19 - iter 1/16 - loss 0.17839646 - samples/sec: 66.07 - lr: 0.000015
2021-06-22 13:57:28,565 epoch 19 - iter 2/16 - loss 0.27097142 - samples/sec: 64.00 - lr: 0.000015
2021-06-22 13:57:29,060 epoch 19 - iter 3/16 - loss 0.22988434 - samples/sec: 64.66 - lr: 0.000015
2021-06-22 13:57:29,548 epoch 19 - iter 4/16 - loss 0.21031257 - samples/sec: 65.59 - lr: 0.000015
2021-06-22 13:57:30,011 epoch 19 - iter 5/16 - loss 0.21958839 - samples/sec: 69.29 - lr: 0.000015
2021-06-22 13:57:30,592 epoch 19 - iter 6/16 - loss 0.20425305 - samples/sec: 55.09 - lr: 0.000015
2021-06-22 13:57:31,077 epoch 19 - iter 7/16 - loss 0.22803979 - samples/sec: 66.01 - lr: 0.000015
2021-06-22 13:57:31,574 epoch 19 - iter 8/16 - loss 0.22121138 - samples/sec: 64.51 - lr: 0.000015
2021-06-22 13:57:32,076 epoch 19 - iter 9/16 - loss 0.22832445 - samples/sec: 63.77 - lr: 0.000015
2021-06-22 13:57:32,573 epoch 19 - iter 10/16 - loss 0.21906682 - samples/sec: 64.41 - lr: 0.000015
2021-06-22 13:57:33,073 epoch 19 - iter 11/16 - loss 0.22392683 - samples/sec: 64.05 - lr: 0.000015
2021-06-22 13:57:33,563 epoch 19 - iter 12/16 - loss 0.21966200 - samples/sec: 65.40 - lr: 0.000015
2021-06-22 13:57:34,057 epoch 19 - iter 13/16 - loss 0.22698979 - samples/sec: 64.82 - lr: 0.000015
2021-06-22 13:57:34,552 epoch 19 - iter 14/16 - loss 0.22652569 - samples/sec: 64.70 - lr: 0.000015
2021-06-22 13:57:35,040 epoch 19 - iter 15/16 - loss 0.23353601 - samples/sec: 65.69 - lr: 0.000015
2021-06-22 13:57:35,385 epoch 19 - iter 16/16 - loss 0.23032246 - samples/sec: 92.81 - lr: 0.000015
2021-06-22 13:57:35,386 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:35,386 EPOCH 19 done: loss 0.2303 - lr 0.0000150
2021-06-22 13:57:36,003 DEV : loss 0.22705352306365967 - score 0.9324
2021-06-22 13:57:36,011 BAD EPOCHS (no improvement): 2
2021-06-22 13:57:36,011 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:36,500 epoch 20 - iter 1/16 - loss 0.12096310 - samples/sec: 65.53 - lr: 0.000015
2021-06-22 13:57:36,997 epoch 20 - iter 2/16 - loss 0.16866422 - samples/sec: 64.51 - lr: 0.000015
2021-06-22 13:57:37,484 epoch 20 - iter 3/16 - loss 0.22824518 - samples/sec: 65.78 - lr: 0.000015
2021-06-22 13:57:37,975 epoch 20 - iter 4/16 - loss 0.24295148 - samples/sec: 65.17 - lr: 0.000015
2021-06-22 13:57:38,466 epoch 20 - iter 5/16 - loss 0.23066050 - samples/sec: 65.24 - lr: 0.000015
2021-06-22 13:57:38,951 epoch 20 - iter 6/16 - loss 0.23692456 - samples/sec: 66.03 - lr: 0.000015
2021-06-22 13:57:39,435 epoch 20 - iter 7/16 - loss 0.22794593 - samples/sec: 66.16 - lr: 0.000015
2021-06-22 13:57:39,928 epoch 20 - iter 8/16 - loss 0.23180925 - samples/sec: 65.03 - lr: 0.000015
2021-06-22 13:57:40,429 epoch 20 - iter 9/16 - loss 0.23195070 - samples/sec: 63.96 - lr: 0.000015
2021-06-22 13:57:40,925 epoch 20 - iter 10/16 - loss 0.22274133 - samples/sec: 64.59 - lr: 0.000015
2021-06-22 13:57:41,413 epoch 20 - iter 11/16 - loss 0.21572989 - samples/sec: 65.61 - lr: 0.000015
2021-06-22 13:57:41,906 epoch 20 - iter 12/16 - loss 0.20697768 - samples/sec: 64.95 - lr: 0.000015
2021-06-22 13:57:42,396 epoch 20 - iter 13/16 - loss 0.20788537 - samples/sec: 65.31 - lr: 0.000015
2021-06-22 13:57:42,894 epoch 20 - iter 14/16 - loss 0.20541476 - samples/sec: 64.34 - lr: 0.000015
2021-06-22 13:57:43,394 epoch 20 - iter 15/16 - loss 0.20457563 - samples/sec: 64.11 - lr: 0.000015
2021-06-22 13:57:43,740 epoch 20 - iter 16/16 - loss 0.20296846 - samples/sec: 92.68 - lr: 0.000015
2021-06-22 13:57:43,740 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:43,740 EPOCH 20 done: loss 0.2030 - lr 0.0000150
2021-06-22 13:57:44,355 DEV : loss 0.22913335263729095 - score 0.9272
2021-06-22 13:57:44,364 BAD EPOCHS (no improvement): 3
2021-06-22 13:57:44,364 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:44,844 epoch 21 - iter 1/16 - loss 0.09691155 - samples/sec: 66.72 - lr: 0.000015
2021-06-22 13:57:45,337 epoch 21 - iter 2/16 - loss 0.13804787 - samples/sec: 64.95 - lr: 0.000015
2021-06-22 13:57:45,831 epoch 21 - iter 3/16 - loss 0.12063062 - samples/sec: 64.85 - lr: 0.000015
2021-06-22 13:57:46,320 epoch 21 - iter 4/16 - loss 0.13437397 - samples/sec: 65.58 - lr: 0.000015
2021-06-22 13:57:46,812 epoch 21 - iter 5/16 - loss 0.12753289 - samples/sec: 65.02 - lr: 0.000015
2021-06-22 13:57:47,297 epoch 21 - iter 6/16 - loss 0.13312261 - samples/sec: 66.09 - lr: 0.000015
2021-06-22 13:57:47,787 epoch 21 - iter 7/16 - loss 0.14312794 - samples/sec: 65.42 - lr: 0.000015
2021-06-22 13:57:48,290 epoch 21 - iter 8/16 - loss 0.15093835 - samples/sec: 63.62 - lr: 0.000015
2021-06-22 13:57:48,791 epoch 21 - iter 9/16 - loss 0.16619167 - samples/sec: 63.91 - lr: 0.000015
2021-06-22 13:57:49,288 epoch 21 - iter 10/16 - loss 0.17740752 - samples/sec: 64.54 - lr: 0.000015
2021-06-22 13:57:49,788 epoch 21 - iter 11/16 - loss 0.18209578 - samples/sec: 63.95 - lr: 0.000015
2021-06-22 13:57:50,283 epoch 21 - iter 12/16 - loss 0.18499484 - samples/sec: 64.71 - lr: 0.000015
2021-06-22 13:57:50,777 epoch 21 - iter 13/16 - loss 0.18818828 - samples/sec: 64.96 - lr: 0.000015
2021-06-22 13:57:51,260 epoch 21 - iter 14/16 - loss 0.18940673 - samples/sec: 66.22 - lr: 0.000015
2021-06-22 13:57:51,740 epoch 21 - iter 15/16 - loss 0.18788665 - samples/sec: 66.70 - lr: 0.000015
2021-06-22 13:57:52,082 epoch 21 - iter 16/16 - loss 0.18444135 - samples/sec: 93.73 - lr: 0.000015
2021-06-22 13:57:52,083 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:52,083 EPOCH 21 done: loss 0.1844 - lr 0.0000150
2021-06-22 13:57:52,700 DEV : loss 0.2258574366569519 - score 0.9262
Epoch    21: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 13:57:52,709 BAD EPOCHS (no improvement): 4
2021-06-22 13:57:52,709 ----------------------------------------------------------------------------------------------------
2021-06-22 13:57:53,200 epoch 22 - iter 1/16 - loss 0.30952525 - samples/sec: 65.19 - lr: 0.000008
2021-06-22 13:57:53,689 epoch 22 - iter 2/16 - loss 0.22305557 - samples/sec: 65.46 - lr: 0.000008
2021-06-22 13:57:54,167 epoch 22 - iter 3/16 - loss 0.18479935 - samples/sec: 67.09 - lr: 0.000008
2021-06-22 13:57:54,659 epoch 22 - iter 4/16 - loss 0.17876619 - samples/sec: 65.02 - lr: 0.000008
2021-06-22 13:57:55,145 epoch 22 - iter 5/16 - loss 0.20499396 - samples/sec: 65.95 - lr: 0.000008
2021-06-22 13:57:55,635 epoch 22 - iter 6/16 - loss 0.19053231 - samples/sec: 65.44 - lr: 0.000008
2021-06-22 13:57:56,133 epoch 22 - iter 7/16 - loss 0.20109458 - samples/sec: 64.28 - lr: 0.000008
2021-06-22 13:57:56,632 epoch 22 - iter 8/16 - loss 0.20171236 - samples/sec: 64.14 - lr: 0.000008
2021-06-22 13:57:57,129 epoch 22 - iter 9/16 - loss 0.20040831 - samples/sec: 64.47 - lr: 0.000008
2021-06-22 13:57:57,628 epoch 22 - iter 10/16 - loss 0.19723691 - samples/sec: 64.25 - lr: 0.000008
2021-06-22 13:57:58,117 epoch 22 - iter 11/16 - loss 0.20094854 - samples/sec: 65.52 - lr: 0.000008
2021-06-22 13:57:58,610 epoch 22 - iter 12/16 - loss 0.20834136 - samples/sec: 64.94 - lr: 0.000008
2021-06-22 13:57:59,102 epoch 22 - iter 13/16 - loss 0.21166691 - samples/sec: 65.11 - lr: 0.000008
2021-06-22 13:57:59,592 epoch 22 - iter 14/16 - loss 0.21288404 - samples/sec: 65.37 - lr: 0.000008
2021-06-22 13:58:00,071 epoch 22 - iter 15/16 - loss 0.21336028 - samples/sec: 66.80 - lr: 0.000008
2021-06-22 13:58:00,421 epoch 22 - iter 16/16 - loss 0.20585757 - samples/sec: 91.59 - lr: 0.000008
2021-06-22 13:58:00,421 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:00,421 EPOCH 22 done: loss 0.2059 - lr 0.0000075
2021-06-22 13:58:01,038 DEV : loss 0.224913090467453 - score 0.9189
2021-06-22 13:58:01,046 BAD EPOCHS (no improvement): 1
2021-06-22 13:58:01,046 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:01,538 epoch 23 - iter 1/16 - loss 0.11793375 - samples/sec: 65.23 - lr: 0.000008
2021-06-22 13:58:02,039 epoch 23 - iter 2/16 - loss 0.20607769 - samples/sec: 63.85 - lr: 0.000008
2021-06-22 13:58:02,535 epoch 23 - iter 3/16 - loss 0.21992524 - samples/sec: 64.57 - lr: 0.000008
2021-06-22 13:58:03,003 epoch 23 - iter 4/16 - loss 0.19068987 - samples/sec: 68.44 - lr: 0.000008
2021-06-22 13:58:03,492 epoch 23 - iter 5/16 - loss 0.20277792 - samples/sec: 65.48 - lr: 0.000008
2021-06-22 13:58:03,990 epoch 23 - iter 6/16 - loss 0.20186528 - samples/sec: 64.32 - lr: 0.000008
2021-06-22 13:58:04,483 epoch 23 - iter 7/16 - loss 0.21131366 - samples/sec: 65.04 - lr: 0.000008
2021-06-22 13:58:04,983 epoch 23 - iter 8/16 - loss 0.21975759 - samples/sec: 64.00 - lr: 0.000008
2021-06-22 13:58:05,474 epoch 23 - iter 9/16 - loss 0.20426808 - samples/sec: 65.34 - lr: 0.000008
2021-06-22 13:58:05,966 epoch 23 - iter 10/16 - loss 0.19677176 - samples/sec: 65.00 - lr: 0.000008
2021-06-22 13:58:06,457 epoch 23 - iter 11/16 - loss 0.19465595 - samples/sec: 65.25 - lr: 0.000008
2021-06-22 13:58:06,959 epoch 23 - iter 12/16 - loss 0.19233249 - samples/sec: 63.81 - lr: 0.000008
2021-06-22 13:58:07,459 epoch 23 - iter 13/16 - loss 0.20455858 - samples/sec: 64.14 - lr: 0.000008
2021-06-22 13:58:07,928 epoch 23 - iter 14/16 - loss 0.19857422 - samples/sec: 68.26 - lr: 0.000008
2021-06-22 13:58:08,417 epoch 23 - iter 15/16 - loss 0.19314866 - samples/sec: 65.44 - lr: 0.000008
2021-06-22 13:58:08,759 epoch 23 - iter 16/16 - loss 0.19489786 - samples/sec: 93.69 - lr: 0.000008
2021-06-22 13:58:08,760 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:08,760 EPOCH 23 done: loss 0.1949 - lr 0.0000075
2021-06-22 13:58:09,376 DEV : loss 0.22443197667598724 - score 0.9262
2021-06-22 13:58:09,385 BAD EPOCHS (no improvement): 2
2021-06-22 13:58:09,385 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:09,866 epoch 24 - iter 1/16 - loss 0.15079471 - samples/sec: 66.59 - lr: 0.000008
2021-06-22 13:58:10,361 epoch 24 - iter 2/16 - loss 0.24676190 - samples/sec: 64.76 - lr: 0.000008
2021-06-22 13:58:10,826 epoch 24 - iter 3/16 - loss 0.24620969 - samples/sec: 68.85 - lr: 0.000008
2021-06-22 13:58:11,320 epoch 24 - iter 4/16 - loss 0.21458324 - samples/sec: 64.76 - lr: 0.000008
2021-06-22 13:58:11,818 epoch 24 - iter 5/16 - loss 0.23253338 - samples/sec: 64.37 - lr: 0.000008
2021-06-22 13:58:12,309 epoch 24 - iter 6/16 - loss 0.23945097 - samples/sec: 65.21 - lr: 0.000008
2021-06-22 13:58:12,816 epoch 24 - iter 7/16 - loss 0.23001180 - samples/sec: 63.24 - lr: 0.000008
2021-06-22 13:58:13,306 epoch 24 - iter 8/16 - loss 0.23416257 - samples/sec: 65.35 - lr: 0.000008
2021-06-22 13:58:13,804 epoch 24 - iter 9/16 - loss 0.23978792 - samples/sec: 64.34 - lr: 0.000008
2021-06-22 13:58:14,304 epoch 24 - iter 10/16 - loss 0.23947522 - samples/sec: 63.97 - lr: 0.000008
2021-06-22 13:58:14,796 epoch 24 - iter 11/16 - loss 0.22701884 - samples/sec: 65.13 - lr: 0.000008
2021-06-22 13:58:15,283 epoch 24 - iter 12/16 - loss 0.22026426 - samples/sec: 65.81 - lr: 0.000008
2021-06-22 13:58:15,774 epoch 24 - iter 13/16 - loss 0.21303428 - samples/sec: 65.28 - lr: 0.000008
2021-06-22 13:58:16,272 epoch 24 - iter 14/16 - loss 0.20299503 - samples/sec: 64.25 - lr: 0.000008
2021-06-22 13:58:16,852 epoch 24 - iter 15/16 - loss 0.20285182 - samples/sec: 55.26 - lr: 0.000008
2021-06-22 13:58:17,185 epoch 24 - iter 16/16 - loss 0.21859521 - samples/sec: 96.04 - lr: 0.000008
2021-06-22 13:58:17,186 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:17,186 EPOCH 24 done: loss 0.2186 - lr 0.0000075
2021-06-22 13:58:17,802 DEV : loss 0.22473767399787903 - score 0.9262
2021-06-22 13:58:17,811 BAD EPOCHS (no improvement): 3
2021-06-22 13:58:17,811 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:18,290 epoch 25 - iter 1/16 - loss 0.12183380 - samples/sec: 66.84 - lr: 0.000008
2021-06-22 13:58:18,782 epoch 25 - iter 2/16 - loss 0.13371110 - samples/sec: 65.10 - lr: 0.000008
2021-06-22 13:58:19,274 epoch 25 - iter 3/16 - loss 0.13058917 - samples/sec: 65.12 - lr: 0.000008
2021-06-22 13:58:19,766 epoch 25 - iter 4/16 - loss 0.12036785 - samples/sec: 65.13 - lr: 0.000008
2021-06-22 13:58:20,266 epoch 25 - iter 5/16 - loss 0.11904814 - samples/sec: 64.08 - lr: 0.000008
2021-06-22 13:58:20,738 epoch 25 - iter 6/16 - loss 0.11974625 - samples/sec: 67.81 - lr: 0.000008
2021-06-22 13:58:21,209 epoch 25 - iter 7/16 - loss 0.13468010 - samples/sec: 68.05 - lr: 0.000008
2021-06-22 13:58:21,708 epoch 25 - iter 8/16 - loss 0.13046375 - samples/sec: 64.12 - lr: 0.000008
2021-06-22 13:58:22,194 epoch 25 - iter 9/16 - loss 0.13270997 - samples/sec: 65.88 - lr: 0.000008
2021-06-22 13:58:22,694 epoch 25 - iter 10/16 - loss 0.12467960 - samples/sec: 64.12 - lr: 0.000008
2021-06-22 13:58:23,184 epoch 25 - iter 11/16 - loss 0.12026491 - samples/sec: 65.30 - lr: 0.000008
2021-06-22 13:58:23,683 epoch 25 - iter 12/16 - loss 0.13298328 - samples/sec: 64.19 - lr: 0.000008
2021-06-22 13:58:24,177 epoch 25 - iter 13/16 - loss 0.13263925 - samples/sec: 64.85 - lr: 0.000008
2021-06-22 13:58:24,679 epoch 25 - iter 14/16 - loss 0.14111401 - samples/sec: 63.88 - lr: 0.000008
2021-06-22 13:58:25,178 epoch 25 - iter 15/16 - loss 0.15249242 - samples/sec: 64.13 - lr: 0.000008
2021-06-22 13:58:25,520 epoch 25 - iter 16/16 - loss 0.15326996 - samples/sec: 93.74 - lr: 0.000008
2021-06-22 13:58:25,520 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:25,520 EPOCH 25 done: loss 0.1533 - lr 0.0000075
2021-06-22 13:58:26,137 DEV : loss 0.22757835686206818 - score 0.9262
Epoch    25: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 13:58:26,145 BAD EPOCHS (no improvement): 4
2021-06-22 13:58:26,146 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:26,637 epoch 26 - iter 1/16 - loss 0.18654323 - samples/sec: 65.13 - lr: 0.000004
2021-06-22 13:58:27,128 epoch 26 - iter 2/16 - loss 0.17782500 - samples/sec: 65.24 - lr: 0.000004
2021-06-22 13:58:27,625 epoch 26 - iter 3/16 - loss 0.20965491 - samples/sec: 64.50 - lr: 0.000004
2021-06-22 13:58:28,129 epoch 26 - iter 4/16 - loss 0.20684262 - samples/sec: 63.56 - lr: 0.000004
2021-06-22 13:58:28,624 epoch 26 - iter 5/16 - loss 0.24445382 - samples/sec: 64.72 - lr: 0.000004
2021-06-22 13:58:29,112 epoch 26 - iter 6/16 - loss 0.22997259 - samples/sec: 65.55 - lr: 0.000004
2021-06-22 13:58:29,584 epoch 26 - iter 7/16 - loss 0.21682835 - samples/sec: 67.98 - lr: 0.000004
2021-06-22 13:58:30,081 epoch 26 - iter 8/16 - loss 0.20580284 - samples/sec: 64.36 - lr: 0.000004
2021-06-22 13:58:30,588 epoch 26 - iter 9/16 - loss 0.21590618 - samples/sec: 63.25 - lr: 0.000004
2021-06-22 13:58:31,088 epoch 26 - iter 10/16 - loss 0.20794256 - samples/sec: 64.04 - lr: 0.000004
2021-06-22 13:58:31,587 epoch 26 - iter 11/16 - loss 0.20081196 - samples/sec: 64.13 - lr: 0.000004
2021-06-22 13:58:32,076 epoch 26 - iter 12/16 - loss 0.19948736 - samples/sec: 65.56 - lr: 0.000004
2021-06-22 13:58:32,567 epoch 26 - iter 13/16 - loss 0.19595947 - samples/sec: 65.20 - lr: 0.000004
2021-06-22 13:58:33,066 epoch 26 - iter 14/16 - loss 0.19287404 - samples/sec: 64.22 - lr: 0.000004
2021-06-22 13:58:33,544 epoch 26 - iter 15/16 - loss 0.18737373 - samples/sec: 67.00 - lr: 0.000004
2021-06-22 13:58:33,866 epoch 26 - iter 16/16 - loss 0.19442658 - samples/sec: 99.43 - lr: 0.000004
2021-06-22 13:58:33,867 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:33,867 EPOCH 26 done: loss 0.1944 - lr 0.0000038
2021-06-22 13:58:34,482 DEV : loss 0.2270641177892685 - score 0.9262
2021-06-22 13:58:34,490 BAD EPOCHS (no improvement): 1
2021-06-22 13:58:34,491 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:34,984 epoch 27 - iter 1/16 - loss 0.28204823 - samples/sec: 64.91 - lr: 0.000004
2021-06-22 13:58:35,482 epoch 27 - iter 2/16 - loss 0.21550810 - samples/sec: 64.32 - lr: 0.000004
2021-06-22 13:58:35,968 epoch 27 - iter 3/16 - loss 0.19395705 - samples/sec: 65.89 - lr: 0.000004
2021-06-22 13:58:36,464 epoch 27 - iter 4/16 - loss 0.19277969 - samples/sec: 64.67 - lr: 0.000004
2021-06-22 13:58:36,965 epoch 27 - iter 5/16 - loss 0.21325738 - samples/sec: 63.93 - lr: 0.000004
2021-06-22 13:58:37,459 epoch 27 - iter 6/16 - loss 0.19650127 - samples/sec: 64.83 - lr: 0.000004
2021-06-22 13:58:37,956 epoch 27 - iter 7/16 - loss 0.18116445 - samples/sec: 64.46 - lr: 0.000004
2021-06-22 13:58:38,449 epoch 27 - iter 8/16 - loss 0.20427331 - samples/sec: 64.88 - lr: 0.000004
2021-06-22 13:58:38,951 epoch 27 - iter 9/16 - loss 0.20818196 - samples/sec: 63.79 - lr: 0.000004
2021-06-22 13:58:39,445 epoch 27 - iter 10/16 - loss 0.21634123 - samples/sec: 64.95 - lr: 0.000004
2021-06-22 13:58:39,911 epoch 27 - iter 11/16 - loss 0.20262281 - samples/sec: 68.75 - lr: 0.000004
2021-06-22 13:58:40,395 epoch 27 - iter 12/16 - loss 0.20114242 - samples/sec: 66.10 - lr: 0.000004
2021-06-22 13:58:40,874 epoch 27 - iter 13/16 - loss 0.19822866 - samples/sec: 66.87 - lr: 0.000004
2021-06-22 13:58:41,365 epoch 27 - iter 14/16 - loss 0.19724938 - samples/sec: 65.27 - lr: 0.000004
2021-06-22 13:58:41,857 epoch 27 - iter 15/16 - loss 0.19337827 - samples/sec: 65.07 - lr: 0.000004
2021-06-22 13:58:42,206 epoch 27 - iter 16/16 - loss 0.19538094 - samples/sec: 91.80 - lr: 0.000004
2021-06-22 13:58:42,207 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:42,207 EPOCH 27 done: loss 0.1954 - lr 0.0000038
2021-06-22 13:58:42,823 DEV : loss 0.224955752491951 - score 0.9262
2021-06-22 13:58:42,832 BAD EPOCHS (no improvement): 2
2021-06-22 13:58:42,832 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:43,325 epoch 28 - iter 1/16 - loss 0.18937945 - samples/sec: 64.98 - lr: 0.000004
2021-06-22 13:58:43,817 epoch 28 - iter 2/16 - loss 0.25430244 - samples/sec: 65.10 - lr: 0.000004
2021-06-22 13:58:44,313 epoch 28 - iter 3/16 - loss 0.20882765 - samples/sec: 64.59 - lr: 0.000004
2021-06-22 13:58:44,810 epoch 28 - iter 4/16 - loss 0.19317812 - samples/sec: 64.38 - lr: 0.000004
2021-06-22 13:58:45,314 epoch 28 - iter 5/16 - loss 0.19394240 - samples/sec: 63.56 - lr: 0.000004
2021-06-22 13:58:45,806 epoch 28 - iter 6/16 - loss 0.20105422 - samples/sec: 65.10 - lr: 0.000004
2021-06-22 13:58:46,291 epoch 28 - iter 7/16 - loss 0.20594899 - samples/sec: 66.09 - lr: 0.000004
2021-06-22 13:58:46,778 epoch 28 - iter 8/16 - loss 0.19632559 - samples/sec: 65.76 - lr: 0.000004
2021-06-22 13:58:47,276 epoch 28 - iter 9/16 - loss 0.20754003 - samples/sec: 64.30 - lr: 0.000004
2021-06-22 13:58:47,749 epoch 28 - iter 10/16 - loss 0.21026188 - samples/sec: 67.70 - lr: 0.000004
2021-06-22 13:58:48,250 epoch 28 - iter 11/16 - loss 0.21668886 - samples/sec: 63.93 - lr: 0.000004
2021-06-22 13:58:48,752 epoch 28 - iter 12/16 - loss 0.21124069 - samples/sec: 63.81 - lr: 0.000004
2021-06-22 13:58:49,223 epoch 28 - iter 13/16 - loss 0.22017802 - samples/sec: 68.00 - lr: 0.000004
2021-06-22 13:58:49,719 epoch 28 - iter 14/16 - loss 0.21668797 - samples/sec: 64.59 - lr: 0.000004
2021-06-22 13:58:50,210 epoch 28 - iter 15/16 - loss 0.20679078 - samples/sec: 65.26 - lr: 0.000004
2021-06-22 13:58:50,558 epoch 28 - iter 16/16 - loss 0.20072248 - samples/sec: 91.98 - lr: 0.000004
2021-06-22 13:58:50,559 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:50,559 EPOCH 28 done: loss 0.2007 - lr 0.0000038
2021-06-22 13:58:51,177 DEV : loss 0.22485722601413727 - score 0.9262
2021-06-22 13:58:51,186 BAD EPOCHS (no improvement): 3
2021-06-22 13:58:51,186 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:51,676 epoch 29 - iter 1/16 - loss 0.12306619 - samples/sec: 65.40 - lr: 0.000004
2021-06-22 13:58:52,177 epoch 29 - iter 2/16 - loss 0.23163199 - samples/sec: 63.91 - lr: 0.000004
2021-06-22 13:58:52,666 epoch 29 - iter 3/16 - loss 0.17549928 - samples/sec: 65.48 - lr: 0.000004
2021-06-22 13:58:53,159 epoch 29 - iter 4/16 - loss 0.17910033 - samples/sec: 65.06 - lr: 0.000004
2021-06-22 13:58:53,657 epoch 29 - iter 5/16 - loss 0.18672380 - samples/sec: 64.34 - lr: 0.000004
2021-06-22 13:58:54,159 epoch 29 - iter 6/16 - loss 0.18942205 - samples/sec: 63.70 - lr: 0.000004
2021-06-22 13:58:54,647 epoch 29 - iter 7/16 - loss 0.17937836 - samples/sec: 65.69 - lr: 0.000004
2021-06-22 13:58:55,133 epoch 29 - iter 8/16 - loss 0.17342088 - samples/sec: 65.91 - lr: 0.000004
2021-06-22 13:58:55,636 epoch 29 - iter 9/16 - loss 0.16974460 - samples/sec: 63.68 - lr: 0.000004
2021-06-22 13:58:56,130 epoch 29 - iter 10/16 - loss 0.17067230 - samples/sec: 64.76 - lr: 0.000004
2021-06-22 13:58:56,623 epoch 29 - iter 11/16 - loss 0.17110614 - samples/sec: 64.99 - lr: 0.000004
2021-06-22 13:58:57,105 epoch 29 - iter 12/16 - loss 0.16637092 - samples/sec: 66.55 - lr: 0.000004
2021-06-22 13:58:57,593 epoch 29 - iter 13/16 - loss 0.16782727 - samples/sec: 65.65 - lr: 0.000004
2021-06-22 13:58:58,069 epoch 29 - iter 14/16 - loss 0.17990607 - samples/sec: 67.28 - lr: 0.000004
2021-06-22 13:58:58,565 epoch 29 - iter 15/16 - loss 0.17293287 - samples/sec: 64.59 - lr: 0.000004
2021-06-22 13:58:58,908 epoch 29 - iter 16/16 - loss 0.16806930 - samples/sec: 93.18 - lr: 0.000004
2021-06-22 13:58:58,909 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:58,909 EPOCH 29 done: loss 0.1681 - lr 0.0000038
2021-06-22 13:58:59,525 DEV : loss 0.2243821620941162 - score 0.9262
Epoch    29: reducing learning rate of group 0 to 1.8750e-06.
2021-06-22 13:58:59,533 BAD EPOCHS (no improvement): 4
2021-06-22 13:58:59,534 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:59,534 ----------------------------------------------------------------------------------------------------
2021-06-22 13:58:59,534 learning rate too small - quitting training!
2021-06-22 13:58:59,534 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:00,049 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:00,049 Testing using best model ...
2021-06-22 13:59:00,049 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/best-model.pt
2021-06-22 13:59:04,172 0.7984	0.9900	0.8839
2021-06-22 13:59:04,172 
Results:
- F1-score (micro) 0.8839
- F1-score (macro) 0.8839

By class:
SENT       tp: 99 - fp: 25 - fn: 1 - precision: 0.7984 - recall: 0.9900 - f1-score: 0.8839
2021-06-22 13:59:04,172 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/
2021-06-22 13:59:04,216 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt
2021-06-22 13:59:04,216 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/sent_train.txt
2021-06-22 13:59:04,218 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/sent_dev.txt
2021-06-22 13:59:04,220 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/sent_test.txt
Corpus: 8099 train + 840 dev + 1047 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 13:59:14,007 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:14,010 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50265, 1024, padding_idx=1)
          (position_embeddings): Embedding(514, 1024, padding_idx=1)
          (token_type_embeddings): Embedding(1, 1024)
          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (12): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (13): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (14): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (15): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (16): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (17): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (18): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (19): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (20): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (21): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (22): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (23): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4146, out_features=4146, bias=True)
  (rnn): LSTM(4146, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 13:59:14,010 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:14,010 Corpus: "Corpus: 8099 train + 840 dev + 1047 test sentences"
2021-06-22 13:59:14,010 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:14,010 Parameters:
2021-06-22 13:59:14,010  - learning_rate: "3e-05"
2021-06-22 13:59:14,010  - mini_batch_size: "32"
2021-06-22 13:59:14,010  - patience: "3"
2021-06-22 13:59:14,010  - anneal_factor: "0.5"
2021-06-22 13:59:14,010  - max_epochs: "40"
2021-06-22 13:59:14,010  - shuffle: "True"
2021-06-22 13:59:14,010  - train_with_dev: "False"
2021-06-22 13:59:14,010  - batch_growth_annealing: "False"
2021-06-22 13:59:14,010 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:14,010 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt"
2021-06-22 13:59:14,010 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:14,011 Device: cuda:0
2021-06-22 13:59:14,011 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:14,011 Embeddings storage mode: cpu
2021-06-22 13:59:14,012 ----------------------------------------------------------------------------------------------------
2021-06-22 13:59:48,890 epoch 1 - iter 25/254 - loss 18.05328041 - samples/sec: 22.94 - lr: 0.000030
2021-06-22 14:00:23,700 epoch 1 - iter 50/254 - loss 10.79080743 - samples/sec: 22.98 - lr: 0.000030
2021-06-22 14:00:58,489 epoch 1 - iter 75/254 - loss 7.75917994 - samples/sec: 23.00 - lr: 0.000030
2021-06-22 14:01:33,137 epoch 1 - iter 100/254 - loss 6.07560384 - samples/sec: 23.09 - lr: 0.000030
2021-06-22 14:02:08,308 epoch 1 - iter 125/254 - loss 5.04263013 - samples/sec: 22.75 - lr: 0.000030
2021-06-22 14:02:42,921 epoch 1 - iter 150/254 - loss 4.32476076 - samples/sec: 23.11 - lr: 0.000030
2021-06-22 14:03:17,573 epoch 1 - iter 175/254 - loss 3.80490441 - samples/sec: 23.09 - lr: 0.000030
2021-06-22 14:03:52,218 epoch 1 - iter 200/254 - loss 3.41318045 - samples/sec: 23.09 - lr: 0.000030
2021-06-22 14:04:26,937 epoch 1 - iter 225/254 - loss 3.11051853 - samples/sec: 23.04 - lr: 0.000030
2021-06-22 14:05:01,570 epoch 1 - iter 250/254 - loss 2.85275734 - samples/sec: 23.10 - lr: 0.000030
2021-06-22 14:05:05,918 ----------------------------------------------------------------------------------------------------
2021-06-22 14:05:05,918 EPOCH 1 done: loss 2.8135 - lr 0.0000300
2021-06-22 14:05:27,698 DEV : loss 0.3489534854888916 - score 0.9114
2021-06-22 14:05:27,760 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:05:29,527 ----------------------------------------------------------------------------------------------------
2021-06-22 14:05:41,972 epoch 2 - iter 25/254 - loss 0.48411378 - samples/sec: 64.29 - lr: 0.000030
2021-06-22 14:05:54,396 epoch 2 - iter 50/254 - loss 0.49917840 - samples/sec: 64.40 - lr: 0.000030
2021-06-22 14:06:06,766 epoch 2 - iter 75/254 - loss 0.48234332 - samples/sec: 64.68 - lr: 0.000030
2021-06-22 14:06:19,148 epoch 2 - iter 100/254 - loss 0.47548488 - samples/sec: 64.61 - lr: 0.000030
2021-06-22 14:06:31,553 epoch 2 - iter 125/254 - loss 0.46809524 - samples/sec: 64.50 - lr: 0.000030
2021-06-22 14:06:43,958 epoch 2 - iter 150/254 - loss 0.46054550 - samples/sec: 64.50 - lr: 0.000030
2021-06-22 14:06:56,350 epoch 2 - iter 175/254 - loss 0.45025292 - samples/sec: 64.57 - lr: 0.000030
2021-06-22 14:07:08,709 epoch 2 - iter 200/254 - loss 0.44255163 - samples/sec: 64.74 - lr: 0.000030
2021-06-22 14:07:21,185 epoch 2 - iter 225/254 - loss 0.43833289 - samples/sec: 64.13 - lr: 0.000030
2021-06-22 14:07:33,640 epoch 2 - iter 250/254 - loss 0.43159527 - samples/sec: 64.24 - lr: 0.000030
2021-06-22 14:07:35,253 ----------------------------------------------------------------------------------------------------
2021-06-22 14:07:35,253 EPOCH 2 done: loss 0.4329 - lr 0.0000300
2021-06-22 14:07:39,639 DEV : loss 0.2403041422367096 - score 0.9438
2021-06-22 14:07:39,701 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:07:48,553 ----------------------------------------------------------------------------------------------------
2021-06-22 14:08:00,934 epoch 3 - iter 25/254 - loss 0.36543513 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 14:08:13,358 epoch 3 - iter 50/254 - loss 0.35622839 - samples/sec: 64.40 - lr: 0.000030
2021-06-22 14:08:25,833 epoch 3 - iter 75/254 - loss 0.34363181 - samples/sec: 64.14 - lr: 0.000030
2021-06-22 14:08:38,226 epoch 3 - iter 100/254 - loss 0.34657337 - samples/sec: 64.56 - lr: 0.000030
2021-06-22 14:08:50,656 epoch 3 - iter 125/254 - loss 0.34372616 - samples/sec: 64.37 - lr: 0.000030
2021-06-22 14:09:03,064 epoch 3 - iter 150/254 - loss 0.34116902 - samples/sec: 64.48 - lr: 0.000030
2021-06-22 14:09:15,448 epoch 3 - iter 175/254 - loss 0.34378854 - samples/sec: 64.61 - lr: 0.000030
2021-06-22 14:09:27,808 epoch 3 - iter 200/254 - loss 0.34094477 - samples/sec: 64.73 - lr: 0.000030
2021-06-22 14:09:40,187 epoch 3 - iter 225/254 - loss 0.33897906 - samples/sec: 64.64 - lr: 0.000030
2021-06-22 14:09:52,586 epoch 3 - iter 250/254 - loss 0.33718101 - samples/sec: 64.53 - lr: 0.000030
2021-06-22 14:09:54,172 ----------------------------------------------------------------------------------------------------
2021-06-22 14:09:54,172 EPOCH 3 done: loss 0.3358 - lr 0.0000300
2021-06-22 14:09:58,544 DEV : loss 0.19419805705547333 - score 0.9558
2021-06-22 14:09:58,607 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:10:07,554 ----------------------------------------------------------------------------------------------------
2021-06-22 14:10:19,969 epoch 4 - iter 25/254 - loss 0.28889504 - samples/sec: 64.45 - lr: 0.000030
2021-06-22 14:10:32,389 epoch 4 - iter 50/254 - loss 0.28422137 - samples/sec: 64.42 - lr: 0.000030
2021-06-22 14:10:44,773 epoch 4 - iter 75/254 - loss 0.28004418 - samples/sec: 64.61 - lr: 0.000030
2021-06-22 14:10:57,162 epoch 4 - iter 100/254 - loss 0.28262969 - samples/sec: 64.58 - lr: 0.000030
2021-06-22 14:11:09,594 epoch 4 - iter 125/254 - loss 0.28897352 - samples/sec: 64.36 - lr: 0.000030
2021-06-22 14:11:22,101 epoch 4 - iter 150/254 - loss 0.28521809 - samples/sec: 63.97 - lr: 0.000030
2021-06-22 14:11:34,609 epoch 4 - iter 175/254 - loss 0.28147807 - samples/sec: 63.96 - lr: 0.000030
2021-06-22 14:11:47,121 epoch 4 - iter 200/254 - loss 0.28359838 - samples/sec: 63.95 - lr: 0.000030
2021-06-22 14:11:59,563 epoch 4 - iter 225/254 - loss 0.28468455 - samples/sec: 64.31 - lr: 0.000030
2021-06-22 14:12:11,966 epoch 4 - iter 250/254 - loss 0.28142949 - samples/sec: 64.51 - lr: 0.000030
2021-06-22 14:12:13,566 ----------------------------------------------------------------------------------------------------
2021-06-22 14:12:13,566 EPOCH 4 done: loss 0.2816 - lr 0.0000300
2021-06-22 14:12:17,938 DEV : loss 0.18280811607837677 - score 0.9611
2021-06-22 14:12:18,000 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:12:26,970 ----------------------------------------------------------------------------------------------------
2021-06-22 14:12:39,410 epoch 5 - iter 25/254 - loss 0.26111581 - samples/sec: 64.32 - lr: 0.000030
2021-06-22 14:12:51,869 epoch 5 - iter 50/254 - loss 0.26736972 - samples/sec: 64.22 - lr: 0.000030
2021-06-22 14:13:04,295 epoch 5 - iter 75/254 - loss 0.26694979 - samples/sec: 64.39 - lr: 0.000030
2021-06-22 14:13:16,700 epoch 5 - iter 100/254 - loss 0.27384991 - samples/sec: 64.49 - lr: 0.000030
2021-06-22 14:13:29,107 epoch 5 - iter 125/254 - loss 0.26978782 - samples/sec: 64.49 - lr: 0.000030
2021-06-22 14:13:41,551 epoch 5 - iter 150/254 - loss 0.26684787 - samples/sec: 64.30 - lr: 0.000030
2021-06-22 14:13:54,056 epoch 5 - iter 175/254 - loss 0.26270288 - samples/sec: 63.98 - lr: 0.000030
2021-06-22 14:14:06,556 epoch 5 - iter 200/254 - loss 0.25685800 - samples/sec: 64.01 - lr: 0.000030
2021-06-22 14:14:18,937 epoch 5 - iter 225/254 - loss 0.25331237 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 14:14:31,331 epoch 5 - iter 250/254 - loss 0.25528123 - samples/sec: 64.55 - lr: 0.000030
2021-06-22 14:14:32,919 ----------------------------------------------------------------------------------------------------
2021-06-22 14:14:32,919 EPOCH 5 done: loss 0.2558 - lr 0.0000300
2021-06-22 14:14:37,870 DEV : loss 0.1609092354774475 - score 0.9613
2021-06-22 14:14:37,932 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:14:46,903 ----------------------------------------------------------------------------------------------------
2021-06-22 14:14:59,397 epoch 6 - iter 25/254 - loss 0.23839194 - samples/sec: 64.04 - lr: 0.000030
2021-06-22 14:15:11,830 epoch 6 - iter 50/254 - loss 0.25334111 - samples/sec: 64.35 - lr: 0.000030
2021-06-22 14:15:24,352 epoch 6 - iter 75/254 - loss 0.25297525 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 14:15:36,783 epoch 6 - iter 100/254 - loss 0.25394255 - samples/sec: 64.36 - lr: 0.000030
2021-06-22 14:15:49,177 epoch 6 - iter 125/254 - loss 0.24646585 - samples/sec: 64.55 - lr: 0.000030
2021-06-22 14:16:01,653 epoch 6 - iter 150/254 - loss 0.24515143 - samples/sec: 64.13 - lr: 0.000030
2021-06-22 14:16:14,088 epoch 6 - iter 175/254 - loss 0.24150583 - samples/sec: 64.34 - lr: 0.000030
2021-06-22 14:16:26,480 epoch 6 - iter 200/254 - loss 0.23772345 - samples/sec: 64.57 - lr: 0.000030
2021-06-22 14:16:38,831 epoch 6 - iter 225/254 - loss 0.23639197 - samples/sec: 64.78 - lr: 0.000030
2021-06-22 14:16:51,283 epoch 6 - iter 250/254 - loss 0.23110624 - samples/sec: 64.26 - lr: 0.000030
2021-06-22 14:16:52,883 ----------------------------------------------------------------------------------------------------
2021-06-22 14:16:52,884 EPOCH 6 done: loss 0.2310 - lr 0.0000300
2021-06-22 14:16:57,266 DEV : loss 0.15380145609378815 - score 0.9659
2021-06-22 14:16:57,328 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:17:06,023 ----------------------------------------------------------------------------------------------------
2021-06-22 14:17:18,429 epoch 7 - iter 25/254 - loss 0.20616044 - samples/sec: 64.50 - lr: 0.000030
2021-06-22 14:17:30,802 epoch 7 - iter 50/254 - loss 0.21500022 - samples/sec: 64.66 - lr: 0.000030
2021-06-22 14:17:43,251 epoch 7 - iter 75/254 - loss 0.21778800 - samples/sec: 64.27 - lr: 0.000030
2021-06-22 14:17:55,675 epoch 7 - iter 100/254 - loss 0.21227243 - samples/sec: 64.40 - lr: 0.000030
2021-06-22 14:18:08,106 epoch 7 - iter 125/254 - loss 0.21146011 - samples/sec: 64.36 - lr: 0.000030
2021-06-22 14:18:20,500 epoch 7 - iter 150/254 - loss 0.21751277 - samples/sec: 64.56 - lr: 0.000030
2021-06-22 14:18:32,914 epoch 7 - iter 175/254 - loss 0.22272499 - samples/sec: 64.45 - lr: 0.000030
2021-06-22 14:18:45,362 epoch 7 - iter 200/254 - loss 0.22244136 - samples/sec: 64.27 - lr: 0.000030
2021-06-22 14:18:57,824 epoch 7 - iter 225/254 - loss 0.22312323 - samples/sec: 64.21 - lr: 0.000030
2021-06-22 14:19:10,258 epoch 7 - iter 250/254 - loss 0.22100065 - samples/sec: 64.35 - lr: 0.000030
2021-06-22 14:19:11,867 ----------------------------------------------------------------------------------------------------
2021-06-22 14:19:11,867 EPOCH 7 done: loss 0.2204 - lr 0.0000300
2021-06-22 14:19:16,244 DEV : loss 0.14932338893413544 - score 0.9696
2021-06-22 14:19:16,307 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:19:24,745 ----------------------------------------------------------------------------------------------------
2021-06-22 14:19:37,094 epoch 8 - iter 25/254 - loss 0.18922870 - samples/sec: 64.80 - lr: 0.000030
2021-06-22 14:19:49,520 epoch 8 - iter 50/254 - loss 0.20571428 - samples/sec: 64.39 - lr: 0.000030
2021-06-22 14:20:01,964 epoch 8 - iter 75/254 - loss 0.19971329 - samples/sec: 64.30 - lr: 0.000030
2021-06-22 14:20:14,408 epoch 8 - iter 100/254 - loss 0.19560110 - samples/sec: 64.30 - lr: 0.000030
2021-06-22 14:20:26,782 epoch 8 - iter 125/254 - loss 0.19881577 - samples/sec: 64.66 - lr: 0.000030
2021-06-22 14:20:39,156 epoch 8 - iter 150/254 - loss 0.20615545 - samples/sec: 64.66 - lr: 0.000030
2021-06-22 14:20:51,525 epoch 8 - iter 175/254 - loss 0.20499370 - samples/sec: 64.69 - lr: 0.000030
2021-06-22 14:21:03,936 epoch 8 - iter 200/254 - loss 0.20497533 - samples/sec: 64.47 - lr: 0.000030
2021-06-22 14:21:16,317 epoch 8 - iter 225/254 - loss 0.20230169 - samples/sec: 64.62 - lr: 0.000030
2021-06-22 14:21:28,674 epoch 8 - iter 250/254 - loss 0.20782270 - samples/sec: 64.75 - lr: 0.000030
2021-06-22 14:21:30,276 ----------------------------------------------------------------------------------------------------
2021-06-22 14:21:30,277 EPOCH 8 done: loss 0.2087 - lr 0.0000300
2021-06-22 14:21:34,655 DEV : loss 0.13933943212032318 - score 0.9669
2021-06-22 14:21:34,718 BAD EPOCHS (no improvement): 1
2021-06-22 14:21:34,718 ----------------------------------------------------------------------------------------------------
2021-06-22 14:21:47,073 epoch 9 - iter 25/254 - loss 0.21025495 - samples/sec: 64.76 - lr: 0.000030
2021-06-22 14:21:59,475 epoch 9 - iter 50/254 - loss 0.22736399 - samples/sec: 64.52 - lr: 0.000030
2021-06-22 14:22:11,843 epoch 9 - iter 75/254 - loss 0.20951575 - samples/sec: 64.69 - lr: 0.000030
2021-06-22 14:22:24,178 epoch 9 - iter 100/254 - loss 0.20377700 - samples/sec: 64.86 - lr: 0.000030
2021-06-22 14:22:36,582 epoch 9 - iter 125/254 - loss 0.19837954 - samples/sec: 64.50 - lr: 0.000030
2021-06-22 14:22:49,115 epoch 9 - iter 150/254 - loss 0.19678652 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 14:23:01,577 epoch 9 - iter 175/254 - loss 0.19642461 - samples/sec: 64.20 - lr: 0.000030
2021-06-22 14:23:14,111 epoch 9 - iter 200/254 - loss 0.19051505 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 14:23:26,526 epoch 9 - iter 225/254 - loss 0.18703452 - samples/sec: 64.45 - lr: 0.000030
2021-06-22 14:23:38,951 epoch 9 - iter 250/254 - loss 0.18658419 - samples/sec: 64.39 - lr: 0.000030
2021-06-22 14:23:40,558 ----------------------------------------------------------------------------------------------------
2021-06-22 14:23:40,558 EPOCH 9 done: loss 0.1851 - lr 0.0000300
2021-06-22 14:23:45,481 DEV : loss 0.13092291355133057 - score 0.9708
2021-06-22 14:23:45,544 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:23:53,968 ----------------------------------------------------------------------------------------------------
2021-06-22 14:24:06,351 epoch 10 - iter 25/254 - loss 0.17109986 - samples/sec: 64.61 - lr: 0.000030
2021-06-22 14:24:18,803 epoch 10 - iter 50/254 - loss 0.16255981 - samples/sec: 64.26 - lr: 0.000030
2021-06-22 14:24:31,301 epoch 10 - iter 75/254 - loss 0.16799754 - samples/sec: 64.02 - lr: 0.000030
2021-06-22 14:24:43,773 epoch 10 - iter 100/254 - loss 0.17425542 - samples/sec: 64.15 - lr: 0.000030
2021-06-22 14:24:56,244 epoch 10 - iter 125/254 - loss 0.17546791 - samples/sec: 64.15 - lr: 0.000030
2021-06-22 14:25:08,658 epoch 10 - iter 150/254 - loss 0.17620479 - samples/sec: 64.45 - lr: 0.000030
2021-06-22 14:25:21,084 epoch 10 - iter 175/254 - loss 0.17437541 - samples/sec: 64.39 - lr: 0.000030
2021-06-22 14:25:33,540 epoch 10 - iter 200/254 - loss 0.17774272 - samples/sec: 64.23 - lr: 0.000030
2021-06-22 14:25:46,019 epoch 10 - iter 225/254 - loss 0.17727497 - samples/sec: 64.12 - lr: 0.000030
2021-06-22 14:25:58,507 epoch 10 - iter 250/254 - loss 0.17253663 - samples/sec: 64.07 - lr: 0.000030
2021-06-22 14:26:00,099 ----------------------------------------------------------------------------------------------------
2021-06-22 14:26:00,099 EPOCH 10 done: loss 0.1721 - lr 0.0000300
2021-06-22 14:26:04,479 DEV : loss 0.12570083141326904 - score 0.9736
2021-06-22 14:26:04,541 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:26:13,132 ----------------------------------------------------------------------------------------------------
2021-06-22 14:26:25,629 epoch 11 - iter 25/254 - loss 0.15320837 - samples/sec: 64.03 - lr: 0.000030
2021-06-22 14:26:38,089 epoch 11 - iter 50/254 - loss 0.15694738 - samples/sec: 64.21 - lr: 0.000030
2021-06-22 14:26:50,544 epoch 11 - iter 75/254 - loss 0.15978025 - samples/sec: 64.24 - lr: 0.000030
2021-06-22 14:27:03,022 epoch 11 - iter 100/254 - loss 0.16892436 - samples/sec: 64.12 - lr: 0.000030
2021-06-22 14:27:15,426 epoch 11 - iter 125/254 - loss 0.16572708 - samples/sec: 64.51 - lr: 0.000030
2021-06-22 14:27:27,812 epoch 11 - iter 150/254 - loss 0.16480276 - samples/sec: 64.60 - lr: 0.000030
2021-06-22 14:27:40,223 epoch 11 - iter 175/254 - loss 0.16431796 - samples/sec: 64.46 - lr: 0.000030
2021-06-22 14:27:52,688 epoch 11 - iter 200/254 - loss 0.16533693 - samples/sec: 64.19 - lr: 0.000030
2021-06-22 14:28:05,107 epoch 11 - iter 225/254 - loss 0.16256439 - samples/sec: 64.43 - lr: 0.000030
2021-06-22 14:28:17,546 epoch 11 - iter 250/254 - loss 0.16368743 - samples/sec: 64.32 - lr: 0.000030
2021-06-22 14:28:19,140 ----------------------------------------------------------------------------------------------------
2021-06-22 14:28:19,140 EPOCH 11 done: loss 0.1633 - lr 0.0000300
2021-06-22 14:28:23,517 DEV : loss 0.12474183738231659 - score 0.9706
2021-06-22 14:28:23,578 BAD EPOCHS (no improvement): 1
2021-06-22 14:28:23,579 ----------------------------------------------------------------------------------------------------
2021-06-22 14:28:35,920 epoch 12 - iter 25/254 - loss 0.14224219 - samples/sec: 64.83 - lr: 0.000030
2021-06-22 14:28:48,359 epoch 12 - iter 50/254 - loss 0.14631040 - samples/sec: 64.32 - lr: 0.000030
2021-06-22 14:29:00,816 epoch 12 - iter 75/254 - loss 0.14978829 - samples/sec: 64.23 - lr: 0.000030
2021-06-22 14:29:13,327 epoch 12 - iter 100/254 - loss 0.15377141 - samples/sec: 63.95 - lr: 0.000030
2021-06-22 14:29:25,761 epoch 12 - iter 125/254 - loss 0.15513189 - samples/sec: 64.35 - lr: 0.000030
2021-06-22 14:29:38,153 epoch 12 - iter 150/254 - loss 0.15705566 - samples/sec: 64.56 - lr: 0.000030
2021-06-22 14:29:50,612 epoch 12 - iter 175/254 - loss 0.15507559 - samples/sec: 64.22 - lr: 0.000030
2021-06-22 14:30:02,987 epoch 12 - iter 200/254 - loss 0.15589099 - samples/sec: 64.65 - lr: 0.000030
2021-06-22 14:30:15,380 epoch 12 - iter 225/254 - loss 0.15839005 - samples/sec: 64.56 - lr: 0.000030
2021-06-22 14:30:27,804 epoch 12 - iter 250/254 - loss 0.16011313 - samples/sec: 64.40 - lr: 0.000030
2021-06-22 14:30:29,404 ----------------------------------------------------------------------------------------------------
2021-06-22 14:30:29,405 EPOCH 12 done: loss 0.1593 - lr 0.0000300
2021-06-22 14:30:33,776 DEV : loss 0.12505654990673065 - score 0.9721
2021-06-22 14:30:33,839 BAD EPOCHS (no improvement): 2
2021-06-22 14:30:33,840 ----------------------------------------------------------------------------------------------------
2021-06-22 14:30:46,247 epoch 13 - iter 25/254 - loss 0.11389311 - samples/sec: 64.49 - lr: 0.000030
2021-06-22 14:30:58,623 epoch 13 - iter 50/254 - loss 0.13135554 - samples/sec: 64.65 - lr: 0.000030
2021-06-22 14:31:11,034 epoch 13 - iter 75/254 - loss 0.13639638 - samples/sec: 64.47 - lr: 0.000030
2021-06-22 14:31:23,414 epoch 13 - iter 100/254 - loss 0.13579578 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 14:31:35,867 epoch 13 - iter 125/254 - loss 0.14053688 - samples/sec: 64.25 - lr: 0.000030
2021-06-22 14:31:48,241 epoch 13 - iter 150/254 - loss 0.14500421 - samples/sec: 64.66 - lr: 0.000030
2021-06-22 14:32:01,231 epoch 13 - iter 175/254 - loss 0.14502116 - samples/sec: 61.60 - lr: 0.000030
2021-06-22 14:32:13,687 epoch 13 - iter 200/254 - loss 0.14776190 - samples/sec: 64.23 - lr: 0.000030
2021-06-22 14:32:26,143 epoch 13 - iter 225/254 - loss 0.14667876 - samples/sec: 64.24 - lr: 0.000030
2021-06-22 14:32:38,554 epoch 13 - iter 250/254 - loss 0.14519558 - samples/sec: 64.46 - lr: 0.000030
2021-06-22 14:32:40,145 ----------------------------------------------------------------------------------------------------
2021-06-22 14:32:40,145 EPOCH 13 done: loss 0.1454 - lr 0.0000300
2021-06-22 14:32:44,509 DEV : loss 0.12525130808353424 - score 0.971
2021-06-22 14:32:44,572 BAD EPOCHS (no improvement): 3
2021-06-22 14:32:44,572 ----------------------------------------------------------------------------------------------------
2021-06-22 14:32:56,950 epoch 14 - iter 25/254 - loss 0.12549139 - samples/sec: 64.64 - lr: 0.000030
2021-06-22 14:33:09,381 epoch 14 - iter 50/254 - loss 0.13037817 - samples/sec: 64.36 - lr: 0.000030
2021-06-22 14:33:21,773 epoch 14 - iter 75/254 - loss 0.13521109 - samples/sec: 64.57 - lr: 0.000030
2021-06-22 14:33:34,105 epoch 14 - iter 100/254 - loss 0.14322364 - samples/sec: 64.88 - lr: 0.000030
2021-06-22 14:33:46,533 epoch 14 - iter 125/254 - loss 0.14185309 - samples/sec: 64.38 - lr: 0.000030
2021-06-22 14:33:58,852 epoch 14 - iter 150/254 - loss 0.14056491 - samples/sec: 64.95 - lr: 0.000030
2021-06-22 14:34:11,289 epoch 14 - iter 175/254 - loss 0.13760886 - samples/sec: 64.33 - lr: 0.000030
2021-06-22 14:34:23,707 epoch 14 - iter 200/254 - loss 0.13581920 - samples/sec: 64.43 - lr: 0.000030
2021-06-22 14:34:36,090 epoch 14 - iter 225/254 - loss 0.13735233 - samples/sec: 64.62 - lr: 0.000030
2021-06-22 14:34:48,486 epoch 14 - iter 250/254 - loss 0.13867749 - samples/sec: 64.54 - lr: 0.000030
2021-06-22 14:34:50,078 ----------------------------------------------------------------------------------------------------
2021-06-22 14:34:50,078 EPOCH 14 done: loss 0.1377 - lr 0.0000300
2021-06-22 14:34:54,448 DEV : loss 0.13152554631233215 - score 0.9714
Epoch    14: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 14:34:54,510 BAD EPOCHS (no improvement): 4
2021-06-22 14:34:54,510 ----------------------------------------------------------------------------------------------------
2021-06-22 14:35:06,975 epoch 15 - iter 25/254 - loss 0.13069876 - samples/sec: 64.19 - lr: 0.000015
2021-06-22 14:35:19,403 epoch 15 - iter 50/254 - loss 0.12483729 - samples/sec: 64.38 - lr: 0.000015
2021-06-22 14:35:31,743 epoch 15 - iter 75/254 - loss 0.12382265 - samples/sec: 64.84 - lr: 0.000015
2021-06-22 14:35:44,125 epoch 15 - iter 100/254 - loss 0.12918320 - samples/sec: 64.62 - lr: 0.000015
2021-06-22 14:35:56,635 epoch 15 - iter 125/254 - loss 0.13323671 - samples/sec: 63.96 - lr: 0.000015
2021-06-22 14:36:08,948 epoch 15 - iter 150/254 - loss 0.13849670 - samples/sec: 64.98 - lr: 0.000015
2021-06-22 14:36:21,250 epoch 15 - iter 175/254 - loss 0.13643232 - samples/sec: 65.04 - lr: 0.000015
2021-06-22 14:36:33,589 epoch 15 - iter 200/254 - loss 0.13541209 - samples/sec: 64.84 - lr: 0.000015
2021-06-22 14:36:46,058 epoch 15 - iter 225/254 - loss 0.13574069 - samples/sec: 64.17 - lr: 0.000015
2021-06-22 14:36:58,474 epoch 15 - iter 250/254 - loss 0.13479966 - samples/sec: 64.44 - lr: 0.000015
2021-06-22 14:37:00,040 ----------------------------------------------------------------------------------------------------
2021-06-22 14:37:00,040 EPOCH 15 done: loss 0.1338 - lr 0.0000150
2021-06-22 14:37:04,411 DEV : loss 0.12019053101539612 - score 0.9712
2021-06-22 14:37:04,474 BAD EPOCHS (no improvement): 1
2021-06-22 14:37:04,474 ----------------------------------------------------------------------------------------------------
2021-06-22 14:37:16,848 epoch 16 - iter 25/254 - loss 0.14081784 - samples/sec: 64.66 - lr: 0.000015
2021-06-22 14:37:29,252 epoch 16 - iter 50/254 - loss 0.12941661 - samples/sec: 64.50 - lr: 0.000015
2021-06-22 14:37:41,703 epoch 16 - iter 75/254 - loss 0.12230385 - samples/sec: 64.26 - lr: 0.000015
2021-06-22 14:37:53,992 epoch 16 - iter 100/254 - loss 0.11340454 - samples/sec: 65.11 - lr: 0.000015
2021-06-22 14:38:06,363 epoch 16 - iter 125/254 - loss 0.11368885 - samples/sec: 64.68 - lr: 0.000015
2021-06-22 14:38:18,682 epoch 16 - iter 150/254 - loss 0.11694576 - samples/sec: 64.95 - lr: 0.000015
2021-06-22 14:38:31,014 epoch 16 - iter 175/254 - loss 0.12219976 - samples/sec: 64.88 - lr: 0.000015
2021-06-22 14:38:43,495 epoch 16 - iter 200/254 - loss 0.12105008 - samples/sec: 64.11 - lr: 0.000015
2021-06-22 14:38:55,986 epoch 16 - iter 225/254 - loss 0.12260971 - samples/sec: 64.05 - lr: 0.000015
2021-06-22 14:39:08,373 epoch 16 - iter 250/254 - loss 0.12437644 - samples/sec: 64.59 - lr: 0.000015
2021-06-22 14:39:09,960 ----------------------------------------------------------------------------------------------------
2021-06-22 14:39:09,960 EPOCH 16 done: loss 0.1232 - lr 0.0000150
2021-06-22 14:39:14,330 DEV : loss 0.11298460513353348 - score 0.9744
2021-06-22 14:39:14,392 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:39:22,917 ----------------------------------------------------------------------------------------------------
2021-06-22 14:39:35,343 epoch 17 - iter 25/254 - loss 0.14006678 - samples/sec: 64.39 - lr: 0.000015
2021-06-22 14:39:47,737 epoch 17 - iter 50/254 - loss 0.12681714 - samples/sec: 64.56 - lr: 0.000015
2021-06-22 14:40:00,155 epoch 17 - iter 75/254 - loss 0.12371289 - samples/sec: 64.43 - lr: 0.000015
2021-06-22 14:40:12,602 epoch 17 - iter 100/254 - loss 0.13054100 - samples/sec: 64.28 - lr: 0.000015
2021-06-22 14:40:25,071 epoch 17 - iter 125/254 - loss 0.13180885 - samples/sec: 64.17 - lr: 0.000015
2021-06-22 14:40:37,430 epoch 17 - iter 150/254 - loss 0.12954165 - samples/sec: 64.74 - lr: 0.000015
2021-06-22 14:40:49,834 epoch 17 - iter 175/254 - loss 0.12957593 - samples/sec: 64.50 - lr: 0.000015
2021-06-22 14:41:02,260 epoch 17 - iter 200/254 - loss 0.12996065 - samples/sec: 64.39 - lr: 0.000015
2021-06-22 14:41:14,645 epoch 17 - iter 225/254 - loss 0.13064764 - samples/sec: 64.61 - lr: 0.000015
2021-06-22 14:41:27,671 epoch 17 - iter 250/254 - loss 0.13034407 - samples/sec: 61.42 - lr: 0.000015
2021-06-22 14:41:29,260 ----------------------------------------------------------------------------------------------------
2021-06-22 14:41:29,260 EPOCH 17 done: loss 0.1326 - lr 0.0000150
2021-06-22 14:41:33,629 DEV : loss 0.11474385857582092 - score 0.9743
2021-06-22 14:41:33,692 BAD EPOCHS (no improvement): 1
2021-06-22 14:41:33,692 ----------------------------------------------------------------------------------------------------
2021-06-22 14:41:46,104 epoch 18 - iter 25/254 - loss 0.11216278 - samples/sec: 64.46 - lr: 0.000015
2021-06-22 14:41:58,544 epoch 18 - iter 50/254 - loss 0.10955736 - samples/sec: 64.32 - lr: 0.000015
2021-06-22 14:42:11,034 epoch 18 - iter 75/254 - loss 0.10737355 - samples/sec: 64.06 - lr: 0.000015
2021-06-22 14:42:23,442 epoch 18 - iter 100/254 - loss 0.10866075 - samples/sec: 64.49 - lr: 0.000015
2021-06-22 14:42:35,831 epoch 18 - iter 125/254 - loss 0.11161018 - samples/sec: 64.58 - lr: 0.000015
2021-06-22 14:42:48,208 epoch 18 - iter 150/254 - loss 0.11535367 - samples/sec: 64.65 - lr: 0.000015
2021-06-22 14:43:00,624 epoch 18 - iter 175/254 - loss 0.11231635 - samples/sec: 64.44 - lr: 0.000015
2021-06-22 14:43:13,023 epoch 18 - iter 200/254 - loss 0.11337874 - samples/sec: 64.53 - lr: 0.000015
2021-06-22 14:43:25,364 epoch 18 - iter 225/254 - loss 0.11173767 - samples/sec: 64.83 - lr: 0.000015
2021-06-22 14:43:37,838 epoch 18 - iter 250/254 - loss 0.11186819 - samples/sec: 64.14 - lr: 0.000015
2021-06-22 14:43:39,431 ----------------------------------------------------------------------------------------------------
2021-06-22 14:43:39,431 EPOCH 18 done: loss 0.1124 - lr 0.0000150
2021-06-22 14:43:43,804 DEV : loss 0.1138792410492897 - score 0.9729
2021-06-22 14:43:43,866 BAD EPOCHS (no improvement): 2
2021-06-22 14:43:43,867 ----------------------------------------------------------------------------------------------------
2021-06-22 14:43:56,199 epoch 19 - iter 25/254 - loss 0.11683594 - samples/sec: 64.88 - lr: 0.000015
2021-06-22 14:44:08,588 epoch 19 - iter 50/254 - loss 0.10895535 - samples/sec: 64.58 - lr: 0.000015
2021-06-22 14:44:20,935 epoch 19 - iter 75/254 - loss 0.10981258 - samples/sec: 64.80 - lr: 0.000015
2021-06-22 14:44:33,342 epoch 19 - iter 100/254 - loss 0.11325364 - samples/sec: 64.49 - lr: 0.000015
2021-06-22 14:44:45,844 epoch 19 - iter 125/254 - loss 0.11698409 - samples/sec: 64.00 - lr: 0.000015
2021-06-22 14:44:58,283 epoch 19 - iter 150/254 - loss 0.11337854 - samples/sec: 64.33 - lr: 0.000015
2021-06-22 14:45:10,795 epoch 19 - iter 175/254 - loss 0.11506195 - samples/sec: 63.94 - lr: 0.000015
2021-06-22 14:45:23,282 epoch 19 - iter 200/254 - loss 0.11666034 - samples/sec: 64.08 - lr: 0.000015
2021-06-22 14:45:35,700 epoch 19 - iter 225/254 - loss 0.11434104 - samples/sec: 64.43 - lr: 0.000015
2021-06-22 14:45:48,197 epoch 19 - iter 250/254 - loss 0.11257103 - samples/sec: 64.02 - lr: 0.000015
2021-06-22 14:45:49,813 ----------------------------------------------------------------------------------------------------
2021-06-22 14:45:49,813 EPOCH 19 done: loss 0.1123 - lr 0.0000150
2021-06-22 14:45:54,184 DEV : loss 0.11576578766107559 - score 0.9743
2021-06-22 14:45:54,247 BAD EPOCHS (no improvement): 3
2021-06-22 14:45:54,247 ----------------------------------------------------------------------------------------------------
2021-06-22 14:46:06,653 epoch 20 - iter 25/254 - loss 0.10377685 - samples/sec: 64.49 - lr: 0.000015
2021-06-22 14:46:19,128 epoch 20 - iter 50/254 - loss 0.11508779 - samples/sec: 64.14 - lr: 0.000015
2021-06-22 14:46:31,545 epoch 20 - iter 75/254 - loss 0.11941946 - samples/sec: 64.44 - lr: 0.000015
2021-06-22 14:46:43,962 epoch 20 - iter 100/254 - loss 0.11750874 - samples/sec: 64.43 - lr: 0.000015
2021-06-22 14:46:56,429 epoch 20 - iter 125/254 - loss 0.10963765 - samples/sec: 64.18 - lr: 0.000015
2021-06-22 14:47:08,945 epoch 20 - iter 150/254 - loss 0.10616314 - samples/sec: 63.93 - lr: 0.000015
2021-06-22 14:47:21,451 epoch 20 - iter 175/254 - loss 0.10365368 - samples/sec: 63.97 - lr: 0.000015
2021-06-22 14:47:33,932 epoch 20 - iter 200/254 - loss 0.10198676 - samples/sec: 64.11 - lr: 0.000015
2021-06-22 14:47:46,293 epoch 20 - iter 225/254 - loss 0.10324635 - samples/sec: 64.73 - lr: 0.000015
2021-06-22 14:47:58,763 epoch 20 - iter 250/254 - loss 0.10557914 - samples/sec: 64.16 - lr: 0.000015
2021-06-22 14:48:00,360 ----------------------------------------------------------------------------------------------------
2021-06-22 14:48:00,360 EPOCH 20 done: loss 0.1059 - lr 0.0000150
2021-06-22 14:48:04,740 DEV : loss 0.11693590134382248 - score 0.975
2021-06-22 14:48:04,802 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:48:13,146 ----------------------------------------------------------------------------------------------------
2021-06-22 14:48:25,614 epoch 21 - iter 25/254 - loss 0.11834474 - samples/sec: 64.18 - lr: 0.000015
2021-06-22 14:48:38,040 epoch 21 - iter 50/254 - loss 0.10505158 - samples/sec: 64.39 - lr: 0.000015
2021-06-22 14:48:50,463 epoch 21 - iter 75/254 - loss 0.10390903 - samples/sec: 64.41 - lr: 0.000015
2021-06-22 14:49:02,974 epoch 21 - iter 100/254 - loss 0.10378888 - samples/sec: 63.95 - lr: 0.000015
2021-06-22 14:49:15,423 epoch 21 - iter 125/254 - loss 0.11266919 - samples/sec: 64.27 - lr: 0.000015
2021-06-22 14:49:27,859 epoch 21 - iter 150/254 - loss 0.11083915 - samples/sec: 64.33 - lr: 0.000015
2021-06-22 14:49:40,268 epoch 21 - iter 175/254 - loss 0.11012885 - samples/sec: 64.48 - lr: 0.000015
2021-06-22 14:49:52,733 epoch 21 - iter 200/254 - loss 0.10748039 - samples/sec: 64.18 - lr: 0.000015
2021-06-22 14:50:05,227 epoch 21 - iter 225/254 - loss 0.10566340 - samples/sec: 64.04 - lr: 0.000015
2021-06-22 14:50:17,613 epoch 21 - iter 250/254 - loss 0.10638024 - samples/sec: 64.60 - lr: 0.000015
2021-06-22 14:50:19,197 ----------------------------------------------------------------------------------------------------
2021-06-22 14:50:19,197 EPOCH 21 done: loss 0.1062 - lr 0.0000150
2021-06-22 14:50:24,156 DEV : loss 0.11665605008602142 - score 0.9757
2021-06-22 14:50:24,219 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:50:32,760 ----------------------------------------------------------------------------------------------------
2021-06-22 14:50:45,159 epoch 22 - iter 25/254 - loss 0.10509301 - samples/sec: 64.53 - lr: 0.000015
2021-06-22 14:50:57,619 epoch 22 - iter 50/254 - loss 0.10937876 - samples/sec: 64.21 - lr: 0.000015
2021-06-22 14:51:10,052 epoch 22 - iter 75/254 - loss 0.10761534 - samples/sec: 64.35 - lr: 0.000015
2021-06-22 14:51:22,451 epoch 22 - iter 100/254 - loss 0.11068222 - samples/sec: 64.53 - lr: 0.000015
2021-06-22 14:51:34,931 epoch 22 - iter 125/254 - loss 0.10582772 - samples/sec: 64.11 - lr: 0.000015
2021-06-22 14:51:47,376 epoch 22 - iter 150/254 - loss 0.10361087 - samples/sec: 64.29 - lr: 0.000015
2021-06-22 14:51:59,720 epoch 22 - iter 175/254 - loss 0.10100820 - samples/sec: 64.82 - lr: 0.000015
2021-06-22 14:52:12,095 epoch 22 - iter 200/254 - loss 0.10166131 - samples/sec: 64.65 - lr: 0.000015
2021-06-22 14:52:24,502 epoch 22 - iter 225/254 - loss 0.10150482 - samples/sec: 64.49 - lr: 0.000015
2021-06-22 14:52:36,951 epoch 22 - iter 250/254 - loss 0.10232988 - samples/sec: 64.27 - lr: 0.000015
2021-06-22 14:52:38,514 ----------------------------------------------------------------------------------------------------
2021-06-22 14:52:38,515 EPOCH 22 done: loss 0.1029 - lr 0.0000150
2021-06-22 14:52:42,886 DEV : loss 0.11374139040708542 - score 0.9742
2021-06-22 14:52:42,948 BAD EPOCHS (no improvement): 1
2021-06-22 14:52:42,948 ----------------------------------------------------------------------------------------------------
2021-06-22 14:52:55,304 epoch 23 - iter 25/254 - loss 0.09945198 - samples/sec: 64.75 - lr: 0.000015
2021-06-22 14:53:07,757 epoch 23 - iter 50/254 - loss 0.09236526 - samples/sec: 64.25 - lr: 0.000015
2021-06-22 14:53:20,211 epoch 23 - iter 75/254 - loss 0.08869440 - samples/sec: 64.24 - lr: 0.000015
2021-06-22 14:53:32,653 epoch 23 - iter 100/254 - loss 0.09446007 - samples/sec: 64.31 - lr: 0.000015
2021-06-22 14:53:45,098 epoch 23 - iter 125/254 - loss 0.09726962 - samples/sec: 64.29 - lr: 0.000015
2021-06-22 14:53:57,460 epoch 23 - iter 150/254 - loss 0.09864674 - samples/sec: 64.73 - lr: 0.000015
2021-06-22 14:54:09,931 epoch 23 - iter 175/254 - loss 0.09886356 - samples/sec: 64.15 - lr: 0.000015
2021-06-22 14:54:22,371 epoch 23 - iter 200/254 - loss 0.10235130 - samples/sec: 64.32 - lr: 0.000015
2021-06-22 14:54:34,813 epoch 23 - iter 225/254 - loss 0.09946125 - samples/sec: 64.30 - lr: 0.000015
2021-06-22 14:54:47,256 epoch 23 - iter 250/254 - loss 0.09799698 - samples/sec: 64.30 - lr: 0.000015
2021-06-22 14:54:48,831 ----------------------------------------------------------------------------------------------------
2021-06-22 14:54:48,831 EPOCH 23 done: loss 0.0974 - lr 0.0000150
2021-06-22 14:54:53,212 DEV : loss 0.11365184187889099 - score 0.9756
2021-06-22 14:54:53,275 BAD EPOCHS (no improvement): 2
2021-06-22 14:54:53,275 ----------------------------------------------------------------------------------------------------
2021-06-22 14:55:05,712 epoch 24 - iter 25/254 - loss 0.09926391 - samples/sec: 64.33 - lr: 0.000015
2021-06-22 14:55:18,225 epoch 24 - iter 50/254 - loss 0.09846738 - samples/sec: 63.94 - lr: 0.000015
2021-06-22 14:55:30,637 epoch 24 - iter 75/254 - loss 0.10418134 - samples/sec: 64.46 - lr: 0.000015
2021-06-22 14:55:43,045 epoch 24 - iter 100/254 - loss 0.10689535 - samples/sec: 64.48 - lr: 0.000015
2021-06-22 14:55:55,511 epoch 24 - iter 125/254 - loss 0.10150280 - samples/sec: 64.18 - lr: 0.000015
2021-06-22 14:56:08,050 epoch 24 - iter 150/254 - loss 0.09977274 - samples/sec: 63.81 - lr: 0.000015
2021-06-22 14:56:20,551 epoch 24 - iter 175/254 - loss 0.09935834 - samples/sec: 64.00 - lr: 0.000015
2021-06-22 14:56:33,003 epoch 24 - iter 200/254 - loss 0.09957507 - samples/sec: 64.26 - lr: 0.000015
2021-06-22 14:56:45,428 epoch 24 - iter 225/254 - loss 0.09926721 - samples/sec: 64.39 - lr: 0.000015
2021-06-22 14:56:57,867 epoch 24 - iter 250/254 - loss 0.09909906 - samples/sec: 64.32 - lr: 0.000015
2021-06-22 14:56:59,481 ----------------------------------------------------------------------------------------------------
2021-06-22 14:56:59,481 EPOCH 24 done: loss 0.0993 - lr 0.0000150
2021-06-22 14:57:03,863 DEV : loss 0.10878080874681473 - score 0.9755
2021-06-22 14:57:03,926 BAD EPOCHS (no improvement): 3
2021-06-22 14:57:03,926 ----------------------------------------------------------------------------------------------------
2021-06-22 14:57:16,347 epoch 25 - iter 25/254 - loss 0.09797905 - samples/sec: 64.42 - lr: 0.000015
2021-06-22 14:57:28,821 epoch 25 - iter 50/254 - loss 0.08935431 - samples/sec: 64.14 - lr: 0.000015
2021-06-22 14:57:41,281 epoch 25 - iter 75/254 - loss 0.09509944 - samples/sec: 64.21 - lr: 0.000015
2021-06-22 14:57:53,741 epoch 25 - iter 100/254 - loss 0.08948170 - samples/sec: 64.22 - lr: 0.000015
2021-06-22 14:58:06,156 epoch 25 - iter 125/254 - loss 0.08875815 - samples/sec: 64.45 - lr: 0.000015
2021-06-22 14:58:19,232 epoch 25 - iter 150/254 - loss 0.08987312 - samples/sec: 61.19 - lr: 0.000015
2021-06-22 14:58:31,667 epoch 25 - iter 175/254 - loss 0.09011738 - samples/sec: 64.34 - lr: 0.000015
2021-06-22 14:58:44,088 epoch 25 - iter 200/254 - loss 0.09429793 - samples/sec: 64.42 - lr: 0.000015
2021-06-22 14:58:56,618 epoch 25 - iter 225/254 - loss 0.09439751 - samples/sec: 63.85 - lr: 0.000015
2021-06-22 14:59:09,063 epoch 25 - iter 250/254 - loss 0.09244493 - samples/sec: 64.29 - lr: 0.000015
2021-06-22 14:59:10,666 ----------------------------------------------------------------------------------------------------
2021-06-22 14:59:10,667 EPOCH 25 done: loss 0.0922 - lr 0.0000150
2021-06-22 14:59:15,042 DEV : loss 0.10840002447366714 - score 0.9763
2021-06-22 14:59:15,105 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 14:59:24,062 ----------------------------------------------------------------------------------------------------
2021-06-22 14:59:36,580 epoch 26 - iter 25/254 - loss 0.09077754 - samples/sec: 63.92 - lr: 0.000015
2021-06-22 14:59:48,969 epoch 26 - iter 50/254 - loss 0.08895350 - samples/sec: 64.58 - lr: 0.000015
2021-06-22 15:00:01,369 epoch 26 - iter 75/254 - loss 0.09600191 - samples/sec: 64.52 - lr: 0.000015
2021-06-22 15:00:13,859 epoch 26 - iter 100/254 - loss 0.08897512 - samples/sec: 64.06 - lr: 0.000015
2021-06-22 15:00:26,246 epoch 26 - iter 125/254 - loss 0.08890186 - samples/sec: 64.59 - lr: 0.000015
2021-06-22 15:00:38,714 epoch 26 - iter 150/254 - loss 0.08765458 - samples/sec: 64.17 - lr: 0.000015
2021-06-22 15:00:51,218 epoch 26 - iter 175/254 - loss 0.08653373 - samples/sec: 63.99 - lr: 0.000015
2021-06-22 15:01:03,689 epoch 26 - iter 200/254 - loss 0.08597853 - samples/sec: 64.16 - lr: 0.000015
2021-06-22 15:01:16,094 epoch 26 - iter 225/254 - loss 0.08601599 - samples/sec: 64.50 - lr: 0.000015
2021-06-22 15:01:28,540 epoch 26 - iter 250/254 - loss 0.08569396 - samples/sec: 64.28 - lr: 0.000015
2021-06-22 15:01:30,128 ----------------------------------------------------------------------------------------------------
2021-06-22 15:01:30,129 EPOCH 26 done: loss 0.0853 - lr 0.0000150
2021-06-22 15:01:34,494 DEV : loss 0.11356167495250702 - score 0.9763
2021-06-22 15:01:34,559 BAD EPOCHS (no improvement): 1
2021-06-22 15:01:34,559 ----------------------------------------------------------------------------------------------------
2021-06-22 15:01:46,986 epoch 27 - iter 25/254 - loss 0.10164188 - samples/sec: 64.38 - lr: 0.000015
2021-06-22 15:01:59,442 epoch 27 - iter 50/254 - loss 0.09688717 - samples/sec: 64.23 - lr: 0.000015
2021-06-22 15:02:11,914 epoch 27 - iter 75/254 - loss 0.09169838 - samples/sec: 64.15 - lr: 0.000015
2021-06-22 15:02:24,296 epoch 27 - iter 100/254 - loss 0.08556740 - samples/sec: 64.62 - lr: 0.000015
2021-06-22 15:02:36,746 epoch 27 - iter 125/254 - loss 0.08310712 - samples/sec: 64.26 - lr: 0.000015
2021-06-22 15:02:49,207 epoch 27 - iter 150/254 - loss 0.08196208 - samples/sec: 64.21 - lr: 0.000015
2021-06-22 15:03:01,647 epoch 27 - iter 175/254 - loss 0.08114220 - samples/sec: 64.32 - lr: 0.000015
2021-06-22 15:03:14,063 epoch 27 - iter 200/254 - loss 0.08236762 - samples/sec: 64.45 - lr: 0.000015
2021-06-22 15:03:26,460 epoch 27 - iter 225/254 - loss 0.08617901 - samples/sec: 64.54 - lr: 0.000015
2021-06-22 15:03:38,891 epoch 27 - iter 250/254 - loss 0.08648102 - samples/sec: 64.36 - lr: 0.000015
2021-06-22 15:03:40,497 ----------------------------------------------------------------------------------------------------
2021-06-22 15:03:40,497 EPOCH 27 done: loss 0.0867 - lr 0.0000150
2021-06-22 15:03:44,864 DEV : loss 0.11138893663883209 - score 0.9749
2021-06-22 15:03:44,927 BAD EPOCHS (no improvement): 2
2021-06-22 15:03:44,927 ----------------------------------------------------------------------------------------------------
2021-06-22 15:03:57,271 epoch 28 - iter 25/254 - loss 0.07134790 - samples/sec: 64.82 - lr: 0.000015
2021-06-22 15:04:09,665 epoch 28 - iter 50/254 - loss 0.07449531 - samples/sec: 64.55 - lr: 0.000015
2021-06-22 15:04:22,087 epoch 28 - iter 75/254 - loss 0.08180922 - samples/sec: 64.41 - lr: 0.000015
2021-06-22 15:04:34,448 epoch 28 - iter 100/254 - loss 0.08458635 - samples/sec: 64.73 - lr: 0.000015
2021-06-22 15:04:46,893 epoch 28 - iter 125/254 - loss 0.08433958 - samples/sec: 64.29 - lr: 0.000015
2021-06-22 15:04:59,364 epoch 28 - iter 150/254 - loss 0.08300274 - samples/sec: 64.16 - lr: 0.000015
2021-06-22 15:05:11,860 epoch 28 - iter 175/254 - loss 0.08325782 - samples/sec: 64.03 - lr: 0.000015
2021-06-22 15:05:24,308 epoch 28 - iter 200/254 - loss 0.08393716 - samples/sec: 64.28 - lr: 0.000015
2021-06-22 15:05:36,805 epoch 28 - iter 225/254 - loss 0.08312728 - samples/sec: 64.03 - lr: 0.000015
2021-06-22 15:05:49,317 epoch 28 - iter 250/254 - loss 0.08385308 - samples/sec: 63.94 - lr: 0.000015
2021-06-22 15:05:50,896 ----------------------------------------------------------------------------------------------------
2021-06-22 15:05:50,896 EPOCH 28 done: loss 0.0838 - lr 0.0000150
2021-06-22 15:05:55,850 DEV : loss 0.1089797392487526 - score 0.9777
2021-06-22 15:05:55,913 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:06:04,612 ----------------------------------------------------------------------------------------------------
2021-06-22 15:06:17,109 epoch 29 - iter 25/254 - loss 0.07974672 - samples/sec: 64.02 - lr: 0.000015
2021-06-22 15:06:29,523 epoch 29 - iter 50/254 - loss 0.09267753 - samples/sec: 64.46 - lr: 0.000015
2021-06-22 15:06:42,039 epoch 29 - iter 75/254 - loss 0.08948329 - samples/sec: 63.92 - lr: 0.000015
2021-06-22 15:06:54,484 epoch 29 - iter 100/254 - loss 0.08326591 - samples/sec: 64.29 - lr: 0.000015
2021-06-22 15:07:07,007 epoch 29 - iter 125/254 - loss 0.08470930 - samples/sec: 63.89 - lr: 0.000015
2021-06-22 15:07:19,429 epoch 29 - iter 150/254 - loss 0.08980234 - samples/sec: 64.41 - lr: 0.000015
2021-06-22 15:07:31,816 epoch 29 - iter 175/254 - loss 0.09331070 - samples/sec: 64.59 - lr: 0.000015
2021-06-22 15:07:44,264 epoch 29 - iter 200/254 - loss 0.09403058 - samples/sec: 64.27 - lr: 0.000015
2021-06-22 15:07:56,733 epoch 29 - iter 225/254 - loss 0.09084623 - samples/sec: 64.17 - lr: 0.000015
2021-06-22 15:08:09,190 epoch 29 - iter 250/254 - loss 0.08793164 - samples/sec: 64.22 - lr: 0.000015
2021-06-22 15:08:10,798 ----------------------------------------------------------------------------------------------------
2021-06-22 15:08:10,798 EPOCH 29 done: loss 0.0883 - lr 0.0000150
2021-06-22 15:08:15,170 DEV : loss 0.11276935040950775 - score 0.9757
2021-06-22 15:08:15,233 BAD EPOCHS (no improvement): 1
2021-06-22 15:08:15,234 ----------------------------------------------------------------------------------------------------
2021-06-22 15:08:27,659 epoch 30 - iter 25/254 - loss 0.07570014 - samples/sec: 64.39 - lr: 0.000015
2021-06-22 15:08:40,074 epoch 30 - iter 50/254 - loss 0.08262577 - samples/sec: 64.45 - lr: 0.000015
2021-06-22 15:08:52,561 epoch 30 - iter 75/254 - loss 0.09106213 - samples/sec: 64.08 - lr: 0.000015
2021-06-22 15:09:05,050 epoch 30 - iter 100/254 - loss 0.07982037 - samples/sec: 64.06 - lr: 0.000015
2021-06-22 15:09:17,543 epoch 30 - iter 125/254 - loss 0.08421864 - samples/sec: 64.04 - lr: 0.000015
2021-06-22 15:09:29,995 epoch 30 - iter 150/254 - loss 0.08360807 - samples/sec: 64.25 - lr: 0.000015
2021-06-22 15:09:42,533 epoch 30 - iter 175/254 - loss 0.08146894 - samples/sec: 63.82 - lr: 0.000015
2021-06-22 15:09:55,000 epoch 30 - iter 200/254 - loss 0.08430593 - samples/sec: 64.18 - lr: 0.000015
2021-06-22 15:10:07,467 epoch 30 - iter 225/254 - loss 0.08410252 - samples/sec: 64.18 - lr: 0.000015
2021-06-22 15:10:19,917 epoch 30 - iter 250/254 - loss 0.08199794 - samples/sec: 64.26 - lr: 0.000015
2021-06-22 15:10:21,523 ----------------------------------------------------------------------------------------------------
2021-06-22 15:10:21,523 EPOCH 30 done: loss 0.0816 - lr 0.0000150
2021-06-22 15:10:25,904 DEV : loss 0.10681486874818802 - score 0.9806
2021-06-22 15:10:25,967 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:10:35,084 ----------------------------------------------------------------------------------------------------
2021-06-22 15:10:47,486 epoch 31 - iter 25/254 - loss 0.07462017 - samples/sec: 64.52 - lr: 0.000015
2021-06-22 15:10:59,942 epoch 31 - iter 50/254 - loss 0.08861919 - samples/sec: 64.23 - lr: 0.000015
2021-06-22 15:11:12,379 epoch 31 - iter 75/254 - loss 0.08277148 - samples/sec: 64.34 - lr: 0.000015
2021-06-22 15:11:24,818 epoch 31 - iter 100/254 - loss 0.07669999 - samples/sec: 64.32 - lr: 0.000015
2021-06-22 15:11:37,279 epoch 31 - iter 125/254 - loss 0.07864797 - samples/sec: 64.21 - lr: 0.000015
2021-06-22 15:11:49,753 epoch 31 - iter 150/254 - loss 0.07925364 - samples/sec: 64.14 - lr: 0.000015
2021-06-22 15:12:02,186 epoch 31 - iter 175/254 - loss 0.08193031 - samples/sec: 64.35 - lr: 0.000015
2021-06-22 15:12:14,645 epoch 31 - iter 200/254 - loss 0.08187069 - samples/sec: 64.22 - lr: 0.000015
2021-06-22 15:12:27,052 epoch 31 - iter 225/254 - loss 0.08427227 - samples/sec: 64.49 - lr: 0.000015
2021-06-22 15:12:39,467 epoch 31 - iter 250/254 - loss 0.08489880 - samples/sec: 64.45 - lr: 0.000015
2021-06-22 15:12:41,088 ----------------------------------------------------------------------------------------------------
2021-06-22 15:12:41,088 EPOCH 31 done: loss 0.0846 - lr 0.0000150
2021-06-22 15:12:45,448 DEV : loss 0.1124235987663269 - score 0.9777
2021-06-22 15:12:45,511 BAD EPOCHS (no improvement): 1
2021-06-22 15:12:45,511 ----------------------------------------------------------------------------------------------------
2021-06-22 15:12:57,956 epoch 32 - iter 25/254 - loss 0.07908400 - samples/sec: 64.29 - lr: 0.000015
2021-06-22 15:13:10,388 epoch 32 - iter 50/254 - loss 0.07316858 - samples/sec: 64.36 - lr: 0.000015
2021-06-22 15:13:22,761 epoch 32 - iter 75/254 - loss 0.08126937 - samples/sec: 64.66 - lr: 0.000015
2021-06-22 15:13:35,276 epoch 32 - iter 100/254 - loss 0.08124078 - samples/sec: 63.93 - lr: 0.000015
2021-06-22 15:13:47,675 epoch 32 - iter 125/254 - loss 0.08230543 - samples/sec: 64.53 - lr: 0.000015
2021-06-22 15:14:00,149 epoch 32 - iter 150/254 - loss 0.08472221 - samples/sec: 64.15 - lr: 0.000015
2021-06-22 15:14:12,564 epoch 32 - iter 175/254 - loss 0.08518227 - samples/sec: 64.44 - lr: 0.000015
2021-06-22 15:14:24,964 epoch 32 - iter 200/254 - loss 0.08577669 - samples/sec: 64.53 - lr: 0.000015
2021-06-22 15:14:37,340 epoch 32 - iter 225/254 - loss 0.08490123 - samples/sec: 64.65 - lr: 0.000015
2021-06-22 15:14:49,755 epoch 32 - iter 250/254 - loss 0.08436222 - samples/sec: 64.44 - lr: 0.000015
2021-06-22 15:14:51,325 ----------------------------------------------------------------------------------------------------
2021-06-22 15:14:51,325 EPOCH 32 done: loss 0.0841 - lr 0.0000150
2021-06-22 15:14:56,263 DEV : loss 0.10941360890865326 - score 0.979
2021-06-22 15:14:56,326 BAD EPOCHS (no improvement): 2
2021-06-22 15:14:56,326 ----------------------------------------------------------------------------------------------------
2021-06-22 15:15:08,750 epoch 33 - iter 25/254 - loss 0.08749575 - samples/sec: 64.40 - lr: 0.000015
2021-06-22 15:15:21,161 epoch 33 - iter 50/254 - loss 0.07576030 - samples/sec: 64.47 - lr: 0.000015
2021-06-22 15:15:33,503 epoch 33 - iter 75/254 - loss 0.06961154 - samples/sec: 64.83 - lr: 0.000015
2021-06-22 15:15:45,889 epoch 33 - iter 100/254 - loss 0.07237893 - samples/sec: 64.59 - lr: 0.000015
2021-06-22 15:15:58,297 epoch 33 - iter 125/254 - loss 0.07490514 - samples/sec: 64.48 - lr: 0.000015
2021-06-22 15:16:10,704 epoch 33 - iter 150/254 - loss 0.07336835 - samples/sec: 64.49 - lr: 0.000015
2021-06-22 15:16:23,111 epoch 33 - iter 175/254 - loss 0.07529749 - samples/sec: 64.49 - lr: 0.000015
2021-06-22 15:16:35,479 epoch 33 - iter 200/254 - loss 0.07544036 - samples/sec: 64.69 - lr: 0.000015
2021-06-22 15:16:47,867 epoch 33 - iter 225/254 - loss 0.07596201 - samples/sec: 64.59 - lr: 0.000015
2021-06-22 15:17:00,239 epoch 33 - iter 250/254 - loss 0.07689701 - samples/sec: 64.67 - lr: 0.000015
2021-06-22 15:17:01,843 ----------------------------------------------------------------------------------------------------
2021-06-22 15:17:01,843 EPOCH 33 done: loss 0.0769 - lr 0.0000150
2021-06-22 15:17:06,210 DEV : loss 0.107818603515625 - score 0.9783
2021-06-22 15:17:06,272 BAD EPOCHS (no improvement): 3
2021-06-22 15:17:06,272 ----------------------------------------------------------------------------------------------------
2021-06-22 15:17:18,707 epoch 34 - iter 25/254 - loss 0.06056024 - samples/sec: 64.35 - lr: 0.000015
2021-06-22 15:17:31,138 epoch 34 - iter 50/254 - loss 0.06848972 - samples/sec: 64.36 - lr: 0.000015
2021-06-22 15:17:43,588 epoch 34 - iter 75/254 - loss 0.07083580 - samples/sec: 64.26 - lr: 0.000015
2021-06-22 15:17:55,972 epoch 34 - iter 100/254 - loss 0.07109887 - samples/sec: 64.61 - lr: 0.000015
2021-06-22 15:18:08,455 epoch 34 - iter 125/254 - loss 0.07136739 - samples/sec: 64.09 - lr: 0.000015
2021-06-22 15:18:20,869 epoch 34 - iter 150/254 - loss 0.07125834 - samples/sec: 64.45 - lr: 0.000015
2021-06-22 15:18:33,273 epoch 34 - iter 175/254 - loss 0.07083638 - samples/sec: 64.51 - lr: 0.000015
2021-06-22 15:18:45,713 epoch 34 - iter 200/254 - loss 0.06868644 - samples/sec: 64.31 - lr: 0.000015
2021-06-22 15:18:58,151 epoch 34 - iter 225/254 - loss 0.07242832 - samples/sec: 64.33 - lr: 0.000015
2021-06-22 15:19:10,547 epoch 34 - iter 250/254 - loss 0.07049986 - samples/sec: 64.54 - lr: 0.000015
2021-06-22 15:19:12,157 ----------------------------------------------------------------------------------------------------
2021-06-22 15:19:12,157 EPOCH 34 done: loss 0.0699 - lr 0.0000150
2021-06-22 15:19:16,527 DEV : loss 0.10449977219104767 - score 0.9798
Epoch    34: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 15:19:16,591 BAD EPOCHS (no improvement): 4
2021-06-22 15:19:16,591 ----------------------------------------------------------------------------------------------------
2021-06-22 15:19:29,000 epoch 35 - iter 25/254 - loss 0.06887736 - samples/sec: 64.48 - lr: 0.000008
2021-06-22 15:19:41,432 epoch 35 - iter 50/254 - loss 0.06858618 - samples/sec: 64.35 - lr: 0.000008
2021-06-22 15:19:53,894 epoch 35 - iter 75/254 - loss 0.07063202 - samples/sec: 64.21 - lr: 0.000008
2021-06-22 15:20:06,277 epoch 35 - iter 100/254 - loss 0.07491447 - samples/sec: 64.61 - lr: 0.000008
2021-06-22 15:20:18,620 epoch 35 - iter 125/254 - loss 0.06802299 - samples/sec: 64.83 - lr: 0.000008
2021-06-22 15:20:30,970 epoch 35 - iter 150/254 - loss 0.07228740 - samples/sec: 64.78 - lr: 0.000008
2021-06-22 15:20:43,274 epoch 35 - iter 175/254 - loss 0.07241522 - samples/sec: 65.03 - lr: 0.000008
2021-06-22 15:20:55,665 epoch 35 - iter 200/254 - loss 0.07268116 - samples/sec: 64.57 - lr: 0.000008
2021-06-22 15:21:08,055 epoch 35 - iter 225/254 - loss 0.07241859 - samples/sec: 64.57 - lr: 0.000008
2021-06-22 15:21:20,434 epoch 35 - iter 250/254 - loss 0.07323912 - samples/sec: 64.64 - lr: 0.000008
2021-06-22 15:21:22,015 ----------------------------------------------------------------------------------------------------
2021-06-22 15:21:22,015 EPOCH 35 done: loss 0.0730 - lr 0.0000075
2021-06-22 15:21:26,378 DEV : loss 0.11272139847278595 - score 0.9777
2021-06-22 15:21:26,440 BAD EPOCHS (no improvement): 1
2021-06-22 15:21:26,440 ----------------------------------------------------------------------------------------------------
2021-06-22 15:21:38,722 epoch 36 - iter 25/254 - loss 0.09375437 - samples/sec: 65.15 - lr: 0.000008
2021-06-22 15:21:51,103 epoch 36 - iter 50/254 - loss 0.08059259 - samples/sec: 64.62 - lr: 0.000008
2021-06-22 15:22:03,517 epoch 36 - iter 75/254 - loss 0.07363758 - samples/sec: 64.45 - lr: 0.000008
2021-06-22 15:22:15,925 epoch 36 - iter 100/254 - loss 0.07223905 - samples/sec: 64.48 - lr: 0.000008
2021-06-22 15:22:28,266 epoch 36 - iter 125/254 - loss 0.07207612 - samples/sec: 64.83 - lr: 0.000008
2021-06-22 15:22:40,604 epoch 36 - iter 150/254 - loss 0.07568752 - samples/sec: 64.85 - lr: 0.000008
2021-06-22 15:22:53,046 epoch 36 - iter 175/254 - loss 0.07680828 - samples/sec: 64.31 - lr: 0.000008
2021-06-22 15:23:05,519 epoch 36 - iter 200/254 - loss 0.07542640 - samples/sec: 64.14 - lr: 0.000008
2021-06-22 15:23:17,930 epoch 36 - iter 225/254 - loss 0.07332215 - samples/sec: 64.47 - lr: 0.000008
2021-06-22 15:23:30,351 epoch 36 - iter 250/254 - loss 0.07109921 - samples/sec: 64.42 - lr: 0.000008
2021-06-22 15:23:31,936 ----------------------------------------------------------------------------------------------------
2021-06-22 15:23:31,936 EPOCH 36 done: loss 0.0714 - lr 0.0000075
2021-06-22 15:23:36,893 DEV : loss 0.10867483913898468 - score 0.977
2021-06-22 15:23:36,956 BAD EPOCHS (no improvement): 2
2021-06-22 15:23:36,956 ----------------------------------------------------------------------------------------------------
2021-06-22 15:23:49,388 epoch 37 - iter 25/254 - loss 0.08017643 - samples/sec: 64.36 - lr: 0.000008
2021-06-22 15:24:01,663 epoch 37 - iter 50/254 - loss 0.07627234 - samples/sec: 65.18 - lr: 0.000008
2021-06-22 15:24:14,106 epoch 37 - iter 75/254 - loss 0.06644380 - samples/sec: 64.30 - lr: 0.000008
2021-06-22 15:24:26,473 epoch 37 - iter 100/254 - loss 0.06498156 - samples/sec: 64.69 - lr: 0.000008
2021-06-22 15:24:38,891 epoch 37 - iter 125/254 - loss 0.06180777 - samples/sec: 64.43 - lr: 0.000008
2021-06-22 15:24:51,306 epoch 37 - iter 150/254 - loss 0.06029173 - samples/sec: 64.45 - lr: 0.000008
2021-06-22 15:25:03,753 epoch 37 - iter 175/254 - loss 0.06394772 - samples/sec: 64.28 - lr: 0.000008
2021-06-22 15:25:16,164 epoch 37 - iter 200/254 - loss 0.06288804 - samples/sec: 64.47 - lr: 0.000008
2021-06-22 15:25:28,545 epoch 37 - iter 225/254 - loss 0.06659872 - samples/sec: 64.62 - lr: 0.000008
2021-06-22 15:25:40,965 epoch 37 - iter 250/254 - loss 0.06822252 - samples/sec: 64.42 - lr: 0.000008
2021-06-22 15:25:42,550 ----------------------------------------------------------------------------------------------------
2021-06-22 15:25:42,550 EPOCH 37 done: loss 0.0684 - lr 0.0000075
2021-06-22 15:25:46,909 DEV : loss 0.10851961374282837 - score 0.9791
2021-06-22 15:25:46,971 BAD EPOCHS (no improvement): 3
2021-06-22 15:25:46,972 ----------------------------------------------------------------------------------------------------
2021-06-22 15:25:59,440 epoch 38 - iter 25/254 - loss 0.04676082 - samples/sec: 64.17 - lr: 0.000008
2021-06-22 15:26:11,849 epoch 38 - iter 50/254 - loss 0.06160558 - samples/sec: 64.48 - lr: 0.000008
2021-06-22 15:26:24,216 epoch 38 - iter 75/254 - loss 0.05961113 - samples/sec: 64.70 - lr: 0.000008
2021-06-22 15:26:36,637 epoch 38 - iter 100/254 - loss 0.06425404 - samples/sec: 64.41 - lr: 0.000008
2021-06-22 15:26:49,061 epoch 38 - iter 125/254 - loss 0.06450188 - samples/sec: 64.40 - lr: 0.000008
2021-06-22 15:27:01,577 epoch 38 - iter 150/254 - loss 0.06258089 - samples/sec: 63.92 - lr: 0.000008
2021-06-22 15:27:14,052 epoch 38 - iter 175/254 - loss 0.06201480 - samples/sec: 64.14 - lr: 0.000008
2021-06-22 15:27:26,421 epoch 38 - iter 200/254 - loss 0.06068467 - samples/sec: 64.69 - lr: 0.000008
2021-06-22 15:27:38,843 epoch 38 - iter 225/254 - loss 0.06077349 - samples/sec: 64.41 - lr: 0.000008
2021-06-22 15:27:51,216 epoch 38 - iter 250/254 - loss 0.05992164 - samples/sec: 64.67 - lr: 0.000008
2021-06-22 15:27:52,798 ----------------------------------------------------------------------------------------------------
2021-06-22 15:27:52,798 EPOCH 38 done: loss 0.0593 - lr 0.0000075
2021-06-22 15:27:57,145 DEV : loss 0.11281140893697739 - score 0.9777
Epoch    38: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 15:27:57,207 BAD EPOCHS (no improvement): 4
2021-06-22 15:27:57,207 ----------------------------------------------------------------------------------------------------
2021-06-22 15:28:09,642 epoch 39 - iter 25/254 - loss 0.07420877 - samples/sec: 64.34 - lr: 0.000004
2021-06-22 15:28:22,079 epoch 39 - iter 50/254 - loss 0.06662294 - samples/sec: 64.33 - lr: 0.000004
2021-06-22 15:28:34,552 epoch 39 - iter 75/254 - loss 0.06654739 - samples/sec: 64.14 - lr: 0.000004
2021-06-22 15:28:46,918 epoch 39 - iter 100/254 - loss 0.06732417 - samples/sec: 64.70 - lr: 0.000004
2021-06-22 15:28:59,369 epoch 39 - iter 125/254 - loss 0.06246177 - samples/sec: 64.26 - lr: 0.000004
2021-06-22 15:29:11,818 epoch 39 - iter 150/254 - loss 0.06369662 - samples/sec: 64.27 - lr: 0.000004
2021-06-22 15:29:24,157 epoch 39 - iter 175/254 - loss 0.06112635 - samples/sec: 64.84 - lr: 0.000004
2021-06-22 15:29:36,604 epoch 39 - iter 200/254 - loss 0.06023366 - samples/sec: 64.28 - lr: 0.000004
2021-06-22 15:29:49,055 epoch 39 - iter 225/254 - loss 0.06241130 - samples/sec: 64.26 - lr: 0.000004
2021-06-22 15:30:01,490 epoch 39 - iter 250/254 - loss 0.06448096 - samples/sec: 64.34 - lr: 0.000004
2021-06-22 15:30:03,092 ----------------------------------------------------------------------------------------------------
2021-06-22 15:30:03,092 EPOCH 39 done: loss 0.0640 - lr 0.0000038
2021-06-22 15:30:07,466 DEV : loss 0.11010400205850601 - score 0.9798
2021-06-22 15:30:07,529 BAD EPOCHS (no improvement): 1
2021-06-22 15:30:07,530 ----------------------------------------------------------------------------------------------------
2021-06-22 15:30:19,983 epoch 40 - iter 25/254 - loss 0.06181635 - samples/sec: 64.25 - lr: 0.000004
2021-06-22 15:30:32,415 epoch 40 - iter 50/254 - loss 0.06552020 - samples/sec: 64.35 - lr: 0.000004
2021-06-22 15:30:44,805 epoch 40 - iter 75/254 - loss 0.06634927 - samples/sec: 64.58 - lr: 0.000004
2021-06-22 15:30:57,143 epoch 40 - iter 100/254 - loss 0.07056553 - samples/sec: 64.85 - lr: 0.000004
2021-06-22 15:31:09,589 epoch 40 - iter 125/254 - loss 0.07025045 - samples/sec: 64.29 - lr: 0.000004
2021-06-22 15:31:22,038 epoch 40 - iter 150/254 - loss 0.06640382 - samples/sec: 64.27 - lr: 0.000004
2021-06-22 15:31:34,450 epoch 40 - iter 175/254 - loss 0.06779570 - samples/sec: 64.46 - lr: 0.000004
2021-06-22 15:31:46,940 epoch 40 - iter 200/254 - loss 0.06675896 - samples/sec: 64.06 - lr: 0.000004
2021-06-22 15:31:59,347 epoch 40 - iter 225/254 - loss 0.06662648 - samples/sec: 64.49 - lr: 0.000004
2021-06-22 15:32:11,832 epoch 40 - iter 250/254 - loss 0.06556547 - samples/sec: 64.09 - lr: 0.000004
2021-06-22 15:32:13,427 ----------------------------------------------------------------------------------------------------
2021-06-22 15:32:13,427 EPOCH 40 done: loss 0.0653 - lr 0.0000038
2021-06-22 15:32:18,371 DEV : loss 0.10956572741270065 - score 0.979
2021-06-22 15:32:18,434 BAD EPOCHS (no improvement): 2
2021-06-22 15:32:19,620 ----------------------------------------------------------------------------------------------------
2021-06-22 15:32:19,620 Testing using best model ...
2021-06-22 15:32:19,620 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/best-model.pt
2021-06-22 15:32:46,925 0.9608	0.9752	0.9679
2021-06-22 15:32:46,925 
Results:
- F1-score (micro) 0.9679
- F1-score (macro) 0.9679

By class:
SENT       tp: 906 - fp: 37 - fn: 23 - precision: 0.9608 - recall: 0.9752 - f1-score: 0.9679
2021-06-22 15:32:46,925 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/
2021-06-22 15:32:46,937 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc
2021-06-22 15:32:46,938 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/sent_train.txt
2021-06-22 15:32:46,940 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/sent_dev.txt
2021-06-22 15:32:46,940 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/sent_test.txt
Corpus: 1343 train + 158 dev + 161 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 15:33:04,425 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:04,427 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 15:33:04,427 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:04,427 Corpus: "Corpus: 1343 train + 158 dev + 161 test sentences"
2021-06-22 15:33:04,427 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:04,427 Parameters:
2021-06-22 15:33:04,427  - learning_rate: "3e-05"
2021-06-22 15:33:04,427  - mini_batch_size: "32"
2021-06-22 15:33:04,427  - patience: "3"
2021-06-22 15:33:04,427  - anneal_factor: "0.5"
2021-06-22 15:33:04,427  - max_epochs: "40"
2021-06-22 15:33:04,427  - shuffle: "True"
2021-06-22 15:33:04,427  - train_with_dev: "False"
2021-06-22 15:33:04,428  - batch_growth_annealing: "False"
2021-06-22 15:33:04,428 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:04,428 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc"
2021-06-22 15:33:04,428 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:04,428 Device: cuda:0
2021-06-22 15:33:04,428 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:04,428 Embeddings storage mode: cpu
2021-06-22 15:33:04,429 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:08,241 epoch 1 - iter 4/42 - loss 24.25926352 - samples/sec: 33.58 - lr: 0.000030
2021-06-22 15:33:12,086 epoch 1 - iter 8/42 - loss 18.57732904 - samples/sec: 33.29 - lr: 0.000030
2021-06-22 15:33:15,945 epoch 1 - iter 12/42 - loss 15.05219491 - samples/sec: 33.18 - lr: 0.000030
2021-06-22 15:33:19,804 epoch 1 - iter 16/42 - loss 12.95313188 - samples/sec: 33.17 - lr: 0.000030
2021-06-22 15:33:23,666 epoch 1 - iter 20/42 - loss 11.57789407 - samples/sec: 33.14 - lr: 0.000030
2021-06-22 15:33:27,506 epoch 1 - iter 24/42 - loss 10.50072179 - samples/sec: 33.34 - lr: 0.000030
2021-06-22 15:33:31,342 epoch 1 - iter 28/42 - loss 9.68798797 - samples/sec: 33.37 - lr: 0.000030
2021-06-22 15:33:35,206 epoch 1 - iter 32/42 - loss 9.01614662 - samples/sec: 33.13 - lr: 0.000030
2021-06-22 15:33:39,073 epoch 1 - iter 36/42 - loss 8.43140499 - samples/sec: 33.10 - lr: 0.000030
2021-06-22 15:33:42,936 epoch 1 - iter 40/42 - loss 7.91111692 - samples/sec: 33.15 - lr: 0.000030
2021-06-22 15:33:44,836 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:44,836 EPOCH 1 done: loss 7.6844 - lr 0.0000300
2021-06-22 15:33:47,567 DEV : loss 2.563889265060425 - score 0.0379
2021-06-22 15:33:47,578 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:33:48,002 ----------------------------------------------------------------------------------------------------
2021-06-22 15:33:49,957 epoch 2 - iter 4/42 - loss 3.12519228 - samples/sec: 65.50 - lr: 0.000030
2021-06-22 15:33:51,880 epoch 2 - iter 8/42 - loss 2.85694620 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 15:33:53,834 epoch 2 - iter 12/42 - loss 2.71947751 - samples/sec: 65.53 - lr: 0.000030
2021-06-22 15:33:55,788 epoch 2 - iter 16/42 - loss 2.58277563 - samples/sec: 65.51 - lr: 0.000030
2021-06-22 15:33:57,737 epoch 2 - iter 20/42 - loss 2.46754029 - samples/sec: 65.71 - lr: 0.000030
2021-06-22 15:33:59,649 epoch 2 - iter 24/42 - loss 2.32267105 - samples/sec: 66.98 - lr: 0.000030
2021-06-22 15:34:01,641 epoch 2 - iter 28/42 - loss 2.23237606 - samples/sec: 64.25 - lr: 0.000030
2021-06-22 15:34:03,612 epoch 2 - iter 32/42 - loss 2.16055811 - samples/sec: 64.96 - lr: 0.000030
2021-06-22 15:34:05,561 epoch 2 - iter 36/42 - loss 2.06939718 - samples/sec: 65.69 - lr: 0.000030
2021-06-22 15:34:07,533 epoch 2 - iter 40/42 - loss 1.99418831 - samples/sec: 64.95 - lr: 0.000030
2021-06-22 15:34:08,497 ----------------------------------------------------------------------------------------------------
2021-06-22 15:34:08,498 EPOCH 2 done: loss 1.9558 - lr 0.0000300
2021-06-22 15:34:09,311 DEV : loss 0.7884694933891296 - score 0.89
2021-06-22 15:34:09,323 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:34:12,114 ----------------------------------------------------------------------------------------------------
2021-06-22 15:34:14,095 epoch 3 - iter 4/42 - loss 1.13877371 - samples/sec: 64.66 - lr: 0.000030
2021-06-22 15:34:16,073 epoch 3 - iter 8/42 - loss 1.20708482 - samples/sec: 64.71 - lr: 0.000030
2021-06-22 15:34:17,999 epoch 3 - iter 12/42 - loss 1.13618812 - samples/sec: 66.50 - lr: 0.000030
2021-06-22 15:34:19,942 epoch 3 - iter 16/42 - loss 1.14921692 - samples/sec: 65.90 - lr: 0.000030
2021-06-22 15:34:21,886 epoch 3 - iter 20/42 - loss 1.11145904 - samples/sec: 65.86 - lr: 0.000030
2021-06-22 15:34:23,845 epoch 3 - iter 24/42 - loss 1.07338274 - samples/sec: 65.36 - lr: 0.000030
2021-06-22 15:34:25,813 epoch 3 - iter 28/42 - loss 1.05152147 - samples/sec: 65.06 - lr: 0.000030
2021-06-22 15:34:27,798 epoch 3 - iter 32/42 - loss 1.03704954 - samples/sec: 64.49 - lr: 0.000030
2021-06-22 15:34:29,755 epoch 3 - iter 36/42 - loss 1.02107075 - samples/sec: 65.44 - lr: 0.000030
2021-06-22 15:34:31,692 epoch 3 - iter 40/42 - loss 0.99695126 - samples/sec: 66.10 - lr: 0.000030
2021-06-22 15:34:32,648 ----------------------------------------------------------------------------------------------------
2021-06-22 15:34:32,649 EPOCH 3 done: loss 0.9943 - lr 0.0000300
2021-06-22 15:34:33,459 DEV : loss 0.5656822919845581 - score 0.9359
2021-06-22 15:34:33,470 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:34:36,292 ----------------------------------------------------------------------------------------------------
2021-06-22 15:34:40,253 epoch 4 - iter 4/42 - loss 0.78323767 - samples/sec: 32.32 - lr: 0.000030
2021-06-22 15:34:42,154 epoch 4 - iter 8/42 - loss 0.85600215 - samples/sec: 67.37 - lr: 0.000030
2021-06-22 15:34:44,135 epoch 4 - iter 12/42 - loss 0.88038788 - samples/sec: 64.63 - lr: 0.000030
2021-06-22 15:34:46,104 epoch 4 - iter 16/42 - loss 0.87514491 - samples/sec: 65.01 - lr: 0.000030
2021-06-22 15:34:48,086 epoch 4 - iter 20/42 - loss 0.86002831 - samples/sec: 64.62 - lr: 0.000030
2021-06-22 15:34:50,012 epoch 4 - iter 24/42 - loss 0.83875491 - samples/sec: 66.47 - lr: 0.000030
2021-06-22 15:34:51,974 epoch 4 - iter 28/42 - loss 0.83360965 - samples/sec: 65.28 - lr: 0.000030
2021-06-22 15:34:53,893 epoch 4 - iter 32/42 - loss 0.84876011 - samples/sec: 66.71 - lr: 0.000030
2021-06-22 15:34:55,853 epoch 4 - iter 36/42 - loss 0.83407035 - samples/sec: 65.32 - lr: 0.000030
2021-06-22 15:34:57,785 epoch 4 - iter 40/42 - loss 0.81713816 - samples/sec: 66.27 - lr: 0.000030
2021-06-22 15:34:58,748 ----------------------------------------------------------------------------------------------------
2021-06-22 15:34:58,748 EPOCH 4 done: loss 0.8044 - lr 0.0000300
2021-06-22 15:34:59,561 DEV : loss 0.4853294789791107 - score 0.942
2021-06-22 15:34:59,572 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:35:02,463 ----------------------------------------------------------------------------------------------------
2021-06-22 15:35:04,445 epoch 5 - iter 4/42 - loss 0.65520719 - samples/sec: 64.61 - lr: 0.000030
2021-06-22 15:35:06,397 epoch 5 - iter 8/42 - loss 0.70479873 - samples/sec: 65.59 - lr: 0.000030
2021-06-22 15:35:08,318 epoch 5 - iter 12/42 - loss 0.74423063 - samples/sec: 66.67 - lr: 0.000030
2021-06-22 15:35:10,240 epoch 5 - iter 16/42 - loss 0.74419747 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 15:35:12,194 epoch 5 - iter 20/42 - loss 0.75726352 - samples/sec: 65.53 - lr: 0.000030
2021-06-22 15:35:14,119 epoch 5 - iter 24/42 - loss 0.74734963 - samples/sec: 66.52 - lr: 0.000030
2021-06-22 15:35:16,089 epoch 5 - iter 28/42 - loss 0.71640106 - samples/sec: 64.99 - lr: 0.000030
2021-06-22 15:35:18,040 epoch 5 - iter 32/42 - loss 0.70596164 - samples/sec: 65.64 - lr: 0.000030
2021-06-22 15:35:19,965 epoch 5 - iter 36/42 - loss 0.71332978 - samples/sec: 66.52 - lr: 0.000030
2021-06-22 15:35:21,926 epoch 5 - iter 40/42 - loss 0.71792799 - samples/sec: 65.27 - lr: 0.000030
2021-06-22 15:35:22,875 ----------------------------------------------------------------------------------------------------
2021-06-22 15:35:22,875 EPOCH 5 done: loss 0.7033 - lr 0.0000300
2021-06-22 15:35:23,688 DEV : loss 0.5300959348678589 - score 0.9461
2021-06-22 15:35:23,699 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:35:26,577 ----------------------------------------------------------------------------------------------------
2021-06-22 15:35:28,517 epoch 6 - iter 4/42 - loss 0.59888137 - samples/sec: 66.02 - lr: 0.000030
2021-06-22 15:35:30,474 epoch 6 - iter 8/42 - loss 0.62223244 - samples/sec: 65.41 - lr: 0.000030
2021-06-22 15:35:32,413 epoch 6 - iter 12/42 - loss 0.65126998 - samples/sec: 66.04 - lr: 0.000030
2021-06-22 15:35:34,383 epoch 6 - iter 16/42 - loss 0.64096863 - samples/sec: 64.98 - lr: 0.000030
2021-06-22 15:35:36,322 epoch 6 - iter 20/42 - loss 0.65242948 - samples/sec: 66.03 - lr: 0.000030
2021-06-22 15:35:38,247 epoch 6 - iter 24/42 - loss 0.70889073 - samples/sec: 66.55 - lr: 0.000030
2021-06-22 15:35:40,182 epoch 6 - iter 28/42 - loss 0.69140289 - samples/sec: 66.16 - lr: 0.000030
2021-06-22 15:35:42,162 epoch 6 - iter 32/42 - loss 0.67798636 - samples/sec: 64.67 - lr: 0.000030
2021-06-22 15:35:44,093 epoch 6 - iter 36/42 - loss 0.67099523 - samples/sec: 66.28 - lr: 0.000030
2021-06-22 15:35:46,057 epoch 6 - iter 40/42 - loss 0.66168551 - samples/sec: 65.20 - lr: 0.000030
2021-06-22 15:35:46,998 ----------------------------------------------------------------------------------------------------
2021-06-22 15:35:46,999 EPOCH 6 done: loss 0.6539 - lr 0.0000300
2021-06-22 15:35:47,813 DEV : loss 0.45525437593460083 - score 0.9501
2021-06-22 15:35:47,825 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:35:50,819 ----------------------------------------------------------------------------------------------------
2021-06-22 15:35:52,758 epoch 7 - iter 4/42 - loss 0.64294030 - samples/sec: 66.06 - lr: 0.000030
2021-06-22 15:35:54,692 epoch 7 - iter 8/42 - loss 0.59778024 - samples/sec: 66.20 - lr: 0.000030
2021-06-22 15:35:56,645 epoch 7 - iter 12/42 - loss 0.59486047 - samples/sec: 65.56 - lr: 0.000030
2021-06-22 15:35:58,632 epoch 7 - iter 16/42 - loss 0.61793623 - samples/sec: 64.43 - lr: 0.000030
2021-06-22 15:36:00,579 epoch 7 - iter 20/42 - loss 0.60530546 - samples/sec: 65.78 - lr: 0.000030
2021-06-22 15:36:02,478 epoch 7 - iter 24/42 - loss 0.60384395 - samples/sec: 67.42 - lr: 0.000030
2021-06-22 15:36:04,427 epoch 7 - iter 28/42 - loss 0.62075940 - samples/sec: 65.69 - lr: 0.000030
2021-06-22 15:36:06,380 epoch 7 - iter 32/42 - loss 0.62891575 - samples/sec: 65.57 - lr: 0.000030
2021-06-22 15:36:08,320 epoch 7 - iter 36/42 - loss 0.62665740 - samples/sec: 65.97 - lr: 0.000030
2021-06-22 15:36:10,282 epoch 7 - iter 40/42 - loss 0.61992767 - samples/sec: 65.27 - lr: 0.000030
2021-06-22 15:36:11,251 ----------------------------------------------------------------------------------------------------
2021-06-22 15:36:11,251 EPOCH 7 done: loss 0.6167 - lr 0.0000300
2021-06-22 15:36:12,065 DEV : loss 0.43159767985343933 - score 0.9522
2021-06-22 15:36:12,077 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:36:14,979 ----------------------------------------------------------------------------------------------------
2021-06-22 15:36:16,933 epoch 8 - iter 4/42 - loss 0.66155360 - samples/sec: 65.55 - lr: 0.000030
2021-06-22 15:36:18,877 epoch 8 - iter 8/42 - loss 0.62021002 - samples/sec: 65.87 - lr: 0.000030
2021-06-22 15:36:20,798 epoch 8 - iter 12/42 - loss 0.59795869 - samples/sec: 66.67 - lr: 0.000030
2021-06-22 15:36:22,736 epoch 8 - iter 16/42 - loss 0.56447367 - samples/sec: 66.05 - lr: 0.000030
2021-06-22 15:36:24,670 epoch 8 - iter 20/42 - loss 0.56949087 - samples/sec: 66.20 - lr: 0.000030
2021-06-22 15:36:26,639 epoch 8 - iter 24/42 - loss 0.56258761 - samples/sec: 65.04 - lr: 0.000030
2021-06-22 15:36:28,559 epoch 8 - iter 28/42 - loss 0.56684974 - samples/sec: 66.69 - lr: 0.000030
2021-06-22 15:36:30,509 epoch 8 - iter 32/42 - loss 0.57393257 - samples/sec: 65.67 - lr: 0.000030
2021-06-22 15:36:32,478 epoch 8 - iter 36/42 - loss 0.55993728 - samples/sec: 65.01 - lr: 0.000030
2021-06-22 15:36:34,449 epoch 8 - iter 40/42 - loss 0.55660405 - samples/sec: 64.95 - lr: 0.000030
2021-06-22 15:36:35,420 ----------------------------------------------------------------------------------------------------
2021-06-22 15:36:35,421 EPOCH 8 done: loss 0.5527 - lr 0.0000300
2021-06-22 15:36:36,234 DEV : loss 0.426422655582428 - score 0.9501
2021-06-22 15:36:36,246 BAD EPOCHS (no improvement): 1
2021-06-22 15:36:36,246 ----------------------------------------------------------------------------------------------------
2021-06-22 15:36:38,189 epoch 9 - iter 4/42 - loss 0.72673084 - samples/sec: 65.89 - lr: 0.000030
2021-06-22 15:36:40,103 epoch 9 - iter 8/42 - loss 0.61183890 - samples/sec: 66.89 - lr: 0.000030
2021-06-22 15:36:42,155 epoch 9 - iter 12/42 - loss 0.53655492 - samples/sec: 62.41 - lr: 0.000030
2021-06-22 15:36:44,147 epoch 9 - iter 16/42 - loss 0.53202617 - samples/sec: 64.28 - lr: 0.000030
2021-06-22 15:36:46,111 epoch 9 - iter 20/42 - loss 0.51674235 - samples/sec: 65.18 - lr: 0.000030
2021-06-22 15:36:48,039 epoch 9 - iter 24/42 - loss 0.49087247 - samples/sec: 66.41 - lr: 0.000030
2021-06-22 15:36:49,986 epoch 9 - iter 28/42 - loss 0.48908855 - samples/sec: 65.76 - lr: 0.000030
2021-06-22 15:36:51,938 epoch 9 - iter 32/42 - loss 0.47793315 - samples/sec: 65.61 - lr: 0.000030
2021-06-22 15:36:53,902 epoch 9 - iter 36/42 - loss 0.48022242 - samples/sec: 65.18 - lr: 0.000030
2021-06-22 15:36:55,867 epoch 9 - iter 40/42 - loss 0.46355386 - samples/sec: 65.15 - lr: 0.000030
2021-06-22 15:36:56,837 ----------------------------------------------------------------------------------------------------
2021-06-22 15:36:56,837 EPOCH 9 done: loss 0.4737 - lr 0.0000300
2021-06-22 15:36:57,650 DEV : loss 0.4210248589515686 - score 0.9451
2021-06-22 15:36:57,661 BAD EPOCHS (no improvement): 2
2021-06-22 15:36:57,661 ----------------------------------------------------------------------------------------------------
2021-06-22 15:36:59,620 epoch 10 - iter 4/42 - loss 0.51869302 - samples/sec: 65.35 - lr: 0.000030
2021-06-22 15:37:01,592 epoch 10 - iter 8/42 - loss 0.48368942 - samples/sec: 64.94 - lr: 0.000030
2021-06-22 15:37:03,513 epoch 10 - iter 12/42 - loss 0.47447692 - samples/sec: 66.67 - lr: 0.000030
2021-06-22 15:37:05,436 epoch 10 - iter 16/42 - loss 0.46173704 - samples/sec: 66.59 - lr: 0.000030
2021-06-22 15:37:07,404 epoch 10 - iter 20/42 - loss 0.45830942 - samples/sec: 65.05 - lr: 0.000030
2021-06-22 15:37:09,352 epoch 10 - iter 24/42 - loss 0.47210389 - samples/sec: 65.73 - lr: 0.000030
2021-06-22 15:37:11,273 epoch 10 - iter 28/42 - loss 0.45641961 - samples/sec: 66.65 - lr: 0.000030
2021-06-22 15:37:13,248 epoch 10 - iter 32/42 - loss 0.44114214 - samples/sec: 64.84 - lr: 0.000030
2021-06-22 15:37:15,205 epoch 10 - iter 36/42 - loss 0.44333856 - samples/sec: 65.42 - lr: 0.000030
2021-06-22 15:37:17,127 epoch 10 - iter 40/42 - loss 0.45487136 - samples/sec: 66.60 - lr: 0.000030
2021-06-22 15:37:18,095 ----------------------------------------------------------------------------------------------------
2021-06-22 15:37:18,095 EPOCH 10 done: loss 0.4597 - lr 0.0000300
2021-06-22 15:37:18,908 DEV : loss 0.420717716217041 - score 0.9479
2021-06-22 15:37:18,919 BAD EPOCHS (no improvement): 3
2021-06-22 15:37:18,920 ----------------------------------------------------------------------------------------------------
2021-06-22 15:37:20,835 epoch 11 - iter 4/42 - loss 0.50636810 - samples/sec: 66.85 - lr: 0.000030
2021-06-22 15:37:22,780 epoch 11 - iter 8/42 - loss 0.49393054 - samples/sec: 65.81 - lr: 0.000030
2021-06-22 15:37:24,708 epoch 11 - iter 12/42 - loss 0.53480556 - samples/sec: 66.42 - lr: 0.000030
2021-06-22 15:37:26,672 epoch 11 - iter 16/42 - loss 0.55412729 - samples/sec: 65.20 - lr: 0.000030
2021-06-22 15:37:28,600 epoch 11 - iter 20/42 - loss 0.50825386 - samples/sec: 66.40 - lr: 0.000030
2021-06-22 15:37:30,577 epoch 11 - iter 24/42 - loss 0.48185267 - samples/sec: 64.77 - lr: 0.000030
2021-06-22 15:37:32,520 epoch 11 - iter 28/42 - loss 0.47395906 - samples/sec: 65.90 - lr: 0.000030
2021-06-22 15:37:34,474 epoch 11 - iter 32/42 - loss 0.47082140 - samples/sec: 65.54 - lr: 0.000030
2021-06-22 15:37:36,459 epoch 11 - iter 36/42 - loss 0.48721872 - samples/sec: 64.48 - lr: 0.000030
2021-06-22 15:37:38,404 epoch 11 - iter 40/42 - loss 0.46800266 - samples/sec: 65.84 - lr: 0.000030
2021-06-22 15:37:39,380 ----------------------------------------------------------------------------------------------------
2021-06-22 15:37:39,380 EPOCH 11 done: loss 0.4717 - lr 0.0000300
2021-06-22 15:37:40,195 DEV : loss 0.40481749176979065 - score 0.9499
Epoch    11: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 15:37:40,206 BAD EPOCHS (no improvement): 4
2021-06-22 15:37:40,207 ----------------------------------------------------------------------------------------------------
2021-06-22 15:37:42,167 epoch 12 - iter 4/42 - loss 0.50885881 - samples/sec: 65.31 - lr: 0.000015
2021-06-22 15:37:44,089 epoch 12 - iter 8/42 - loss 0.40623065 - samples/sec: 66.63 - lr: 0.000015
2021-06-22 15:37:46,046 epoch 12 - iter 12/42 - loss 0.44765738 - samples/sec: 65.42 - lr: 0.000015
2021-06-22 15:37:48,031 epoch 12 - iter 16/42 - loss 0.48991814 - samples/sec: 64.49 - lr: 0.000015
2021-06-22 15:37:49,968 epoch 12 - iter 20/42 - loss 0.47736627 - samples/sec: 66.10 - lr: 0.000015
2021-06-22 15:37:51,944 epoch 12 - iter 24/42 - loss 0.46016584 - samples/sec: 64.81 - lr: 0.000015
2021-06-22 15:37:53,836 epoch 12 - iter 28/42 - loss 0.45274409 - samples/sec: 67.68 - lr: 0.000015
2021-06-22 15:37:55,813 epoch 12 - iter 32/42 - loss 0.43865938 - samples/sec: 64.77 - lr: 0.000015
2021-06-22 15:37:57,755 epoch 12 - iter 36/42 - loss 0.43801252 - samples/sec: 65.91 - lr: 0.000015
2021-06-22 15:37:59,723 epoch 12 - iter 40/42 - loss 0.44809772 - samples/sec: 65.09 - lr: 0.000015
2021-06-22 15:38:00,675 ----------------------------------------------------------------------------------------------------
2021-06-22 15:38:00,676 EPOCH 12 done: loss 0.4487 - lr 0.0000150
2021-06-22 15:38:01,491 DEV : loss 0.40558239817619324 - score 0.9528
2021-06-22 15:38:01,502 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:38:04,548 ----------------------------------------------------------------------------------------------------
2021-06-22 15:38:06,507 epoch 13 - iter 4/42 - loss 0.38763549 - samples/sec: 65.37 - lr: 0.000015
2021-06-22 15:38:08,459 epoch 13 - iter 8/42 - loss 0.41599224 - samples/sec: 65.60 - lr: 0.000015
2021-06-22 15:38:10,409 epoch 13 - iter 12/42 - loss 0.40154830 - samples/sec: 65.67 - lr: 0.000015
2021-06-22 15:38:12,348 epoch 13 - iter 16/42 - loss 0.39480182 - samples/sec: 66.03 - lr: 0.000015
2021-06-22 15:38:14,271 epoch 13 - iter 20/42 - loss 0.41087703 - samples/sec: 66.58 - lr: 0.000015
2021-06-22 15:38:16,230 epoch 13 - iter 24/42 - loss 0.39408976 - samples/sec: 65.35 - lr: 0.000015
2021-06-22 15:38:18,189 epoch 13 - iter 28/42 - loss 0.40716128 - samples/sec: 65.36 - lr: 0.000015
2021-06-22 15:38:20,112 epoch 13 - iter 32/42 - loss 0.41547978 - samples/sec: 66.58 - lr: 0.000015
2021-06-22 15:38:22,077 epoch 13 - iter 36/42 - loss 0.41052493 - samples/sec: 65.17 - lr: 0.000015
2021-06-22 15:38:24,026 epoch 13 - iter 40/42 - loss 0.40874566 - samples/sec: 65.71 - lr: 0.000015
2021-06-22 15:38:24,991 ----------------------------------------------------------------------------------------------------
2021-06-22 15:38:24,991 EPOCH 13 done: loss 0.4090 - lr 0.0000150
2021-06-22 15:38:25,803 DEV : loss 0.4035457670688629 - score 0.9501
2021-06-22 15:38:25,815 BAD EPOCHS (no improvement): 1
2021-06-22 15:38:25,815 ----------------------------------------------------------------------------------------------------
2021-06-22 15:38:27,779 epoch 14 - iter 4/42 - loss 0.33607374 - samples/sec: 65.17 - lr: 0.000015
2021-06-22 15:38:29,729 epoch 14 - iter 8/42 - loss 0.35955253 - samples/sec: 65.67 - lr: 0.000015
2021-06-22 15:38:31,674 epoch 14 - iter 12/42 - loss 0.41573917 - samples/sec: 65.84 - lr: 0.000015
2021-06-22 15:38:33,640 epoch 14 - iter 16/42 - loss 0.42743852 - samples/sec: 65.11 - lr: 0.000015
2021-06-22 15:38:35,566 epoch 14 - iter 20/42 - loss 0.42250382 - samples/sec: 66.48 - lr: 0.000015
2021-06-22 15:38:37,479 epoch 14 - iter 24/42 - loss 0.42529099 - samples/sec: 66.95 - lr: 0.000015
2021-06-22 15:38:39,451 epoch 14 - iter 28/42 - loss 0.43234397 - samples/sec: 64.93 - lr: 0.000015
2021-06-22 15:38:41,420 epoch 14 - iter 32/42 - loss 0.43323017 - samples/sec: 65.00 - lr: 0.000015
2021-06-22 15:38:43,348 epoch 14 - iter 36/42 - loss 0.43646234 - samples/sec: 66.41 - lr: 0.000015
2021-06-22 15:38:45,299 epoch 14 - iter 40/42 - loss 0.43240006 - samples/sec: 65.65 - lr: 0.000015
2021-06-22 15:38:46,235 ----------------------------------------------------------------------------------------------------
2021-06-22 15:38:46,235 EPOCH 14 done: loss 0.4318 - lr 0.0000150
2021-06-22 15:38:47,049 DEV : loss 0.40655991435050964 - score 0.9526
2021-06-22 15:38:47,060 BAD EPOCHS (no improvement): 2
2021-06-22 15:38:47,060 ----------------------------------------------------------------------------------------------------
2021-06-22 15:38:49,164 epoch 15 - iter 4/42 - loss 0.35408840 - samples/sec: 60.84 - lr: 0.000015
2021-06-22 15:38:51,097 epoch 15 - iter 8/42 - loss 0.38923126 - samples/sec: 66.24 - lr: 0.000015
2021-06-22 15:38:53,008 epoch 15 - iter 12/42 - loss 0.38310363 - samples/sec: 66.99 - lr: 0.000015
2021-06-22 15:38:54,940 epoch 15 - iter 16/42 - loss 0.37843259 - samples/sec: 66.28 - lr: 0.000015
2021-06-22 15:38:56,928 epoch 15 - iter 20/42 - loss 0.38075839 - samples/sec: 64.42 - lr: 0.000015
2021-06-22 15:38:58,892 epoch 15 - iter 24/42 - loss 0.39047748 - samples/sec: 65.17 - lr: 0.000015
2021-06-22 15:39:00,839 epoch 15 - iter 28/42 - loss 0.39195783 - samples/sec: 65.77 - lr: 0.000015
2021-06-22 15:39:02,751 epoch 15 - iter 32/42 - loss 0.39172861 - samples/sec: 66.96 - lr: 0.000015
2021-06-22 15:39:04,723 epoch 15 - iter 36/42 - loss 0.39124953 - samples/sec: 64.96 - lr: 0.000015
2021-06-22 15:39:06,685 epoch 15 - iter 40/42 - loss 0.38728775 - samples/sec: 65.25 - lr: 0.000015
2021-06-22 15:39:07,645 ----------------------------------------------------------------------------------------------------
2021-06-22 15:39:07,646 EPOCH 15 done: loss 0.3858 - lr 0.0000150
2021-06-22 15:39:08,460 DEV : loss 0.40990790724754333 - score 0.9504
2021-06-22 15:39:08,472 BAD EPOCHS (no improvement): 3
2021-06-22 15:39:08,472 ----------------------------------------------------------------------------------------------------
2021-06-22 15:39:10,376 epoch 16 - iter 4/42 - loss 0.35871618 - samples/sec: 67.22 - lr: 0.000015
2021-06-22 15:39:12,271 epoch 16 - iter 8/42 - loss 0.31848673 - samples/sec: 67.60 - lr: 0.000015
2021-06-22 15:39:14,250 epoch 16 - iter 12/42 - loss 0.31888613 - samples/sec: 64.70 - lr: 0.000015
2021-06-22 15:39:16,200 epoch 16 - iter 16/42 - loss 0.32448219 - samples/sec: 65.65 - lr: 0.000015
2021-06-22 15:39:18,140 epoch 16 - iter 20/42 - loss 0.35388932 - samples/sec: 65.99 - lr: 0.000015
2021-06-22 15:39:20,120 epoch 16 - iter 24/42 - loss 0.34626282 - samples/sec: 64.67 - lr: 0.000015
2021-06-22 15:39:22,076 epoch 16 - iter 28/42 - loss 0.37099348 - samples/sec: 65.47 - lr: 0.000015
2021-06-22 15:39:24,038 epoch 16 - iter 32/42 - loss 0.36992285 - samples/sec: 65.25 - lr: 0.000015
2021-06-22 15:39:26,029 epoch 16 - iter 36/42 - loss 0.37271872 - samples/sec: 64.32 - lr: 0.000015
2021-06-22 15:39:27,985 epoch 16 - iter 40/42 - loss 0.38765257 - samples/sec: 65.43 - lr: 0.000015
2021-06-22 15:39:28,948 ----------------------------------------------------------------------------------------------------
2021-06-22 15:39:28,949 EPOCH 16 done: loss 0.3919 - lr 0.0000150
2021-06-22 15:39:29,762 DEV : loss 0.42000657320022583 - score 0.9506
Epoch    16: reducing learning rate of group 0 to 7.5000e-06.
2021-06-22 15:39:29,773 BAD EPOCHS (no improvement): 4
2021-06-22 15:39:29,773 ----------------------------------------------------------------------------------------------------
2021-06-22 15:39:31,693 epoch 17 - iter 4/42 - loss 0.38301766 - samples/sec: 66.70 - lr: 0.000008
2021-06-22 15:39:33,627 epoch 17 - iter 8/42 - loss 0.34438629 - samples/sec: 66.21 - lr: 0.000008
2021-06-22 15:39:35,580 epoch 17 - iter 12/42 - loss 0.36997484 - samples/sec: 65.56 - lr: 0.000008
2021-06-22 15:39:37,527 epoch 17 - iter 16/42 - loss 0.36484356 - samples/sec: 65.76 - lr: 0.000008
2021-06-22 15:39:39,483 epoch 17 - iter 20/42 - loss 0.38279277 - samples/sec: 65.44 - lr: 0.000008
2021-06-22 15:39:41,427 epoch 17 - iter 24/42 - loss 0.35669943 - samples/sec: 65.89 - lr: 0.000008
2021-06-22 15:39:43,404 epoch 17 - iter 28/42 - loss 0.36531661 - samples/sec: 64.76 - lr: 0.000008
2021-06-22 15:39:45,366 epoch 17 - iter 32/42 - loss 0.36127529 - samples/sec: 65.26 - lr: 0.000008
2021-06-22 15:39:47,309 epoch 17 - iter 36/42 - loss 0.36092471 - samples/sec: 65.89 - lr: 0.000008
2021-06-22 15:39:49,268 epoch 17 - iter 40/42 - loss 0.36018442 - samples/sec: 65.36 - lr: 0.000008
2021-06-22 15:39:50,270 ----------------------------------------------------------------------------------------------------
2021-06-22 15:39:50,270 EPOCH 17 done: loss 0.3623 - lr 0.0000075
2021-06-22 15:39:51,085 DEV : loss 0.40752291679382324 - score 0.9551
2021-06-22 15:39:51,096 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:39:55,696 ----------------------------------------------------------------------------------------------------
2021-06-22 15:39:57,634 epoch 18 - iter 4/42 - loss 0.44358459 - samples/sec: 66.09 - lr: 0.000008
2021-06-22 15:39:59,588 epoch 18 - iter 8/42 - loss 0.41162324 - samples/sec: 65.52 - lr: 0.000008
2021-06-22 15:40:01,544 epoch 18 - iter 12/42 - loss 0.34692194 - samples/sec: 65.46 - lr: 0.000008
2021-06-22 15:40:03,507 epoch 18 - iter 16/42 - loss 0.37789876 - samples/sec: 65.24 - lr: 0.000008
2021-06-22 15:40:05,479 epoch 18 - iter 20/42 - loss 0.37575936 - samples/sec: 64.93 - lr: 0.000008
2021-06-22 15:40:07,428 epoch 18 - iter 24/42 - loss 0.36254685 - samples/sec: 65.70 - lr: 0.000008
2021-06-22 15:40:09,398 epoch 18 - iter 28/42 - loss 0.35561740 - samples/sec: 64.99 - lr: 0.000008
2021-06-22 15:40:11,330 epoch 18 - iter 32/42 - loss 0.36437158 - samples/sec: 66.27 - lr: 0.000008
2021-06-22 15:40:13,299 epoch 18 - iter 36/42 - loss 0.35234395 - samples/sec: 65.04 - lr: 0.000008
2021-06-22 15:40:15,260 epoch 18 - iter 40/42 - loss 0.35149154 - samples/sec: 65.28 - lr: 0.000008
2021-06-22 15:40:16,221 ----------------------------------------------------------------------------------------------------
2021-06-22 15:40:16,221 EPOCH 18 done: loss 0.3497 - lr 0.0000075
2021-06-22 15:40:17,034 DEV : loss 0.40617719292640686 - score 0.9551
2021-06-22 15:40:17,046 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:40:21,685 ----------------------------------------------------------------------------------------------------
2021-06-22 15:40:23,677 epoch 19 - iter 4/42 - loss 0.36338321 - samples/sec: 64.28 - lr: 0.000008
2021-06-22 15:40:25,670 epoch 19 - iter 8/42 - loss 0.38512472 - samples/sec: 64.26 - lr: 0.000008
2021-06-22 15:40:27,648 epoch 19 - iter 12/42 - loss 0.33431274 - samples/sec: 64.75 - lr: 0.000008
2021-06-22 15:40:29,588 epoch 19 - iter 16/42 - loss 0.36044011 - samples/sec: 65.97 - lr: 0.000008
2021-06-22 15:40:31,548 epoch 19 - iter 20/42 - loss 0.36431336 - samples/sec: 65.33 - lr: 0.000008
2021-06-22 15:40:33,472 epoch 19 - iter 24/42 - loss 0.36150322 - samples/sec: 66.56 - lr: 0.000008
2021-06-22 15:40:35,419 epoch 19 - iter 28/42 - loss 0.37170912 - samples/sec: 65.75 - lr: 0.000008
2021-06-22 15:40:37,326 epoch 19 - iter 32/42 - loss 0.35848349 - samples/sec: 67.16 - lr: 0.000008
2021-06-22 15:40:39,250 epoch 19 - iter 36/42 - loss 0.34755336 - samples/sec: 66.52 - lr: 0.000008
2021-06-22 15:40:41,223 epoch 19 - iter 40/42 - loss 0.35423551 - samples/sec: 64.90 - lr: 0.000008
2021-06-22 15:40:42,187 ----------------------------------------------------------------------------------------------------
2021-06-22 15:40:42,188 EPOCH 19 done: loss 0.3498 - lr 0.0000075
2021-06-22 15:40:43,000 DEV : loss 0.4084717333316803 - score 0.9551
2021-06-22 15:40:43,011 BAD EPOCHS (no improvement): 1
2021-06-22 15:40:43,012 ----------------------------------------------------------------------------------------------------
2021-06-22 15:40:45,080 epoch 20 - iter 4/42 - loss 0.45131516 - samples/sec: 61.91 - lr: 0.000008
2021-06-22 15:40:47,001 epoch 20 - iter 8/42 - loss 0.37276752 - samples/sec: 66.63 - lr: 0.000008
2021-06-22 15:40:48,939 epoch 20 - iter 12/42 - loss 0.40183186 - samples/sec: 66.10 - lr: 0.000008
2021-06-22 15:40:50,870 epoch 20 - iter 16/42 - loss 0.36273777 - samples/sec: 66.28 - lr: 0.000008
2021-06-22 15:40:52,841 epoch 20 - iter 20/42 - loss 0.36569624 - samples/sec: 64.97 - lr: 0.000008
2021-06-22 15:40:54,798 epoch 20 - iter 24/42 - loss 0.36100363 - samples/sec: 65.43 - lr: 0.000008
2021-06-22 15:40:56,731 epoch 20 - iter 28/42 - loss 0.36843427 - samples/sec: 66.23 - lr: 0.000008
2021-06-22 15:40:58,685 epoch 20 - iter 32/42 - loss 0.37039170 - samples/sec: 65.55 - lr: 0.000008
2021-06-22 15:41:00,641 epoch 20 - iter 36/42 - loss 0.36346886 - samples/sec: 65.45 - lr: 0.000008
2021-06-22 15:41:02,624 epoch 20 - iter 40/42 - loss 0.35944802 - samples/sec: 64.57 - lr: 0.000008
2021-06-22 15:41:03,605 ----------------------------------------------------------------------------------------------------
2021-06-22 15:41:03,605 EPOCH 20 done: loss 0.3598 - lr 0.0000075
2021-06-22 15:41:04,419 DEV : loss 0.4096738398075104 - score 0.9551
2021-06-22 15:41:04,430 BAD EPOCHS (no improvement): 2
2021-06-22 15:41:04,431 ----------------------------------------------------------------------------------------------------
2021-06-22 15:41:06,364 epoch 21 - iter 4/42 - loss 0.29705577 - samples/sec: 66.21 - lr: 0.000008
2021-06-22 15:41:08,357 epoch 21 - iter 8/42 - loss 0.35384510 - samples/sec: 64.26 - lr: 0.000008
2021-06-22 15:41:10,315 epoch 21 - iter 12/42 - loss 0.35606635 - samples/sec: 65.37 - lr: 0.000008
2021-06-22 15:41:12,208 epoch 21 - iter 16/42 - loss 0.33880591 - samples/sec: 67.67 - lr: 0.000008
2021-06-22 15:41:14,182 epoch 21 - iter 20/42 - loss 0.35274676 - samples/sec: 64.85 - lr: 0.000008
2021-06-22 15:41:16,178 epoch 21 - iter 24/42 - loss 0.35013328 - samples/sec: 64.14 - lr: 0.000008
2021-06-22 15:41:18,106 epoch 21 - iter 28/42 - loss 0.34242785 - samples/sec: 66.43 - lr: 0.000008
2021-06-22 15:41:20,029 epoch 21 - iter 32/42 - loss 0.35136337 - samples/sec: 66.56 - lr: 0.000008
2021-06-22 15:41:21,974 epoch 21 - iter 36/42 - loss 0.35081523 - samples/sec: 65.86 - lr: 0.000008
2021-06-22 15:41:23,946 epoch 21 - iter 40/42 - loss 0.34550011 - samples/sec: 64.91 - lr: 0.000008
2021-06-22 15:41:24,905 ----------------------------------------------------------------------------------------------------
2021-06-22 15:41:24,905 EPOCH 21 done: loss 0.3396 - lr 0.0000075
2021-06-22 15:41:25,720 DEV : loss 0.4067978858947754 - score 0.9551
2021-06-22 15:41:25,732 BAD EPOCHS (no improvement): 3
2021-06-22 15:41:25,732 ----------------------------------------------------------------------------------------------------
2021-06-22 15:41:27,709 epoch 22 - iter 4/42 - loss 0.27148379 - samples/sec: 64.77 - lr: 0.000008
2021-06-22 15:41:29,670 epoch 22 - iter 8/42 - loss 0.26548416 - samples/sec: 65.29 - lr: 0.000008
2021-06-22 15:41:31,598 epoch 22 - iter 12/42 - loss 0.28946833 - samples/sec: 66.39 - lr: 0.000008
2021-06-22 15:41:33,549 epoch 22 - iter 16/42 - loss 0.34258933 - samples/sec: 65.64 - lr: 0.000008
2021-06-22 15:41:35,470 epoch 22 - iter 20/42 - loss 0.32307106 - samples/sec: 66.66 - lr: 0.000008
2021-06-22 15:41:37,437 epoch 22 - iter 24/42 - loss 0.32876312 - samples/sec: 65.08 - lr: 0.000008
2021-06-22 15:41:39,389 epoch 22 - iter 28/42 - loss 0.31699700 - samples/sec: 65.59 - lr: 0.000008
2021-06-22 15:41:41,366 epoch 22 - iter 32/42 - loss 0.31756040 - samples/sec: 64.77 - lr: 0.000008
2021-06-22 15:41:43,298 epoch 22 - iter 36/42 - loss 0.30916846 - samples/sec: 66.27 - lr: 0.000008
2021-06-22 15:41:45,250 epoch 22 - iter 40/42 - loss 0.31631279 - samples/sec: 65.59 - lr: 0.000008
2021-06-22 15:41:46,221 ----------------------------------------------------------------------------------------------------
2021-06-22 15:41:46,221 EPOCH 22 done: loss 0.3210 - lr 0.0000075
2021-06-22 15:41:47,035 DEV : loss 0.40991631150245667 - score 0.9528
Epoch    22: reducing learning rate of group 0 to 3.7500e-06.
2021-06-22 15:41:47,046 BAD EPOCHS (no improvement): 4
2021-06-22 15:41:47,046 ----------------------------------------------------------------------------------------------------
2021-06-22 15:41:48,989 epoch 23 - iter 4/42 - loss 0.27974328 - samples/sec: 65.89 - lr: 0.000004
2021-06-22 15:41:50,965 epoch 23 - iter 8/42 - loss 0.29517704 - samples/sec: 64.82 - lr: 0.000004
2021-06-22 15:41:52,927 epoch 23 - iter 12/42 - loss 0.31570104 - samples/sec: 65.26 - lr: 0.000004
2021-06-22 15:41:54,868 epoch 23 - iter 16/42 - loss 0.32117601 - samples/sec: 65.94 - lr: 0.000004
2021-06-22 15:41:56,810 epoch 23 - iter 20/42 - loss 0.30936301 - samples/sec: 65.93 - lr: 0.000004
2021-06-22 15:41:58,710 epoch 23 - iter 24/42 - loss 0.30022323 - samples/sec: 67.40 - lr: 0.000004
2021-06-22 15:42:00,673 epoch 23 - iter 28/42 - loss 0.32979617 - samples/sec: 65.23 - lr: 0.000004
2021-06-22 15:42:02,593 epoch 23 - iter 32/42 - loss 0.31448266 - samples/sec: 66.69 - lr: 0.000004
2021-06-22 15:42:04,569 epoch 23 - iter 36/42 - loss 0.32303911 - samples/sec: 64.80 - lr: 0.000004
2021-06-22 15:42:06,550 epoch 23 - iter 40/42 - loss 0.32676008 - samples/sec: 64.66 - lr: 0.000004
2021-06-22 15:42:07,534 ----------------------------------------------------------------------------------------------------
2021-06-22 15:42:07,534 EPOCH 23 done: loss 0.3238 - lr 0.0000038
2021-06-22 15:42:08,349 DEV : loss 0.40602388978004456 - score 0.9528
2021-06-22 15:42:08,360 BAD EPOCHS (no improvement): 1
2021-06-22 15:42:08,361 ----------------------------------------------------------------------------------------------------
2021-06-22 15:42:10,306 epoch 24 - iter 4/42 - loss 0.29814526 - samples/sec: 65.84 - lr: 0.000004
2021-06-22 15:42:12,266 epoch 24 - iter 8/42 - loss 0.32468934 - samples/sec: 65.31 - lr: 0.000004
2021-06-22 15:42:14,182 epoch 24 - iter 12/42 - loss 0.32423730 - samples/sec: 66.84 - lr: 0.000004
2021-06-22 15:42:16,160 epoch 24 - iter 16/42 - loss 0.32738706 - samples/sec: 64.73 - lr: 0.000004
2021-06-22 15:42:18,135 epoch 24 - iter 20/42 - loss 0.32034359 - samples/sec: 64.82 - lr: 0.000004
2021-06-22 15:42:20,081 epoch 24 - iter 24/42 - loss 0.32235012 - samples/sec: 65.82 - lr: 0.000004
2021-06-22 15:42:22,013 epoch 24 - iter 28/42 - loss 0.31673148 - samples/sec: 66.25 - lr: 0.000004
2021-06-22 15:42:23,967 epoch 24 - iter 32/42 - loss 0.31205062 - samples/sec: 65.55 - lr: 0.000004
2021-06-22 15:42:25,926 epoch 24 - iter 36/42 - loss 0.31652982 - samples/sec: 65.36 - lr: 0.000004
2021-06-22 15:42:27,889 epoch 24 - iter 40/42 - loss 0.32713201 - samples/sec: 65.20 - lr: 0.000004
2021-06-22 15:42:28,865 ----------------------------------------------------------------------------------------------------
2021-06-22 15:42:28,865 EPOCH 24 done: loss 0.3329 - lr 0.0000038
2021-06-22 15:42:29,811 DEV : loss 0.40489229559898376 - score 0.9528
2021-06-22 15:42:29,822 BAD EPOCHS (no improvement): 2
2021-06-22 15:42:29,822 ----------------------------------------------------------------------------------------------------
2021-06-22 15:42:31,737 epoch 25 - iter 4/42 - loss 0.48299983 - samples/sec: 66.89 - lr: 0.000004
2021-06-22 15:42:33,682 epoch 25 - iter 8/42 - loss 0.40723366 - samples/sec: 65.81 - lr: 0.000004
2021-06-22 15:42:35,644 epoch 25 - iter 12/42 - loss 0.44082858 - samples/sec: 65.25 - lr: 0.000004
2021-06-22 15:42:37,590 epoch 25 - iter 16/42 - loss 0.41362625 - samples/sec: 65.79 - lr: 0.000004
2021-06-22 15:42:39,544 epoch 25 - iter 20/42 - loss 0.37660490 - samples/sec: 65.54 - lr: 0.000004
2021-06-22 15:42:41,444 epoch 25 - iter 24/42 - loss 0.37303993 - samples/sec: 67.38 - lr: 0.000004
2021-06-22 15:42:43,411 epoch 25 - iter 28/42 - loss 0.37934226 - samples/sec: 65.12 - lr: 0.000004
2021-06-22 15:42:45,408 epoch 25 - iter 32/42 - loss 0.38406274 - samples/sec: 64.11 - lr: 0.000004
2021-06-22 15:42:47,338 epoch 25 - iter 36/42 - loss 0.36328766 - samples/sec: 66.35 - lr: 0.000004
2021-06-22 15:42:49,298 epoch 25 - iter 40/42 - loss 0.35649850 - samples/sec: 65.32 - lr: 0.000004
2021-06-22 15:42:50,289 ----------------------------------------------------------------------------------------------------
2021-06-22 15:42:50,290 EPOCH 25 done: loss 0.3528 - lr 0.0000038
2021-06-22 15:42:51,106 DEV : loss 0.4057808816432953 - score 0.9528
2021-06-22 15:42:51,117 BAD EPOCHS (no improvement): 3
2021-06-22 15:42:51,117 ----------------------------------------------------------------------------------------------------
2021-06-22 15:42:53,083 epoch 26 - iter 4/42 - loss 0.27118942 - samples/sec: 65.12 - lr: 0.000004
2021-06-22 15:42:55,075 epoch 26 - iter 8/42 - loss 0.28980350 - samples/sec: 64.30 - lr: 0.000004
2021-06-22 15:42:56,992 epoch 26 - iter 12/42 - loss 0.31490824 - samples/sec: 66.77 - lr: 0.000004
2021-06-22 15:42:58,957 epoch 26 - iter 16/42 - loss 0.31513913 - samples/sec: 65.18 - lr: 0.000004
2021-06-22 15:43:00,886 epoch 26 - iter 20/42 - loss 0.31520019 - samples/sec: 66.37 - lr: 0.000004
2021-06-22 15:43:02,870 epoch 26 - iter 24/42 - loss 0.31234119 - samples/sec: 64.53 - lr: 0.000004
2021-06-22 15:43:04,839 epoch 26 - iter 28/42 - loss 0.34096449 - samples/sec: 65.02 - lr: 0.000004
2021-06-22 15:43:06,809 epoch 26 - iter 32/42 - loss 0.33966869 - samples/sec: 65.00 - lr: 0.000004
2021-06-22 15:43:08,757 epoch 26 - iter 36/42 - loss 0.35184841 - samples/sec: 65.74 - lr: 0.000004
2021-06-22 15:43:10,689 epoch 26 - iter 40/42 - loss 0.34058065 - samples/sec: 66.27 - lr: 0.000004
2021-06-22 15:43:11,655 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:11,655 EPOCH 26 done: loss 0.3419 - lr 0.0000038
2021-06-22 15:43:12,472 DEV : loss 0.4127483069896698 - score 0.9528
Epoch    26: reducing learning rate of group 0 to 1.8750e-06.
2021-06-22 15:43:12,483 BAD EPOCHS (no improvement): 4
2021-06-22 15:43:12,483 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:12,483 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:12,483 learning rate too small - quitting training!
2021-06-22 15:43:12,483 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:12,908 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:12,908 Testing using best model ...
2021-06-22 15:43:12,909 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/best-model.pt
2021-06-22 15:43:16,456 0.9452	0.9718	0.9583
2021-06-22 15:43:16,457 
Results:
- F1-score (micro) 0.9583
- F1-score (macro) 0.9583

By class:
SENT       tp: 207 - fp: 12 - fn: 6 - precision: 0.9452 - recall: 0.9718 - f1-score: 0.9583
2021-06-22 15:43:16,457 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/
2021-06-22 15:43:16,484 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt
2021-06-22 15:43:16,487 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/sent_train.txt
2021-06-22 15:43:16,489 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/sent_dev.txt
2021-06-22 15:43:16,491 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/sent_test.txt
Corpus: 10286 train + 1410 dev + 1379 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-06-22 15:43:27,172 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:27,173 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-06-22 15:43:27,173 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:27,173 Corpus: "Corpus: 10286 train + 1410 dev + 1379 test sentences"
2021-06-22 15:43:27,173 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:27,173 Parameters:
2021-06-22 15:43:27,173  - learning_rate: "3e-05"
2021-06-22 15:43:27,173  - mini_batch_size: "32"
2021-06-22 15:43:27,173  - patience: "3"
2021-06-22 15:43:27,173  - anneal_factor: "0.5"
2021-06-22 15:43:27,173  - max_epochs: "40"
2021-06-22 15:43:27,173  - shuffle: "True"
2021-06-22 15:43:27,173  - train_with_dev: "False"
2021-06-22 15:43:27,173  - batch_growth_annealing: "False"
2021-06-22 15:43:27,173 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:27,173 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt"
2021-06-22 15:43:27,173 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:27,173 Device: cuda:0
2021-06-22 15:43:27,173 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:27,173 Embeddings storage mode: cpu
2021-06-22 15:43:27,174 ----------------------------------------------------------------------------------------------------
2021-06-22 15:43:52,135 epoch 1 - iter 32/322 - loss 14.84816198 - samples/sec: 41.03 - lr: 0.000030
2021-06-22 15:44:17,073 epoch 1 - iter 64/322 - loss 9.00497537 - samples/sec: 41.06 - lr: 0.000030
2021-06-22 15:44:42,572 epoch 1 - iter 96/322 - loss 6.61942640 - samples/sec: 40.16 - lr: 0.000030
2021-06-22 15:45:07,568 epoch 1 - iter 128/322 - loss 5.28342824 - samples/sec: 40.97 - lr: 0.000030
2021-06-22 15:45:32,535 epoch 1 - iter 160/322 - loss 4.42973024 - samples/sec: 41.02 - lr: 0.000030
2021-06-22 15:45:57,515 epoch 1 - iter 192/322 - loss 3.84445162 - samples/sec: 41.00 - lr: 0.000030
2021-06-22 15:46:22,476 epoch 1 - iter 224/322 - loss 3.42245232 - samples/sec: 41.03 - lr: 0.000030
2021-06-22 15:46:47,467 epoch 1 - iter 256/322 - loss 3.08072338 - samples/sec: 40.98 - lr: 0.000030
2021-06-22 15:47:12,368 epoch 1 - iter 288/322 - loss 2.81338947 - samples/sec: 41.13 - lr: 0.000030
2021-06-22 15:47:37,323 epoch 1 - iter 320/322 - loss 2.59787757 - samples/sec: 41.04 - lr: 0.000030
2021-06-22 15:47:38,461 ----------------------------------------------------------------------------------------------------
2021-06-22 15:47:38,461 EPOCH 1 done: loss 2.5876 - lr 0.0000300
2021-06-22 15:47:58,274 DEV : loss 0.42155495285987854 - score 0.9201
2021-06-22 15:47:58,378 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:47:58,918 ----------------------------------------------------------------------------------------------------
2021-06-22 15:48:15,055 epoch 2 - iter 32/322 - loss 0.61137025 - samples/sec: 63.46 - lr: 0.000030
2021-06-22 15:48:31,179 epoch 2 - iter 64/322 - loss 0.59232011 - samples/sec: 63.52 - lr: 0.000030
2021-06-22 15:48:47,342 epoch 2 - iter 96/322 - loss 0.58393052 - samples/sec: 63.36 - lr: 0.000030
2021-06-22 15:49:03,430 epoch 2 - iter 128/322 - loss 0.56074617 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 15:49:19,603 epoch 2 - iter 160/322 - loss 0.54992522 - samples/sec: 63.32 - lr: 0.000030
2021-06-22 15:49:35,741 epoch 2 - iter 192/322 - loss 0.53882852 - samples/sec: 63.46 - lr: 0.000030
2021-06-22 15:49:51,902 epoch 2 - iter 224/322 - loss 0.52310423 - samples/sec: 63.37 - lr: 0.000030
2021-06-22 15:50:08,058 epoch 2 - iter 256/322 - loss 0.50505886 - samples/sec: 63.39 - lr: 0.000030
2021-06-22 15:50:24,098 epoch 2 - iter 288/322 - loss 0.49498725 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 15:50:40,244 epoch 2 - iter 320/322 - loss 0.48995010 - samples/sec: 63.43 - lr: 0.000030
2021-06-22 15:50:41,011 ----------------------------------------------------------------------------------------------------
2021-06-22 15:50:41,012 EPOCH 2 done: loss 0.4898 - lr 0.0000300
2021-06-22 15:50:48,539 DEV : loss 0.24731063842773438 - score 0.9523
2021-06-22 15:50:48,643 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:50:54,128 ----------------------------------------------------------------------------------------------------
2021-06-22 15:51:10,299 epoch 3 - iter 32/322 - loss 0.35376163 - samples/sec: 63.33 - lr: 0.000030
2021-06-22 15:51:26,416 epoch 3 - iter 64/322 - loss 0.36724905 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 15:51:42,491 epoch 3 - iter 96/322 - loss 0.36122036 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 15:51:58,649 epoch 3 - iter 128/322 - loss 0.36472877 - samples/sec: 63.38 - lr: 0.000030
2021-06-22 15:52:14,740 epoch 3 - iter 160/322 - loss 0.36164858 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 15:52:30,894 epoch 3 - iter 192/322 - loss 0.36138711 - samples/sec: 63.40 - lr: 0.000030
2021-06-22 15:52:47,072 epoch 3 - iter 224/322 - loss 0.36720319 - samples/sec: 63.30 - lr: 0.000030
2021-06-22 15:53:03,156 epoch 3 - iter 256/322 - loss 0.36759809 - samples/sec: 63.68 - lr: 0.000030
2021-06-22 15:53:19,274 epoch 3 - iter 288/322 - loss 0.36386885 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 15:53:35,417 epoch 3 - iter 320/322 - loss 0.35891034 - samples/sec: 63.44 - lr: 0.000030
2021-06-22 15:53:36,179 ----------------------------------------------------------------------------------------------------
2021-06-22 15:53:36,179 EPOCH 3 done: loss 0.3596 - lr 0.0000300
2021-06-22 15:53:43,648 DEV : loss 0.21296359598636627 - score 0.9587
2021-06-22 15:53:43,754 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:53:49,110 ----------------------------------------------------------------------------------------------------
2021-06-22 15:54:05,231 epoch 4 - iter 32/322 - loss 0.29956034 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 15:54:21,379 epoch 4 - iter 64/322 - loss 0.29989294 - samples/sec: 63.42 - lr: 0.000030
2021-06-22 15:54:37,422 epoch 4 - iter 96/322 - loss 0.29528883 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 15:54:53,592 epoch 4 - iter 128/322 - loss 0.30014358 - samples/sec: 63.33 - lr: 0.000030
2021-06-22 15:55:09,737 epoch 4 - iter 160/322 - loss 0.30123566 - samples/sec: 63.43 - lr: 0.000030
2021-06-22 15:55:25,840 epoch 4 - iter 192/322 - loss 0.30103783 - samples/sec: 63.60 - lr: 0.000030
2021-06-22 15:55:41,977 epoch 4 - iter 224/322 - loss 0.29622855 - samples/sec: 63.46 - lr: 0.000030
2021-06-22 15:55:58,114 epoch 4 - iter 256/322 - loss 0.29284980 - samples/sec: 63.47 - lr: 0.000030
2021-06-22 15:56:14,042 epoch 4 - iter 288/322 - loss 0.29616975 - samples/sec: 64.30 - lr: 0.000030
2021-06-22 15:56:29,915 epoch 4 - iter 320/322 - loss 0.29488045 - samples/sec: 64.52 - lr: 0.000030
2021-06-22 15:56:30,653 ----------------------------------------------------------------------------------------------------
2021-06-22 15:56:30,653 EPOCH 4 done: loss 0.2947 - lr 0.0000300
2021-06-22 15:56:38,857 DEV : loss 0.19352680444717407 - score 0.9639
2021-06-22 15:56:38,962 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 15:56:44,444 ----------------------------------------------------------------------------------------------------
2021-06-22 15:57:00,393 epoch 5 - iter 32/322 - loss 0.28204589 - samples/sec: 64.22 - lr: 0.000030
2021-06-22 15:57:16,333 epoch 5 - iter 64/322 - loss 0.27232320 - samples/sec: 64.25 - lr: 0.000030
2021-06-22 15:57:32,215 epoch 5 - iter 96/322 - loss 0.27174610 - samples/sec: 64.48 - lr: 0.000030
2021-06-22 15:57:48,139 epoch 5 - iter 128/322 - loss 0.26259592 - samples/sec: 64.31 - lr: 0.000030
2021-06-22 15:58:04,152 epoch 5 - iter 160/322 - loss 0.25703836 - samples/sec: 63.96 - lr: 0.000030
2021-06-22 15:58:20,240 epoch 5 - iter 192/322 - loss 0.25583970 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 15:58:36,283 epoch 5 - iter 224/322 - loss 0.25388280 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 15:58:52,361 epoch 5 - iter 256/322 - loss 0.25153315 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 15:59:08,444 epoch 5 - iter 288/322 - loss 0.25111649 - samples/sec: 63.68 - lr: 0.000030
2021-06-22 15:59:24,503 epoch 5 - iter 320/322 - loss 0.25234124 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 15:59:25,261 ----------------------------------------------------------------------------------------------------
2021-06-22 15:59:25,261 EPOCH 5 done: loss 0.2514 - lr 0.0000300
2021-06-22 15:59:32,724 DEV : loss 0.21073545515537262 - score 0.9632
2021-06-22 15:59:32,830 BAD EPOCHS (no improvement): 1
2021-06-22 15:59:32,830 ----------------------------------------------------------------------------------------------------
2021-06-22 15:59:48,967 epoch 6 - iter 32/322 - loss 0.24707091 - samples/sec: 63.46 - lr: 0.000030
2021-06-22 16:00:05,054 epoch 6 - iter 64/322 - loss 0.25486650 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 16:00:21,144 epoch 6 - iter 96/322 - loss 0.23869097 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 16:00:37,172 epoch 6 - iter 128/322 - loss 0.24020607 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 16:00:53,223 epoch 6 - iter 160/322 - loss 0.24379719 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 16:01:09,292 epoch 6 - iter 192/322 - loss 0.23918753 - samples/sec: 63.73 - lr: 0.000030
2021-06-22 16:01:25,368 epoch 6 - iter 224/322 - loss 0.23655971 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 16:01:41,457 epoch 6 - iter 256/322 - loss 0.24149973 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 16:01:57,510 epoch 6 - iter 288/322 - loss 0.24282108 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 16:02:13,628 epoch 6 - iter 320/322 - loss 0.23952219 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 16:02:14,378 ----------------------------------------------------------------------------------------------------
2021-06-22 16:02:14,378 EPOCH 6 done: loss 0.2394 - lr 0.0000300
2021-06-22 16:02:21,873 DEV : loss 0.19767098128795624 - score 0.965
2021-06-22 16:02:21,978 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:02:27,456 ----------------------------------------------------------------------------------------------------
2021-06-22 16:02:43,617 epoch 7 - iter 32/322 - loss 0.22051077 - samples/sec: 63.37 - lr: 0.000030
2021-06-22 16:02:59,755 epoch 7 - iter 64/322 - loss 0.22368747 - samples/sec: 63.46 - lr: 0.000030
2021-06-22 16:03:15,860 epoch 7 - iter 96/322 - loss 0.21899930 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 16:03:31,942 epoch 7 - iter 128/322 - loss 0.22757985 - samples/sec: 63.68 - lr: 0.000030
2021-06-22 16:03:48,018 epoch 7 - iter 160/322 - loss 0.22014167 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 16:04:04,055 epoch 7 - iter 192/322 - loss 0.22407394 - samples/sec: 63.86 - lr: 0.000030
2021-06-22 16:04:20,156 epoch 7 - iter 224/322 - loss 0.22493249 - samples/sec: 63.61 - lr: 0.000030
2021-06-22 16:04:36,194 epoch 7 - iter 256/322 - loss 0.22384831 - samples/sec: 63.86 - lr: 0.000030
2021-06-22 16:04:52,266 epoch 7 - iter 288/322 - loss 0.22173353 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 16:05:08,288 epoch 7 - iter 320/322 - loss 0.21961506 - samples/sec: 63.92 - lr: 0.000030
2021-06-22 16:05:09,056 ----------------------------------------------------------------------------------------------------
2021-06-22 16:05:09,056 EPOCH 7 done: loss 0.2197 - lr 0.0000300
2021-06-22 16:05:17,288 DEV : loss 0.17871569097042084 - score 0.9643
2021-06-22 16:05:17,392 BAD EPOCHS (no improvement): 1
2021-06-22 16:05:17,393 ----------------------------------------------------------------------------------------------------
2021-06-22 16:05:33,559 epoch 8 - iter 32/322 - loss 0.21175804 - samples/sec: 63.35 - lr: 0.000030
2021-06-22 16:05:49,676 epoch 8 - iter 64/322 - loss 0.20410993 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 16:06:05,804 epoch 8 - iter 96/322 - loss 0.20772725 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 16:06:21,960 epoch 8 - iter 128/322 - loss 0.20381613 - samples/sec: 63.39 - lr: 0.000030
2021-06-22 16:06:38,068 epoch 8 - iter 160/322 - loss 0.20684891 - samples/sec: 63.58 - lr: 0.000030
2021-06-22 16:06:54,193 epoch 8 - iter 192/322 - loss 0.21304519 - samples/sec: 63.51 - lr: 0.000030
2021-06-22 16:07:10,318 epoch 8 - iter 224/322 - loss 0.21216903 - samples/sec: 63.51 - lr: 0.000030
2021-06-22 16:07:26,450 epoch 8 - iter 256/322 - loss 0.20853446 - samples/sec: 63.48 - lr: 0.000030
2021-06-22 16:07:42,569 epoch 8 - iter 288/322 - loss 0.20785520 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 16:07:58,633 epoch 8 - iter 320/322 - loss 0.20445218 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 16:07:59,380 ----------------------------------------------------------------------------------------------------
2021-06-22 16:07:59,380 EPOCH 8 done: loss 0.2046 - lr 0.0000300
2021-06-22 16:08:06,869 DEV : loss 0.18297255039215088 - score 0.9663
2021-06-22 16:08:06,974 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:08:12,557 ----------------------------------------------------------------------------------------------------
2021-06-22 16:08:28,536 epoch 9 - iter 32/322 - loss 0.19670497 - samples/sec: 64.10 - lr: 0.000030
2021-06-22 16:08:44,646 epoch 9 - iter 64/322 - loss 0.20506398 - samples/sec: 63.57 - lr: 0.000030
2021-06-22 16:09:00,654 epoch 9 - iter 96/322 - loss 0.20390422 - samples/sec: 63.98 - lr: 0.000030
2021-06-22 16:09:16,748 epoch 9 - iter 128/322 - loss 0.20082699 - samples/sec: 63.63 - lr: 0.000030
2021-06-22 16:09:32,801 epoch 9 - iter 160/322 - loss 0.19860899 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 16:09:48,799 epoch 9 - iter 192/322 - loss 0.19505230 - samples/sec: 64.01 - lr: 0.000030
2021-06-22 16:10:04,886 epoch 9 - iter 224/322 - loss 0.19619178 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 16:10:21,001 epoch 9 - iter 256/322 - loss 0.19461500 - samples/sec: 63.55 - lr: 0.000030
2021-06-22 16:10:37,055 epoch 9 - iter 288/322 - loss 0.19147008 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 16:10:53,134 epoch 9 - iter 320/322 - loss 0.18971413 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 16:10:53,892 ----------------------------------------------------------------------------------------------------
2021-06-22 16:10:53,892 EPOCH 9 done: loss 0.1893 - lr 0.0000300
2021-06-22 16:11:01,368 DEV : loss 0.17502756416797638 - score 0.9678
2021-06-22 16:11:01,474 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:11:07,058 ----------------------------------------------------------------------------------------------------
2021-06-22 16:11:23,199 epoch 10 - iter 32/322 - loss 0.15710622 - samples/sec: 63.45 - lr: 0.000030
2021-06-22 16:11:39,301 epoch 10 - iter 64/322 - loss 0.16414723 - samples/sec: 63.60 - lr: 0.000030
2021-06-22 16:11:55,387 epoch 10 - iter 96/322 - loss 0.17583847 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 16:12:11,474 epoch 10 - iter 128/322 - loss 0.18073276 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 16:12:27,609 epoch 10 - iter 160/322 - loss 0.18058102 - samples/sec: 63.47 - lr: 0.000030
2021-06-22 16:12:43,687 epoch 10 - iter 192/322 - loss 0.18083354 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 16:12:59,750 epoch 10 - iter 224/322 - loss 0.18024471 - samples/sec: 63.76 - lr: 0.000030
2021-06-22 16:13:15,836 epoch 10 - iter 256/322 - loss 0.17909399 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 16:13:31,889 epoch 10 - iter 288/322 - loss 0.17780976 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 16:13:48,008 epoch 10 - iter 320/322 - loss 0.18029377 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 16:13:48,770 ----------------------------------------------------------------------------------------------------
2021-06-22 16:13:48,770 EPOCH 10 done: loss 0.1805 - lr 0.0000300
2021-06-22 16:13:56,225 DEV : loss 0.17022773623466492 - score 0.9666
2021-06-22 16:13:56,333 BAD EPOCHS (no improvement): 1
2021-06-22 16:13:56,333 ----------------------------------------------------------------------------------------------------
2021-06-22 16:14:12,385 epoch 11 - iter 32/322 - loss 0.16088743 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 16:14:29,239 epoch 11 - iter 64/322 - loss 0.16857007 - samples/sec: 60.76 - lr: 0.000030
2021-06-22 16:14:45,412 epoch 11 - iter 96/322 - loss 0.17149189 - samples/sec: 63.32 - lr: 0.000030
2021-06-22 16:15:01,547 epoch 11 - iter 128/322 - loss 0.16318400 - samples/sec: 63.47 - lr: 0.000030
2021-06-22 16:15:17,666 epoch 11 - iter 160/322 - loss 0.15885521 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 16:15:33,778 epoch 11 - iter 192/322 - loss 0.16673232 - samples/sec: 63.56 - lr: 0.000030
2021-06-22 16:15:49,870 epoch 11 - iter 224/322 - loss 0.16975010 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 16:16:05,992 epoch 11 - iter 256/322 - loss 0.17050767 - samples/sec: 63.52 - lr: 0.000030
2021-06-22 16:16:22,047 epoch 11 - iter 288/322 - loss 0.16867888 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 16:16:38,075 epoch 11 - iter 320/322 - loss 0.17020491 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 16:16:38,831 ----------------------------------------------------------------------------------------------------
2021-06-22 16:16:38,832 EPOCH 11 done: loss 0.1705 - lr 0.0000300
2021-06-22 16:16:46,279 DEV : loss 0.1837705820798874 - score 0.9672
2021-06-22 16:16:46,385 BAD EPOCHS (no improvement): 2
2021-06-22 16:16:46,385 ----------------------------------------------------------------------------------------------------
2021-06-22 16:17:02,392 epoch 12 - iter 32/322 - loss 0.18339803 - samples/sec: 63.98 - lr: 0.000030
2021-06-22 16:17:18,501 epoch 12 - iter 64/322 - loss 0.18157338 - samples/sec: 63.57 - lr: 0.000030
2021-06-22 16:17:34,529 epoch 12 - iter 96/322 - loss 0.17196042 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 16:17:50,580 epoch 12 - iter 128/322 - loss 0.16395021 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 16:18:06,696 epoch 12 - iter 160/322 - loss 0.16136491 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 16:18:22,777 epoch 12 - iter 192/322 - loss 0.16381603 - samples/sec: 63.69 - lr: 0.000030
2021-06-22 16:18:38,837 epoch 12 - iter 224/322 - loss 0.16103255 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 16:18:54,892 epoch 12 - iter 256/322 - loss 0.16074182 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 16:19:10,983 epoch 12 - iter 288/322 - loss 0.16233887 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 16:19:27,045 epoch 12 - iter 320/322 - loss 0.16235189 - samples/sec: 63.76 - lr: 0.000030
2021-06-22 16:19:27,804 ----------------------------------------------------------------------------------------------------
2021-06-22 16:19:27,804 EPOCH 12 done: loss 0.1621 - lr 0.0000300
2021-06-22 16:19:35,238 DEV : loss 0.1504455953836441 - score 0.9675
2021-06-22 16:19:35,343 BAD EPOCHS (no improvement): 3
2021-06-22 16:19:35,343 ----------------------------------------------------------------------------------------------------
2021-06-22 16:19:51,360 epoch 13 - iter 32/322 - loss 0.13273853 - samples/sec: 63.94 - lr: 0.000030
2021-06-22 16:20:07,392 epoch 13 - iter 64/322 - loss 0.13890579 - samples/sec: 63.88 - lr: 0.000030
2021-06-22 16:20:23,500 epoch 13 - iter 96/322 - loss 0.13711110 - samples/sec: 63.58 - lr: 0.000030
2021-06-22 16:20:39,620 epoch 13 - iter 128/322 - loss 0.14089477 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 16:20:55,661 epoch 13 - iter 160/322 - loss 0.13897357 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 16:21:11,783 epoch 13 - iter 192/322 - loss 0.14273650 - samples/sec: 63.52 - lr: 0.000030
2021-06-22 16:21:27,939 epoch 13 - iter 224/322 - loss 0.14449403 - samples/sec: 63.39 - lr: 0.000030
2021-06-22 16:21:44,055 epoch 13 - iter 256/322 - loss 0.14976926 - samples/sec: 63.55 - lr: 0.000030
2021-06-22 16:22:00,211 epoch 13 - iter 288/322 - loss 0.15256489 - samples/sec: 63.39 - lr: 0.000030
2021-06-22 16:22:16,246 epoch 13 - iter 320/322 - loss 0.14958936 - samples/sec: 63.87 - lr: 0.000030
2021-06-22 16:22:16,988 ----------------------------------------------------------------------------------------------------
2021-06-22 16:22:16,988 EPOCH 13 done: loss 0.1494 - lr 0.0000300
2021-06-22 16:22:24,437 DEV : loss 0.15838505327701569 - score 0.97
2021-06-22 16:22:24,543 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:22:30,023 ----------------------------------------------------------------------------------------------------
2021-06-22 16:22:45,879 epoch 14 - iter 32/322 - loss 0.14011412 - samples/sec: 64.59 - lr: 0.000030
2021-06-22 16:23:01,953 epoch 14 - iter 64/322 - loss 0.14044374 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 16:23:18,137 epoch 14 - iter 96/322 - loss 0.15147062 - samples/sec: 63.28 - lr: 0.000030
2021-06-22 16:23:34,201 epoch 14 - iter 128/322 - loss 0.15795279 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 16:23:50,148 epoch 14 - iter 160/322 - loss 0.15423282 - samples/sec: 64.22 - lr: 0.000030
2021-06-22 16:24:06,149 epoch 14 - iter 192/322 - loss 0.15462463 - samples/sec: 64.00 - lr: 0.000030
2021-06-22 16:24:22,168 epoch 14 - iter 224/322 - loss 0.15303811 - samples/sec: 63.93 - lr: 0.000030
2021-06-22 16:24:38,198 epoch 14 - iter 256/322 - loss 0.15294189 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 16:24:54,195 epoch 14 - iter 288/322 - loss 0.15323288 - samples/sec: 64.02 - lr: 0.000030
2021-06-22 16:25:10,211 epoch 14 - iter 320/322 - loss 0.15541788 - samples/sec: 63.94 - lr: 0.000030
2021-06-22 16:25:10,965 ----------------------------------------------------------------------------------------------------
2021-06-22 16:25:10,965 EPOCH 14 done: loss 0.1550 - lr 0.0000300
2021-06-22 16:25:19,141 DEV : loss 0.16138269007205963 - score 0.9697
2021-06-22 16:25:19,246 BAD EPOCHS (no improvement): 1
2021-06-22 16:25:19,246 ----------------------------------------------------------------------------------------------------
2021-06-22 16:25:35,301 epoch 15 - iter 32/322 - loss 0.14327174 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 16:25:51,353 epoch 15 - iter 64/322 - loss 0.14848616 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 16:26:07,438 epoch 15 - iter 96/322 - loss 0.15088450 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 16:26:23,538 epoch 15 - iter 128/322 - loss 0.14815319 - samples/sec: 63.61 - lr: 0.000030
2021-06-22 16:26:39,665 epoch 15 - iter 160/322 - loss 0.14657138 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 16:26:55,790 epoch 15 - iter 192/322 - loss 0.14693700 - samples/sec: 63.51 - lr: 0.000030
2021-06-22 16:27:11,944 epoch 15 - iter 224/322 - loss 0.14737778 - samples/sec: 63.40 - lr: 0.000030
2021-06-22 16:27:28,056 epoch 15 - iter 256/322 - loss 0.14370254 - samples/sec: 63.56 - lr: 0.000030
2021-06-22 16:27:44,139 epoch 15 - iter 288/322 - loss 0.14760839 - samples/sec: 63.68 - lr: 0.000030
2021-06-22 16:28:00,240 epoch 15 - iter 320/322 - loss 0.14645132 - samples/sec: 63.61 - lr: 0.000030
2021-06-22 16:28:01,003 ----------------------------------------------------------------------------------------------------
2021-06-22 16:28:01,003 EPOCH 15 done: loss 0.1473 - lr 0.0000300
2021-06-22 16:28:08,430 DEV : loss 0.14853535592556 - score 0.9699
2021-06-22 16:28:08,534 BAD EPOCHS (no improvement): 2
2021-06-22 16:28:08,535 ----------------------------------------------------------------------------------------------------
2021-06-22 16:28:24,671 epoch 16 - iter 32/322 - loss 0.11481349 - samples/sec: 63.47 - lr: 0.000030
2021-06-22 16:28:40,843 epoch 16 - iter 64/322 - loss 0.13551646 - samples/sec: 63.32 - lr: 0.000030
2021-06-22 16:28:56,948 epoch 16 - iter 96/322 - loss 0.13731514 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 16:29:13,001 epoch 16 - iter 128/322 - loss 0.13801839 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 16:29:29,059 epoch 16 - iter 160/322 - loss 0.13906636 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 16:29:45,119 epoch 16 - iter 192/322 - loss 0.13918995 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 16:30:01,211 epoch 16 - iter 224/322 - loss 0.14153699 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 16:30:17,349 epoch 16 - iter 256/322 - loss 0.14294753 - samples/sec: 63.46 - lr: 0.000030
2021-06-22 16:30:33,517 epoch 16 - iter 288/322 - loss 0.14265466 - samples/sec: 63.34 - lr: 0.000030
2021-06-22 16:30:49,523 epoch 16 - iter 320/322 - loss 0.14459190 - samples/sec: 63.98 - lr: 0.000030
2021-06-22 16:30:50,278 ----------------------------------------------------------------------------------------------------
2021-06-22 16:30:50,278 EPOCH 16 done: loss 0.1440 - lr 0.0000300
2021-06-22 16:30:57,701 DEV : loss 0.15980973839759827 - score 0.97
2021-06-22 16:30:57,807 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:31:03,381 ----------------------------------------------------------------------------------------------------
2021-06-22 16:31:19,424 epoch 17 - iter 32/322 - loss 0.13387806 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 16:31:35,535 epoch 17 - iter 64/322 - loss 0.14287078 - samples/sec: 63.57 - lr: 0.000030
2021-06-22 16:31:51,622 epoch 17 - iter 96/322 - loss 0.13422062 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 16:32:07,702 epoch 17 - iter 128/322 - loss 0.13563318 - samples/sec: 63.69 - lr: 0.000030
2021-06-22 16:32:23,822 epoch 17 - iter 160/322 - loss 0.13496167 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 16:32:39,863 epoch 17 - iter 192/322 - loss 0.13362956 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 16:32:55,934 epoch 17 - iter 224/322 - loss 0.13339166 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 16:33:11,975 epoch 17 - iter 256/322 - loss 0.12996250 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 16:33:28,093 epoch 17 - iter 288/322 - loss 0.13047936 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 16:33:44,097 epoch 17 - iter 320/322 - loss 0.13171615 - samples/sec: 63.99 - lr: 0.000030
2021-06-22 16:33:44,852 ----------------------------------------------------------------------------------------------------
2021-06-22 16:33:44,853 EPOCH 17 done: loss 0.1316 - lr 0.0000300
2021-06-22 16:33:53,036 DEV : loss 0.16200463473796844 - score 0.9684
2021-06-22 16:33:53,142 BAD EPOCHS (no improvement): 1
2021-06-22 16:33:53,143 ----------------------------------------------------------------------------------------------------
2021-06-22 16:34:09,169 epoch 18 - iter 32/322 - loss 0.13330473 - samples/sec: 63.90 - lr: 0.000030
2021-06-22 16:34:25,182 epoch 18 - iter 64/322 - loss 0.12376282 - samples/sec: 63.96 - lr: 0.000030
2021-06-22 16:34:41,193 epoch 18 - iter 96/322 - loss 0.12881082 - samples/sec: 63.96 - lr: 0.000030
2021-06-22 16:34:57,286 epoch 18 - iter 128/322 - loss 0.13626181 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 16:35:13,331 epoch 18 - iter 160/322 - loss 0.13052610 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 16:35:29,422 epoch 18 - iter 192/322 - loss 0.12755352 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 16:35:45,474 epoch 18 - iter 224/322 - loss 0.12870345 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 16:36:01,589 epoch 18 - iter 256/322 - loss 0.13021416 - samples/sec: 63.55 - lr: 0.000030
2021-06-22 16:36:17,620 epoch 18 - iter 288/322 - loss 0.12892577 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 16:36:33,719 epoch 18 - iter 320/322 - loss 0.13131716 - samples/sec: 63.61 - lr: 0.000030
2021-06-22 16:36:34,469 ----------------------------------------------------------------------------------------------------
2021-06-22 16:36:34,469 EPOCH 18 done: loss 0.1318 - lr 0.0000300
2021-06-22 16:36:41,898 DEV : loss 0.15629668533802032 - score 0.9695
2021-06-22 16:36:42,004 BAD EPOCHS (no improvement): 2
2021-06-22 16:36:42,004 ----------------------------------------------------------------------------------------------------
2021-06-22 16:36:58,051 epoch 19 - iter 32/322 - loss 0.13067507 - samples/sec: 63.82 - lr: 0.000030
2021-06-22 16:37:14,116 epoch 19 - iter 64/322 - loss 0.12821091 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 16:37:30,096 epoch 19 - iter 96/322 - loss 0.13227231 - samples/sec: 64.09 - lr: 0.000030
2021-06-22 16:37:46,161 epoch 19 - iter 128/322 - loss 0.12703923 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 16:38:02,220 epoch 19 - iter 160/322 - loss 0.12765190 - samples/sec: 63.77 - lr: 0.000030
2021-06-22 16:38:18,259 epoch 19 - iter 192/322 - loss 0.13031370 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 16:38:34,379 epoch 19 - iter 224/322 - loss 0.13091724 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 16:38:50,477 epoch 19 - iter 256/322 - loss 0.12872736 - samples/sec: 63.62 - lr: 0.000030
2021-06-22 16:39:06,523 epoch 19 - iter 288/322 - loss 0.12811893 - samples/sec: 63.82 - lr: 0.000030
2021-06-22 16:39:22,595 epoch 19 - iter 320/322 - loss 0.12700240 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 16:39:23,357 ----------------------------------------------------------------------------------------------------
2021-06-22 16:39:23,358 EPOCH 19 done: loss 0.1264 - lr 0.0000300
2021-06-22 16:39:30,795 DEV : loss 0.1609303057193756 - score 0.9688
2021-06-22 16:39:30,903 BAD EPOCHS (no improvement): 3
2021-06-22 16:39:30,903 ----------------------------------------------------------------------------------------------------
2021-06-22 16:39:47,011 epoch 20 - iter 32/322 - loss 0.11154305 - samples/sec: 63.58 - lr: 0.000030
2021-06-22 16:40:03,099 epoch 20 - iter 64/322 - loss 0.11443602 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 16:40:19,171 epoch 20 - iter 96/322 - loss 0.11785702 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 16:40:35,256 epoch 20 - iter 128/322 - loss 0.11843794 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 16:40:51,320 epoch 20 - iter 160/322 - loss 0.11914215 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 16:41:07,324 epoch 20 - iter 192/322 - loss 0.12101049 - samples/sec: 63.99 - lr: 0.000030
2021-06-22 16:41:23,400 epoch 20 - iter 224/322 - loss 0.11811985 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 16:41:39,492 epoch 20 - iter 256/322 - loss 0.12001534 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 16:41:55,534 epoch 20 - iter 288/322 - loss 0.12050173 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 16:42:11,607 epoch 20 - iter 320/322 - loss 0.11992842 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 16:42:12,364 ----------------------------------------------------------------------------------------------------
2021-06-22 16:42:12,364 EPOCH 20 done: loss 0.1194 - lr 0.0000300
2021-06-22 16:42:20,555 DEV : loss 0.15702319145202637 - score 0.9703
2021-06-22 16:42:20,662 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:42:26,248 ----------------------------------------------------------------------------------------------------
2021-06-22 16:42:42,345 epoch 21 - iter 32/322 - loss 0.10664673 - samples/sec: 63.62 - lr: 0.000030
2021-06-22 16:42:58,431 epoch 21 - iter 64/322 - loss 0.11564991 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 16:43:14,485 epoch 21 - iter 96/322 - loss 0.11303561 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 16:43:30,612 epoch 21 - iter 128/322 - loss 0.11490623 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 16:43:46,717 epoch 21 - iter 160/322 - loss 0.11518961 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 16:44:02,804 epoch 21 - iter 192/322 - loss 0.11483615 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 16:44:18,930 epoch 21 - iter 224/322 - loss 0.11418407 - samples/sec: 63.51 - lr: 0.000030
2021-06-22 16:44:35,028 epoch 21 - iter 256/322 - loss 0.11415459 - samples/sec: 63.62 - lr: 0.000030
2021-06-22 16:44:51,124 epoch 21 - iter 288/322 - loss 0.11408323 - samples/sec: 63.63 - lr: 0.000030
2021-06-22 16:45:07,243 epoch 21 - iter 320/322 - loss 0.11487213 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 16:45:08,003 ----------------------------------------------------------------------------------------------------
2021-06-22 16:45:08,003 EPOCH 21 done: loss 0.1152 - lr 0.0000300
2021-06-22 16:45:15,442 DEV : loss 0.1569027155637741 - score 0.9693
2021-06-22 16:45:15,549 BAD EPOCHS (no improvement): 1
2021-06-22 16:45:15,549 ----------------------------------------------------------------------------------------------------
2021-06-22 16:45:31,715 epoch 22 - iter 32/322 - loss 0.08846110 - samples/sec: 63.35 - lr: 0.000030
2021-06-22 16:45:47,844 epoch 22 - iter 64/322 - loss 0.10458762 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 16:46:03,984 epoch 22 - iter 96/322 - loss 0.10989367 - samples/sec: 63.45 - lr: 0.000030
2021-06-22 16:46:20,057 epoch 22 - iter 128/322 - loss 0.10822929 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 16:46:36,162 epoch 22 - iter 160/322 - loss 0.11260788 - samples/sec: 63.59 - lr: 0.000030
2021-06-22 16:46:52,296 epoch 22 - iter 192/322 - loss 0.11242898 - samples/sec: 63.48 - lr: 0.000030
2021-06-22 16:47:08,429 epoch 22 - iter 224/322 - loss 0.11181850 - samples/sec: 63.48 - lr: 0.000030
2021-06-22 16:47:24,497 epoch 22 - iter 256/322 - loss 0.11418968 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 16:47:40,573 epoch 22 - iter 288/322 - loss 0.11258033 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 16:47:56,612 epoch 22 - iter 320/322 - loss 0.11315057 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 16:47:57,370 ----------------------------------------------------------------------------------------------------
2021-06-22 16:47:57,371 EPOCH 22 done: loss 0.1134 - lr 0.0000300
2021-06-22 16:48:04,814 DEV : loss 0.15021729469299316 - score 0.9713
2021-06-22 16:48:04,920 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:48:10,281 ----------------------------------------------------------------------------------------------------
2021-06-22 16:48:26,412 epoch 23 - iter 32/322 - loss 0.11793910 - samples/sec: 63.49 - lr: 0.000030
2021-06-22 16:48:42,528 epoch 23 - iter 64/322 - loss 0.11282510 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 16:48:58,594 epoch 23 - iter 96/322 - loss 0.10991867 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 16:49:14,680 epoch 23 - iter 128/322 - loss 0.11615745 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 16:49:30,801 epoch 23 - iter 160/322 - loss 0.11223374 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 16:49:46,926 epoch 23 - iter 192/322 - loss 0.11004572 - samples/sec: 63.51 - lr: 0.000030
2021-06-22 16:50:03,011 epoch 23 - iter 224/322 - loss 0.10961855 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 16:50:19,042 epoch 23 - iter 256/322 - loss 0.10698591 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 16:50:35,097 epoch 23 - iter 288/322 - loss 0.10485965 - samples/sec: 63.79 - lr: 0.000030
2021-06-22 16:50:51,224 epoch 23 - iter 320/322 - loss 0.10591268 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 16:50:51,969 ----------------------------------------------------------------------------------------------------
2021-06-22 16:50:51,969 EPOCH 23 done: loss 0.1055 - lr 0.0000300
2021-06-22 16:50:59,419 DEV : loss 0.15899530053138733 - score 0.9719
2021-06-22 16:50:59,525 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:51:05,088 ----------------------------------------------------------------------------------------------------
2021-06-22 16:51:21,175 epoch 24 - iter 32/322 - loss 0.08982961 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 16:51:37,303 epoch 24 - iter 64/322 - loss 0.09470216 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 16:51:54,095 epoch 24 - iter 96/322 - loss 0.09149369 - samples/sec: 60.99 - lr: 0.000030
2021-06-22 16:52:10,159 epoch 24 - iter 128/322 - loss 0.09781060 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 16:52:26,172 epoch 24 - iter 160/322 - loss 0.10171144 - samples/sec: 63.95 - lr: 0.000030
2021-06-22 16:52:42,249 epoch 24 - iter 192/322 - loss 0.10516668 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 16:52:58,364 epoch 24 - iter 224/322 - loss 0.10559956 - samples/sec: 63.55 - lr: 0.000030
2021-06-22 16:53:14,462 epoch 24 - iter 256/322 - loss 0.10430323 - samples/sec: 63.62 - lr: 0.000030
2021-06-22 16:53:30,554 epoch 24 - iter 288/322 - loss 0.10330096 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 16:53:46,701 epoch 24 - iter 320/322 - loss 0.10403916 - samples/sec: 63.42 - lr: 0.000030
2021-06-22 16:53:47,461 ----------------------------------------------------------------------------------------------------
2021-06-22 16:53:47,462 EPOCH 24 done: loss 0.1041 - lr 0.0000300
2021-06-22 16:53:54,900 DEV : loss 0.15651123225688934 - score 0.9696
2021-06-22 16:53:55,007 BAD EPOCHS (no improvement): 1
2021-06-22 16:53:55,007 ----------------------------------------------------------------------------------------------------
2021-06-22 16:54:11,160 epoch 25 - iter 32/322 - loss 0.09575394 - samples/sec: 63.40 - lr: 0.000030
2021-06-22 16:54:27,236 epoch 25 - iter 64/322 - loss 0.09649319 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 16:54:43,269 epoch 25 - iter 96/322 - loss 0.09831740 - samples/sec: 63.87 - lr: 0.000030
2021-06-22 16:54:59,354 epoch 25 - iter 128/322 - loss 0.09813149 - samples/sec: 63.67 - lr: 0.000030
2021-06-22 16:55:15,428 epoch 25 - iter 160/322 - loss 0.09655209 - samples/sec: 63.71 - lr: 0.000030
2021-06-22 16:55:31,499 epoch 25 - iter 192/322 - loss 0.09971153 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 16:55:47,507 epoch 25 - iter 224/322 - loss 0.10020597 - samples/sec: 63.98 - lr: 0.000030
2021-06-22 16:56:03,658 epoch 25 - iter 256/322 - loss 0.10079110 - samples/sec: 63.41 - lr: 0.000030
2021-06-22 16:56:19,707 epoch 25 - iter 288/322 - loss 0.09714420 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 16:56:35,816 epoch 25 - iter 320/322 - loss 0.09701227 - samples/sec: 63.57 - lr: 0.000030
2021-06-22 16:56:36,568 ----------------------------------------------------------------------------------------------------
2021-06-22 16:56:36,569 EPOCH 25 done: loss 0.0970 - lr 0.0000300
2021-06-22 16:56:44,002 DEV : loss 0.15069392323493958 - score 0.9695
2021-06-22 16:56:44,109 BAD EPOCHS (no improvement): 2
2021-06-22 16:56:44,109 ----------------------------------------------------------------------------------------------------
2021-06-22 16:57:00,232 epoch 26 - iter 32/322 - loss 0.08537597 - samples/sec: 63.52 - lr: 0.000030
2021-06-22 16:57:16,324 epoch 26 - iter 64/322 - loss 0.09190550 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 16:57:32,342 epoch 26 - iter 96/322 - loss 0.08906944 - samples/sec: 63.94 - lr: 0.000030
2021-06-22 16:57:48,393 epoch 26 - iter 128/322 - loss 0.08943705 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 16:58:04,451 epoch 26 - iter 160/322 - loss 0.09063466 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 16:58:20,499 epoch 26 - iter 192/322 - loss 0.09049413 - samples/sec: 63.82 - lr: 0.000030
2021-06-22 16:58:36,619 epoch 26 - iter 224/322 - loss 0.09403422 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 16:58:52,777 epoch 26 - iter 256/322 - loss 0.09771855 - samples/sec: 63.38 - lr: 0.000030
2021-06-22 16:59:08,880 epoch 26 - iter 288/322 - loss 0.09665690 - samples/sec: 63.60 - lr: 0.000030
2021-06-22 16:59:24,917 epoch 26 - iter 320/322 - loss 0.09617685 - samples/sec: 63.86 - lr: 0.000030
2021-06-22 16:59:25,678 ----------------------------------------------------------------------------------------------------
2021-06-22 16:59:25,678 EPOCH 26 done: loss 0.0957 - lr 0.0000300
2021-06-22 16:59:33,122 DEV : loss 0.15108592808246613 - score 0.9721
2021-06-22 16:59:33,229 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 16:59:38,916 ----------------------------------------------------------------------------------------------------
2021-06-22 16:59:55,059 epoch 27 - iter 32/322 - loss 0.08718449 - samples/sec: 63.44 - lr: 0.000030
2021-06-22 17:00:11,199 epoch 27 - iter 64/322 - loss 0.09964850 - samples/sec: 63.45 - lr: 0.000030
2021-06-22 17:00:27,318 epoch 27 - iter 96/322 - loss 0.10196431 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 17:00:43,395 epoch 27 - iter 128/322 - loss 0.09797944 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 17:00:59,451 epoch 27 - iter 160/322 - loss 0.09668626 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 17:01:15,500 epoch 27 - iter 192/322 - loss 0.09769317 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 17:01:31,489 epoch 27 - iter 224/322 - loss 0.09866283 - samples/sec: 64.05 - lr: 0.000030
2021-06-22 17:01:47,488 epoch 27 - iter 256/322 - loss 0.09968773 - samples/sec: 64.01 - lr: 0.000030
2021-06-22 17:02:03,671 epoch 27 - iter 288/322 - loss 0.10085063 - samples/sec: 63.28 - lr: 0.000030
2021-06-22 17:02:19,763 epoch 27 - iter 320/322 - loss 0.10074446 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 17:02:20,519 ----------------------------------------------------------------------------------------------------
2021-06-22 17:02:20,519 EPOCH 27 done: loss 0.1004 - lr 0.0000300
2021-06-22 17:02:28,724 DEV : loss 0.15061800181865692 - score 0.9706
2021-06-22 17:02:28,830 BAD EPOCHS (no improvement): 1
2021-06-22 17:02:28,830 ----------------------------------------------------------------------------------------------------
2021-06-22 17:02:44,875 epoch 28 - iter 32/322 - loss 0.08671253 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 17:03:00,952 epoch 28 - iter 64/322 - loss 0.07928184 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 17:03:17,096 epoch 28 - iter 96/322 - loss 0.08024435 - samples/sec: 63.44 - lr: 0.000030
2021-06-22 17:03:33,227 epoch 28 - iter 128/322 - loss 0.08047449 - samples/sec: 63.49 - lr: 0.000030
2021-06-22 17:03:49,321 epoch 28 - iter 160/322 - loss 0.08593876 - samples/sec: 63.63 - lr: 0.000030
2021-06-22 17:04:05,393 epoch 28 - iter 192/322 - loss 0.08524001 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 17:04:21,481 epoch 28 - iter 224/322 - loss 0.08964746 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 17:04:37,570 epoch 28 - iter 256/322 - loss 0.08672750 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 17:04:53,703 epoch 28 - iter 288/322 - loss 0.08579207 - samples/sec: 63.48 - lr: 0.000030
2021-06-22 17:05:09,793 epoch 28 - iter 320/322 - loss 0.08583094 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 17:05:10,549 ----------------------------------------------------------------------------------------------------
2021-06-22 17:05:10,549 EPOCH 28 done: loss 0.0863 - lr 0.0000300
2021-06-22 17:05:17,986 DEV : loss 0.15449897944927216 - score 0.9696
2021-06-22 17:05:18,092 BAD EPOCHS (no improvement): 2
2021-06-22 17:05:18,092 ----------------------------------------------------------------------------------------------------
2021-06-22 17:05:34,218 epoch 29 - iter 32/322 - loss 0.07879508 - samples/sec: 63.51 - lr: 0.000030
2021-06-22 17:05:50,345 epoch 29 - iter 64/322 - loss 0.07916350 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 17:06:06,456 epoch 29 - iter 96/322 - loss 0.07960472 - samples/sec: 63.56 - lr: 0.000030
2021-06-22 17:06:22,571 epoch 29 - iter 128/322 - loss 0.07640247 - samples/sec: 63.55 - lr: 0.000030
2021-06-22 17:06:38,679 epoch 29 - iter 160/322 - loss 0.08404212 - samples/sec: 63.58 - lr: 0.000030
2021-06-22 17:06:54,829 epoch 29 - iter 192/322 - loss 0.08862105 - samples/sec: 63.41 - lr: 0.000030
2021-06-22 17:07:10,964 epoch 29 - iter 224/322 - loss 0.08902246 - samples/sec: 63.47 - lr: 0.000030
2021-06-22 17:07:27,108 epoch 29 - iter 256/322 - loss 0.09193850 - samples/sec: 63.44 - lr: 0.000030
2021-06-22 17:07:43,171 epoch 29 - iter 288/322 - loss 0.09045973 - samples/sec: 63.76 - lr: 0.000030
2021-06-22 17:07:59,259 epoch 29 - iter 320/322 - loss 0.09235836 - samples/sec: 63.66 - lr: 0.000030
2021-06-22 17:08:00,023 ----------------------------------------------------------------------------------------------------
2021-06-22 17:08:00,023 EPOCH 29 done: loss 0.0920 - lr 0.0000300
2021-06-22 17:08:07,472 DEV : loss 0.1453298181295395 - score 0.9714
2021-06-22 17:08:07,578 BAD EPOCHS (no improvement): 3
2021-06-22 17:08:07,578 ----------------------------------------------------------------------------------------------------
2021-06-22 17:08:23,650 epoch 30 - iter 32/322 - loss 0.08583693 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 17:08:39,779 epoch 30 - iter 64/322 - loss 0.08756051 - samples/sec: 63.50 - lr: 0.000030
2021-06-22 17:08:55,932 epoch 30 - iter 96/322 - loss 0.08865122 - samples/sec: 63.40 - lr: 0.000030
2021-06-22 17:09:12,021 epoch 30 - iter 128/322 - loss 0.09195882 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 17:09:28,119 epoch 30 - iter 160/322 - loss 0.08891510 - samples/sec: 63.62 - lr: 0.000030
2021-06-22 17:09:44,237 epoch 30 - iter 192/322 - loss 0.08916960 - samples/sec: 63.54 - lr: 0.000030
2021-06-22 17:10:00,326 epoch 30 - iter 224/322 - loss 0.08948274 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 17:10:16,439 epoch 30 - iter 256/322 - loss 0.08759392 - samples/sec: 63.56 - lr: 0.000030
2021-06-22 17:10:32,587 epoch 30 - iter 288/322 - loss 0.08588433 - samples/sec: 63.42 - lr: 0.000030
2021-06-22 17:10:48,703 epoch 30 - iter 320/322 - loss 0.08876975 - samples/sec: 63.55 - lr: 0.000030
2021-06-22 17:10:49,455 ----------------------------------------------------------------------------------------------------
2021-06-22 17:10:49,456 EPOCH 30 done: loss 0.0886 - lr 0.0000300
2021-06-22 17:10:56,887 DEV : loss 0.14846919476985931 - score 0.9722
2021-06-22 17:10:56,994 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 17:11:02,571 ----------------------------------------------------------------------------------------------------
2021-06-22 17:11:18,707 epoch 31 - iter 32/322 - loss 0.08595678 - samples/sec: 63.47 - lr: 0.000030
2021-06-22 17:11:34,546 epoch 31 - iter 64/322 - loss 0.08051653 - samples/sec: 64.66 - lr: 0.000030
2021-06-22 17:11:50,397 epoch 31 - iter 96/322 - loss 0.08222422 - samples/sec: 64.61 - lr: 0.000030
2021-06-22 17:12:06,341 epoch 31 - iter 128/322 - loss 0.08568636 - samples/sec: 64.23 - lr: 0.000030
2021-06-22 17:12:22,404 epoch 31 - iter 160/322 - loss 0.08399033 - samples/sec: 63.76 - lr: 0.000030
2021-06-22 17:12:38,437 epoch 31 - iter 192/322 - loss 0.08397290 - samples/sec: 63.88 - lr: 0.000030
2021-06-22 17:12:54,494 epoch 31 - iter 224/322 - loss 0.08340275 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 17:13:11,318 epoch 31 - iter 256/322 - loss 0.08425056 - samples/sec: 60.87 - lr: 0.000030
2021-06-22 17:13:27,317 epoch 31 - iter 288/322 - loss 0.08302528 - samples/sec: 64.01 - lr: 0.000030
2021-06-22 17:13:43,354 epoch 31 - iter 320/322 - loss 0.08307179 - samples/sec: 63.86 - lr: 0.000030
2021-06-22 17:13:44,110 ----------------------------------------------------------------------------------------------------
2021-06-22 17:13:44,110 EPOCH 31 done: loss 0.0833 - lr 0.0000300
2021-06-22 17:13:51,555 DEV : loss 0.14183558523654938 - score 0.9722
2021-06-22 17:13:51,661 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 17:13:57,220 ----------------------------------------------------------------------------------------------------
2021-06-22 17:14:13,344 epoch 32 - iter 32/322 - loss 0.09021842 - samples/sec: 63.52 - lr: 0.000030
2021-06-22 17:14:29,396 epoch 32 - iter 64/322 - loss 0.07562868 - samples/sec: 63.80 - lr: 0.000030
2021-06-22 17:14:45,487 epoch 32 - iter 96/322 - loss 0.08240484 - samples/sec: 63.65 - lr: 0.000030
2021-06-22 17:15:01,536 epoch 32 - iter 128/322 - loss 0.08246502 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 17:15:17,604 epoch 32 - iter 160/322 - loss 0.08069130 - samples/sec: 63.74 - lr: 0.000030
2021-06-22 17:15:33,641 epoch 32 - iter 192/322 - loss 0.07893635 - samples/sec: 63.86 - lr: 0.000030
2021-06-22 17:15:49,710 epoch 32 - iter 224/322 - loss 0.07982062 - samples/sec: 63.73 - lr: 0.000030
2021-06-22 17:16:05,835 epoch 32 - iter 256/322 - loss 0.08245437 - samples/sec: 63.51 - lr: 0.000030
2021-06-22 17:16:21,884 epoch 32 - iter 288/322 - loss 0.08341961 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 17:16:37,862 epoch 32 - iter 320/322 - loss 0.08230937 - samples/sec: 64.09 - lr: 0.000030
2021-06-22 17:16:38,620 ----------------------------------------------------------------------------------------------------
2021-06-22 17:16:38,620 EPOCH 32 done: loss 0.0827 - lr 0.0000300
2021-06-22 17:16:46,063 DEV : loss 0.1599709838628769 - score 0.9687
2021-06-22 17:16:46,170 BAD EPOCHS (no improvement): 1
2021-06-22 17:16:46,170 ----------------------------------------------------------------------------------------------------
2021-06-22 17:17:02,208 epoch 33 - iter 32/322 - loss 0.06856502 - samples/sec: 63.86 - lr: 0.000030
2021-06-22 17:17:18,281 epoch 33 - iter 64/322 - loss 0.07196904 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 17:17:34,352 epoch 33 - iter 96/322 - loss 0.07908073 - samples/sec: 63.72 - lr: 0.000030
2021-06-22 17:17:50,445 epoch 33 - iter 128/322 - loss 0.08040707 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 17:18:06,561 epoch 33 - iter 160/322 - loss 0.08031076 - samples/sec: 63.55 - lr: 0.000030
2021-06-22 17:18:22,639 epoch 33 - iter 192/322 - loss 0.08111543 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 17:18:38,670 epoch 33 - iter 224/322 - loss 0.07947211 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 17:18:54,658 epoch 33 - iter 256/322 - loss 0.07945215 - samples/sec: 64.06 - lr: 0.000030
2021-06-22 17:19:10,703 epoch 33 - iter 288/322 - loss 0.07979875 - samples/sec: 63.83 - lr: 0.000030
2021-06-22 17:19:26,702 epoch 33 - iter 320/322 - loss 0.07833978 - samples/sec: 64.01 - lr: 0.000030
2021-06-22 17:19:27,447 ----------------------------------------------------------------------------------------------------
2021-06-22 17:19:27,447 EPOCH 33 done: loss 0.0783 - lr 0.0000300
2021-06-22 17:19:34,897 DEV : loss 0.1477040946483612 - score 0.971
2021-06-22 17:19:35,004 BAD EPOCHS (no improvement): 2
2021-06-22 17:19:35,004 ----------------------------------------------------------------------------------------------------
2021-06-22 17:19:51,048 epoch 34 - iter 32/322 - loss 0.09177950 - samples/sec: 63.84 - lr: 0.000030
2021-06-22 17:20:07,013 epoch 34 - iter 64/322 - loss 0.08246331 - samples/sec: 64.15 - lr: 0.000030
2021-06-22 17:20:23,062 epoch 34 - iter 96/322 - loss 0.07634461 - samples/sec: 63.81 - lr: 0.000030
2021-06-22 17:20:39,092 epoch 34 - iter 128/322 - loss 0.07770732 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 17:20:54,987 epoch 34 - iter 160/322 - loss 0.07675216 - samples/sec: 64.43 - lr: 0.000030
2021-06-22 17:21:11,057 epoch 34 - iter 192/322 - loss 0.07613107 - samples/sec: 63.73 - lr: 0.000030
2021-06-22 17:21:27,043 epoch 34 - iter 224/322 - loss 0.07500435 - samples/sec: 64.06 - lr: 0.000030
2021-06-22 17:21:43,136 epoch 34 - iter 256/322 - loss 0.07430438 - samples/sec: 63.64 - lr: 0.000030
2021-06-22 17:21:59,943 epoch 34 - iter 288/322 - loss 0.07705374 - samples/sec: 60.93 - lr: 0.000030
2021-06-22 17:22:16,021 epoch 34 - iter 320/322 - loss 0.07879032 - samples/sec: 63.70 - lr: 0.000030
2021-06-22 17:22:16,784 ----------------------------------------------------------------------------------------------------
2021-06-22 17:22:16,785 EPOCH 34 done: loss 0.0788 - lr 0.0000300
2021-06-22 17:22:24,230 DEV : loss 0.16010946035385132 - score 0.9696
2021-06-22 17:22:24,337 BAD EPOCHS (no improvement): 3
2021-06-22 17:22:24,337 ----------------------------------------------------------------------------------------------------
2021-06-22 17:22:40,377 epoch 35 - iter 32/322 - loss 0.09095013 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 17:22:56,439 epoch 35 - iter 64/322 - loss 0.07638669 - samples/sec: 63.76 - lr: 0.000030
2021-06-22 17:23:12,496 epoch 35 - iter 96/322 - loss 0.07600104 - samples/sec: 63.78 - lr: 0.000030
2021-06-22 17:23:28,480 epoch 35 - iter 128/322 - loss 0.07589325 - samples/sec: 64.07 - lr: 0.000030
2021-06-22 17:23:44,471 epoch 35 - iter 160/322 - loss 0.07626675 - samples/sec: 64.04 - lr: 0.000030
2021-06-22 17:24:00,460 epoch 35 - iter 192/322 - loss 0.07614143 - samples/sec: 64.05 - lr: 0.000030
2021-06-22 17:24:16,489 epoch 35 - iter 224/322 - loss 0.07816883 - samples/sec: 63.89 - lr: 0.000030
2021-06-22 17:24:32,527 epoch 35 - iter 256/322 - loss 0.07770067 - samples/sec: 63.85 - lr: 0.000030
2021-06-22 17:24:48,591 epoch 35 - iter 288/322 - loss 0.07766708 - samples/sec: 63.75 - lr: 0.000030
2021-06-22 17:25:04,710 epoch 35 - iter 320/322 - loss 0.07753587 - samples/sec: 63.53 - lr: 0.000030
2021-06-22 17:25:05,462 ----------------------------------------------------------------------------------------------------
2021-06-22 17:25:05,463 EPOCH 35 done: loss 0.0779 - lr 0.0000300
2021-06-22 17:25:12,912 DEV : loss 0.15704070031642914 - score 0.9711
Epoch    35: reducing learning rate of group 0 to 1.5000e-05.
2021-06-22 17:25:13,019 BAD EPOCHS (no improvement): 4
2021-06-22 17:25:13,019 ----------------------------------------------------------------------------------------------------
2021-06-22 17:25:29,053 epoch 36 - iter 32/322 - loss 0.07514147 - samples/sec: 63.87 - lr: 0.000015
2021-06-22 17:25:45,090 epoch 36 - iter 64/322 - loss 0.07197629 - samples/sec: 63.86 - lr: 0.000015
2021-06-22 17:26:01,149 epoch 36 - iter 96/322 - loss 0.07101412 - samples/sec: 63.77 - lr: 0.000015
2021-06-22 17:26:17,061 epoch 36 - iter 128/322 - loss 0.07018375 - samples/sec: 64.36 - lr: 0.000015
2021-06-22 17:26:33,053 epoch 36 - iter 160/322 - loss 0.07589988 - samples/sec: 64.04 - lr: 0.000015
2021-06-22 17:26:49,095 epoch 36 - iter 192/322 - loss 0.07407824 - samples/sec: 63.84 - lr: 0.000015
2021-06-22 17:27:05,130 epoch 36 - iter 224/322 - loss 0.07516270 - samples/sec: 63.87 - lr: 0.000015
2021-06-22 17:27:21,190 epoch 36 - iter 256/322 - loss 0.07477359 - samples/sec: 63.77 - lr: 0.000015
2021-06-22 17:27:37,255 epoch 36 - iter 288/322 - loss 0.07393832 - samples/sec: 63.75 - lr: 0.000015
2021-06-22 17:27:53,233 epoch 36 - iter 320/322 - loss 0.07382061 - samples/sec: 64.10 - lr: 0.000015
2021-06-22 17:27:53,995 ----------------------------------------------------------------------------------------------------
2021-06-22 17:27:53,995 EPOCH 36 done: loss 0.0737 - lr 0.0000150
2021-06-22 17:28:01,440 DEV : loss 0.15042968094348907 - score 0.9718
2021-06-22 17:28:01,548 BAD EPOCHS (no improvement): 1
2021-06-22 17:28:01,548 ----------------------------------------------------------------------------------------------------
2021-06-22 17:28:17,592 epoch 37 - iter 32/322 - loss 0.06954605 - samples/sec: 63.83 - lr: 0.000015
2021-06-22 17:28:33,655 epoch 37 - iter 64/322 - loss 0.06117725 - samples/sec: 63.76 - lr: 0.000015
2021-06-22 17:28:49,661 epoch 37 - iter 96/322 - loss 0.07536680 - samples/sec: 63.98 - lr: 0.000015
2021-06-22 17:29:05,641 epoch 37 - iter 128/322 - loss 0.07404859 - samples/sec: 64.09 - lr: 0.000015
2021-06-22 17:29:21,694 epoch 37 - iter 160/322 - loss 0.07222951 - samples/sec: 63.80 - lr: 0.000015
2021-06-22 17:29:37,741 epoch 37 - iter 192/322 - loss 0.07424688 - samples/sec: 63.82 - lr: 0.000015
2021-06-22 17:29:53,751 epoch 37 - iter 224/322 - loss 0.07136215 - samples/sec: 63.97 - lr: 0.000015
2021-06-22 17:30:09,759 epoch 37 - iter 256/322 - loss 0.07028997 - samples/sec: 63.98 - lr: 0.000015
2021-06-22 17:30:25,759 epoch 37 - iter 288/322 - loss 0.06953008 - samples/sec: 64.01 - lr: 0.000015
2021-06-22 17:30:41,679 epoch 37 - iter 320/322 - loss 0.06871136 - samples/sec: 64.33 - lr: 0.000015
2021-06-22 17:30:42,431 ----------------------------------------------------------------------------------------------------
2021-06-22 17:30:42,432 EPOCH 37 done: loss 0.0684 - lr 0.0000150
2021-06-22 17:30:49,875 DEV : loss 0.1521436870098114 - score 0.9722
2021-06-22 17:30:49,983 BAD EPOCHS (no improvement): 2
2021-06-22 17:30:49,984 ----------------------------------------------------------------------------------------------------
2021-06-22 17:31:06,777 epoch 38 - iter 32/322 - loss 0.05596934 - samples/sec: 60.98 - lr: 0.000015
2021-06-22 17:31:22,818 epoch 38 - iter 64/322 - loss 0.06145131 - samples/sec: 63.85 - lr: 0.000015
2021-06-22 17:31:38,734 epoch 38 - iter 96/322 - loss 0.06055526 - samples/sec: 64.35 - lr: 0.000015
2021-06-22 17:31:54,737 epoch 38 - iter 128/322 - loss 0.06279270 - samples/sec: 63.99 - lr: 0.000015
2021-06-22 17:32:10,814 epoch 38 - iter 160/322 - loss 0.06301738 - samples/sec: 63.70 - lr: 0.000015
2021-06-22 17:32:26,932 epoch 38 - iter 192/322 - loss 0.06221748 - samples/sec: 63.54 - lr: 0.000015
2021-06-22 17:32:43,046 epoch 38 - iter 224/322 - loss 0.06312834 - samples/sec: 63.55 - lr: 0.000015
2021-06-22 17:32:59,160 epoch 38 - iter 256/322 - loss 0.06190068 - samples/sec: 63.55 - lr: 0.000015
2021-06-22 17:33:15,218 epoch 38 - iter 288/322 - loss 0.06249316 - samples/sec: 63.78 - lr: 0.000015
2021-06-22 17:33:31,327 epoch 38 - iter 320/322 - loss 0.06454785 - samples/sec: 63.57 - lr: 0.000015
2021-06-22 17:33:32,080 ----------------------------------------------------------------------------------------------------
2021-06-22 17:33:32,080 EPOCH 38 done: loss 0.0642 - lr 0.0000150
2021-06-22 17:33:39,536 DEV : loss 0.16291984915733337 - score 0.9726
2021-06-22 17:33:39,643 BAD EPOCHS (no improvement): 0
saving best model
2021-06-22 17:33:45,223 ----------------------------------------------------------------------------------------------------
2021-06-22 17:34:01,377 epoch 39 - iter 32/322 - loss 0.05752919 - samples/sec: 63.40 - lr: 0.000015
2021-06-22 17:34:17,460 epoch 39 - iter 64/322 - loss 0.06190783 - samples/sec: 63.68 - lr: 0.000015
2021-06-22 17:34:33,521 epoch 39 - iter 96/322 - loss 0.06430172 - samples/sec: 63.76 - lr: 0.000015
2021-06-22 17:34:49,673 epoch 39 - iter 128/322 - loss 0.06293911 - samples/sec: 63.41 - lr: 0.000015
2021-06-22 17:35:05,803 epoch 39 - iter 160/322 - loss 0.06752682 - samples/sec: 63.49 - lr: 0.000015
2021-06-22 17:35:21,900 epoch 39 - iter 192/322 - loss 0.06506395 - samples/sec: 63.62 - lr: 0.000015
2021-06-22 17:35:38,024 epoch 39 - iter 224/322 - loss 0.06651978 - samples/sec: 63.51 - lr: 0.000015
2021-06-22 17:35:54,128 epoch 39 - iter 256/322 - loss 0.06849616 - samples/sec: 63.59 - lr: 0.000015
2021-06-22 17:36:10,148 epoch 39 - iter 288/322 - loss 0.06720483 - samples/sec: 63.93 - lr: 0.000015
2021-06-22 17:36:26,274 epoch 39 - iter 320/322 - loss 0.06686391 - samples/sec: 63.51 - lr: 0.000015
2021-06-22 17:36:27,036 ----------------------------------------------------------------------------------------------------
2021-06-22 17:36:27,036 EPOCH 39 done: loss 0.0666 - lr 0.0000150
2021-06-22 17:36:34,477 DEV : loss 0.16075845062732697 - score 0.9726
2021-06-22 17:36:34,585 BAD EPOCHS (no improvement): 1
2021-06-22 17:36:34,585 ----------------------------------------------------------------------------------------------------
2021-06-22 17:36:50,711 epoch 40 - iter 32/322 - loss 0.05658092 - samples/sec: 63.51 - lr: 0.000015
2021-06-22 17:37:06,821 epoch 40 - iter 64/322 - loss 0.05775786 - samples/sec: 63.57 - lr: 0.000015
2021-06-22 17:37:22,945 epoch 40 - iter 96/322 - loss 0.05816158 - samples/sec: 63.51 - lr: 0.000015
2021-06-22 17:37:39,032 epoch 40 - iter 128/322 - loss 0.06217973 - samples/sec: 63.66 - lr: 0.000015
2021-06-22 17:37:55,067 epoch 40 - iter 160/322 - loss 0.06333817 - samples/sec: 63.87 - lr: 0.000015
2021-06-22 17:38:11,164 epoch 40 - iter 192/322 - loss 0.06451261 - samples/sec: 63.62 - lr: 0.000015
2021-06-22 17:38:27,237 epoch 40 - iter 224/322 - loss 0.06270109 - samples/sec: 63.72 - lr: 0.000015
2021-06-22 17:38:43,333 epoch 40 - iter 256/322 - loss 0.06400372 - samples/sec: 63.63 - lr: 0.000015
2021-06-22 17:38:59,498 epoch 40 - iter 288/322 - loss 0.06540867 - samples/sec: 63.35 - lr: 0.000015
2021-06-22 17:39:15,638 epoch 40 - iter 320/322 - loss 0.06460897 - samples/sec: 63.45 - lr: 0.000015
2021-06-22 17:39:16,393 ----------------------------------------------------------------------------------------------------
2021-06-22 17:39:16,393 EPOCH 40 done: loss 0.0644 - lr 0.0000150
2021-06-22 17:39:23,849 DEV : loss 0.15661410987377167 - score 0.9714
2021-06-22 17:39:23,956 BAD EPOCHS (no improvement): 2
2021-06-22 17:39:24,495 ----------------------------------------------------------------------------------------------------
2021-06-22 17:39:24,495 Testing using best model ...
2021-06-22 17:39:24,495 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/best-model.pt
2021-06-22 17:39:43,154 0.9673	0.9819	0.9746
2021-06-22 17:39:43,155 
Results:
- F1-score (micro) 0.9746
- F1-score (macro) 0.9746

By class:
SENT       tp: 1303 - fp: 44 - fn: 24 - precision: 0.9673 - recall: 0.9819 - f1-score: 0.9746
2021-06-22 17:39:43,155 ----------------------------------------------------------------------------------------------------
