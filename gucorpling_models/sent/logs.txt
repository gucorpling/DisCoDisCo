/home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/
2021-05-27 12:29:28,505 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb
2021-05-27 12:29:28,505 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/sent_train.txt
2021-05-27 12:29:28,505 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/sent_dev.txt
2021-05-27 12:29:28,505 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/sent_test.txt
Corpus: 2538 train + 541 dev + 490 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 12:29:37,281 ----------------------------------------------------------------------------------------------------
2021-05-27 12:29:37,283 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 12:29:37,283 ----------------------------------------------------------------------------------------------------
2021-05-27 12:29:37,283 Corpus: "Corpus: 2538 train + 541 dev + 490 test sentences"
2021-05-27 12:29:37,283 ----------------------------------------------------------------------------------------------------
2021-05-27 12:29:37,283 Parameters:
2021-05-27 12:29:37,283  - learning_rate: "0.1"
2021-05-27 12:29:37,283  - mini_batch_size: "32"
2021-05-27 12:29:37,283  - patience: "3"
2021-05-27 12:29:37,283  - anneal_factor: "0.5"
2021-05-27 12:29:37,283  - max_epochs: "30"
2021-05-27 12:29:37,283  - shuffle: "True"
2021-05-27 12:29:37,283  - train_with_dev: "False"
2021-05-27 12:29:37,283  - batch_growth_annealing: "False"
2021-05-27 12:29:37,283 ----------------------------------------------------------------------------------------------------
2021-05-27 12:29:37,283 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb"
2021-05-27 12:29:37,283 ----------------------------------------------------------------------------------------------------
2021-05-27 12:29:37,283 Device: cuda:0
2021-05-27 12:29:37,283 ----------------------------------------------------------------------------------------------------
2021-05-27 12:29:37,283 Embeddings storage mode: cpu
2021-05-27 12:29:37,284 ----------------------------------------------------------------------------------------------------
2021-05-27 12:29:46,424 epoch 1 - iter 8/80 - loss 5.77540195 - samples/sec: 28.01 - lr: 0.100000
2021-05-27 12:29:55,799 epoch 1 - iter 16/80 - loss 4.97148809 - samples/sec: 27.31 - lr: 0.100000
2021-05-27 12:30:05,043 epoch 1 - iter 24/80 - loss 4.81572331 - samples/sec: 27.70 - lr: 0.100000
2021-05-27 12:30:14,334 epoch 1 - iter 32/80 - loss 4.53717257 - samples/sec: 27.55 - lr: 0.100000
2021-05-27 12:30:23,637 epoch 1 - iter 40/80 - loss 4.35819872 - samples/sec: 27.52 - lr: 0.100000
2021-05-27 12:30:32,925 epoch 1 - iter 48/80 - loss 4.18579767 - samples/sec: 27.56 - lr: 0.100000
2021-05-27 12:30:42,449 epoch 1 - iter 56/80 - loss 4.02930329 - samples/sec: 26.88 - lr: 0.100000
2021-05-27 12:30:51,860 epoch 1 - iter 64/80 - loss 3.95559777 - samples/sec: 27.20 - lr: 0.100000
2021-05-27 12:31:01,199 epoch 1 - iter 72/80 - loss 3.84683889 - samples/sec: 27.42 - lr: 0.100000
2021-05-27 12:31:09,813 epoch 1 - iter 80/80 - loss 3.68088249 - samples/sec: 29.72 - lr: 0.100000
2021-05-27 12:31:09,813 ----------------------------------------------------------------------------------------------------
2021-05-27 12:31:09,813 EPOCH 1 done: loss 3.6809 - lr 0.1000000
2021-05-27 12:31:23,797 DEV : loss 1.3219306468963623 - score 0.2515
2021-05-27 12:31:23,848 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:31:24,835 ----------------------------------------------------------------------------------------------------
2021-05-27 12:31:28,350 epoch 2 - iter 8/80 - loss 2.47380507 - samples/sec: 72.84 - lr: 0.100000
2021-05-27 12:31:32,210 epoch 2 - iter 16/80 - loss 2.35654285 - samples/sec: 66.33 - lr: 0.100000
2021-05-27 12:31:35,820 epoch 2 - iter 24/80 - loss 2.29165757 - samples/sec: 70.92 - lr: 0.100000
2021-05-27 12:31:39,375 epoch 2 - iter 32/80 - loss 2.20784730 - samples/sec: 72.03 - lr: 0.100000
2021-05-27 12:31:42,968 epoch 2 - iter 40/80 - loss 2.18896790 - samples/sec: 71.27 - lr: 0.100000
2021-05-27 12:31:46,573 epoch 2 - iter 48/80 - loss 2.07091817 - samples/sec: 71.03 - lr: 0.100000
2021-05-27 12:31:50,145 epoch 2 - iter 56/80 - loss 2.00124642 - samples/sec: 71.68 - lr: 0.100000
2021-05-27 12:31:53,721 epoch 2 - iter 64/80 - loss 1.91646636 - samples/sec: 71.60 - lr: 0.100000
2021-05-27 12:31:57,289 epoch 2 - iter 72/80 - loss 1.84766132 - samples/sec: 71.77 - lr: 0.100000
2021-05-27 12:32:00,611 epoch 2 - iter 80/80 - loss 1.80469562 - samples/sec: 77.08 - lr: 0.100000
2021-05-27 12:32:00,611 ----------------------------------------------------------------------------------------------------
2021-05-27 12:32:00,611 EPOCH 2 done: loss 1.8047 - lr 0.1000000
2021-05-27 12:32:03,431 DEV : loss 0.573747992515564 - score 0.8903
2021-05-27 12:32:03,482 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:32:13,402 ----------------------------------------------------------------------------------------------------
2021-05-27 12:32:17,005 epoch 3 - iter 8/80 - loss 1.09682503 - samples/sec: 71.06 - lr: 0.100000
2021-05-27 12:32:20,584 epoch 3 - iter 16/80 - loss 1.21830776 - samples/sec: 71.54 - lr: 0.100000
2021-05-27 12:32:24,174 epoch 3 - iter 24/80 - loss 1.14392080 - samples/sec: 71.33 - lr: 0.100000
2021-05-27 12:32:27,750 epoch 3 - iter 32/80 - loss 1.10903094 - samples/sec: 71.60 - lr: 0.100000
2021-05-27 12:32:31,326 epoch 3 - iter 40/80 - loss 1.13609027 - samples/sec: 71.60 - lr: 0.100000
2021-05-27 12:32:34,920 epoch 3 - iter 48/80 - loss 1.16198268 - samples/sec: 71.24 - lr: 0.100000
2021-05-27 12:32:38,467 epoch 3 - iter 56/80 - loss 1.13458347 - samples/sec: 72.18 - lr: 0.100000
2021-05-27 12:32:42,060 epoch 3 - iter 64/80 - loss 1.14981830 - samples/sec: 71.26 - lr: 0.100000
2021-05-27 12:32:45,643 epoch 3 - iter 72/80 - loss 1.10897144 - samples/sec: 71.47 - lr: 0.100000
2021-05-27 12:32:48,959 epoch 3 - iter 80/80 - loss 1.08175057 - samples/sec: 77.23 - lr: 0.100000
2021-05-27 12:32:48,959 ----------------------------------------------------------------------------------------------------
2021-05-27 12:32:48,959 EPOCH 3 done: loss 1.0818 - lr 0.1000000
2021-05-27 12:32:51,802 DEV : loss 0.5072826147079468 - score 0.9113
2021-05-27 12:32:51,854 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:33:00,500 ----------------------------------------------------------------------------------------------------
2021-05-27 12:33:04,103 epoch 4 - iter 8/80 - loss 0.92291611 - samples/sec: 71.08 - lr: 0.100000
2021-05-27 12:33:07,684 epoch 4 - iter 16/80 - loss 0.86698134 - samples/sec: 71.51 - lr: 0.100000
2021-05-27 12:33:11,272 epoch 4 - iter 24/80 - loss 0.93228459 - samples/sec: 71.36 - lr: 0.100000
2021-05-27 12:33:14,860 epoch 4 - iter 32/80 - loss 0.92105959 - samples/sec: 71.37 - lr: 0.100000
2021-05-27 12:33:18,472 epoch 4 - iter 40/80 - loss 0.89383448 - samples/sec: 70.89 - lr: 0.100000
2021-05-27 12:33:22,101 epoch 4 - iter 48/80 - loss 0.89509990 - samples/sec: 70.57 - lr: 0.100000
2021-05-27 12:33:26,025 epoch 4 - iter 56/80 - loss 0.83964584 - samples/sec: 65.25 - lr: 0.100000
2021-05-27 12:33:29,610 epoch 4 - iter 64/80 - loss 0.83810675 - samples/sec: 71.41 - lr: 0.100000
2021-05-27 12:33:33,199 epoch 4 - iter 72/80 - loss 0.87068386 - samples/sec: 71.34 - lr: 0.100000
2021-05-27 12:33:36,526 epoch 4 - iter 80/80 - loss 0.86919062 - samples/sec: 76.98 - lr: 0.100000
2021-05-27 12:33:36,526 ----------------------------------------------------------------------------------------------------
2021-05-27 12:33:36,526 EPOCH 4 done: loss 0.8692 - lr 0.1000000
2021-05-27 12:33:39,347 DEV : loss 0.39934203028678894 - score 0.9122
2021-05-27 12:33:39,399 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:33:47,941 ----------------------------------------------------------------------------------------------------
2021-05-27 12:33:51,512 epoch 5 - iter 8/80 - loss 0.63216904 - samples/sec: 71.72 - lr: 0.100000
2021-05-27 12:33:55,083 epoch 5 - iter 16/80 - loss 0.61310849 - samples/sec: 71.69 - lr: 0.100000
2021-05-27 12:33:58,696 epoch 5 - iter 24/80 - loss 0.70677379 - samples/sec: 70.87 - lr: 0.100000
2021-05-27 12:34:02,280 epoch 5 - iter 32/80 - loss 0.72682083 - samples/sec: 71.44 - lr: 0.100000
2021-05-27 12:34:05,870 epoch 5 - iter 40/80 - loss 0.69702321 - samples/sec: 71.32 - lr: 0.100000
2021-05-27 12:34:09,482 epoch 5 - iter 48/80 - loss 0.71374192 - samples/sec: 70.90 - lr: 0.100000
2021-05-27 12:34:13,063 epoch 5 - iter 56/80 - loss 0.74735837 - samples/sec: 71.51 - lr: 0.100000
2021-05-27 12:34:16,684 epoch 5 - iter 64/80 - loss 0.76557655 - samples/sec: 70.71 - lr: 0.100000
2021-05-27 12:34:20,268 epoch 5 - iter 72/80 - loss 0.78501792 - samples/sec: 71.43 - lr: 0.100000
2021-05-27 12:34:23,613 epoch 5 - iter 80/80 - loss 0.79944351 - samples/sec: 76.55 - lr: 0.100000
2021-05-27 12:34:23,614 ----------------------------------------------------------------------------------------------------
2021-05-27 12:34:23,614 EPOCH 5 done: loss 0.7994 - lr 0.1000000
2021-05-27 12:34:26,446 DEV : loss 0.4017470180988312 - score 0.9264
2021-05-27 12:34:26,499 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:34:35,152 ----------------------------------------------------------------------------------------------------
2021-05-27 12:34:38,748 epoch 6 - iter 8/80 - loss 0.91519956 - samples/sec: 71.22 - lr: 0.100000
2021-05-27 12:34:42,348 epoch 6 - iter 16/80 - loss 0.76559033 - samples/sec: 71.12 - lr: 0.100000
2021-05-27 12:34:45,955 epoch 6 - iter 24/80 - loss 0.73102141 - samples/sec: 70.98 - lr: 0.100000
2021-05-27 12:34:49,539 epoch 6 - iter 32/80 - loss 0.66929543 - samples/sec: 71.45 - lr: 0.100000
2021-05-27 12:34:53,125 epoch 6 - iter 40/80 - loss 0.68825230 - samples/sec: 71.40 - lr: 0.100000
2021-05-27 12:34:56,726 epoch 6 - iter 48/80 - loss 0.71091221 - samples/sec: 71.11 - lr: 0.100000
2021-05-27 12:35:00,296 epoch 6 - iter 56/80 - loss 0.70849199 - samples/sec: 71.72 - lr: 0.100000
2021-05-27 12:35:03,907 epoch 6 - iter 64/80 - loss 0.69841673 - samples/sec: 70.92 - lr: 0.100000
2021-05-27 12:35:07,498 epoch 6 - iter 72/80 - loss 0.69753494 - samples/sec: 71.30 - lr: 0.100000
2021-05-27 12:35:10,827 epoch 6 - iter 80/80 - loss 0.70287262 - samples/sec: 76.93 - lr: 0.100000
2021-05-27 12:35:10,827 ----------------------------------------------------------------------------------------------------
2021-05-27 12:35:10,827 EPOCH 6 done: loss 0.7029 - lr 0.1000000
2021-05-27 12:35:13,976 DEV : loss 0.5111727714538574 - score 0.8936
2021-05-27 12:35:14,028 BAD EPOCHS (no improvement): 1
2021-05-27 12:35:14,028 ----------------------------------------------------------------------------------------------------
2021-05-27 12:35:17,605 epoch 7 - iter 8/80 - loss 0.57895449 - samples/sec: 71.58 - lr: 0.100000
2021-05-27 12:35:21,163 epoch 7 - iter 16/80 - loss 0.63710380 - samples/sec: 71.97 - lr: 0.100000
2021-05-27 12:35:24,720 epoch 7 - iter 24/80 - loss 0.64704011 - samples/sec: 71.98 - lr: 0.100000
2021-05-27 12:35:28,272 epoch 7 - iter 32/80 - loss 0.61855925 - samples/sec: 72.09 - lr: 0.100000
2021-05-27 12:35:31,916 epoch 7 - iter 40/80 - loss 0.64593438 - samples/sec: 70.28 - lr: 0.100000
2021-05-27 12:35:35,539 epoch 7 - iter 48/80 - loss 0.63035269 - samples/sec: 70.67 - lr: 0.100000
2021-05-27 12:35:39,156 epoch 7 - iter 56/80 - loss 0.64185932 - samples/sec: 70.79 - lr: 0.100000
2021-05-27 12:35:42,759 epoch 7 - iter 64/80 - loss 0.65194036 - samples/sec: 71.07 - lr: 0.100000
2021-05-27 12:35:46,381 epoch 7 - iter 72/80 - loss 0.66758288 - samples/sec: 70.70 - lr: 0.100000
2021-05-27 12:35:49,677 epoch 7 - iter 80/80 - loss 0.66760169 - samples/sec: 77.70 - lr: 0.100000
2021-05-27 12:35:49,677 ----------------------------------------------------------------------------------------------------
2021-05-27 12:35:49,677 EPOCH 7 done: loss 0.6676 - lr 0.1000000
2021-05-27 12:35:52,520 DEV : loss 0.5376443266868591 - score 0.9016
2021-05-27 12:35:52,573 BAD EPOCHS (no improvement): 2
2021-05-27 12:35:52,573 ----------------------------------------------------------------------------------------------------
2021-05-27 12:35:56,168 epoch 8 - iter 8/80 - loss 0.51944730 - samples/sec: 71.23 - lr: 0.100000
2021-05-27 12:35:59,760 epoch 8 - iter 16/80 - loss 0.64544049 - samples/sec: 71.28 - lr: 0.100000
2021-05-27 12:36:03,327 epoch 8 - iter 24/80 - loss 0.60823871 - samples/sec: 71.79 - lr: 0.100000
2021-05-27 12:36:06,914 epoch 8 - iter 32/80 - loss 0.65279116 - samples/sec: 71.38 - lr: 0.100000
2021-05-27 12:36:10,514 epoch 8 - iter 40/80 - loss 0.63951568 - samples/sec: 71.12 - lr: 0.100000
2021-05-27 12:36:14,091 epoch 8 - iter 48/80 - loss 0.63212750 - samples/sec: 71.59 - lr: 0.100000
2021-05-27 12:36:17,671 epoch 8 - iter 56/80 - loss 0.61384030 - samples/sec: 71.52 - lr: 0.100000
2021-05-27 12:36:21,310 epoch 8 - iter 64/80 - loss 0.62467730 - samples/sec: 70.36 - lr: 0.100000
2021-05-27 12:36:24,897 epoch 8 - iter 72/80 - loss 0.62888229 - samples/sec: 71.39 - lr: 0.100000
2021-05-27 12:36:28,200 epoch 8 - iter 80/80 - loss 0.65608490 - samples/sec: 77.51 - lr: 0.100000
2021-05-27 12:36:28,201 ----------------------------------------------------------------------------------------------------
2021-05-27 12:36:28,201 EPOCH 8 done: loss 0.6561 - lr 0.1000000
2021-05-27 12:36:31,047 DEV : loss 0.3485454022884369 - score 0.9271
2021-05-27 12:36:31,099 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:36:39,787 ----------------------------------------------------------------------------------------------------
2021-05-27 12:36:43,661 epoch 9 - iter 8/80 - loss 0.66178881 - samples/sec: 66.11 - lr: 0.100000
2021-05-27 12:36:47,236 epoch 9 - iter 16/80 - loss 0.64816054 - samples/sec: 71.63 - lr: 0.100000
2021-05-27 12:36:50,811 epoch 9 - iter 24/80 - loss 0.64446837 - samples/sec: 71.62 - lr: 0.100000
2021-05-27 12:36:54,424 epoch 9 - iter 32/80 - loss 0.60590624 - samples/sec: 70.86 - lr: 0.100000
2021-05-27 12:36:57,981 epoch 9 - iter 40/80 - loss 0.58897199 - samples/sec: 71.99 - lr: 0.100000
2021-05-27 12:37:01,569 epoch 9 - iter 48/80 - loss 0.57328129 - samples/sec: 71.36 - lr: 0.100000
2021-05-27 12:37:05,203 epoch 9 - iter 56/80 - loss 0.57141310 - samples/sec: 70.47 - lr: 0.100000
2021-05-27 12:37:08,814 epoch 9 - iter 64/80 - loss 0.62785920 - samples/sec: 70.90 - lr: 0.100000
2021-05-27 12:37:12,409 epoch 9 - iter 72/80 - loss 0.61304505 - samples/sec: 71.23 - lr: 0.100000
2021-05-27 12:37:15,717 epoch 9 - iter 80/80 - loss 0.60461567 - samples/sec: 77.40 - lr: 0.100000
2021-05-27 12:37:15,717 ----------------------------------------------------------------------------------------------------
2021-05-27 12:37:15,717 EPOCH 9 done: loss 0.6046 - lr 0.1000000
2021-05-27 12:37:18,555 DEV : loss 0.4158787429332733 - score 0.9244
2021-05-27 12:37:18,607 BAD EPOCHS (no improvement): 1
2021-05-27 12:37:18,608 ----------------------------------------------------------------------------------------------------
2021-05-27 12:37:22,156 epoch 10 - iter 8/80 - loss 0.44345147 - samples/sec: 72.16 - lr: 0.100000
2021-05-27 12:37:25,779 epoch 10 - iter 16/80 - loss 0.55836260 - samples/sec: 70.68 - lr: 0.100000
2021-05-27 12:37:29,369 epoch 10 - iter 24/80 - loss 0.56301018 - samples/sec: 71.33 - lr: 0.100000
2021-05-27 12:37:32,991 epoch 10 - iter 32/80 - loss 0.55672981 - samples/sec: 70.68 - lr: 0.100000
2021-05-27 12:37:36,591 epoch 10 - iter 40/80 - loss 0.57243448 - samples/sec: 71.14 - lr: 0.100000
2021-05-27 12:37:40,177 epoch 10 - iter 48/80 - loss 0.59857613 - samples/sec: 71.40 - lr: 0.100000
2021-05-27 12:37:43,729 epoch 10 - iter 56/80 - loss 0.64198421 - samples/sec: 72.09 - lr: 0.100000
2021-05-27 12:37:47,294 epoch 10 - iter 64/80 - loss 0.62517091 - samples/sec: 71.81 - lr: 0.100000
2021-05-27 12:37:50,879 epoch 10 - iter 72/80 - loss 0.62844606 - samples/sec: 71.43 - lr: 0.100000
2021-05-27 12:37:54,176 epoch 10 - iter 80/80 - loss 0.61873758 - samples/sec: 77.65 - lr: 0.100000
2021-05-27 12:37:54,177 ----------------------------------------------------------------------------------------------------
2021-05-27 12:37:54,177 EPOCH 10 done: loss 0.6187 - lr 0.1000000
2021-05-27 12:37:57,018 DEV : loss 0.34920814633369446 - score 0.9258
2021-05-27 12:37:57,071 BAD EPOCHS (no improvement): 2
2021-05-27 12:37:57,071 ----------------------------------------------------------------------------------------------------
2021-05-27 12:38:00,630 epoch 11 - iter 8/80 - loss 0.46850625 - samples/sec: 71.95 - lr: 0.100000
2021-05-27 12:38:04,256 epoch 11 - iter 16/80 - loss 0.49919840 - samples/sec: 70.62 - lr: 0.100000
2021-05-27 12:38:07,826 epoch 11 - iter 24/80 - loss 0.57634336 - samples/sec: 71.71 - lr: 0.100000
2021-05-27 12:38:11,437 epoch 11 - iter 32/80 - loss 0.58332176 - samples/sec: 70.91 - lr: 0.100000
2021-05-27 12:38:15,010 epoch 11 - iter 40/80 - loss 0.57880352 - samples/sec: 71.66 - lr: 0.100000
2021-05-27 12:38:18,627 epoch 11 - iter 48/80 - loss 0.57884569 - samples/sec: 70.80 - lr: 0.100000
2021-05-27 12:38:22,200 epoch 11 - iter 56/80 - loss 0.54750363 - samples/sec: 71.66 - lr: 0.100000
2021-05-27 12:38:25,817 epoch 11 - iter 64/80 - loss 0.53652935 - samples/sec: 70.80 - lr: 0.100000
2021-05-27 12:38:29,388 epoch 11 - iter 72/80 - loss 0.53717659 - samples/sec: 71.71 - lr: 0.100000
2021-05-27 12:38:32,714 epoch 11 - iter 80/80 - loss 0.54139346 - samples/sec: 76.97 - lr: 0.100000
2021-05-27 12:38:32,714 ----------------------------------------------------------------------------------------------------
2021-05-27 12:38:32,715 EPOCH 11 done: loss 0.5414 - lr 0.1000000
2021-05-27 12:38:35,555 DEV : loss 0.41577860713005066 - score 0.9164
2021-05-27 12:38:35,607 BAD EPOCHS (no improvement): 3
2021-05-27 12:38:35,607 ----------------------------------------------------------------------------------------------------
2021-05-27 12:38:39,160 epoch 12 - iter 8/80 - loss 0.51172354 - samples/sec: 72.07 - lr: 0.100000
2021-05-27 12:38:42,768 epoch 12 - iter 16/80 - loss 0.59291546 - samples/sec: 70.96 - lr: 0.100000
2021-05-27 12:38:46,349 epoch 12 - iter 24/80 - loss 0.55952427 - samples/sec: 71.51 - lr: 0.100000
2021-05-27 12:38:49,953 epoch 12 - iter 32/80 - loss 0.50790821 - samples/sec: 71.05 - lr: 0.100000
2021-05-27 12:38:53,533 epoch 12 - iter 40/80 - loss 0.47530163 - samples/sec: 71.52 - lr: 0.100000
2021-05-27 12:38:57,082 epoch 12 - iter 48/80 - loss 0.47275354 - samples/sec: 72.15 - lr: 0.100000
2021-05-27 12:39:00,680 epoch 12 - iter 56/80 - loss 0.47360373 - samples/sec: 71.17 - lr: 0.100000
2021-05-27 12:39:04,300 epoch 12 - iter 64/80 - loss 0.49638117 - samples/sec: 70.72 - lr: 0.100000
2021-05-27 12:39:07,870 epoch 12 - iter 72/80 - loss 0.51378811 - samples/sec: 71.72 - lr: 0.100000
2021-05-27 12:39:11,210 epoch 12 - iter 80/80 - loss 0.55551145 - samples/sec: 76.68 - lr: 0.100000
2021-05-27 12:39:11,210 ----------------------------------------------------------------------------------------------------
2021-05-27 12:39:11,210 EPOCH 12 done: loss 0.5555 - lr 0.1000000
2021-05-27 12:39:14,367 DEV : loss 0.3625085651874542 - score 0.9261
Epoch    12: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 12:39:14,419 BAD EPOCHS (no improvement): 4
2021-05-27 12:39:14,420 ----------------------------------------------------------------------------------------------------
2021-05-27 12:39:17,977 epoch 13 - iter 8/80 - loss 0.40764709 - samples/sec: 71.97 - lr: 0.050000
2021-05-27 12:39:21,569 epoch 13 - iter 16/80 - loss 0.51372072 - samples/sec: 71.28 - lr: 0.050000
2021-05-27 12:39:25,149 epoch 13 - iter 24/80 - loss 0.49483473 - samples/sec: 71.54 - lr: 0.050000
2021-05-27 12:39:28,767 epoch 13 - iter 32/80 - loss 0.48666850 - samples/sec: 70.76 - lr: 0.050000
2021-05-27 12:39:32,396 epoch 13 - iter 40/80 - loss 0.46458942 - samples/sec: 70.56 - lr: 0.050000
2021-05-27 12:39:35,983 epoch 13 - iter 48/80 - loss 0.46024160 - samples/sec: 71.40 - lr: 0.050000
2021-05-27 12:39:39,547 epoch 13 - iter 56/80 - loss 0.45311122 - samples/sec: 71.83 - lr: 0.050000
2021-05-27 12:39:43,137 epoch 13 - iter 64/80 - loss 0.44954477 - samples/sec: 71.33 - lr: 0.050000
2021-05-27 12:39:46,705 epoch 13 - iter 72/80 - loss 0.47428681 - samples/sec: 71.75 - lr: 0.050000
2021-05-27 12:39:50,025 epoch 13 - iter 80/80 - loss 0.47092721 - samples/sec: 77.14 - lr: 0.050000
2021-05-27 12:39:50,025 ----------------------------------------------------------------------------------------------------
2021-05-27 12:39:50,025 EPOCH 13 done: loss 0.4709 - lr 0.0500000
2021-05-27 12:39:52,865 DEV : loss 0.33482861518859863 - score 0.922
2021-05-27 12:39:52,917 BAD EPOCHS (no improvement): 1
2021-05-27 12:39:52,917 ----------------------------------------------------------------------------------------------------
2021-05-27 12:39:56,523 epoch 14 - iter 8/80 - loss 0.46330136 - samples/sec: 71.01 - lr: 0.050000
2021-05-27 12:40:00,123 epoch 14 - iter 16/80 - loss 0.49232765 - samples/sec: 71.14 - lr: 0.050000
2021-05-27 12:40:03,695 epoch 14 - iter 24/80 - loss 0.49353385 - samples/sec: 71.68 - lr: 0.050000
2021-05-27 12:40:07,277 epoch 14 - iter 32/80 - loss 0.45801896 - samples/sec: 71.48 - lr: 0.050000
2021-05-27 12:40:10,860 epoch 14 - iter 40/80 - loss 0.45764225 - samples/sec: 71.45 - lr: 0.050000
2021-05-27 12:40:14,468 epoch 14 - iter 48/80 - loss 0.47006369 - samples/sec: 70.98 - lr: 0.050000
2021-05-27 12:40:18,071 epoch 14 - iter 56/80 - loss 0.46611325 - samples/sec: 71.06 - lr: 0.050000
2021-05-27 12:40:21,678 epoch 14 - iter 64/80 - loss 0.44562045 - samples/sec: 71.00 - lr: 0.050000
2021-05-27 12:40:25,295 epoch 14 - iter 72/80 - loss 0.43560062 - samples/sec: 70.77 - lr: 0.050000
2021-05-27 12:40:28,593 epoch 14 - iter 80/80 - loss 0.45936485 - samples/sec: 77.64 - lr: 0.050000
2021-05-27 12:40:28,593 ----------------------------------------------------------------------------------------------------
2021-05-27 12:40:28,594 EPOCH 14 done: loss 0.4594 - lr 0.0500000
2021-05-27 12:40:31,426 DEV : loss 0.5639854073524475 - score 0.8847
2021-05-27 12:40:31,479 BAD EPOCHS (no improvement): 2
2021-05-27 12:40:31,479 ----------------------------------------------------------------------------------------------------
2021-05-27 12:40:35,090 epoch 15 - iter 8/80 - loss 0.68669543 - samples/sec: 70.91 - lr: 0.050000
2021-05-27 12:40:38,722 epoch 15 - iter 16/80 - loss 0.55495918 - samples/sec: 70.48 - lr: 0.050000
2021-05-27 12:40:42,320 epoch 15 - iter 24/80 - loss 0.51959445 - samples/sec: 71.18 - lr: 0.050000
2021-05-27 12:40:45,926 epoch 15 - iter 32/80 - loss 0.46616810 - samples/sec: 71.00 - lr: 0.050000
2021-05-27 12:40:49,513 epoch 15 - iter 40/80 - loss 0.47000882 - samples/sec: 71.39 - lr: 0.050000
2021-05-27 12:40:53,132 epoch 15 - iter 48/80 - loss 0.48337581 - samples/sec: 70.74 - lr: 0.050000
2021-05-27 12:40:56,694 epoch 15 - iter 56/80 - loss 0.46317873 - samples/sec: 71.89 - lr: 0.050000
2021-05-27 12:41:00,266 epoch 15 - iter 64/80 - loss 0.45173172 - samples/sec: 71.68 - lr: 0.050000
2021-05-27 12:41:04,182 epoch 15 - iter 72/80 - loss 0.45934183 - samples/sec: 65.39 - lr: 0.050000
2021-05-27 12:41:07,495 epoch 15 - iter 80/80 - loss 0.44618490 - samples/sec: 77.29 - lr: 0.050000
2021-05-27 12:41:07,495 ----------------------------------------------------------------------------------------------------
2021-05-27 12:41:07,495 EPOCH 15 done: loss 0.4462 - lr 0.0500000
2021-05-27 12:41:10,330 DEV : loss 0.31851285696029663 - score 0.9316
2021-05-27 12:41:10,383 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:41:18,871 ----------------------------------------------------------------------------------------------------
2021-05-27 12:41:22,450 epoch 16 - iter 8/80 - loss 0.38334837 - samples/sec: 71.55 - lr: 0.050000
2021-05-27 12:41:26,032 epoch 16 - iter 16/80 - loss 0.33778782 - samples/sec: 71.49 - lr: 0.050000
2021-05-27 12:41:29,659 epoch 16 - iter 24/80 - loss 0.35588853 - samples/sec: 70.59 - lr: 0.050000
2021-05-27 12:41:33,233 epoch 16 - iter 32/80 - loss 0.35798820 - samples/sec: 71.65 - lr: 0.050000
2021-05-27 12:41:36,844 epoch 16 - iter 40/80 - loss 0.39304864 - samples/sec: 70.92 - lr: 0.050000
2021-05-27 12:41:40,439 epoch 16 - iter 48/80 - loss 0.39070043 - samples/sec: 71.21 - lr: 0.050000
2021-05-27 12:41:44,033 epoch 16 - iter 56/80 - loss 0.39397923 - samples/sec: 71.26 - lr: 0.050000
2021-05-27 12:41:47,636 epoch 16 - iter 64/80 - loss 0.38881037 - samples/sec: 71.06 - lr: 0.050000
2021-05-27 12:41:51,232 epoch 16 - iter 72/80 - loss 0.38501358 - samples/sec: 71.21 - lr: 0.050000
2021-05-27 12:41:54,549 epoch 16 - iter 80/80 - loss 0.39917187 - samples/sec: 77.19 - lr: 0.050000
2021-05-27 12:41:54,549 ----------------------------------------------------------------------------------------------------
2021-05-27 12:41:54,549 EPOCH 16 done: loss 0.3992 - lr 0.0500000
2021-05-27 12:41:57,388 DEV : loss 0.3091350793838501 - score 0.926
2021-05-27 12:41:57,441 BAD EPOCHS (no improvement): 1
2021-05-27 12:41:57,441 ----------------------------------------------------------------------------------------------------
2021-05-27 12:42:01,011 epoch 17 - iter 8/80 - loss 0.37738030 - samples/sec: 71.73 - lr: 0.050000
2021-05-27 12:42:04,557 epoch 17 - iter 16/80 - loss 0.34270434 - samples/sec: 72.19 - lr: 0.050000
2021-05-27 12:42:08,133 epoch 17 - iter 24/80 - loss 0.38307594 - samples/sec: 71.62 - lr: 0.050000
2021-05-27 12:42:11,778 epoch 17 - iter 32/80 - loss 0.40532950 - samples/sec: 70.25 - lr: 0.050000
2021-05-27 12:42:15,374 epoch 17 - iter 40/80 - loss 0.39754482 - samples/sec: 71.19 - lr: 0.050000
2021-05-27 12:42:18,941 epoch 17 - iter 48/80 - loss 0.39612679 - samples/sec: 71.78 - lr: 0.050000
2021-05-27 12:42:22,534 epoch 17 - iter 56/80 - loss 0.40533970 - samples/sec: 71.28 - lr: 0.050000
2021-05-27 12:42:26,138 epoch 17 - iter 64/80 - loss 0.39780922 - samples/sec: 71.05 - lr: 0.050000
2021-05-27 12:42:29,693 epoch 17 - iter 72/80 - loss 0.39818988 - samples/sec: 72.01 - lr: 0.050000
2021-05-27 12:42:33,010 epoch 17 - iter 80/80 - loss 0.42314166 - samples/sec: 77.21 - lr: 0.050000
2021-05-27 12:42:33,010 ----------------------------------------------------------------------------------------------------
2021-05-27 12:42:33,010 EPOCH 17 done: loss 0.4231 - lr 0.0500000
2021-05-27 12:42:36,170 DEV : loss 0.2991924583911896 - score 0.9449
2021-05-27 12:42:36,222 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:42:44,892 ----------------------------------------------------------------------------------------------------
2021-05-27 12:42:48,487 epoch 18 - iter 8/80 - loss 0.31190241 - samples/sec: 71.24 - lr: 0.050000
2021-05-27 12:42:52,061 epoch 18 - iter 16/80 - loss 0.39045393 - samples/sec: 71.64 - lr: 0.050000
2021-05-27 12:42:55,659 epoch 18 - iter 24/80 - loss 0.35980713 - samples/sec: 71.18 - lr: 0.050000
2021-05-27 12:42:59,248 epoch 18 - iter 32/80 - loss 0.36719022 - samples/sec: 71.34 - lr: 0.050000
2021-05-27 12:43:02,830 epoch 18 - iter 40/80 - loss 0.39641104 - samples/sec: 71.48 - lr: 0.050000
2021-05-27 12:43:06,429 epoch 18 - iter 48/80 - loss 0.40949294 - samples/sec: 71.14 - lr: 0.050000
2021-05-27 12:43:10,030 epoch 18 - iter 56/80 - loss 0.41148920 - samples/sec: 71.10 - lr: 0.050000
2021-05-27 12:43:13,612 epoch 18 - iter 64/80 - loss 0.41441929 - samples/sec: 71.49 - lr: 0.050000
2021-05-27 12:43:17,175 epoch 18 - iter 72/80 - loss 0.41397360 - samples/sec: 71.86 - lr: 0.050000
2021-05-27 12:43:20,481 epoch 18 - iter 80/80 - loss 0.40833420 - samples/sec: 77.46 - lr: 0.050000
2021-05-27 12:43:20,481 ----------------------------------------------------------------------------------------------------
2021-05-27 12:43:20,481 EPOCH 18 done: loss 0.4083 - lr 0.0500000
2021-05-27 12:43:23,320 DEV : loss 0.30521276593208313 - score 0.9274
2021-05-27 12:43:23,371 BAD EPOCHS (no improvement): 1
2021-05-27 12:43:23,372 ----------------------------------------------------------------------------------------------------
2021-05-27 12:43:26,962 epoch 19 - iter 8/80 - loss 0.39132203 - samples/sec: 71.31 - lr: 0.050000
2021-05-27 12:43:30,535 epoch 19 - iter 16/80 - loss 0.33657251 - samples/sec: 71.67 - lr: 0.050000
2021-05-27 12:43:34,137 epoch 19 - iter 24/80 - loss 0.34668673 - samples/sec: 71.09 - lr: 0.050000
2021-05-27 12:43:37,739 epoch 19 - iter 32/80 - loss 0.34097269 - samples/sec: 71.09 - lr: 0.050000
2021-05-27 12:43:41,300 epoch 19 - iter 40/80 - loss 0.36723253 - samples/sec: 71.91 - lr: 0.050000
2021-05-27 12:43:44,885 epoch 19 - iter 48/80 - loss 0.38801266 - samples/sec: 71.41 - lr: 0.050000
2021-05-27 12:43:48,515 epoch 19 - iter 56/80 - loss 0.36509013 - samples/sec: 70.55 - lr: 0.050000
2021-05-27 12:43:52,095 epoch 19 - iter 64/80 - loss 0.37158056 - samples/sec: 71.52 - lr: 0.050000
2021-05-27 12:43:55,673 epoch 19 - iter 72/80 - loss 0.38798945 - samples/sec: 71.55 - lr: 0.050000
2021-05-27 12:43:58,982 epoch 19 - iter 80/80 - loss 0.39578858 - samples/sec: 77.40 - lr: 0.050000
2021-05-27 12:43:58,982 ----------------------------------------------------------------------------------------------------
2021-05-27 12:43:58,982 EPOCH 19 done: loss 0.3958 - lr 0.0500000
2021-05-27 12:44:01,816 DEV : loss 0.3209875822067261 - score 0.9289
2021-05-27 12:44:01,868 BAD EPOCHS (no improvement): 2
2021-05-27 12:44:01,868 ----------------------------------------------------------------------------------------------------
2021-05-27 12:44:05,462 epoch 20 - iter 8/80 - loss 0.46624789 - samples/sec: 71.26 - lr: 0.050000
2021-05-27 12:44:09,063 epoch 20 - iter 16/80 - loss 0.46954169 - samples/sec: 71.09 - lr: 0.050000
2021-05-27 12:44:12,634 epoch 20 - iter 24/80 - loss 0.42747629 - samples/sec: 71.71 - lr: 0.050000
2021-05-27 12:44:16,197 epoch 20 - iter 32/80 - loss 0.40785520 - samples/sec: 71.86 - lr: 0.050000
2021-05-27 12:44:19,802 epoch 20 - iter 40/80 - loss 0.38604404 - samples/sec: 71.02 - lr: 0.050000
2021-05-27 12:44:23,382 epoch 20 - iter 48/80 - loss 0.38767306 - samples/sec: 71.52 - lr: 0.050000
2021-05-27 12:44:26,972 epoch 20 - iter 56/80 - loss 0.40091076 - samples/sec: 71.32 - lr: 0.050000
2021-05-27 12:44:30,549 epoch 20 - iter 64/80 - loss 0.39809661 - samples/sec: 71.60 - lr: 0.050000
2021-05-27 12:44:34,157 epoch 20 - iter 72/80 - loss 0.39715016 - samples/sec: 70.97 - lr: 0.050000
2021-05-27 12:44:37,481 epoch 20 - iter 80/80 - loss 0.39571863 - samples/sec: 77.04 - lr: 0.050000
2021-05-27 12:44:37,481 ----------------------------------------------------------------------------------------------------
2021-05-27 12:44:37,481 EPOCH 20 done: loss 0.3957 - lr 0.0500000
2021-05-27 12:44:40,642 DEV : loss 0.3105930685997009 - score 0.9375
2021-05-27 12:44:40,694 BAD EPOCHS (no improvement): 3
2021-05-27 12:44:40,694 ----------------------------------------------------------------------------------------------------
2021-05-27 12:44:44,274 epoch 21 - iter 8/80 - loss 0.40298674 - samples/sec: 71.52 - lr: 0.050000
2021-05-27 12:44:47,880 epoch 21 - iter 16/80 - loss 0.41492869 - samples/sec: 71.01 - lr: 0.050000
2021-05-27 12:44:51,470 epoch 21 - iter 24/80 - loss 0.41059670 - samples/sec: 71.32 - lr: 0.050000
2021-05-27 12:44:55,044 epoch 21 - iter 32/80 - loss 0.40295048 - samples/sec: 71.65 - lr: 0.050000
2021-05-27 12:44:58,651 epoch 21 - iter 40/80 - loss 0.40947759 - samples/sec: 70.99 - lr: 0.050000
2021-05-27 12:45:02,260 epoch 21 - iter 48/80 - loss 0.39982336 - samples/sec: 70.95 - lr: 0.050000
2021-05-27 12:45:05,870 epoch 21 - iter 56/80 - loss 0.38421760 - samples/sec: 70.93 - lr: 0.050000
2021-05-27 12:45:09,427 epoch 21 - iter 64/80 - loss 0.39704290 - samples/sec: 71.99 - lr: 0.050000
2021-05-27 12:45:13,020 epoch 21 - iter 72/80 - loss 0.38582330 - samples/sec: 71.26 - lr: 0.050000
2021-05-27 12:45:16,341 epoch 21 - iter 80/80 - loss 0.39477034 - samples/sec: 77.10 - lr: 0.050000
2021-05-27 12:45:16,341 ----------------------------------------------------------------------------------------------------
2021-05-27 12:45:16,341 EPOCH 21 done: loss 0.3948 - lr 0.0500000
2021-05-27 12:45:19,176 DEV : loss 0.295231431722641 - score 0.9372
Epoch    21: reducing learning rate of group 0 to 2.5000e-02.
2021-05-27 12:45:19,228 BAD EPOCHS (no improvement): 4
2021-05-27 12:45:19,229 ----------------------------------------------------------------------------------------------------
2021-05-27 12:45:22,768 epoch 22 - iter 8/80 - loss 0.27510741 - samples/sec: 72.35 - lr: 0.025000
2021-05-27 12:45:26,365 epoch 22 - iter 16/80 - loss 0.37735118 - samples/sec: 71.19 - lr: 0.025000
2021-05-27 12:45:29,953 epoch 22 - iter 24/80 - loss 0.37323232 - samples/sec: 71.36 - lr: 0.025000
2021-05-27 12:45:33,535 epoch 22 - iter 32/80 - loss 0.36667484 - samples/sec: 71.48 - lr: 0.025000
2021-05-27 12:45:37,138 epoch 22 - iter 40/80 - loss 0.33345646 - samples/sec: 71.07 - lr: 0.025000
2021-05-27 12:45:40,740 epoch 22 - iter 48/80 - loss 0.34530330 - samples/sec: 71.07 - lr: 0.025000
2021-05-27 12:45:44,312 epoch 22 - iter 56/80 - loss 0.35053243 - samples/sec: 71.69 - lr: 0.025000
2021-05-27 12:45:47,924 epoch 22 - iter 64/80 - loss 0.35645871 - samples/sec: 70.89 - lr: 0.025000
2021-05-27 12:45:51,537 epoch 22 - iter 72/80 - loss 0.34937481 - samples/sec: 70.88 - lr: 0.025000
2021-05-27 12:45:54,833 epoch 22 - iter 80/80 - loss 0.34596885 - samples/sec: 77.68 - lr: 0.025000
2021-05-27 12:45:54,833 ----------------------------------------------------------------------------------------------------
2021-05-27 12:45:54,833 EPOCH 22 done: loss 0.3460 - lr 0.0250000
2021-05-27 12:45:57,671 DEV : loss 0.34602752327919006 - score 0.9208
2021-05-27 12:45:57,723 BAD EPOCHS (no improvement): 1
2021-05-27 12:45:57,724 ----------------------------------------------------------------------------------------------------
2021-05-27 12:46:01,297 epoch 23 - iter 8/80 - loss 0.34048843 - samples/sec: 71.65 - lr: 0.025000
2021-05-27 12:46:04,864 epoch 23 - iter 16/80 - loss 0.31451995 - samples/sec: 71.79 - lr: 0.025000
2021-05-27 12:46:08,448 epoch 23 - iter 24/80 - loss 0.35781407 - samples/sec: 71.44 - lr: 0.025000
2021-05-27 12:46:12,025 epoch 23 - iter 32/80 - loss 0.34754541 - samples/sec: 71.58 - lr: 0.025000
2021-05-27 12:46:15,625 epoch 23 - iter 40/80 - loss 0.35137300 - samples/sec: 71.13 - lr: 0.025000
2021-05-27 12:46:19,185 epoch 23 - iter 48/80 - loss 0.35364809 - samples/sec: 71.92 - lr: 0.025000
2021-05-27 12:46:22,736 epoch 23 - iter 56/80 - loss 0.35242260 - samples/sec: 72.11 - lr: 0.025000
2021-05-27 12:46:26,310 epoch 23 - iter 64/80 - loss 0.34309758 - samples/sec: 71.65 - lr: 0.025000
2021-05-27 12:46:29,898 epoch 23 - iter 72/80 - loss 0.32893761 - samples/sec: 71.35 - lr: 0.025000
2021-05-27 12:46:33,251 epoch 23 - iter 80/80 - loss 0.34564307 - samples/sec: 76.38 - lr: 0.025000
2021-05-27 12:46:33,251 ----------------------------------------------------------------------------------------------------
2021-05-27 12:46:33,251 EPOCH 23 done: loss 0.3456 - lr 0.0250000
2021-05-27 12:46:36,411 DEV : loss 0.3079380989074707 - score 0.9343
2021-05-27 12:46:36,464 BAD EPOCHS (no improvement): 2
2021-05-27 12:46:36,464 ----------------------------------------------------------------------------------------------------
2021-05-27 12:46:40,031 epoch 24 - iter 8/80 - loss 0.31766762 - samples/sec: 71.78 - lr: 0.025000
2021-05-27 12:46:43,619 epoch 24 - iter 16/80 - loss 0.28658977 - samples/sec: 71.36 - lr: 0.025000
2021-05-27 12:46:47,210 epoch 24 - iter 24/80 - loss 0.31645647 - samples/sec: 71.32 - lr: 0.025000
2021-05-27 12:46:50,820 epoch 24 - iter 32/80 - loss 0.32236639 - samples/sec: 70.92 - lr: 0.025000
2021-05-27 12:46:54,394 epoch 24 - iter 40/80 - loss 0.32741243 - samples/sec: 71.65 - lr: 0.025000
2021-05-27 12:46:57,987 epoch 24 - iter 48/80 - loss 0.33964763 - samples/sec: 71.26 - lr: 0.025000
2021-05-27 12:47:01,584 epoch 24 - iter 56/80 - loss 0.33681910 - samples/sec: 71.18 - lr: 0.025000
2021-05-27 12:47:05,224 epoch 24 - iter 64/80 - loss 0.33792128 - samples/sec: 70.35 - lr: 0.025000
2021-05-27 12:47:08,826 epoch 24 - iter 72/80 - loss 0.34128076 - samples/sec: 71.07 - lr: 0.025000
2021-05-27 12:47:12,154 epoch 24 - iter 80/80 - loss 0.34940150 - samples/sec: 76.94 - lr: 0.025000
2021-05-27 12:47:12,155 ----------------------------------------------------------------------------------------------------
2021-05-27 12:47:12,155 EPOCH 24 done: loss 0.3494 - lr 0.0250000
2021-05-27 12:47:14,992 DEV : loss 0.30869436264038086 - score 0.93
2021-05-27 12:47:15,044 BAD EPOCHS (no improvement): 3
2021-05-27 12:47:15,044 ----------------------------------------------------------------------------------------------------
2021-05-27 12:47:18,631 epoch 25 - iter 8/80 - loss 0.37420005 - samples/sec: 71.39 - lr: 0.025000
2021-05-27 12:47:22,241 epoch 25 - iter 16/80 - loss 0.34372953 - samples/sec: 70.92 - lr: 0.025000
2021-05-27 12:47:25,829 epoch 25 - iter 24/80 - loss 0.36206256 - samples/sec: 71.37 - lr: 0.025000
2021-05-27 12:47:29,458 epoch 25 - iter 32/80 - loss 0.32158213 - samples/sec: 70.54 - lr: 0.025000
2021-05-27 12:47:33,064 epoch 25 - iter 40/80 - loss 0.33735971 - samples/sec: 71.02 - lr: 0.025000
2021-05-27 12:47:36,644 epoch 25 - iter 48/80 - loss 0.32965267 - samples/sec: 71.52 - lr: 0.025000
2021-05-27 12:47:40,226 epoch 25 - iter 56/80 - loss 0.33337321 - samples/sec: 71.49 - lr: 0.025000
2021-05-27 12:47:43,815 epoch 25 - iter 64/80 - loss 0.34082752 - samples/sec: 71.33 - lr: 0.025000
2021-05-27 12:47:47,427 epoch 25 - iter 72/80 - loss 0.35134400 - samples/sec: 70.88 - lr: 0.025000
2021-05-27 12:47:50,664 epoch 25 - iter 80/80 - loss 0.34828083 - samples/sec: 79.11 - lr: 0.025000
2021-05-27 12:47:50,664 ----------------------------------------------------------------------------------------------------
2021-05-27 12:47:50,664 EPOCH 25 done: loss 0.3483 - lr 0.0250000
2021-05-27 12:47:53,494 DEV : loss 0.288652241230011 - score 0.9338
Epoch    25: reducing learning rate of group 0 to 1.2500e-02.
2021-05-27 12:47:53,547 BAD EPOCHS (no improvement): 4
2021-05-27 12:47:53,547 ----------------------------------------------------------------------------------------------------
2021-05-27 12:47:57,412 epoch 26 - iter 8/80 - loss 0.30610272 - samples/sec: 66.25 - lr: 0.012500
2021-05-27 12:48:01,006 epoch 26 - iter 16/80 - loss 0.32373057 - samples/sec: 71.24 - lr: 0.012500
2021-05-27 12:48:04,646 epoch 26 - iter 24/80 - loss 0.33067927 - samples/sec: 70.34 - lr: 0.012500
2021-05-27 12:48:08,215 epoch 26 - iter 32/80 - loss 0.32012166 - samples/sec: 71.74 - lr: 0.012500
2021-05-27 12:48:11,785 epoch 26 - iter 40/80 - loss 0.33730455 - samples/sec: 71.73 - lr: 0.012500
2021-05-27 12:48:15,371 epoch 26 - iter 48/80 - loss 0.32704357 - samples/sec: 71.40 - lr: 0.012500
2021-05-27 12:48:18,955 epoch 26 - iter 56/80 - loss 0.32945829 - samples/sec: 71.45 - lr: 0.012500
2021-05-27 12:48:22,552 epoch 26 - iter 64/80 - loss 0.31982089 - samples/sec: 71.19 - lr: 0.012500
2021-05-27 12:48:26,125 epoch 26 - iter 72/80 - loss 0.32662745 - samples/sec: 71.66 - lr: 0.012500
2021-05-27 12:48:29,442 epoch 26 - iter 80/80 - loss 0.33192395 - samples/sec: 77.19 - lr: 0.012500
2021-05-27 12:48:29,442 ----------------------------------------------------------------------------------------------------
2021-05-27 12:48:29,442 EPOCH 26 done: loss 0.3319 - lr 0.0125000
2021-05-27 12:48:32,279 DEV : loss 0.2973305881023407 - score 0.9363
2021-05-27 12:48:32,332 BAD EPOCHS (no improvement): 1
2021-05-27 12:48:32,332 ----------------------------------------------------------------------------------------------------
2021-05-27 12:48:35,908 epoch 27 - iter 8/80 - loss 0.26923558 - samples/sec: 71.61 - lr: 0.012500
2021-05-27 12:48:39,496 epoch 27 - iter 16/80 - loss 0.31112441 - samples/sec: 71.36 - lr: 0.012500
2021-05-27 12:48:43,082 epoch 27 - iter 24/80 - loss 0.31299901 - samples/sec: 71.41 - lr: 0.012500
2021-05-27 12:48:46,679 epoch 27 - iter 32/80 - loss 0.30940000 - samples/sec: 71.19 - lr: 0.012500
2021-05-27 12:48:50,232 epoch 27 - iter 40/80 - loss 0.29982405 - samples/sec: 72.06 - lr: 0.012500
2021-05-27 12:48:53,811 epoch 27 - iter 48/80 - loss 0.30978251 - samples/sec: 71.54 - lr: 0.012500
2021-05-27 12:48:57,416 epoch 27 - iter 56/80 - loss 0.31879225 - samples/sec: 71.03 - lr: 0.012500
2021-05-27 12:49:00,994 epoch 27 - iter 64/80 - loss 0.31878496 - samples/sec: 71.57 - lr: 0.012500
2021-05-27 12:49:04,582 epoch 27 - iter 72/80 - loss 0.32776429 - samples/sec: 71.37 - lr: 0.012500
2021-05-27 12:49:07,876 epoch 27 - iter 80/80 - loss 0.32184549 - samples/sec: 77.73 - lr: 0.012500
2021-05-27 12:49:07,876 ----------------------------------------------------------------------------------------------------
2021-05-27 12:49:07,876 EPOCH 27 done: loss 0.3218 - lr 0.0125000
2021-05-27 12:49:10,712 DEV : loss 0.29749777913093567 - score 0.9409
2021-05-27 12:49:10,764 BAD EPOCHS (no improvement): 2
2021-05-27 12:49:10,764 ----------------------------------------------------------------------------------------------------
2021-05-27 12:49:14,359 epoch 28 - iter 8/80 - loss 0.23182132 - samples/sec: 71.24 - lr: 0.012500
2021-05-27 12:49:17,955 epoch 28 - iter 16/80 - loss 0.24912819 - samples/sec: 71.19 - lr: 0.012500
2021-05-27 12:49:21,543 epoch 28 - iter 24/80 - loss 0.28281023 - samples/sec: 71.37 - lr: 0.012500
2021-05-27 12:49:25,116 epoch 28 - iter 32/80 - loss 0.28752661 - samples/sec: 71.67 - lr: 0.012500
2021-05-27 12:49:28,687 epoch 28 - iter 40/80 - loss 0.29093840 - samples/sec: 71.71 - lr: 0.012500
2021-05-27 12:49:32,269 epoch 28 - iter 48/80 - loss 0.28649800 - samples/sec: 71.47 - lr: 0.012500
2021-05-27 12:49:35,809 epoch 28 - iter 56/80 - loss 0.30976516 - samples/sec: 72.34 - lr: 0.012500
2021-05-27 12:49:39,399 epoch 28 - iter 64/80 - loss 0.31493505 - samples/sec: 71.32 - lr: 0.012500
2021-05-27 12:49:42,960 epoch 28 - iter 72/80 - loss 0.32827498 - samples/sec: 71.92 - lr: 0.012500
2021-05-27 12:49:46,277 epoch 28 - iter 80/80 - loss 0.32316812 - samples/sec: 77.18 - lr: 0.012500
2021-05-27 12:49:46,278 ----------------------------------------------------------------------------------------------------
2021-05-27 12:49:46,278 EPOCH 28 done: loss 0.3232 - lr 0.0125000
2021-05-27 12:49:49,113 DEV : loss 0.3070167899131775 - score 0.931
2021-05-27 12:49:49,166 BAD EPOCHS (no improvement): 3
2021-05-27 12:49:49,166 ----------------------------------------------------------------------------------------------------
2021-05-27 12:49:52,738 epoch 29 - iter 8/80 - loss 0.37648175 - samples/sec: 71.69 - lr: 0.012500
2021-05-27 12:49:56,340 epoch 29 - iter 16/80 - loss 0.35555282 - samples/sec: 71.08 - lr: 0.012500
2021-05-27 12:49:59,912 epoch 29 - iter 24/80 - loss 0.33403282 - samples/sec: 71.68 - lr: 0.012500
2021-05-27 12:50:03,516 epoch 29 - iter 32/80 - loss 0.31492610 - samples/sec: 71.04 - lr: 0.012500
2021-05-27 12:50:07,058 epoch 29 - iter 40/80 - loss 0.33274990 - samples/sec: 72.31 - lr: 0.012500
2021-05-27 12:50:10,614 epoch 29 - iter 48/80 - loss 0.31645783 - samples/sec: 71.99 - lr: 0.012500
2021-05-27 12:50:14,175 epoch 29 - iter 56/80 - loss 0.32885500 - samples/sec: 71.91 - lr: 0.012500
2021-05-27 12:50:17,752 epoch 29 - iter 64/80 - loss 0.32611667 - samples/sec: 71.58 - lr: 0.012500
2021-05-27 12:50:21,316 epoch 29 - iter 72/80 - loss 0.32249194 - samples/sec: 71.83 - lr: 0.012500
2021-05-27 12:50:24,648 epoch 29 - iter 80/80 - loss 0.32282248 - samples/sec: 76.86 - lr: 0.012500
2021-05-27 12:50:24,648 ----------------------------------------------------------------------------------------------------
2021-05-27 12:50:24,648 EPOCH 29 done: loss 0.3228 - lr 0.0125000
2021-05-27 12:50:27,798 DEV : loss 0.2958317995071411 - score 0.9382
Epoch    29: reducing learning rate of group 0 to 6.2500e-03.
2021-05-27 12:50:27,850 BAD EPOCHS (no improvement): 4
2021-05-27 12:50:27,851 ----------------------------------------------------------------------------------------------------
2021-05-27 12:50:31,424 epoch 30 - iter 8/80 - loss 0.21789455 - samples/sec: 71.66 - lr: 0.006250
2021-05-27 12:50:35,005 epoch 30 - iter 16/80 - loss 0.26383954 - samples/sec: 71.50 - lr: 0.006250
2021-05-27 12:50:38,597 epoch 30 - iter 24/80 - loss 0.27558599 - samples/sec: 71.29 - lr: 0.006250
2021-05-27 12:50:42,159 epoch 30 - iter 32/80 - loss 0.27714440 - samples/sec: 71.89 - lr: 0.006250
2021-05-27 12:50:45,717 epoch 30 - iter 40/80 - loss 0.29358346 - samples/sec: 71.96 - lr: 0.006250
2021-05-27 12:50:49,283 epoch 30 - iter 48/80 - loss 0.29469347 - samples/sec: 71.79 - lr: 0.006250
2021-05-27 12:50:52,892 epoch 30 - iter 56/80 - loss 0.28794540 - samples/sec: 70.95 - lr: 0.006250
2021-05-27 12:50:56,440 epoch 30 - iter 64/80 - loss 0.29816095 - samples/sec: 72.17 - lr: 0.006250
2021-05-27 12:51:00,028 epoch 30 - iter 72/80 - loss 0.30079129 - samples/sec: 71.35 - lr: 0.006250
2021-05-27 12:51:03,324 epoch 30 - iter 80/80 - loss 0.31454578 - samples/sec: 77.71 - lr: 0.006250
2021-05-27 12:51:03,324 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:03,324 EPOCH 30 done: loss 0.3145 - lr 0.0062500
2021-05-27 12:51:06,161 DEV : loss 0.3054106533527374 - score 0.9309
2021-05-27 12:51:06,213 BAD EPOCHS (no improvement): 1
2021-05-27 12:51:07,210 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:07,210 Testing using best model ...
2021-05-27 12:51:07,211 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/zho.pdtb.cdtb/best-model.pt
2021-05-27 12:51:20,073 0.9380	0.8985	0.9178
2021-05-27 12:51:20,073 
Results:
- F1-score (micro) 0.9178
- F1-score (macro) 0.9178

By class:
SENT       tp: 363 - fp: 24 - fn: 41 - precision: 0.9380 - recall: 0.8985 - f1-score: 0.9178
2021-05-27 12:51:20,073 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/
2021-05-27 12:51:20,102 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb
2021-05-27 12:51:20,102 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/sent_train.txt
2021-05-27 12:51:20,102 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/sent_dev.txt
2021-05-27 12:51:20,102 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/sent_test.txt
Corpus: 2146 train + 371 dev + 396 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 12:51:27,358 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:27,361 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 12:51:27,361 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:27,361 Corpus: "Corpus: 2146 train + 371 dev + 396 test sentences"
2021-05-27 12:51:27,361 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:27,361 Parameters:
2021-05-27 12:51:27,362  - learning_rate: "0.1"
2021-05-27 12:51:27,362  - mini_batch_size: "32"
2021-05-27 12:51:27,362  - patience: "3"
2021-05-27 12:51:27,362  - anneal_factor: "0.5"
2021-05-27 12:51:27,362  - max_epochs: "30"
2021-05-27 12:51:27,362  - shuffle: "True"
2021-05-27 12:51:27,362  - train_with_dev: "False"
2021-05-27 12:51:27,362  - batch_growth_annealing: "False"
2021-05-27 12:51:27,362 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:27,362 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb"
2021-05-27 12:51:27,362 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:27,362 Device: cuda:0
2021-05-27 12:51:27,362 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:27,362 Embeddings storage mode: cpu
2021-05-27 12:51:27,365 ----------------------------------------------------------------------------------------------------
2021-05-27 12:51:34,996 epoch 1 - iter 6/68 - loss 9.24712245 - samples/sec: 25.16 - lr: 0.100000
2021-05-27 12:51:42,759 epoch 1 - iter 12/68 - loss 7.22244368 - samples/sec: 24.73 - lr: 0.100000
2021-05-27 12:51:50,227 epoch 1 - iter 18/68 - loss 5.96538521 - samples/sec: 25.71 - lr: 0.100000
2021-05-27 12:51:57,624 epoch 1 - iter 24/68 - loss 5.10847844 - samples/sec: 25.96 - lr: 0.100000
2021-05-27 12:52:05,120 epoch 1 - iter 30/68 - loss 4.61749056 - samples/sec: 25.62 - lr: 0.100000
2021-05-27 12:52:12,678 epoch 1 - iter 36/68 - loss 4.27912859 - samples/sec: 25.40 - lr: 0.100000
2021-05-27 12:52:20,208 epoch 1 - iter 42/68 - loss 3.96865374 - samples/sec: 25.50 - lr: 0.100000
2021-05-27 12:52:27,678 epoch 1 - iter 48/68 - loss 3.69146278 - samples/sec: 25.71 - lr: 0.100000
2021-05-27 12:52:35,187 epoch 1 - iter 54/68 - loss 3.42629724 - samples/sec: 25.57 - lr: 0.100000
2021-05-27 12:52:42,714 epoch 1 - iter 60/68 - loss 3.22042296 - samples/sec: 25.51 - lr: 0.100000
2021-05-27 12:52:50,366 epoch 1 - iter 66/68 - loss 3.09883348 - samples/sec: 25.09 - lr: 0.100000
2021-05-27 12:52:51,948 ----------------------------------------------------------------------------------------------------
2021-05-27 12:52:51,949 EPOCH 1 done: loss 3.0386 - lr 0.1000000
2021-05-27 12:53:01,598 DEV : loss 0.45477256178855896 - score 0.8771
2021-05-27 12:53:01,633 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:53:02,665 ----------------------------------------------------------------------------------------------------
2021-05-27 12:53:05,612 epoch 2 - iter 6/68 - loss 1.04491876 - samples/sec: 65.18 - lr: 0.100000
2021-05-27 12:53:08,578 epoch 2 - iter 12/68 - loss 0.89220771 - samples/sec: 64.75 - lr: 0.100000
2021-05-27 12:53:11,568 epoch 2 - iter 18/68 - loss 0.95001280 - samples/sec: 64.22 - lr: 0.100000
2021-05-27 12:53:14,528 epoch 2 - iter 24/68 - loss 0.97950509 - samples/sec: 64.89 - lr: 0.100000
2021-05-27 12:53:17,475 epoch 2 - iter 30/68 - loss 0.96073143 - samples/sec: 65.15 - lr: 0.100000
2021-05-27 12:53:20,402 epoch 2 - iter 36/68 - loss 0.90465511 - samples/sec: 65.62 - lr: 0.100000
2021-05-27 12:53:23,381 epoch 2 - iter 42/68 - loss 0.94703397 - samples/sec: 64.47 - lr: 0.100000
2021-05-27 12:53:26,330 epoch 2 - iter 48/68 - loss 0.93673399 - samples/sec: 65.12 - lr: 0.100000
2021-05-27 12:53:29,251 epoch 2 - iter 54/68 - loss 0.89652422 - samples/sec: 65.73 - lr: 0.100000
2021-05-27 12:53:32,233 epoch 2 - iter 60/68 - loss 0.90521922 - samples/sec: 64.41 - lr: 0.100000
2021-05-27 12:53:35,186 epoch 2 - iter 66/68 - loss 0.95731062 - samples/sec: 65.04 - lr: 0.100000
2021-05-27 12:53:35,767 ----------------------------------------------------------------------------------------------------
2021-05-27 12:53:35,767 EPOCH 2 done: loss 0.9461 - lr 0.1000000
2021-05-27 12:53:37,884 DEV : loss 0.2704465985298157 - score 0.9398
2021-05-27 12:53:37,918 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:53:46,651 ----------------------------------------------------------------------------------------------------
2021-05-27 12:53:49,570 epoch 3 - iter 6/68 - loss 0.77000583 - samples/sec: 65.82 - lr: 0.100000
2021-05-27 12:53:52,525 epoch 3 - iter 12/68 - loss 0.77484201 - samples/sec: 64.98 - lr: 0.100000
2021-05-27 12:53:55,455 epoch 3 - iter 18/68 - loss 0.69527255 - samples/sec: 65.55 - lr: 0.100000
2021-05-27 12:53:58,412 epoch 3 - iter 24/68 - loss 0.67085271 - samples/sec: 64.94 - lr: 0.100000
2021-05-27 12:54:01,340 epoch 3 - iter 30/68 - loss 0.71154790 - samples/sec: 65.60 - lr: 0.100000
2021-05-27 12:54:04,336 epoch 3 - iter 36/68 - loss 0.75757740 - samples/sec: 64.09 - lr: 0.100000
2021-05-27 12:54:07,268 epoch 3 - iter 42/68 - loss 0.71865762 - samples/sec: 65.49 - lr: 0.100000
2021-05-27 12:54:10,167 epoch 3 - iter 48/68 - loss 0.67013142 - samples/sec: 66.26 - lr: 0.100000
2021-05-27 12:54:13,146 epoch 3 - iter 54/68 - loss 0.67321594 - samples/sec: 64.45 - lr: 0.100000
2021-05-27 12:54:16,081 epoch 3 - iter 60/68 - loss 0.67172592 - samples/sec: 65.43 - lr: 0.100000
2021-05-27 12:54:18,996 epoch 3 - iter 66/68 - loss 0.65998901 - samples/sec: 65.88 - lr: 0.100000
2021-05-27 12:54:19,573 ----------------------------------------------------------------------------------------------------
2021-05-27 12:54:19,573 EPOCH 3 done: loss 0.6509 - lr 0.1000000
2021-05-27 12:54:21,904 DEV : loss 0.19384926557540894 - score 0.9526
2021-05-27 12:54:21,939 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:54:31,043 ----------------------------------------------------------------------------------------------------
2021-05-27 12:54:33,986 epoch 4 - iter 6/68 - loss 0.54981068 - samples/sec: 65.26 - lr: 0.100000
2021-05-27 12:54:36,967 epoch 4 - iter 12/68 - loss 0.66326047 - samples/sec: 64.43 - lr: 0.100000
2021-05-27 12:54:39,920 epoch 4 - iter 18/68 - loss 0.66125035 - samples/sec: 65.02 - lr: 0.100000
2021-05-27 12:54:42,796 epoch 4 - iter 24/68 - loss 0.61724295 - samples/sec: 66.77 - lr: 0.100000
2021-05-27 12:54:45,746 epoch 4 - iter 30/68 - loss 0.65764335 - samples/sec: 65.10 - lr: 0.100000
2021-05-27 12:54:48,717 epoch 4 - iter 36/68 - loss 0.63767208 - samples/sec: 64.65 - lr: 0.100000
2021-05-27 12:54:51,669 epoch 4 - iter 42/68 - loss 0.62943762 - samples/sec: 65.05 - lr: 0.100000
2021-05-27 12:54:54,616 epoch 4 - iter 48/68 - loss 0.61723888 - samples/sec: 65.17 - lr: 0.100000
2021-05-27 12:54:57,542 epoch 4 - iter 54/68 - loss 0.61860464 - samples/sec: 65.62 - lr: 0.100000
2021-05-27 12:55:00,489 epoch 4 - iter 60/68 - loss 0.63719612 - samples/sec: 65.16 - lr: 0.100000
2021-05-27 12:55:03,428 epoch 4 - iter 66/68 - loss 0.62595153 - samples/sec: 65.34 - lr: 0.100000
2021-05-27 12:55:03,986 ----------------------------------------------------------------------------------------------------
2021-05-27 12:55:03,986 EPOCH 4 done: loss 0.6324 - lr 0.1000000
2021-05-27 12:55:06,093 DEV : loss 0.17788831889629364 - score 0.9708
2021-05-27 12:55:06,128 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 12:55:14,934 ----------------------------------------------------------------------------------------------------
2021-05-27 12:55:17,889 epoch 5 - iter 6/68 - loss 0.75459919 - samples/sec: 64.98 - lr: 0.100000
2021-05-27 12:55:20,848 epoch 5 - iter 12/68 - loss 0.68695981 - samples/sec: 64.91 - lr: 0.100000
2021-05-27 12:55:23,799 epoch 5 - iter 18/68 - loss 0.74802651 - samples/sec: 65.08 - lr: 0.100000
2021-05-27 12:55:26,765 epoch 5 - iter 24/68 - loss 0.67176512 - samples/sec: 64.74 - lr: 0.100000
2021-05-27 12:55:29,702 epoch 5 - iter 30/68 - loss 0.64993688 - samples/sec: 65.40 - lr: 0.100000
2021-05-27 12:55:32,622 epoch 5 - iter 36/68 - loss 0.64046384 - samples/sec: 65.75 - lr: 0.100000
2021-05-27 12:55:35,556 epoch 5 - iter 42/68 - loss 0.60140024 - samples/sec: 65.46 - lr: 0.100000
2021-05-27 12:55:38,493 epoch 5 - iter 48/68 - loss 0.59291558 - samples/sec: 65.40 - lr: 0.100000
2021-05-27 12:55:41,431 epoch 5 - iter 54/68 - loss 0.58507278 - samples/sec: 65.36 - lr: 0.100000
2021-05-27 12:55:44,313 epoch 5 - iter 60/68 - loss 0.57197987 - samples/sec: 66.64 - lr: 0.100000
2021-05-27 12:55:47,229 epoch 5 - iter 66/68 - loss 0.55784032 - samples/sec: 65.85 - lr: 0.100000
2021-05-27 12:55:47,799 ----------------------------------------------------------------------------------------------------
2021-05-27 12:55:47,800 EPOCH 5 done: loss 0.5509 - lr 0.1000000
2021-05-27 12:55:49,901 DEV : loss 0.18647849559783936 - score 0.9542
2021-05-27 12:55:49,936 BAD EPOCHS (no improvement): 1
2021-05-27 12:55:49,936 ----------------------------------------------------------------------------------------------------
2021-05-27 12:55:52,824 epoch 6 - iter 6/68 - loss 0.39925802 - samples/sec: 66.51 - lr: 0.100000
2021-05-27 12:55:55,776 epoch 6 - iter 12/68 - loss 0.47394073 - samples/sec: 65.06 - lr: 0.100000
2021-05-27 12:55:58,681 epoch 6 - iter 18/68 - loss 0.44327521 - samples/sec: 66.11 - lr: 0.100000
2021-05-27 12:56:01,627 epoch 6 - iter 24/68 - loss 0.56782741 - samples/sec: 65.19 - lr: 0.100000
2021-05-27 12:56:04,592 epoch 6 - iter 30/68 - loss 0.55488578 - samples/sec: 64.76 - lr: 0.100000
2021-05-27 12:56:07,545 epoch 6 - iter 36/68 - loss 0.52563749 - samples/sec: 65.03 - lr: 0.100000
2021-05-27 12:56:10,472 epoch 6 - iter 42/68 - loss 0.50756846 - samples/sec: 65.62 - lr: 0.100000
2021-05-27 12:56:13,460 epoch 6 - iter 48/68 - loss 0.52078996 - samples/sec: 64.27 - lr: 0.100000
2021-05-27 12:56:16,392 epoch 6 - iter 54/68 - loss 0.51399123 - samples/sec: 65.50 - lr: 0.100000
2021-05-27 12:56:19,313 epoch 6 - iter 60/68 - loss 0.48802920 - samples/sec: 65.74 - lr: 0.100000
2021-05-27 12:56:22,281 epoch 6 - iter 66/68 - loss 0.50200960 - samples/sec: 64.71 - lr: 0.100000
2021-05-27 12:56:22,845 ----------------------------------------------------------------------------------------------------
2021-05-27 12:56:22,845 EPOCH 6 done: loss 0.4958 - lr 0.1000000
2021-05-27 12:56:24,950 DEV : loss 0.3037823438644409 - score 0.9304
2021-05-27 12:56:24,985 BAD EPOCHS (no improvement): 2
2021-05-27 12:56:24,985 ----------------------------------------------------------------------------------------------------
2021-05-27 12:56:28,168 epoch 7 - iter 6/68 - loss 0.30779225 - samples/sec: 60.34 - lr: 0.100000
2021-05-27 12:56:31,131 epoch 7 - iter 12/68 - loss 0.50078039 - samples/sec: 64.81 - lr: 0.100000
2021-05-27 12:56:34,097 epoch 7 - iter 18/68 - loss 0.49500264 - samples/sec: 64.74 - lr: 0.100000
2021-05-27 12:56:37,061 epoch 7 - iter 24/68 - loss 0.45448347 - samples/sec: 64.80 - lr: 0.100000
2021-05-27 12:56:39,997 epoch 7 - iter 30/68 - loss 0.44439739 - samples/sec: 65.40 - lr: 0.100000
2021-05-27 12:56:42,936 epoch 7 - iter 36/68 - loss 0.48568009 - samples/sec: 65.35 - lr: 0.100000
2021-05-27 12:56:45,865 epoch 7 - iter 42/68 - loss 0.47256270 - samples/sec: 65.56 - lr: 0.100000
2021-05-27 12:56:48,796 epoch 7 - iter 48/68 - loss 0.49829065 - samples/sec: 65.52 - lr: 0.100000
2021-05-27 12:56:51,718 epoch 7 - iter 54/68 - loss 0.49724725 - samples/sec: 65.72 - lr: 0.100000
2021-05-27 12:56:54,676 epoch 7 - iter 60/68 - loss 0.50461787 - samples/sec: 64.92 - lr: 0.100000
2021-05-27 12:56:57,594 epoch 7 - iter 66/68 - loss 0.51130549 - samples/sec: 65.83 - lr: 0.100000
2021-05-27 12:56:58,156 ----------------------------------------------------------------------------------------------------
2021-05-27 12:56:58,156 EPOCH 7 done: loss 0.5057 - lr 0.1000000
2021-05-27 12:57:00,263 DEV : loss 0.16399560868740082 - score 0.9562
2021-05-27 12:57:00,298 BAD EPOCHS (no improvement): 3
2021-05-27 12:57:00,298 ----------------------------------------------------------------------------------------------------
2021-05-27 12:57:03,187 epoch 8 - iter 6/68 - loss 0.54346162 - samples/sec: 66.47 - lr: 0.100000
2021-05-27 12:57:06,117 epoch 8 - iter 12/68 - loss 0.40387855 - samples/sec: 65.56 - lr: 0.100000
2021-05-27 12:57:09,089 epoch 8 - iter 18/68 - loss 0.37926576 - samples/sec: 64.61 - lr: 0.100000
2021-05-27 12:57:12,025 epoch 8 - iter 24/68 - loss 0.38872564 - samples/sec: 65.41 - lr: 0.100000
2021-05-27 12:57:14,996 epoch 8 - iter 30/68 - loss 0.42080455 - samples/sec: 64.65 - lr: 0.100000
2021-05-27 12:57:17,952 epoch 8 - iter 36/68 - loss 0.41098690 - samples/sec: 64.97 - lr: 0.100000
2021-05-27 12:57:20,863 epoch 8 - iter 42/68 - loss 0.42477018 - samples/sec: 65.97 - lr: 0.100000
2021-05-27 12:57:23,810 epoch 8 - iter 48/68 - loss 0.42535836 - samples/sec: 65.17 - lr: 0.100000
2021-05-27 12:57:26,735 epoch 8 - iter 54/68 - loss 0.42620416 - samples/sec: 65.66 - lr: 0.100000
2021-05-27 12:57:29,680 epoch 8 - iter 60/68 - loss 0.41916793 - samples/sec: 65.20 - lr: 0.100000
2021-05-27 12:57:32,594 epoch 8 - iter 66/68 - loss 0.43423748 - samples/sec: 65.92 - lr: 0.100000
2021-05-27 12:57:33,173 ----------------------------------------------------------------------------------------------------
2021-05-27 12:57:33,173 EPOCH 8 done: loss 0.4259 - lr 0.1000000
2021-05-27 12:57:35,278 DEV : loss 0.16995078325271606 - score 0.9544
Epoch     8: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 12:57:35,313 BAD EPOCHS (no improvement): 4
2021-05-27 12:57:35,314 ----------------------------------------------------------------------------------------------------
2021-05-27 12:57:38,235 epoch 9 - iter 6/68 - loss 0.37533550 - samples/sec: 65.74 - lr: 0.050000
2021-05-27 12:57:41,208 epoch 9 - iter 12/68 - loss 0.42077311 - samples/sec: 64.59 - lr: 0.050000
2021-05-27 12:57:44,154 epoch 9 - iter 18/68 - loss 0.40333032 - samples/sec: 65.20 - lr: 0.050000
2021-05-27 12:57:47,088 epoch 9 - iter 24/68 - loss 0.40968192 - samples/sec: 65.46 - lr: 0.050000
2021-05-27 12:57:49,991 epoch 9 - iter 30/68 - loss 0.40846044 - samples/sec: 66.16 - lr: 0.050000
2021-05-27 12:57:52,906 epoch 9 - iter 36/68 - loss 0.39315733 - samples/sec: 65.87 - lr: 0.050000
2021-05-27 12:57:55,864 epoch 9 - iter 42/68 - loss 0.38257817 - samples/sec: 64.92 - lr: 0.050000
2021-05-27 12:57:58,799 epoch 9 - iter 48/68 - loss 0.37822388 - samples/sec: 65.43 - lr: 0.050000
2021-05-27 12:58:01,738 epoch 9 - iter 54/68 - loss 0.37444769 - samples/sec: 65.36 - lr: 0.050000
2021-05-27 12:58:04,677 epoch 9 - iter 60/68 - loss 0.37376374 - samples/sec: 65.34 - lr: 0.050000
2021-05-27 12:58:07,639 epoch 9 - iter 66/68 - loss 0.36953305 - samples/sec: 64.84 - lr: 0.050000
2021-05-27 12:58:08,203 ----------------------------------------------------------------------------------------------------
2021-05-27 12:58:08,203 EPOCH 9 done: loss 0.3705 - lr 0.0500000
2021-05-27 12:58:10,316 DEV : loss 0.1680418848991394 - score 0.9618
2021-05-27 12:58:10,351 BAD EPOCHS (no improvement): 1
2021-05-27 12:58:10,351 ----------------------------------------------------------------------------------------------------
2021-05-27 12:58:13,512 epoch 10 - iter 6/68 - loss 0.43685547 - samples/sec: 60.75 - lr: 0.050000
2021-05-27 12:58:16,457 epoch 10 - iter 12/68 - loss 0.42245396 - samples/sec: 65.22 - lr: 0.050000
2021-05-27 12:58:19,419 epoch 10 - iter 18/68 - loss 0.39581825 - samples/sec: 64.83 - lr: 0.050000
2021-05-27 12:58:22,338 epoch 10 - iter 24/68 - loss 0.41294970 - samples/sec: 65.79 - lr: 0.050000
2021-05-27 12:58:25,292 epoch 10 - iter 30/68 - loss 0.38302195 - samples/sec: 65.01 - lr: 0.050000
2021-05-27 12:58:28,260 epoch 10 - iter 36/68 - loss 0.36989727 - samples/sec: 64.71 - lr: 0.050000
2021-05-27 12:58:31,213 epoch 10 - iter 42/68 - loss 0.35680389 - samples/sec: 65.04 - lr: 0.050000
2021-05-27 12:58:34,144 epoch 10 - iter 48/68 - loss 0.35210519 - samples/sec: 65.51 - lr: 0.050000
2021-05-27 12:58:37,116 epoch 10 - iter 54/68 - loss 0.34288912 - samples/sec: 64.62 - lr: 0.050000
2021-05-27 12:58:40,073 epoch 10 - iter 60/68 - loss 0.33916274 - samples/sec: 64.94 - lr: 0.050000
2021-05-27 12:58:42,956 epoch 10 - iter 66/68 - loss 0.35158784 - samples/sec: 66.62 - lr: 0.050000
2021-05-27 12:58:43,542 ----------------------------------------------------------------------------------------------------
2021-05-27 12:58:43,542 EPOCH 10 done: loss 0.3455 - lr 0.0500000
2021-05-27 12:58:45,651 DEV : loss 0.15314754843711853 - score 0.9659
2021-05-27 12:58:45,686 BAD EPOCHS (no improvement): 2
2021-05-27 12:58:45,686 ----------------------------------------------------------------------------------------------------
2021-05-27 12:58:48,625 epoch 11 - iter 6/68 - loss 0.34610783 - samples/sec: 65.34 - lr: 0.050000
2021-05-27 12:58:51,544 epoch 11 - iter 12/68 - loss 0.26687124 - samples/sec: 65.81 - lr: 0.050000
2021-05-27 12:58:54,534 epoch 11 - iter 18/68 - loss 0.28133592 - samples/sec: 64.21 - lr: 0.050000
2021-05-27 12:58:57,439 epoch 11 - iter 24/68 - loss 0.31058972 - samples/sec: 66.12 - lr: 0.050000
2021-05-27 12:59:00,364 epoch 11 - iter 30/68 - loss 0.30077880 - samples/sec: 65.66 - lr: 0.050000
2021-05-27 12:59:03,266 epoch 11 - iter 36/68 - loss 0.32263084 - samples/sec: 66.17 - lr: 0.050000
2021-05-27 12:59:06,232 epoch 11 - iter 42/68 - loss 0.32958365 - samples/sec: 64.75 - lr: 0.050000
2021-05-27 12:59:09,152 epoch 11 - iter 48/68 - loss 0.32914204 - samples/sec: 65.75 - lr: 0.050000
2021-05-27 12:59:12,108 epoch 11 - iter 54/68 - loss 0.33507351 - samples/sec: 64.98 - lr: 0.050000
2021-05-27 12:59:15,059 epoch 11 - iter 60/68 - loss 0.33331325 - samples/sec: 65.07 - lr: 0.050000
2021-05-27 12:59:18,007 epoch 11 - iter 66/68 - loss 0.33757420 - samples/sec: 65.14 - lr: 0.050000
2021-05-27 12:59:18,585 ----------------------------------------------------------------------------------------------------
2021-05-27 12:59:18,585 EPOCH 11 done: loss 0.3380 - lr 0.0500000
2021-05-27 12:59:20,691 DEV : loss 0.12804418802261353 - score 0.9655
2021-05-27 12:59:20,726 BAD EPOCHS (no improvement): 3
2021-05-27 12:59:20,726 ----------------------------------------------------------------------------------------------------
2021-05-27 12:59:23,660 epoch 12 - iter 6/68 - loss 0.36790985 - samples/sec: 65.47 - lr: 0.050000
2021-05-27 12:59:26,579 epoch 12 - iter 12/68 - loss 0.35794855 - samples/sec: 65.79 - lr: 0.050000
2021-05-27 12:59:29,529 epoch 12 - iter 18/68 - loss 0.33386935 - samples/sec: 65.10 - lr: 0.050000
2021-05-27 12:59:32,467 epoch 12 - iter 24/68 - loss 0.32650071 - samples/sec: 65.36 - lr: 0.050000
2021-05-27 12:59:35,412 epoch 12 - iter 30/68 - loss 0.31764904 - samples/sec: 65.21 - lr: 0.050000
2021-05-27 12:59:38,359 epoch 12 - iter 36/68 - loss 0.31889190 - samples/sec: 65.16 - lr: 0.050000
2021-05-27 12:59:41,262 epoch 12 - iter 42/68 - loss 0.32958206 - samples/sec: 66.15 - lr: 0.050000
2021-05-27 12:59:44,232 epoch 12 - iter 48/68 - loss 0.33366995 - samples/sec: 64.68 - lr: 0.050000
2021-05-27 12:59:47,182 epoch 12 - iter 54/68 - loss 0.31619675 - samples/sec: 65.09 - lr: 0.050000
2021-05-27 12:59:50,105 epoch 12 - iter 60/68 - loss 0.31247152 - samples/sec: 65.71 - lr: 0.050000
2021-05-27 12:59:53,040 epoch 12 - iter 66/68 - loss 0.30673537 - samples/sec: 65.43 - lr: 0.050000
2021-05-27 12:59:53,611 ----------------------------------------------------------------------------------------------------
2021-05-27 12:59:53,611 EPOCH 12 done: loss 0.3049 - lr 0.0500000
2021-05-27 12:59:55,715 DEV : loss 0.11668723076581955 - score 0.971
2021-05-27 12:59:55,750 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:00:04,944 ----------------------------------------------------------------------------------------------------
2021-05-27 13:00:07,861 epoch 13 - iter 6/68 - loss 0.24119562 - samples/sec: 65.85 - lr: 0.050000
2021-05-27 13:00:10,778 epoch 13 - iter 12/68 - loss 0.28163498 - samples/sec: 65.82 - lr: 0.050000
2021-05-27 13:00:13,714 epoch 13 - iter 18/68 - loss 0.30924349 - samples/sec: 65.42 - lr: 0.050000
2021-05-27 13:00:16,658 epoch 13 - iter 24/68 - loss 0.32085308 - samples/sec: 65.23 - lr: 0.050000
2021-05-27 13:00:19,587 epoch 13 - iter 30/68 - loss 0.33511383 - samples/sec: 65.79 - lr: 0.050000
2021-05-27 13:00:22,556 epoch 13 - iter 36/68 - loss 0.31835379 - samples/sec: 64.69 - lr: 0.050000
2021-05-27 13:00:25,541 epoch 13 - iter 42/68 - loss 0.33163354 - samples/sec: 64.34 - lr: 0.050000
2021-05-27 13:00:28,485 epoch 13 - iter 48/68 - loss 0.31960442 - samples/sec: 65.24 - lr: 0.050000
2021-05-27 13:00:31,440 epoch 13 - iter 54/68 - loss 0.31259407 - samples/sec: 64.98 - lr: 0.050000
2021-05-27 13:00:34,390 epoch 13 - iter 60/68 - loss 0.30392779 - samples/sec: 65.11 - lr: 0.050000
2021-05-27 13:00:37,326 epoch 13 - iter 66/68 - loss 0.31335428 - samples/sec: 65.41 - lr: 0.050000
2021-05-27 13:00:37,900 ----------------------------------------------------------------------------------------------------
2021-05-27 13:00:37,900 EPOCH 13 done: loss 0.3636 - lr 0.0500000
2021-05-27 13:00:40,009 DEV : loss 0.16255640983581543 - score 0.9606
2021-05-27 13:00:40,044 BAD EPOCHS (no improvement): 1
2021-05-27 13:00:40,045 ----------------------------------------------------------------------------------------------------
2021-05-27 13:00:42,953 epoch 14 - iter 6/68 - loss 0.33631515 - samples/sec: 66.03 - lr: 0.050000
2021-05-27 13:00:45,902 epoch 14 - iter 12/68 - loss 0.38377712 - samples/sec: 65.12 - lr: 0.050000
2021-05-27 13:00:48,886 epoch 14 - iter 18/68 - loss 0.35141382 - samples/sec: 64.34 - lr: 0.050000
2021-05-27 13:00:51,835 epoch 14 - iter 24/68 - loss 0.33605250 - samples/sec: 65.14 - lr: 0.050000
2021-05-27 13:00:54,742 epoch 14 - iter 30/68 - loss 0.34828899 - samples/sec: 66.06 - lr: 0.050000
2021-05-27 13:00:57,699 epoch 14 - iter 36/68 - loss 0.32555902 - samples/sec: 64.93 - lr: 0.050000
2021-05-27 13:01:00,656 epoch 14 - iter 42/68 - loss 0.35534378 - samples/sec: 64.95 - lr: 0.050000
2021-05-27 13:01:03,581 epoch 14 - iter 48/68 - loss 0.35499780 - samples/sec: 65.66 - lr: 0.050000
2021-05-27 13:01:06,481 epoch 14 - iter 54/68 - loss 0.35077148 - samples/sec: 66.22 - lr: 0.050000
2021-05-27 13:01:09,431 epoch 14 - iter 60/68 - loss 0.33750184 - samples/sec: 65.10 - lr: 0.050000
2021-05-27 13:01:12,356 epoch 14 - iter 66/68 - loss 0.32559988 - samples/sec: 65.65 - lr: 0.050000
2021-05-27 13:01:12,922 ----------------------------------------------------------------------------------------------------
2021-05-27 13:01:12,922 EPOCH 14 done: loss 0.3283 - lr 0.0500000
2021-05-27 13:01:15,027 DEV : loss 0.12219484150409698 - score 0.9785
2021-05-27 13:01:15,063 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:01:23,965 ----------------------------------------------------------------------------------------------------
2021-05-27 13:01:26,882 epoch 15 - iter 6/68 - loss 0.36981423 - samples/sec: 65.86 - lr: 0.050000
2021-05-27 13:01:29,821 epoch 15 - iter 12/68 - loss 0.36547298 - samples/sec: 65.34 - lr: 0.050000
2021-05-27 13:01:32,800 epoch 15 - iter 18/68 - loss 0.35957324 - samples/sec: 64.46 - lr: 0.050000
2021-05-27 13:01:35,709 epoch 15 - iter 24/68 - loss 0.31245467 - samples/sec: 66.02 - lr: 0.050000
2021-05-27 13:01:38,639 epoch 15 - iter 30/68 - loss 0.28646958 - samples/sec: 65.54 - lr: 0.050000
2021-05-27 13:01:41,618 epoch 15 - iter 36/68 - loss 0.28494629 - samples/sec: 64.46 - lr: 0.050000
2021-05-27 13:01:44,620 epoch 15 - iter 42/68 - loss 0.33345024 - samples/sec: 63.98 - lr: 0.050000
2021-05-27 13:01:47,609 epoch 15 - iter 48/68 - loss 0.34588599 - samples/sec: 64.24 - lr: 0.050000
2021-05-27 13:01:50,549 epoch 15 - iter 54/68 - loss 0.33457775 - samples/sec: 65.33 - lr: 0.050000
2021-05-27 13:01:53,496 epoch 15 - iter 60/68 - loss 0.32792425 - samples/sec: 65.17 - lr: 0.050000
2021-05-27 13:01:56,453 epoch 15 - iter 66/68 - loss 0.32388780 - samples/sec: 64.93 - lr: 0.050000
2021-05-27 13:01:57,025 ----------------------------------------------------------------------------------------------------
2021-05-27 13:01:57,025 EPOCH 15 done: loss 0.3184 - lr 0.0500000
2021-05-27 13:01:59,138 DEV : loss 0.18710172176361084 - score 0.9552
2021-05-27 13:01:59,174 BAD EPOCHS (no improvement): 1
2021-05-27 13:01:59,174 ----------------------------------------------------------------------------------------------------
2021-05-27 13:02:02,053 epoch 16 - iter 6/68 - loss 0.27481992 - samples/sec: 66.70 - lr: 0.050000
2021-05-27 13:02:04,968 epoch 16 - iter 12/68 - loss 0.30807405 - samples/sec: 65.88 - lr: 0.050000
2021-05-27 13:02:07,877 epoch 16 - iter 18/68 - loss 0.29117645 - samples/sec: 66.02 - lr: 0.050000
2021-05-27 13:02:10,834 epoch 16 - iter 24/68 - loss 0.31847446 - samples/sec: 64.95 - lr: 0.050000
2021-05-27 13:02:13,817 epoch 16 - iter 30/68 - loss 0.29176075 - samples/sec: 64.37 - lr: 0.050000
2021-05-27 13:02:16,720 epoch 16 - iter 36/68 - loss 0.29988809 - samples/sec: 66.16 - lr: 0.050000
2021-05-27 13:02:19,714 epoch 16 - iter 42/68 - loss 0.29185149 - samples/sec: 64.15 - lr: 0.050000
2021-05-27 13:02:22,918 epoch 16 - iter 48/68 - loss 0.28390750 - samples/sec: 59.93 - lr: 0.050000
2021-05-27 13:02:25,829 epoch 16 - iter 54/68 - loss 0.29127072 - samples/sec: 65.97 - lr: 0.050000
2021-05-27 13:02:28,772 epoch 16 - iter 60/68 - loss 0.29552047 - samples/sec: 65.26 - lr: 0.050000
2021-05-27 13:02:31,746 epoch 16 - iter 66/68 - loss 0.30767772 - samples/sec: 64.59 - lr: 0.050000
2021-05-27 13:02:32,318 ----------------------------------------------------------------------------------------------------
2021-05-27 13:02:32,319 EPOCH 16 done: loss 0.3081 - lr 0.0500000
2021-05-27 13:02:34,424 DEV : loss 0.16312776505947113 - score 0.9642
2021-05-27 13:02:34,459 BAD EPOCHS (no improvement): 2
2021-05-27 13:02:34,459 ----------------------------------------------------------------------------------------------------
2021-05-27 13:02:37,419 epoch 17 - iter 6/68 - loss 0.32072985 - samples/sec: 64.89 - lr: 0.050000
2021-05-27 13:02:40,355 epoch 17 - iter 12/68 - loss 0.31171670 - samples/sec: 65.39 - lr: 0.050000
2021-05-27 13:02:43,314 epoch 17 - iter 18/68 - loss 0.30236866 - samples/sec: 64.91 - lr: 0.050000
2021-05-27 13:02:46,230 epoch 17 - iter 24/68 - loss 0.29667949 - samples/sec: 65.86 - lr: 0.050000
2021-05-27 13:02:49,208 epoch 17 - iter 30/68 - loss 0.31115348 - samples/sec: 64.49 - lr: 0.050000
2021-05-27 13:02:52,157 epoch 17 - iter 36/68 - loss 0.33165762 - samples/sec: 65.11 - lr: 0.050000
2021-05-27 13:02:55,076 epoch 17 - iter 42/68 - loss 0.34898179 - samples/sec: 65.80 - lr: 0.050000
2021-05-27 13:02:58,032 epoch 17 - iter 48/68 - loss 0.33076336 - samples/sec: 64.97 - lr: 0.050000
2021-05-27 13:03:00,997 epoch 17 - iter 54/68 - loss 0.32462192 - samples/sec: 64.77 - lr: 0.050000
2021-05-27 13:03:03,888 epoch 17 - iter 60/68 - loss 0.33519064 - samples/sec: 66.42 - lr: 0.050000
2021-05-27 13:03:06,763 epoch 17 - iter 66/68 - loss 0.33361901 - samples/sec: 66.82 - lr: 0.050000
2021-05-27 13:03:07,335 ----------------------------------------------------------------------------------------------------
2021-05-27 13:03:07,335 EPOCH 17 done: loss 0.3311 - lr 0.0500000
2021-05-27 13:03:09,438 DEV : loss 0.2468118518590927 - score 0.9429
2021-05-27 13:03:09,474 BAD EPOCHS (no improvement): 3
2021-05-27 13:03:09,474 ----------------------------------------------------------------------------------------------------
2021-05-27 13:03:12,386 epoch 18 - iter 6/68 - loss 0.37726772 - samples/sec: 65.95 - lr: 0.050000
2021-05-27 13:03:15,346 epoch 18 - iter 12/68 - loss 0.34226728 - samples/sec: 64.87 - lr: 0.050000
2021-05-27 13:03:18,282 epoch 18 - iter 18/68 - loss 0.34117354 - samples/sec: 65.42 - lr: 0.050000
2021-05-27 13:03:21,221 epoch 18 - iter 24/68 - loss 0.31841643 - samples/sec: 65.34 - lr: 0.050000
2021-05-27 13:03:24,109 epoch 18 - iter 30/68 - loss 0.30122744 - samples/sec: 66.50 - lr: 0.050000
2021-05-27 13:03:27,064 epoch 18 - iter 36/68 - loss 0.29229869 - samples/sec: 64.99 - lr: 0.050000
2021-05-27 13:03:29,993 epoch 18 - iter 42/68 - loss 0.30009663 - samples/sec: 65.57 - lr: 0.050000
2021-05-27 13:03:32,916 epoch 18 - iter 48/68 - loss 0.30244130 - samples/sec: 65.69 - lr: 0.050000
2021-05-27 13:03:35,852 epoch 18 - iter 54/68 - loss 0.31673035 - samples/sec: 65.40 - lr: 0.050000
2021-05-27 13:03:38,837 epoch 18 - iter 60/68 - loss 0.30760040 - samples/sec: 64.34 - lr: 0.050000
2021-05-27 13:03:41,813 epoch 18 - iter 66/68 - loss 0.30891929 - samples/sec: 64.53 - lr: 0.050000
2021-05-27 13:03:42,376 ----------------------------------------------------------------------------------------------------
2021-05-27 13:03:42,376 EPOCH 18 done: loss 0.3030 - lr 0.0500000
2021-05-27 13:03:44,479 DEV : loss 0.1301187425851822 - score 0.9752
Epoch    18: reducing learning rate of group 0 to 2.5000e-02.
2021-05-27 13:03:44,514 BAD EPOCHS (no improvement): 4
2021-05-27 13:03:44,515 ----------------------------------------------------------------------------------------------------
2021-05-27 13:03:47,411 epoch 19 - iter 6/68 - loss 0.23304905 - samples/sec: 66.30 - lr: 0.025000
2021-05-27 13:03:50,345 epoch 19 - iter 12/68 - loss 0.28280701 - samples/sec: 65.45 - lr: 0.025000
2021-05-27 13:03:53,302 epoch 19 - iter 18/68 - loss 0.30596349 - samples/sec: 64.96 - lr: 0.025000
2021-05-27 13:03:56,275 epoch 19 - iter 24/68 - loss 0.27601295 - samples/sec: 64.59 - lr: 0.025000
2021-05-27 13:03:59,207 epoch 19 - iter 30/68 - loss 0.28417952 - samples/sec: 65.50 - lr: 0.025000
2021-05-27 13:04:02,134 epoch 19 - iter 36/68 - loss 0.28377722 - samples/sec: 65.61 - lr: 0.025000
2021-05-27 13:04:05,069 epoch 19 - iter 42/68 - loss 0.27704092 - samples/sec: 65.44 - lr: 0.025000
2021-05-27 13:04:08,176 epoch 19 - iter 48/68 - loss 0.27642495 - samples/sec: 61.80 - lr: 0.025000
2021-05-27 13:04:11,141 epoch 19 - iter 54/68 - loss 0.27349957 - samples/sec: 64.76 - lr: 0.025000
2021-05-27 13:04:14,100 epoch 19 - iter 60/68 - loss 0.27003871 - samples/sec: 64.91 - lr: 0.025000
2021-05-27 13:04:17,043 epoch 19 - iter 66/68 - loss 0.26792038 - samples/sec: 65.24 - lr: 0.025000
2021-05-27 13:04:17,628 ----------------------------------------------------------------------------------------------------
2021-05-27 13:04:17,628 EPOCH 19 done: loss 0.2652 - lr 0.0250000
2021-05-27 13:04:19,731 DEV : loss 0.10149559378623962 - score 0.9749
2021-05-27 13:04:19,766 BAD EPOCHS (no improvement): 1
2021-05-27 13:04:19,767 ----------------------------------------------------------------------------------------------------
2021-05-27 13:04:22,731 epoch 20 - iter 6/68 - loss 0.30585687 - samples/sec: 64.78 - lr: 0.025000
2021-05-27 13:04:25,658 epoch 20 - iter 12/68 - loss 0.29234483 - samples/sec: 65.61 - lr: 0.025000
2021-05-27 13:04:28,612 epoch 20 - iter 18/68 - loss 0.27374157 - samples/sec: 65.02 - lr: 0.025000
2021-05-27 13:04:31,515 epoch 20 - iter 24/68 - loss 0.25940720 - samples/sec: 66.15 - lr: 0.025000
2021-05-27 13:04:34,414 epoch 20 - iter 30/68 - loss 0.27602515 - samples/sec: 66.25 - lr: 0.025000
2021-05-27 13:04:37,383 epoch 20 - iter 36/68 - loss 0.26521871 - samples/sec: 64.68 - lr: 0.025000
2021-05-27 13:04:40,329 epoch 20 - iter 42/68 - loss 0.28900534 - samples/sec: 65.19 - lr: 0.025000
2021-05-27 13:04:43,268 epoch 20 - iter 48/68 - loss 0.29092720 - samples/sec: 65.33 - lr: 0.025000
2021-05-27 13:04:46,233 epoch 20 - iter 54/68 - loss 0.29130185 - samples/sec: 64.76 - lr: 0.025000
2021-05-27 13:04:49,133 epoch 20 - iter 60/68 - loss 0.29113010 - samples/sec: 66.22 - lr: 0.025000
2021-05-27 13:04:52,076 epoch 20 - iter 66/68 - loss 0.29895347 - samples/sec: 65.27 - lr: 0.025000
2021-05-27 13:04:52,654 ----------------------------------------------------------------------------------------------------
2021-05-27 13:04:52,655 EPOCH 20 done: loss 0.3014 - lr 0.0250000
2021-05-27 13:04:54,755 DEV : loss 0.1577633023262024 - score 0.9624
2021-05-27 13:04:54,790 BAD EPOCHS (no improvement): 2
2021-05-27 13:04:54,790 ----------------------------------------------------------------------------------------------------
2021-05-27 13:04:57,753 epoch 21 - iter 6/68 - loss 0.30111123 - samples/sec: 64.81 - lr: 0.025000
2021-05-27 13:05:00,681 epoch 21 - iter 12/68 - loss 0.28067014 - samples/sec: 65.59 - lr: 0.025000
2021-05-27 13:05:03,604 epoch 21 - iter 18/68 - loss 0.29406227 - samples/sec: 65.71 - lr: 0.025000
2021-05-27 13:05:06,544 epoch 21 - iter 24/68 - loss 0.30566663 - samples/sec: 65.33 - lr: 0.025000
2021-05-27 13:05:09,496 epoch 21 - iter 30/68 - loss 0.29435139 - samples/sec: 65.04 - lr: 0.025000
2021-05-27 13:05:12,463 epoch 21 - iter 36/68 - loss 0.26835938 - samples/sec: 64.73 - lr: 0.025000
2021-05-27 13:05:15,397 epoch 21 - iter 42/68 - loss 0.26148376 - samples/sec: 65.45 - lr: 0.025000
2021-05-27 13:05:18,347 epoch 21 - iter 48/68 - loss 0.26917424 - samples/sec: 65.10 - lr: 0.025000
2021-05-27 13:05:21,234 epoch 21 - iter 54/68 - loss 0.25802661 - samples/sec: 66.52 - lr: 0.025000
2021-05-27 13:05:24,162 epoch 21 - iter 60/68 - loss 0.25952789 - samples/sec: 65.60 - lr: 0.025000
2021-05-27 13:05:27,109 epoch 21 - iter 66/68 - loss 0.25791722 - samples/sec: 65.16 - lr: 0.025000
2021-05-27 13:05:27,677 ----------------------------------------------------------------------------------------------------
2021-05-27 13:05:27,677 EPOCH 21 done: loss 0.2522 - lr 0.0250000
2021-05-27 13:05:29,782 DEV : loss 0.09671740233898163 - score 0.975
2021-05-27 13:05:29,817 BAD EPOCHS (no improvement): 3
2021-05-27 13:05:29,818 ----------------------------------------------------------------------------------------------------
2021-05-27 13:05:32,747 epoch 22 - iter 6/68 - loss 0.21075354 - samples/sec: 65.56 - lr: 0.025000
2021-05-27 13:05:35,655 epoch 22 - iter 12/68 - loss 0.19299498 - samples/sec: 66.04 - lr: 0.025000
2021-05-27 13:05:38,575 epoch 22 - iter 18/68 - loss 0.20375650 - samples/sec: 65.77 - lr: 0.025000
2021-05-27 13:05:41,521 epoch 22 - iter 24/68 - loss 0.24703307 - samples/sec: 65.19 - lr: 0.025000
2021-05-27 13:05:44,475 epoch 22 - iter 30/68 - loss 0.27427954 - samples/sec: 65.01 - lr: 0.025000
2021-05-27 13:05:47,456 epoch 22 - iter 36/68 - loss 0.27040452 - samples/sec: 64.42 - lr: 0.025000
2021-05-27 13:05:50,388 epoch 22 - iter 42/68 - loss 0.26876976 - samples/sec: 65.50 - lr: 0.025000
2021-05-27 13:05:53,558 epoch 22 - iter 48/68 - loss 0.27449012 - samples/sec: 60.59 - lr: 0.025000
2021-05-27 13:05:56,520 epoch 22 - iter 54/68 - loss 0.28394313 - samples/sec: 64.83 - lr: 0.025000
2021-05-27 13:05:59,447 epoch 22 - iter 60/68 - loss 0.27718440 - samples/sec: 65.62 - lr: 0.025000
2021-05-27 13:06:02,406 epoch 22 - iter 66/68 - loss 0.28067041 - samples/sec: 64.89 - lr: 0.025000
2021-05-27 13:06:02,979 ----------------------------------------------------------------------------------------------------
2021-05-27 13:06:02,979 EPOCH 22 done: loss 0.2768 - lr 0.0250000
2021-05-27 13:06:05,083 DEV : loss 0.11434745788574219 - score 0.9752
Epoch    22: reducing learning rate of group 0 to 1.2500e-02.
2021-05-27 13:06:05,118 BAD EPOCHS (no improvement): 4
2021-05-27 13:06:05,118 ----------------------------------------------------------------------------------------------------
2021-05-27 13:06:08,067 epoch 23 - iter 6/68 - loss 0.20679038 - samples/sec: 65.13 - lr: 0.012500
2021-05-27 13:06:10,996 epoch 23 - iter 12/68 - loss 0.25034427 - samples/sec: 65.58 - lr: 0.012500
2021-05-27 13:06:13,964 epoch 23 - iter 18/68 - loss 0.25066365 - samples/sec: 64.71 - lr: 0.012500
2021-05-27 13:06:16,884 epoch 23 - iter 24/68 - loss 0.23120235 - samples/sec: 65.75 - lr: 0.012500
2021-05-27 13:06:19,787 epoch 23 - iter 30/68 - loss 0.23010690 - samples/sec: 66.16 - lr: 0.012500
2021-05-27 13:06:22,751 epoch 23 - iter 36/68 - loss 0.23103016 - samples/sec: 64.78 - lr: 0.012500
2021-05-27 13:06:25,680 epoch 23 - iter 42/68 - loss 0.24016982 - samples/sec: 65.57 - lr: 0.012500
2021-05-27 13:06:28,604 epoch 23 - iter 48/68 - loss 0.23474597 - samples/sec: 65.69 - lr: 0.012500
2021-05-27 13:06:31,530 epoch 23 - iter 54/68 - loss 0.23209819 - samples/sec: 65.62 - lr: 0.012500
2021-05-27 13:06:34,493 epoch 23 - iter 60/68 - loss 0.23551939 - samples/sec: 64.82 - lr: 0.012500
2021-05-27 13:06:37,441 epoch 23 - iter 66/68 - loss 0.23657122 - samples/sec: 65.15 - lr: 0.012500
2021-05-27 13:06:38,008 ----------------------------------------------------------------------------------------------------
2021-05-27 13:06:38,008 EPOCH 23 done: loss 0.2362 - lr 0.0125000
2021-05-27 13:06:40,113 DEV : loss 0.11699482053518295 - score 0.9715
2021-05-27 13:06:40,148 BAD EPOCHS (no improvement): 1
2021-05-27 13:06:40,148 ----------------------------------------------------------------------------------------------------
2021-05-27 13:06:43,109 epoch 24 - iter 6/68 - loss 0.26934135 - samples/sec: 64.86 - lr: 0.012500
2021-05-27 13:06:46,072 epoch 24 - iter 12/68 - loss 0.29004363 - samples/sec: 64.81 - lr: 0.012500
2021-05-27 13:06:48,996 epoch 24 - iter 18/68 - loss 0.27477724 - samples/sec: 65.68 - lr: 0.012500
2021-05-27 13:06:51,921 epoch 24 - iter 24/68 - loss 0.24502042 - samples/sec: 65.65 - lr: 0.012500
2021-05-27 13:06:54,847 epoch 24 - iter 30/68 - loss 0.25812220 - samples/sec: 65.63 - lr: 0.012500
2021-05-27 13:06:57,757 epoch 24 - iter 36/68 - loss 0.26262658 - samples/sec: 66.00 - lr: 0.012500
2021-05-27 13:07:00,698 epoch 24 - iter 42/68 - loss 0.25874984 - samples/sec: 65.29 - lr: 0.012500
2021-05-27 13:07:03,640 epoch 24 - iter 48/68 - loss 0.25718697 - samples/sec: 65.28 - lr: 0.012500
2021-05-27 13:07:06,594 epoch 24 - iter 54/68 - loss 0.24746778 - samples/sec: 65.02 - lr: 0.012500
2021-05-27 13:07:09,526 epoch 24 - iter 60/68 - loss 0.24358803 - samples/sec: 65.50 - lr: 0.012500
2021-05-27 13:07:12,458 epoch 24 - iter 66/68 - loss 0.23451112 - samples/sec: 65.49 - lr: 0.012500
2021-05-27 13:07:13,034 ----------------------------------------------------------------------------------------------------
2021-05-27 13:07:13,034 EPOCH 24 done: loss 0.2325 - lr 0.0125000
2021-05-27 13:07:15,137 DEV : loss 0.12909238040447235 - score 0.9697
2021-05-27 13:07:15,172 BAD EPOCHS (no improvement): 2
2021-05-27 13:07:15,172 ----------------------------------------------------------------------------------------------------
2021-05-27 13:07:18,137 epoch 25 - iter 6/68 - loss 0.24677264 - samples/sec: 64.76 - lr: 0.012500
2021-05-27 13:07:21,088 epoch 25 - iter 12/68 - loss 0.26249926 - samples/sec: 65.08 - lr: 0.012500
2021-05-27 13:07:24,048 epoch 25 - iter 18/68 - loss 0.27477886 - samples/sec: 64.87 - lr: 0.012500
2021-05-27 13:07:26,967 epoch 25 - iter 24/68 - loss 0.25478996 - samples/sec: 65.79 - lr: 0.012500
2021-05-27 13:07:29,909 epoch 25 - iter 30/68 - loss 0.26903947 - samples/sec: 65.29 - lr: 0.012500
2021-05-27 13:07:32,825 epoch 25 - iter 36/68 - loss 0.24823463 - samples/sec: 65.85 - lr: 0.012500
2021-05-27 13:07:35,761 epoch 25 - iter 42/68 - loss 0.23637324 - samples/sec: 65.42 - lr: 0.012500
2021-05-27 13:07:38,947 epoch 25 - iter 48/68 - loss 0.23975238 - samples/sec: 60.27 - lr: 0.012500
2021-05-27 13:07:41,878 epoch 25 - iter 54/68 - loss 0.25311831 - samples/sec: 65.53 - lr: 0.012500
2021-05-27 13:07:44,769 epoch 25 - iter 60/68 - loss 0.24940320 - samples/sec: 66.41 - lr: 0.012500
2021-05-27 13:07:47,729 epoch 25 - iter 66/68 - loss 0.24873917 - samples/sec: 64.88 - lr: 0.012500
2021-05-27 13:07:48,290 ----------------------------------------------------------------------------------------------------
2021-05-27 13:07:48,290 EPOCH 25 done: loss 0.2731 - lr 0.0125000
2021-05-27 13:07:50,390 DEV : loss 0.1031678169965744 - score 0.9771
2021-05-27 13:07:50,425 BAD EPOCHS (no improvement): 3
2021-05-27 13:07:50,426 ----------------------------------------------------------------------------------------------------
2021-05-27 13:07:53,348 epoch 26 - iter 6/68 - loss 0.24158381 - samples/sec: 65.72 - lr: 0.012500
2021-05-27 13:07:56,240 epoch 26 - iter 12/68 - loss 0.19896777 - samples/sec: 66.40 - lr: 0.012500
2021-05-27 13:07:59,180 epoch 26 - iter 18/68 - loss 0.23554288 - samples/sec: 65.32 - lr: 0.012500
2021-05-27 13:08:02,150 epoch 26 - iter 24/68 - loss 0.22863217 - samples/sec: 64.67 - lr: 0.012500
2021-05-27 13:08:05,096 epoch 26 - iter 30/68 - loss 0.24413366 - samples/sec: 65.18 - lr: 0.012500
2021-05-27 13:08:08,026 epoch 26 - iter 36/68 - loss 0.24715105 - samples/sec: 65.54 - lr: 0.012500
2021-05-27 13:08:10,956 epoch 26 - iter 42/68 - loss 0.25410279 - samples/sec: 65.56 - lr: 0.012500
2021-05-27 13:08:13,880 epoch 26 - iter 48/68 - loss 0.25704644 - samples/sec: 65.66 - lr: 0.012500
2021-05-27 13:08:16,808 epoch 26 - iter 54/68 - loss 0.25014245 - samples/sec: 65.60 - lr: 0.012500
2021-05-27 13:08:19,749 epoch 26 - iter 60/68 - loss 0.24742370 - samples/sec: 65.30 - lr: 0.012500
2021-05-27 13:08:22,657 epoch 26 - iter 66/68 - loss 0.24298201 - samples/sec: 66.04 - lr: 0.012500
2021-05-27 13:08:23,211 ----------------------------------------------------------------------------------------------------
2021-05-27 13:08:23,211 EPOCH 26 done: loss 0.2428 - lr 0.0125000
2021-05-27 13:08:25,314 DEV : loss 0.1159483790397644 - score 0.9734
Epoch    26: reducing learning rate of group 0 to 6.2500e-03.
2021-05-27 13:08:25,349 BAD EPOCHS (no improvement): 4
2021-05-27 13:08:25,350 ----------------------------------------------------------------------------------------------------
2021-05-27 13:08:28,282 epoch 27 - iter 6/68 - loss 0.23089729 - samples/sec: 65.48 - lr: 0.006250
2021-05-27 13:08:31,198 epoch 27 - iter 12/68 - loss 0.29166583 - samples/sec: 65.87 - lr: 0.006250
2021-05-27 13:08:34,092 epoch 27 - iter 18/68 - loss 0.30699618 - samples/sec: 66.36 - lr: 0.006250
2021-05-27 13:08:36,954 epoch 27 - iter 24/68 - loss 0.28930870 - samples/sec: 67.10 - lr: 0.006250
2021-05-27 13:08:39,885 epoch 27 - iter 30/68 - loss 0.26493299 - samples/sec: 65.53 - lr: 0.006250
2021-05-27 13:08:42,814 epoch 27 - iter 36/68 - loss 0.26869670 - samples/sec: 65.57 - lr: 0.006250
2021-05-27 13:08:45,763 epoch 27 - iter 42/68 - loss 0.26250610 - samples/sec: 65.13 - lr: 0.006250
2021-05-27 13:08:48,706 epoch 27 - iter 48/68 - loss 0.26536193 - samples/sec: 65.25 - lr: 0.006250
2021-05-27 13:08:51,635 epoch 27 - iter 54/68 - loss 0.25370035 - samples/sec: 65.55 - lr: 0.006250
2021-05-27 13:08:54,559 epoch 27 - iter 60/68 - loss 0.25080264 - samples/sec: 65.68 - lr: 0.006250
2021-05-27 13:08:57,520 epoch 27 - iter 66/68 - loss 0.25086966 - samples/sec: 64.87 - lr: 0.006250
2021-05-27 13:08:58,097 ----------------------------------------------------------------------------------------------------
2021-05-27 13:08:58,097 EPOCH 27 done: loss 0.2464 - lr 0.0062500
2021-05-27 13:09:00,202 DEV : loss 0.10746611654758453 - score 0.9752
2021-05-27 13:09:00,237 BAD EPOCHS (no improvement): 1
2021-05-27 13:09:00,237 ----------------------------------------------------------------------------------------------------
2021-05-27 13:09:03,086 epoch 28 - iter 6/68 - loss 0.17605666 - samples/sec: 67.42 - lr: 0.006250
2021-05-27 13:09:06,011 epoch 28 - iter 12/68 - loss 0.25698145 - samples/sec: 65.64 - lr: 0.006250
2021-05-27 13:09:08,913 epoch 28 - iter 18/68 - loss 0.24806834 - samples/sec: 66.19 - lr: 0.006250
2021-05-27 13:09:11,838 epoch 28 - iter 24/68 - loss 0.23944312 - samples/sec: 65.64 - lr: 0.006250
2021-05-27 13:09:14,788 epoch 28 - iter 30/68 - loss 0.22732711 - samples/sec: 65.10 - lr: 0.006250
2021-05-27 13:09:17,693 epoch 28 - iter 36/68 - loss 0.23482874 - samples/sec: 66.13 - lr: 0.006250
2021-05-27 13:09:20,636 epoch 28 - iter 42/68 - loss 0.22197209 - samples/sec: 65.25 - lr: 0.006250
2021-05-27 13:09:23,604 epoch 28 - iter 48/68 - loss 0.20896809 - samples/sec: 64.69 - lr: 0.006250
2021-05-27 13:09:26,783 epoch 28 - iter 54/68 - loss 0.20631725 - samples/sec: 60.42 - lr: 0.006250
2021-05-27 13:09:29,728 epoch 28 - iter 60/68 - loss 0.21108641 - samples/sec: 65.21 - lr: 0.006250
2021-05-27 13:09:32,678 epoch 28 - iter 66/68 - loss 0.20508955 - samples/sec: 65.11 - lr: 0.006250
2021-05-27 13:09:33,242 ----------------------------------------------------------------------------------------------------
2021-05-27 13:09:33,243 EPOCH 28 done: loss 0.2476 - lr 0.0062500
2021-05-27 13:09:35,347 DEV : loss 0.12295365333557129 - score 0.9697
2021-05-27 13:09:35,382 BAD EPOCHS (no improvement): 2
2021-05-27 13:09:35,382 ----------------------------------------------------------------------------------------------------
2021-05-27 13:09:38,264 epoch 29 - iter 6/68 - loss 0.29212792 - samples/sec: 66.65 - lr: 0.006250
2021-05-27 13:09:41,170 epoch 29 - iter 12/68 - loss 0.27303471 - samples/sec: 66.09 - lr: 0.006250
2021-05-27 13:09:44,119 epoch 29 - iter 18/68 - loss 0.24511691 - samples/sec: 65.12 - lr: 0.006250
2021-05-27 13:09:47,060 epoch 29 - iter 24/68 - loss 0.23999761 - samples/sec: 65.29 - lr: 0.006250
2021-05-27 13:09:50,040 epoch 29 - iter 30/68 - loss 0.22221538 - samples/sec: 64.46 - lr: 0.006250
2021-05-27 13:09:52,985 epoch 29 - iter 36/68 - loss 0.22979328 - samples/sec: 65.19 - lr: 0.006250
2021-05-27 13:09:55,883 epoch 29 - iter 42/68 - loss 0.22227753 - samples/sec: 66.27 - lr: 0.006250
2021-05-27 13:09:58,827 epoch 29 - iter 48/68 - loss 0.22289939 - samples/sec: 65.23 - lr: 0.006250
2021-05-27 13:10:01,748 epoch 29 - iter 54/68 - loss 0.23091523 - samples/sec: 65.75 - lr: 0.006250
2021-05-27 13:10:04,647 epoch 29 - iter 60/68 - loss 0.23040469 - samples/sec: 66.24 - lr: 0.006250
2021-05-27 13:10:07,620 epoch 29 - iter 66/68 - loss 0.22424560 - samples/sec: 64.59 - lr: 0.006250
2021-05-27 13:10:08,168 ----------------------------------------------------------------------------------------------------
2021-05-27 13:10:08,168 EPOCH 29 done: loss 0.2227 - lr 0.0062500
2021-05-27 13:10:10,273 DEV : loss 0.12584060430526733 - score 0.9697
2021-05-27 13:10:10,309 BAD EPOCHS (no improvement): 3
2021-05-27 13:10:10,309 ----------------------------------------------------------------------------------------------------
2021-05-27 13:10:13,197 epoch 30 - iter 6/68 - loss 0.23867891 - samples/sec: 66.50 - lr: 0.006250
2021-05-27 13:10:16,146 epoch 30 - iter 12/68 - loss 0.23044745 - samples/sec: 65.12 - lr: 0.006250
2021-05-27 13:10:19,057 epoch 30 - iter 18/68 - loss 0.22837871 - samples/sec: 65.97 - lr: 0.006250
2021-05-27 13:10:22,031 epoch 30 - iter 24/68 - loss 0.21860280 - samples/sec: 64.57 - lr: 0.006250
2021-05-27 13:10:24,938 epoch 30 - iter 30/68 - loss 0.22081026 - samples/sec: 66.07 - lr: 0.006250
2021-05-27 13:10:27,894 epoch 30 - iter 36/68 - loss 0.21711342 - samples/sec: 64.98 - lr: 0.006250
2021-05-27 13:10:30,807 epoch 30 - iter 42/68 - loss 0.21157043 - samples/sec: 65.92 - lr: 0.006250
2021-05-27 13:10:33,750 epoch 30 - iter 48/68 - loss 0.20989248 - samples/sec: 65.25 - lr: 0.006250
2021-05-27 13:10:36,681 epoch 30 - iter 54/68 - loss 0.20919625 - samples/sec: 65.53 - lr: 0.006250
2021-05-27 13:10:39,597 epoch 30 - iter 60/68 - loss 0.21699874 - samples/sec: 65.86 - lr: 0.006250
2021-05-27 13:10:42,525 epoch 30 - iter 66/68 - loss 0.21774475 - samples/sec: 65.58 - lr: 0.006250
2021-05-27 13:10:43,107 ----------------------------------------------------------------------------------------------------
2021-05-27 13:10:43,107 EPOCH 30 done: loss 0.2152 - lr 0.0062500
2021-05-27 13:10:45,209 DEV : loss 0.11278834193944931 - score 0.9734
Epoch    30: reducing learning rate of group 0 to 3.1250e-03.
2021-05-27 13:10:45,244 BAD EPOCHS (no improvement): 4
2021-05-27 13:10:46,275 ----------------------------------------------------------------------------------------------------
2021-05-27 13:10:46,275 Testing using best model ...
2021-05-27 13:10:46,275 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.rststb/best-model.pt
2021-05-27 13:10:57,905 0.9565	0.9439	0.9502
2021-05-27 13:10:57,905 
Results:
- F1-score (micro) 0.9502
- F1-score (macro) 0.9502

By class:
SENT       tp: 286 - fp: 13 - fn: 17 - precision: 0.9565 - recall: 0.9439 - f1-score: 0.9502
2021-05-27 13:10:57,905 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/
2021-05-27 13:10:57,929 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb
2021-05-27 13:10:57,930 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/sent_train.txt
2021-05-27 13:10:57,930 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/sent_dev.txt
2021-05-27 13:10:57,930 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/sent_test.txt
Corpus: 441 train + 104 dev + 165 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 13:11:07,770 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:07,772 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 13:11:07,772 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:07,772 Corpus: "Corpus: 441 train + 104 dev + 165 test sentences"
2021-05-27 13:11:07,772 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:07,772 Parameters:
2021-05-27 13:11:07,772  - learning_rate: "0.1"
2021-05-27 13:11:07,772  - mini_batch_size: "32"
2021-05-27 13:11:07,773  - patience: "3"
2021-05-27 13:11:07,773  - anneal_factor: "0.5"
2021-05-27 13:11:07,773  - max_epochs: "30"
2021-05-27 13:11:07,773  - shuffle: "True"
2021-05-27 13:11:07,773  - train_with_dev: "False"
2021-05-27 13:11:07,773  - batch_growth_annealing: "False"
2021-05-27 13:11:07,773 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:07,773 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb"
2021-05-27 13:11:07,773 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:07,773 Device: cuda:0
2021-05-27 13:11:07,773 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:07,773 Embeddings storage mode: cpu
2021-05-27 13:11:07,776 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:08,993 epoch 1 - iter 1/14 - loss 31.71678734 - samples/sec: 26.32 - lr: 0.100000
2021-05-27 13:11:10,516 epoch 1 - iter 2/14 - loss 19.37105989 - samples/sec: 21.00 - lr: 0.100000
2021-05-27 13:11:12,035 epoch 1 - iter 3/14 - loss 15.46238708 - samples/sec: 21.08 - lr: 0.100000
2021-05-27 13:11:13,406 epoch 1 - iter 4/14 - loss 13.29855704 - samples/sec: 23.33 - lr: 0.100000
2021-05-27 13:11:14,604 epoch 1 - iter 5/14 - loss 11.80306435 - samples/sec: 26.72 - lr: 0.100000
2021-05-27 13:11:15,840 epoch 1 - iter 6/14 - loss 10.96943124 - samples/sec: 25.89 - lr: 0.100000
2021-05-27 13:11:17,037 epoch 1 - iter 7/14 - loss 10.16503157 - samples/sec: 26.74 - lr: 0.100000
2021-05-27 13:11:18,227 epoch 1 - iter 8/14 - loss 9.51420510 - samples/sec: 26.92 - lr: 0.100000
2021-05-27 13:11:19,448 epoch 1 - iter 9/14 - loss 9.25910208 - samples/sec: 26.21 - lr: 0.100000
2021-05-27 13:11:20,669 epoch 1 - iter 10/14 - loss 8.86621237 - samples/sec: 26.21 - lr: 0.100000
2021-05-27 13:11:21,901 epoch 1 - iter 11/14 - loss 8.42062001 - samples/sec: 25.98 - lr: 0.100000
2021-05-27 13:11:23,114 epoch 1 - iter 12/14 - loss 8.05996795 - samples/sec: 26.39 - lr: 0.100000
2021-05-27 13:11:24,334 epoch 1 - iter 13/14 - loss 7.85220568 - samples/sec: 26.21 - lr: 0.100000
2021-05-27 13:11:25,327 epoch 1 - iter 14/14 - loss 7.55445290 - samples/sec: 32.26 - lr: 0.100000
2021-05-27 13:11:25,327 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:25,327 EPOCH 1 done: loss 7.5545 - lr 0.1000000
2021-05-27 13:11:28,652 DEV : loss 5.671534538269043 - score 0.0
2021-05-27 13:11:28,662 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:11:29,652 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:30,092 epoch 2 - iter 1/14 - loss 3.18192005 - samples/sec: 72.85 - lr: 0.100000
2021-05-27 13:11:30,546 epoch 2 - iter 2/14 - loss 3.84672785 - samples/sec: 70.58 - lr: 0.100000
2021-05-27 13:11:30,995 epoch 2 - iter 3/14 - loss 3.91663122 - samples/sec: 71.39 - lr: 0.100000
2021-05-27 13:11:31,446 epoch 2 - iter 4/14 - loss 4.02219498 - samples/sec: 70.96 - lr: 0.100000
2021-05-27 13:11:31,897 epoch 2 - iter 5/14 - loss 3.88221645 - samples/sec: 71.01 - lr: 0.100000
2021-05-27 13:11:32,335 epoch 2 - iter 6/14 - loss 4.26767890 - samples/sec: 73.09 - lr: 0.100000
2021-05-27 13:11:32,778 epoch 2 - iter 7/14 - loss 4.33193949 - samples/sec: 72.39 - lr: 0.100000
2021-05-27 13:11:33,221 epoch 2 - iter 8/14 - loss 4.50605118 - samples/sec: 72.23 - lr: 0.100000
2021-05-27 13:11:33,679 epoch 2 - iter 9/14 - loss 4.56997575 - samples/sec: 69.94 - lr: 0.100000
2021-05-27 13:11:34,102 epoch 2 - iter 10/14 - loss 4.68065920 - samples/sec: 75.80 - lr: 0.100000
2021-05-27 13:11:34,545 epoch 2 - iter 11/14 - loss 4.69761051 - samples/sec: 72.22 - lr: 0.100000
2021-05-27 13:11:34,999 epoch 2 - iter 12/14 - loss 4.79321035 - samples/sec: 70.53 - lr: 0.100000
2021-05-27 13:11:35,465 epoch 2 - iter 13/14 - loss 4.78068080 - samples/sec: 68.70 - lr: 0.100000
2021-05-27 13:11:35,839 epoch 2 - iter 14/14 - loss 4.74413320 - samples/sec: 85.84 - lr: 0.100000
2021-05-27 13:11:35,839 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:35,839 EPOCH 2 done: loss 4.7441 - lr 0.1000000
2021-05-27 13:11:36,390 DEV : loss 4.79230260848999 - score 0.0
2021-05-27 13:11:36,400 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:11:45,397 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:45,838 epoch 3 - iter 1/14 - loss 4.63072872 - samples/sec: 72.78 - lr: 0.100000
2021-05-27 13:11:46,289 epoch 3 - iter 2/14 - loss 4.39143443 - samples/sec: 70.95 - lr: 0.100000
2021-05-27 13:11:46,742 epoch 3 - iter 3/14 - loss 4.91518720 - samples/sec: 70.73 - lr: 0.100000
2021-05-27 13:11:47,185 epoch 3 - iter 4/14 - loss 4.71658850 - samples/sec: 72.32 - lr: 0.100000
2021-05-27 13:11:47,621 epoch 3 - iter 5/14 - loss 4.61618958 - samples/sec: 73.42 - lr: 0.100000
2021-05-27 13:11:48,074 epoch 3 - iter 6/14 - loss 4.53017505 - samples/sec: 70.77 - lr: 0.100000
2021-05-27 13:11:48,504 epoch 3 - iter 7/14 - loss 4.27397578 - samples/sec: 74.49 - lr: 0.100000
2021-05-27 13:11:48,956 epoch 3 - iter 8/14 - loss 4.14977953 - samples/sec: 70.72 - lr: 0.100000
2021-05-27 13:11:49,408 epoch 3 - iter 9/14 - loss 4.12861864 - samples/sec: 70.86 - lr: 0.100000
2021-05-27 13:11:49,847 epoch 3 - iter 10/14 - loss 4.06250131 - samples/sec: 73.07 - lr: 0.100000
2021-05-27 13:11:50,294 epoch 3 - iter 11/14 - loss 4.09688150 - samples/sec: 71.65 - lr: 0.100000
2021-05-27 13:11:50,743 epoch 3 - iter 12/14 - loss 4.07372822 - samples/sec: 71.32 - lr: 0.100000
2021-05-27 13:11:51,186 epoch 3 - iter 13/14 - loss 3.98264201 - samples/sec: 72.31 - lr: 0.100000
2021-05-27 13:11:51,547 epoch 3 - iter 14/14 - loss 3.93741858 - samples/sec: 88.70 - lr: 0.100000
2021-05-27 13:11:51,547 ----------------------------------------------------------------------------------------------------
2021-05-27 13:11:51,547 EPOCH 3 done: loss 3.9374 - lr 0.1000000
2021-05-27 13:11:52,089 DEV : loss 4.195860862731934 - score 0.0
2021-05-27 13:11:52,099 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:12:00,903 ----------------------------------------------------------------------------------------------------
2021-05-27 13:12:01,358 epoch 4 - iter 1/14 - loss 3.67232823 - samples/sec: 70.47 - lr: 0.100000
2021-05-27 13:12:01,812 epoch 4 - iter 2/14 - loss 3.77558303 - samples/sec: 70.68 - lr: 0.100000
2021-05-27 13:12:02,255 epoch 4 - iter 3/14 - loss 3.73980856 - samples/sec: 72.16 - lr: 0.100000
2021-05-27 13:12:02,707 epoch 4 - iter 4/14 - loss 3.68874496 - samples/sec: 70.99 - lr: 0.100000
2021-05-27 13:12:03,141 epoch 4 - iter 5/14 - loss 3.61918573 - samples/sec: 73.74 - lr: 0.100000
2021-05-27 13:12:03,598 epoch 4 - iter 6/14 - loss 3.40607361 - samples/sec: 70.10 - lr: 0.100000
2021-05-27 13:12:04,056 epoch 4 - iter 7/14 - loss 3.49404502 - samples/sec: 69.94 - lr: 0.100000
2021-05-27 13:12:04,499 epoch 4 - iter 8/14 - loss 3.42356727 - samples/sec: 72.23 - lr: 0.100000
2021-05-27 13:12:04,960 epoch 4 - iter 9/14 - loss 3.43733234 - samples/sec: 69.55 - lr: 0.100000
2021-05-27 13:12:05,405 epoch 4 - iter 10/14 - loss 3.39952581 - samples/sec: 71.92 - lr: 0.100000
2021-05-27 13:12:05,857 epoch 4 - iter 11/14 - loss 3.58843996 - samples/sec: 70.91 - lr: 0.100000
2021-05-27 13:12:06,295 epoch 4 - iter 12/14 - loss 3.46212254 - samples/sec: 73.06 - lr: 0.100000
2021-05-27 13:12:06,727 epoch 4 - iter 13/14 - loss 3.54645228 - samples/sec: 74.22 - lr: 0.100000
2021-05-27 13:12:07,092 epoch 4 - iter 14/14 - loss 3.57799275 - samples/sec: 87.55 - lr: 0.100000
2021-05-27 13:12:07,093 ----------------------------------------------------------------------------------------------------
2021-05-27 13:12:07,093 EPOCH 4 done: loss 3.5780 - lr 0.1000000
2021-05-27 13:12:07,633 DEV : loss 2.401841640472412 - score 0.0
2021-05-27 13:12:07,643 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:12:16,512 ----------------------------------------------------------------------------------------------------
2021-05-27 13:12:16,959 epoch 5 - iter 1/14 - loss 2.33824539 - samples/sec: 71.75 - lr: 0.100000
2021-05-27 13:12:17,403 epoch 5 - iter 2/14 - loss 2.38933587 - samples/sec: 71.99 - lr: 0.100000
2021-05-27 13:12:17,856 epoch 5 - iter 3/14 - loss 2.81921879 - samples/sec: 70.77 - lr: 0.100000
2021-05-27 13:12:18,302 epoch 5 - iter 4/14 - loss 2.87343371 - samples/sec: 71.78 - lr: 0.100000
2021-05-27 13:12:18,751 epoch 5 - iter 5/14 - loss 2.80612340 - samples/sec: 71.37 - lr: 0.100000
2021-05-27 13:12:19,202 epoch 5 - iter 6/14 - loss 3.17062628 - samples/sec: 70.94 - lr: 0.100000
2021-05-27 13:12:19,662 epoch 5 - iter 7/14 - loss 3.09270661 - samples/sec: 69.73 - lr: 0.100000
2021-05-27 13:12:20,118 epoch 5 - iter 8/14 - loss 3.21358186 - samples/sec: 70.15 - lr: 0.100000
2021-05-27 13:12:20,557 epoch 5 - iter 9/14 - loss 3.18568691 - samples/sec: 72.98 - lr: 0.100000
2021-05-27 13:12:21,013 epoch 5 - iter 10/14 - loss 3.36044493 - samples/sec: 70.22 - lr: 0.100000
2021-05-27 13:12:21,434 epoch 5 - iter 11/14 - loss 3.27662269 - samples/sec: 76.15 - lr: 0.100000
2021-05-27 13:12:21,890 epoch 5 - iter 12/14 - loss 3.35783092 - samples/sec: 70.27 - lr: 0.100000
2021-05-27 13:12:22,343 epoch 5 - iter 13/14 - loss 3.32467615 - samples/sec: 70.63 - lr: 0.100000
2021-05-27 13:12:22,700 epoch 5 - iter 14/14 - loss 3.36649430 - samples/sec: 89.89 - lr: 0.100000
2021-05-27 13:12:22,700 ----------------------------------------------------------------------------------------------------
2021-05-27 13:12:22,700 EPOCH 5 done: loss 3.3665 - lr 0.1000000
2021-05-27 13:12:23,249 DEV : loss 2.2252321243286133 - score 0.1684
2021-05-27 13:12:23,259 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:12:31,924 ----------------------------------------------------------------------------------------------------
2021-05-27 13:12:32,367 epoch 6 - iter 1/14 - loss 2.31037188 - samples/sec: 72.52 - lr: 0.100000
2021-05-27 13:12:32,913 epoch 6 - iter 2/14 - loss 2.52231133 - samples/sec: 58.60 - lr: 0.100000
2021-05-27 13:12:33,368 epoch 6 - iter 3/14 - loss 3.15540051 - samples/sec: 70.45 - lr: 0.100000
2021-05-27 13:12:33,822 epoch 6 - iter 4/14 - loss 3.22417110 - samples/sec: 70.51 - lr: 0.100000
2021-05-27 13:12:34,268 epoch 6 - iter 5/14 - loss 3.41474013 - samples/sec: 71.83 - lr: 0.100000
2021-05-27 13:12:34,710 epoch 6 - iter 6/14 - loss 3.28609796 - samples/sec: 72.43 - lr: 0.100000
2021-05-27 13:12:35,161 epoch 6 - iter 7/14 - loss 3.19984657 - samples/sec: 71.06 - lr: 0.100000
2021-05-27 13:12:35,602 epoch 6 - iter 8/14 - loss 3.22635651 - samples/sec: 72.57 - lr: 0.100000
2021-05-27 13:12:36,040 epoch 6 - iter 9/14 - loss 3.09999026 - samples/sec: 73.13 - lr: 0.100000
2021-05-27 13:12:36,484 epoch 6 - iter 10/14 - loss 3.05391910 - samples/sec: 72.08 - lr: 0.100000
2021-05-27 13:12:36,938 epoch 6 - iter 11/14 - loss 2.97625466 - samples/sec: 70.58 - lr: 0.100000
2021-05-27 13:12:37,397 epoch 6 - iter 12/14 - loss 3.08612309 - samples/sec: 69.77 - lr: 0.100000
2021-05-27 13:12:37,833 epoch 6 - iter 13/14 - loss 2.97938870 - samples/sec: 73.41 - lr: 0.100000
2021-05-27 13:12:38,201 epoch 6 - iter 14/14 - loss 2.99534963 - samples/sec: 87.19 - lr: 0.100000
2021-05-27 13:12:38,201 ----------------------------------------------------------------------------------------------------
2021-05-27 13:12:38,201 EPOCH 6 done: loss 2.9953 - lr 0.1000000
2021-05-27 13:12:38,746 DEV : loss 1.9394440650939941 - score 0.3429
2021-05-27 13:12:38,756 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:12:47,408 ----------------------------------------------------------------------------------------------------
2021-05-27 13:12:47,862 epoch 7 - iter 1/14 - loss 1.98453450 - samples/sec: 70.50 - lr: 0.100000
2021-05-27 13:12:48,319 epoch 7 - iter 2/14 - loss 2.20955217 - samples/sec: 70.17 - lr: 0.100000
2021-05-27 13:12:48,767 epoch 7 - iter 3/14 - loss 2.44721150 - samples/sec: 71.50 - lr: 0.100000
2021-05-27 13:12:49,214 epoch 7 - iter 4/14 - loss 2.62117606 - samples/sec: 71.61 - lr: 0.100000
2021-05-27 13:12:49,660 epoch 7 - iter 5/14 - loss 2.57483683 - samples/sec: 71.89 - lr: 0.100000
2021-05-27 13:12:50,117 epoch 7 - iter 6/14 - loss 2.78500636 - samples/sec: 70.02 - lr: 0.100000
2021-05-27 13:12:50,558 epoch 7 - iter 7/14 - loss 2.71350006 - samples/sec: 72.55 - lr: 0.100000
2021-05-27 13:12:51,003 epoch 7 - iter 8/14 - loss 2.81797943 - samples/sec: 71.97 - lr: 0.100000
2021-05-27 13:12:51,433 epoch 7 - iter 9/14 - loss 2.73637250 - samples/sec: 74.59 - lr: 0.100000
2021-05-27 13:12:51,880 epoch 7 - iter 10/14 - loss 2.68383696 - samples/sec: 71.65 - lr: 0.100000
2021-05-27 13:12:52,328 epoch 7 - iter 11/14 - loss 2.62214026 - samples/sec: 71.43 - lr: 0.100000
2021-05-27 13:12:52,772 epoch 7 - iter 12/14 - loss 2.68728081 - samples/sec: 72.24 - lr: 0.100000
2021-05-27 13:12:53,221 epoch 7 - iter 13/14 - loss 2.66778174 - samples/sec: 71.20 - lr: 0.100000
2021-05-27 13:12:53,586 epoch 7 - iter 14/14 - loss 2.67249886 - samples/sec: 87.77 - lr: 0.100000
2021-05-27 13:12:53,587 ----------------------------------------------------------------------------------------------------
2021-05-27 13:12:53,587 EPOCH 7 done: loss 2.6725 - lr 0.1000000
2021-05-27 13:12:54,128 DEV : loss 2.2250866889953613 - score 0.7673
2021-05-27 13:12:54,138 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:13:02,932 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:03,395 epoch 8 - iter 1/14 - loss 2.11640739 - samples/sec: 69.25 - lr: 0.100000
2021-05-27 13:13:03,839 epoch 8 - iter 2/14 - loss 2.52450359 - samples/sec: 72.09 - lr: 0.100000
2021-05-27 13:13:04,276 epoch 8 - iter 3/14 - loss 2.33645837 - samples/sec: 73.35 - lr: 0.100000
2021-05-27 13:13:04,715 epoch 8 - iter 4/14 - loss 2.38875240 - samples/sec: 72.83 - lr: 0.100000
2021-05-27 13:13:05,169 epoch 8 - iter 5/14 - loss 2.43251033 - samples/sec: 70.60 - lr: 0.100000
2021-05-27 13:13:05,606 epoch 8 - iter 6/14 - loss 2.29157410 - samples/sec: 73.25 - lr: 0.100000
2021-05-27 13:13:06,041 epoch 8 - iter 7/14 - loss 2.28403505 - samples/sec: 73.74 - lr: 0.100000
2021-05-27 13:13:06,501 epoch 8 - iter 8/14 - loss 2.30679135 - samples/sec: 69.53 - lr: 0.100000
2021-05-27 13:13:06,960 epoch 8 - iter 9/14 - loss 2.32544898 - samples/sec: 69.87 - lr: 0.100000
2021-05-27 13:13:07,408 epoch 8 - iter 10/14 - loss 2.39771475 - samples/sec: 71.51 - lr: 0.100000
2021-05-27 13:13:07,865 epoch 8 - iter 11/14 - loss 2.37185750 - samples/sec: 70.01 - lr: 0.100000
2021-05-27 13:13:08,318 epoch 8 - iter 12/14 - loss 2.40097583 - samples/sec: 70.73 - lr: 0.100000
2021-05-27 13:13:08,775 epoch 8 - iter 13/14 - loss 2.32305537 - samples/sec: 70.05 - lr: 0.100000
2021-05-27 13:13:09,144 epoch 8 - iter 14/14 - loss 2.39409608 - samples/sec: 86.83 - lr: 0.100000
2021-05-27 13:13:09,145 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:09,145 EPOCH 8 done: loss 2.3941 - lr 0.1000000
2021-05-27 13:13:09,693 DEV : loss 1.6287773847579956 - score 0.7391
2021-05-27 13:13:09,703 BAD EPOCHS (no improvement): 1
2021-05-27 13:13:09,703 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:10,166 epoch 9 - iter 1/14 - loss 1.48861575 - samples/sec: 69.29 - lr: 0.100000
2021-05-27 13:13:10,612 epoch 9 - iter 2/14 - loss 1.74817431 - samples/sec: 71.77 - lr: 0.100000
2021-05-27 13:13:11,070 epoch 9 - iter 3/14 - loss 1.62179542 - samples/sec: 69.90 - lr: 0.100000
2021-05-27 13:13:11,528 epoch 9 - iter 4/14 - loss 2.01898104 - samples/sec: 70.01 - lr: 0.100000
2021-05-27 13:13:11,963 epoch 9 - iter 5/14 - loss 1.95708709 - samples/sec: 73.57 - lr: 0.100000
2021-05-27 13:13:12,408 epoch 9 - iter 6/14 - loss 1.98523390 - samples/sec: 72.02 - lr: 0.100000
2021-05-27 13:13:12,866 epoch 9 - iter 7/14 - loss 2.04022680 - samples/sec: 69.87 - lr: 0.100000
2021-05-27 13:13:13,311 epoch 9 - iter 8/14 - loss 1.89168085 - samples/sec: 71.99 - lr: 0.100000
2021-05-27 13:13:13,762 epoch 9 - iter 9/14 - loss 1.89202193 - samples/sec: 70.94 - lr: 0.100000
2021-05-27 13:13:14,210 epoch 9 - iter 10/14 - loss 1.96929072 - samples/sec: 71.60 - lr: 0.100000
2021-05-27 13:13:14,669 epoch 9 - iter 11/14 - loss 2.07630211 - samples/sec: 69.71 - lr: 0.100000
2021-05-27 13:13:15,121 epoch 9 - iter 12/14 - loss 2.03736372 - samples/sec: 70.96 - lr: 0.100000
2021-05-27 13:13:15,577 epoch 9 - iter 13/14 - loss 2.22397187 - samples/sec: 70.25 - lr: 0.100000
2021-05-27 13:13:15,950 epoch 9 - iter 14/14 - loss 2.21443240 - samples/sec: 85.76 - lr: 0.100000
2021-05-27 13:13:15,951 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:15,951 EPOCH 9 done: loss 2.2144 - lr 0.1000000
2021-05-27 13:13:16,500 DEV : loss 1.3617193698883057 - score 0.7746
2021-05-27 13:13:16,510 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:13:25,312 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:25,779 epoch 10 - iter 1/14 - loss 1.86409533 - samples/sec: 68.61 - lr: 0.100000
2021-05-27 13:13:26,231 epoch 10 - iter 2/14 - loss 2.14530092 - samples/sec: 70.83 - lr: 0.100000
2021-05-27 13:13:26,688 epoch 10 - iter 3/14 - loss 2.17038159 - samples/sec: 70.21 - lr: 0.100000
2021-05-27 13:13:27,152 epoch 10 - iter 4/14 - loss 2.32330981 - samples/sec: 68.98 - lr: 0.100000
2021-05-27 13:13:27,715 epoch 10 - iter 5/14 - loss 2.37901175 - samples/sec: 56.90 - lr: 0.100000
2021-05-27 13:13:28,182 epoch 10 - iter 6/14 - loss 2.27497409 - samples/sec: 68.56 - lr: 0.100000
2021-05-27 13:13:28,624 epoch 10 - iter 7/14 - loss 2.27687160 - samples/sec: 72.40 - lr: 0.100000
2021-05-27 13:13:29,071 epoch 10 - iter 8/14 - loss 2.09636770 - samples/sec: 71.72 - lr: 0.100000
2021-05-27 13:13:29,529 epoch 10 - iter 9/14 - loss 2.10087642 - samples/sec: 69.89 - lr: 0.100000
2021-05-27 13:13:29,983 epoch 10 - iter 10/14 - loss 2.10324844 - samples/sec: 70.59 - lr: 0.100000
2021-05-27 13:13:30,424 epoch 10 - iter 11/14 - loss 2.05709501 - samples/sec: 72.60 - lr: 0.100000
2021-05-27 13:13:30,873 epoch 10 - iter 12/14 - loss 2.06621969 - samples/sec: 71.29 - lr: 0.100000
2021-05-27 13:13:31,323 epoch 10 - iter 13/14 - loss 2.08962545 - samples/sec: 71.25 - lr: 0.100000
2021-05-27 13:13:31,687 epoch 10 - iter 14/14 - loss 2.07114799 - samples/sec: 87.90 - lr: 0.100000
2021-05-27 13:13:31,688 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:31,688 EPOCH 10 done: loss 2.0711 - lr 0.1000000
2021-05-27 13:13:32,239 DEV : loss 1.7724337577819824 - score 0.5378
2021-05-27 13:13:32,249 BAD EPOCHS (no improvement): 1
2021-05-27 13:13:32,249 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:32,704 epoch 11 - iter 1/14 - loss 2.23046565 - samples/sec: 70.46 - lr: 0.100000
2021-05-27 13:13:33,148 epoch 11 - iter 2/14 - loss 2.11007690 - samples/sec: 72.07 - lr: 0.100000
2021-05-27 13:13:33,602 epoch 11 - iter 3/14 - loss 2.24915791 - samples/sec: 70.59 - lr: 0.100000
2021-05-27 13:13:34,062 epoch 11 - iter 4/14 - loss 2.02691990 - samples/sec: 69.62 - lr: 0.100000
2021-05-27 13:13:34,526 epoch 11 - iter 5/14 - loss 2.06555662 - samples/sec: 69.00 - lr: 0.100000
2021-05-27 13:13:34,984 epoch 11 - iter 6/14 - loss 2.05217659 - samples/sec: 69.93 - lr: 0.100000
2021-05-27 13:13:35,428 epoch 11 - iter 7/14 - loss 1.95157380 - samples/sec: 72.03 - lr: 0.100000
2021-05-27 13:13:35,885 epoch 11 - iter 8/14 - loss 1.92619291 - samples/sec: 70.20 - lr: 0.100000
2021-05-27 13:13:36,339 epoch 11 - iter 9/14 - loss 1.84977436 - samples/sec: 70.44 - lr: 0.100000
2021-05-27 13:13:36,787 epoch 11 - iter 10/14 - loss 1.78561957 - samples/sec: 71.48 - lr: 0.100000
2021-05-27 13:13:37,246 epoch 11 - iter 11/14 - loss 1.89968391 - samples/sec: 69.90 - lr: 0.100000
2021-05-27 13:13:37,707 epoch 11 - iter 12/14 - loss 1.90975126 - samples/sec: 69.37 - lr: 0.100000
2021-05-27 13:13:38,166 epoch 11 - iter 13/14 - loss 1.87383276 - samples/sec: 69.90 - lr: 0.100000
2021-05-27 13:13:38,522 epoch 11 - iter 14/14 - loss 1.84008842 - samples/sec: 89.75 - lr: 0.100000
2021-05-27 13:13:38,523 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:38,523 EPOCH 11 done: loss 1.8401 - lr 0.1000000
2021-05-27 13:13:39,074 DEV : loss 1.9621843099594116 - score 0.5929
2021-05-27 13:13:39,084 BAD EPOCHS (no improvement): 2
2021-05-27 13:13:39,085 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:39,529 epoch 12 - iter 1/14 - loss 1.79169393 - samples/sec: 72.05 - lr: 0.100000
2021-05-27 13:13:39,992 epoch 12 - iter 2/14 - loss 2.19696796 - samples/sec: 69.14 - lr: 0.100000
2021-05-27 13:13:40,451 epoch 12 - iter 3/14 - loss 1.93454671 - samples/sec: 69.91 - lr: 0.100000
2021-05-27 13:13:40,903 epoch 12 - iter 4/14 - loss 2.15131950 - samples/sec: 70.79 - lr: 0.100000
2021-05-27 13:13:41,371 epoch 12 - iter 5/14 - loss 1.99218898 - samples/sec: 68.40 - lr: 0.100000
2021-05-27 13:13:41,820 epoch 12 - iter 6/14 - loss 1.99257473 - samples/sec: 71.30 - lr: 0.100000
2021-05-27 13:13:42,266 epoch 12 - iter 7/14 - loss 1.96585933 - samples/sec: 71.84 - lr: 0.100000
2021-05-27 13:13:42,720 epoch 12 - iter 8/14 - loss 1.92329986 - samples/sec: 70.60 - lr: 0.100000
2021-05-27 13:13:43,181 epoch 12 - iter 9/14 - loss 1.88479692 - samples/sec: 69.43 - lr: 0.100000
2021-05-27 13:13:43,633 epoch 12 - iter 10/14 - loss 1.95167700 - samples/sec: 70.89 - lr: 0.100000
2021-05-27 13:13:44,081 epoch 12 - iter 11/14 - loss 1.91673468 - samples/sec: 71.57 - lr: 0.100000
2021-05-27 13:13:44,538 epoch 12 - iter 12/14 - loss 1.93970767 - samples/sec: 70.06 - lr: 0.100000
2021-05-27 13:13:44,991 epoch 12 - iter 13/14 - loss 1.96252938 - samples/sec: 70.71 - lr: 0.100000
2021-05-27 13:13:45,361 epoch 12 - iter 14/14 - loss 2.02586437 - samples/sec: 86.50 - lr: 0.100000
2021-05-27 13:13:45,361 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:45,361 EPOCH 12 done: loss 2.0259 - lr 0.1000000
2021-05-27 13:13:45,912 DEV : loss 1.5457011461257935 - score 0.7791
2021-05-27 13:13:45,922 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:13:54,796 ----------------------------------------------------------------------------------------------------
2021-05-27 13:13:55,247 epoch 13 - iter 1/14 - loss 1.29042530 - samples/sec: 71.09 - lr: 0.100000
2021-05-27 13:13:55,714 epoch 13 - iter 2/14 - loss 1.95931923 - samples/sec: 68.62 - lr: 0.100000
2021-05-27 13:13:56,158 epoch 13 - iter 3/14 - loss 1.81552037 - samples/sec: 72.14 - lr: 0.100000
2021-05-27 13:13:56,626 epoch 13 - iter 4/14 - loss 1.66580635 - samples/sec: 68.44 - lr: 0.100000
2021-05-27 13:13:57,085 epoch 13 - iter 5/14 - loss 1.72759125 - samples/sec: 69.74 - lr: 0.100000
2021-05-27 13:13:57,525 epoch 13 - iter 6/14 - loss 1.78787980 - samples/sec: 72.77 - lr: 0.100000
2021-05-27 13:13:57,981 epoch 13 - iter 7/14 - loss 1.75018968 - samples/sec: 70.32 - lr: 0.100000
2021-05-27 13:13:58,445 epoch 13 - iter 8/14 - loss 1.60702172 - samples/sec: 68.97 - lr: 0.100000
2021-05-27 13:13:58,896 epoch 13 - iter 9/14 - loss 1.57817565 - samples/sec: 71.02 - lr: 0.100000
2021-05-27 13:13:59,357 epoch 13 - iter 10/14 - loss 1.68237224 - samples/sec: 69.56 - lr: 0.100000
2021-05-27 13:13:59,809 epoch 13 - iter 11/14 - loss 1.83204722 - samples/sec: 70.76 - lr: 0.100000
2021-05-27 13:14:00,261 epoch 13 - iter 12/14 - loss 1.77967906 - samples/sec: 70.86 - lr: 0.100000
2021-05-27 13:14:00,712 epoch 13 - iter 13/14 - loss 1.70105542 - samples/sec: 71.02 - lr: 0.100000
2021-05-27 13:14:01,088 epoch 13 - iter 14/14 - loss 1.82425560 - samples/sec: 85.24 - lr: 0.100000
2021-05-27 13:14:01,088 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:01,088 EPOCH 13 done: loss 1.8243 - lr 0.1000000
2021-05-27 13:14:01,639 DEV : loss 1.4298938512802124 - score 0.7571
2021-05-27 13:14:01,649 BAD EPOCHS (no improvement): 1
2021-05-27 13:14:01,649 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:02,109 epoch 14 - iter 1/14 - loss 1.35198522 - samples/sec: 69.56 - lr: 0.100000
2021-05-27 13:14:02,565 epoch 14 - iter 2/14 - loss 1.64626443 - samples/sec: 70.23 - lr: 0.100000
2021-05-27 13:14:03,021 epoch 14 - iter 3/14 - loss 1.56348002 - samples/sec: 70.37 - lr: 0.100000
2021-05-27 13:14:03,473 epoch 14 - iter 4/14 - loss 1.40912582 - samples/sec: 70.83 - lr: 0.100000
2021-05-27 13:14:03,925 epoch 14 - iter 5/14 - loss 1.36967174 - samples/sec: 70.90 - lr: 0.100000
2021-05-27 13:14:04,368 epoch 14 - iter 6/14 - loss 1.42128898 - samples/sec: 72.19 - lr: 0.100000
2021-05-27 13:14:04,817 epoch 14 - iter 7/14 - loss 1.46206211 - samples/sec: 71.32 - lr: 0.100000
2021-05-27 13:14:05,280 epoch 14 - iter 8/14 - loss 1.47955617 - samples/sec: 69.27 - lr: 0.100000
2021-05-27 13:14:05,727 epoch 14 - iter 9/14 - loss 1.43166729 - samples/sec: 71.64 - lr: 0.100000
2021-05-27 13:14:06,181 epoch 14 - iter 10/14 - loss 1.57444264 - samples/sec: 70.47 - lr: 0.100000
2021-05-27 13:14:06,637 epoch 14 - iter 11/14 - loss 1.54042269 - samples/sec: 70.31 - lr: 0.100000
2021-05-27 13:14:07,086 epoch 14 - iter 12/14 - loss 1.50676344 - samples/sec: 71.35 - lr: 0.100000
2021-05-27 13:14:07,543 epoch 14 - iter 13/14 - loss 1.50491841 - samples/sec: 70.01 - lr: 0.100000
2021-05-27 13:14:07,918 epoch 14 - iter 14/14 - loss 1.49532899 - samples/sec: 85.56 - lr: 0.100000
2021-05-27 13:14:07,918 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:07,918 EPOCH 14 done: loss 1.4953 - lr 0.1000000
2021-05-27 13:14:08,469 DEV : loss 1.2915704250335693 - score 0.7836
2021-05-27 13:14:08,479 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:14:17,446 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:18,012 epoch 15 - iter 1/14 - loss 1.38195419 - samples/sec: 56.61 - lr: 0.100000
2021-05-27 13:14:18,460 epoch 15 - iter 2/14 - loss 1.37917876 - samples/sec: 71.53 - lr: 0.100000
2021-05-27 13:14:18,903 epoch 15 - iter 3/14 - loss 1.44310741 - samples/sec: 72.29 - lr: 0.100000
2021-05-27 13:14:19,345 epoch 15 - iter 4/14 - loss 1.49992427 - samples/sec: 72.44 - lr: 0.100000
2021-05-27 13:14:19,790 epoch 15 - iter 5/14 - loss 1.43685815 - samples/sec: 72.00 - lr: 0.100000
2021-05-27 13:14:20,248 epoch 15 - iter 6/14 - loss 1.70517490 - samples/sec: 69.99 - lr: 0.100000
2021-05-27 13:14:20,703 epoch 15 - iter 7/14 - loss 1.61359680 - samples/sec: 70.33 - lr: 0.100000
2021-05-27 13:14:21,138 epoch 15 - iter 8/14 - loss 1.55056293 - samples/sec: 73.74 - lr: 0.100000
2021-05-27 13:14:21,595 epoch 15 - iter 9/14 - loss 1.52051551 - samples/sec: 69.94 - lr: 0.100000
2021-05-27 13:14:22,040 epoch 15 - iter 10/14 - loss 1.52777194 - samples/sec: 72.08 - lr: 0.100000
2021-05-27 13:14:22,499 epoch 15 - iter 11/14 - loss 1.55036596 - samples/sec: 69.77 - lr: 0.100000
2021-05-27 13:14:22,943 epoch 15 - iter 12/14 - loss 1.49331140 - samples/sec: 72.15 - lr: 0.100000
2021-05-27 13:14:23,395 epoch 15 - iter 13/14 - loss 1.46715327 - samples/sec: 70.89 - lr: 0.100000
2021-05-27 13:14:23,740 epoch 15 - iter 14/14 - loss 1.44176058 - samples/sec: 92.70 - lr: 0.100000
2021-05-27 13:14:23,741 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:23,741 EPOCH 15 done: loss 1.4418 - lr 0.1000000
2021-05-27 13:14:24,285 DEV : loss 2.024230480194092 - score 0.6174
2021-05-27 13:14:24,295 BAD EPOCHS (no improvement): 1
2021-05-27 13:14:24,295 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:24,749 epoch 16 - iter 1/14 - loss 1.89707601 - samples/sec: 70.49 - lr: 0.100000
2021-05-27 13:14:25,200 epoch 16 - iter 2/14 - loss 1.86530024 - samples/sec: 71.11 - lr: 0.100000
2021-05-27 13:14:25,659 epoch 16 - iter 3/14 - loss 1.78447227 - samples/sec: 69.74 - lr: 0.100000
2021-05-27 13:14:26,089 epoch 16 - iter 4/14 - loss 1.62589106 - samples/sec: 74.50 - lr: 0.100000
2021-05-27 13:14:26,529 epoch 16 - iter 5/14 - loss 1.50647237 - samples/sec: 72.78 - lr: 0.100000
2021-05-27 13:14:26,985 epoch 16 - iter 6/14 - loss 1.42569691 - samples/sec: 70.32 - lr: 0.100000
2021-05-27 13:14:27,418 epoch 16 - iter 7/14 - loss 1.45353998 - samples/sec: 73.95 - lr: 0.100000
2021-05-27 13:14:27,871 epoch 16 - iter 8/14 - loss 1.40073167 - samples/sec: 70.64 - lr: 0.100000
2021-05-27 13:14:28,313 epoch 16 - iter 9/14 - loss 1.46870148 - samples/sec: 72.44 - lr: 0.100000
2021-05-27 13:14:28,763 epoch 16 - iter 10/14 - loss 1.45842738 - samples/sec: 71.25 - lr: 0.100000
2021-05-27 13:14:29,213 epoch 16 - iter 11/14 - loss 1.40118703 - samples/sec: 71.15 - lr: 0.100000
2021-05-27 13:14:29,662 epoch 16 - iter 12/14 - loss 1.37783295 - samples/sec: 71.31 - lr: 0.100000
2021-05-27 13:14:30,113 epoch 16 - iter 13/14 - loss 1.35645657 - samples/sec: 70.98 - lr: 0.100000
2021-05-27 13:14:30,480 epoch 16 - iter 14/14 - loss 1.49240049 - samples/sec: 87.37 - lr: 0.100000
2021-05-27 13:14:30,480 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:30,480 EPOCH 16 done: loss 1.4924 - lr 0.1000000
2021-05-27 13:14:31,024 DEV : loss 1.1148345470428467 - score 0.8258
2021-05-27 13:14:31,034 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:14:39,828 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:40,281 epoch 17 - iter 1/14 - loss 1.20738721 - samples/sec: 70.76 - lr: 0.100000
2021-05-27 13:14:40,737 epoch 17 - iter 2/14 - loss 1.15558684 - samples/sec: 70.16 - lr: 0.100000
2021-05-27 13:14:41,188 epoch 17 - iter 3/14 - loss 1.16421445 - samples/sec: 71.11 - lr: 0.100000
2021-05-27 13:14:41,647 epoch 17 - iter 4/14 - loss 1.53230584 - samples/sec: 69.78 - lr: 0.100000
2021-05-27 13:14:42,101 epoch 17 - iter 5/14 - loss 1.41652675 - samples/sec: 70.50 - lr: 0.100000
2021-05-27 13:14:42,554 epoch 17 - iter 6/14 - loss 1.59158027 - samples/sec: 70.71 - lr: 0.100000
2021-05-27 13:14:42,992 epoch 17 - iter 7/14 - loss 1.55917103 - samples/sec: 73.09 - lr: 0.100000
2021-05-27 13:14:43,454 epoch 17 - iter 8/14 - loss 1.50314716 - samples/sec: 69.43 - lr: 0.100000
2021-05-27 13:14:43,908 epoch 17 - iter 9/14 - loss 1.57379275 - samples/sec: 70.47 - lr: 0.100000
2021-05-27 13:14:44,362 epoch 17 - iter 10/14 - loss 1.72963912 - samples/sec: 70.59 - lr: 0.100000
2021-05-27 13:14:44,798 epoch 17 - iter 11/14 - loss 1.74788614 - samples/sec: 73.40 - lr: 0.100000
2021-05-27 13:14:45,262 epoch 17 - iter 12/14 - loss 1.69742761 - samples/sec: 69.05 - lr: 0.100000
2021-05-27 13:14:45,715 epoch 17 - iter 13/14 - loss 1.75377486 - samples/sec: 70.70 - lr: 0.100000
2021-05-27 13:14:46,083 epoch 17 - iter 14/14 - loss 1.69954710 - samples/sec: 86.99 - lr: 0.100000
2021-05-27 13:14:46,084 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:46,084 EPOCH 17 done: loss 1.6995 - lr 0.1000000
2021-05-27 13:14:46,634 DEV : loss 1.8213486671447754 - score 0.6718
2021-05-27 13:14:46,644 BAD EPOCHS (no improvement): 1
2021-05-27 13:14:46,644 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:47,086 epoch 18 - iter 1/14 - loss 1.34729338 - samples/sec: 72.43 - lr: 0.100000
2021-05-27 13:14:47,544 epoch 18 - iter 2/14 - loss 0.99969172 - samples/sec: 69.87 - lr: 0.100000
2021-05-27 13:14:48,005 epoch 18 - iter 3/14 - loss 1.36694360 - samples/sec: 69.46 - lr: 0.100000
2021-05-27 13:14:48,462 epoch 18 - iter 4/14 - loss 1.40208662 - samples/sec: 70.16 - lr: 0.100000
2021-05-27 13:14:48,914 epoch 18 - iter 5/14 - loss 1.41791003 - samples/sec: 70.84 - lr: 0.100000
2021-05-27 13:14:49,364 epoch 18 - iter 6/14 - loss 1.43429945 - samples/sec: 71.20 - lr: 0.100000
2021-05-27 13:14:49,817 epoch 18 - iter 7/14 - loss 1.52440352 - samples/sec: 70.68 - lr: 0.100000
2021-05-27 13:14:50,269 epoch 18 - iter 8/14 - loss 1.44418812 - samples/sec: 70.94 - lr: 0.100000
2021-05-27 13:14:50,732 epoch 18 - iter 9/14 - loss 1.39174451 - samples/sec: 69.13 - lr: 0.100000
2021-05-27 13:14:51,187 epoch 18 - iter 10/14 - loss 1.32790415 - samples/sec: 70.38 - lr: 0.100000
2021-05-27 13:14:51,639 epoch 18 - iter 11/14 - loss 1.44828465 - samples/sec: 70.78 - lr: 0.100000
2021-05-27 13:14:52,081 epoch 18 - iter 12/14 - loss 1.43392341 - samples/sec: 72.57 - lr: 0.100000
2021-05-27 13:14:52,529 epoch 18 - iter 13/14 - loss 1.36854393 - samples/sec: 71.42 - lr: 0.100000
2021-05-27 13:14:52,900 epoch 18 - iter 14/14 - loss 1.39174025 - samples/sec: 86.46 - lr: 0.100000
2021-05-27 13:14:52,900 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:52,900 EPOCH 18 done: loss 1.3917 - lr 0.1000000
2021-05-27 13:14:53,449 DEV : loss 1.1670198440551758 - score 0.8
2021-05-27 13:14:53,459 BAD EPOCHS (no improvement): 2
2021-05-27 13:14:53,459 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:53,922 epoch 19 - iter 1/14 - loss 1.38980532 - samples/sec: 69.21 - lr: 0.100000
2021-05-27 13:14:54,359 epoch 19 - iter 2/14 - loss 1.26600599 - samples/sec: 73.26 - lr: 0.100000
2021-05-27 13:14:54,807 epoch 19 - iter 3/14 - loss 1.27054000 - samples/sec: 71.48 - lr: 0.100000
2021-05-27 13:14:55,256 epoch 19 - iter 4/14 - loss 1.22411016 - samples/sec: 71.31 - lr: 0.100000
2021-05-27 13:14:55,705 epoch 19 - iter 5/14 - loss 1.35004168 - samples/sec: 71.42 - lr: 0.100000
2021-05-27 13:14:56,160 epoch 19 - iter 6/14 - loss 1.56048791 - samples/sec: 70.39 - lr: 0.100000
2021-05-27 13:14:56,611 epoch 19 - iter 7/14 - loss 1.57312376 - samples/sec: 70.92 - lr: 0.100000
2021-05-27 13:14:57,069 epoch 19 - iter 8/14 - loss 1.57329398 - samples/sec: 69.95 - lr: 0.100000
2021-05-27 13:14:57,524 epoch 19 - iter 9/14 - loss 1.52556128 - samples/sec: 70.45 - lr: 0.100000
2021-05-27 13:14:57,976 epoch 19 - iter 10/14 - loss 1.47936829 - samples/sec: 70.79 - lr: 0.100000
2021-05-27 13:14:58,420 epoch 19 - iter 11/14 - loss 1.44613562 - samples/sec: 72.15 - lr: 0.100000
2021-05-27 13:14:58,886 epoch 19 - iter 12/14 - loss 1.39472305 - samples/sec: 68.73 - lr: 0.100000
2021-05-27 13:14:59,337 epoch 19 - iter 13/14 - loss 1.46574590 - samples/sec: 71.10 - lr: 0.100000
2021-05-27 13:14:59,705 epoch 19 - iter 14/14 - loss 1.48297236 - samples/sec: 86.85 - lr: 0.100000
2021-05-27 13:14:59,706 ----------------------------------------------------------------------------------------------------
2021-05-27 13:14:59,706 EPOCH 19 done: loss 1.4830 - lr 0.1000000
2021-05-27 13:15:00,255 DEV : loss 1.1915913820266724 - score 0.8082
2021-05-27 13:15:00,265 BAD EPOCHS (no improvement): 3
2021-05-27 13:15:00,265 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:00,724 epoch 20 - iter 1/14 - loss 1.05085826 - samples/sec: 69.78 - lr: 0.100000
2021-05-27 13:15:01,176 epoch 20 - iter 2/14 - loss 1.01965806 - samples/sec: 70.94 - lr: 0.100000
2021-05-27 13:15:01,745 epoch 20 - iter 3/14 - loss 1.11210050 - samples/sec: 56.25 - lr: 0.100000
2021-05-27 13:15:02,187 epoch 20 - iter 4/14 - loss 1.13173978 - samples/sec: 72.48 - lr: 0.100000
2021-05-27 13:15:02,631 epoch 20 - iter 5/14 - loss 1.30364536 - samples/sec: 72.09 - lr: 0.100000
2021-05-27 13:15:03,086 epoch 20 - iter 6/14 - loss 1.31435999 - samples/sec: 70.51 - lr: 0.100000
2021-05-27 13:15:03,552 epoch 20 - iter 7/14 - loss 1.23284623 - samples/sec: 68.61 - lr: 0.100000
2021-05-27 13:15:04,013 epoch 20 - iter 8/14 - loss 1.19987775 - samples/sec: 69.62 - lr: 0.100000
2021-05-27 13:15:04,465 epoch 20 - iter 9/14 - loss 1.18365348 - samples/sec: 70.77 - lr: 0.100000
2021-05-27 13:15:04,917 epoch 20 - iter 10/14 - loss 1.24727036 - samples/sec: 70.83 - lr: 0.100000
2021-05-27 13:15:05,370 epoch 20 - iter 11/14 - loss 1.25149673 - samples/sec: 70.77 - lr: 0.100000
2021-05-27 13:15:05,812 epoch 20 - iter 12/14 - loss 1.22913427 - samples/sec: 72.50 - lr: 0.100000
2021-05-27 13:15:06,260 epoch 20 - iter 13/14 - loss 1.25192778 - samples/sec: 71.39 - lr: 0.100000
2021-05-27 13:15:06,630 epoch 20 - iter 14/14 - loss 1.25762485 - samples/sec: 86.62 - lr: 0.100000
2021-05-27 13:15:06,630 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:06,631 EPOCH 20 done: loss 1.2576 - lr 0.1000000
2021-05-27 13:15:07,180 DEV : loss 1.3583418130874634 - score 0.7463
Epoch    20: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 13:15:07,191 BAD EPOCHS (no improvement): 4
2021-05-27 13:15:07,191 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:07,632 epoch 21 - iter 1/14 - loss 0.64740241 - samples/sec: 72.61 - lr: 0.050000
2021-05-27 13:15:08,085 epoch 21 - iter 2/14 - loss 0.71839172 - samples/sec: 70.65 - lr: 0.050000
2021-05-27 13:15:08,522 epoch 21 - iter 3/14 - loss 0.97201582 - samples/sec: 73.31 - lr: 0.050000
2021-05-27 13:15:08,971 epoch 21 - iter 4/14 - loss 0.96460262 - samples/sec: 71.29 - lr: 0.050000
2021-05-27 13:15:09,420 epoch 21 - iter 5/14 - loss 0.93167634 - samples/sec: 71.44 - lr: 0.050000
2021-05-27 13:15:09,883 epoch 21 - iter 6/14 - loss 1.05294009 - samples/sec: 69.17 - lr: 0.050000
2021-05-27 13:15:10,348 epoch 21 - iter 7/14 - loss 1.07241923 - samples/sec: 68.81 - lr: 0.050000
2021-05-27 13:15:10,808 epoch 21 - iter 8/14 - loss 1.00491950 - samples/sec: 69.61 - lr: 0.050000
2021-05-27 13:15:11,272 epoch 21 - iter 9/14 - loss 1.06194573 - samples/sec: 69.11 - lr: 0.050000
2021-05-27 13:15:11,728 epoch 21 - iter 10/14 - loss 1.05430735 - samples/sec: 70.22 - lr: 0.050000
2021-05-27 13:15:12,176 epoch 21 - iter 11/14 - loss 1.02380747 - samples/sec: 71.52 - lr: 0.050000
2021-05-27 13:15:12,635 epoch 21 - iter 12/14 - loss 1.02048209 - samples/sec: 69.76 - lr: 0.050000
2021-05-27 13:15:13,078 epoch 21 - iter 13/14 - loss 1.00958199 - samples/sec: 72.33 - lr: 0.050000
2021-05-27 13:15:13,442 epoch 21 - iter 14/14 - loss 0.99550985 - samples/sec: 88.08 - lr: 0.050000
2021-05-27 13:15:13,442 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:13,442 EPOCH 21 done: loss 0.9955 - lr 0.0500000
2021-05-27 13:15:13,991 DEV : loss 1.0082488059997559 - score 0.8272
2021-05-27 13:15:14,001 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:15:22,757 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:23,190 epoch 22 - iter 1/14 - loss 1.04896402 - samples/sec: 74.11 - lr: 0.050000
2021-05-27 13:15:23,629 epoch 22 - iter 2/14 - loss 0.81544477 - samples/sec: 72.85 - lr: 0.050000
2021-05-27 13:15:24,061 epoch 22 - iter 3/14 - loss 0.82181247 - samples/sec: 74.23 - lr: 0.050000
2021-05-27 13:15:24,512 epoch 22 - iter 4/14 - loss 0.87671381 - samples/sec: 70.99 - lr: 0.050000
2021-05-27 13:15:24,960 epoch 22 - iter 5/14 - loss 0.87996962 - samples/sec: 71.45 - lr: 0.050000
2021-05-27 13:15:25,418 epoch 22 - iter 6/14 - loss 0.85529981 - samples/sec: 69.93 - lr: 0.050000
2021-05-27 13:15:25,880 epoch 22 - iter 7/14 - loss 0.88530617 - samples/sec: 69.30 - lr: 0.050000
2021-05-27 13:15:26,337 epoch 22 - iter 8/14 - loss 0.92796557 - samples/sec: 70.08 - lr: 0.050000
2021-05-27 13:15:26,789 epoch 22 - iter 9/14 - loss 0.92763703 - samples/sec: 70.89 - lr: 0.050000
2021-05-27 13:15:27,239 epoch 22 - iter 10/14 - loss 0.89949305 - samples/sec: 71.17 - lr: 0.050000
2021-05-27 13:15:27,699 epoch 22 - iter 11/14 - loss 0.87123797 - samples/sec: 69.67 - lr: 0.050000
2021-05-27 13:15:28,158 epoch 22 - iter 12/14 - loss 0.86229525 - samples/sec: 69.80 - lr: 0.050000
2021-05-27 13:15:28,625 epoch 22 - iter 13/14 - loss 0.86775149 - samples/sec: 68.65 - lr: 0.050000
2021-05-27 13:15:28,995 epoch 22 - iter 14/14 - loss 0.89852415 - samples/sec: 86.40 - lr: 0.050000
2021-05-27 13:15:28,996 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:28,996 EPOCH 22 done: loss 0.8985 - lr 0.0500000
2021-05-27 13:15:29,546 DEV : loss 1.040670394897461 - score 0.7929
2021-05-27 13:15:29,556 BAD EPOCHS (no improvement): 1
2021-05-27 13:15:29,556 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:30,008 epoch 23 - iter 1/14 - loss 0.94460273 - samples/sec: 70.77 - lr: 0.050000
2021-05-27 13:15:30,467 epoch 23 - iter 2/14 - loss 0.90577742 - samples/sec: 69.87 - lr: 0.050000
2021-05-27 13:15:30,928 epoch 23 - iter 3/14 - loss 0.86320382 - samples/sec: 69.41 - lr: 0.050000
2021-05-27 13:15:31,379 epoch 23 - iter 4/14 - loss 0.83619475 - samples/sec: 71.09 - lr: 0.050000
2021-05-27 13:15:31,847 epoch 23 - iter 5/14 - loss 0.82974606 - samples/sec: 68.49 - lr: 0.050000
2021-05-27 13:15:32,303 epoch 23 - iter 6/14 - loss 0.83583158 - samples/sec: 70.15 - lr: 0.050000
2021-05-27 13:15:32,756 epoch 23 - iter 7/14 - loss 0.86026709 - samples/sec: 70.76 - lr: 0.050000
2021-05-27 13:15:33,214 epoch 23 - iter 8/14 - loss 0.85947376 - samples/sec: 69.92 - lr: 0.050000
2021-05-27 13:15:33,667 epoch 23 - iter 9/14 - loss 0.80993940 - samples/sec: 70.66 - lr: 0.050000
2021-05-27 13:15:34,123 epoch 23 - iter 10/14 - loss 0.85005113 - samples/sec: 70.19 - lr: 0.050000
2021-05-27 13:15:34,581 epoch 23 - iter 11/14 - loss 0.84962218 - samples/sec: 69.98 - lr: 0.050000
2021-05-27 13:15:35,039 epoch 23 - iter 12/14 - loss 0.86107427 - samples/sec: 70.02 - lr: 0.050000
2021-05-27 13:15:35,498 epoch 23 - iter 13/14 - loss 0.90055020 - samples/sec: 69.67 - lr: 0.050000
2021-05-27 13:15:35,849 epoch 23 - iter 14/14 - loss 0.90601721 - samples/sec: 91.41 - lr: 0.050000
2021-05-27 13:15:35,849 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:35,849 EPOCH 23 done: loss 0.9060 - lr 0.0500000
2021-05-27 13:15:36,399 DEV : loss 0.9777796864509583 - score 0.8395
2021-05-27 13:15:36,410 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:15:45,415 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:45,865 epoch 24 - iter 1/14 - loss 1.10491812 - samples/sec: 71.39 - lr: 0.050000
2021-05-27 13:15:46,305 epoch 24 - iter 2/14 - loss 0.95870745 - samples/sec: 72.73 - lr: 0.050000
2021-05-27 13:15:46,762 epoch 24 - iter 3/14 - loss 1.04045860 - samples/sec: 70.06 - lr: 0.050000
2021-05-27 13:15:47,195 epoch 24 - iter 4/14 - loss 0.99021001 - samples/sec: 73.99 - lr: 0.050000
2021-05-27 13:15:47,633 epoch 24 - iter 5/14 - loss 0.94691912 - samples/sec: 73.19 - lr: 0.050000
2021-05-27 13:15:48,087 epoch 24 - iter 6/14 - loss 0.92370873 - samples/sec: 70.48 - lr: 0.050000
2021-05-27 13:15:48,541 epoch 24 - iter 7/14 - loss 0.94300826 - samples/sec: 70.60 - lr: 0.050000
2021-05-27 13:15:48,980 epoch 24 - iter 8/14 - loss 0.87057309 - samples/sec: 72.86 - lr: 0.050000
2021-05-27 13:15:49,420 epoch 24 - iter 9/14 - loss 0.88634225 - samples/sec: 72.79 - lr: 0.050000
2021-05-27 13:15:49,873 epoch 24 - iter 10/14 - loss 0.87116332 - samples/sec: 70.72 - lr: 0.050000
2021-05-27 13:15:50,324 epoch 24 - iter 11/14 - loss 0.86590581 - samples/sec: 71.04 - lr: 0.050000
2021-05-27 13:15:50,775 epoch 24 - iter 12/14 - loss 0.88146089 - samples/sec: 71.06 - lr: 0.050000
2021-05-27 13:15:51,227 epoch 24 - iter 13/14 - loss 0.86176287 - samples/sec: 70.91 - lr: 0.050000
2021-05-27 13:15:51,591 epoch 24 - iter 14/14 - loss 0.84588349 - samples/sec: 87.84 - lr: 0.050000
2021-05-27 13:15:51,592 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:51,592 EPOCH 24 done: loss 0.8459 - lr 0.0500000
2021-05-27 13:15:52,132 DEV : loss 0.9646588563919067 - score 0.8272
2021-05-27 13:15:52,142 BAD EPOCHS (no improvement): 1
2021-05-27 13:15:52,142 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:52,586 epoch 25 - iter 1/14 - loss 0.94501132 - samples/sec: 72.25 - lr: 0.050000
2021-05-27 13:15:53,036 epoch 25 - iter 2/14 - loss 0.95504496 - samples/sec: 71.08 - lr: 0.050000
2021-05-27 13:15:53,479 epoch 25 - iter 3/14 - loss 1.09061267 - samples/sec: 72.29 - lr: 0.050000
2021-05-27 13:15:53,924 epoch 25 - iter 4/14 - loss 0.97018470 - samples/sec: 72.05 - lr: 0.050000
2021-05-27 13:15:54,383 epoch 25 - iter 5/14 - loss 0.87224594 - samples/sec: 69.81 - lr: 0.050000
2021-05-27 13:15:54,833 epoch 25 - iter 6/14 - loss 0.84205307 - samples/sec: 71.08 - lr: 0.050000
2021-05-27 13:15:55,290 epoch 25 - iter 7/14 - loss 0.89931707 - samples/sec: 70.14 - lr: 0.050000
2021-05-27 13:15:55,734 epoch 25 - iter 8/14 - loss 0.91348735 - samples/sec: 72.20 - lr: 0.050000
2021-05-27 13:15:56,184 epoch 25 - iter 9/14 - loss 0.86277051 - samples/sec: 71.10 - lr: 0.050000
2021-05-27 13:15:56,632 epoch 25 - iter 10/14 - loss 0.86440224 - samples/sec: 71.48 - lr: 0.050000
2021-05-27 13:15:57,172 epoch 25 - iter 11/14 - loss 0.87652219 - samples/sec: 59.33 - lr: 0.050000
2021-05-27 13:15:57,620 epoch 25 - iter 12/14 - loss 0.87868513 - samples/sec: 71.44 - lr: 0.050000
2021-05-27 13:15:58,070 epoch 25 - iter 13/14 - loss 0.86825062 - samples/sec: 71.29 - lr: 0.050000
2021-05-27 13:15:58,416 epoch 25 - iter 14/14 - loss 0.87278338 - samples/sec: 92.39 - lr: 0.050000
2021-05-27 13:15:58,417 ----------------------------------------------------------------------------------------------------
2021-05-27 13:15:58,417 EPOCH 25 done: loss 0.8728 - lr 0.0500000
2021-05-27 13:15:58,958 DEV : loss 1.0493253469467163 - score 0.8442
2021-05-27 13:15:58,968 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:16:08,335 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:08,768 epoch 26 - iter 1/14 - loss 1.22046447 - samples/sec: 74.08 - lr: 0.050000
2021-05-27 13:16:09,213 epoch 26 - iter 2/14 - loss 1.01580387 - samples/sec: 71.95 - lr: 0.050000
2021-05-27 13:16:09,666 epoch 26 - iter 3/14 - loss 0.80020233 - samples/sec: 70.83 - lr: 0.050000
2021-05-27 13:16:10,122 epoch 26 - iter 4/14 - loss 0.81619206 - samples/sec: 70.15 - lr: 0.050000
2021-05-27 13:16:10,569 epoch 26 - iter 5/14 - loss 0.76876965 - samples/sec: 71.72 - lr: 0.050000
2021-05-27 13:16:11,024 epoch 26 - iter 6/14 - loss 0.78115932 - samples/sec: 70.29 - lr: 0.050000
2021-05-27 13:16:11,482 epoch 26 - iter 7/14 - loss 0.80929453 - samples/sec: 69.99 - lr: 0.050000
2021-05-27 13:16:11,932 epoch 26 - iter 8/14 - loss 0.82871454 - samples/sec: 71.14 - lr: 0.050000
2021-05-27 13:16:12,392 epoch 26 - iter 9/14 - loss 0.83066987 - samples/sec: 69.67 - lr: 0.050000
2021-05-27 13:16:12,856 epoch 26 - iter 10/14 - loss 0.85395364 - samples/sec: 69.06 - lr: 0.050000
2021-05-27 13:16:13,307 epoch 26 - iter 11/14 - loss 0.84994448 - samples/sec: 70.96 - lr: 0.050000
2021-05-27 13:16:13,744 epoch 26 - iter 12/14 - loss 0.84857578 - samples/sec: 73.33 - lr: 0.050000
2021-05-27 13:16:14,192 epoch 26 - iter 13/14 - loss 0.86850861 - samples/sec: 71.45 - lr: 0.050000
2021-05-27 13:16:14,561 epoch 26 - iter 14/14 - loss 0.85316030 - samples/sec: 86.99 - lr: 0.050000
2021-05-27 13:16:14,561 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:14,561 EPOCH 26 done: loss 0.8532 - lr 0.0500000
2021-05-27 13:16:15,110 DEV : loss 1.1704084873199463 - score 0.8267
2021-05-27 13:16:15,120 BAD EPOCHS (no improvement): 1
2021-05-27 13:16:15,120 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:15,566 epoch 27 - iter 1/14 - loss 0.54031754 - samples/sec: 71.87 - lr: 0.050000
2021-05-27 13:16:16,014 epoch 27 - iter 2/14 - loss 0.53929132 - samples/sec: 71.43 - lr: 0.050000
2021-05-27 13:16:16,482 epoch 27 - iter 3/14 - loss 0.72320855 - samples/sec: 68.60 - lr: 0.050000
2021-05-27 13:16:16,921 epoch 27 - iter 4/14 - loss 0.75887808 - samples/sec: 72.85 - lr: 0.050000
2021-05-27 13:16:17,372 epoch 27 - iter 5/14 - loss 0.70395048 - samples/sec: 70.99 - lr: 0.050000
2021-05-27 13:16:17,818 epoch 27 - iter 6/14 - loss 0.74471629 - samples/sec: 71.91 - lr: 0.050000
2021-05-27 13:16:18,274 epoch 27 - iter 7/14 - loss 0.74535128 - samples/sec: 70.21 - lr: 0.050000
2021-05-27 13:16:18,730 epoch 27 - iter 8/14 - loss 0.75614339 - samples/sec: 70.24 - lr: 0.050000
2021-05-27 13:16:19,184 epoch 27 - iter 9/14 - loss 0.78200983 - samples/sec: 70.57 - lr: 0.050000
2021-05-27 13:16:19,623 epoch 27 - iter 10/14 - loss 0.76896842 - samples/sec: 72.98 - lr: 0.050000
2021-05-27 13:16:20,078 epoch 27 - iter 11/14 - loss 0.79712669 - samples/sec: 70.31 - lr: 0.050000
2021-05-27 13:16:20,533 epoch 27 - iter 12/14 - loss 0.80536555 - samples/sec: 70.39 - lr: 0.050000
2021-05-27 13:16:20,994 epoch 27 - iter 13/14 - loss 0.81453955 - samples/sec: 69.57 - lr: 0.050000
2021-05-27 13:16:21,367 epoch 27 - iter 14/14 - loss 0.82173003 - samples/sec: 85.82 - lr: 0.050000
2021-05-27 13:16:21,367 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:21,367 EPOCH 27 done: loss 0.8217 - lr 0.0500000
2021-05-27 13:16:21,917 DEV : loss 0.9906529784202576 - score 0.8235
2021-05-27 13:16:21,927 BAD EPOCHS (no improvement): 2
2021-05-27 13:16:21,927 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:22,368 epoch 28 - iter 1/14 - loss 0.34895694 - samples/sec: 72.69 - lr: 0.050000
2021-05-27 13:16:22,819 epoch 28 - iter 2/14 - loss 0.63702628 - samples/sec: 70.97 - lr: 0.050000
2021-05-27 13:16:23,277 epoch 28 - iter 3/14 - loss 0.77074109 - samples/sec: 69.92 - lr: 0.050000
2021-05-27 13:16:23,734 epoch 28 - iter 4/14 - loss 0.84600528 - samples/sec: 70.20 - lr: 0.050000
2021-05-27 13:16:24,176 epoch 28 - iter 5/14 - loss 0.83632886 - samples/sec: 72.38 - lr: 0.050000
2021-05-27 13:16:24,627 epoch 28 - iter 6/14 - loss 0.82364629 - samples/sec: 71.11 - lr: 0.050000
2021-05-27 13:16:25,088 epoch 28 - iter 7/14 - loss 0.80772487 - samples/sec: 69.36 - lr: 0.050000
2021-05-27 13:16:25,534 epoch 28 - iter 8/14 - loss 0.77257749 - samples/sec: 71.85 - lr: 0.050000
2021-05-27 13:16:25,992 epoch 28 - iter 9/14 - loss 0.76199638 - samples/sec: 69.93 - lr: 0.050000
2021-05-27 13:16:26,431 epoch 28 - iter 10/14 - loss 0.79459897 - samples/sec: 73.01 - lr: 0.050000
2021-05-27 13:16:26,879 epoch 28 - iter 11/14 - loss 0.75158551 - samples/sec: 71.42 - lr: 0.050000
2021-05-27 13:16:27,333 epoch 28 - iter 12/14 - loss 0.73284795 - samples/sec: 70.57 - lr: 0.050000
2021-05-27 13:16:27,790 epoch 28 - iter 13/14 - loss 0.73044194 - samples/sec: 70.14 - lr: 0.050000
2021-05-27 13:16:28,145 epoch 28 - iter 14/14 - loss 0.76955925 - samples/sec: 90.12 - lr: 0.050000
2021-05-27 13:16:28,146 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:28,146 EPOCH 28 done: loss 0.7696 - lr 0.0500000
2021-05-27 13:16:28,695 DEV : loss 1.0832210779190063 - score 0.8229
2021-05-27 13:16:28,705 BAD EPOCHS (no improvement): 3
2021-05-27 13:16:28,705 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:29,148 epoch 29 - iter 1/14 - loss 0.80886233 - samples/sec: 72.24 - lr: 0.050000
2021-05-27 13:16:29,577 epoch 29 - iter 2/14 - loss 0.98643601 - samples/sec: 74.81 - lr: 0.050000
2021-05-27 13:16:30,028 epoch 29 - iter 3/14 - loss 0.85432959 - samples/sec: 70.87 - lr: 0.050000
2021-05-27 13:16:30,480 epoch 29 - iter 4/14 - loss 0.84312487 - samples/sec: 71.00 - lr: 0.050000
2021-05-27 13:16:30,931 epoch 29 - iter 5/14 - loss 0.79753458 - samples/sec: 70.96 - lr: 0.050000
2021-05-27 13:16:31,376 epoch 29 - iter 6/14 - loss 0.73793543 - samples/sec: 71.92 - lr: 0.050000
2021-05-27 13:16:31,823 epoch 29 - iter 7/14 - loss 0.71087075 - samples/sec: 71.76 - lr: 0.050000
2021-05-27 13:16:32,271 epoch 29 - iter 8/14 - loss 0.68509106 - samples/sec: 71.48 - lr: 0.050000
2021-05-27 13:16:32,731 epoch 29 - iter 9/14 - loss 0.72001302 - samples/sec: 69.60 - lr: 0.050000
2021-05-27 13:16:33,179 epoch 29 - iter 10/14 - loss 0.69844296 - samples/sec: 71.54 - lr: 0.050000
2021-05-27 13:16:33,630 epoch 29 - iter 11/14 - loss 0.78301210 - samples/sec: 71.02 - lr: 0.050000
2021-05-27 13:16:34,091 epoch 29 - iter 12/14 - loss 0.80134955 - samples/sec: 69.36 - lr: 0.050000
2021-05-27 13:16:34,562 epoch 29 - iter 13/14 - loss 0.83087685 - samples/sec: 68.02 - lr: 0.050000
2021-05-27 13:16:34,924 epoch 29 - iter 14/14 - loss 0.81716558 - samples/sec: 88.69 - lr: 0.050000
2021-05-27 13:16:34,924 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:34,924 EPOCH 29 done: loss 0.8172 - lr 0.0500000
2021-05-27 13:16:35,474 DEV : loss 0.952389657497406 - score 0.8516
2021-05-27 13:16:35,484 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:16:44,459 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:44,922 epoch 30 - iter 1/14 - loss 1.66723514 - samples/sec: 69.18 - lr: 0.050000
2021-05-27 13:16:45,368 epoch 30 - iter 2/14 - loss 1.15747419 - samples/sec: 71.82 - lr: 0.050000
2021-05-27 13:16:45,827 epoch 30 - iter 3/14 - loss 1.02196894 - samples/sec: 69.80 - lr: 0.050000
2021-05-27 13:16:46,278 epoch 30 - iter 4/14 - loss 0.92759731 - samples/sec: 71.09 - lr: 0.050000
2021-05-27 13:16:46,712 epoch 30 - iter 5/14 - loss 0.84362475 - samples/sec: 73.67 - lr: 0.050000
2021-05-27 13:16:47,165 epoch 30 - iter 6/14 - loss 0.75942239 - samples/sec: 70.80 - lr: 0.050000
2021-05-27 13:16:47,609 epoch 30 - iter 7/14 - loss 0.77948706 - samples/sec: 72.02 - lr: 0.050000
2021-05-27 13:16:48,053 epoch 30 - iter 8/14 - loss 0.78544837 - samples/sec: 72.19 - lr: 0.050000
2021-05-27 13:16:48,500 epoch 30 - iter 9/14 - loss 0.79046349 - samples/sec: 71.76 - lr: 0.050000
2021-05-27 13:16:48,936 epoch 30 - iter 10/14 - loss 0.75971071 - samples/sec: 73.32 - lr: 0.050000
2021-05-27 13:16:49,487 epoch 30 - iter 11/14 - loss 0.74938470 - samples/sec: 58.15 - lr: 0.050000
2021-05-27 13:16:49,942 epoch 30 - iter 12/14 - loss 0.75568262 - samples/sec: 70.48 - lr: 0.050000
2021-05-27 13:16:50,391 epoch 30 - iter 13/14 - loss 0.73029381 - samples/sec: 71.28 - lr: 0.050000
2021-05-27 13:16:50,752 epoch 30 - iter 14/14 - loss 0.72583575 - samples/sec: 88.85 - lr: 0.050000
2021-05-27 13:16:50,752 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:50,752 EPOCH 30 done: loss 0.7258 - lr 0.0500000
2021-05-27 13:16:51,294 DEV : loss 1.1445934772491455 - score 0.7653
2021-05-27 13:16:51,304 BAD EPOCHS (no improvement): 1
2021-05-27 13:16:52,259 ----------------------------------------------------------------------------------------------------
2021-05-27 13:16:52,259 Testing using best model ...
2021-05-27 13:16:52,259 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/zho.rst.sctb/best-model.pt
2021-05-27 13:16:57,723 0.9375	0.7955	0.8607
2021-05-27 13:16:57,723 
Results:
- F1-score (micro) 0.8607
- F1-score (macro) 0.8607

By class:
SENT       tp: 105 - fp: 7 - fn: 27 - precision: 0.9375 - recall: 0.7955 - f1-score: 0.8607
2021-05-27 13:16:57,723 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/
2021-05-27 13:16:57,751 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis
2021-05-27 13:16:57,753 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/sent_train.txt
2021-05-27 13:16:57,755 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/sent_dev.txt
2021-05-27 13:16:57,756 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/sent_test.txt
Corpus: 1092 train + 243 dev + 249 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 13:17:03,628 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:03,631 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 13:17:03,631 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:03,631 Corpus: "Corpus: 1092 train + 243 dev + 249 test sentences"
2021-05-27 13:17:03,631 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:03,631 Parameters:
2021-05-27 13:17:03,631  - learning_rate: "0.1"
2021-05-27 13:17:03,631  - mini_batch_size: "32"
2021-05-27 13:17:03,631  - patience: "3"
2021-05-27 13:17:03,631  - anneal_factor: "0.5"
2021-05-27 13:17:03,631  - max_epochs: "30"
2021-05-27 13:17:03,631  - shuffle: "True"
2021-05-27 13:17:03,631  - train_with_dev: "False"
2021-05-27 13:17:03,631  - batch_growth_annealing: "False"
2021-05-27 13:17:03,631 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:03,631 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis"
2021-05-27 13:17:03,631 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:03,631 Device: cuda:0
2021-05-27 13:17:03,631 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:03,631 Embeddings storage mode: cpu
2021-05-27 13:17:03,633 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:07,727 epoch 1 - iter 3/35 - loss 14.53537369 - samples/sec: 23.45 - lr: 0.100000
2021-05-27 13:17:11,529 epoch 1 - iter 6/35 - loss 10.60737626 - samples/sec: 25.25 - lr: 0.100000
2021-05-27 13:17:15,346 epoch 1 - iter 9/35 - loss 8.81683932 - samples/sec: 25.15 - lr: 0.100000
2021-05-27 13:17:19,225 epoch 1 - iter 12/35 - loss 7.79512441 - samples/sec: 24.75 - lr: 0.100000
2021-05-27 13:17:23,086 epoch 1 - iter 15/35 - loss 7.12428966 - samples/sec: 24.87 - lr: 0.100000
2021-05-27 13:17:27,071 epoch 1 - iter 18/35 - loss 6.64375130 - samples/sec: 24.09 - lr: 0.100000
2021-05-27 13:17:30,906 epoch 1 - iter 21/35 - loss 6.18372340 - samples/sec: 25.04 - lr: 0.100000
2021-05-27 13:17:34,720 epoch 1 - iter 24/35 - loss 5.89845615 - samples/sec: 25.17 - lr: 0.100000
2021-05-27 13:17:38,509 epoch 1 - iter 27/35 - loss 5.58990725 - samples/sec: 25.34 - lr: 0.100000
2021-05-27 13:17:42,324 epoch 1 - iter 30/35 - loss 5.33373546 - samples/sec: 25.17 - lr: 0.100000
2021-05-27 13:17:46,203 epoch 1 - iter 33/35 - loss 5.16678072 - samples/sec: 24.75 - lr: 0.100000
2021-05-27 13:17:47,733 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:47,733 EPOCH 1 done: loss 5.0280 - lr 0.1000000
2021-05-27 13:17:54,044 DEV : loss 2.5734801292419434 - score 0.0
2021-05-27 13:17:54,066 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:17:55,022 ----------------------------------------------------------------------------------------------------
2021-05-27 13:17:56,514 epoch 2 - iter 3/35 - loss 2.44369789 - samples/sec: 64.35 - lr: 0.100000
2021-05-27 13:17:58,029 epoch 2 - iter 6/35 - loss 3.02382058 - samples/sec: 63.39 - lr: 0.100000
2021-05-27 13:17:59,705 epoch 2 - iter 9/35 - loss 2.88152699 - samples/sec: 57.31 - lr: 0.100000
2021-05-27 13:18:01,182 epoch 2 - iter 12/35 - loss 2.69087574 - samples/sec: 65.01 - lr: 0.100000
2021-05-27 13:18:02,684 epoch 2 - iter 15/35 - loss 2.49001151 - samples/sec: 63.93 - lr: 0.100000
2021-05-27 13:18:04,197 epoch 2 - iter 18/35 - loss 2.34048688 - samples/sec: 63.48 - lr: 0.100000
2021-05-27 13:18:05,710 epoch 2 - iter 21/35 - loss 2.25948900 - samples/sec: 63.45 - lr: 0.100000
2021-05-27 13:18:07,215 epoch 2 - iter 24/35 - loss 2.13362440 - samples/sec: 63.82 - lr: 0.100000
2021-05-27 13:18:08,716 epoch 2 - iter 27/35 - loss 2.21566100 - samples/sec: 63.99 - lr: 0.100000
2021-05-27 13:18:10,230 epoch 2 - iter 30/35 - loss 2.17408457 - samples/sec: 63.43 - lr: 0.100000
2021-05-27 13:18:11,749 epoch 2 - iter 33/35 - loss 2.16441911 - samples/sec: 63.20 - lr: 0.100000
2021-05-27 13:18:12,341 ----------------------------------------------------------------------------------------------------
2021-05-27 13:18:12,341 EPOCH 2 done: loss 2.0953 - lr 0.1000000
2021-05-27 13:18:13,736 DEV : loss 0.5116999745368958 - score 0.8979
2021-05-27 13:18:13,759 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:18:24,791 ----------------------------------------------------------------------------------------------------
2021-05-27 13:18:26,264 epoch 3 - iter 3/35 - loss 2.29810997 - samples/sec: 65.24 - lr: 0.100000
2021-05-27 13:18:27,781 epoch 3 - iter 6/35 - loss 1.78371179 - samples/sec: 63.28 - lr: 0.100000
2021-05-27 13:18:29,244 epoch 3 - iter 9/35 - loss 1.65806017 - samples/sec: 65.64 - lr: 0.100000
2021-05-27 13:18:30,728 epoch 3 - iter 12/35 - loss 1.43139808 - samples/sec: 64.72 - lr: 0.100000
2021-05-27 13:18:32,261 epoch 3 - iter 15/35 - loss 1.45251681 - samples/sec: 62.64 - lr: 0.100000
2021-05-27 13:18:33,782 epoch 3 - iter 18/35 - loss 1.45763296 - samples/sec: 63.15 - lr: 0.100000
2021-05-27 13:18:35,272 epoch 3 - iter 21/35 - loss 1.37622497 - samples/sec: 64.46 - lr: 0.100000
2021-05-27 13:18:36,773 epoch 3 - iter 24/35 - loss 1.29336060 - samples/sec: 63.97 - lr: 0.100000
2021-05-27 13:18:38,287 epoch 3 - iter 27/35 - loss 1.25855658 - samples/sec: 63.43 - lr: 0.100000
2021-05-27 13:18:39,799 epoch 3 - iter 30/35 - loss 1.27750112 - samples/sec: 63.54 - lr: 0.100000
2021-05-27 13:18:41,316 epoch 3 - iter 33/35 - loss 1.25802716 - samples/sec: 63.29 - lr: 0.100000
2021-05-27 13:18:41,932 ----------------------------------------------------------------------------------------------------
2021-05-27 13:18:41,932 EPOCH 3 done: loss 1.2224 - lr 0.1000000
2021-05-27 13:18:43,318 DEV : loss 0.4877193868160248 - score 0.9159
2021-05-27 13:18:43,341 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:18:52,451 ----------------------------------------------------------------------------------------------------
2021-05-27 13:18:53,927 epoch 4 - iter 3/35 - loss 0.85217438 - samples/sec: 65.11 - lr: 0.100000
2021-05-27 13:18:55,442 epoch 4 - iter 6/35 - loss 0.99868100 - samples/sec: 63.36 - lr: 0.100000
2021-05-27 13:18:56,962 epoch 4 - iter 9/35 - loss 1.18088400 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 13:18:58,446 epoch 4 - iter 12/35 - loss 1.04139157 - samples/sec: 64.71 - lr: 0.100000
2021-05-27 13:18:59,964 epoch 4 - iter 15/35 - loss 1.01172390 - samples/sec: 63.26 - lr: 0.100000
2021-05-27 13:19:01,423 epoch 4 - iter 18/35 - loss 0.96837446 - samples/sec: 65.82 - lr: 0.100000
2021-05-27 13:19:02,939 epoch 4 - iter 21/35 - loss 0.94386025 - samples/sec: 63.36 - lr: 0.100000
2021-05-27 13:19:04,452 epoch 4 - iter 24/35 - loss 0.92823524 - samples/sec: 63.46 - lr: 0.100000
2021-05-27 13:19:05,979 epoch 4 - iter 27/35 - loss 0.92523593 - samples/sec: 62.87 - lr: 0.100000
2021-05-27 13:19:07,507 epoch 4 - iter 30/35 - loss 0.95802678 - samples/sec: 62.88 - lr: 0.100000
2021-05-27 13:19:09,020 epoch 4 - iter 33/35 - loss 0.93711505 - samples/sec: 63.48 - lr: 0.100000
2021-05-27 13:19:09,626 ----------------------------------------------------------------------------------------------------
2021-05-27 13:19:09,626 EPOCH 4 done: loss 0.9050 - lr 0.1000000
2021-05-27 13:19:11,018 DEV : loss 0.2782980799674988 - score 0.9584
2021-05-27 13:19:11,041 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:19:20,470 ----------------------------------------------------------------------------------------------------
2021-05-27 13:19:21,963 epoch 5 - iter 3/35 - loss 0.52282377 - samples/sec: 64.34 - lr: 0.100000
2021-05-27 13:19:23,447 epoch 5 - iter 6/35 - loss 0.53370416 - samples/sec: 64.75 - lr: 0.100000
2021-05-27 13:19:24,946 epoch 5 - iter 9/35 - loss 0.58681888 - samples/sec: 64.06 - lr: 0.100000
2021-05-27 13:19:26,471 epoch 5 - iter 12/35 - loss 0.62870997 - samples/sec: 62.96 - lr: 0.100000
2021-05-27 13:19:27,980 epoch 5 - iter 15/35 - loss 0.65875302 - samples/sec: 63.63 - lr: 0.100000
2021-05-27 13:19:29,494 epoch 5 - iter 18/35 - loss 0.68642314 - samples/sec: 63.42 - lr: 0.100000
2021-05-27 13:19:31,028 epoch 5 - iter 21/35 - loss 0.67663169 - samples/sec: 62.60 - lr: 0.100000
2021-05-27 13:19:32,536 epoch 5 - iter 24/35 - loss 0.65811240 - samples/sec: 63.69 - lr: 0.100000
2021-05-27 13:19:34,051 epoch 5 - iter 27/35 - loss 0.65406655 - samples/sec: 63.40 - lr: 0.100000
2021-05-27 13:19:35,567 epoch 5 - iter 30/35 - loss 0.69730642 - samples/sec: 63.34 - lr: 0.100000
2021-05-27 13:19:37,222 epoch 5 - iter 33/35 - loss 0.68693393 - samples/sec: 58.03 - lr: 0.100000
2021-05-27 13:19:37,845 ----------------------------------------------------------------------------------------------------
2021-05-27 13:19:37,845 EPOCH 5 done: loss 0.6795 - lr 0.1000000
2021-05-27 13:19:39,233 DEV : loss 0.41704481840133667 - score 0.9237
2021-05-27 13:19:39,257 BAD EPOCHS (no improvement): 1
2021-05-27 13:19:39,257 ----------------------------------------------------------------------------------------------------
2021-05-27 13:19:40,746 epoch 6 - iter 3/35 - loss 0.79532045 - samples/sec: 64.51 - lr: 0.100000
2021-05-27 13:19:42,250 epoch 6 - iter 6/35 - loss 1.00746533 - samples/sec: 63.85 - lr: 0.100000
2021-05-27 13:19:43,767 epoch 6 - iter 9/35 - loss 0.79652024 - samples/sec: 63.30 - lr: 0.100000
2021-05-27 13:19:45,263 epoch 6 - iter 12/35 - loss 0.80652325 - samples/sec: 64.19 - lr: 0.100000
2021-05-27 13:19:46,753 epoch 6 - iter 15/35 - loss 0.75320365 - samples/sec: 64.43 - lr: 0.100000
2021-05-27 13:19:48,244 epoch 6 - iter 18/35 - loss 0.74471145 - samples/sec: 64.42 - lr: 0.100000
2021-05-27 13:19:49,754 epoch 6 - iter 21/35 - loss 0.72277126 - samples/sec: 63.60 - lr: 0.100000
2021-05-27 13:19:51,281 epoch 6 - iter 24/35 - loss 0.72480692 - samples/sec: 62.90 - lr: 0.100000
2021-05-27 13:19:52,798 epoch 6 - iter 27/35 - loss 0.74402894 - samples/sec: 63.29 - lr: 0.100000
2021-05-27 13:19:54,297 epoch 6 - iter 30/35 - loss 0.72278238 - samples/sec: 64.08 - lr: 0.100000
2021-05-27 13:19:55,824 epoch 6 - iter 33/35 - loss 0.69892507 - samples/sec: 62.89 - lr: 0.100000
2021-05-27 13:19:56,442 ----------------------------------------------------------------------------------------------------
2021-05-27 13:19:56,442 EPOCH 6 done: loss 0.7016 - lr 0.1000000
2021-05-27 13:19:57,826 DEV : loss 0.29485052824020386 - score 0.9509
2021-05-27 13:19:57,850 BAD EPOCHS (no improvement): 2
2021-05-27 13:19:57,850 ----------------------------------------------------------------------------------------------------
2021-05-27 13:19:59,333 epoch 7 - iter 3/35 - loss 0.64192263 - samples/sec: 64.75 - lr: 0.100000
2021-05-27 13:20:00,850 epoch 7 - iter 6/35 - loss 0.83243880 - samples/sec: 63.32 - lr: 0.100000
2021-05-27 13:20:02,347 epoch 7 - iter 9/35 - loss 0.81611919 - samples/sec: 64.13 - lr: 0.100000
2021-05-27 13:20:03,870 epoch 7 - iter 12/35 - loss 0.82559541 - samples/sec: 63.08 - lr: 0.100000
2021-05-27 13:20:05,365 epoch 7 - iter 15/35 - loss 0.77070317 - samples/sec: 64.24 - lr: 0.100000
2021-05-27 13:20:06,884 epoch 7 - iter 18/35 - loss 0.76313885 - samples/sec: 63.21 - lr: 0.100000
2021-05-27 13:20:08,373 epoch 7 - iter 21/35 - loss 0.69954372 - samples/sec: 64.51 - lr: 0.100000
2021-05-27 13:20:09,905 epoch 7 - iter 24/35 - loss 0.72283433 - samples/sec: 62.66 - lr: 0.100000
2021-05-27 13:20:11,397 epoch 7 - iter 27/35 - loss 0.68983744 - samples/sec: 64.38 - lr: 0.100000
2021-05-27 13:20:12,903 epoch 7 - iter 30/35 - loss 0.69767970 - samples/sec: 63.75 - lr: 0.100000
2021-05-27 13:20:14,391 epoch 7 - iter 33/35 - loss 0.70675845 - samples/sec: 64.53 - lr: 0.100000
2021-05-27 13:20:15,005 ----------------------------------------------------------------------------------------------------
2021-05-27 13:20:15,005 EPOCH 7 done: loss 0.6759 - lr 0.1000000
2021-05-27 13:20:16,391 DEV : loss 0.3056337833404541 - score 0.9507
2021-05-27 13:20:16,414 BAD EPOCHS (no improvement): 3
2021-05-27 13:20:16,414 ----------------------------------------------------------------------------------------------------
2021-05-27 13:20:17,882 epoch 8 - iter 3/35 - loss 0.48473116 - samples/sec: 65.43 - lr: 0.100000
2021-05-27 13:20:19,394 epoch 8 - iter 6/35 - loss 0.55804951 - samples/sec: 63.50 - lr: 0.100000
2021-05-27 13:20:20,881 epoch 8 - iter 9/35 - loss 0.72207752 - samples/sec: 64.59 - lr: 0.100000
2021-05-27 13:20:22,385 epoch 8 - iter 12/35 - loss 0.68554098 - samples/sec: 63.87 - lr: 0.100000
2021-05-27 13:20:23,902 epoch 8 - iter 15/35 - loss 0.61020737 - samples/sec: 63.28 - lr: 0.100000
2021-05-27 13:20:25,406 epoch 8 - iter 18/35 - loss 0.55507228 - samples/sec: 63.88 - lr: 0.100000
2021-05-27 13:20:26,904 epoch 8 - iter 21/35 - loss 0.53115316 - samples/sec: 64.12 - lr: 0.100000
2021-05-27 13:20:28,428 epoch 8 - iter 24/35 - loss 0.54467038 - samples/sec: 63.00 - lr: 0.100000
2021-05-27 13:20:29,916 epoch 8 - iter 27/35 - loss 0.55003849 - samples/sec: 64.53 - lr: 0.100000
2021-05-27 13:20:31,425 epoch 8 - iter 30/35 - loss 0.52796944 - samples/sec: 63.63 - lr: 0.100000
2021-05-27 13:20:32,921 epoch 8 - iter 33/35 - loss 0.55591558 - samples/sec: 64.22 - lr: 0.100000
2021-05-27 13:20:33,516 ----------------------------------------------------------------------------------------------------
2021-05-27 13:20:33,516 EPOCH 8 done: loss 0.5557 - lr 0.1000000
2021-05-27 13:20:35,053 DEV : loss 0.24222680926322937 - score 0.9542
Epoch     8: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 13:20:35,076 BAD EPOCHS (no improvement): 4
2021-05-27 13:20:35,077 ----------------------------------------------------------------------------------------------------
2021-05-27 13:20:36,564 epoch 9 - iter 3/35 - loss 0.45167051 - samples/sec: 64.56 - lr: 0.050000
2021-05-27 13:20:38,067 epoch 9 - iter 6/35 - loss 0.40868066 - samples/sec: 63.91 - lr: 0.050000
2021-05-27 13:20:39,541 epoch 9 - iter 9/35 - loss 0.35379714 - samples/sec: 65.16 - lr: 0.050000
2021-05-27 13:20:41,019 epoch 9 - iter 12/35 - loss 0.37467196 - samples/sec: 64.96 - lr: 0.050000
2021-05-27 13:20:42,522 epoch 9 - iter 15/35 - loss 0.38174971 - samples/sec: 63.91 - lr: 0.050000
2021-05-27 13:20:44,026 epoch 9 - iter 18/35 - loss 0.38237379 - samples/sec: 63.85 - lr: 0.050000
2021-05-27 13:20:45,535 epoch 9 - iter 21/35 - loss 0.36829232 - samples/sec: 63.64 - lr: 0.050000
2021-05-27 13:20:47,049 epoch 9 - iter 24/35 - loss 0.38395596 - samples/sec: 63.40 - lr: 0.050000
2021-05-27 13:20:48,553 epoch 9 - iter 27/35 - loss 0.37400646 - samples/sec: 63.87 - lr: 0.050000
2021-05-27 13:20:50,063 epoch 9 - iter 30/35 - loss 0.36997092 - samples/sec: 63.61 - lr: 0.050000
2021-05-27 13:20:51,566 epoch 9 - iter 33/35 - loss 0.37895787 - samples/sec: 63.88 - lr: 0.050000
2021-05-27 13:20:52,173 ----------------------------------------------------------------------------------------------------
2021-05-27 13:20:52,173 EPOCH 9 done: loss 0.4099 - lr 0.0500000
2021-05-27 13:20:53,560 DEV : loss 0.2301192730665207 - score 0.9548
2021-05-27 13:20:53,584 BAD EPOCHS (no improvement): 1
2021-05-27 13:20:53,584 ----------------------------------------------------------------------------------------------------
2021-05-27 13:20:55,088 epoch 10 - iter 3/35 - loss 0.30093749 - samples/sec: 63.83 - lr: 0.050000
2021-05-27 13:20:56,595 epoch 10 - iter 6/35 - loss 0.33867645 - samples/sec: 63.73 - lr: 0.050000
2021-05-27 13:20:58,101 epoch 10 - iter 9/35 - loss 0.42134232 - samples/sec: 63.79 - lr: 0.050000
2021-05-27 13:20:59,577 epoch 10 - iter 12/35 - loss 0.43157417 - samples/sec: 65.03 - lr: 0.050000
2021-05-27 13:21:01,069 epoch 10 - iter 15/35 - loss 0.39542743 - samples/sec: 64.38 - lr: 0.050000
2021-05-27 13:21:02,566 epoch 10 - iter 18/35 - loss 0.42244424 - samples/sec: 64.15 - lr: 0.050000
2021-05-27 13:21:04,059 epoch 10 - iter 21/35 - loss 0.42081027 - samples/sec: 64.31 - lr: 0.050000
2021-05-27 13:21:05,555 epoch 10 - iter 24/35 - loss 0.42889371 - samples/sec: 64.22 - lr: 0.050000
2021-05-27 13:21:07,059 epoch 10 - iter 27/35 - loss 0.44092256 - samples/sec: 63.85 - lr: 0.050000
2021-05-27 13:21:08,544 epoch 10 - iter 30/35 - loss 0.43222709 - samples/sec: 64.64 - lr: 0.050000
2021-05-27 13:21:10,051 epoch 10 - iter 33/35 - loss 0.41210684 - samples/sec: 63.74 - lr: 0.050000
2021-05-27 13:21:10,664 ----------------------------------------------------------------------------------------------------
2021-05-27 13:21:10,665 EPOCH 10 done: loss 0.4061 - lr 0.0500000
2021-05-27 13:21:12,052 DEV : loss 0.26227909326553345 - score 0.953
2021-05-27 13:21:12,075 BAD EPOCHS (no improvement): 2
2021-05-27 13:21:12,076 ----------------------------------------------------------------------------------------------------
2021-05-27 13:21:13,566 epoch 11 - iter 3/35 - loss 0.31146844 - samples/sec: 64.42 - lr: 0.050000
2021-05-27 13:21:15,077 epoch 11 - iter 6/35 - loss 0.37967571 - samples/sec: 63.58 - lr: 0.050000
2021-05-27 13:21:16,567 epoch 11 - iter 9/35 - loss 0.36639583 - samples/sec: 64.42 - lr: 0.050000
2021-05-27 13:21:18,074 epoch 11 - iter 12/35 - loss 0.36106242 - samples/sec: 63.76 - lr: 0.050000
2021-05-27 13:21:19,581 epoch 11 - iter 15/35 - loss 0.40471820 - samples/sec: 63.71 - lr: 0.050000
2021-05-27 13:21:21,074 epoch 11 - iter 18/35 - loss 0.38157203 - samples/sec: 64.31 - lr: 0.050000
2021-05-27 13:21:22,588 epoch 11 - iter 21/35 - loss 0.36624390 - samples/sec: 63.46 - lr: 0.050000
2021-05-27 13:21:24,053 epoch 11 - iter 24/35 - loss 0.36588767 - samples/sec: 65.55 - lr: 0.050000
2021-05-27 13:21:25,515 epoch 11 - iter 27/35 - loss 0.35788923 - samples/sec: 65.69 - lr: 0.050000
2021-05-27 13:21:27,019 epoch 11 - iter 30/35 - loss 0.37710330 - samples/sec: 63.83 - lr: 0.050000
2021-05-27 13:21:28,510 epoch 11 - iter 33/35 - loss 0.37490708 - samples/sec: 64.42 - lr: 0.050000
2021-05-27 13:21:29,134 ----------------------------------------------------------------------------------------------------
2021-05-27 13:21:29,134 EPOCH 11 done: loss 0.3645 - lr 0.0500000
2021-05-27 13:21:30,521 DEV : loss 0.21951352059841156 - score 0.9567
2021-05-27 13:21:30,545 BAD EPOCHS (no improvement): 3
2021-05-27 13:21:30,545 ----------------------------------------------------------------------------------------------------
2021-05-27 13:21:32,020 epoch 12 - iter 3/35 - loss 0.54755922 - samples/sec: 65.12 - lr: 0.050000
2021-05-27 13:21:33,527 epoch 12 - iter 6/35 - loss 0.48692507 - samples/sec: 63.70 - lr: 0.050000
2021-05-27 13:21:35,140 epoch 12 - iter 9/35 - loss 0.43296575 - samples/sec: 59.53 - lr: 0.050000
2021-05-27 13:21:36,633 epoch 12 - iter 12/35 - loss 0.38838748 - samples/sec: 64.34 - lr: 0.050000
2021-05-27 13:21:38,128 epoch 12 - iter 15/35 - loss 0.42019331 - samples/sec: 64.24 - lr: 0.050000
2021-05-27 13:21:39,623 epoch 12 - iter 18/35 - loss 0.41854300 - samples/sec: 64.24 - lr: 0.050000
2021-05-27 13:21:41,115 epoch 12 - iter 21/35 - loss 0.40210612 - samples/sec: 64.34 - lr: 0.050000
2021-05-27 13:21:42,639 epoch 12 - iter 24/35 - loss 0.39123224 - samples/sec: 63.01 - lr: 0.050000
2021-05-27 13:21:44,136 epoch 12 - iter 27/35 - loss 0.37812924 - samples/sec: 64.16 - lr: 0.050000
2021-05-27 13:21:45,632 epoch 12 - iter 30/35 - loss 0.37091282 - samples/sec: 64.21 - lr: 0.050000
2021-05-27 13:21:47,143 epoch 12 - iter 33/35 - loss 0.36420665 - samples/sec: 63.54 - lr: 0.050000
2021-05-27 13:21:47,736 ----------------------------------------------------------------------------------------------------
2021-05-27 13:21:47,736 EPOCH 12 done: loss 0.3693 - lr 0.0500000
2021-05-27 13:21:49,120 DEV : loss 0.3521794080734253 - score 0.9358
Epoch    12: reducing learning rate of group 0 to 2.5000e-02.
2021-05-27 13:21:49,143 BAD EPOCHS (no improvement): 4
2021-05-27 13:21:49,144 ----------------------------------------------------------------------------------------------------
2021-05-27 13:21:50,648 epoch 13 - iter 3/35 - loss 0.22070360 - samples/sec: 63.85 - lr: 0.025000
2021-05-27 13:21:52,138 epoch 13 - iter 6/35 - loss 0.22468706 - samples/sec: 64.45 - lr: 0.025000
2021-05-27 13:21:53,648 epoch 13 - iter 9/35 - loss 0.24649288 - samples/sec: 63.58 - lr: 0.025000
2021-05-27 13:21:55,145 epoch 13 - iter 12/35 - loss 0.25191686 - samples/sec: 64.16 - lr: 0.025000
2021-05-27 13:21:56,634 epoch 13 - iter 15/35 - loss 0.30312592 - samples/sec: 64.48 - lr: 0.025000
2021-05-27 13:21:58,132 epoch 13 - iter 18/35 - loss 0.31758855 - samples/sec: 64.10 - lr: 0.025000
2021-05-27 13:21:59,622 epoch 13 - iter 21/35 - loss 0.30738132 - samples/sec: 64.45 - lr: 0.025000
2021-05-27 13:22:01,094 epoch 13 - iter 24/35 - loss 0.31349513 - samples/sec: 65.25 - lr: 0.025000
2021-05-27 13:22:02,605 epoch 13 - iter 27/35 - loss 0.31892516 - samples/sec: 63.53 - lr: 0.025000
2021-05-27 13:22:04,091 epoch 13 - iter 30/35 - loss 0.33414664 - samples/sec: 64.62 - lr: 0.025000
2021-05-27 13:22:05,619 epoch 13 - iter 33/35 - loss 0.34850446 - samples/sec: 62.88 - lr: 0.025000
2021-05-27 13:22:06,205 ----------------------------------------------------------------------------------------------------
2021-05-27 13:22:06,205 EPOCH 13 done: loss 0.3457 - lr 0.0250000
2021-05-27 13:22:07,592 DEV : loss 0.21904194355010986 - score 0.9628
2021-05-27 13:22:07,616 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:22:16,360 ----------------------------------------------------------------------------------------------------
2021-05-27 13:22:17,858 epoch 14 - iter 3/35 - loss 0.25802628 - samples/sec: 64.15 - lr: 0.025000
2021-05-27 13:22:19,377 epoch 14 - iter 6/35 - loss 0.33237664 - samples/sec: 63.22 - lr: 0.025000
2021-05-27 13:22:20,869 epoch 14 - iter 9/35 - loss 0.33098386 - samples/sec: 64.34 - lr: 0.025000
2021-05-27 13:22:22,381 epoch 14 - iter 12/35 - loss 0.31614278 - samples/sec: 63.52 - lr: 0.025000
2021-05-27 13:22:23,843 epoch 14 - iter 15/35 - loss 0.34072886 - samples/sec: 65.68 - lr: 0.025000
2021-05-27 13:22:25,346 epoch 14 - iter 18/35 - loss 0.33671102 - samples/sec: 63.90 - lr: 0.025000
2021-05-27 13:22:26,833 epoch 14 - iter 21/35 - loss 0.33809311 - samples/sec: 64.59 - lr: 0.025000
2021-05-27 13:22:28,352 epoch 14 - iter 24/35 - loss 0.33170880 - samples/sec: 63.22 - lr: 0.025000
2021-05-27 13:22:29,867 epoch 14 - iter 27/35 - loss 0.31348411 - samples/sec: 63.38 - lr: 0.025000
2021-05-27 13:22:31,351 epoch 14 - iter 30/35 - loss 0.31306817 - samples/sec: 64.73 - lr: 0.025000
2021-05-27 13:22:32,842 epoch 14 - iter 33/35 - loss 0.32293373 - samples/sec: 64.39 - lr: 0.025000
2021-05-27 13:22:33,454 ----------------------------------------------------------------------------------------------------
2021-05-27 13:22:33,454 EPOCH 14 done: loss 0.3299 - lr 0.0250000
2021-05-27 13:22:34,841 DEV : loss 0.24141548573970795 - score 0.953
2021-05-27 13:22:34,864 BAD EPOCHS (no improvement): 1
2021-05-27 13:22:34,864 ----------------------------------------------------------------------------------------------------
2021-05-27 13:22:36,326 epoch 15 - iter 3/35 - loss 0.24930412 - samples/sec: 65.73 - lr: 0.025000
2021-05-27 13:22:37,823 epoch 15 - iter 6/35 - loss 0.32081190 - samples/sec: 64.11 - lr: 0.025000
2021-05-27 13:22:39,334 epoch 15 - iter 9/35 - loss 0.29447530 - samples/sec: 63.58 - lr: 0.025000
2021-05-27 13:22:40,825 epoch 15 - iter 12/35 - loss 0.30460726 - samples/sec: 64.41 - lr: 0.025000
2021-05-27 13:22:42,296 epoch 15 - iter 15/35 - loss 0.29568606 - samples/sec: 65.26 - lr: 0.025000
2021-05-27 13:22:43,790 epoch 15 - iter 18/35 - loss 0.29957585 - samples/sec: 64.31 - lr: 0.025000
2021-05-27 13:22:45,293 epoch 15 - iter 21/35 - loss 0.31359362 - samples/sec: 63.88 - lr: 0.025000
2021-05-27 13:22:46,790 epoch 15 - iter 24/35 - loss 0.30640089 - samples/sec: 64.15 - lr: 0.025000
2021-05-27 13:22:48,447 epoch 15 - iter 27/35 - loss 0.29201780 - samples/sec: 57.94 - lr: 0.025000
2021-05-27 13:22:49,971 epoch 15 - iter 30/35 - loss 0.29387342 - samples/sec: 63.05 - lr: 0.025000
2021-05-27 13:22:51,462 epoch 15 - iter 33/35 - loss 0.29762366 - samples/sec: 64.39 - lr: 0.025000
2021-05-27 13:22:52,061 ----------------------------------------------------------------------------------------------------
2021-05-27 13:22:52,061 EPOCH 15 done: loss 0.2930 - lr 0.0250000
2021-05-27 13:22:53,450 DEV : loss 0.2148616462945938 - score 0.9548
2021-05-27 13:22:53,473 BAD EPOCHS (no improvement): 2
2021-05-27 13:22:53,473 ----------------------------------------------------------------------------------------------------
2021-05-27 13:22:54,991 epoch 16 - iter 3/35 - loss 0.33134858 - samples/sec: 63.27 - lr: 0.025000
2021-05-27 13:22:56,474 epoch 16 - iter 6/35 - loss 0.41165395 - samples/sec: 64.76 - lr: 0.025000
2021-05-27 13:22:57,959 epoch 16 - iter 9/35 - loss 0.35567329 - samples/sec: 64.65 - lr: 0.025000
2021-05-27 13:22:59,450 epoch 16 - iter 12/35 - loss 0.35548227 - samples/sec: 64.42 - lr: 0.025000
2021-05-27 13:23:00,958 epoch 16 - iter 15/35 - loss 0.34418298 - samples/sec: 63.68 - lr: 0.025000
2021-05-27 13:23:02,490 epoch 16 - iter 18/35 - loss 0.33559285 - samples/sec: 62.68 - lr: 0.025000
2021-05-27 13:23:03,978 epoch 16 - iter 21/35 - loss 0.33806842 - samples/sec: 64.53 - lr: 0.025000
2021-05-27 13:23:05,478 epoch 16 - iter 24/35 - loss 0.31810915 - samples/sec: 64.02 - lr: 0.025000
2021-05-27 13:23:06,980 epoch 16 - iter 27/35 - loss 0.31008358 - samples/sec: 63.96 - lr: 0.025000
2021-05-27 13:23:08,465 epoch 16 - iter 30/35 - loss 0.30237935 - samples/sec: 64.64 - lr: 0.025000
2021-05-27 13:23:09,974 epoch 16 - iter 33/35 - loss 0.30058841 - samples/sec: 63.67 - lr: 0.025000
2021-05-27 13:23:10,571 ----------------------------------------------------------------------------------------------------
2021-05-27 13:23:10,571 EPOCH 16 done: loss 0.3255 - lr 0.0250000
2021-05-27 13:23:11,966 DEV : loss 0.22000208497047424 - score 0.9569
2021-05-27 13:23:11,990 BAD EPOCHS (no improvement): 3
2021-05-27 13:23:11,990 ----------------------------------------------------------------------------------------------------
2021-05-27 13:23:13,487 epoch 17 - iter 3/35 - loss 0.30442842 - samples/sec: 64.15 - lr: 0.025000
2021-05-27 13:23:14,991 epoch 17 - iter 6/35 - loss 0.26175300 - samples/sec: 63.84 - lr: 0.025000
2021-05-27 13:23:16,480 epoch 17 - iter 9/35 - loss 0.23961800 - samples/sec: 64.52 - lr: 0.025000
2021-05-27 13:23:17,947 epoch 17 - iter 12/35 - loss 0.25566021 - samples/sec: 65.44 - lr: 0.025000
2021-05-27 13:23:19,446 epoch 17 - iter 15/35 - loss 0.26776479 - samples/sec: 64.09 - lr: 0.025000
2021-05-27 13:23:20,957 epoch 17 - iter 18/35 - loss 0.26673735 - samples/sec: 63.56 - lr: 0.025000
2021-05-27 13:23:22,426 epoch 17 - iter 21/35 - loss 0.27463283 - samples/sec: 65.37 - lr: 0.025000
2021-05-27 13:23:23,931 epoch 17 - iter 24/35 - loss 0.28210867 - samples/sec: 63.80 - lr: 0.025000
2021-05-27 13:23:25,432 epoch 17 - iter 27/35 - loss 0.27381223 - samples/sec: 63.96 - lr: 0.025000
2021-05-27 13:23:26,924 epoch 17 - iter 30/35 - loss 0.26429226 - samples/sec: 64.37 - lr: 0.025000
2021-05-27 13:23:28,433 epoch 17 - iter 33/35 - loss 0.26311844 - samples/sec: 63.65 - lr: 0.025000
2021-05-27 13:23:29,032 ----------------------------------------------------------------------------------------------------
2021-05-27 13:23:29,032 EPOCH 17 done: loss 0.2864 - lr 0.0250000
2021-05-27 13:23:30,419 DEV : loss 0.20870642364025116 - score 0.9591
Epoch    17: reducing learning rate of group 0 to 1.2500e-02.
2021-05-27 13:23:30,443 BAD EPOCHS (no improvement): 4
2021-05-27 13:23:30,443 ----------------------------------------------------------------------------------------------------
2021-05-27 13:23:31,941 epoch 18 - iter 3/35 - loss 0.37440491 - samples/sec: 64.12 - lr: 0.012500
2021-05-27 13:23:33,404 epoch 18 - iter 6/35 - loss 0.33716387 - samples/sec: 65.62 - lr: 0.012500
2021-05-27 13:23:34,882 epoch 18 - iter 9/35 - loss 0.29720888 - samples/sec: 64.99 - lr: 0.012500
2021-05-27 13:23:36,380 epoch 18 - iter 12/35 - loss 0.28032971 - samples/sec: 64.09 - lr: 0.012500
2021-05-27 13:23:37,886 epoch 18 - iter 15/35 - loss 0.27139042 - samples/sec: 63.77 - lr: 0.012500
2021-05-27 13:23:39,388 epoch 18 - iter 18/35 - loss 0.27985099 - samples/sec: 63.92 - lr: 0.012500
2021-05-27 13:23:40,861 epoch 18 - iter 21/35 - loss 0.26662114 - samples/sec: 65.22 - lr: 0.012500
2021-05-27 13:23:42,386 epoch 18 - iter 24/35 - loss 0.27697084 - samples/sec: 62.95 - lr: 0.012500
2021-05-27 13:23:43,884 epoch 18 - iter 27/35 - loss 0.28421180 - samples/sec: 64.11 - lr: 0.012500
2021-05-27 13:23:45,378 epoch 18 - iter 30/35 - loss 0.28851835 - samples/sec: 64.27 - lr: 0.012500
2021-05-27 13:23:46,884 epoch 18 - iter 33/35 - loss 0.27906298 - samples/sec: 63.77 - lr: 0.012500
2021-05-27 13:23:47,486 ----------------------------------------------------------------------------------------------------
2021-05-27 13:23:47,487 EPOCH 18 done: loss 0.2712 - lr 0.0125000
2021-05-27 13:23:49,030 DEV : loss 0.18758916854858398 - score 0.9609
2021-05-27 13:23:49,053 BAD EPOCHS (no improvement): 1
2021-05-27 13:23:49,054 ----------------------------------------------------------------------------------------------------
2021-05-27 13:23:50,544 epoch 19 - iter 3/35 - loss 0.24713671 - samples/sec: 64.43 - lr: 0.012500
2021-05-27 13:23:52,057 epoch 19 - iter 6/35 - loss 0.26846498 - samples/sec: 63.48 - lr: 0.012500
2021-05-27 13:23:53,577 epoch 19 - iter 9/35 - loss 0.29939679 - samples/sec: 63.19 - lr: 0.012500
2021-05-27 13:23:55,039 epoch 19 - iter 12/35 - loss 0.29600418 - samples/sec: 65.67 - lr: 0.012500
2021-05-27 13:23:56,543 epoch 19 - iter 15/35 - loss 0.29624338 - samples/sec: 63.87 - lr: 0.012500
2021-05-27 13:23:58,034 epoch 19 - iter 18/35 - loss 0.27792388 - samples/sec: 64.40 - lr: 0.012500
2021-05-27 13:23:59,546 epoch 19 - iter 21/35 - loss 0.26727894 - samples/sec: 63.51 - lr: 0.012500
2021-05-27 13:24:01,058 epoch 19 - iter 24/35 - loss 0.27236858 - samples/sec: 63.49 - lr: 0.012500
2021-05-27 13:24:02,556 epoch 19 - iter 27/35 - loss 0.27655885 - samples/sec: 64.12 - lr: 0.012500
2021-05-27 13:24:04,013 epoch 19 - iter 30/35 - loss 0.27315980 - samples/sec: 65.91 - lr: 0.012500
2021-05-27 13:24:05,465 epoch 19 - iter 33/35 - loss 0.27841513 - samples/sec: 66.13 - lr: 0.012500
2021-05-27 13:24:06,075 ----------------------------------------------------------------------------------------------------
2021-05-27 13:24:06,076 EPOCH 19 done: loss 0.2900 - lr 0.0125000
2021-05-27 13:24:07,467 DEV : loss 0.19626204669475555 - score 0.9569
2021-05-27 13:24:07,490 BAD EPOCHS (no improvement): 2
2021-05-27 13:24:07,490 ----------------------------------------------------------------------------------------------------
2021-05-27 13:24:08,978 epoch 20 - iter 3/35 - loss 0.35557695 - samples/sec: 64.57 - lr: 0.012500
2021-05-27 13:24:10,444 epoch 20 - iter 6/35 - loss 0.29996195 - samples/sec: 65.48 - lr: 0.012500
2021-05-27 13:24:11,915 epoch 20 - iter 9/35 - loss 0.27831426 - samples/sec: 65.30 - lr: 0.012500
2021-05-27 13:24:13,395 epoch 20 - iter 12/35 - loss 0.27842091 - samples/sec: 64.90 - lr: 0.012500
2021-05-27 13:24:14,867 epoch 20 - iter 15/35 - loss 0.28869731 - samples/sec: 65.22 - lr: 0.012500
2021-05-27 13:24:16,371 epoch 20 - iter 18/35 - loss 0.27707322 - samples/sec: 63.83 - lr: 0.012500
2021-05-27 13:24:17,840 epoch 20 - iter 21/35 - loss 0.27715184 - samples/sec: 65.40 - lr: 0.012500
2021-05-27 13:24:19,307 epoch 20 - iter 24/35 - loss 0.26792258 - samples/sec: 65.47 - lr: 0.012500
2021-05-27 13:24:20,756 epoch 20 - iter 27/35 - loss 0.25824499 - samples/sec: 66.26 - lr: 0.012500
2021-05-27 13:24:22,220 epoch 20 - iter 30/35 - loss 0.25474608 - samples/sec: 65.62 - lr: 0.012500
2021-05-27 13:24:23,670 epoch 20 - iter 33/35 - loss 0.24860861 - samples/sec: 66.20 - lr: 0.012500
2021-05-27 13:24:24,282 ----------------------------------------------------------------------------------------------------
2021-05-27 13:24:24,282 EPOCH 20 done: loss 0.2542 - lr 0.0125000
2021-05-27 13:24:25,670 DEV : loss 0.19798044860363007 - score 0.9569
2021-05-27 13:24:25,693 BAD EPOCHS (no improvement): 3
2021-05-27 13:24:25,694 ----------------------------------------------------------------------------------------------------
2021-05-27 13:24:27,169 epoch 21 - iter 3/35 - loss 0.23633242 - samples/sec: 65.11 - lr: 0.012500
2021-05-27 13:24:28,637 epoch 21 - iter 6/35 - loss 0.22792557 - samples/sec: 65.40 - lr: 0.012500
2021-05-27 13:24:30,141 epoch 21 - iter 9/35 - loss 0.24594926 - samples/sec: 63.84 - lr: 0.012500
2021-05-27 13:24:31,646 epoch 21 - iter 12/35 - loss 0.26809543 - samples/sec: 63.82 - lr: 0.012500
2021-05-27 13:24:33,150 epoch 21 - iter 15/35 - loss 0.25878141 - samples/sec: 63.86 - lr: 0.012500
2021-05-27 13:24:34,643 epoch 21 - iter 18/35 - loss 0.25995228 - samples/sec: 64.30 - lr: 0.012500
2021-05-27 13:24:36,093 epoch 21 - iter 21/35 - loss 0.25294614 - samples/sec: 66.26 - lr: 0.012500
2021-05-27 13:24:37,564 epoch 21 - iter 24/35 - loss 0.23911253 - samples/sec: 65.25 - lr: 0.012500
2021-05-27 13:24:39,067 epoch 21 - iter 27/35 - loss 0.23518006 - samples/sec: 63.92 - lr: 0.012500
2021-05-27 13:24:40,550 epoch 21 - iter 30/35 - loss 0.24370263 - samples/sec: 64.74 - lr: 0.012500
2021-05-27 13:24:42,041 epoch 21 - iter 33/35 - loss 0.24995163 - samples/sec: 64.39 - lr: 0.012500
2021-05-27 13:24:42,644 ----------------------------------------------------------------------------------------------------
2021-05-27 13:24:42,644 EPOCH 21 done: loss 0.2578 - lr 0.0125000
2021-05-27 13:24:44,032 DEV : loss 0.2472885251045227 - score 0.9492
Epoch    21: reducing learning rate of group 0 to 6.2500e-03.
2021-05-27 13:24:44,055 BAD EPOCHS (no improvement): 4
2021-05-27 13:24:44,056 ----------------------------------------------------------------------------------------------------
2021-05-27 13:24:45,704 epoch 22 - iter 3/35 - loss 0.36549660 - samples/sec: 58.25 - lr: 0.006250
2021-05-27 13:24:47,215 epoch 22 - iter 6/35 - loss 0.29745394 - samples/sec: 63.59 - lr: 0.006250
2021-05-27 13:24:48,718 epoch 22 - iter 9/35 - loss 0.30780376 - samples/sec: 63.87 - lr: 0.006250
2021-05-27 13:24:50,233 epoch 22 - iter 12/35 - loss 0.27698400 - samples/sec: 63.38 - lr: 0.006250
2021-05-27 13:24:51,707 epoch 22 - iter 15/35 - loss 0.24600988 - samples/sec: 65.15 - lr: 0.006250
2021-05-27 13:24:53,208 epoch 22 - iter 18/35 - loss 0.23669238 - samples/sec: 63.99 - lr: 0.006250
2021-05-27 13:24:54,712 epoch 22 - iter 21/35 - loss 0.25008688 - samples/sec: 63.84 - lr: 0.006250
2021-05-27 13:24:56,221 epoch 22 - iter 24/35 - loss 0.24784629 - samples/sec: 63.64 - lr: 0.006250
2021-05-27 13:24:57,698 epoch 22 - iter 27/35 - loss 0.24910766 - samples/sec: 65.01 - lr: 0.006250
2021-05-27 13:24:59,158 epoch 22 - iter 30/35 - loss 0.24798736 - samples/sec: 65.81 - lr: 0.006250
2021-05-27 13:25:00,656 epoch 22 - iter 33/35 - loss 0.24711591 - samples/sec: 64.09 - lr: 0.006250
2021-05-27 13:25:01,263 ----------------------------------------------------------------------------------------------------
2021-05-27 13:25:01,263 EPOCH 22 done: loss 0.2418 - lr 0.0062500
2021-05-27 13:25:02,652 DEV : loss 0.20600171387195587 - score 0.9571
2021-05-27 13:25:02,676 BAD EPOCHS (no improvement): 1
2021-05-27 13:25:02,676 ----------------------------------------------------------------------------------------------------
2021-05-27 13:25:04,137 epoch 23 - iter 3/35 - loss 0.18082884 - samples/sec: 65.75 - lr: 0.006250
2021-05-27 13:25:05,606 epoch 23 - iter 6/35 - loss 0.23695676 - samples/sec: 65.35 - lr: 0.006250
2021-05-27 13:25:07,089 epoch 23 - iter 9/35 - loss 0.25682362 - samples/sec: 64.75 - lr: 0.006250
2021-05-27 13:25:08,570 epoch 23 - iter 12/35 - loss 0.26091588 - samples/sec: 64.86 - lr: 0.006250
2021-05-27 13:25:10,055 epoch 23 - iter 15/35 - loss 0.23941284 - samples/sec: 64.67 - lr: 0.006250
2021-05-27 13:25:11,547 epoch 23 - iter 18/35 - loss 0.24366354 - samples/sec: 64.36 - lr: 0.006250
2021-05-27 13:25:13,065 epoch 23 - iter 21/35 - loss 0.25212370 - samples/sec: 63.26 - lr: 0.006250
2021-05-27 13:25:14,528 epoch 23 - iter 24/35 - loss 0.24335814 - samples/sec: 65.66 - lr: 0.006250
2021-05-27 13:25:16,028 epoch 23 - iter 27/35 - loss 0.25111022 - samples/sec: 64.02 - lr: 0.006250
2021-05-27 13:25:17,520 epoch 23 - iter 30/35 - loss 0.24214850 - samples/sec: 64.36 - lr: 0.006250
2021-05-27 13:25:19,016 epoch 23 - iter 33/35 - loss 0.25117920 - samples/sec: 64.19 - lr: 0.006250
2021-05-27 13:25:19,637 ----------------------------------------------------------------------------------------------------
2021-05-27 13:25:19,637 EPOCH 23 done: loss 0.2472 - lr 0.0062500
2021-05-27 13:25:21,023 DEV : loss 0.18894284963607788 - score 0.9569
2021-05-27 13:25:21,047 BAD EPOCHS (no improvement): 2
2021-05-27 13:25:21,047 ----------------------------------------------------------------------------------------------------
2021-05-27 13:25:22,539 epoch 24 - iter 3/35 - loss 0.31722573 - samples/sec: 64.37 - lr: 0.006250
2021-05-27 13:25:24,047 epoch 24 - iter 6/35 - loss 0.25052873 - samples/sec: 63.67 - lr: 0.006250
2021-05-27 13:25:25,551 epoch 24 - iter 9/35 - loss 0.24923072 - samples/sec: 63.86 - lr: 0.006250
2021-05-27 13:25:27,036 epoch 24 - iter 12/35 - loss 0.22382540 - samples/sec: 64.66 - lr: 0.006250
2021-05-27 13:25:28,528 epoch 24 - iter 15/35 - loss 0.23296539 - samples/sec: 64.35 - lr: 0.006250
2021-05-27 13:25:30,009 epoch 24 - iter 18/35 - loss 0.24686192 - samples/sec: 64.85 - lr: 0.006250
2021-05-27 13:25:31,532 epoch 24 - iter 21/35 - loss 0.23140597 - samples/sec: 63.06 - lr: 0.006250
2021-05-27 13:25:33,021 epoch 24 - iter 24/35 - loss 0.22868044 - samples/sec: 64.48 - lr: 0.006250
2021-05-27 13:25:34,519 epoch 24 - iter 27/35 - loss 0.25435707 - samples/sec: 64.15 - lr: 0.006250
2021-05-27 13:25:35,987 epoch 24 - iter 30/35 - loss 0.25158480 - samples/sec: 65.39 - lr: 0.006250
2021-05-27 13:25:37,471 epoch 24 - iter 33/35 - loss 0.24252600 - samples/sec: 64.71 - lr: 0.006250
2021-05-27 13:25:38,075 ----------------------------------------------------------------------------------------------------
2021-05-27 13:25:38,075 EPOCH 24 done: loss 0.2354 - lr 0.0062500
2021-05-27 13:25:39,463 DEV : loss 0.17930036783218384 - score 0.9546
2021-05-27 13:25:39,486 BAD EPOCHS (no improvement): 3
2021-05-27 13:25:39,486 ----------------------------------------------------------------------------------------------------
2021-05-27 13:25:40,981 epoch 25 - iter 3/35 - loss 0.28332098 - samples/sec: 64.25 - lr: 0.006250
2021-05-27 13:25:42,469 epoch 25 - iter 6/35 - loss 0.22654556 - samples/sec: 64.52 - lr: 0.006250
2021-05-27 13:25:43,978 epoch 25 - iter 9/35 - loss 0.23172738 - samples/sec: 63.64 - lr: 0.006250
2021-05-27 13:25:45,448 epoch 25 - iter 12/35 - loss 0.23139445 - samples/sec: 65.33 - lr: 0.006250
2021-05-27 13:25:46,947 epoch 25 - iter 15/35 - loss 0.22665676 - samples/sec: 64.06 - lr: 0.006250
2021-05-27 13:25:48,460 epoch 25 - iter 18/35 - loss 0.21617952 - samples/sec: 63.50 - lr: 0.006250
2021-05-27 13:25:49,968 epoch 25 - iter 21/35 - loss 0.22992000 - samples/sec: 63.68 - lr: 0.006250
2021-05-27 13:25:51,434 epoch 25 - iter 24/35 - loss 0.23607047 - samples/sec: 65.50 - lr: 0.006250
2021-05-27 13:25:52,942 epoch 25 - iter 27/35 - loss 0.24493406 - samples/sec: 63.69 - lr: 0.006250
2021-05-27 13:25:54,434 epoch 25 - iter 30/35 - loss 0.23801338 - samples/sec: 64.36 - lr: 0.006250
2021-05-27 13:25:55,938 epoch 25 - iter 33/35 - loss 0.23280767 - samples/sec: 63.86 - lr: 0.006250
2021-05-27 13:25:56,540 ----------------------------------------------------------------------------------------------------
2021-05-27 13:25:56,540 EPOCH 25 done: loss 0.2294 - lr 0.0062500
2021-05-27 13:25:58,078 DEV : loss 0.19068434834480286 - score 0.9569
Epoch    25: reducing learning rate of group 0 to 3.1250e-03.
2021-05-27 13:25:58,101 BAD EPOCHS (no improvement): 4
2021-05-27 13:25:58,101 ----------------------------------------------------------------------------------------------------
2021-05-27 13:25:59,545 epoch 26 - iter 3/35 - loss 0.21418253 - samples/sec: 66.50 - lr: 0.003125
2021-05-27 13:26:01,033 epoch 26 - iter 6/35 - loss 0.19245979 - samples/sec: 64.57 - lr: 0.003125
2021-05-27 13:26:02,528 epoch 26 - iter 9/35 - loss 0.15482935 - samples/sec: 64.22 - lr: 0.003125
2021-05-27 13:26:04,042 epoch 26 - iter 12/35 - loss 0.18588109 - samples/sec: 63.44 - lr: 0.003125
2021-05-27 13:26:05,562 epoch 26 - iter 15/35 - loss 0.18544610 - samples/sec: 63.16 - lr: 0.003125
2021-05-27 13:26:07,054 epoch 26 - iter 18/35 - loss 0.17938870 - samples/sec: 64.36 - lr: 0.003125
2021-05-27 13:26:08,555 epoch 26 - iter 21/35 - loss 0.17570094 - samples/sec: 63.99 - lr: 0.003125
2021-05-27 13:26:10,051 epoch 26 - iter 24/35 - loss 0.18855547 - samples/sec: 64.22 - lr: 0.003125
2021-05-27 13:26:11,547 epoch 26 - iter 27/35 - loss 0.18535287 - samples/sec: 64.18 - lr: 0.003125
2021-05-27 13:26:13,043 epoch 26 - iter 30/35 - loss 0.19841882 - samples/sec: 64.19 - lr: 0.003125
2021-05-27 13:26:14,550 epoch 26 - iter 33/35 - loss 0.20586396 - samples/sec: 63.71 - lr: 0.003125
2021-05-27 13:26:15,171 ----------------------------------------------------------------------------------------------------
2021-05-27 13:26:15,171 EPOCH 26 done: loss 0.2346 - lr 0.0031250
2021-05-27 13:26:16,557 DEV : loss 0.17845678329467773 - score 0.9546
2021-05-27 13:26:16,580 BAD EPOCHS (no improvement): 1
2021-05-27 13:26:16,580 ----------------------------------------------------------------------------------------------------
2021-05-27 13:26:18,088 epoch 27 - iter 3/35 - loss 0.24843383 - samples/sec: 63.70 - lr: 0.003125
2021-05-27 13:26:19,597 epoch 27 - iter 6/35 - loss 0.28029029 - samples/sec: 63.64 - lr: 0.003125
2021-05-27 13:26:21,077 epoch 27 - iter 9/35 - loss 0.26422554 - samples/sec: 64.87 - lr: 0.003125
2021-05-27 13:26:22,558 epoch 27 - iter 12/35 - loss 0.22378132 - samples/sec: 64.85 - lr: 0.003125
2021-05-27 13:26:24,052 epoch 27 - iter 15/35 - loss 0.21709161 - samples/sec: 64.28 - lr: 0.003125
2021-05-27 13:26:25,534 epoch 27 - iter 18/35 - loss 0.21601452 - samples/sec: 64.82 - lr: 0.003125
2021-05-27 13:26:27,038 epoch 27 - iter 21/35 - loss 0.20370055 - samples/sec: 63.84 - lr: 0.003125
2021-05-27 13:26:28,538 epoch 27 - iter 24/35 - loss 0.21359341 - samples/sec: 64.04 - lr: 0.003125
2021-05-27 13:26:30,056 epoch 27 - iter 27/35 - loss 0.22675180 - samples/sec: 63.24 - lr: 0.003125
2021-05-27 13:26:31,550 epoch 27 - iter 30/35 - loss 0.22221257 - samples/sec: 64.29 - lr: 0.003125
2021-05-27 13:26:33,056 epoch 27 - iter 33/35 - loss 0.21989535 - samples/sec: 63.76 - lr: 0.003125
2021-05-27 13:26:33,681 ----------------------------------------------------------------------------------------------------
2021-05-27 13:26:33,681 EPOCH 27 done: loss 0.2141 - lr 0.0031250
2021-05-27 13:26:35,068 DEV : loss 0.18742595613002777 - score 0.9569
2021-05-27 13:26:35,091 BAD EPOCHS (no improvement): 2
2021-05-27 13:26:35,091 ----------------------------------------------------------------------------------------------------
2021-05-27 13:26:36,590 epoch 28 - iter 3/35 - loss 0.11347349 - samples/sec: 64.05 - lr: 0.003125
2021-05-27 13:26:38,101 epoch 28 - iter 6/35 - loss 0.14386757 - samples/sec: 63.59 - lr: 0.003125
2021-05-27 13:26:39,588 epoch 28 - iter 9/35 - loss 0.24234398 - samples/sec: 64.57 - lr: 0.003125
2021-05-27 13:26:41,086 epoch 28 - iter 12/35 - loss 0.29139353 - samples/sec: 64.12 - lr: 0.003125
2021-05-27 13:26:42,607 epoch 28 - iter 15/35 - loss 0.27786417 - samples/sec: 63.13 - lr: 0.003125
2021-05-27 13:26:44,113 epoch 28 - iter 18/35 - loss 0.25871409 - samples/sec: 63.75 - lr: 0.003125
2021-05-27 13:26:45,623 epoch 28 - iter 21/35 - loss 0.24694367 - samples/sec: 63.58 - lr: 0.003125
2021-05-27 13:26:47,085 epoch 28 - iter 24/35 - loss 0.23937609 - samples/sec: 65.72 - lr: 0.003125
2021-05-27 13:26:48,582 epoch 28 - iter 27/35 - loss 0.23901916 - samples/sec: 64.15 - lr: 0.003125
2021-05-27 13:26:50,073 epoch 28 - iter 30/35 - loss 0.22747276 - samples/sec: 64.40 - lr: 0.003125
2021-05-27 13:26:51,577 epoch 28 - iter 33/35 - loss 0.22319861 - samples/sec: 63.82 - lr: 0.003125
2021-05-27 13:26:52,177 ----------------------------------------------------------------------------------------------------
2021-05-27 13:26:52,177 EPOCH 28 done: loss 0.2155 - lr 0.0031250
2021-05-27 13:26:53,564 DEV : loss 0.17704474925994873 - score 0.9546
2021-05-27 13:26:53,587 BAD EPOCHS (no improvement): 3
2021-05-27 13:26:53,587 ----------------------------------------------------------------------------------------------------
2021-05-27 13:26:55,255 epoch 29 - iter 3/35 - loss 0.31037426 - samples/sec: 57.60 - lr: 0.003125
2021-05-27 13:26:56,766 epoch 29 - iter 6/35 - loss 0.24962272 - samples/sec: 63.52 - lr: 0.003125
2021-05-27 13:26:58,262 epoch 29 - iter 9/35 - loss 0.19660435 - samples/sec: 64.23 - lr: 0.003125
2021-05-27 13:26:59,773 epoch 29 - iter 12/35 - loss 0.20169907 - samples/sec: 63.55 - lr: 0.003125
2021-05-27 13:27:01,276 epoch 29 - iter 15/35 - loss 0.20358898 - samples/sec: 63.88 - lr: 0.003125
2021-05-27 13:27:02,790 epoch 29 - iter 18/35 - loss 0.21199796 - samples/sec: 63.44 - lr: 0.003125
2021-05-27 13:27:04,251 epoch 29 - iter 21/35 - loss 0.23233049 - samples/sec: 65.73 - lr: 0.003125
2021-05-27 13:27:05,725 epoch 29 - iter 24/35 - loss 0.22782812 - samples/sec: 65.13 - lr: 0.003125
2021-05-27 13:27:07,221 epoch 29 - iter 27/35 - loss 0.22640799 - samples/sec: 64.21 - lr: 0.003125
2021-05-27 13:27:08,739 epoch 29 - iter 30/35 - loss 0.22577184 - samples/sec: 63.28 - lr: 0.003125
2021-05-27 13:27:10,214 epoch 29 - iter 33/35 - loss 0.21715457 - samples/sec: 65.07 - lr: 0.003125
2021-05-27 13:27:10,821 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:10,822 EPOCH 29 done: loss 0.2082 - lr 0.0031250
2021-05-27 13:27:12,208 DEV : loss 0.17233321070671082 - score 0.9567
Epoch    29: reducing learning rate of group 0 to 1.5625e-03.
2021-05-27 13:27:12,231 BAD EPOCHS (no improvement): 4
2021-05-27 13:27:12,232 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:13,720 epoch 30 - iter 3/35 - loss 0.34016033 - samples/sec: 64.54 - lr: 0.001563
2021-05-27 13:27:15,213 epoch 30 - iter 6/35 - loss 0.25391345 - samples/sec: 64.30 - lr: 0.001563
2021-05-27 13:27:16,718 epoch 30 - iter 9/35 - loss 0.26181130 - samples/sec: 63.81 - lr: 0.001563
2021-05-27 13:27:18,223 epoch 30 - iter 12/35 - loss 0.27128367 - samples/sec: 63.83 - lr: 0.001563
2021-05-27 13:27:19,732 epoch 30 - iter 15/35 - loss 0.27368269 - samples/sec: 63.62 - lr: 0.001563
2021-05-27 13:27:21,245 epoch 30 - iter 18/35 - loss 0.27174545 - samples/sec: 63.48 - lr: 0.001563
2021-05-27 13:27:22,740 epoch 30 - iter 21/35 - loss 0.25516841 - samples/sec: 64.24 - lr: 0.001563
2021-05-27 13:27:24,236 epoch 30 - iter 24/35 - loss 0.24973125 - samples/sec: 64.16 - lr: 0.001563
2021-05-27 13:27:25,714 epoch 30 - iter 27/35 - loss 0.24376784 - samples/sec: 65.01 - lr: 0.001563
2021-05-27 13:27:27,194 epoch 30 - iter 30/35 - loss 0.22551794 - samples/sec: 64.89 - lr: 0.001563
2021-05-27 13:27:28,705 epoch 30 - iter 33/35 - loss 0.21700056 - samples/sec: 63.54 - lr: 0.001563
2021-05-27 13:27:29,314 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:29,314 EPOCH 30 done: loss 0.2236 - lr 0.0015625
2021-05-27 13:27:30,700 DEV : loss 0.1752225160598755 - score 0.9569
2021-05-27 13:27:30,723 BAD EPOCHS (no improvement): 1
2021-05-27 13:27:31,676 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:31,677 Testing using best model ...
2021-05-27 13:27:31,677 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/fra.sdrt.annodis/best-model.pt
2021-05-27 13:27:39,423 0.8855	0.9526	0.9178
2021-05-27 13:27:39,423 
Results:
- F1-score (micro) 0.9178
- F1-score (macro) 0.9178

By class:
SENT       tp: 201 - fp: 26 - fn: 10 - precision: 0.8855 - recall: 0.9526 - f1-score: 0.9178
2021-05-27 13:27:39,423 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/
2021-05-27 13:27:39,448 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert
2021-05-27 13:27:39,448 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/sent_train.txt
2021-05-27 13:27:39,449 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/sent_dev.txt
2021-05-27 13:27:39,450 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/sent_test.txt
Corpus: 1046 train + 371 dev + 330 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 13:27:45,800 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:45,802 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 13:27:45,803 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:45,803 Corpus: "Corpus: 1046 train + 371 dev + 330 test sentences"
2021-05-27 13:27:45,803 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:45,803 Parameters:
2021-05-27 13:27:45,803  - learning_rate: "0.1"
2021-05-27 13:27:45,803  - mini_batch_size: "32"
2021-05-27 13:27:45,803  - patience: "3"
2021-05-27 13:27:45,803  - anneal_factor: "0.5"
2021-05-27 13:27:45,803  - max_epochs: "30"
2021-05-27 13:27:45,803  - shuffle: "True"
2021-05-27 13:27:45,803  - train_with_dev: "False"
2021-05-27 13:27:45,803  - batch_growth_annealing: "False"
2021-05-27 13:27:45,803 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:45,803 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert"
2021-05-27 13:27:45,803 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:45,803 Device: cuda:0
2021-05-27 13:27:45,803 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:45,803 Embeddings storage mode: cpu
2021-05-27 13:27:45,804 ----------------------------------------------------------------------------------------------------
2021-05-27 13:27:49,713 epoch 1 - iter 3/33 - loss 14.44368807 - samples/sec: 24.57 - lr: 0.100000
2021-05-27 13:27:53,601 epoch 1 - iter 6/33 - loss 11.00871674 - samples/sec: 24.69 - lr: 0.100000
2021-05-27 13:27:57,643 epoch 1 - iter 9/33 - loss 8.99261612 - samples/sec: 23.75 - lr: 0.100000
2021-05-27 13:28:01,538 epoch 1 - iter 12/33 - loss 8.02621849 - samples/sec: 24.65 - lr: 0.100000
2021-05-27 13:28:05,409 epoch 1 - iter 15/33 - loss 7.36811833 - samples/sec: 24.80 - lr: 0.100000
2021-05-27 13:28:09,364 epoch 1 - iter 18/33 - loss 6.81484813 - samples/sec: 24.28 - lr: 0.100000
2021-05-27 13:28:13,266 epoch 1 - iter 21/33 - loss 6.54674219 - samples/sec: 24.61 - lr: 0.100000
2021-05-27 13:28:17,144 epoch 1 - iter 24/33 - loss 6.19774422 - samples/sec: 24.76 - lr: 0.100000
2021-05-27 13:28:21,038 epoch 1 - iter 27/33 - loss 5.88621769 - samples/sec: 24.65 - lr: 0.100000
2021-05-27 13:28:25,002 epoch 1 - iter 30/33 - loss 5.58199486 - samples/sec: 24.22 - lr: 0.100000
2021-05-27 13:28:28,669 epoch 1 - iter 33/33 - loss 5.34507751 - samples/sec: 26.18 - lr: 0.100000
2021-05-27 13:28:28,669 ----------------------------------------------------------------------------------------------------
2021-05-27 13:28:28,669 EPOCH 1 done: loss 5.3451 - lr 0.1000000
2021-05-27 13:28:38,939 DEV : loss 1.6386291980743408 - score 0.8714
2021-05-27 13:28:38,974 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:28:39,935 ----------------------------------------------------------------------------------------------------
2021-05-27 13:28:41,477 epoch 2 - iter 3/33 - loss 2.46810834 - samples/sec: 62.27 - lr: 0.100000
2021-05-27 13:28:43,009 epoch 2 - iter 6/33 - loss 2.90006481 - samples/sec: 62.68 - lr: 0.100000
2021-05-27 13:28:44,529 epoch 2 - iter 9/33 - loss 2.56507152 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 13:28:46,097 epoch 2 - iter 12/33 - loss 2.64316649 - samples/sec: 61.26 - lr: 0.100000
2021-05-27 13:28:47,621 epoch 2 - iter 15/33 - loss 2.60631060 - samples/sec: 63.00 - lr: 0.100000
2021-05-27 13:28:49,183 epoch 2 - iter 18/33 - loss 2.56290686 - samples/sec: 61.47 - lr: 0.100000
2021-05-27 13:28:50,698 epoch 2 - iter 21/33 - loss 2.42732295 - samples/sec: 63.41 - lr: 0.100000
2021-05-27 13:28:52,232 epoch 2 - iter 24/33 - loss 2.36278793 - samples/sec: 62.59 - lr: 0.100000
2021-05-27 13:28:53,775 epoch 2 - iter 27/33 - loss 2.27077821 - samples/sec: 62.23 - lr: 0.100000
2021-05-27 13:28:55,274 epoch 2 - iter 30/33 - loss 2.25716249 - samples/sec: 64.06 - lr: 0.100000
2021-05-27 13:28:56,662 epoch 2 - iter 33/33 - loss 2.16155905 - samples/sec: 69.20 - lr: 0.100000
2021-05-27 13:28:56,662 ----------------------------------------------------------------------------------------------------
2021-05-27 13:28:56,662 EPOCH 2 done: loss 2.1616 - lr 0.1000000
2021-05-27 13:28:58,825 DEV : loss 1.2365909814834595 - score 0.6142
2021-05-27 13:28:58,860 BAD EPOCHS (no improvement): 1
2021-05-27 13:28:58,861 ----------------------------------------------------------------------------------------------------
2021-05-27 13:29:00,390 epoch 3 - iter 3/33 - loss 1.41108376 - samples/sec: 62.80 - lr: 0.100000
2021-05-27 13:29:01,886 epoch 3 - iter 6/33 - loss 1.30526389 - samples/sec: 64.18 - lr: 0.100000
2021-05-27 13:29:03,431 epoch 3 - iter 9/33 - loss 1.21582487 - samples/sec: 62.18 - lr: 0.100000
2021-05-27 13:29:04,975 epoch 3 - iter 12/33 - loss 1.23905609 - samples/sec: 62.17 - lr: 0.100000
2021-05-27 13:29:06,530 epoch 3 - iter 15/33 - loss 1.37572297 - samples/sec: 61.75 - lr: 0.100000
2021-05-27 13:29:08,069 epoch 3 - iter 18/33 - loss 1.37096124 - samples/sec: 62.43 - lr: 0.100000
2021-05-27 13:29:09,588 epoch 3 - iter 21/33 - loss 1.35246269 - samples/sec: 63.22 - lr: 0.100000
2021-05-27 13:29:11,111 epoch 3 - iter 24/33 - loss 1.34121209 - samples/sec: 63.05 - lr: 0.100000
2021-05-27 13:29:12,640 epoch 3 - iter 27/33 - loss 1.28600736 - samples/sec: 62.81 - lr: 0.100000
2021-05-27 13:29:14,162 epoch 3 - iter 30/33 - loss 1.29878304 - samples/sec: 63.08 - lr: 0.100000
2021-05-27 13:29:15,546 epoch 3 - iter 33/33 - loss 1.27981004 - samples/sec: 69.39 - lr: 0.100000
2021-05-27 13:29:15,546 ----------------------------------------------------------------------------------------------------
2021-05-27 13:29:15,546 EPOCH 3 done: loss 1.2798 - lr 0.1000000
2021-05-27 13:29:17,701 DEV : loss 0.5820881128311157 - score 0.9004
2021-05-27 13:29:17,736 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:29:26,488 ----------------------------------------------------------------------------------------------------
2021-05-27 13:29:28,037 epoch 4 - iter 3/33 - loss 0.91715006 - samples/sec: 62.01 - lr: 0.100000
2021-05-27 13:29:29,583 epoch 4 - iter 6/33 - loss 1.18935645 - samples/sec: 62.13 - lr: 0.100000
2021-05-27 13:29:31,114 epoch 4 - iter 9/33 - loss 1.01592413 - samples/sec: 62.71 - lr: 0.100000
2021-05-27 13:29:32,645 epoch 4 - iter 12/33 - loss 1.08556834 - samples/sec: 62.74 - lr: 0.100000
2021-05-27 13:29:34,185 epoch 4 - iter 15/33 - loss 1.03968654 - samples/sec: 62.36 - lr: 0.100000
2021-05-27 13:29:35,717 epoch 4 - iter 18/33 - loss 1.08835115 - samples/sec: 62.68 - lr: 0.100000
2021-05-27 13:29:37,255 epoch 4 - iter 21/33 - loss 1.12446412 - samples/sec: 62.41 - lr: 0.100000
2021-05-27 13:29:38,821 epoch 4 - iter 24/33 - loss 1.09416596 - samples/sec: 61.33 - lr: 0.100000
2021-05-27 13:29:40,368 epoch 4 - iter 27/33 - loss 1.13681870 - samples/sec: 62.10 - lr: 0.100000
2021-05-27 13:29:41,862 epoch 4 - iter 30/33 - loss 1.07615097 - samples/sec: 64.24 - lr: 0.100000
2021-05-27 13:29:43,254 epoch 4 - iter 33/33 - loss 1.06456489 - samples/sec: 68.99 - lr: 0.100000
2021-05-27 13:29:43,255 ----------------------------------------------------------------------------------------------------
2021-05-27 13:29:43,255 EPOCH 4 done: loss 1.0646 - lr 0.1000000
2021-05-27 13:29:45,590 DEV : loss 0.8078543543815613 - score 0.8596
2021-05-27 13:29:45,625 BAD EPOCHS (no improvement): 1
2021-05-27 13:29:45,625 ----------------------------------------------------------------------------------------------------
2021-05-27 13:29:47,197 epoch 5 - iter 3/33 - loss 0.82866303 - samples/sec: 61.11 - lr: 0.100000
2021-05-27 13:29:48,751 epoch 5 - iter 6/33 - loss 0.77029534 - samples/sec: 61.80 - lr: 0.100000
2021-05-27 13:29:50,263 epoch 5 - iter 9/33 - loss 0.63881518 - samples/sec: 63.49 - lr: 0.100000
2021-05-27 13:29:51,796 epoch 5 - iter 12/33 - loss 0.59258575 - samples/sec: 62.66 - lr: 0.100000
2021-05-27 13:29:53,317 epoch 5 - iter 15/33 - loss 0.68738141 - samples/sec: 63.14 - lr: 0.100000
2021-05-27 13:29:54,800 epoch 5 - iter 18/33 - loss 0.74603473 - samples/sec: 64.77 - lr: 0.100000
2021-05-27 13:29:56,345 epoch 5 - iter 21/33 - loss 0.77292107 - samples/sec: 62.15 - lr: 0.100000
2021-05-27 13:29:57,879 epoch 5 - iter 24/33 - loss 0.78172895 - samples/sec: 62.57 - lr: 0.100000
2021-05-27 13:29:59,418 epoch 5 - iter 27/33 - loss 0.77796206 - samples/sec: 62.41 - lr: 0.100000
2021-05-27 13:30:00,963 epoch 5 - iter 30/33 - loss 0.79688912 - samples/sec: 62.17 - lr: 0.100000
2021-05-27 13:30:02,347 epoch 5 - iter 33/33 - loss 0.79608208 - samples/sec: 69.35 - lr: 0.100000
2021-05-27 13:30:02,348 ----------------------------------------------------------------------------------------------------
2021-05-27 13:30:02,348 EPOCH 5 done: loss 0.7961 - lr 0.1000000
2021-05-27 13:30:04,507 DEV : loss 0.4821632504463196 - score 0.92
2021-05-27 13:30:04,542 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:30:13,187 ----------------------------------------------------------------------------------------------------
2021-05-27 13:30:14,717 epoch 6 - iter 3/33 - loss 0.29175782 - samples/sec: 62.82 - lr: 0.100000
2021-05-27 13:30:16,245 epoch 6 - iter 6/33 - loss 0.51403282 - samples/sec: 62.85 - lr: 0.100000
2021-05-27 13:30:17,780 epoch 6 - iter 9/33 - loss 0.61676490 - samples/sec: 62.55 - lr: 0.100000
2021-05-27 13:30:19,343 epoch 6 - iter 12/33 - loss 0.63798584 - samples/sec: 61.45 - lr: 0.100000
2021-05-27 13:30:20,874 epoch 6 - iter 15/33 - loss 0.75345613 - samples/sec: 62.72 - lr: 0.100000
2021-05-27 13:30:22,395 epoch 6 - iter 18/33 - loss 0.77888496 - samples/sec: 63.15 - lr: 0.100000
2021-05-27 13:30:23,908 epoch 6 - iter 21/33 - loss 0.73762701 - samples/sec: 63.43 - lr: 0.100000
2021-05-27 13:30:25,416 epoch 6 - iter 24/33 - loss 0.72439757 - samples/sec: 63.70 - lr: 0.100000
2021-05-27 13:30:26,941 epoch 6 - iter 27/33 - loss 0.69815304 - samples/sec: 62.97 - lr: 0.100000
2021-05-27 13:30:28,488 epoch 6 - iter 30/33 - loss 0.69233915 - samples/sec: 62.07 - lr: 0.100000
2021-05-27 13:30:29,868 epoch 6 - iter 33/33 - loss 0.65977221 - samples/sec: 69.58 - lr: 0.100000
2021-05-27 13:30:29,869 ----------------------------------------------------------------------------------------------------
2021-05-27 13:30:29,869 EPOCH 6 done: loss 0.6598 - lr 0.1000000
2021-05-27 13:30:32,024 DEV : loss 0.5619003772735596 - score 0.9072
2021-05-27 13:30:32,059 BAD EPOCHS (no improvement): 1
2021-05-27 13:30:32,060 ----------------------------------------------------------------------------------------------------
2021-05-27 13:30:33,598 epoch 7 - iter 3/33 - loss 0.62781457 - samples/sec: 62.43 - lr: 0.100000
2021-05-27 13:30:35,124 epoch 7 - iter 6/33 - loss 0.76202645 - samples/sec: 62.92 - lr: 0.100000
2021-05-27 13:30:36,637 epoch 7 - iter 9/33 - loss 0.73268643 - samples/sec: 63.47 - lr: 0.100000
2021-05-27 13:30:38,168 epoch 7 - iter 12/33 - loss 0.69668016 - samples/sec: 62.72 - lr: 0.100000
2021-05-27 13:30:39,684 epoch 7 - iter 15/33 - loss 0.61709344 - samples/sec: 63.34 - lr: 0.100000
2021-05-27 13:30:41,242 epoch 7 - iter 18/33 - loss 0.55607913 - samples/sec: 61.64 - lr: 0.100000
2021-05-27 13:30:42,740 epoch 7 - iter 21/33 - loss 0.56976711 - samples/sec: 64.12 - lr: 0.100000
2021-05-27 13:30:44,270 epoch 7 - iter 24/33 - loss 0.57164556 - samples/sec: 62.75 - lr: 0.100000
2021-05-27 13:30:45,831 epoch 7 - iter 27/33 - loss 0.58831030 - samples/sec: 61.52 - lr: 0.100000
2021-05-27 13:30:47,372 epoch 7 - iter 30/33 - loss 0.58687444 - samples/sec: 62.33 - lr: 0.100000
2021-05-27 13:30:48,743 epoch 7 - iter 33/33 - loss 0.55812457 - samples/sec: 70.05 - lr: 0.100000
2021-05-27 13:30:48,743 ----------------------------------------------------------------------------------------------------
2021-05-27 13:30:48,743 EPOCH 7 done: loss 0.5581 - lr 0.1000000
2021-05-27 13:30:51,071 DEV : loss 0.41695553064346313 - score 0.9268
2021-05-27 13:30:51,107 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:30:59,859 ----------------------------------------------------------------------------------------------------
2021-05-27 13:31:01,401 epoch 8 - iter 3/33 - loss 0.33192770 - samples/sec: 62.30 - lr: 0.100000
2021-05-27 13:31:02,911 epoch 8 - iter 6/33 - loss 0.31418484 - samples/sec: 63.61 - lr: 0.100000
2021-05-27 13:31:04,449 epoch 8 - iter 9/33 - loss 0.29809168 - samples/sec: 62.42 - lr: 0.100000
2021-05-27 13:31:05,996 epoch 8 - iter 12/33 - loss 0.31278446 - samples/sec: 62.08 - lr: 0.100000
2021-05-27 13:31:07,507 epoch 8 - iter 15/33 - loss 0.33734159 - samples/sec: 63.58 - lr: 0.100000
2021-05-27 13:31:09,055 epoch 8 - iter 18/33 - loss 0.38249565 - samples/sec: 62.02 - lr: 0.100000
2021-05-27 13:31:10,595 epoch 8 - iter 21/33 - loss 0.38128592 - samples/sec: 62.38 - lr: 0.100000
2021-05-27 13:31:12,138 epoch 8 - iter 24/33 - loss 0.41504151 - samples/sec: 62.23 - lr: 0.100000
2021-05-27 13:31:13,694 epoch 8 - iter 27/33 - loss 0.46474244 - samples/sec: 61.73 - lr: 0.100000
2021-05-27 13:31:15,249 epoch 8 - iter 30/33 - loss 0.49260364 - samples/sec: 61.73 - lr: 0.100000
2021-05-27 13:31:16,639 epoch 8 - iter 33/33 - loss 0.47532820 - samples/sec: 69.11 - lr: 0.100000
2021-05-27 13:31:16,639 ----------------------------------------------------------------------------------------------------
2021-05-27 13:31:16,639 EPOCH 8 done: loss 0.4753 - lr 0.1000000
2021-05-27 13:31:18,796 DEV : loss 1.546863317489624 - score 0.7738
2021-05-27 13:31:18,831 BAD EPOCHS (no improvement): 1
2021-05-27 13:31:18,832 ----------------------------------------------------------------------------------------------------
2021-05-27 13:31:20,380 epoch 9 - iter 3/33 - loss 0.55551475 - samples/sec: 62.01 - lr: 0.100000
2021-05-27 13:31:21,897 epoch 9 - iter 6/33 - loss 0.42288647 - samples/sec: 63.32 - lr: 0.100000
2021-05-27 13:31:23,435 epoch 9 - iter 9/33 - loss 0.53086642 - samples/sec: 62.43 - lr: 0.100000
2021-05-27 13:31:24,976 epoch 9 - iter 12/33 - loss 0.51631482 - samples/sec: 62.34 - lr: 0.100000
2021-05-27 13:31:26,522 epoch 9 - iter 15/33 - loss 0.55432641 - samples/sec: 62.11 - lr: 0.100000
2021-05-27 13:31:28,061 epoch 9 - iter 18/33 - loss 0.54796844 - samples/sec: 62.39 - lr: 0.100000
2021-05-27 13:31:29,595 epoch 9 - iter 21/33 - loss 0.51906987 - samples/sec: 62.60 - lr: 0.100000
2021-05-27 13:31:31,112 epoch 9 - iter 24/33 - loss 0.49798501 - samples/sec: 63.32 - lr: 0.100000
2021-05-27 13:31:32,655 epoch 9 - iter 27/33 - loss 0.50325767 - samples/sec: 62.21 - lr: 0.100000
2021-05-27 13:31:34,199 epoch 9 - iter 30/33 - loss 0.48635185 - samples/sec: 62.23 - lr: 0.100000
2021-05-27 13:31:35,566 epoch 9 - iter 33/33 - loss 0.46428919 - samples/sec: 70.26 - lr: 0.100000
2021-05-27 13:31:35,566 ----------------------------------------------------------------------------------------------------
2021-05-27 13:31:35,566 EPOCH 9 done: loss 0.4643 - lr 0.1000000
2021-05-27 13:31:37,719 DEV : loss 0.2672036588191986 - score 0.9387
2021-05-27 13:31:37,754 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:31:46,683 ----------------------------------------------------------------------------------------------------
2021-05-27 13:31:48,220 epoch 10 - iter 3/33 - loss 0.65678954 - samples/sec: 62.52 - lr: 0.100000
2021-05-27 13:31:49,783 epoch 10 - iter 6/33 - loss 0.55376275 - samples/sec: 61.42 - lr: 0.100000
2021-05-27 13:31:51,315 epoch 10 - iter 9/33 - loss 0.45115858 - samples/sec: 62.71 - lr: 0.100000
2021-05-27 13:31:52,864 epoch 10 - iter 12/33 - loss 0.40790004 - samples/sec: 62.00 - lr: 0.100000
2021-05-27 13:31:54,597 epoch 10 - iter 15/33 - loss 0.43409925 - samples/sec: 55.41 - lr: 0.100000
2021-05-27 13:31:56,141 epoch 10 - iter 18/33 - loss 0.46399352 - samples/sec: 62.21 - lr: 0.100000
2021-05-27 13:31:57,683 epoch 10 - iter 21/33 - loss 0.46818253 - samples/sec: 62.28 - lr: 0.100000
2021-05-27 13:31:59,233 epoch 10 - iter 24/33 - loss 0.43800059 - samples/sec: 61.92 - lr: 0.100000
2021-05-27 13:32:00,748 epoch 10 - iter 27/33 - loss 0.42427125 - samples/sec: 63.39 - lr: 0.100000
2021-05-27 13:32:02,252 epoch 10 - iter 30/33 - loss 0.42386566 - samples/sec: 63.88 - lr: 0.100000
2021-05-27 13:32:03,623 epoch 10 - iter 33/33 - loss 0.40613997 - samples/sec: 70.03 - lr: 0.100000
2021-05-27 13:32:03,623 ----------------------------------------------------------------------------------------------------
2021-05-27 13:32:03,623 EPOCH 10 done: loss 0.4061 - lr 0.1000000
2021-05-27 13:32:05,777 DEV : loss 0.27717897295951843 - score 0.9436
2021-05-27 13:32:05,812 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:32:14,504 ----------------------------------------------------------------------------------------------------
2021-05-27 13:32:16,063 epoch 11 - iter 3/33 - loss 0.25226148 - samples/sec: 61.65 - lr: 0.100000
2021-05-27 13:32:17,585 epoch 11 - iter 6/33 - loss 0.32283008 - samples/sec: 63.07 - lr: 0.100000
2021-05-27 13:32:19,100 epoch 11 - iter 9/33 - loss 0.32133479 - samples/sec: 63.39 - lr: 0.100000
2021-05-27 13:32:20,536 epoch 11 - iter 12/33 - loss 0.29634262 - samples/sec: 66.89 - lr: 0.100000
2021-05-27 13:32:22,088 epoch 11 - iter 15/33 - loss 0.30235539 - samples/sec: 61.86 - lr: 0.100000
2021-05-27 13:32:23,622 epoch 11 - iter 18/33 - loss 0.42008897 - samples/sec: 62.61 - lr: 0.100000
2021-05-27 13:32:25,154 epoch 11 - iter 21/33 - loss 0.39811931 - samples/sec: 62.67 - lr: 0.100000
2021-05-27 13:32:26,711 epoch 11 - iter 24/33 - loss 0.38925355 - samples/sec: 61.67 - lr: 0.100000
2021-05-27 13:32:28,251 epoch 11 - iter 27/33 - loss 0.36897749 - samples/sec: 62.36 - lr: 0.100000
2021-05-27 13:32:29,793 epoch 11 - iter 30/33 - loss 0.37135352 - samples/sec: 62.30 - lr: 0.100000
2021-05-27 13:32:31,181 epoch 11 - iter 33/33 - loss 0.37337480 - samples/sec: 69.20 - lr: 0.100000
2021-05-27 13:32:31,181 ----------------------------------------------------------------------------------------------------
2021-05-27 13:32:31,181 EPOCH 11 done: loss 0.3734 - lr 0.1000000
2021-05-27 13:32:33,334 DEV : loss 0.2646951973438263 - score 0.9398
2021-05-27 13:32:33,369 BAD EPOCHS (no improvement): 1
2021-05-27 13:32:33,369 ----------------------------------------------------------------------------------------------------
2021-05-27 13:32:34,900 epoch 12 - iter 3/33 - loss 0.27799491 - samples/sec: 62.74 - lr: 0.100000
2021-05-27 13:32:36,447 epoch 12 - iter 6/33 - loss 0.34070264 - samples/sec: 62.05 - lr: 0.100000
2021-05-27 13:32:37,982 epoch 12 - iter 9/33 - loss 0.32277877 - samples/sec: 62.59 - lr: 0.100000
2021-05-27 13:32:39,517 epoch 12 - iter 12/33 - loss 0.34430416 - samples/sec: 62.52 - lr: 0.100000
2021-05-27 13:32:41,045 epoch 12 - iter 15/33 - loss 0.36157427 - samples/sec: 62.86 - lr: 0.100000
2021-05-27 13:32:42,538 epoch 12 - iter 18/33 - loss 0.32780376 - samples/sec: 64.32 - lr: 0.100000
2021-05-27 13:32:44,084 epoch 12 - iter 21/33 - loss 0.32092764 - samples/sec: 62.13 - lr: 0.100000
2021-05-27 13:32:45,609 epoch 12 - iter 24/33 - loss 0.30846081 - samples/sec: 62.97 - lr: 0.100000
2021-05-27 13:32:47,102 epoch 12 - iter 27/33 - loss 0.31888737 - samples/sec: 64.30 - lr: 0.100000
2021-05-27 13:32:48,624 epoch 12 - iter 30/33 - loss 0.32344623 - samples/sec: 63.10 - lr: 0.100000
2021-05-27 13:32:50,014 epoch 12 - iter 33/33 - loss 0.31080838 - samples/sec: 69.12 - lr: 0.100000
2021-05-27 13:32:50,014 ----------------------------------------------------------------------------------------------------
2021-05-27 13:32:50,014 EPOCH 12 done: loss 0.3108 - lr 0.1000000
2021-05-27 13:32:52,343 DEV : loss 0.322551965713501 - score 0.9386
2021-05-27 13:32:52,379 BAD EPOCHS (no improvement): 2
2021-05-27 13:32:52,379 ----------------------------------------------------------------------------------------------------
2021-05-27 13:32:53,867 epoch 13 - iter 3/33 - loss 0.15582530 - samples/sec: 64.54 - lr: 0.100000
2021-05-27 13:32:55,398 epoch 13 - iter 6/33 - loss 0.23832167 - samples/sec: 62.76 - lr: 0.100000
2021-05-27 13:32:56,953 epoch 13 - iter 9/33 - loss 0.30296899 - samples/sec: 61.73 - lr: 0.100000
2021-05-27 13:32:58,476 epoch 13 - iter 12/33 - loss 0.30525213 - samples/sec: 63.07 - lr: 0.100000
2021-05-27 13:33:00,010 epoch 13 - iter 15/33 - loss 0.32462264 - samples/sec: 62.60 - lr: 0.100000
2021-05-27 13:33:01,537 epoch 13 - iter 18/33 - loss 0.33220853 - samples/sec: 62.87 - lr: 0.100000
2021-05-27 13:33:03,077 epoch 13 - iter 21/33 - loss 0.32902417 - samples/sec: 62.38 - lr: 0.100000
2021-05-27 13:33:04,630 epoch 13 - iter 24/33 - loss 0.31139977 - samples/sec: 61.84 - lr: 0.100000
2021-05-27 13:33:06,169 epoch 13 - iter 27/33 - loss 0.29167417 - samples/sec: 62.40 - lr: 0.100000
2021-05-27 13:33:07,681 epoch 13 - iter 30/33 - loss 0.29702293 - samples/sec: 63.51 - lr: 0.100000
2021-05-27 13:33:09,092 epoch 13 - iter 33/33 - loss 0.30729139 - samples/sec: 68.03 - lr: 0.100000
2021-05-27 13:33:09,093 ----------------------------------------------------------------------------------------------------
2021-05-27 13:33:09,093 EPOCH 13 done: loss 0.3073 - lr 0.1000000
2021-05-27 13:33:11,249 DEV : loss 0.24142222106456757 - score 0.9556
2021-05-27 13:33:11,285 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 13:33:20,263 ----------------------------------------------------------------------------------------------------
2021-05-27 13:33:21,803 epoch 14 - iter 3/33 - loss 0.47382089 - samples/sec: 62.40 - lr: 0.100000
2021-05-27 13:33:23,332 epoch 14 - iter 6/33 - loss 0.37355194 - samples/sec: 62.81 - lr: 0.100000
2021-05-27 13:33:24,879 epoch 14 - iter 9/33 - loss 0.37835387 - samples/sec: 62.05 - lr: 0.100000
2021-05-27 13:33:26,408 epoch 14 - iter 12/33 - loss 0.46341635 - samples/sec: 62.80 - lr: 0.100000
2021-05-27 13:33:27,941 epoch 14 - iter 15/33 - loss 0.44519164 - samples/sec: 62.64 - lr: 0.100000
2021-05-27 13:33:29,503 epoch 14 - iter 18/33 - loss 0.41802556 - samples/sec: 61.49 - lr: 0.100000
2021-05-27 13:33:31,009 epoch 14 - iter 21/33 - loss 0.37623397 - samples/sec: 63.76 - lr: 0.100000
2021-05-27 13:33:32,546 epoch 14 - iter 24/33 - loss 0.35058670 - samples/sec: 62.48 - lr: 0.100000
2021-05-27 13:33:34,071 epoch 14 - iter 27/33 - loss 0.34628758 - samples/sec: 62.99 - lr: 0.100000
2021-05-27 13:33:35,607 epoch 14 - iter 30/33 - loss 0.35292009 - samples/sec: 62.50 - lr: 0.100000
2021-05-27 13:33:37,008 epoch 14 - iter 33/33 - loss 0.38456669 - samples/sec: 68.56 - lr: 0.100000
2021-05-27 13:33:37,008 ----------------------------------------------------------------------------------------------------
2021-05-27 13:33:37,008 EPOCH 14 done: loss 0.3846 - lr 0.1000000
2021-05-27 13:33:39,162 DEV : loss 0.22319483757019043 - score 0.9461
2021-05-27 13:33:39,197 BAD EPOCHS (no improvement): 1
2021-05-27 13:33:39,198 ----------------------------------------------------------------------------------------------------
2021-05-27 13:33:40,754 epoch 15 - iter 3/33 - loss 0.80677954 - samples/sec: 61.70 - lr: 0.100000
2021-05-27 13:33:42,292 epoch 15 - iter 6/33 - loss 0.65523454 - samples/sec: 62.42 - lr: 0.100000
2021-05-27 13:33:43,824 epoch 15 - iter 9/33 - loss 0.51072868 - samples/sec: 62.70 - lr: 0.100000
2021-05-27 13:33:45,389 epoch 15 - iter 12/33 - loss 0.47109445 - samples/sec: 61.36 - lr: 0.100000
2021-05-27 13:33:46,947 epoch 15 - iter 15/33 - loss 0.43179083 - samples/sec: 61.63 - lr: 0.100000
2021-05-27 13:33:48,489 epoch 15 - iter 18/33 - loss 0.40251731 - samples/sec: 62.29 - lr: 0.100000
2021-05-27 13:33:50,010 epoch 15 - iter 21/33 - loss 0.41713031 - samples/sec: 63.15 - lr: 0.100000
2021-05-27 13:33:51,558 epoch 15 - iter 24/33 - loss 0.43393859 - samples/sec: 62.02 - lr: 0.100000
2021-05-27 13:33:53,078 epoch 15 - iter 27/33 - loss 0.40616777 - samples/sec: 63.16 - lr: 0.100000
2021-05-27 13:33:54,591 epoch 15 - iter 30/33 - loss 0.40385105 - samples/sec: 63.49 - lr: 0.100000
2021-05-27 13:33:55,950 epoch 15 - iter 33/33 - loss 0.41699636 - samples/sec: 70.66 - lr: 0.100000
2021-05-27 13:33:55,950 ----------------------------------------------------------------------------------------------------
2021-05-27 13:33:55,951 EPOCH 15 done: loss 0.4170 - lr 0.1000000
2021-05-27 13:33:58,274 DEV : loss 0.6436249017715454 - score 0.91
2021-05-27 13:33:58,310 BAD EPOCHS (no improvement): 2
2021-05-27 13:33:58,310 ----------------------------------------------------------------------------------------------------
2021-05-27 13:33:59,840 epoch 16 - iter 3/33 - loss 0.36323476 - samples/sec: 62.76 - lr: 0.100000
2021-05-27 13:34:01,357 epoch 16 - iter 6/33 - loss 0.24765474 - samples/sec: 63.30 - lr: 0.100000
2021-05-27 13:34:02,906 epoch 16 - iter 9/33 - loss 0.24231960 - samples/sec: 62.01 - lr: 0.100000
2021-05-27 13:34:04,453 epoch 16 - iter 12/33 - loss 0.23111815 - samples/sec: 62.09 - lr: 0.100000
2021-05-27 13:34:05,985 epoch 16 - iter 15/33 - loss 0.25304779 - samples/sec: 62.67 - lr: 0.100000
2021-05-27 13:34:07,550 epoch 16 - iter 18/33 - loss 0.24925995 - samples/sec: 61.35 - lr: 0.100000
2021-05-27 13:34:09,095 epoch 16 - iter 21/33 - loss 0.25262964 - samples/sec: 62.17 - lr: 0.100000
2021-05-27 13:34:10,645 epoch 16 - iter 24/33 - loss 0.24218763 - samples/sec: 61.94 - lr: 0.100000
2021-05-27 13:34:12,190 epoch 16 - iter 27/33 - loss 0.23912246 - samples/sec: 62.15 - lr: 0.100000
2021-05-27 13:34:13,688 epoch 16 - iter 30/33 - loss 0.23974694 - samples/sec: 64.10 - lr: 0.100000
2021-05-27 13:34:15,085 epoch 16 - iter 33/33 - loss 0.26466937 - samples/sec: 68.78 - lr: 0.100000
2021-05-27 13:34:15,085 ----------------------------------------------------------------------------------------------------
2021-05-27 13:34:15,085 EPOCH 16 done: loss 0.2647 - lr 0.1000000
2021-05-27 13:34:17,239 DEV : loss 0.9671201109886169 - score 0.8617
2021-05-27 13:34:17,274 BAD EPOCHS (no improvement): 3
2021-05-27 13:34:17,275 ----------------------------------------------------------------------------------------------------
2021-05-27 13:34:18,787 epoch 17 - iter 3/33 - loss 0.39094921 - samples/sec: 63.48 - lr: 0.100000
2021-05-27 13:34:20,313 epoch 17 - iter 6/33 - loss 0.40499739 - samples/sec: 62.93 - lr: 0.100000
2021-05-27 13:34:21,860 epoch 17 - iter 9/33 - loss 0.37294826 - samples/sec: 62.10 - lr: 0.100000
2021-05-27 13:34:23,399 epoch 17 - iter 12/33 - loss 0.32871351 - samples/sec: 62.39 - lr: 0.100000
2021-05-27 13:34:24,967 epoch 17 - iter 15/33 - loss 0.35199599 - samples/sec: 61.24 - lr: 0.100000
2021-05-27 13:34:26,472 epoch 17 - iter 18/33 - loss 0.33330322 - samples/sec: 63.82 - lr: 0.100000
2021-05-27 13:34:28,009 epoch 17 - iter 21/33 - loss 0.33830099 - samples/sec: 62.48 - lr: 0.100000
2021-05-27 13:34:29,547 epoch 17 - iter 24/33 - loss 0.32925347 - samples/sec: 62.44 - lr: 0.100000
2021-05-27 13:34:31,100 epoch 17 - iter 27/33 - loss 0.33171485 - samples/sec: 61.84 - lr: 0.100000
2021-05-27 13:34:32,640 epoch 17 - iter 30/33 - loss 0.32835927 - samples/sec: 62.34 - lr: 0.100000
2021-05-27 13:34:34,057 epoch 17 - iter 33/33 - loss 0.32796448 - samples/sec: 67.78 - lr: 0.100000
2021-05-27 13:34:34,057 ----------------------------------------------------------------------------------------------------
2021-05-27 13:34:34,057 EPOCH 17 done: loss 0.3280 - lr 0.1000000
2021-05-27 13:34:36,210 DEV : loss 0.27579930424690247 - score 0.9459
Epoch    17: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 13:34:36,245 BAD EPOCHS (no improvement): 4
2021-05-27 13:34:36,245 ----------------------------------------------------------------------------------------------------
2021-05-27 13:34:37,801 epoch 18 - iter 3/33 - loss 0.23446353 - samples/sec: 61.72 - lr: 0.050000
2021-05-27 13:34:39,297 epoch 18 - iter 6/33 - loss 0.19521012 - samples/sec: 64.20 - lr: 0.050000
2021-05-27 13:34:40,831 epoch 18 - iter 9/33 - loss 0.19314618 - samples/sec: 62.62 - lr: 0.050000
2021-05-27 13:34:42,371 epoch 18 - iter 12/33 - loss 0.17208014 - samples/sec: 62.37 - lr: 0.050000
2021-05-27 13:34:43,871 epoch 18 - iter 15/33 - loss 0.18136447 - samples/sec: 63.98 - lr: 0.050000
2021-05-27 13:34:45,414 epoch 18 - iter 18/33 - loss 0.17977836 - samples/sec: 62.25 - lr: 0.050000
2021-05-27 13:34:46,947 epoch 18 - iter 21/33 - loss 0.21845461 - samples/sec: 62.66 - lr: 0.050000
2021-05-27 13:34:48,506 epoch 18 - iter 24/33 - loss 0.22581178 - samples/sec: 61.58 - lr: 0.050000
2021-05-27 13:34:50,026 epoch 18 - iter 27/33 - loss 0.22475296 - samples/sec: 63.19 - lr: 0.050000
2021-05-27 13:34:51,587 epoch 18 - iter 30/33 - loss 0.22652555 - samples/sec: 61.53 - lr: 0.050000
2021-05-27 13:34:52,976 epoch 18 - iter 33/33 - loss 0.22543322 - samples/sec: 69.10 - lr: 0.050000
2021-05-27 13:34:52,977 ----------------------------------------------------------------------------------------------------
2021-05-27 13:34:52,977 EPOCH 18 done: loss 0.2254 - lr 0.0500000
2021-05-27 13:34:55,297 DEV : loss 0.32216835021972656 - score 0.9364
2021-05-27 13:34:55,333 BAD EPOCHS (no improvement): 1
2021-05-27 13:34:55,333 ----------------------------------------------------------------------------------------------------
2021-05-27 13:34:56,860 epoch 19 - iter 3/33 - loss 0.10114286 - samples/sec: 62.87 - lr: 0.050000
2021-05-27 13:34:58,356 epoch 19 - iter 6/33 - loss 0.12854669 - samples/sec: 64.20 - lr: 0.050000
2021-05-27 13:34:59,914 epoch 19 - iter 9/33 - loss 0.17269678 - samples/sec: 61.63 - lr: 0.050000
2021-05-27 13:35:01,463 epoch 19 - iter 12/33 - loss 0.17980010 - samples/sec: 62.02 - lr: 0.050000
2021-05-27 13:35:03,010 epoch 19 - iter 15/33 - loss 0.17402432 - samples/sec: 62.07 - lr: 0.050000
2021-05-27 13:35:04,553 epoch 19 - iter 18/33 - loss 0.16655577 - samples/sec: 62.24 - lr: 0.050000
2021-05-27 13:35:06,062 epoch 19 - iter 21/33 - loss 0.16573031 - samples/sec: 63.64 - lr: 0.050000
2021-05-27 13:35:07,599 epoch 19 - iter 24/33 - loss 0.16161064 - samples/sec: 62.48 - lr: 0.050000
2021-05-27 13:35:09,166 epoch 19 - iter 27/33 - loss 0.16996202 - samples/sec: 61.27 - lr: 0.050000
2021-05-27 13:35:10,693 epoch 19 - iter 30/33 - loss 0.17142742 - samples/sec: 62.90 - lr: 0.050000
2021-05-27 13:35:12,081 epoch 19 - iter 33/33 - loss 0.17268976 - samples/sec: 69.19 - lr: 0.050000
2021-05-27 13:35:12,081 ----------------------------------------------------------------------------------------------------
2021-05-27 13:35:12,081 EPOCH 19 done: loss 0.1727 - lr 0.0500000
2021-05-27 13:35:14,235 DEV : loss 0.35611462593078613 - score 0.9382
2021-05-27 13:35:14,270 BAD EPOCHS (no improvement): 2
2021-05-27 13:35:14,270 ----------------------------------------------------------------------------------------------------
2021-05-27 13:35:15,799 epoch 20 - iter 3/33 - loss 0.15054352 - samples/sec: 62.79 - lr: 0.050000
2021-05-27 13:35:17,336 epoch 20 - iter 6/33 - loss 0.13991427 - samples/sec: 62.51 - lr: 0.050000
2021-05-27 13:35:18,855 epoch 20 - iter 9/33 - loss 0.14974624 - samples/sec: 63.23 - lr: 0.050000
2021-05-27 13:35:20,412 epoch 20 - iter 12/33 - loss 0.18025178 - samples/sec: 61.66 - lr: 0.050000
2021-05-27 13:35:21,934 epoch 20 - iter 15/33 - loss 0.19528122 - samples/sec: 63.08 - lr: 0.050000
2021-05-27 13:35:23,478 epoch 20 - iter 18/33 - loss 0.18305624 - samples/sec: 62.23 - lr: 0.050000
2021-05-27 13:35:25,039 epoch 20 - iter 21/33 - loss 0.18222192 - samples/sec: 61.50 - lr: 0.050000
2021-05-27 13:35:26,570 epoch 20 - iter 24/33 - loss 0.18686756 - samples/sec: 62.73 - lr: 0.050000
2021-05-27 13:35:28,104 epoch 20 - iter 27/33 - loss 0.18433755 - samples/sec: 62.62 - lr: 0.050000
2021-05-27 13:35:29,623 epoch 20 - iter 30/33 - loss 0.18761169 - samples/sec: 63.22 - lr: 0.050000
2021-05-27 13:35:31,014 epoch 20 - iter 33/33 - loss 0.19885745 - samples/sec: 69.04 - lr: 0.050000
2021-05-27 13:35:31,014 ----------------------------------------------------------------------------------------------------
2021-05-27 13:35:31,014 EPOCH 20 done: loss 0.1989 - lr 0.0500000
2021-05-27 13:35:33,170 DEV : loss 0.393307626247406 - score 0.9357
2021-05-27 13:35:33,206 BAD EPOCHS (no improvement): 3
2021-05-27 13:35:33,206 ----------------------------------------------------------------------------------------------------
2021-05-27 13:35:34,724 epoch 21 - iter 3/33 - loss 0.24294839 - samples/sec: 63.26 - lr: 0.050000
2021-05-27 13:35:36,264 epoch 21 - iter 6/33 - loss 0.22660317 - samples/sec: 62.36 - lr: 0.050000
2021-05-27 13:35:37,780 epoch 21 - iter 9/33 - loss 0.20299322 - samples/sec: 63.35 - lr: 0.050000
2021-05-27 13:35:39,278 epoch 21 - iter 12/33 - loss 0.18136685 - samples/sec: 64.11 - lr: 0.050000
2021-05-27 13:35:40,797 epoch 21 - iter 15/33 - loss 0.19053832 - samples/sec: 63.23 - lr: 0.050000
2021-05-27 13:35:42,312 epoch 21 - iter 18/33 - loss 0.20567003 - samples/sec: 63.38 - lr: 0.050000
2021-05-27 13:35:43,877 epoch 21 - iter 21/33 - loss 0.21184302 - samples/sec: 61.37 - lr: 0.050000
2021-05-27 13:35:45,432 epoch 21 - iter 24/33 - loss 0.22708973 - samples/sec: 61.76 - lr: 0.050000
2021-05-27 13:35:47,000 epoch 21 - iter 27/33 - loss 0.23214095 - samples/sec: 61.25 - lr: 0.050000
2021-05-27 13:35:48,557 epoch 21 - iter 30/33 - loss 0.22319302 - samples/sec: 61.66 - lr: 0.050000
2021-05-27 13:35:49,958 epoch 21 - iter 33/33 - loss 0.22116680 - samples/sec: 68.56 - lr: 0.050000
2021-05-27 13:35:49,958 ----------------------------------------------------------------------------------------------------
2021-05-27 13:35:49,958 EPOCH 21 done: loss 0.2212 - lr 0.0500000
2021-05-27 13:35:52,279 DEV : loss 0.3784825801849365 - score 0.9393
Epoch    21: reducing learning rate of group 0 to 2.5000e-02.
2021-05-27 13:35:52,314 BAD EPOCHS (no improvement): 4
2021-05-27 13:35:52,314 ----------------------------------------------------------------------------------------------------
2021-05-27 13:35:53,829 epoch 22 - iter 3/33 - loss 0.14355636 - samples/sec: 63.41 - lr: 0.025000
2021-05-27 13:35:55,377 epoch 22 - iter 6/33 - loss 0.14413399 - samples/sec: 62.02 - lr: 0.025000
2021-05-27 13:35:56,917 epoch 22 - iter 9/33 - loss 0.13444622 - samples/sec: 62.36 - lr: 0.025000
2021-05-27 13:35:58,466 epoch 22 - iter 12/33 - loss 0.11945337 - samples/sec: 62.01 - lr: 0.025000
2021-05-27 13:36:00,013 epoch 22 - iter 15/33 - loss 0.15458824 - samples/sec: 62.07 - lr: 0.025000
2021-05-27 13:36:01,549 epoch 22 - iter 18/33 - loss 0.16377005 - samples/sec: 62.50 - lr: 0.025000
2021-05-27 13:36:03,102 epoch 22 - iter 21/33 - loss 0.16074116 - samples/sec: 61.85 - lr: 0.025000
2021-05-27 13:36:04,624 epoch 22 - iter 24/33 - loss 0.16461913 - samples/sec: 63.07 - lr: 0.025000
2021-05-27 13:36:06,144 epoch 22 - iter 27/33 - loss 0.16450001 - samples/sec: 63.21 - lr: 0.025000
2021-05-27 13:36:07,705 epoch 22 - iter 30/33 - loss 0.18322805 - samples/sec: 61.51 - lr: 0.025000
2021-05-27 13:36:09,072 epoch 22 - iter 33/33 - loss 0.18269772 - samples/sec: 70.23 - lr: 0.025000
2021-05-27 13:36:09,073 ----------------------------------------------------------------------------------------------------
2021-05-27 13:36:09,073 EPOCH 22 done: loss 0.1827 - lr 0.0250000
2021-05-27 13:36:11,226 DEV : loss 0.28669893741607666 - score 0.9438
2021-05-27 13:36:11,262 BAD EPOCHS (no improvement): 1
2021-05-27 13:36:11,262 ----------------------------------------------------------------------------------------------------
2021-05-27 13:36:12,799 epoch 23 - iter 3/33 - loss 0.14933145 - samples/sec: 62.50 - lr: 0.025000
2021-05-27 13:36:14,327 epoch 23 - iter 6/33 - loss 0.15686554 - samples/sec: 62.85 - lr: 0.025000
2021-05-27 13:36:15,853 epoch 23 - iter 9/33 - loss 0.14845720 - samples/sec: 62.91 - lr: 0.025000
2021-05-27 13:36:17,395 epoch 23 - iter 12/33 - loss 0.15935091 - samples/sec: 62.26 - lr: 0.025000
2021-05-27 13:36:18,893 epoch 23 - iter 15/33 - loss 0.15433016 - samples/sec: 64.11 - lr: 0.025000
2021-05-27 13:36:20,415 epoch 23 - iter 18/33 - loss 0.16678936 - samples/sec: 63.11 - lr: 0.025000
2021-05-27 13:36:21,933 epoch 23 - iter 21/33 - loss 0.17737660 - samples/sec: 63.27 - lr: 0.025000
2021-05-27 13:36:23,473 epoch 23 - iter 24/33 - loss 0.19359936 - samples/sec: 62.35 - lr: 0.025000
2021-05-27 13:36:24,998 epoch 23 - iter 27/33 - loss 0.19455307 - samples/sec: 62.99 - lr: 0.025000
2021-05-27 13:36:26,537 epoch 23 - iter 30/33 - loss 0.19677501 - samples/sec: 62.38 - lr: 0.025000
2021-05-27 13:36:27,931 epoch 23 - iter 33/33 - loss 0.18929032 - samples/sec: 68.89 - lr: 0.025000
2021-05-27 13:36:27,931 ----------------------------------------------------------------------------------------------------
2021-05-27 13:36:27,931 EPOCH 23 done: loss 0.1893 - lr 0.0250000
2021-05-27 13:36:30,085 DEV : loss 0.33403587341308594 - score 0.9417
2021-05-27 13:36:30,120 BAD EPOCHS (no improvement): 2
2021-05-27 13:36:30,121 ----------------------------------------------------------------------------------------------------
2021-05-27 13:36:31,653 epoch 24 - iter 3/33 - loss 0.21170227 - samples/sec: 62.69 - lr: 0.025000
2021-05-27 13:36:33,181 epoch 24 - iter 6/33 - loss 0.19170068 - samples/sec: 62.86 - lr: 0.025000
2021-05-27 13:36:34,735 epoch 24 - iter 9/33 - loss 0.21289077 - samples/sec: 61.76 - lr: 0.025000
2021-05-27 13:36:36,270 epoch 24 - iter 12/33 - loss 0.19635622 - samples/sec: 62.58 - lr: 0.025000
2021-05-27 13:36:37,748 epoch 24 - iter 15/33 - loss 0.17804819 - samples/sec: 64.97 - lr: 0.025000
2021-05-27 13:36:39,303 epoch 24 - iter 18/33 - loss 0.16916133 - samples/sec: 61.75 - lr: 0.025000
2021-05-27 13:36:40,833 epoch 24 - iter 21/33 - loss 0.16713252 - samples/sec: 62.76 - lr: 0.025000
2021-05-27 13:36:42,366 epoch 24 - iter 24/33 - loss 0.17285155 - samples/sec: 62.67 - lr: 0.025000
2021-05-27 13:36:43,897 epoch 24 - iter 27/33 - loss 0.17002689 - samples/sec: 62.72 - lr: 0.025000
2021-05-27 13:36:45,417 epoch 24 - iter 30/33 - loss 0.16780179 - samples/sec: 63.17 - lr: 0.025000
2021-05-27 13:36:46,811 epoch 24 - iter 33/33 - loss 0.16640659 - samples/sec: 68.92 - lr: 0.025000
2021-05-27 13:36:46,811 ----------------------------------------------------------------------------------------------------
2021-05-27 13:36:46,811 EPOCH 24 done: loss 0.1664 - lr 0.0250000
2021-05-27 13:36:49,134 DEV : loss 0.27056601643562317 - score 0.9481
2021-05-27 13:36:49,170 BAD EPOCHS (no improvement): 3
2021-05-27 13:36:49,170 ----------------------------------------------------------------------------------------------------
2021-05-27 13:36:50,656 epoch 25 - iter 3/33 - loss 0.07447896 - samples/sec: 64.66 - lr: 0.025000
2021-05-27 13:36:52,198 epoch 25 - iter 6/33 - loss 0.08853564 - samples/sec: 62.27 - lr: 0.025000
2021-05-27 13:36:53,744 epoch 25 - iter 9/33 - loss 0.12968023 - samples/sec: 62.09 - lr: 0.025000
2021-05-27 13:36:55,293 epoch 25 - iter 12/33 - loss 0.13272800 - samples/sec: 61.99 - lr: 0.025000
2021-05-27 13:36:56,837 epoch 25 - iter 15/33 - loss 0.13824168 - samples/sec: 62.23 - lr: 0.025000
2021-05-27 13:36:58,348 epoch 25 - iter 18/33 - loss 0.13955654 - samples/sec: 63.52 - lr: 0.025000
2021-05-27 13:36:59,858 epoch 25 - iter 21/33 - loss 0.13341781 - samples/sec: 63.61 - lr: 0.025000
2021-05-27 13:37:01,385 epoch 25 - iter 24/33 - loss 0.12947876 - samples/sec: 62.91 - lr: 0.025000
2021-05-27 13:37:02,919 epoch 25 - iter 27/33 - loss 0.14068514 - samples/sec: 62.59 - lr: 0.025000
2021-05-27 13:37:04,460 epoch 25 - iter 30/33 - loss 0.15014322 - samples/sec: 62.32 - lr: 0.025000
2021-05-27 13:37:05,854 epoch 25 - iter 33/33 - loss 0.15416089 - samples/sec: 68.90 - lr: 0.025000
2021-05-27 13:37:05,854 ----------------------------------------------------------------------------------------------------
2021-05-27 13:37:05,854 EPOCH 25 done: loss 0.1542 - lr 0.0250000
2021-05-27 13:37:08,010 DEV : loss 0.35275745391845703 - score 0.9429
Epoch    25: reducing learning rate of group 0 to 1.2500e-02.
2021-05-27 13:37:08,046 BAD EPOCHS (no improvement): 4
2021-05-27 13:37:08,046 ----------------------------------------------------------------------------------------------------
2021-05-27 13:37:09,599 epoch 26 - iter 3/33 - loss 0.20544044 - samples/sec: 61.83 - lr: 0.012500
2021-05-27 13:37:11,125 epoch 26 - iter 6/33 - loss 0.21025244 - samples/sec: 62.95 - lr: 0.012500
2021-05-27 13:37:12,642 epoch 26 - iter 9/33 - loss 0.19959686 - samples/sec: 63.30 - lr: 0.012500
2021-05-27 13:37:14,170 epoch 26 - iter 12/33 - loss 0.20715077 - samples/sec: 62.82 - lr: 0.012500
2021-05-27 13:37:15,660 epoch 26 - iter 15/33 - loss 0.19159523 - samples/sec: 64.48 - lr: 0.012500
2021-05-27 13:37:17,200 epoch 26 - iter 18/33 - loss 0.17614189 - samples/sec: 62.34 - lr: 0.012500
2021-05-27 13:37:18,739 epoch 26 - iter 21/33 - loss 0.17412298 - samples/sec: 62.41 - lr: 0.012500
2021-05-27 13:37:20,267 epoch 26 - iter 24/33 - loss 0.17491568 - samples/sec: 62.82 - lr: 0.012500
2021-05-27 13:37:21,783 epoch 26 - iter 27/33 - loss 0.16180333 - samples/sec: 63.36 - lr: 0.012500
2021-05-27 13:37:23,325 epoch 26 - iter 30/33 - loss 0.15891189 - samples/sec: 62.29 - lr: 0.012500
2021-05-27 13:37:24,729 epoch 26 - iter 33/33 - loss 0.14846045 - samples/sec: 68.40 - lr: 0.012500
2021-05-27 13:37:24,729 ----------------------------------------------------------------------------------------------------
2021-05-27 13:37:24,729 EPOCH 26 done: loss 0.1485 - lr 0.0125000
2021-05-27 13:37:26,881 DEV : loss 0.2833605408668518 - score 0.9491
2021-05-27 13:37:26,916 BAD EPOCHS (no improvement): 1
2021-05-27 13:37:26,917 ----------------------------------------------------------------------------------------------------
2021-05-27 13:37:28,436 epoch 27 - iter 3/33 - loss 0.12188735 - samples/sec: 63.23 - lr: 0.012500
2021-05-27 13:37:29,993 epoch 27 - iter 6/33 - loss 0.14980132 - samples/sec: 61.67 - lr: 0.012500
2021-05-27 13:37:31,527 epoch 27 - iter 9/33 - loss 0.14475077 - samples/sec: 62.58 - lr: 0.012500
2021-05-27 13:37:33,033 epoch 27 - iter 12/33 - loss 0.12463056 - samples/sec: 63.78 - lr: 0.012500
2021-05-27 13:37:34,585 epoch 27 - iter 15/33 - loss 0.13071945 - samples/sec: 61.87 - lr: 0.012500
2021-05-27 13:37:36,105 epoch 27 - iter 18/33 - loss 0.14064498 - samples/sec: 63.17 - lr: 0.012500
2021-05-27 13:37:37,645 epoch 27 - iter 21/33 - loss 0.14184400 - samples/sec: 62.36 - lr: 0.012500
2021-05-27 13:37:39,159 epoch 27 - iter 24/33 - loss 0.13813366 - samples/sec: 63.42 - lr: 0.012500
2021-05-27 13:37:40,673 epoch 27 - iter 27/33 - loss 0.13618760 - samples/sec: 63.42 - lr: 0.012500
2021-05-27 13:37:42,215 epoch 27 - iter 30/33 - loss 0.13355639 - samples/sec: 62.30 - lr: 0.012500
2021-05-27 13:37:43,614 epoch 27 - iter 33/33 - loss 0.14218789 - samples/sec: 68.67 - lr: 0.012500
2021-05-27 13:37:43,614 ----------------------------------------------------------------------------------------------------
2021-05-27 13:37:43,614 EPOCH 27 done: loss 0.1422 - lr 0.0125000
2021-05-27 13:37:45,937 DEV : loss 0.32073506712913513 - score 0.9455
2021-05-27 13:37:45,972 BAD EPOCHS (no improvement): 2
2021-05-27 13:37:45,972 ----------------------------------------------------------------------------------------------------
2021-05-27 13:37:47,532 epoch 28 - iter 3/33 - loss 0.19443305 - samples/sec: 61.56 - lr: 0.012500
2021-05-27 13:37:49,077 epoch 28 - iter 6/33 - loss 0.14613775 - samples/sec: 62.15 - lr: 0.012500
2021-05-27 13:37:50,632 epoch 28 - iter 9/33 - loss 0.14268017 - samples/sec: 61.78 - lr: 0.012500
2021-05-27 13:37:52,125 epoch 28 - iter 12/33 - loss 0.14477475 - samples/sec: 64.29 - lr: 0.012500
2021-05-27 13:37:53,656 epoch 28 - iter 15/33 - loss 0.13822414 - samples/sec: 62.75 - lr: 0.012500
2021-05-27 13:37:55,189 epoch 28 - iter 18/33 - loss 0.13952615 - samples/sec: 62.63 - lr: 0.012500
2021-05-27 13:37:56,707 epoch 28 - iter 21/33 - loss 0.14240789 - samples/sec: 63.27 - lr: 0.012500
2021-05-27 13:37:58,223 epoch 28 - iter 24/33 - loss 0.14877727 - samples/sec: 63.33 - lr: 0.012500
2021-05-27 13:37:59,747 epoch 28 - iter 27/33 - loss 0.14780182 - samples/sec: 63.01 - lr: 0.012500
2021-05-27 13:38:01,280 epoch 28 - iter 30/33 - loss 0.14325269 - samples/sec: 62.66 - lr: 0.012500
2021-05-27 13:38:02,665 epoch 28 - iter 33/33 - loss 0.14026503 - samples/sec: 69.34 - lr: 0.012500
2021-05-27 13:38:02,665 ----------------------------------------------------------------------------------------------------
2021-05-27 13:38:02,665 EPOCH 28 done: loss 0.1403 - lr 0.0125000
2021-05-27 13:38:04,821 DEV : loss 0.40674564242362976 - score 0.9405
2021-05-27 13:38:04,856 BAD EPOCHS (no improvement): 3
2021-05-27 13:38:04,857 ----------------------------------------------------------------------------------------------------
2021-05-27 13:38:06,381 epoch 29 - iter 3/33 - loss 0.13367196 - samples/sec: 62.98 - lr: 0.012500
2021-05-27 13:38:07,921 epoch 29 - iter 6/33 - loss 0.12940807 - samples/sec: 62.40 - lr: 0.012500
2021-05-27 13:38:09,429 epoch 29 - iter 9/33 - loss 0.12215109 - samples/sec: 63.66 - lr: 0.012500
2021-05-27 13:38:10,949 epoch 29 - iter 12/33 - loss 0.12391601 - samples/sec: 63.20 - lr: 0.012500
2021-05-27 13:38:12,470 epoch 29 - iter 15/33 - loss 0.11320171 - samples/sec: 63.14 - lr: 0.012500
2021-05-27 13:38:14,029 epoch 29 - iter 18/33 - loss 0.11453903 - samples/sec: 61.60 - lr: 0.012500
2021-05-27 13:38:15,576 epoch 29 - iter 21/33 - loss 0.12497104 - samples/sec: 62.07 - lr: 0.012500
2021-05-27 13:38:17,085 epoch 29 - iter 24/33 - loss 0.12332128 - samples/sec: 63.64 - lr: 0.012500
2021-05-27 13:38:18,617 epoch 29 - iter 27/33 - loss 0.13648970 - samples/sec: 62.69 - lr: 0.012500
2021-05-27 13:38:20,159 epoch 29 - iter 30/33 - loss 0.13159433 - samples/sec: 62.27 - lr: 0.012500
2021-05-27 13:38:21,538 epoch 29 - iter 33/33 - loss 0.12787429 - samples/sec: 69.67 - lr: 0.012500
2021-05-27 13:38:21,538 ----------------------------------------------------------------------------------------------------
2021-05-27 13:38:21,538 EPOCH 29 done: loss 0.1279 - lr 0.0125000
2021-05-27 13:38:23,693 DEV : loss 0.34616315364837646 - score 0.9429
Epoch    29: reducing learning rate of group 0 to 6.2500e-03.
2021-05-27 13:38:23,729 BAD EPOCHS (no improvement): 4
2021-05-27 13:38:23,729 ----------------------------------------------------------------------------------------------------
2021-05-27 13:38:25,245 epoch 30 - iter 3/33 - loss 0.12722230 - samples/sec: 63.33 - lr: 0.006250
2021-05-27 13:38:26,759 epoch 30 - iter 6/33 - loss 0.23276224 - samples/sec: 63.42 - lr: 0.006250
2021-05-27 13:38:28,240 epoch 30 - iter 9/33 - loss 0.18247488 - samples/sec: 64.87 - lr: 0.006250
2021-05-27 13:38:29,787 epoch 30 - iter 12/33 - loss 0.18153734 - samples/sec: 62.05 - lr: 0.006250
2021-05-27 13:38:31,320 epoch 30 - iter 15/33 - loss 0.17374585 - samples/sec: 62.65 - lr: 0.006250
2021-05-27 13:38:32,881 epoch 30 - iter 18/33 - loss 0.15704634 - samples/sec: 61.54 - lr: 0.006250
2021-05-27 13:38:34,402 epoch 30 - iter 21/33 - loss 0.14827321 - samples/sec: 63.12 - lr: 0.006250
2021-05-27 13:38:35,972 epoch 30 - iter 24/33 - loss 0.14707421 - samples/sec: 61.17 - lr: 0.006250
2021-05-27 13:38:37,518 epoch 30 - iter 27/33 - loss 0.13957933 - samples/sec: 62.12 - lr: 0.006250
2021-05-27 13:38:39,215 epoch 30 - iter 30/33 - loss 0.14533140 - samples/sec: 56.59 - lr: 0.006250
2021-05-27 13:38:40,606 epoch 30 - iter 33/33 - loss 0.14341164 - samples/sec: 69.04 - lr: 0.006250
2021-05-27 13:38:40,606 ----------------------------------------------------------------------------------------------------
2021-05-27 13:38:40,606 EPOCH 30 done: loss 0.1434 - lr 0.0062500
2021-05-27 13:38:42,762 DEV : loss 0.34799203276634216 - score 0.9415
2021-05-27 13:38:42,797 BAD EPOCHS (no improvement): 1
2021-05-27 13:38:43,751 ----------------------------------------------------------------------------------------------------
2021-05-27 13:38:43,751 Testing using best model ...
2021-05-27 13:38:43,751 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eus.rst.ert/best-model.pt
2021-05-27 13:38:53,367 0.9096	0.9750	0.9412
2021-05-27 13:38:53,367 
Results:
- F1-score (micro) 0.9412
- F1-score (macro) 0.9412

By class:
SENT       tp: 312 - fp: 31 - fn: 8 - precision: 0.9096 - recall: 0.9750 - f1-score: 0.9412
2021-05-27 13:38:53,367 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/
2021-05-27 13:38:53,394 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb
2021-05-27 13:38:53,394 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/sent_train.txt
2021-05-27 13:38:53,396 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/sent_dev.txt
2021-05-27 13:38:53,398 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/sent_test.txt
Corpus: 51481 train + 1929 dev + 2695 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 13:39:18,751 ----------------------------------------------------------------------------------------------------
2021-05-27 13:39:18,754 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 13:39:18,754 ----------------------------------------------------------------------------------------------------
2021-05-27 13:39:18,754 Corpus: "Corpus: 51481 train + 1929 dev + 2695 test sentences"
2021-05-27 13:39:18,754 ----------------------------------------------------------------------------------------------------
2021-05-27 13:39:18,754 Parameters:
2021-05-27 13:39:18,754  - learning_rate: "0.1"
2021-05-27 13:39:18,754  - mini_batch_size: "32"
2021-05-27 13:39:18,754  - patience: "3"
2021-05-27 13:39:18,754  - anneal_factor: "0.5"
2021-05-27 13:39:18,754  - max_epochs: "30"
2021-05-27 13:39:18,754  - shuffle: "True"
2021-05-27 13:39:18,754  - train_with_dev: "False"
2021-05-27 13:39:18,754  - batch_growth_annealing: "False"
2021-05-27 13:39:18,754 ----------------------------------------------------------------------------------------------------
2021-05-27 13:39:18,754 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb"
2021-05-27 13:39:18,754 ----------------------------------------------------------------------------------------------------
2021-05-27 13:39:18,754 Device: cuda:0
2021-05-27 13:39:18,754 ----------------------------------------------------------------------------------------------------
2021-05-27 13:39:18,754 Embeddings storage mode: cpu
2021-05-27 13:39:18,755 ----------------------------------------------------------------------------------------------------
2021-05-27 13:42:42,598 epoch 1 - iter 160/1609 - loss 2.41997600 - samples/sec: 25.12 - lr: 0.100000
2021-05-27 13:45:59,628 epoch 1 - iter 320/1609 - loss 1.66893119 - samples/sec: 25.99 - lr: 0.100000
2021-05-27 13:49:17,021 epoch 1 - iter 480/1609 - loss 1.32873501 - samples/sec: 25.94 - lr: 0.100000
2021-05-27 13:52:34,789 epoch 1 - iter 640/1609 - loss 1.14638264 - samples/sec: 25.89 - lr: 0.100000
2021-05-27 13:55:55,152 epoch 1 - iter 800/1609 - loss 1.03225135 - samples/sec: 25.55 - lr: 0.100000
2021-05-27 13:59:13,084 epoch 1 - iter 960/1609 - loss 0.94918244 - samples/sec: 25.87 - lr: 0.100000
2021-05-27 14:02:31,237 epoch 1 - iter 1120/1609 - loss 0.88211282 - samples/sec: 25.84 - lr: 0.100000
2021-05-27 14:05:49,675 epoch 1 - iter 1280/1609 - loss 0.84365600 - samples/sec: 25.80 - lr: 0.100000
2021-05-27 14:09:08,150 epoch 1 - iter 1440/1609 - loss 0.80441203 - samples/sec: 25.80 - lr: 0.100000
2021-05-27 14:12:26,617 epoch 1 - iter 1600/1609 - loss 0.77619557 - samples/sec: 25.80 - lr: 0.100000
2021-05-27 14:12:37,520 ----------------------------------------------------------------------------------------------------
2021-05-27 14:12:37,520 EPOCH 1 done: loss 0.7757 - lr 0.1000000
2021-05-27 14:13:31,969 DEV : loss 0.2681247889995575 - score 0.9448
2021-05-27 14:13:32,148 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 14:13:33,119 ----------------------------------------------------------------------------------------------------
2021-05-27 14:14:53,236 epoch 2 - iter 160/1609 - loss 0.44227391 - samples/sec: 63.91 - lr: 0.100000
2021-05-27 14:16:13,040 epoch 2 - iter 320/1609 - loss 0.41926086 - samples/sec: 64.16 - lr: 0.100000
2021-05-27 14:17:32,762 epoch 2 - iter 480/1609 - loss 0.43231836 - samples/sec: 64.23 - lr: 0.100000
2021-05-27 14:18:52,669 epoch 2 - iter 640/1609 - loss 0.43098686 - samples/sec: 64.08 - lr: 0.100000
2021-05-27 14:20:12,728 epoch 2 - iter 800/1609 - loss 0.42959791 - samples/sec: 63.96 - lr: 0.100000
2021-05-27 14:21:32,556 epoch 2 - iter 960/1609 - loss 0.42413296 - samples/sec: 64.14 - lr: 0.100000
2021-05-27 14:22:52,858 epoch 2 - iter 1120/1609 - loss 0.42140061 - samples/sec: 63.77 - lr: 0.100000
2021-05-27 14:24:12,793 epoch 2 - iter 1280/1609 - loss 0.41871886 - samples/sec: 64.06 - lr: 0.100000
2021-05-27 14:25:32,539 epoch 2 - iter 1440/1609 - loss 0.41568265 - samples/sec: 64.21 - lr: 0.100000
2021-05-27 14:26:52,116 epoch 2 - iter 1600/1609 - loss 0.41367813 - samples/sec: 64.35 - lr: 0.100000
2021-05-27 14:26:56,464 ----------------------------------------------------------------------------------------------------
2021-05-27 14:26:56,465 EPOCH 2 done: loss 0.4146 - lr 0.1000000
2021-05-27 14:27:07,342 DEV : loss 0.592901349067688 - score 0.8766
2021-05-27 14:27:07,522 BAD EPOCHS (no improvement): 1
2021-05-27 14:27:07,522 ----------------------------------------------------------------------------------------------------
2021-05-27 14:28:27,824 epoch 3 - iter 160/1609 - loss 0.39207091 - samples/sec: 63.77 - lr: 0.100000
2021-05-27 14:29:48,275 epoch 3 - iter 320/1609 - loss 0.38994944 - samples/sec: 63.65 - lr: 0.100000
2021-05-27 14:31:08,560 epoch 3 - iter 480/1609 - loss 0.37391367 - samples/sec: 63.78 - lr: 0.100000
2021-05-27 14:32:28,969 epoch 3 - iter 640/1609 - loss 0.37167300 - samples/sec: 63.68 - lr: 0.100000
2021-05-27 14:33:49,640 epoch 3 - iter 800/1609 - loss 0.37622893 - samples/sec: 63.47 - lr: 0.100000
2021-05-27 14:35:10,019 epoch 3 - iter 960/1609 - loss 0.38227918 - samples/sec: 63.71 - lr: 0.100000
2021-05-27 14:36:30,539 epoch 3 - iter 1120/1609 - loss 0.37647415 - samples/sec: 63.59 - lr: 0.100000
2021-05-27 14:37:50,860 epoch 3 - iter 1280/1609 - loss 0.37787710 - samples/sec: 63.75 - lr: 0.100000
2021-05-27 14:39:11,281 epoch 3 - iter 1440/1609 - loss 0.37636466 - samples/sec: 63.67 - lr: 0.100000
2021-05-27 14:40:31,544 epoch 3 - iter 1600/1609 - loss 0.37598921 - samples/sec: 63.80 - lr: 0.100000
2021-05-27 14:40:35,988 ----------------------------------------------------------------------------------------------------
2021-05-27 14:40:35,988 EPOCH 3 done: loss 0.3755 - lr 0.1000000
2021-05-27 14:40:46,935 DEV : loss 0.31263467669487 - score 0.934
2021-05-27 14:40:47,115 BAD EPOCHS (no improvement): 2
2021-05-27 14:40:47,115 ----------------------------------------------------------------------------------------------------
2021-05-27 14:42:07,928 epoch 4 - iter 160/1609 - loss 0.35840744 - samples/sec: 63.36 - lr: 0.100000
2021-05-27 14:43:28,834 epoch 4 - iter 320/1609 - loss 0.34309567 - samples/sec: 63.29 - lr: 0.100000
2021-05-27 14:44:49,655 epoch 4 - iter 480/1609 - loss 0.35293876 - samples/sec: 63.36 - lr: 0.100000
2021-05-27 14:46:10,456 epoch 4 - iter 640/1609 - loss 0.35203950 - samples/sec: 63.37 - lr: 0.100000
2021-05-27 14:47:31,274 epoch 4 - iter 800/1609 - loss 0.34771182 - samples/sec: 63.36 - lr: 0.100000
2021-05-27 14:48:52,055 epoch 4 - iter 960/1609 - loss 0.34507109 - samples/sec: 63.39 - lr: 0.100000
2021-05-27 14:50:12,923 epoch 4 - iter 1120/1609 - loss 0.34127123 - samples/sec: 63.32 - lr: 0.100000
2021-05-27 14:51:33,497 epoch 4 - iter 1280/1609 - loss 0.34322249 - samples/sec: 63.55 - lr: 0.100000
2021-05-27 14:52:54,028 epoch 4 - iter 1440/1609 - loss 0.34539573 - samples/sec: 63.58 - lr: 0.100000
2021-05-27 14:54:14,836 epoch 4 - iter 1600/1609 - loss 0.34084717 - samples/sec: 63.37 - lr: 0.100000
2021-05-27 14:54:19,266 ----------------------------------------------------------------------------------------------------
2021-05-27 14:54:19,266 EPOCH 4 done: loss 0.3403 - lr 0.1000000
2021-05-27 14:54:30,238 DEV : loss 0.23738472163677216 - score 0.9525
2021-05-27 14:54:30,419 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 14:54:39,128 ----------------------------------------------------------------------------------------------------
2021-05-27 14:56:00,179 epoch 5 - iter 160/1609 - loss 0.31716355 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 14:57:20,870 epoch 5 - iter 320/1609 - loss 0.31859038 - samples/sec: 63.46 - lr: 0.100000
2021-05-27 14:58:41,157 epoch 5 - iter 480/1609 - loss 0.32185091 - samples/sec: 63.78 - lr: 0.100000
2021-05-27 15:00:01,609 epoch 5 - iter 640/1609 - loss 0.32113151 - samples/sec: 63.65 - lr: 0.100000
2021-05-27 15:01:22,258 epoch 5 - iter 800/1609 - loss 0.31822998 - samples/sec: 63.49 - lr: 0.100000
2021-05-27 15:02:42,887 epoch 5 - iter 960/1609 - loss 0.32218097 - samples/sec: 63.51 - lr: 0.100000
2021-05-27 15:04:03,833 epoch 5 - iter 1120/1609 - loss 0.32329279 - samples/sec: 63.26 - lr: 0.100000
2021-05-27 15:05:24,849 epoch 5 - iter 1280/1609 - loss 0.32461716 - samples/sec: 63.20 - lr: 0.100000
2021-05-27 15:06:46,092 epoch 5 - iter 1440/1609 - loss 0.32240377 - samples/sec: 63.03 - lr: 0.100000
2021-05-27 15:08:06,981 epoch 5 - iter 1600/1609 - loss 0.32177929 - samples/sec: 63.30 - lr: 0.100000
2021-05-27 15:08:11,460 ----------------------------------------------------------------------------------------------------
2021-05-27 15:08:11,460 EPOCH 5 done: loss 0.3218 - lr 0.1000000
2021-05-27 15:08:22,463 DEV : loss 0.2376498281955719 - score 0.9505
2021-05-27 15:08:22,643 BAD EPOCHS (no improvement): 1
2021-05-27 15:08:22,644 ----------------------------------------------------------------------------------------------------
2021-05-27 15:09:46,473 epoch 6 - iter 160/1609 - loss 0.28989794 - samples/sec: 61.08 - lr: 0.100000
2021-05-27 15:11:07,320 epoch 6 - iter 320/1609 - loss 0.29804100 - samples/sec: 63.34 - lr: 0.100000
2021-05-27 15:12:27,988 epoch 6 - iter 480/1609 - loss 0.29698001 - samples/sec: 63.48 - lr: 0.100000
2021-05-27 15:13:48,746 epoch 6 - iter 640/1609 - loss 0.29471856 - samples/sec: 63.41 - lr: 0.100000
2021-05-27 15:15:09,749 epoch 6 - iter 800/1609 - loss 0.29553825 - samples/sec: 63.21 - lr: 0.100000
2021-05-27 15:16:30,771 epoch 6 - iter 960/1609 - loss 0.29787396 - samples/sec: 63.20 - lr: 0.100000
2021-05-27 15:17:52,014 epoch 6 - iter 1120/1609 - loss 0.29684390 - samples/sec: 63.03 - lr: 0.100000
2021-05-27 15:19:13,083 epoch 6 - iter 1280/1609 - loss 0.29902604 - samples/sec: 63.16 - lr: 0.100000
2021-05-27 15:20:34,014 epoch 6 - iter 1440/1609 - loss 0.29769818 - samples/sec: 63.27 - lr: 0.100000
2021-05-27 15:21:55,095 epoch 6 - iter 1600/1609 - loss 0.29852312 - samples/sec: 63.15 - lr: 0.100000
2021-05-27 15:21:59,553 ----------------------------------------------------------------------------------------------------
2021-05-27 15:21:59,553 EPOCH 6 done: loss 0.2987 - lr 0.1000000
2021-05-27 15:22:10,547 DEV : loss 0.2864784300327301 - score 0.9325
2021-05-27 15:22:10,728 BAD EPOCHS (no improvement): 2
2021-05-27 15:22:10,728 ----------------------------------------------------------------------------------------------------
2021-05-27 15:23:31,937 epoch 7 - iter 160/1609 - loss 0.30328855 - samples/sec: 63.06 - lr: 0.100000
2021-05-27 15:24:53,148 epoch 7 - iter 320/1609 - loss 0.30133716 - samples/sec: 63.05 - lr: 0.100000
2021-05-27 15:26:14,194 epoch 7 - iter 480/1609 - loss 0.28712566 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 15:27:34,866 epoch 7 - iter 640/1609 - loss 0.28551748 - samples/sec: 63.47 - lr: 0.100000
2021-05-27 15:28:55,259 epoch 7 - iter 800/1609 - loss 0.29001006 - samples/sec: 63.69 - lr: 0.100000
2021-05-27 15:30:16,227 epoch 7 - iter 960/1609 - loss 0.28869924 - samples/sec: 63.24 - lr: 0.100000
2021-05-27 15:31:36,838 epoch 7 - iter 1120/1609 - loss 0.28935968 - samples/sec: 63.52 - lr: 0.100000
2021-05-27 15:32:57,428 epoch 7 - iter 1280/1609 - loss 0.28986986 - samples/sec: 63.54 - lr: 0.100000
2021-05-27 15:34:18,132 epoch 7 - iter 1440/1609 - loss 0.28822933 - samples/sec: 63.45 - lr: 0.100000
2021-05-27 15:35:39,007 epoch 7 - iter 1600/1609 - loss 0.28572342 - samples/sec: 63.31 - lr: 0.100000
2021-05-27 15:35:43,494 ----------------------------------------------------------------------------------------------------
2021-05-27 15:35:43,494 EPOCH 7 done: loss 0.2867 - lr 0.1000000
2021-05-27 15:35:54,493 DEV : loss 0.2140078991651535 - score 0.9553
2021-05-27 15:35:54,675 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 15:36:03,505 ----------------------------------------------------------------------------------------------------
2021-05-27 15:37:24,720 epoch 8 - iter 160/1609 - loss 0.26187555 - samples/sec: 63.05 - lr: 0.100000
2021-05-27 15:38:45,768 epoch 8 - iter 320/1609 - loss 0.26345862 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 15:40:07,141 epoch 8 - iter 480/1609 - loss 0.26679269 - samples/sec: 62.93 - lr: 0.100000
2021-05-27 15:41:28,258 epoch 8 - iter 640/1609 - loss 0.26657479 - samples/sec: 63.12 - lr: 0.100000
2021-05-27 15:42:49,163 epoch 8 - iter 800/1609 - loss 0.27462778 - samples/sec: 63.29 - lr: 0.100000
2021-05-27 15:44:10,206 epoch 8 - iter 960/1609 - loss 0.27076343 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 15:45:31,247 epoch 8 - iter 1120/1609 - loss 0.27245398 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 15:46:52,372 epoch 8 - iter 1280/1609 - loss 0.27098038 - samples/sec: 63.12 - lr: 0.100000
2021-05-27 15:48:13,468 epoch 8 - iter 1440/1609 - loss 0.26731641 - samples/sec: 63.14 - lr: 0.100000
2021-05-27 15:49:34,578 epoch 8 - iter 1600/1609 - loss 0.26707556 - samples/sec: 63.13 - lr: 0.100000
2021-05-27 15:49:39,002 ----------------------------------------------------------------------------------------------------
2021-05-27 15:49:39,003 EPOCH 8 done: loss 0.2664 - lr 0.1000000
2021-05-27 15:49:50,015 DEV : loss 0.22229830920696259 - score 0.9508
2021-05-27 15:49:50,197 BAD EPOCHS (no improvement): 1
2021-05-27 15:49:50,198 ----------------------------------------------------------------------------------------------------
2021-05-27 15:51:11,016 epoch 9 - iter 160/1609 - loss 0.24349507 - samples/sec: 63.36 - lr: 0.100000
2021-05-27 15:52:31,996 epoch 9 - iter 320/1609 - loss 0.24257294 - samples/sec: 63.23 - lr: 0.100000
2021-05-27 15:53:52,988 epoch 9 - iter 480/1609 - loss 0.24847293 - samples/sec: 63.22 - lr: 0.100000
2021-05-27 15:55:17,324 epoch 9 - iter 640/1609 - loss 0.25021830 - samples/sec: 60.72 - lr: 0.100000
2021-05-27 15:56:38,417 epoch 9 - iter 800/1609 - loss 0.24507854 - samples/sec: 63.14 - lr: 0.100000
2021-05-27 15:57:59,287 epoch 9 - iter 960/1609 - loss 0.24654007 - samples/sec: 63.32 - lr: 0.100000
2021-05-27 15:59:20,268 epoch 9 - iter 1120/1609 - loss 0.24938481 - samples/sec: 63.23 - lr: 0.100000
2021-05-27 16:00:41,462 epoch 9 - iter 1280/1609 - loss 0.25233163 - samples/sec: 63.07 - lr: 0.100000
2021-05-27 16:02:02,098 epoch 9 - iter 1440/1609 - loss 0.25482790 - samples/sec: 63.50 - lr: 0.100000
2021-05-27 16:03:22,614 epoch 9 - iter 1600/1609 - loss 0.25461264 - samples/sec: 63.60 - lr: 0.100000
2021-05-27 16:03:27,050 ----------------------------------------------------------------------------------------------------
2021-05-27 16:03:27,050 EPOCH 9 done: loss 0.2542 - lr 0.1000000
2021-05-27 16:03:38,050 DEV : loss 0.19388583302497864 - score 0.9574
2021-05-27 16:03:38,234 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 16:03:47,237 ----------------------------------------------------------------------------------------------------
2021-05-27 16:05:07,933 epoch 10 - iter 160/1609 - loss 0.26613963 - samples/sec: 63.46 - lr: 0.100000
2021-05-27 16:06:28,913 epoch 10 - iter 320/1609 - loss 0.25403559 - samples/sec: 63.23 - lr: 0.100000
2021-05-27 16:07:49,949 epoch 10 - iter 480/1609 - loss 0.25180650 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 16:09:10,896 epoch 10 - iter 640/1609 - loss 0.25351388 - samples/sec: 63.26 - lr: 0.100000
2021-05-27 16:10:32,113 epoch 10 - iter 800/1609 - loss 0.25311534 - samples/sec: 63.05 - lr: 0.100000
2021-05-27 16:11:52,751 epoch 10 - iter 960/1609 - loss 0.24999075 - samples/sec: 63.50 - lr: 0.100000
2021-05-27 16:13:13,193 epoch 10 - iter 1120/1609 - loss 0.25222050 - samples/sec: 63.65 - lr: 0.100000
2021-05-27 16:14:33,858 epoch 10 - iter 1280/1609 - loss 0.25172931 - samples/sec: 63.48 - lr: 0.100000
2021-05-27 16:15:54,784 epoch 10 - iter 1440/1609 - loss 0.24935477 - samples/sec: 63.27 - lr: 0.100000
2021-05-27 16:17:15,556 epoch 10 - iter 1600/1609 - loss 0.24891038 - samples/sec: 63.39 - lr: 0.100000
2021-05-27 16:17:20,005 ----------------------------------------------------------------------------------------------------
2021-05-27 16:17:20,006 EPOCH 10 done: loss 0.2487 - lr 0.1000000
2021-05-27 16:17:31,015 DEV : loss 0.1836956888437271 - score 0.9571
2021-05-27 16:17:31,198 BAD EPOCHS (no improvement): 1
2021-05-27 16:17:31,199 ----------------------------------------------------------------------------------------------------
2021-05-27 16:18:52,338 epoch 11 - iter 160/1609 - loss 0.24731739 - samples/sec: 63.11 - lr: 0.100000
2021-05-27 16:20:13,109 epoch 11 - iter 320/1609 - loss 0.25443389 - samples/sec: 63.40 - lr: 0.100000
2021-05-27 16:21:33,981 epoch 11 - iter 480/1609 - loss 0.24869690 - samples/sec: 63.32 - lr: 0.100000
2021-05-27 16:22:54,473 epoch 11 - iter 640/1609 - loss 0.24791658 - samples/sec: 63.62 - lr: 0.100000
2021-05-27 16:24:15,119 epoch 11 - iter 800/1609 - loss 0.25056014 - samples/sec: 63.49 - lr: 0.100000
2021-05-27 16:25:35,791 epoch 11 - iter 960/1609 - loss 0.25210229 - samples/sec: 63.47 - lr: 0.100000
2021-05-27 16:26:56,549 epoch 11 - iter 1120/1609 - loss 0.25219448 - samples/sec: 63.41 - lr: 0.100000
2021-05-27 16:28:17,178 epoch 11 - iter 1280/1609 - loss 0.25138993 - samples/sec: 63.51 - lr: 0.100000
2021-05-27 16:29:37,923 epoch 11 - iter 1440/1609 - loss 0.25115737 - samples/sec: 63.42 - lr: 0.100000
2021-05-27 16:30:58,601 epoch 11 - iter 1600/1609 - loss 0.25001721 - samples/sec: 63.47 - lr: 0.100000
2021-05-27 16:31:03,037 ----------------------------------------------------------------------------------------------------
2021-05-27 16:31:03,038 EPOCH 11 done: loss 0.2503 - lr 0.1000000
2021-05-27 16:31:14,064 DEV : loss 0.18257252871990204 - score 0.9573
2021-05-27 16:31:14,246 BAD EPOCHS (no improvement): 2
2021-05-27 16:31:14,246 ----------------------------------------------------------------------------------------------------
2021-05-27 16:32:34,883 epoch 12 - iter 160/1609 - loss 0.24156353 - samples/sec: 63.50 - lr: 0.100000
2021-05-27 16:33:55,441 epoch 12 - iter 320/1609 - loss 0.24908393 - samples/sec: 63.56 - lr: 0.100000
2021-05-27 16:35:16,189 epoch 12 - iter 480/1609 - loss 0.24630522 - samples/sec: 63.41 - lr: 0.100000
2021-05-27 16:36:36,967 epoch 12 - iter 640/1609 - loss 0.24086217 - samples/sec: 63.39 - lr: 0.100000
2021-05-27 16:37:57,638 epoch 12 - iter 800/1609 - loss 0.24115202 - samples/sec: 63.47 - lr: 0.100000
2021-05-27 16:39:18,461 epoch 12 - iter 960/1609 - loss 0.23960930 - samples/sec: 63.35 - lr: 0.100000
2021-05-27 16:40:39,680 epoch 12 - iter 1120/1609 - loss 0.24239694 - samples/sec: 63.05 - lr: 0.100000
2021-05-27 16:42:00,733 epoch 12 - iter 1280/1609 - loss 0.24299404 - samples/sec: 63.17 - lr: 0.100000
2021-05-27 16:43:21,691 epoch 12 - iter 1440/1609 - loss 0.24490562 - samples/sec: 63.25 - lr: 0.100000
2021-05-27 16:44:42,649 epoch 12 - iter 1600/1609 - loss 0.24542280 - samples/sec: 63.25 - lr: 0.100000
2021-05-27 16:44:47,105 ----------------------------------------------------------------------------------------------------
2021-05-27 16:44:47,106 EPOCH 12 done: loss 0.2458 - lr 0.1000000
2021-05-27 16:44:58,163 DEV : loss 0.18502968549728394 - score 0.9591
2021-05-27 16:44:58,346 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 16:45:07,203 ----------------------------------------------------------------------------------------------------
2021-05-27 16:46:28,368 epoch 13 - iter 160/1609 - loss 0.23961384 - samples/sec: 63.09 - lr: 0.100000
2021-05-27 16:47:49,537 epoch 13 - iter 320/1609 - loss 0.23769123 - samples/sec: 63.08 - lr: 0.100000
2021-05-27 16:49:10,215 epoch 13 - iter 480/1609 - loss 0.24049801 - samples/sec: 63.47 - lr: 0.100000
2021-05-27 16:50:31,338 epoch 13 - iter 640/1609 - loss 0.24442739 - samples/sec: 63.12 - lr: 0.100000
2021-05-27 16:51:52,376 epoch 13 - iter 800/1609 - loss 0.24049719 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 16:53:13,659 epoch 13 - iter 960/1609 - loss 0.23981587 - samples/sec: 63.00 - lr: 0.100000
2021-05-27 16:54:34,762 epoch 13 - iter 1120/1609 - loss 0.23803050 - samples/sec: 63.14 - lr: 0.100000
2021-05-27 16:55:55,639 epoch 13 - iter 1280/1609 - loss 0.24003060 - samples/sec: 63.31 - lr: 0.100000
2021-05-27 16:57:16,648 epoch 13 - iter 1440/1609 - loss 0.23843683 - samples/sec: 63.21 - lr: 0.100000
2021-05-27 16:58:37,623 epoch 13 - iter 1600/1609 - loss 0.23898632 - samples/sec: 63.24 - lr: 0.100000
2021-05-27 16:58:42,076 ----------------------------------------------------------------------------------------------------
2021-05-27 16:58:42,077 EPOCH 13 done: loss 0.2391 - lr 0.1000000
2021-05-27 16:58:53,111 DEV : loss 0.22629116475582123 - score 0.9442
2021-05-27 16:58:53,293 BAD EPOCHS (no improvement): 1
2021-05-27 16:58:53,293 ----------------------------------------------------------------------------------------------------
2021-05-27 17:00:14,268 epoch 14 - iter 160/1609 - loss 0.23065426 - samples/sec: 63.24 - lr: 0.100000
2021-05-27 17:01:35,195 epoch 14 - iter 320/1609 - loss 0.22791090 - samples/sec: 63.27 - lr: 0.100000
2021-05-27 17:02:56,269 epoch 14 - iter 480/1609 - loss 0.22985731 - samples/sec: 63.16 - lr: 0.100000
2021-05-27 17:04:17,300 epoch 14 - iter 640/1609 - loss 0.23136860 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 17:05:38,609 epoch 14 - iter 800/1609 - loss 0.23204985 - samples/sec: 62.98 - lr: 0.100000
2021-05-27 17:06:59,558 epoch 14 - iter 960/1609 - loss 0.23323878 - samples/sec: 63.26 - lr: 0.100000
2021-05-27 17:08:20,703 epoch 14 - iter 1120/1609 - loss 0.23513227 - samples/sec: 63.10 - lr: 0.100000
2021-05-27 17:09:41,827 epoch 14 - iter 1280/1609 - loss 0.23409798 - samples/sec: 63.12 - lr: 0.100000
2021-05-27 17:11:02,906 epoch 14 - iter 1440/1609 - loss 0.23159294 - samples/sec: 63.15 - lr: 0.100000
2021-05-27 17:12:23,935 epoch 14 - iter 1600/1609 - loss 0.22986646 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 17:12:28,406 ----------------------------------------------------------------------------------------------------
2021-05-27 17:12:28,407 EPOCH 14 done: loss 0.2296 - lr 0.1000000
2021-05-27 17:12:42,527 DEV : loss 0.18668586015701294 - score 0.9556
2021-05-27 17:12:42,708 BAD EPOCHS (no improvement): 2
2021-05-27 17:12:42,708 ----------------------------------------------------------------------------------------------------
2021-05-27 17:14:03,601 epoch 15 - iter 160/1609 - loss 0.22311072 - samples/sec: 63.30 - lr: 0.100000
2021-05-27 17:15:24,762 epoch 15 - iter 320/1609 - loss 0.22134464 - samples/sec: 63.09 - lr: 0.100000
2021-05-27 17:16:45,980 epoch 15 - iter 480/1609 - loss 0.21533826 - samples/sec: 63.05 - lr: 0.100000
2021-05-27 17:18:07,227 epoch 15 - iter 640/1609 - loss 0.21930187 - samples/sec: 63.02 - lr: 0.100000
2021-05-27 17:19:28,306 epoch 15 - iter 800/1609 - loss 0.21912940 - samples/sec: 63.15 - lr: 0.100000
2021-05-27 17:20:49,485 epoch 15 - iter 960/1609 - loss 0.22246086 - samples/sec: 63.08 - lr: 0.100000
2021-05-27 17:22:10,741 epoch 15 - iter 1120/1609 - loss 0.22345409 - samples/sec: 63.02 - lr: 0.100000
2021-05-27 17:23:31,931 epoch 15 - iter 1280/1609 - loss 0.22384461 - samples/sec: 63.07 - lr: 0.100000
2021-05-27 17:24:52,967 epoch 15 - iter 1440/1609 - loss 0.22282866 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 17:26:14,008 epoch 15 - iter 1600/1609 - loss 0.22476622 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 17:26:18,489 ----------------------------------------------------------------------------------------------------
2021-05-27 17:26:18,489 EPOCH 15 done: loss 0.2245 - lr 0.1000000
2021-05-27 17:26:29,505 DEV : loss 0.17833855748176575 - score 0.9581
2021-05-27 17:26:29,688 BAD EPOCHS (no improvement): 3
2021-05-27 17:26:29,688 ----------------------------------------------------------------------------------------------------
2021-05-27 17:27:50,894 epoch 16 - iter 160/1609 - loss 0.21594012 - samples/sec: 63.06 - lr: 0.100000
2021-05-27 17:29:11,929 epoch 16 - iter 320/1609 - loss 0.22317390 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 17:30:32,797 epoch 16 - iter 480/1609 - loss 0.22523529 - samples/sec: 63.32 - lr: 0.100000
2021-05-27 17:31:53,635 epoch 16 - iter 640/1609 - loss 0.22889606 - samples/sec: 63.34 - lr: 0.100000
2021-05-27 17:33:14,896 epoch 16 - iter 800/1609 - loss 0.22327399 - samples/sec: 63.01 - lr: 0.100000
2021-05-27 17:34:35,833 epoch 16 - iter 960/1609 - loss 0.22070351 - samples/sec: 63.27 - lr: 0.100000
2021-05-27 17:35:56,449 epoch 16 - iter 1120/1609 - loss 0.22151386 - samples/sec: 63.52 - lr: 0.100000
2021-05-27 17:37:17,217 epoch 16 - iter 1280/1609 - loss 0.22317957 - samples/sec: 63.40 - lr: 0.100000
2021-05-27 17:38:37,780 epoch 16 - iter 1440/1609 - loss 0.22330565 - samples/sec: 63.56 - lr: 0.100000
2021-05-27 17:39:58,467 epoch 16 - iter 1600/1609 - loss 0.22186558 - samples/sec: 63.46 - lr: 0.100000
2021-05-27 17:40:02,915 ----------------------------------------------------------------------------------------------------
2021-05-27 17:40:02,915 EPOCH 16 done: loss 0.2221 - lr 0.1000000
2021-05-27 17:40:13,949 DEV : loss 0.16638904809951782 - score 0.9599
2021-05-27 17:40:14,133 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 17:40:23,073 ----------------------------------------------------------------------------------------------------
2021-05-27 17:41:44,095 epoch 17 - iter 160/1609 - loss 0.22285248 - samples/sec: 63.20 - lr: 0.100000
2021-05-27 17:43:05,053 epoch 17 - iter 320/1609 - loss 0.21873089 - samples/sec: 63.25 - lr: 0.100000
2021-05-27 17:44:26,370 epoch 17 - iter 480/1609 - loss 0.21991976 - samples/sec: 62.97 - lr: 0.100000
2021-05-27 17:45:47,512 epoch 17 - iter 640/1609 - loss 0.21828163 - samples/sec: 63.11 - lr: 0.100000
2021-05-27 17:47:08,773 epoch 17 - iter 800/1609 - loss 0.22255987 - samples/sec: 63.01 - lr: 0.100000
2021-05-27 17:48:29,627 epoch 17 - iter 960/1609 - loss 0.22475653 - samples/sec: 63.33 - lr: 0.100000
2021-05-27 17:49:50,821 epoch 17 - iter 1120/1609 - loss 0.22543320 - samples/sec: 63.07 - lr: 0.100000
2021-05-27 17:51:12,020 epoch 17 - iter 1280/1609 - loss 0.22449770 - samples/sec: 63.06 - lr: 0.100000
2021-05-27 17:52:33,223 epoch 17 - iter 1440/1609 - loss 0.22274860 - samples/sec: 63.06 - lr: 0.100000
2021-05-27 17:53:54,391 epoch 17 - iter 1600/1609 - loss 0.22136420 - samples/sec: 63.09 - lr: 0.100000
2021-05-27 17:53:58,832 ----------------------------------------------------------------------------------------------------
2021-05-27 17:53:58,832 EPOCH 17 done: loss 0.2216 - lr 0.1000000
2021-05-27 17:54:09,848 DEV : loss 0.172080859541893 - score 0.9634
2021-05-27 17:54:10,030 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 17:54:18,468 ----------------------------------------------------------------------------------------------------
2021-05-27 17:55:39,741 epoch 18 - iter 160/1609 - loss 0.22231828 - samples/sec: 63.01 - lr: 0.100000
2021-05-27 17:57:01,000 epoch 18 - iter 320/1609 - loss 0.22484999 - samples/sec: 63.01 - lr: 0.100000
2021-05-27 17:58:22,360 epoch 18 - iter 480/1609 - loss 0.22191869 - samples/sec: 62.94 - lr: 0.100000
2021-05-27 17:59:46,958 epoch 18 - iter 640/1609 - loss 0.21656452 - samples/sec: 60.53 - lr: 0.100000
2021-05-27 18:01:08,295 epoch 18 - iter 800/1609 - loss 0.21631968 - samples/sec: 62.95 - lr: 0.100000
2021-05-27 18:02:29,567 epoch 18 - iter 960/1609 - loss 0.21587963 - samples/sec: 63.00 - lr: 0.100000
2021-05-27 18:03:50,773 epoch 18 - iter 1120/1609 - loss 0.21719040 - samples/sec: 63.06 - lr: 0.100000
2021-05-27 18:05:11,287 epoch 18 - iter 1280/1609 - loss 0.21862260 - samples/sec: 63.60 - lr: 0.100000
2021-05-27 18:06:31,635 epoch 18 - iter 1440/1609 - loss 0.21564917 - samples/sec: 63.73 - lr: 0.100000
2021-05-27 18:07:52,669 epoch 18 - iter 1600/1609 - loss 0.21604827 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 18:07:57,088 ----------------------------------------------------------------------------------------------------
2021-05-27 18:07:57,089 EPOCH 18 done: loss 0.2161 - lr 0.1000000
2021-05-27 18:08:08,118 DEV : loss 0.15697312355041504 - score 0.9629
2021-05-27 18:08:08,304 BAD EPOCHS (no improvement): 1
2021-05-27 18:08:08,305 ----------------------------------------------------------------------------------------------------
2021-05-27 18:09:28,875 epoch 19 - iter 160/1609 - loss 0.21514931 - samples/sec: 63.55 - lr: 0.100000
2021-05-27 18:10:49,583 epoch 19 - iter 320/1609 - loss 0.21943969 - samples/sec: 63.44 - lr: 0.100000
2021-05-27 18:12:10,236 epoch 19 - iter 480/1609 - loss 0.21627555 - samples/sec: 63.49 - lr: 0.100000
2021-05-27 18:13:30,824 epoch 19 - iter 640/1609 - loss 0.21102002 - samples/sec: 63.54 - lr: 0.100000
2021-05-27 18:14:51,802 epoch 19 - iter 800/1609 - loss 0.21259497 - samples/sec: 63.23 - lr: 0.100000
2021-05-27 18:16:12,399 epoch 19 - iter 960/1609 - loss 0.21393950 - samples/sec: 63.53 - lr: 0.100000
2021-05-27 18:17:33,559 epoch 19 - iter 1120/1609 - loss 0.21402108 - samples/sec: 63.09 - lr: 0.100000
2021-05-27 18:18:54,697 epoch 19 - iter 1280/1609 - loss 0.21650442 - samples/sec: 63.11 - lr: 0.100000
2021-05-27 18:20:15,858 epoch 19 - iter 1440/1609 - loss 0.21718535 - samples/sec: 63.09 - lr: 0.100000
2021-05-27 18:21:36,998 epoch 19 - iter 1600/1609 - loss 0.21632658 - samples/sec: 63.11 - lr: 0.100000
2021-05-27 18:21:41,471 ----------------------------------------------------------------------------------------------------
2021-05-27 18:21:41,471 EPOCH 19 done: loss 0.2169 - lr 0.1000000
2021-05-27 18:21:52,518 DEV : loss 0.1808941811323166 - score 0.9581
2021-05-27 18:21:52,702 BAD EPOCHS (no improvement): 2
2021-05-27 18:21:52,702 ----------------------------------------------------------------------------------------------------
2021-05-27 18:23:14,028 epoch 20 - iter 160/1609 - loss 0.22043675 - samples/sec: 62.96 - lr: 0.100000
2021-05-27 18:24:35,412 epoch 20 - iter 320/1609 - loss 0.21160846 - samples/sec: 62.92 - lr: 0.100000
2021-05-27 18:25:56,584 epoch 20 - iter 480/1609 - loss 0.21561509 - samples/sec: 63.08 - lr: 0.100000
2021-05-27 18:27:17,838 epoch 20 - iter 640/1609 - loss 0.21056886 - samples/sec: 63.02 - lr: 0.100000
2021-05-27 18:28:39,088 epoch 20 - iter 800/1609 - loss 0.21245784 - samples/sec: 63.02 - lr: 0.100000
2021-05-27 18:30:00,225 epoch 20 - iter 960/1609 - loss 0.21560111 - samples/sec: 63.11 - lr: 0.100000
2021-05-27 18:31:21,442 epoch 20 - iter 1120/1609 - loss 0.21605646 - samples/sec: 63.05 - lr: 0.100000
2021-05-27 18:32:42,489 epoch 20 - iter 1280/1609 - loss 0.21691697 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 18:34:03,754 epoch 20 - iter 1440/1609 - loss 0.21621596 - samples/sec: 63.01 - lr: 0.100000
2021-05-27 18:35:25,049 epoch 20 - iter 1600/1609 - loss 0.21607273 - samples/sec: 62.99 - lr: 0.100000
2021-05-27 18:35:29,574 ----------------------------------------------------------------------------------------------------
2021-05-27 18:35:29,574 EPOCH 20 done: loss 0.2161 - lr 0.1000000
2021-05-27 18:35:40,617 DEV : loss 0.16527146100997925 - score 0.963
2021-05-27 18:35:40,801 BAD EPOCHS (no improvement): 3
2021-05-27 18:35:40,801 ----------------------------------------------------------------------------------------------------
2021-05-27 18:37:02,241 epoch 21 - iter 160/1609 - loss 0.18287087 - samples/sec: 62.88 - lr: 0.100000
2021-05-27 18:38:23,574 epoch 21 - iter 320/1609 - loss 0.18734247 - samples/sec: 62.96 - lr: 0.100000
2021-05-27 18:39:44,609 epoch 21 - iter 480/1609 - loss 0.19910771 - samples/sec: 63.19 - lr: 0.100000
2021-05-27 18:41:06,102 epoch 21 - iter 640/1609 - loss 0.20273466 - samples/sec: 62.83 - lr: 0.100000
2021-05-27 18:42:30,454 epoch 21 - iter 800/1609 - loss 0.20498869 - samples/sec: 60.70 - lr: 0.100000
2021-05-27 18:43:51,941 epoch 21 - iter 960/1609 - loss 0.21124504 - samples/sec: 62.84 - lr: 0.100000
2021-05-27 18:45:13,174 epoch 21 - iter 1120/1609 - loss 0.20849875 - samples/sec: 63.03 - lr: 0.100000
2021-05-27 18:46:34,507 epoch 21 - iter 1280/1609 - loss 0.21018849 - samples/sec: 62.96 - lr: 0.100000
2021-05-27 18:47:55,499 epoch 21 - iter 1440/1609 - loss 0.20843353 - samples/sec: 63.22 - lr: 0.100000
2021-05-27 18:49:16,646 epoch 21 - iter 1600/1609 - loss 0.20941843 - samples/sec: 63.10 - lr: 0.100000
2021-05-27 18:49:21,095 ----------------------------------------------------------------------------------------------------
2021-05-27 18:49:21,096 EPOCH 21 done: loss 0.2093 - lr 0.1000000
2021-05-27 18:49:32,129 DEV : loss 0.15948311984539032 - score 0.961
Epoch    21: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 18:49:32,312 BAD EPOCHS (no improvement): 4
2021-05-27 18:49:32,313 ----------------------------------------------------------------------------------------------------
2021-05-27 18:50:53,126 epoch 22 - iter 160/1609 - loss 0.19606667 - samples/sec: 63.36 - lr: 0.050000
2021-05-27 18:52:14,496 epoch 22 - iter 320/1609 - loss 0.20668670 - samples/sec: 62.93 - lr: 0.050000
2021-05-27 18:53:35,676 epoch 22 - iter 480/1609 - loss 0.20341461 - samples/sec: 63.08 - lr: 0.050000
2021-05-27 18:54:57,144 epoch 22 - iter 640/1609 - loss 0.19807001 - samples/sec: 62.85 - lr: 0.050000
2021-05-27 18:56:18,643 epoch 22 - iter 800/1609 - loss 0.19884074 - samples/sec: 62.83 - lr: 0.050000
2021-05-27 18:57:40,185 epoch 22 - iter 960/1609 - loss 0.19848284 - samples/sec: 62.80 - lr: 0.050000
2021-05-27 18:59:01,600 epoch 22 - iter 1120/1609 - loss 0.19711926 - samples/sec: 62.89 - lr: 0.050000
2021-05-27 19:00:22,845 epoch 22 - iter 1280/1609 - loss 0.19759646 - samples/sec: 63.03 - lr: 0.050000
2021-05-27 19:01:44,127 epoch 22 - iter 1440/1609 - loss 0.19644851 - samples/sec: 63.00 - lr: 0.050000
2021-05-27 19:03:05,424 epoch 22 - iter 1600/1609 - loss 0.19622265 - samples/sec: 62.99 - lr: 0.050000
2021-05-27 19:03:09,867 ----------------------------------------------------------------------------------------------------
2021-05-27 19:03:09,868 EPOCH 22 done: loss 0.1962 - lr 0.0500000
2021-05-27 19:03:20,914 DEV : loss 0.14815154671669006 - score 0.9644
2021-05-27 19:03:21,099 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 19:03:30,026 ----------------------------------------------------------------------------------------------------
2021-05-27 19:04:51,020 epoch 23 - iter 160/1609 - loss 0.18824016 - samples/sec: 63.22 - lr: 0.050000
2021-05-27 19:06:11,990 epoch 23 - iter 320/1609 - loss 0.18994736 - samples/sec: 63.24 - lr: 0.050000
2021-05-27 19:07:32,797 epoch 23 - iter 480/1609 - loss 0.19247716 - samples/sec: 63.37 - lr: 0.050000
2021-05-27 19:08:53,399 epoch 23 - iter 640/1609 - loss 0.19097914 - samples/sec: 63.53 - lr: 0.050000
2021-05-27 19:10:14,245 epoch 23 - iter 800/1609 - loss 0.19032755 - samples/sec: 63.34 - lr: 0.050000
2021-05-27 19:11:35,803 epoch 23 - iter 960/1609 - loss 0.18901021 - samples/sec: 62.78 - lr: 0.050000
2021-05-27 19:12:57,105 epoch 23 - iter 1120/1609 - loss 0.18724055 - samples/sec: 62.98 - lr: 0.050000
2021-05-27 19:14:18,397 epoch 23 - iter 1280/1609 - loss 0.18668641 - samples/sec: 62.99 - lr: 0.050000
2021-05-27 19:15:39,625 epoch 23 - iter 1440/1609 - loss 0.18636752 - samples/sec: 63.04 - lr: 0.050000
2021-05-27 19:17:00,797 epoch 23 - iter 1600/1609 - loss 0.18552655 - samples/sec: 63.08 - lr: 0.050000
2021-05-27 19:17:05,269 ----------------------------------------------------------------------------------------------------
2021-05-27 19:17:05,269 EPOCH 23 done: loss 0.1862 - lr 0.0500000
2021-05-27 19:17:16,304 DEV : loss 0.1483762413263321 - score 0.9652
2021-05-27 19:17:16,489 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 19:17:25,305 ----------------------------------------------------------------------------------------------------
2021-05-27 19:18:46,579 epoch 24 - iter 160/1609 - loss 0.17952007 - samples/sec: 63.01 - lr: 0.050000
2021-05-27 19:20:07,727 epoch 24 - iter 320/1609 - loss 0.19068423 - samples/sec: 63.10 - lr: 0.050000
2021-05-27 19:21:28,782 epoch 24 - iter 480/1609 - loss 0.19020400 - samples/sec: 63.17 - lr: 0.050000
2021-05-27 19:22:50,217 epoch 24 - iter 640/1609 - loss 0.18848015 - samples/sec: 62.88 - lr: 0.050000
2021-05-27 19:24:11,705 epoch 24 - iter 800/1609 - loss 0.18868973 - samples/sec: 62.84 - lr: 0.050000
2021-05-27 19:25:33,169 epoch 24 - iter 960/1609 - loss 0.18505938 - samples/sec: 62.86 - lr: 0.050000
2021-05-27 19:26:54,480 epoch 24 - iter 1120/1609 - loss 0.18572105 - samples/sec: 62.97 - lr: 0.050000
2021-05-27 19:28:15,813 epoch 24 - iter 1280/1609 - loss 0.18601318 - samples/sec: 62.96 - lr: 0.050000
2021-05-27 19:29:37,023 epoch 24 - iter 1440/1609 - loss 0.18308798 - samples/sec: 63.05 - lr: 0.050000
2021-05-27 19:30:58,336 epoch 24 - iter 1600/1609 - loss 0.18453381 - samples/sec: 62.97 - lr: 0.050000
2021-05-27 19:31:02,804 ----------------------------------------------------------------------------------------------------
2021-05-27 19:31:02,805 EPOCH 24 done: loss 0.1845 - lr 0.0500000
2021-05-27 19:31:16,938 DEV : loss 0.14243243634700775 - score 0.9674
2021-05-27 19:31:17,122 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 19:31:26,143 ----------------------------------------------------------------------------------------------------
2021-05-27 19:32:47,348 epoch 25 - iter 160/1609 - loss 0.18742161 - samples/sec: 63.06 - lr: 0.050000
2021-05-27 19:34:08,810 epoch 25 - iter 320/1609 - loss 0.18334936 - samples/sec: 62.86 - lr: 0.050000
2021-05-27 19:35:30,015 epoch 25 - iter 480/1609 - loss 0.18078489 - samples/sec: 63.06 - lr: 0.050000
2021-05-27 19:36:51,345 epoch 25 - iter 640/1609 - loss 0.18366280 - samples/sec: 62.96 - lr: 0.050000
2021-05-27 19:38:12,632 epoch 25 - iter 800/1609 - loss 0.18467420 - samples/sec: 62.99 - lr: 0.050000
2021-05-27 19:39:34,054 epoch 25 - iter 960/1609 - loss 0.18389906 - samples/sec: 62.89 - lr: 0.050000
2021-05-27 19:40:54,925 epoch 25 - iter 1120/1609 - loss 0.18189267 - samples/sec: 63.32 - lr: 0.050000
2021-05-27 19:42:15,699 epoch 25 - iter 1280/1609 - loss 0.18028601 - samples/sec: 63.39 - lr: 0.050000
2021-05-27 19:43:36,624 epoch 25 - iter 1440/1609 - loss 0.18083262 - samples/sec: 63.27 - lr: 0.050000
2021-05-27 19:44:57,963 epoch 25 - iter 1600/1609 - loss 0.18127023 - samples/sec: 62.95 - lr: 0.050000
2021-05-27 19:45:02,459 ----------------------------------------------------------------------------------------------------
2021-05-27 19:45:02,459 EPOCH 25 done: loss 0.1816 - lr 0.0500000
2021-05-27 19:45:13,523 DEV : loss 0.1386542171239853 - score 0.9645
2021-05-27 19:45:13,707 BAD EPOCHS (no improvement): 1
2021-05-27 19:45:13,708 ----------------------------------------------------------------------------------------------------
2021-05-27 19:46:35,054 epoch 26 - iter 160/1609 - loss 0.19530436 - samples/sec: 62.95 - lr: 0.050000
2021-05-27 19:47:56,065 epoch 26 - iter 320/1609 - loss 0.18806669 - samples/sec: 63.21 - lr: 0.050000
2021-05-27 19:49:17,210 epoch 26 - iter 480/1609 - loss 0.18324454 - samples/sec: 63.10 - lr: 0.050000
2021-05-27 19:50:38,554 epoch 26 - iter 640/1609 - loss 0.18664889 - samples/sec: 62.95 - lr: 0.050000
2021-05-27 19:52:00,149 epoch 26 - iter 800/1609 - loss 0.18446830 - samples/sec: 62.76 - lr: 0.050000
2021-05-27 19:53:21,489 epoch 26 - iter 960/1609 - loss 0.18282034 - samples/sec: 62.95 - lr: 0.050000
2021-05-27 19:54:42,615 epoch 26 - iter 1120/1609 - loss 0.18250641 - samples/sec: 63.12 - lr: 0.050000
2021-05-27 19:56:03,935 epoch 26 - iter 1280/1609 - loss 0.18159010 - samples/sec: 62.97 - lr: 0.050000
2021-05-27 19:57:25,293 epoch 26 - iter 1440/1609 - loss 0.18151737 - samples/sec: 62.94 - lr: 0.050000
2021-05-27 19:58:46,753 epoch 26 - iter 1600/1609 - loss 0.18070241 - samples/sec: 62.86 - lr: 0.050000
2021-05-27 19:58:51,208 ----------------------------------------------------------------------------------------------------
2021-05-27 19:58:51,208 EPOCH 26 done: loss 0.1809 - lr 0.0500000
2021-05-27 19:59:02,255 DEV : loss 0.14192809164524078 - score 0.9681
2021-05-27 19:59:02,441 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 19:59:11,276 ----------------------------------------------------------------------------------------------------
2021-05-27 20:00:32,503 epoch 27 - iter 160/1609 - loss 0.18257123 - samples/sec: 63.04 - lr: 0.050000
2021-05-27 20:01:53,936 epoch 27 - iter 320/1609 - loss 0.17600228 - samples/sec: 62.88 - lr: 0.050000
2021-05-27 20:03:15,284 epoch 27 - iter 480/1609 - loss 0.17849061 - samples/sec: 62.95 - lr: 0.050000
2021-05-27 20:04:36,177 epoch 27 - iter 640/1609 - loss 0.17647425 - samples/sec: 63.30 - lr: 0.050000
2021-05-27 20:05:57,323 epoch 27 - iter 800/1609 - loss 0.17600277 - samples/sec: 63.10 - lr: 0.050000
2021-05-27 20:07:18,114 epoch 27 - iter 960/1609 - loss 0.17531743 - samples/sec: 63.38 - lr: 0.050000
2021-05-27 20:08:39,138 epoch 27 - iter 1120/1609 - loss 0.17537679 - samples/sec: 63.20 - lr: 0.050000
2021-05-27 20:10:00,160 epoch 27 - iter 1280/1609 - loss 0.17555090 - samples/sec: 63.20 - lr: 0.050000
2021-05-27 20:11:21,154 epoch 27 - iter 1440/1609 - loss 0.17621851 - samples/sec: 63.22 - lr: 0.050000
2021-05-27 20:12:41,876 epoch 27 - iter 1600/1609 - loss 0.17591036 - samples/sec: 63.43 - lr: 0.050000
2021-05-27 20:12:46,304 ----------------------------------------------------------------------------------------------------
2021-05-27 20:12:46,304 EPOCH 27 done: loss 0.1757 - lr 0.0500000
2021-05-27 20:12:57,337 DEV : loss 0.13848043978214264 - score 0.969
2021-05-27 20:12:57,522 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 20:13:06,338 ----------------------------------------------------------------------------------------------------
2021-05-27 20:14:27,716 epoch 28 - iter 160/1609 - loss 0.18259364 - samples/sec: 62.92 - lr: 0.050000
2021-05-27 20:15:48,874 epoch 28 - iter 320/1609 - loss 0.17299909 - samples/sec: 63.09 - lr: 0.050000
2021-05-27 20:17:13,409 epoch 28 - iter 480/1609 - loss 0.17350706 - samples/sec: 60.57 - lr: 0.050000
2021-05-27 20:18:34,854 epoch 28 - iter 640/1609 - loss 0.17662688 - samples/sec: 62.87 - lr: 0.050000
2021-05-27 20:19:56,212 epoch 28 - iter 800/1609 - loss 0.17783993 - samples/sec: 62.94 - lr: 0.050000
2021-05-27 20:21:17,420 epoch 28 - iter 960/1609 - loss 0.17874104 - samples/sec: 63.05 - lr: 0.050000
2021-05-27 20:22:38,652 epoch 28 - iter 1120/1609 - loss 0.17790652 - samples/sec: 63.04 - lr: 0.050000
2021-05-27 20:24:00,059 epoch 28 - iter 1280/1609 - loss 0.17829382 - samples/sec: 62.90 - lr: 0.050000
2021-05-27 20:25:21,500 epoch 28 - iter 1440/1609 - loss 0.17802249 - samples/sec: 62.87 - lr: 0.050000
2021-05-27 20:26:42,904 epoch 28 - iter 1600/1609 - loss 0.17842561 - samples/sec: 62.90 - lr: 0.050000
2021-05-27 20:26:47,393 ----------------------------------------------------------------------------------------------------
2021-05-27 20:26:47,393 EPOCH 28 done: loss 0.1782 - lr 0.0500000
2021-05-27 20:26:58,439 DEV : loss 0.13972614705562592 - score 0.9674
2021-05-27 20:26:58,623 BAD EPOCHS (no improvement): 1
2021-05-27 20:26:58,623 ----------------------------------------------------------------------------------------------------
2021-05-27 20:28:19,974 epoch 29 - iter 160/1609 - loss 0.17982951 - samples/sec: 62.94 - lr: 0.050000
2021-05-27 20:29:41,314 epoch 29 - iter 320/1609 - loss 0.18044531 - samples/sec: 62.95 - lr: 0.050000
2021-05-27 20:31:02,765 epoch 29 - iter 480/1609 - loss 0.18106922 - samples/sec: 62.87 - lr: 0.050000
2021-05-27 20:32:24,071 epoch 29 - iter 640/1609 - loss 0.18150296 - samples/sec: 62.98 - lr: 0.050000
2021-05-27 20:33:45,562 epoch 29 - iter 800/1609 - loss 0.18064337 - samples/sec: 62.83 - lr: 0.050000
2021-05-27 20:35:06,973 epoch 29 - iter 960/1609 - loss 0.17866135 - samples/sec: 62.90 - lr: 0.050000
2021-05-27 20:36:28,304 epoch 29 - iter 1120/1609 - loss 0.17751487 - samples/sec: 62.96 - lr: 0.050000
2021-05-27 20:37:49,613 epoch 29 - iter 1280/1609 - loss 0.17824665 - samples/sec: 62.98 - lr: 0.050000
2021-05-27 20:39:11,321 epoch 29 - iter 1440/1609 - loss 0.17738985 - samples/sec: 62.67 - lr: 0.050000
2021-05-27 20:40:32,789 epoch 29 - iter 1600/1609 - loss 0.17674812 - samples/sec: 62.85 - lr: 0.050000
2021-05-27 20:40:37,294 ----------------------------------------------------------------------------------------------------
2021-05-27 20:40:37,294 EPOCH 29 done: loss 0.1767 - lr 0.0500000
2021-05-27 20:40:48,332 DEV : loss 0.13652946054935455 - score 0.9679
2021-05-27 20:40:48,517 BAD EPOCHS (no improvement): 2
2021-05-27 20:40:48,518 ----------------------------------------------------------------------------------------------------
2021-05-27 20:42:09,819 epoch 30 - iter 160/1609 - loss 0.17125996 - samples/sec: 62.98 - lr: 0.050000
2021-05-27 20:43:30,981 epoch 30 - iter 320/1609 - loss 0.17190013 - samples/sec: 63.09 - lr: 0.050000
2021-05-27 20:44:52,147 epoch 30 - iter 480/1609 - loss 0.17146039 - samples/sec: 63.09 - lr: 0.050000
2021-05-27 20:46:13,103 epoch 30 - iter 640/1609 - loss 0.17267733 - samples/sec: 63.25 - lr: 0.050000
2021-05-27 20:47:34,490 epoch 30 - iter 800/1609 - loss 0.17226810 - samples/sec: 62.92 - lr: 0.050000
2021-05-27 20:48:55,914 epoch 30 - iter 960/1609 - loss 0.16915138 - samples/sec: 62.89 - lr: 0.050000
2021-05-27 20:50:17,334 epoch 30 - iter 1120/1609 - loss 0.16975797 - samples/sec: 62.89 - lr: 0.050000
2021-05-27 20:51:38,723 epoch 30 - iter 1280/1609 - loss 0.17142203 - samples/sec: 62.91 - lr: 0.050000
2021-05-27 20:53:00,172 epoch 30 - iter 1440/1609 - loss 0.17007394 - samples/sec: 62.87 - lr: 0.050000
2021-05-27 20:54:21,541 epoch 30 - iter 1600/1609 - loss 0.17093660 - samples/sec: 62.93 - lr: 0.050000
2021-05-27 20:54:26,044 ----------------------------------------------------------------------------------------------------
2021-05-27 20:54:26,044 EPOCH 30 done: loss 0.1711 - lr 0.0500000
2021-05-27 20:54:37,093 DEV : loss 0.13181069493293762 - score 0.9674
2021-05-27 20:54:37,279 BAD EPOCHS (no improvement): 3
2021-05-27 20:54:38,250 ----------------------------------------------------------------------------------------------------
2021-05-27 20:54:38,250 Testing using best model ...
2021-05-27 20:54:38,250 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eng.pdtb.pdtb/best-model.pt
2021-05-27 20:55:44,269 0.9555	0.9535	0.9545
2021-05-27 20:55:44,269 
Results:
- F1-score (micro) 0.9545
- F1-score (macro) 0.9545

By class:
SENT       tp: 2254 - fp: 105 - fn: 110 - precision: 0.9555 - recall: 0.9535 - f1-score: 0.9545
2021-05-27 20:55:44,269 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/
2021-05-27 20:55:44,322 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum
2021-05-27 20:55:44,322 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/sent_train.txt
2021-05-27 20:55:44,322 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/sent_dev.txt
2021-05-27 20:55:44,324 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/sent_test.txt
Corpus: 3228 train + 752 dev + 767 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 20:56:04,272 ----------------------------------------------------------------------------------------------------
2021-05-27 20:56:04,274 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 20:56:04,274 ----------------------------------------------------------------------------------------------------
2021-05-27 20:56:04,274 Corpus: "Corpus: 3228 train + 752 dev + 767 test sentences"
2021-05-27 20:56:04,274 ----------------------------------------------------------------------------------------------------
2021-05-27 20:56:04,274 Parameters:
2021-05-27 20:56:04,274  - learning_rate: "0.1"
2021-05-27 20:56:04,274  - mini_batch_size: "32"
2021-05-27 20:56:04,274  - patience: "3"
2021-05-27 20:56:04,274  - anneal_factor: "0.5"
2021-05-27 20:56:04,274  - max_epochs: "30"
2021-05-27 20:56:04,275  - shuffle: "True"
2021-05-27 20:56:04,275  - train_with_dev: "False"
2021-05-27 20:56:04,275  - batch_growth_annealing: "False"
2021-05-27 20:56:04,275 ----------------------------------------------------------------------------------------------------
2021-05-27 20:56:04,275 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum"
2021-05-27 20:56:04,275 ----------------------------------------------------------------------------------------------------
2021-05-27 20:56:04,275 Device: cuda:0
2021-05-27 20:56:04,275 ----------------------------------------------------------------------------------------------------
2021-05-27 20:56:04,275 Embeddings storage mode: cpu
2021-05-27 20:56:04,276 ----------------------------------------------------------------------------------------------------
2021-05-27 20:56:17,308 epoch 1 - iter 10/101 - loss 7.33844614 - samples/sec: 24.56 - lr: 0.100000
2021-05-27 20:56:30,341 epoch 1 - iter 20/101 - loss 6.19490194 - samples/sec: 24.55 - lr: 0.100000
2021-05-27 20:56:43,433 epoch 1 - iter 30/101 - loss 5.59579207 - samples/sec: 24.44 - lr: 0.100000
2021-05-27 20:56:56,526 epoch 1 - iter 40/101 - loss 5.27851163 - samples/sec: 24.44 - lr: 0.100000
2021-05-27 20:57:10,022 epoch 1 - iter 50/101 - loss 4.94939997 - samples/sec: 23.71 - lr: 0.100000
2021-05-27 20:57:24,096 epoch 1 - iter 60/101 - loss 4.72051608 - samples/sec: 22.74 - lr: 0.100000
2021-05-27 20:57:37,909 epoch 1 - iter 70/101 - loss 4.46113342 - samples/sec: 23.17 - lr: 0.100000
2021-05-27 20:57:51,699 epoch 1 - iter 80/101 - loss 4.25423732 - samples/sec: 23.21 - lr: 0.100000
2021-05-27 20:58:05,567 epoch 1 - iter 90/101 - loss 4.07154167 - samples/sec: 23.08 - lr: 0.100000
2021-05-27 20:58:19,405 epoch 1 - iter 100/101 - loss 3.87052612 - samples/sec: 23.13 - lr: 0.100000
2021-05-27 20:58:20,600 ----------------------------------------------------------------------------------------------------
2021-05-27 20:58:20,600 EPOCH 1 done: loss 3.8578 - lr 0.1000000
2021-05-27 20:58:40,342 DEV : loss 1.5309991836547852 - score 0.8384
2021-05-27 20:58:40,419 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 20:58:41,375 ----------------------------------------------------------------------------------------------------
2021-05-27 20:58:46,704 epoch 2 - iter 10/101 - loss 1.98218491 - samples/sec: 60.07 - lr: 0.100000
2021-05-27 20:58:51,985 epoch 2 - iter 20/101 - loss 1.93030224 - samples/sec: 60.60 - lr: 0.100000
2021-05-27 20:58:57,329 epoch 2 - iter 30/101 - loss 1.86782498 - samples/sec: 59.89 - lr: 0.100000
2021-05-27 20:59:02,604 epoch 2 - iter 40/101 - loss 1.81961224 - samples/sec: 60.68 - lr: 0.100000
2021-05-27 20:59:07,889 epoch 2 - iter 50/101 - loss 1.79502034 - samples/sec: 60.56 - lr: 0.100000
2021-05-27 20:59:13,244 epoch 2 - iter 60/101 - loss 1.74278112 - samples/sec: 59.77 - lr: 0.100000
2021-05-27 20:59:18,565 epoch 2 - iter 70/101 - loss 1.68509206 - samples/sec: 60.15 - lr: 0.100000
2021-05-27 20:59:23,898 epoch 2 - iter 80/101 - loss 1.67996515 - samples/sec: 60.01 - lr: 0.100000
2021-05-27 20:59:29,214 epoch 2 - iter 90/101 - loss 1.63323181 - samples/sec: 60.20 - lr: 0.100000
2021-05-27 20:59:34,526 epoch 2 - iter 100/101 - loss 1.59337162 - samples/sec: 60.26 - lr: 0.100000
2021-05-27 20:59:34,993 ----------------------------------------------------------------------------------------------------
2021-05-27 20:59:34,993 EPOCH 2 done: loss 1.5832 - lr 0.1000000
2021-05-27 20:59:39,397 DEV : loss 0.5515596866607666 - score 0.9082
2021-05-27 20:59:39,473 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 20:59:48,514 ----------------------------------------------------------------------------------------------------
2021-05-27 20:59:53,828 epoch 3 - iter 10/101 - loss 1.00963445 - samples/sec: 60.24 - lr: 0.100000
2021-05-27 20:59:59,098 epoch 3 - iter 20/101 - loss 1.11428403 - samples/sec: 60.74 - lr: 0.100000
2021-05-27 21:00:04,380 epoch 3 - iter 30/101 - loss 1.15900791 - samples/sec: 60.60 - lr: 0.100000
2021-05-27 21:00:09,609 epoch 3 - iter 40/101 - loss 1.10773904 - samples/sec: 61.21 - lr: 0.100000
2021-05-27 21:00:14,858 epoch 3 - iter 50/101 - loss 1.12074994 - samples/sec: 60.97 - lr: 0.100000
2021-05-27 21:00:20,115 epoch 3 - iter 60/101 - loss 1.17396178 - samples/sec: 60.89 - lr: 0.100000
2021-05-27 21:00:25,376 epoch 3 - iter 70/101 - loss 1.14796961 - samples/sec: 60.83 - lr: 0.100000
2021-05-27 21:00:30,651 epoch 3 - iter 80/101 - loss 1.15826638 - samples/sec: 60.68 - lr: 0.100000
2021-05-27 21:00:35,904 epoch 3 - iter 90/101 - loss 1.18046178 - samples/sec: 60.92 - lr: 0.100000
2021-05-27 21:00:41,184 epoch 3 - iter 100/101 - loss 1.16460539 - samples/sec: 60.62 - lr: 0.100000
2021-05-27 21:00:41,650 ----------------------------------------------------------------------------------------------------
2021-05-27 21:00:41,651 EPOCH 3 done: loss 1.1623 - lr 0.1000000
2021-05-27 21:00:46,423 DEV : loss 0.49492669105529785 - score 0.9205
2021-05-27 21:00:46,501 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:00:55,323 ----------------------------------------------------------------------------------------------------
2021-05-27 21:01:00,598 epoch 4 - iter 10/101 - loss 1.09534396 - samples/sec: 60.67 - lr: 0.100000
2021-05-27 21:01:05,847 epoch 4 - iter 20/101 - loss 1.03214534 - samples/sec: 60.97 - lr: 0.100000
2021-05-27 21:01:11,122 epoch 4 - iter 30/101 - loss 1.08062340 - samples/sec: 60.67 - lr: 0.100000
2021-05-27 21:01:16,343 epoch 4 - iter 40/101 - loss 0.98882495 - samples/sec: 61.30 - lr: 0.100000
2021-05-27 21:01:21,599 epoch 4 - iter 50/101 - loss 1.03856022 - samples/sec: 60.89 - lr: 0.100000
2021-05-27 21:01:26,877 epoch 4 - iter 60/101 - loss 1.05435504 - samples/sec: 60.64 - lr: 0.100000
2021-05-27 21:01:32,132 epoch 4 - iter 70/101 - loss 1.05040189 - samples/sec: 60.91 - lr: 0.100000
2021-05-27 21:01:37,420 epoch 4 - iter 80/101 - loss 1.05607253 - samples/sec: 60.53 - lr: 0.100000
2021-05-27 21:01:42,708 epoch 4 - iter 90/101 - loss 1.04788214 - samples/sec: 60.53 - lr: 0.100000
2021-05-27 21:01:47,983 epoch 4 - iter 100/101 - loss 1.02456152 - samples/sec: 60.67 - lr: 0.100000
2021-05-27 21:01:48,448 ----------------------------------------------------------------------------------------------------
2021-05-27 21:01:48,448 EPOCH 4 done: loss 1.0172 - lr 0.1000000
2021-05-27 21:01:52,847 DEV : loss 0.4804905354976654 - score 0.9263
2021-05-27 21:01:52,925 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:02:01,891 ----------------------------------------------------------------------------------------------------
2021-05-27 21:02:07,123 epoch 5 - iter 10/101 - loss 0.89862112 - samples/sec: 61.18 - lr: 0.100000
2021-05-27 21:02:12,431 epoch 5 - iter 20/101 - loss 1.07939530 - samples/sec: 60.30 - lr: 0.100000
2021-05-27 21:02:17,728 epoch 5 - iter 30/101 - loss 0.98296772 - samples/sec: 60.43 - lr: 0.100000
2021-05-27 21:02:23,008 epoch 5 - iter 40/101 - loss 0.99670657 - samples/sec: 60.61 - lr: 0.100000
2021-05-27 21:02:28,269 epoch 5 - iter 50/101 - loss 0.97372422 - samples/sec: 60.84 - lr: 0.100000
2021-05-27 21:02:33,532 epoch 5 - iter 60/101 - loss 0.97562198 - samples/sec: 60.81 - lr: 0.100000
2021-05-27 21:02:38,772 epoch 5 - iter 70/101 - loss 0.97706427 - samples/sec: 61.08 - lr: 0.100000
2021-05-27 21:02:44,029 epoch 5 - iter 80/101 - loss 0.99461547 - samples/sec: 60.88 - lr: 0.100000
2021-05-27 21:02:49,336 epoch 5 - iter 90/101 - loss 0.99412940 - samples/sec: 60.31 - lr: 0.100000
2021-05-27 21:02:54,648 epoch 5 - iter 100/101 - loss 1.00029142 - samples/sec: 60.25 - lr: 0.100000
2021-05-27 21:02:55,123 ----------------------------------------------------------------------------------------------------
2021-05-27 21:02:55,124 EPOCH 5 done: loss 0.9943 - lr 0.1000000
2021-05-27 21:02:59,525 DEV : loss 0.6064152717590332 - score 0.8998
2021-05-27 21:02:59,603 BAD EPOCHS (no improvement): 1
2021-05-27 21:02:59,603 ----------------------------------------------------------------------------------------------------
2021-05-27 21:03:04,938 epoch 6 - iter 10/101 - loss 0.84121642 - samples/sec: 59.99 - lr: 0.100000
2021-05-27 21:03:10,244 epoch 6 - iter 20/101 - loss 0.84926717 - samples/sec: 60.32 - lr: 0.100000
2021-05-27 21:03:15,522 epoch 6 - iter 30/101 - loss 0.84748285 - samples/sec: 60.65 - lr: 0.100000
2021-05-27 21:03:20,815 epoch 6 - iter 40/101 - loss 0.83366731 - samples/sec: 60.46 - lr: 0.100000
2021-05-27 21:03:26,106 epoch 6 - iter 50/101 - loss 0.80937955 - samples/sec: 60.49 - lr: 0.100000
2021-05-27 21:03:31,393 epoch 6 - iter 60/101 - loss 0.81888656 - samples/sec: 60.54 - lr: 0.100000
2021-05-27 21:03:36,720 epoch 6 - iter 70/101 - loss 0.86257261 - samples/sec: 60.08 - lr: 0.100000
2021-05-27 21:03:42,055 epoch 6 - iter 80/101 - loss 0.89570749 - samples/sec: 59.99 - lr: 0.100000
2021-05-27 21:03:47,371 epoch 6 - iter 90/101 - loss 0.88799989 - samples/sec: 60.20 - lr: 0.100000
2021-05-27 21:03:52,680 epoch 6 - iter 100/101 - loss 0.86361645 - samples/sec: 60.29 - lr: 0.100000
2021-05-27 21:03:53,152 ----------------------------------------------------------------------------------------------------
2021-05-27 21:03:53,153 EPOCH 6 done: loss 0.8730 - lr 0.1000000
2021-05-27 21:03:57,925 DEV : loss 0.6007012128829956 - score 0.9205
2021-05-27 21:03:58,003 BAD EPOCHS (no improvement): 2
2021-05-27 21:03:58,003 ----------------------------------------------------------------------------------------------------
2021-05-27 21:04:03,306 epoch 7 - iter 10/101 - loss 0.85274131 - samples/sec: 60.35 - lr: 0.100000
2021-05-27 21:04:08,617 epoch 7 - iter 20/101 - loss 0.87168045 - samples/sec: 60.27 - lr: 0.100000
2021-05-27 21:04:13,899 epoch 7 - iter 30/101 - loss 0.89002984 - samples/sec: 60.59 - lr: 0.100000
2021-05-27 21:04:19,185 epoch 7 - iter 40/101 - loss 0.88008833 - samples/sec: 60.55 - lr: 0.100000
2021-05-27 21:04:24,464 epoch 7 - iter 50/101 - loss 0.86948520 - samples/sec: 60.62 - lr: 0.100000
2021-05-27 21:04:29,769 epoch 7 - iter 60/101 - loss 0.84083687 - samples/sec: 60.33 - lr: 0.100000
2021-05-27 21:04:35,071 epoch 7 - iter 70/101 - loss 0.80785230 - samples/sec: 60.37 - lr: 0.100000
2021-05-27 21:04:40,407 epoch 7 - iter 80/101 - loss 0.82799356 - samples/sec: 59.98 - lr: 0.100000
2021-05-27 21:04:45,707 epoch 7 - iter 90/101 - loss 0.83121629 - samples/sec: 60.39 - lr: 0.100000
2021-05-27 21:04:50,998 epoch 7 - iter 100/101 - loss 0.81937844 - samples/sec: 60.48 - lr: 0.100000
2021-05-27 21:04:51,470 ----------------------------------------------------------------------------------------------------
2021-05-27 21:04:51,470 EPOCH 7 done: loss 0.8207 - lr 0.1000000
2021-05-27 21:04:55,867 DEV : loss 0.4286750257015228 - score 0.9271
2021-05-27 21:04:55,944 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:05:04,909 ----------------------------------------------------------------------------------------------------
2021-05-27 21:05:10,167 epoch 8 - iter 10/101 - loss 0.54605579 - samples/sec: 60.87 - lr: 0.100000
2021-05-27 21:05:15,493 epoch 8 - iter 20/101 - loss 0.72428716 - samples/sec: 60.10 - lr: 0.100000
2021-05-27 21:05:20,817 epoch 8 - iter 30/101 - loss 0.80173217 - samples/sec: 60.11 - lr: 0.100000
2021-05-27 21:05:26,102 epoch 8 - iter 40/101 - loss 0.78345800 - samples/sec: 60.55 - lr: 0.100000
2021-05-27 21:05:31,425 epoch 8 - iter 50/101 - loss 0.78549733 - samples/sec: 60.13 - lr: 0.100000
2021-05-27 21:05:36,752 epoch 8 - iter 60/101 - loss 0.80046526 - samples/sec: 60.08 - lr: 0.100000
2021-05-27 21:05:42,096 epoch 8 - iter 70/101 - loss 0.82124436 - samples/sec: 59.89 - lr: 0.100000
2021-05-27 21:05:47,426 epoch 8 - iter 80/101 - loss 0.80550478 - samples/sec: 60.05 - lr: 0.100000
2021-05-27 21:05:52,729 epoch 8 - iter 90/101 - loss 0.79050808 - samples/sec: 60.35 - lr: 0.100000
2021-05-27 21:05:58,022 epoch 8 - iter 100/101 - loss 0.78433889 - samples/sec: 60.47 - lr: 0.100000
2021-05-27 21:05:58,493 ----------------------------------------------------------------------------------------------------
2021-05-27 21:05:58,493 EPOCH 8 done: loss 0.7839 - lr 0.1000000
2021-05-27 21:06:02,900 DEV : loss 0.45831793546676636 - score 0.9291
2021-05-27 21:06:02,978 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:06:12,243 ----------------------------------------------------------------------------------------------------
2021-05-27 21:06:17,548 epoch 9 - iter 10/101 - loss 0.64286313 - samples/sec: 60.34 - lr: 0.100000
2021-05-27 21:06:22,796 epoch 9 - iter 20/101 - loss 0.62348024 - samples/sec: 60.98 - lr: 0.100000
2021-05-27 21:06:28,061 epoch 9 - iter 30/101 - loss 0.64106248 - samples/sec: 60.79 - lr: 0.100000
2021-05-27 21:06:33,342 epoch 9 - iter 40/101 - loss 0.70967492 - samples/sec: 60.61 - lr: 0.100000
2021-05-27 21:06:38,615 epoch 9 - iter 50/101 - loss 0.73922598 - samples/sec: 60.70 - lr: 0.100000
2021-05-27 21:06:43,941 epoch 9 - iter 60/101 - loss 0.74356325 - samples/sec: 60.09 - lr: 0.100000
2021-05-27 21:06:49,207 epoch 9 - iter 70/101 - loss 0.74112709 - samples/sec: 60.78 - lr: 0.100000
2021-05-27 21:06:54,454 epoch 9 - iter 80/101 - loss 0.78000973 - samples/sec: 60.99 - lr: 0.100000
2021-05-27 21:06:59,711 epoch 9 - iter 90/101 - loss 0.76919345 - samples/sec: 60.88 - lr: 0.100000
2021-05-27 21:07:04,975 epoch 9 - iter 100/101 - loss 0.76550162 - samples/sec: 60.81 - lr: 0.100000
2021-05-27 21:07:05,435 ----------------------------------------------------------------------------------------------------
2021-05-27 21:07:05,436 EPOCH 9 done: loss 0.7645 - lr 0.1000000
2021-05-27 21:07:10,209 DEV : loss 0.5051281452178955 - score 0.9129
2021-05-27 21:07:10,287 BAD EPOCHS (no improvement): 1
2021-05-27 21:07:10,287 ----------------------------------------------------------------------------------------------------
2021-05-27 21:07:15,529 epoch 10 - iter 10/101 - loss 0.82424013 - samples/sec: 61.06 - lr: 0.100000
2021-05-27 21:07:20,792 epoch 10 - iter 20/101 - loss 0.80311561 - samples/sec: 60.81 - lr: 0.100000
2021-05-27 21:07:26,050 epoch 10 - iter 30/101 - loss 0.76212908 - samples/sec: 60.87 - lr: 0.100000
2021-05-27 21:07:31,309 epoch 10 - iter 40/101 - loss 0.76109519 - samples/sec: 60.86 - lr: 0.100000
2021-05-27 21:07:36,561 epoch 10 - iter 50/101 - loss 0.74544875 - samples/sec: 60.94 - lr: 0.100000
2021-05-27 21:07:41,786 epoch 10 - iter 60/101 - loss 0.73572961 - samples/sec: 61.26 - lr: 0.100000
2021-05-27 21:07:47,052 epoch 10 - iter 70/101 - loss 0.74033196 - samples/sec: 60.77 - lr: 0.100000
2021-05-27 21:07:52,348 epoch 10 - iter 80/101 - loss 0.73352924 - samples/sec: 60.44 - lr: 0.100000
2021-05-27 21:07:57,611 epoch 10 - iter 90/101 - loss 0.74526870 - samples/sec: 60.81 - lr: 0.100000
2021-05-27 21:08:02,888 epoch 10 - iter 100/101 - loss 0.74560544 - samples/sec: 60.65 - lr: 0.100000
2021-05-27 21:08:03,345 ----------------------------------------------------------------------------------------------------
2021-05-27 21:08:03,346 EPOCH 10 done: loss 0.7422 - lr 0.1000000
2021-05-27 21:08:07,726 DEV : loss 0.45151591300964355 - score 0.936
2021-05-27 21:08:07,804 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:08:16,621 ----------------------------------------------------------------------------------------------------
2021-05-27 21:08:21,894 epoch 11 - iter 10/101 - loss 0.58322881 - samples/sec: 60.70 - lr: 0.100000
2021-05-27 21:08:27,169 epoch 11 - iter 20/101 - loss 0.76208544 - samples/sec: 60.67 - lr: 0.100000
2021-05-27 21:08:32,432 epoch 11 - iter 30/101 - loss 0.77495414 - samples/sec: 60.81 - lr: 0.100000
2021-05-27 21:08:37,694 epoch 11 - iter 40/101 - loss 0.77104265 - samples/sec: 60.81 - lr: 0.100000
2021-05-27 21:08:42,955 epoch 11 - iter 50/101 - loss 0.71927118 - samples/sec: 60.84 - lr: 0.100000
2021-05-27 21:08:48,216 epoch 11 - iter 60/101 - loss 0.70849189 - samples/sec: 60.83 - lr: 0.100000
2021-05-27 21:08:53,504 epoch 11 - iter 70/101 - loss 0.71048049 - samples/sec: 60.53 - lr: 0.100000
2021-05-27 21:08:58,804 epoch 11 - iter 80/101 - loss 0.70599623 - samples/sec: 60.38 - lr: 0.100000
2021-05-27 21:09:04,123 epoch 11 - iter 90/101 - loss 0.70547775 - samples/sec: 60.18 - lr: 0.100000
2021-05-27 21:09:09,453 epoch 11 - iter 100/101 - loss 0.69700319 - samples/sec: 60.04 - lr: 0.100000
2021-05-27 21:09:09,924 ----------------------------------------------------------------------------------------------------
2021-05-27 21:09:09,925 EPOCH 11 done: loss 0.6968 - lr 0.1000000
2021-05-27 21:09:14,314 DEV : loss 0.48593372106552124 - score 0.9251
2021-05-27 21:09:14,392 BAD EPOCHS (no improvement): 1
2021-05-27 21:09:14,393 ----------------------------------------------------------------------------------------------------
2021-05-27 21:09:19,693 epoch 12 - iter 10/101 - loss 0.82110990 - samples/sec: 60.38 - lr: 0.100000
2021-05-27 21:09:25,006 epoch 12 - iter 20/101 - loss 0.75123667 - samples/sec: 60.25 - lr: 0.100000
2021-05-27 21:09:30,341 epoch 12 - iter 30/101 - loss 0.71309814 - samples/sec: 59.99 - lr: 0.100000
2021-05-27 21:09:35,681 epoch 12 - iter 40/101 - loss 0.71205112 - samples/sec: 59.93 - lr: 0.100000
2021-05-27 21:09:41,040 epoch 12 - iter 50/101 - loss 0.71192133 - samples/sec: 59.72 - lr: 0.100000
2021-05-27 21:09:46,354 epoch 12 - iter 60/101 - loss 0.69418218 - samples/sec: 60.23 - lr: 0.100000
2021-05-27 21:09:51,708 epoch 12 - iter 70/101 - loss 0.67501652 - samples/sec: 59.78 - lr: 0.100000
2021-05-27 21:09:57,020 epoch 12 - iter 80/101 - loss 0.69343336 - samples/sec: 60.25 - lr: 0.100000
2021-05-27 21:10:02,725 epoch 12 - iter 90/101 - loss 0.69525842 - samples/sec: 56.10 - lr: 0.100000
2021-05-27 21:10:08,033 epoch 12 - iter 100/101 - loss 0.68100862 - samples/sec: 60.29 - lr: 0.100000
2021-05-27 21:10:08,507 ----------------------------------------------------------------------------------------------------
2021-05-27 21:10:08,507 EPOCH 12 done: loss 0.6870 - lr 0.1000000
2021-05-27 21:10:12,899 DEV : loss 0.4732041358947754 - score 0.928
2021-05-27 21:10:12,979 BAD EPOCHS (no improvement): 2
2021-05-27 21:10:12,979 ----------------------------------------------------------------------------------------------------
2021-05-27 21:10:18,234 epoch 13 - iter 10/101 - loss 0.63638586 - samples/sec: 60.90 - lr: 0.100000
2021-05-27 21:10:23,548 epoch 13 - iter 20/101 - loss 0.66414475 - samples/sec: 60.23 - lr: 0.100000
2021-05-27 21:10:28,878 epoch 13 - iter 30/101 - loss 0.63644637 - samples/sec: 60.05 - lr: 0.100000
2021-05-27 21:10:34,155 epoch 13 - iter 40/101 - loss 0.65779954 - samples/sec: 60.65 - lr: 0.100000
2021-05-27 21:10:39,443 epoch 13 - iter 50/101 - loss 0.66826536 - samples/sec: 60.52 - lr: 0.100000
2021-05-27 21:10:44,744 epoch 13 - iter 60/101 - loss 0.68516159 - samples/sec: 60.38 - lr: 0.100000
2021-05-27 21:10:50,027 epoch 13 - iter 70/101 - loss 0.68980170 - samples/sec: 60.58 - lr: 0.100000
2021-05-27 21:10:55,323 epoch 13 - iter 80/101 - loss 0.68944377 - samples/sec: 60.43 - lr: 0.100000
2021-05-27 21:11:00,620 epoch 13 - iter 90/101 - loss 0.68793163 - samples/sec: 60.43 - lr: 0.100000
2021-05-27 21:11:05,875 epoch 13 - iter 100/101 - loss 0.70354022 - samples/sec: 60.90 - lr: 0.100000
2021-05-27 21:11:06,332 ----------------------------------------------------------------------------------------------------
2021-05-27 21:11:06,333 EPOCH 13 done: loss 0.7009 - lr 0.1000000
2021-05-27 21:11:10,712 DEV : loss 0.4340752959251404 - score 0.9339
2021-05-27 21:11:10,791 BAD EPOCHS (no improvement): 3
2021-05-27 21:11:10,792 ----------------------------------------------------------------------------------------------------
2021-05-27 21:11:16,099 epoch 14 - iter 10/101 - loss 0.72451586 - samples/sec: 60.30 - lr: 0.100000
2021-05-27 21:11:21,435 epoch 14 - iter 20/101 - loss 0.69032943 - samples/sec: 59.98 - lr: 0.100000
2021-05-27 21:11:26,723 epoch 14 - iter 30/101 - loss 0.63471469 - samples/sec: 60.53 - lr: 0.100000
2021-05-27 21:11:32,016 epoch 14 - iter 40/101 - loss 0.67319331 - samples/sec: 60.47 - lr: 0.100000
2021-05-27 21:11:37,339 epoch 14 - iter 50/101 - loss 0.68259772 - samples/sec: 60.12 - lr: 0.100000
2021-05-27 21:11:42,621 epoch 14 - iter 60/101 - loss 0.67954107 - samples/sec: 60.59 - lr: 0.100000
2021-05-27 21:11:47,959 epoch 14 - iter 70/101 - loss 0.67535192 - samples/sec: 59.96 - lr: 0.100000
2021-05-27 21:11:53,288 epoch 14 - iter 80/101 - loss 0.66657334 - samples/sec: 60.06 - lr: 0.100000
2021-05-27 21:11:58,576 epoch 14 - iter 90/101 - loss 0.66678343 - samples/sec: 60.53 - lr: 0.100000
2021-05-27 21:12:03,889 epoch 14 - iter 100/101 - loss 0.65399911 - samples/sec: 60.25 - lr: 0.100000
2021-05-27 21:12:04,353 ----------------------------------------------------------------------------------------------------
2021-05-27 21:12:04,353 EPOCH 14 done: loss 0.6519 - lr 0.1000000
2021-05-27 21:12:09,105 DEV : loss 0.4292066991329193 - score 0.9339
Epoch    14: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 21:12:09,183 BAD EPOCHS (no improvement): 4
2021-05-27 21:12:09,184 ----------------------------------------------------------------------------------------------------
2021-05-27 21:12:14,478 epoch 15 - iter 10/101 - loss 0.66026373 - samples/sec: 60.45 - lr: 0.050000
2021-05-27 21:12:19,770 epoch 15 - iter 20/101 - loss 0.58980887 - samples/sec: 60.48 - lr: 0.050000
2021-05-27 21:12:25,075 epoch 15 - iter 30/101 - loss 0.56369836 - samples/sec: 60.34 - lr: 0.050000
2021-05-27 21:12:30,375 epoch 15 - iter 40/101 - loss 0.57504471 - samples/sec: 60.38 - lr: 0.050000
2021-05-27 21:12:35,707 epoch 15 - iter 50/101 - loss 0.58088653 - samples/sec: 60.03 - lr: 0.050000
2021-05-27 21:12:41,046 epoch 15 - iter 60/101 - loss 0.58609181 - samples/sec: 59.94 - lr: 0.050000
2021-05-27 21:12:46,369 epoch 15 - iter 70/101 - loss 0.59963044 - samples/sec: 60.12 - lr: 0.050000
2021-05-27 21:12:51,669 epoch 15 - iter 80/101 - loss 0.58196955 - samples/sec: 60.38 - lr: 0.050000
2021-05-27 21:12:56,983 epoch 15 - iter 90/101 - loss 0.56496122 - samples/sec: 60.23 - lr: 0.050000
2021-05-27 21:13:02,273 epoch 15 - iter 100/101 - loss 0.55750496 - samples/sec: 60.50 - lr: 0.050000
2021-05-27 21:13:02,748 ----------------------------------------------------------------------------------------------------
2021-05-27 21:13:02,748 EPOCH 15 done: loss 0.5607 - lr 0.0500000
2021-05-27 21:13:07,120 DEV : loss 0.48048871755599976 - score 0.9193
2021-05-27 21:13:07,199 BAD EPOCHS (no improvement): 1
2021-05-27 21:13:07,199 ----------------------------------------------------------------------------------------------------
2021-05-27 21:13:12,520 epoch 16 - iter 10/101 - loss 0.71599687 - samples/sec: 60.15 - lr: 0.050000
2021-05-27 21:13:17,817 epoch 16 - iter 20/101 - loss 0.60788851 - samples/sec: 60.43 - lr: 0.050000
2021-05-27 21:13:23,064 epoch 16 - iter 30/101 - loss 0.61079282 - samples/sec: 60.99 - lr: 0.050000
2021-05-27 21:13:28,327 epoch 16 - iter 40/101 - loss 0.59313279 - samples/sec: 60.81 - lr: 0.050000
2021-05-27 21:13:33,646 epoch 16 - iter 50/101 - loss 0.60203384 - samples/sec: 60.17 - lr: 0.050000
2021-05-27 21:13:39,000 epoch 16 - iter 60/101 - loss 0.60175802 - samples/sec: 59.78 - lr: 0.050000
2021-05-27 21:13:44,328 epoch 16 - iter 70/101 - loss 0.60476186 - samples/sec: 60.08 - lr: 0.050000
2021-05-27 21:13:49,641 epoch 16 - iter 80/101 - loss 0.59843122 - samples/sec: 60.24 - lr: 0.050000
2021-05-27 21:13:54,967 epoch 16 - iter 90/101 - loss 0.59009333 - samples/sec: 60.09 - lr: 0.050000
2021-05-27 21:14:00,281 epoch 16 - iter 100/101 - loss 0.57868102 - samples/sec: 60.23 - lr: 0.050000
2021-05-27 21:14:00,759 ----------------------------------------------------------------------------------------------------
2021-05-27 21:14:00,759 EPOCH 16 done: loss 0.5806 - lr 0.0500000
2021-05-27 21:14:05,142 DEV : loss 0.44786447286605835 - score 0.9257
2021-05-27 21:14:05,221 BAD EPOCHS (no improvement): 2
2021-05-27 21:14:05,221 ----------------------------------------------------------------------------------------------------
2021-05-27 21:14:10,523 epoch 17 - iter 10/101 - loss 0.57713896 - samples/sec: 60.37 - lr: 0.050000
2021-05-27 21:14:15,818 epoch 17 - iter 20/101 - loss 0.56254393 - samples/sec: 60.45 - lr: 0.050000
2021-05-27 21:14:21,119 epoch 17 - iter 30/101 - loss 0.53147884 - samples/sec: 60.37 - lr: 0.050000
2021-05-27 21:14:26,463 epoch 17 - iter 40/101 - loss 0.52806384 - samples/sec: 59.89 - lr: 0.050000
2021-05-27 21:14:31,759 epoch 17 - iter 50/101 - loss 0.53672716 - samples/sec: 60.43 - lr: 0.050000
2021-05-27 21:14:37,099 epoch 17 - iter 60/101 - loss 0.52050830 - samples/sec: 59.94 - lr: 0.050000
2021-05-27 21:14:42,412 epoch 17 - iter 70/101 - loss 0.51860419 - samples/sec: 60.24 - lr: 0.050000
2021-05-27 21:14:47,733 epoch 17 - iter 80/101 - loss 0.51961671 - samples/sec: 60.14 - lr: 0.050000
2021-05-27 21:14:53,034 epoch 17 - iter 90/101 - loss 0.52506929 - samples/sec: 60.39 - lr: 0.050000
2021-05-27 21:14:58,353 epoch 17 - iter 100/101 - loss 0.52745479 - samples/sec: 60.17 - lr: 0.050000
2021-05-27 21:14:58,818 ----------------------------------------------------------------------------------------------------
2021-05-27 21:14:58,819 EPOCH 17 done: loss 0.5240 - lr 0.0500000
2021-05-27 21:15:03,582 DEV : loss 0.453805536031723 - score 0.9291
2021-05-27 21:15:03,661 BAD EPOCHS (no improvement): 3
2021-05-27 21:15:03,661 ----------------------------------------------------------------------------------------------------
2021-05-27 21:15:08,941 epoch 18 - iter 10/101 - loss 0.60557936 - samples/sec: 60.62 - lr: 0.050000
2021-05-27 21:15:14,210 epoch 18 - iter 20/101 - loss 0.53308809 - samples/sec: 60.74 - lr: 0.050000
2021-05-27 21:15:19,549 epoch 18 - iter 30/101 - loss 0.53239657 - samples/sec: 59.95 - lr: 0.050000
2021-05-27 21:15:24,862 epoch 18 - iter 40/101 - loss 0.52132814 - samples/sec: 60.23 - lr: 0.050000
2021-05-27 21:15:30,194 epoch 18 - iter 50/101 - loss 0.55096059 - samples/sec: 60.03 - lr: 0.050000
2021-05-27 21:15:35,528 epoch 18 - iter 60/101 - loss 0.54876722 - samples/sec: 60.00 - lr: 0.050000
2021-05-27 21:15:40,844 epoch 18 - iter 70/101 - loss 0.55909515 - samples/sec: 60.21 - lr: 0.050000
2021-05-27 21:15:46,162 epoch 18 - iter 80/101 - loss 0.54955614 - samples/sec: 60.18 - lr: 0.050000
2021-05-27 21:15:51,459 epoch 18 - iter 90/101 - loss 0.54965615 - samples/sec: 60.43 - lr: 0.050000
2021-05-27 21:15:56,786 epoch 18 - iter 100/101 - loss 0.52960657 - samples/sec: 60.07 - lr: 0.050000
2021-05-27 21:15:57,254 ----------------------------------------------------------------------------------------------------
2021-05-27 21:15:57,255 EPOCH 18 done: loss 0.5270 - lr 0.0500000
2021-05-27 21:16:01,634 DEV : loss 0.4424932897090912 - score 0.9341
Epoch    18: reducing learning rate of group 0 to 2.5000e-02.
2021-05-27 21:16:01,713 BAD EPOCHS (no improvement): 4
2021-05-27 21:16:01,713 ----------------------------------------------------------------------------------------------------
2021-05-27 21:16:07,007 epoch 19 - iter 10/101 - loss 0.43590223 - samples/sec: 60.46 - lr: 0.025000
2021-05-27 21:16:12,322 epoch 19 - iter 20/101 - loss 0.47388076 - samples/sec: 60.22 - lr: 0.025000
2021-05-27 21:16:17,642 epoch 19 - iter 30/101 - loss 0.49974354 - samples/sec: 60.15 - lr: 0.025000
2021-05-27 21:16:22,945 epoch 19 - iter 40/101 - loss 0.47861394 - samples/sec: 60.36 - lr: 0.025000
2021-05-27 21:16:28,264 epoch 19 - iter 50/101 - loss 0.47001491 - samples/sec: 60.17 - lr: 0.025000
2021-05-27 21:16:33,550 epoch 19 - iter 60/101 - loss 0.49123633 - samples/sec: 60.54 - lr: 0.025000
2021-05-27 21:16:38,880 epoch 19 - iter 70/101 - loss 0.49871560 - samples/sec: 60.04 - lr: 0.025000
2021-05-27 21:16:44,179 epoch 19 - iter 80/101 - loss 0.48688919 - samples/sec: 60.41 - lr: 0.025000
2021-05-27 21:16:49,510 epoch 19 - iter 90/101 - loss 0.48982764 - samples/sec: 60.04 - lr: 0.025000
2021-05-27 21:16:54,796 epoch 19 - iter 100/101 - loss 0.48378882 - samples/sec: 60.55 - lr: 0.025000
2021-05-27 21:16:55,264 ----------------------------------------------------------------------------------------------------
2021-05-27 21:16:55,264 EPOCH 19 done: loss 0.4844 - lr 0.0250000
2021-05-27 21:16:59,636 DEV : loss 0.4347197413444519 - score 0.9367
2021-05-27 21:16:59,715 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:17:08,579 ----------------------------------------------------------------------------------------------------
2021-05-27 21:17:13,904 epoch 20 - iter 10/101 - loss 0.46486677 - samples/sec: 60.12 - lr: 0.025000
2021-05-27 21:17:19,194 epoch 20 - iter 20/101 - loss 0.45536258 - samples/sec: 60.50 - lr: 0.025000
2021-05-27 21:17:24,522 epoch 20 - iter 30/101 - loss 0.47001735 - samples/sec: 60.07 - lr: 0.025000
2021-05-27 21:17:29,826 epoch 20 - iter 40/101 - loss 0.47781153 - samples/sec: 60.34 - lr: 0.025000
2021-05-27 21:17:35,112 epoch 20 - iter 50/101 - loss 0.51067003 - samples/sec: 60.55 - lr: 0.025000
2021-05-27 21:17:40,447 epoch 20 - iter 60/101 - loss 0.52281057 - samples/sec: 59.99 - lr: 0.025000
2021-05-27 21:17:45,780 epoch 20 - iter 70/101 - loss 0.51137107 - samples/sec: 60.02 - lr: 0.025000
2021-05-27 21:17:51,076 epoch 20 - iter 80/101 - loss 0.50882913 - samples/sec: 60.44 - lr: 0.025000
2021-05-27 21:17:56,384 epoch 20 - iter 90/101 - loss 0.50176261 - samples/sec: 60.29 - lr: 0.025000
2021-05-27 21:18:02,075 epoch 20 - iter 100/101 - loss 0.49139332 - samples/sec: 56.24 - lr: 0.025000
2021-05-27 21:18:02,541 ----------------------------------------------------------------------------------------------------
2021-05-27 21:18:02,541 EPOCH 20 done: loss 0.4928 - lr 0.0250000
2021-05-27 21:18:06,912 DEV : loss 0.44636496901512146 - score 0.9271
2021-05-27 21:18:06,990 BAD EPOCHS (no improvement): 1
2021-05-27 21:18:06,991 ----------------------------------------------------------------------------------------------------
2021-05-27 21:18:12,263 epoch 21 - iter 10/101 - loss 0.48667451 - samples/sec: 60.70 - lr: 0.025000
2021-05-27 21:18:17,607 epoch 21 - iter 20/101 - loss 0.45687551 - samples/sec: 59.89 - lr: 0.025000
2021-05-27 21:18:22,951 epoch 21 - iter 30/101 - loss 0.44690230 - samples/sec: 59.88 - lr: 0.025000
2021-05-27 21:18:28,245 epoch 21 - iter 40/101 - loss 0.45836195 - samples/sec: 60.45 - lr: 0.025000
2021-05-27 21:18:33,544 epoch 21 - iter 50/101 - loss 0.46106581 - samples/sec: 60.40 - lr: 0.025000
2021-05-27 21:18:38,849 epoch 21 - iter 60/101 - loss 0.45003863 - samples/sec: 60.33 - lr: 0.025000
2021-05-27 21:18:44,158 epoch 21 - iter 70/101 - loss 0.45638903 - samples/sec: 60.29 - lr: 0.025000
2021-05-27 21:18:49,461 epoch 21 - iter 80/101 - loss 0.45874340 - samples/sec: 60.35 - lr: 0.025000
2021-05-27 21:18:54,749 epoch 21 - iter 90/101 - loss 0.47409001 - samples/sec: 60.52 - lr: 0.025000
2021-05-27 21:19:00,071 epoch 21 - iter 100/101 - loss 0.47368460 - samples/sec: 60.14 - lr: 0.025000
2021-05-27 21:19:00,541 ----------------------------------------------------------------------------------------------------
2021-05-27 21:19:00,541 EPOCH 21 done: loss 0.4719 - lr 0.0250000
2021-05-27 21:19:04,920 DEV : loss 0.4108179211616516 - score 0.9402
2021-05-27 21:19:04,998 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:19:14,107 ----------------------------------------------------------------------------------------------------
2021-05-27 21:19:19,434 epoch 22 - iter 10/101 - loss 0.48124228 - samples/sec: 60.08 - lr: 0.025000
2021-05-27 21:19:24,752 epoch 22 - iter 20/101 - loss 0.46519407 - samples/sec: 60.19 - lr: 0.025000
2021-05-27 21:19:30,032 epoch 22 - iter 30/101 - loss 0.42818551 - samples/sec: 60.61 - lr: 0.025000
2021-05-27 21:19:35,388 epoch 22 - iter 40/101 - loss 0.41424332 - samples/sec: 59.75 - lr: 0.025000
2021-05-27 21:19:40,713 epoch 22 - iter 50/101 - loss 0.43389233 - samples/sec: 60.11 - lr: 0.025000
2021-05-27 21:19:46,032 epoch 22 - iter 60/101 - loss 0.46224103 - samples/sec: 60.17 - lr: 0.025000
2021-05-27 21:19:51,341 epoch 22 - iter 70/101 - loss 0.47188605 - samples/sec: 60.28 - lr: 0.025000
2021-05-27 21:19:56,633 epoch 22 - iter 80/101 - loss 0.45950301 - samples/sec: 60.48 - lr: 0.025000
2021-05-27 21:20:01,959 epoch 22 - iter 90/101 - loss 0.46038601 - samples/sec: 60.09 - lr: 0.025000
2021-05-27 21:20:07,236 epoch 22 - iter 100/101 - loss 0.45368770 - samples/sec: 60.66 - lr: 0.025000
2021-05-27 21:20:07,707 ----------------------------------------------------------------------------------------------------
2021-05-27 21:20:07,707 EPOCH 22 done: loss 0.4524 - lr 0.0250000
2021-05-27 21:20:12,446 DEV : loss 0.4177383780479431 - score 0.9393
2021-05-27 21:20:12,524 BAD EPOCHS (no improvement): 1
2021-05-27 21:20:12,524 ----------------------------------------------------------------------------------------------------
2021-05-27 21:20:17,784 epoch 23 - iter 10/101 - loss 0.35174146 - samples/sec: 60.85 - lr: 0.025000
2021-05-27 21:20:23,096 epoch 23 - iter 20/101 - loss 0.34226836 - samples/sec: 60.25 - lr: 0.025000
2021-05-27 21:20:28,405 epoch 23 - iter 30/101 - loss 0.38361227 - samples/sec: 60.28 - lr: 0.025000
2021-05-27 21:20:33,720 epoch 23 - iter 40/101 - loss 0.39577354 - samples/sec: 60.21 - lr: 0.025000
2021-05-27 21:20:39,040 epoch 23 - iter 50/101 - loss 0.40354497 - samples/sec: 60.16 - lr: 0.025000
2021-05-27 21:20:44,329 epoch 23 - iter 60/101 - loss 0.40674457 - samples/sec: 60.51 - lr: 0.025000
2021-05-27 21:20:49,622 epoch 23 - iter 70/101 - loss 0.42195020 - samples/sec: 60.46 - lr: 0.025000
2021-05-27 21:20:54,932 epoch 23 - iter 80/101 - loss 0.42851792 - samples/sec: 60.28 - lr: 0.025000
2021-05-27 21:21:00,267 epoch 23 - iter 90/101 - loss 0.43032259 - samples/sec: 60.00 - lr: 0.025000
2021-05-27 21:21:05,569 epoch 23 - iter 100/101 - loss 0.44402585 - samples/sec: 60.36 - lr: 0.025000
2021-05-27 21:21:06,032 ----------------------------------------------------------------------------------------------------
2021-05-27 21:21:06,032 EPOCH 23 done: loss 0.4490 - lr 0.0250000
2021-05-27 21:21:10,401 DEV : loss 0.42053088545799255 - score 0.9318
2021-05-27 21:21:10,479 BAD EPOCHS (no improvement): 2
2021-05-27 21:21:10,479 ----------------------------------------------------------------------------------------------------
2021-05-27 21:21:15,766 epoch 24 - iter 10/101 - loss 0.52579489 - samples/sec: 60.54 - lr: 0.025000
2021-05-27 21:21:21,051 epoch 24 - iter 20/101 - loss 0.50397320 - samples/sec: 60.56 - lr: 0.025000
2021-05-27 21:21:26,342 epoch 24 - iter 30/101 - loss 0.47971077 - samples/sec: 60.49 - lr: 0.025000
2021-05-27 21:21:31,663 epoch 24 - iter 40/101 - loss 0.46354907 - samples/sec: 60.15 - lr: 0.025000
2021-05-27 21:21:36,997 epoch 24 - iter 50/101 - loss 0.46334437 - samples/sec: 60.00 - lr: 0.025000
2021-05-27 21:21:42,299 epoch 24 - iter 60/101 - loss 0.45495247 - samples/sec: 60.36 - lr: 0.025000
2021-05-27 21:21:47,599 epoch 24 - iter 70/101 - loss 0.45354915 - samples/sec: 60.39 - lr: 0.025000
2021-05-27 21:21:52,929 epoch 24 - iter 80/101 - loss 0.45249336 - samples/sec: 60.05 - lr: 0.025000
2021-05-27 21:21:58,264 epoch 24 - iter 90/101 - loss 0.45277026 - samples/sec: 59.99 - lr: 0.025000
2021-05-27 21:22:03,578 epoch 24 - iter 100/101 - loss 0.45276180 - samples/sec: 60.23 - lr: 0.025000
2021-05-27 21:22:04,050 ----------------------------------------------------------------------------------------------------
2021-05-27 21:22:04,050 EPOCH 24 done: loss 0.4540 - lr 0.0250000
2021-05-27 21:22:08,417 DEV : loss 0.4912263751029968 - score 0.9202
2021-05-27 21:22:08,496 BAD EPOCHS (no improvement): 3
2021-05-27 21:22:08,496 ----------------------------------------------------------------------------------------------------
2021-05-27 21:22:13,813 epoch 25 - iter 10/101 - loss 0.43908665 - samples/sec: 60.19 - lr: 0.025000
2021-05-27 21:22:19,127 epoch 25 - iter 20/101 - loss 0.47252880 - samples/sec: 60.23 - lr: 0.025000
2021-05-27 21:22:24,452 epoch 25 - iter 30/101 - loss 0.46743876 - samples/sec: 60.10 - lr: 0.025000
2021-05-27 21:22:29,771 epoch 25 - iter 40/101 - loss 0.43282708 - samples/sec: 60.17 - lr: 0.025000
2021-05-27 21:22:35,024 epoch 25 - iter 50/101 - loss 0.46244889 - samples/sec: 60.93 - lr: 0.025000
2021-05-27 21:22:40,312 epoch 25 - iter 60/101 - loss 0.46619830 - samples/sec: 60.54 - lr: 0.025000
2021-05-27 21:22:45,614 epoch 25 - iter 70/101 - loss 0.44875994 - samples/sec: 60.36 - lr: 0.025000
2021-05-27 21:22:50,947 epoch 25 - iter 80/101 - loss 0.44434396 - samples/sec: 60.02 - lr: 0.025000
2021-05-27 21:22:56,616 epoch 25 - iter 90/101 - loss 0.44696925 - samples/sec: 56.45 - lr: 0.025000
2021-05-27 21:23:01,918 epoch 25 - iter 100/101 - loss 0.45222321 - samples/sec: 60.36 - lr: 0.025000
2021-05-27 21:23:02,386 ----------------------------------------------------------------------------------------------------
2021-05-27 21:23:02,386 EPOCH 25 done: loss 0.4496 - lr 0.0250000
2021-05-27 21:23:06,763 DEV : loss 0.41658759117126465 - score 0.9304
Epoch    25: reducing learning rate of group 0 to 1.2500e-02.
2021-05-27 21:23:06,842 BAD EPOCHS (no improvement): 4
2021-05-27 21:23:06,842 ----------------------------------------------------------------------------------------------------
2021-05-27 21:23:12,159 epoch 26 - iter 10/101 - loss 0.47806480 - samples/sec: 60.20 - lr: 0.012500
2021-05-27 21:23:17,487 epoch 26 - iter 20/101 - loss 0.46773370 - samples/sec: 60.07 - lr: 0.012500
2021-05-27 21:23:22,790 epoch 26 - iter 30/101 - loss 0.43921513 - samples/sec: 60.35 - lr: 0.012500
2021-05-27 21:23:28,104 epoch 26 - iter 40/101 - loss 0.44416715 - samples/sec: 60.23 - lr: 0.012500
2021-05-27 21:23:33,432 epoch 26 - iter 50/101 - loss 0.45482435 - samples/sec: 60.07 - lr: 0.012500
2021-05-27 21:23:38,754 epoch 26 - iter 60/101 - loss 0.45660733 - samples/sec: 60.13 - lr: 0.012500
2021-05-27 21:23:44,070 epoch 26 - iter 70/101 - loss 0.44810787 - samples/sec: 60.21 - lr: 0.012500
2021-05-27 21:23:49,371 epoch 26 - iter 80/101 - loss 0.44691975 - samples/sec: 60.38 - lr: 0.012500
2021-05-27 21:23:54,674 epoch 26 - iter 90/101 - loss 0.43864455 - samples/sec: 60.35 - lr: 0.012500
2021-05-27 21:23:59,947 epoch 26 - iter 100/101 - loss 0.43071138 - samples/sec: 60.70 - lr: 0.012500
2021-05-27 21:24:00,418 ----------------------------------------------------------------------------------------------------
2021-05-27 21:24:00,419 EPOCH 26 done: loss 0.4293 - lr 0.0125000
2021-05-27 21:24:04,794 DEV : loss 0.411865234375 - score 0.9333
2021-05-27 21:24:04,873 BAD EPOCHS (no improvement): 1
2021-05-27 21:24:04,873 ----------------------------------------------------------------------------------------------------
2021-05-27 21:24:10,166 epoch 27 - iter 10/101 - loss 0.40956788 - samples/sec: 60.46 - lr: 0.012500
2021-05-27 21:24:15,491 epoch 27 - iter 20/101 - loss 0.40623535 - samples/sec: 60.10 - lr: 0.012500
2021-05-27 21:24:20,774 epoch 27 - iter 30/101 - loss 0.41146588 - samples/sec: 60.58 - lr: 0.012500
2021-05-27 21:24:26,100 epoch 27 - iter 40/101 - loss 0.38809920 - samples/sec: 60.10 - lr: 0.012500
2021-05-27 21:24:31,399 epoch 27 - iter 50/101 - loss 0.39283982 - samples/sec: 60.40 - lr: 0.012500
2021-05-27 21:24:36,685 epoch 27 - iter 60/101 - loss 0.39532669 - samples/sec: 60.55 - lr: 0.012500
2021-05-27 21:24:42,003 epoch 27 - iter 70/101 - loss 0.39851321 - samples/sec: 60.17 - lr: 0.012500
2021-05-27 21:24:47,323 epoch 27 - iter 80/101 - loss 0.39879790 - samples/sec: 60.17 - lr: 0.012500
2021-05-27 21:24:52,621 epoch 27 - iter 90/101 - loss 0.40958406 - samples/sec: 60.41 - lr: 0.012500
2021-05-27 21:24:57,922 epoch 27 - iter 100/101 - loss 0.40974851 - samples/sec: 60.37 - lr: 0.012500
2021-05-27 21:24:58,394 ----------------------------------------------------------------------------------------------------
2021-05-27 21:24:58,394 EPOCH 27 done: loss 0.4081 - lr 0.0125000
2021-05-27 21:25:03,149 DEV : loss 0.4066813886165619 - score 0.9358
2021-05-27 21:25:03,228 BAD EPOCHS (no improvement): 2
2021-05-27 21:25:03,228 ----------------------------------------------------------------------------------------------------
2021-05-27 21:25:08,484 epoch 28 - iter 10/101 - loss 0.45639579 - samples/sec: 60.89 - lr: 0.012500
2021-05-27 21:25:13,750 epoch 28 - iter 20/101 - loss 0.48122337 - samples/sec: 60.78 - lr: 0.012500
2021-05-27 21:25:19,076 epoch 28 - iter 30/101 - loss 0.45238448 - samples/sec: 60.09 - lr: 0.012500
2021-05-27 21:25:24,415 epoch 28 - iter 40/101 - loss 0.40694163 - samples/sec: 59.94 - lr: 0.012500
2021-05-27 21:25:29,707 epoch 28 - iter 50/101 - loss 0.41116652 - samples/sec: 60.49 - lr: 0.012500
2021-05-27 21:25:35,036 epoch 28 - iter 60/101 - loss 0.41348408 - samples/sec: 60.05 - lr: 0.012500
2021-05-27 21:25:40,352 epoch 28 - iter 70/101 - loss 0.42805309 - samples/sec: 60.20 - lr: 0.012500
2021-05-27 21:25:45,679 epoch 28 - iter 80/101 - loss 0.41477160 - samples/sec: 60.09 - lr: 0.012500
2021-05-27 21:25:50,968 epoch 28 - iter 90/101 - loss 0.41522691 - samples/sec: 60.51 - lr: 0.012500
2021-05-27 21:25:56,286 epoch 28 - iter 100/101 - loss 0.42431716 - samples/sec: 60.18 - lr: 0.012500
2021-05-27 21:25:56,761 ----------------------------------------------------------------------------------------------------
2021-05-27 21:25:56,762 EPOCH 28 done: loss 0.4241 - lr 0.0125000
2021-05-27 21:26:01,140 DEV : loss 0.3825037479400635 - score 0.9371
2021-05-27 21:26:01,219 BAD EPOCHS (no improvement): 3
2021-05-27 21:26:01,219 ----------------------------------------------------------------------------------------------------
2021-05-27 21:26:06,541 epoch 29 - iter 10/101 - loss 0.58943815 - samples/sec: 60.15 - lr: 0.012500
2021-05-27 21:26:11,866 epoch 29 - iter 20/101 - loss 0.55117858 - samples/sec: 60.10 - lr: 0.012500
2021-05-27 21:26:17,195 epoch 29 - iter 30/101 - loss 0.51341884 - samples/sec: 60.05 - lr: 0.012500
2021-05-27 21:26:22,486 epoch 29 - iter 40/101 - loss 0.50523503 - samples/sec: 60.50 - lr: 0.012500
2021-05-27 21:26:27,807 epoch 29 - iter 50/101 - loss 0.48588114 - samples/sec: 60.15 - lr: 0.012500
2021-05-27 21:26:33,150 epoch 29 - iter 60/101 - loss 0.46565925 - samples/sec: 59.90 - lr: 0.012500
2021-05-27 21:26:38,462 epoch 29 - iter 70/101 - loss 0.44087062 - samples/sec: 60.24 - lr: 0.012500
2021-05-27 21:26:43,783 epoch 29 - iter 80/101 - loss 0.43553191 - samples/sec: 60.15 - lr: 0.012500
2021-05-27 21:26:49,089 epoch 29 - iter 90/101 - loss 0.42313514 - samples/sec: 60.32 - lr: 0.012500
2021-05-27 21:26:54,369 epoch 29 - iter 100/101 - loss 0.41998870 - samples/sec: 60.62 - lr: 0.012500
2021-05-27 21:26:54,847 ----------------------------------------------------------------------------------------------------
2021-05-27 21:26:54,847 EPOCH 29 done: loss 0.4204 - lr 0.0125000
2021-05-27 21:26:59,218 DEV : loss 0.38740548491477966 - score 0.9372
Epoch    29: reducing learning rate of group 0 to 6.2500e-03.
2021-05-27 21:26:59,296 BAD EPOCHS (no improvement): 4
2021-05-27 21:26:59,297 ----------------------------------------------------------------------------------------------------
2021-05-27 21:27:04,635 epoch 30 - iter 10/101 - loss 0.48255051 - samples/sec: 59.96 - lr: 0.006250
2021-05-27 21:27:09,921 epoch 30 - iter 20/101 - loss 0.45597881 - samples/sec: 60.55 - lr: 0.006250
2021-05-27 21:27:15,205 epoch 30 - iter 30/101 - loss 0.41268523 - samples/sec: 60.57 - lr: 0.006250
2021-05-27 21:27:20,483 epoch 30 - iter 40/101 - loss 0.44042963 - samples/sec: 60.64 - lr: 0.006250
2021-05-27 21:27:25,779 epoch 30 - iter 50/101 - loss 0.44582436 - samples/sec: 60.43 - lr: 0.006250
2021-05-27 21:27:31,105 epoch 30 - iter 60/101 - loss 0.45867440 - samples/sec: 60.09 - lr: 0.006250
2021-05-27 21:27:36,416 epoch 30 - iter 70/101 - loss 0.44764109 - samples/sec: 60.26 - lr: 0.006250
2021-05-27 21:27:41,778 epoch 30 - iter 80/101 - loss 0.42773892 - samples/sec: 59.69 - lr: 0.006250
2021-05-27 21:27:47,471 epoch 30 - iter 90/101 - loss 0.41570552 - samples/sec: 56.22 - lr: 0.006250
2021-05-27 21:27:52,791 epoch 30 - iter 100/101 - loss 0.40668440 - samples/sec: 60.16 - lr: 0.006250
2021-05-27 21:27:53,244 ----------------------------------------------------------------------------------------------------
2021-05-27 21:27:53,244 EPOCH 30 done: loss 0.4095 - lr 0.0062500
2021-05-27 21:27:57,615 DEV : loss 0.3776387572288513 - score 0.9364
2021-05-27 21:27:57,693 BAD EPOCHS (no improvement): 1
2021-05-27 21:27:58,631 ----------------------------------------------------------------------------------------------------
2021-05-27 21:27:58,632 Testing using best model ...
2021-05-27 21:27:58,632 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.gum/best-model.pt
2021-05-27 21:28:18,577 0.8873	0.9202	0.9035
2021-05-27 21:28:18,577 
Results:
- F1-score (micro) 0.9035
- F1-score (macro) 0.9035

By class:
SENT       tp: 819 - fp: 104 - fn: 71 - precision: 0.8873 - recall: 0.9202 - f1-score: 0.9035
2021-05-27 21:28:18,577 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/
2021-05-27 21:28:18,609 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt
2021-05-27 21:28:18,612 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/sent_train.txt
2021-05-27 21:28:18,614 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/sent_dev.txt
2021-05-27 21:28:18,616 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/sent_test.txt
Corpus: 865 train + 186 dev + 176 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 21:28:25,693 ----------------------------------------------------------------------------------------------------
2021-05-27 21:28:25,695 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 21:28:25,695 ----------------------------------------------------------------------------------------------------
2021-05-27 21:28:25,696 Corpus: "Corpus: 865 train + 186 dev + 176 test sentences"
2021-05-27 21:28:25,696 ----------------------------------------------------------------------------------------------------
2021-05-27 21:28:25,696 Parameters:
2021-05-27 21:28:25,696  - learning_rate: "0.1"
2021-05-27 21:28:25,696  - mini_batch_size: "32"
2021-05-27 21:28:25,696  - patience: "3"
2021-05-27 21:28:25,696  - anneal_factor: "0.5"
2021-05-27 21:28:25,696  - max_epochs: "30"
2021-05-27 21:28:25,696  - shuffle: "True"
2021-05-27 21:28:25,696  - train_with_dev: "False"
2021-05-27 21:28:25,696  - batch_growth_annealing: "False"
2021-05-27 21:28:25,696 ----------------------------------------------------------------------------------------------------
2021-05-27 21:28:25,696 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt"
2021-05-27 21:28:25,696 ----------------------------------------------------------------------------------------------------
2021-05-27 21:28:25,696 Device: cuda:0
2021-05-27 21:28:25,696 ----------------------------------------------------------------------------------------------------
2021-05-27 21:28:25,696 Embeddings storage mode: cpu
2021-05-27 21:28:25,697 ----------------------------------------------------------------------------------------------------
2021-05-27 21:28:28,332 epoch 1 - iter 2/28 - loss 20.83219004 - samples/sec: 24.30 - lr: 0.100000
2021-05-27 21:28:30,962 epoch 1 - iter 4/28 - loss 14.86693978 - samples/sec: 24.33 - lr: 0.100000
2021-05-27 21:28:33,602 epoch 1 - iter 6/28 - loss 12.29009676 - samples/sec: 24.24 - lr: 0.100000
2021-05-27 21:28:36,264 epoch 1 - iter 8/28 - loss 11.24537945 - samples/sec: 24.05 - lr: 0.100000
2021-05-27 21:28:39,033 epoch 1 - iter 10/28 - loss 10.64459200 - samples/sec: 23.11 - lr: 0.100000
2021-05-27 21:28:41,694 epoch 1 - iter 12/28 - loss 9.95210334 - samples/sec: 24.06 - lr: 0.100000
2021-05-27 21:28:44,348 epoch 1 - iter 14/28 - loss 9.52230450 - samples/sec: 24.12 - lr: 0.100000
2021-05-27 21:28:46,966 epoch 1 - iter 16/28 - loss 9.03183633 - samples/sec: 24.45 - lr: 0.100000
2021-05-27 21:28:49,632 epoch 1 - iter 18/28 - loss 8.70043045 - samples/sec: 24.01 - lr: 0.100000
2021-05-27 21:28:52,247 epoch 1 - iter 20/28 - loss 8.36948318 - samples/sec: 24.47 - lr: 0.100000
2021-05-27 21:28:54,869 epoch 1 - iter 22/28 - loss 8.16889121 - samples/sec: 24.41 - lr: 0.100000
2021-05-27 21:28:57,523 epoch 1 - iter 24/28 - loss 7.91302268 - samples/sec: 24.12 - lr: 0.100000
2021-05-27 21:29:00,174 epoch 1 - iter 26/28 - loss 7.70906450 - samples/sec: 24.14 - lr: 0.100000
2021-05-27 21:29:01,587 epoch 1 - iter 28/28 - loss 7.54999604 - samples/sec: 45.28 - lr: 0.100000
2021-05-27 21:29:01,588 ----------------------------------------------------------------------------------------------------
2021-05-27 21:29:01,588 EPOCH 1 done: loss 7.5500 - lr 0.1000000
2021-05-27 21:29:06,483 DEV : loss 2.5449142456054688 - score 0.0677
2021-05-27 21:29:06,502 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:29:07,492 ----------------------------------------------------------------------------------------------------
2021-05-27 21:29:08,536 epoch 2 - iter 2/28 - loss 2.59354305 - samples/sec: 61.32 - lr: 0.100000
2021-05-27 21:29:09,598 epoch 2 - iter 4/28 - loss 2.32283849 - samples/sec: 60.30 - lr: 0.100000
2021-05-27 21:29:10,636 epoch 2 - iter 6/28 - loss 3.29393733 - samples/sec: 61.70 - lr: 0.100000
2021-05-27 21:29:11,708 epoch 2 - iter 8/28 - loss 3.75013879 - samples/sec: 59.73 - lr: 0.100000
2021-05-27 21:29:12,755 epoch 2 - iter 10/28 - loss 3.65496047 - samples/sec: 61.15 - lr: 0.100000
2021-05-27 21:29:13,930 epoch 2 - iter 12/28 - loss 3.66021448 - samples/sec: 54.49 - lr: 0.100000
2021-05-27 21:29:14,979 epoch 2 - iter 14/28 - loss 3.69683698 - samples/sec: 61.01 - lr: 0.100000
2021-05-27 21:29:16,039 epoch 2 - iter 16/28 - loss 3.63727082 - samples/sec: 60.44 - lr: 0.100000
2021-05-27 21:29:17,099 epoch 2 - iter 18/28 - loss 3.59176199 - samples/sec: 60.39 - lr: 0.100000
2021-05-27 21:29:18,141 epoch 2 - iter 20/28 - loss 3.48132373 - samples/sec: 61.46 - lr: 0.100000
2021-05-27 21:29:19,203 epoch 2 - iter 22/28 - loss 3.41156815 - samples/sec: 60.29 - lr: 0.100000
2021-05-27 21:29:20,264 epoch 2 - iter 24/28 - loss 3.40594924 - samples/sec: 60.34 - lr: 0.100000
2021-05-27 21:29:21,312 epoch 2 - iter 26/28 - loss 3.36850466 - samples/sec: 61.13 - lr: 0.100000
2021-05-27 21:29:21,892 epoch 2 - iter 28/28 - loss 3.23919882 - samples/sec: 110.32 - lr: 0.100000
2021-05-27 21:29:21,893 ----------------------------------------------------------------------------------------------------
2021-05-27 21:29:21,893 EPOCH 2 done: loss 3.2392 - lr 0.1000000
2021-05-27 21:29:22,989 DEV : loss 0.9569358825683594 - score 0.8584
2021-05-27 21:29:23,008 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:29:34,271 ----------------------------------------------------------------------------------------------------
2021-05-27 21:29:35,320 epoch 3 - iter 2/28 - loss 2.56842351 - samples/sec: 61.02 - lr: 0.100000
2021-05-27 21:29:36,363 epoch 3 - iter 4/28 - loss 2.89017242 - samples/sec: 61.39 - lr: 0.100000
2021-05-27 21:29:37,425 epoch 3 - iter 6/28 - loss 2.74969256 - samples/sec: 60.33 - lr: 0.100000
2021-05-27 21:29:38,484 epoch 3 - iter 8/28 - loss 2.81426573 - samples/sec: 60.47 - lr: 0.100000
2021-05-27 21:29:39,529 epoch 3 - iter 10/28 - loss 2.68629789 - samples/sec: 61.24 - lr: 0.100000
2021-05-27 21:29:40,576 epoch 3 - iter 12/28 - loss 2.50615685 - samples/sec: 61.16 - lr: 0.100000
2021-05-27 21:29:41,633 epoch 3 - iter 14/28 - loss 2.38390499 - samples/sec: 60.60 - lr: 0.100000
2021-05-27 21:29:42,685 epoch 3 - iter 16/28 - loss 2.33494632 - samples/sec: 60.83 - lr: 0.100000
2021-05-27 21:29:43,723 epoch 3 - iter 18/28 - loss 2.26620671 - samples/sec: 61.68 - lr: 0.100000
2021-05-27 21:29:44,797 epoch 3 - iter 20/28 - loss 2.26536106 - samples/sec: 59.62 - lr: 0.100000
2021-05-27 21:29:45,859 epoch 3 - iter 22/28 - loss 2.18677344 - samples/sec: 60.28 - lr: 0.100000
2021-05-27 21:29:46,921 epoch 3 - iter 24/28 - loss 2.13967005 - samples/sec: 60.31 - lr: 0.100000
2021-05-27 21:29:47,978 epoch 3 - iter 26/28 - loss 2.05176464 - samples/sec: 60.60 - lr: 0.100000
2021-05-27 21:29:48,590 epoch 3 - iter 28/28 - loss 2.01937601 - samples/sec: 104.56 - lr: 0.100000
2021-05-27 21:29:48,591 ----------------------------------------------------------------------------------------------------
2021-05-27 21:29:48,591 EPOCH 3 done: loss 2.0194 - lr 0.1000000
2021-05-27 21:29:49,682 DEV : loss 0.6877806186676025 - score 0.9162
2021-05-27 21:29:49,701 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:29:58,542 ----------------------------------------------------------------------------------------------------
2021-05-27 21:29:59,581 epoch 4 - iter 2/28 - loss 1.70742989 - samples/sec: 61.66 - lr: 0.100000
2021-05-27 21:30:00,625 epoch 4 - iter 4/28 - loss 1.59227094 - samples/sec: 61.36 - lr: 0.100000
2021-05-27 21:30:01,668 epoch 4 - iter 6/28 - loss 1.48080045 - samples/sec: 61.36 - lr: 0.100000
2021-05-27 21:30:02,731 epoch 4 - iter 8/28 - loss 1.42741315 - samples/sec: 60.24 - lr: 0.100000
2021-05-27 21:30:03,792 epoch 4 - iter 10/28 - loss 1.42973744 - samples/sec: 60.33 - lr: 0.100000
2021-05-27 21:30:04,811 epoch 4 - iter 12/28 - loss 1.43142775 - samples/sec: 62.87 - lr: 0.100000
2021-05-27 21:30:05,882 epoch 4 - iter 14/28 - loss 1.41027617 - samples/sec: 59.80 - lr: 0.100000
2021-05-27 21:30:06,964 epoch 4 - iter 16/28 - loss 1.38201398 - samples/sec: 59.17 - lr: 0.100000
2021-05-27 21:30:08,043 epoch 4 - iter 18/28 - loss 1.39192670 - samples/sec: 59.33 - lr: 0.100000
2021-05-27 21:30:09,077 epoch 4 - iter 20/28 - loss 1.36152567 - samples/sec: 61.93 - lr: 0.100000
2021-05-27 21:30:10,132 epoch 4 - iter 22/28 - loss 1.34579765 - samples/sec: 60.69 - lr: 0.100000
2021-05-27 21:30:11,197 epoch 4 - iter 24/28 - loss 1.39346577 - samples/sec: 60.11 - lr: 0.100000
2021-05-27 21:30:12,229 epoch 4 - iter 26/28 - loss 1.36107290 - samples/sec: 62.04 - lr: 0.100000
2021-05-27 21:30:12,827 epoch 4 - iter 28/28 - loss 1.32686127 - samples/sec: 107.23 - lr: 0.100000
2021-05-27 21:30:12,827 ----------------------------------------------------------------------------------------------------
2021-05-27 21:30:12,827 EPOCH 4 done: loss 1.3269 - lr 0.1000000
2021-05-27 21:30:13,916 DEV : loss 1.2549089193344116 - score 0.8412
2021-05-27 21:30:13,935 BAD EPOCHS (no improvement): 1
2021-05-27 21:30:13,935 ----------------------------------------------------------------------------------------------------
2021-05-27 21:30:14,964 epoch 5 - iter 2/28 - loss 0.89274180 - samples/sec: 62.26 - lr: 0.100000
2021-05-27 21:30:16,006 epoch 5 - iter 4/28 - loss 0.89769180 - samples/sec: 61.42 - lr: 0.100000
2021-05-27 21:30:17,047 epoch 5 - iter 6/28 - loss 0.84843253 - samples/sec: 61.51 - lr: 0.100000
2021-05-27 21:30:18,088 epoch 5 - iter 8/28 - loss 0.85094432 - samples/sec: 61.54 - lr: 0.100000
2021-05-27 21:30:19,158 epoch 5 - iter 10/28 - loss 0.87535477 - samples/sec: 59.80 - lr: 0.100000
2021-05-27 21:30:20,222 epoch 5 - iter 12/28 - loss 0.90322481 - samples/sec: 60.21 - lr: 0.100000
2021-05-27 21:30:21,271 epoch 5 - iter 14/28 - loss 0.91570236 - samples/sec: 61.01 - lr: 0.100000
2021-05-27 21:30:22,332 epoch 5 - iter 16/28 - loss 0.89164401 - samples/sec: 60.38 - lr: 0.100000
2021-05-27 21:30:23,373 epoch 5 - iter 18/28 - loss 0.88682313 - samples/sec: 61.49 - lr: 0.100000
2021-05-27 21:30:24,579 epoch 5 - iter 20/28 - loss 0.91469493 - samples/sec: 53.10 - lr: 0.100000
2021-05-27 21:30:25,635 epoch 5 - iter 22/28 - loss 0.92654289 - samples/sec: 60.62 - lr: 0.100000
2021-05-27 21:30:26,699 epoch 5 - iter 24/28 - loss 0.99650154 - samples/sec: 60.19 - lr: 0.100000
2021-05-27 21:30:27,758 epoch 5 - iter 26/28 - loss 1.02945349 - samples/sec: 60.46 - lr: 0.100000
2021-05-27 21:30:28,361 epoch 5 - iter 28/28 - loss 0.98748407 - samples/sec: 106.17 - lr: 0.100000
2021-05-27 21:30:28,361 ----------------------------------------------------------------------------------------------------
2021-05-27 21:30:28,361 EPOCH 5 done: loss 0.9875 - lr 0.1000000
2021-05-27 21:30:29,450 DEV : loss 1.0806076526641846 - score 0.8513
2021-05-27 21:30:29,469 BAD EPOCHS (no improvement): 2
2021-05-27 21:30:29,469 ----------------------------------------------------------------------------------------------------
2021-05-27 21:30:30,515 epoch 6 - iter 2/28 - loss 0.63865563 - samples/sec: 61.23 - lr: 0.100000
2021-05-27 21:30:31,547 epoch 6 - iter 4/28 - loss 0.58540803 - samples/sec: 62.03 - lr: 0.100000
2021-05-27 21:30:32,570 epoch 6 - iter 6/28 - loss 0.76151017 - samples/sec: 62.62 - lr: 0.100000
2021-05-27 21:30:33,647 epoch 6 - iter 8/28 - loss 0.80710050 - samples/sec: 59.45 - lr: 0.100000
2021-05-27 21:30:34,702 epoch 6 - iter 10/28 - loss 0.76650140 - samples/sec: 60.70 - lr: 0.100000
2021-05-27 21:30:35,773 epoch 6 - iter 12/28 - loss 0.86474033 - samples/sec: 59.80 - lr: 0.100000
2021-05-27 21:30:36,822 epoch 6 - iter 14/28 - loss 0.91544882 - samples/sec: 61.03 - lr: 0.100000
2021-05-27 21:30:37,877 epoch 6 - iter 16/28 - loss 0.91982873 - samples/sec: 60.68 - lr: 0.100000
2021-05-27 21:30:38,924 epoch 6 - iter 18/28 - loss 0.90851194 - samples/sec: 61.14 - lr: 0.100000
2021-05-27 21:30:39,984 epoch 6 - iter 20/28 - loss 0.91020553 - samples/sec: 60.43 - lr: 0.100000
2021-05-27 21:30:41,053 epoch 6 - iter 22/28 - loss 0.91487566 - samples/sec: 59.89 - lr: 0.100000
2021-05-27 21:30:42,091 epoch 6 - iter 24/28 - loss 0.95768809 - samples/sec: 61.66 - lr: 0.100000
2021-05-27 21:30:43,156 epoch 6 - iter 26/28 - loss 0.96292930 - samples/sec: 60.16 - lr: 0.100000
2021-05-27 21:30:43,765 epoch 6 - iter 28/28 - loss 0.95394389 - samples/sec: 105.15 - lr: 0.100000
2021-05-27 21:30:43,765 ----------------------------------------------------------------------------------------------------
2021-05-27 21:30:43,765 EPOCH 6 done: loss 0.9539 - lr 0.1000000
2021-05-27 21:30:44,852 DEV : loss 0.6529784202575684 - score 0.9178
2021-05-27 21:30:44,871 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:30:53,320 ----------------------------------------------------------------------------------------------------
2021-05-27 21:30:54,375 epoch 7 - iter 2/28 - loss 1.22661293 - samples/sec: 60.69 - lr: 0.100000
2021-05-27 21:30:55,419 epoch 7 - iter 4/28 - loss 1.02358148 - samples/sec: 61.35 - lr: 0.100000
2021-05-27 21:30:56,455 epoch 7 - iter 6/28 - loss 1.09121392 - samples/sec: 61.77 - lr: 0.100000
2021-05-27 21:30:57,525 epoch 7 - iter 8/28 - loss 1.04814859 - samples/sec: 59.85 - lr: 0.100000
2021-05-27 21:30:58,593 epoch 7 - iter 10/28 - loss 1.04899789 - samples/sec: 59.96 - lr: 0.100000
2021-05-27 21:30:59,648 epoch 7 - iter 12/28 - loss 0.98846603 - samples/sec: 60.72 - lr: 0.100000
2021-05-27 21:31:00,696 epoch 7 - iter 14/28 - loss 0.94145327 - samples/sec: 61.08 - lr: 0.100000
2021-05-27 21:31:01,763 epoch 7 - iter 16/28 - loss 0.89453388 - samples/sec: 60.01 - lr: 0.100000
2021-05-27 21:31:02,801 epoch 7 - iter 18/28 - loss 0.92449308 - samples/sec: 61.70 - lr: 0.100000
2021-05-27 21:31:03,841 epoch 7 - iter 20/28 - loss 0.90126127 - samples/sec: 61.55 - lr: 0.100000
2021-05-27 21:31:04,886 epoch 7 - iter 22/28 - loss 0.91592216 - samples/sec: 61.32 - lr: 0.100000
2021-05-27 21:31:05,926 epoch 7 - iter 24/28 - loss 0.90536292 - samples/sec: 61.53 - lr: 0.100000
2021-05-27 21:31:06,977 epoch 7 - iter 26/28 - loss 0.89843801 - samples/sec: 60.96 - lr: 0.100000
2021-05-27 21:31:07,573 epoch 7 - iter 28/28 - loss 0.89579713 - samples/sec: 107.32 - lr: 0.100000
2021-05-27 21:31:07,574 ----------------------------------------------------------------------------------------------------
2021-05-27 21:31:07,574 EPOCH 7 done: loss 0.8958 - lr 0.1000000
2021-05-27 21:31:08,663 DEV : loss 0.7798709869384766 - score 0.9117
2021-05-27 21:31:08,682 BAD EPOCHS (no improvement): 1
2021-05-27 21:31:08,682 ----------------------------------------------------------------------------------------------------
2021-05-27 21:31:09,702 epoch 8 - iter 2/28 - loss 1.00210083 - samples/sec: 62.78 - lr: 0.100000
2021-05-27 21:31:10,760 epoch 8 - iter 4/28 - loss 0.85629688 - samples/sec: 60.55 - lr: 0.100000
2021-05-27 21:31:11,807 epoch 8 - iter 6/28 - loss 1.08874285 - samples/sec: 61.14 - lr: 0.100000
2021-05-27 21:31:12,841 epoch 8 - iter 8/28 - loss 1.04116559 - samples/sec: 61.90 - lr: 0.100000
2021-05-27 21:31:13,884 epoch 8 - iter 10/28 - loss 0.92624621 - samples/sec: 61.44 - lr: 0.100000
2021-05-27 21:31:14,926 epoch 8 - iter 12/28 - loss 0.87774084 - samples/sec: 61.42 - lr: 0.100000
2021-05-27 21:31:15,969 epoch 8 - iter 14/28 - loss 0.88724872 - samples/sec: 61.40 - lr: 0.100000
2021-05-27 21:31:17,016 epoch 8 - iter 16/28 - loss 0.85091767 - samples/sec: 61.15 - lr: 0.100000
2021-05-27 21:31:18,067 epoch 8 - iter 18/28 - loss 0.85390542 - samples/sec: 60.95 - lr: 0.100000
2021-05-27 21:31:19,277 epoch 8 - iter 20/28 - loss 0.90461945 - samples/sec: 52.90 - lr: 0.100000
2021-05-27 21:31:20,332 epoch 8 - iter 22/28 - loss 0.87948043 - samples/sec: 60.67 - lr: 0.100000
2021-05-27 21:31:21,380 epoch 8 - iter 24/28 - loss 0.86475375 - samples/sec: 61.12 - lr: 0.100000
2021-05-27 21:31:22,408 epoch 8 - iter 26/28 - loss 0.86938822 - samples/sec: 62.26 - lr: 0.100000
2021-05-27 21:31:23,015 epoch 8 - iter 28/28 - loss 0.82983782 - samples/sec: 105.62 - lr: 0.100000
2021-05-27 21:31:23,015 ----------------------------------------------------------------------------------------------------
2021-05-27 21:31:23,015 EPOCH 8 done: loss 0.8298 - lr 0.1000000
2021-05-27 21:31:24,103 DEV : loss 0.6769721508026123 - score 0.9253
2021-05-27 21:31:24,122 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:31:33,067 ----------------------------------------------------------------------------------------------------
2021-05-27 21:31:34,097 epoch 9 - iter 2/28 - loss 0.79633296 - samples/sec: 62.22 - lr: 0.100000
2021-05-27 21:31:35,144 epoch 9 - iter 4/28 - loss 0.90143701 - samples/sec: 61.17 - lr: 0.100000
2021-05-27 21:31:36,191 epoch 9 - iter 6/28 - loss 1.01171442 - samples/sec: 61.14 - lr: 0.100000
2021-05-27 21:31:37,247 epoch 9 - iter 8/28 - loss 1.01120710 - samples/sec: 60.65 - lr: 0.100000
2021-05-27 21:31:38,315 epoch 9 - iter 10/28 - loss 0.91047487 - samples/sec: 59.96 - lr: 0.100000
2021-05-27 21:31:39,364 epoch 9 - iter 12/28 - loss 0.87253833 - samples/sec: 61.05 - lr: 0.100000
2021-05-27 21:31:40,427 epoch 9 - iter 14/28 - loss 0.87498606 - samples/sec: 60.23 - lr: 0.100000
2021-05-27 21:31:41,489 epoch 9 - iter 16/28 - loss 0.90195983 - samples/sec: 60.27 - lr: 0.100000
2021-05-27 21:31:42,531 epoch 9 - iter 18/28 - loss 0.91265517 - samples/sec: 61.48 - lr: 0.100000
2021-05-27 21:31:43,576 epoch 9 - iter 20/28 - loss 0.87584478 - samples/sec: 61.24 - lr: 0.100000
2021-05-27 21:31:44,618 epoch 9 - iter 22/28 - loss 0.87475950 - samples/sec: 61.49 - lr: 0.100000
2021-05-27 21:31:45,637 epoch 9 - iter 24/28 - loss 0.89399052 - samples/sec: 62.80 - lr: 0.100000
2021-05-27 21:31:46,656 epoch 9 - iter 26/28 - loss 0.87352490 - samples/sec: 62.85 - lr: 0.100000
2021-05-27 21:31:47,248 epoch 9 - iter 28/28 - loss 0.82944309 - samples/sec: 108.20 - lr: 0.100000
2021-05-27 21:31:47,249 ----------------------------------------------------------------------------------------------------
2021-05-27 21:31:47,249 EPOCH 9 done: loss 0.8294 - lr 0.1000000
2021-05-27 21:31:48,335 DEV : loss 0.809388279914856 - score 0.9015
2021-05-27 21:31:48,353 BAD EPOCHS (no improvement): 1
2021-05-27 21:31:48,354 ----------------------------------------------------------------------------------------------------
2021-05-27 21:31:49,375 epoch 10 - iter 2/28 - loss 0.61263061 - samples/sec: 62.70 - lr: 0.100000
2021-05-27 21:31:50,395 epoch 10 - iter 4/28 - loss 0.54032576 - samples/sec: 62.80 - lr: 0.100000
2021-05-27 21:31:51,406 epoch 10 - iter 6/28 - loss 0.59032040 - samples/sec: 63.32 - lr: 0.100000
2021-05-27 21:31:52,438 epoch 10 - iter 8/28 - loss 0.64056210 - samples/sec: 62.04 - lr: 0.100000
2021-05-27 21:31:53,480 epoch 10 - iter 10/28 - loss 0.68528067 - samples/sec: 61.46 - lr: 0.100000
2021-05-27 21:31:54,541 epoch 10 - iter 12/28 - loss 0.77401361 - samples/sec: 60.32 - lr: 0.100000
2021-05-27 21:31:55,614 epoch 10 - iter 14/28 - loss 0.84397768 - samples/sec: 59.69 - lr: 0.100000
2021-05-27 21:31:56,656 epoch 10 - iter 16/28 - loss 0.88748618 - samples/sec: 61.48 - lr: 0.100000
2021-05-27 21:31:57,706 epoch 10 - iter 18/28 - loss 0.91033054 - samples/sec: 60.94 - lr: 0.100000
2021-05-27 21:31:58,723 epoch 10 - iter 20/28 - loss 0.88716392 - samples/sec: 62.98 - lr: 0.100000
2021-05-27 21:31:59,760 epoch 10 - iter 22/28 - loss 0.86294250 - samples/sec: 61.75 - lr: 0.100000
2021-05-27 21:32:00,814 epoch 10 - iter 24/28 - loss 0.88993034 - samples/sec: 60.76 - lr: 0.100000
2021-05-27 21:32:01,861 epoch 10 - iter 26/28 - loss 0.87647916 - samples/sec: 61.16 - lr: 0.100000
2021-05-27 21:32:02,452 epoch 10 - iter 28/28 - loss 0.83549614 - samples/sec: 108.31 - lr: 0.100000
2021-05-27 21:32:02,452 ----------------------------------------------------------------------------------------------------
2021-05-27 21:32:02,453 EPOCH 10 done: loss 0.8355 - lr 0.1000000
2021-05-27 21:32:03,545 DEV : loss 0.6888870596885681 - score 0.9061
2021-05-27 21:32:03,564 BAD EPOCHS (no improvement): 2
2021-05-27 21:32:03,564 ----------------------------------------------------------------------------------------------------
2021-05-27 21:32:04,578 epoch 11 - iter 2/28 - loss 0.49797547 - samples/sec: 63.18 - lr: 0.100000
2021-05-27 21:32:05,613 epoch 11 - iter 4/28 - loss 0.83950260 - samples/sec: 61.86 - lr: 0.100000
2021-05-27 21:32:06,636 epoch 11 - iter 6/28 - loss 0.86968955 - samples/sec: 62.62 - lr: 0.100000
2021-05-27 21:32:07,660 epoch 11 - iter 8/28 - loss 0.72624211 - samples/sec: 62.48 - lr: 0.100000
2021-05-27 21:32:08,710 epoch 11 - iter 10/28 - loss 0.67244569 - samples/sec: 60.98 - lr: 0.100000
2021-05-27 21:32:09,751 epoch 11 - iter 12/28 - loss 0.73980253 - samples/sec: 61.53 - lr: 0.100000
2021-05-27 21:32:10,783 epoch 11 - iter 14/28 - loss 0.76942193 - samples/sec: 62.04 - lr: 0.100000
2021-05-27 21:32:11,822 epoch 11 - iter 16/28 - loss 0.77694478 - samples/sec: 61.64 - lr: 0.100000
2021-05-27 21:32:12,870 epoch 11 - iter 18/28 - loss 0.72111443 - samples/sec: 61.09 - lr: 0.100000
2021-05-27 21:32:13,946 epoch 11 - iter 20/28 - loss 0.74969209 - samples/sec: 59.52 - lr: 0.100000
2021-05-27 21:32:15,012 epoch 11 - iter 22/28 - loss 0.73781465 - samples/sec: 60.04 - lr: 0.100000
2021-05-27 21:32:16,082 epoch 11 - iter 24/28 - loss 0.74439576 - samples/sec: 59.88 - lr: 0.100000
2021-05-27 21:32:17,128 epoch 11 - iter 26/28 - loss 0.72626814 - samples/sec: 61.20 - lr: 0.100000
2021-05-27 21:32:17,715 epoch 11 - iter 28/28 - loss 0.69804338 - samples/sec: 109.19 - lr: 0.100000
2021-05-27 21:32:17,715 ----------------------------------------------------------------------------------------------------
2021-05-27 21:32:17,715 EPOCH 11 done: loss 0.6980 - lr 0.1000000
2021-05-27 21:32:18,804 DEV : loss 0.6545508503913879 - score 0.9139
2021-05-27 21:32:18,823 BAD EPOCHS (no improvement): 3
2021-05-27 21:32:18,823 ----------------------------------------------------------------------------------------------------
2021-05-27 21:32:19,836 epoch 12 - iter 2/28 - loss 0.48336527 - samples/sec: 63.22 - lr: 0.100000
2021-05-27 21:32:20,893 epoch 12 - iter 4/28 - loss 0.81680852 - samples/sec: 60.59 - lr: 0.100000
2021-05-27 21:32:21,941 epoch 12 - iter 6/28 - loss 0.79512965 - samples/sec: 61.11 - lr: 0.100000
2021-05-27 21:32:22,967 epoch 12 - iter 8/28 - loss 0.70733500 - samples/sec: 62.38 - lr: 0.100000
2021-05-27 21:32:24,026 epoch 12 - iter 10/28 - loss 0.81691801 - samples/sec: 60.48 - lr: 0.100000
2021-05-27 21:32:25,061 epoch 12 - iter 12/28 - loss 0.83173259 - samples/sec: 61.84 - lr: 0.100000
2021-05-27 21:32:26,124 epoch 12 - iter 14/28 - loss 0.82008835 - samples/sec: 60.25 - lr: 0.100000
2021-05-27 21:32:27,152 epoch 12 - iter 16/28 - loss 0.77147874 - samples/sec: 62.27 - lr: 0.100000
2021-05-27 21:32:28,214 epoch 12 - iter 18/28 - loss 0.80093878 - samples/sec: 60.31 - lr: 0.100000
2021-05-27 21:32:29,240 epoch 12 - iter 20/28 - loss 0.84310015 - samples/sec: 62.42 - lr: 0.100000
2021-05-27 21:32:30,298 epoch 12 - iter 22/28 - loss 0.82788632 - samples/sec: 60.52 - lr: 0.100000
2021-05-27 21:32:31,350 epoch 12 - iter 24/28 - loss 0.82795266 - samples/sec: 60.84 - lr: 0.100000
2021-05-27 21:32:32,409 epoch 12 - iter 26/28 - loss 0.81272192 - samples/sec: 60.49 - lr: 0.100000
2021-05-27 21:32:33,017 epoch 12 - iter 28/28 - loss 0.79032193 - samples/sec: 105.24 - lr: 0.100000
2021-05-27 21:32:33,018 ----------------------------------------------------------------------------------------------------
2021-05-27 21:32:33,018 EPOCH 12 done: loss 0.7903 - lr 0.1000000
2021-05-27 21:32:34,243 DEV : loss 0.9918758273124695 - score 0.8845
Epoch    12: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 21:32:34,263 BAD EPOCHS (no improvement): 4
2021-05-27 21:32:34,263 ----------------------------------------------------------------------------------------------------
2021-05-27 21:32:35,303 epoch 13 - iter 2/28 - loss 0.66809094 - samples/sec: 61.56 - lr: 0.050000
2021-05-27 21:32:36,345 epoch 13 - iter 4/28 - loss 0.69762811 - samples/sec: 61.43 - lr: 0.050000
2021-05-27 21:32:37,379 epoch 13 - iter 6/28 - loss 0.56524643 - samples/sec: 61.93 - lr: 0.050000
2021-05-27 21:32:38,459 epoch 13 - iter 8/28 - loss 0.54954452 - samples/sec: 59.31 - lr: 0.050000
2021-05-27 21:32:39,498 epoch 13 - iter 10/28 - loss 0.61881495 - samples/sec: 61.59 - lr: 0.050000
2021-05-27 21:32:40,556 epoch 13 - iter 12/28 - loss 0.55971762 - samples/sec: 60.56 - lr: 0.050000
2021-05-27 21:32:41,604 epoch 13 - iter 14/28 - loss 0.59402028 - samples/sec: 61.07 - lr: 0.050000
2021-05-27 21:32:42,672 epoch 13 - iter 16/28 - loss 0.57217638 - samples/sec: 59.97 - lr: 0.050000
2021-05-27 21:32:43,724 epoch 13 - iter 18/28 - loss 0.58272540 - samples/sec: 60.85 - lr: 0.050000
2021-05-27 21:32:44,780 epoch 13 - iter 20/28 - loss 0.58951969 - samples/sec: 60.65 - lr: 0.050000
2021-05-27 21:32:45,828 epoch 13 - iter 22/28 - loss 0.58627503 - samples/sec: 61.13 - lr: 0.050000
2021-05-27 21:32:46,861 epoch 13 - iter 24/28 - loss 0.56476933 - samples/sec: 61.94 - lr: 0.050000
2021-05-27 21:32:47,907 epoch 13 - iter 26/28 - loss 0.55003977 - samples/sec: 61.23 - lr: 0.050000
2021-05-27 21:32:48,523 epoch 13 - iter 28/28 - loss 0.54245542 - samples/sec: 104.05 - lr: 0.050000
2021-05-27 21:32:48,523 ----------------------------------------------------------------------------------------------------
2021-05-27 21:32:48,523 EPOCH 13 done: loss 0.5425 - lr 0.0500000
2021-05-27 21:32:49,611 DEV : loss 0.8546513915061951 - score 0.9101
2021-05-27 21:32:49,630 BAD EPOCHS (no improvement): 1
2021-05-27 21:32:49,630 ----------------------------------------------------------------------------------------------------
2021-05-27 21:32:50,677 epoch 14 - iter 2/28 - loss 0.49409461 - samples/sec: 61.15 - lr: 0.050000
2021-05-27 21:32:51,732 epoch 14 - iter 4/28 - loss 0.67245883 - samples/sec: 60.71 - lr: 0.050000
2021-05-27 21:32:52,795 epoch 14 - iter 6/28 - loss 0.55788085 - samples/sec: 60.20 - lr: 0.050000
2021-05-27 21:32:53,857 epoch 14 - iter 8/28 - loss 0.57747529 - samples/sec: 60.28 - lr: 0.050000
2021-05-27 21:32:54,901 epoch 14 - iter 10/28 - loss 0.60562203 - samples/sec: 61.38 - lr: 0.050000
2021-05-27 21:32:55,960 epoch 14 - iter 12/28 - loss 0.55448347 - samples/sec: 60.42 - lr: 0.050000
2021-05-27 21:32:56,990 epoch 14 - iter 14/28 - loss 0.53317649 - samples/sec: 62.19 - lr: 0.050000
2021-05-27 21:32:58,013 epoch 14 - iter 16/28 - loss 0.51028772 - samples/sec: 62.57 - lr: 0.050000
2021-05-27 21:32:59,058 epoch 14 - iter 18/28 - loss 0.55070063 - samples/sec: 61.32 - lr: 0.050000
2021-05-27 21:33:00,103 epoch 14 - iter 20/28 - loss 0.54665423 - samples/sec: 61.23 - lr: 0.050000
2021-05-27 21:33:01,156 epoch 14 - iter 22/28 - loss 0.54284133 - samples/sec: 60.80 - lr: 0.050000
2021-05-27 21:33:02,236 epoch 14 - iter 24/28 - loss 0.52687454 - samples/sec: 59.34 - lr: 0.050000
2021-05-27 21:33:03,279 epoch 14 - iter 26/28 - loss 0.51963292 - samples/sec: 61.36 - lr: 0.050000
2021-05-27 21:33:03,886 epoch 14 - iter 28/28 - loss 0.50718739 - samples/sec: 105.53 - lr: 0.050000
2021-05-27 21:33:03,886 ----------------------------------------------------------------------------------------------------
2021-05-27 21:33:03,886 EPOCH 14 done: loss 0.5072 - lr 0.0500000
2021-05-27 21:33:04,974 DEV : loss 1.1479978561401367 - score 0.8547
2021-05-27 21:33:04,993 BAD EPOCHS (no improvement): 2
2021-05-27 21:33:04,993 ----------------------------------------------------------------------------------------------------
2021-05-27 21:33:06,043 epoch 15 - iter 2/28 - loss 0.26203430 - samples/sec: 60.99 - lr: 0.050000
2021-05-27 21:33:07,094 epoch 15 - iter 4/28 - loss 0.50882031 - samples/sec: 60.90 - lr: 0.050000
2021-05-27 21:33:08,158 epoch 15 - iter 6/28 - loss 0.63335577 - samples/sec: 60.19 - lr: 0.050000
2021-05-27 21:33:09,195 epoch 15 - iter 8/28 - loss 0.56531701 - samples/sec: 61.77 - lr: 0.050000
2021-05-27 21:33:10,233 epoch 15 - iter 10/28 - loss 0.51070520 - samples/sec: 61.68 - lr: 0.050000
2021-05-27 21:33:11,256 epoch 15 - iter 12/28 - loss 0.50361520 - samples/sec: 62.56 - lr: 0.050000
2021-05-27 21:33:12,313 epoch 15 - iter 14/28 - loss 0.48721098 - samples/sec: 60.60 - lr: 0.050000
2021-05-27 21:33:13,373 epoch 15 - iter 16/28 - loss 0.48224454 - samples/sec: 60.37 - lr: 0.050000
2021-05-27 21:33:14,426 epoch 15 - iter 18/28 - loss 0.48603091 - samples/sec: 60.82 - lr: 0.050000
2021-05-27 21:33:15,482 epoch 15 - iter 20/28 - loss 0.50993596 - samples/sec: 60.68 - lr: 0.050000
2021-05-27 21:33:16,501 epoch 15 - iter 22/28 - loss 0.49171234 - samples/sec: 62.81 - lr: 0.050000
2021-05-27 21:33:17,556 epoch 15 - iter 24/28 - loss 0.52055420 - samples/sec: 60.69 - lr: 0.050000
2021-05-27 21:33:18,624 epoch 15 - iter 26/28 - loss 0.53609616 - samples/sec: 59.92 - lr: 0.050000
2021-05-27 21:33:19,228 epoch 15 - iter 28/28 - loss 0.52139203 - samples/sec: 106.16 - lr: 0.050000
2021-05-27 21:33:19,228 ----------------------------------------------------------------------------------------------------
2021-05-27 21:33:19,228 EPOCH 15 done: loss 0.5214 - lr 0.0500000
2021-05-27 21:33:20,315 DEV : loss 0.7807892560958862 - score 0.9035
2021-05-27 21:33:20,334 BAD EPOCHS (no improvement): 3
2021-05-27 21:33:20,334 ----------------------------------------------------------------------------------------------------
2021-05-27 21:33:21,372 epoch 16 - iter 2/28 - loss 0.48737878 - samples/sec: 61.68 - lr: 0.050000
2021-05-27 21:33:22,427 epoch 16 - iter 4/28 - loss 0.58918080 - samples/sec: 60.73 - lr: 0.050000
2021-05-27 21:33:23,466 epoch 16 - iter 6/28 - loss 0.52079253 - samples/sec: 61.60 - lr: 0.050000
2021-05-27 21:33:24,522 epoch 16 - iter 8/28 - loss 0.50984295 - samples/sec: 60.65 - lr: 0.050000
2021-05-27 21:33:25,580 epoch 16 - iter 10/28 - loss 0.55096464 - samples/sec: 60.52 - lr: 0.050000
2021-05-27 21:33:26,600 epoch 16 - iter 12/28 - loss 0.53950658 - samples/sec: 62.81 - lr: 0.050000
2021-05-27 21:33:27,653 epoch 16 - iter 14/28 - loss 0.54182916 - samples/sec: 60.77 - lr: 0.050000
2021-05-27 21:33:28,722 epoch 16 - iter 16/28 - loss 0.55010978 - samples/sec: 59.90 - lr: 0.050000
2021-05-27 21:33:29,782 epoch 16 - iter 18/28 - loss 0.54296056 - samples/sec: 60.44 - lr: 0.050000
2021-05-27 21:33:30,978 epoch 16 - iter 20/28 - loss 0.52105490 - samples/sec: 53.50 - lr: 0.050000
2021-05-27 21:33:32,020 epoch 16 - iter 22/28 - loss 0.52150949 - samples/sec: 61.45 - lr: 0.050000
2021-05-27 21:33:33,055 epoch 16 - iter 24/28 - loss 0.51168933 - samples/sec: 61.88 - lr: 0.050000
2021-05-27 21:33:34,112 epoch 16 - iter 26/28 - loss 0.51263008 - samples/sec: 60.56 - lr: 0.050000
2021-05-27 21:33:34,710 epoch 16 - iter 28/28 - loss 0.48642954 - samples/sec: 107.19 - lr: 0.050000
2021-05-27 21:33:34,710 ----------------------------------------------------------------------------------------------------
2021-05-27 21:33:34,710 EPOCH 16 done: loss 0.4864 - lr 0.0500000
2021-05-27 21:33:35,802 DEV : loss 0.7310397624969482 - score 0.9114
Epoch    16: reducing learning rate of group 0 to 2.5000e-02.
2021-05-27 21:33:35,821 BAD EPOCHS (no improvement): 4
2021-05-27 21:33:35,821 ----------------------------------------------------------------------------------------------------
2021-05-27 21:33:36,869 epoch 17 - iter 2/28 - loss 0.59078300 - samples/sec: 61.12 - lr: 0.025000
2021-05-27 21:33:37,937 epoch 17 - iter 4/28 - loss 0.48404050 - samples/sec: 59.95 - lr: 0.025000
2021-05-27 21:33:38,992 epoch 17 - iter 6/28 - loss 0.38152130 - samples/sec: 60.66 - lr: 0.025000
2021-05-27 21:33:40,052 epoch 17 - iter 8/28 - loss 0.41786325 - samples/sec: 60.44 - lr: 0.025000
2021-05-27 21:33:41,110 epoch 17 - iter 10/28 - loss 0.43314077 - samples/sec: 60.49 - lr: 0.025000
2021-05-27 21:33:42,165 epoch 17 - iter 12/28 - loss 0.47683491 - samples/sec: 60.73 - lr: 0.025000
2021-05-27 21:33:43,215 epoch 17 - iter 14/28 - loss 0.46100828 - samples/sec: 60.96 - lr: 0.025000
2021-05-27 21:33:44,251 epoch 17 - iter 16/28 - loss 0.50209146 - samples/sec: 61.79 - lr: 0.025000
2021-05-27 21:33:45,305 epoch 17 - iter 18/28 - loss 0.52410971 - samples/sec: 60.74 - lr: 0.025000
2021-05-27 21:33:46,332 epoch 17 - iter 20/28 - loss 0.49834696 - samples/sec: 62.40 - lr: 0.025000
2021-05-27 21:33:47,372 epoch 17 - iter 22/28 - loss 0.49183628 - samples/sec: 61.54 - lr: 0.025000
2021-05-27 21:33:48,429 epoch 17 - iter 24/28 - loss 0.49515842 - samples/sec: 60.59 - lr: 0.025000
2021-05-27 21:33:49,464 epoch 17 - iter 26/28 - loss 0.48574815 - samples/sec: 61.88 - lr: 0.025000
2021-05-27 21:33:50,057 epoch 17 - iter 28/28 - loss 0.46176614 - samples/sec: 107.92 - lr: 0.025000
2021-05-27 21:33:50,057 ----------------------------------------------------------------------------------------------------
2021-05-27 21:33:50,058 EPOCH 17 done: loss 0.4618 - lr 0.0250000
2021-05-27 21:33:51,145 DEV : loss 0.870147705078125 - score 0.8857
2021-05-27 21:33:51,164 BAD EPOCHS (no improvement): 1
2021-05-27 21:33:51,164 ----------------------------------------------------------------------------------------------------
2021-05-27 21:33:52,202 epoch 18 - iter 2/28 - loss 0.60236239 - samples/sec: 61.69 - lr: 0.025000
2021-05-27 21:33:53,250 epoch 18 - iter 4/28 - loss 0.47511254 - samples/sec: 61.11 - lr: 0.025000
2021-05-27 21:33:54,305 epoch 18 - iter 6/28 - loss 0.59436881 - samples/sec: 60.68 - lr: 0.025000
2021-05-27 21:33:55,338 epoch 18 - iter 8/28 - loss 0.55197603 - samples/sec: 61.97 - lr: 0.025000
2021-05-27 21:33:56,377 epoch 18 - iter 10/28 - loss 0.47684033 - samples/sec: 61.63 - lr: 0.025000
2021-05-27 21:33:57,424 epoch 18 - iter 12/28 - loss 0.42492342 - samples/sec: 61.15 - lr: 0.025000
2021-05-27 21:33:58,424 epoch 18 - iter 14/28 - loss 0.41740809 - samples/sec: 64.06 - lr: 0.025000
2021-05-27 21:33:59,463 epoch 18 - iter 16/28 - loss 0.47719512 - samples/sec: 61.61 - lr: 0.025000
2021-05-27 21:34:00,507 epoch 18 - iter 18/28 - loss 0.47597219 - samples/sec: 61.34 - lr: 0.025000
2021-05-27 21:34:01,579 epoch 18 - iter 20/28 - loss 0.45088153 - samples/sec: 59.73 - lr: 0.025000
2021-05-27 21:34:02,658 epoch 18 - iter 22/28 - loss 0.44883572 - samples/sec: 59.34 - lr: 0.025000
2021-05-27 21:34:03,707 epoch 18 - iter 24/28 - loss 0.44993360 - samples/sec: 61.08 - lr: 0.025000
2021-05-27 21:34:04,763 epoch 18 - iter 26/28 - loss 0.44165966 - samples/sec: 60.59 - lr: 0.025000
2021-05-27 21:34:05,365 epoch 18 - iter 28/28 - loss 0.43172343 - samples/sec: 106.40 - lr: 0.025000
2021-05-27 21:34:05,366 ----------------------------------------------------------------------------------------------------
2021-05-27 21:34:05,366 EPOCH 18 done: loss 0.4317 - lr 0.0250000
2021-05-27 21:34:06,462 DEV : loss 1.1206028461456299 - score 0.8557
2021-05-27 21:34:06,481 BAD EPOCHS (no improvement): 2
2021-05-27 21:34:06,481 ----------------------------------------------------------------------------------------------------
2021-05-27 21:34:07,505 epoch 19 - iter 2/28 - loss 0.53707585 - samples/sec: 62.49 - lr: 0.025000
2021-05-27 21:34:08,561 epoch 19 - iter 4/28 - loss 0.39670520 - samples/sec: 60.66 - lr: 0.025000
2021-05-27 21:34:09,625 epoch 19 - iter 6/28 - loss 0.43683820 - samples/sec: 60.15 - lr: 0.025000
2021-05-27 21:34:10,695 epoch 19 - iter 8/28 - loss 0.44905902 - samples/sec: 59.85 - lr: 0.025000
2021-05-27 21:34:11,749 epoch 19 - iter 10/28 - loss 0.43424666 - samples/sec: 60.77 - lr: 0.025000
2021-05-27 21:34:12,798 epoch 19 - iter 12/28 - loss 0.51895034 - samples/sec: 61.04 - lr: 0.025000
2021-05-27 21:34:13,853 epoch 19 - iter 14/28 - loss 0.50565639 - samples/sec: 60.70 - lr: 0.025000
2021-05-27 21:34:14,914 epoch 19 - iter 16/28 - loss 0.50183449 - samples/sec: 60.32 - lr: 0.025000
2021-05-27 21:34:15,955 epoch 19 - iter 18/28 - loss 0.46586597 - samples/sec: 61.50 - lr: 0.025000
2021-05-27 21:34:17,016 epoch 19 - iter 20/28 - loss 0.45304118 - samples/sec: 60.35 - lr: 0.025000
2021-05-27 21:34:18,217 epoch 19 - iter 22/28 - loss 0.46651151 - samples/sec: 53.32 - lr: 0.025000
2021-05-27 21:34:19,243 epoch 19 - iter 24/28 - loss 0.44909552 - samples/sec: 62.46 - lr: 0.025000
2021-05-27 21:34:20,289 epoch 19 - iter 26/28 - loss 0.46020842 - samples/sec: 61.19 - lr: 0.025000
2021-05-27 21:34:20,897 epoch 19 - iter 28/28 - loss 0.46515313 - samples/sec: 105.37 - lr: 0.025000
2021-05-27 21:34:20,897 ----------------------------------------------------------------------------------------------------
2021-05-27 21:34:20,897 EPOCH 19 done: loss 0.4652 - lr 0.0250000
2021-05-27 21:34:21,984 DEV : loss 0.7872011065483093 - score 0.8969
2021-05-27 21:34:22,003 BAD EPOCHS (no improvement): 3
2021-05-27 21:34:22,003 ----------------------------------------------------------------------------------------------------
2021-05-27 21:34:23,021 epoch 20 - iter 2/28 - loss 0.48623881 - samples/sec: 62.89 - lr: 0.025000
2021-05-27 21:34:24,090 epoch 20 - iter 4/28 - loss 0.44275092 - samples/sec: 59.93 - lr: 0.025000
2021-05-27 21:34:25,143 epoch 20 - iter 6/28 - loss 0.36304657 - samples/sec: 60.77 - lr: 0.025000
2021-05-27 21:34:26,190 epoch 20 - iter 8/28 - loss 0.34954081 - samples/sec: 61.16 - lr: 0.025000
2021-05-27 21:34:27,243 epoch 20 - iter 10/28 - loss 0.35291400 - samples/sec: 60.81 - lr: 0.025000
2021-05-27 21:34:28,312 epoch 20 - iter 12/28 - loss 0.36047169 - samples/sec: 59.94 - lr: 0.025000
2021-05-27 21:34:29,345 epoch 20 - iter 14/28 - loss 0.40739013 - samples/sec: 61.99 - lr: 0.025000
2021-05-27 21:34:30,420 epoch 20 - iter 16/28 - loss 0.40146263 - samples/sec: 59.56 - lr: 0.025000
2021-05-27 21:34:31,429 epoch 20 - iter 18/28 - loss 0.41196195 - samples/sec: 63.43 - lr: 0.025000
2021-05-27 21:34:32,482 epoch 20 - iter 20/28 - loss 0.39595968 - samples/sec: 60.81 - lr: 0.025000
2021-05-27 21:34:33,515 epoch 20 - iter 22/28 - loss 0.41769345 - samples/sec: 61.99 - lr: 0.025000
2021-05-27 21:34:34,575 epoch 20 - iter 24/28 - loss 0.40702801 - samples/sec: 60.43 - lr: 0.025000
2021-05-27 21:34:35,641 epoch 20 - iter 26/28 - loss 0.41728543 - samples/sec: 60.03 - lr: 0.025000
2021-05-27 21:34:36,260 epoch 20 - iter 28/28 - loss 0.40705656 - samples/sec: 103.55 - lr: 0.025000
2021-05-27 21:34:36,260 ----------------------------------------------------------------------------------------------------
2021-05-27 21:34:36,260 EPOCH 20 done: loss 0.4071 - lr 0.0250000
2021-05-27 21:34:37,347 DEV : loss 0.9684441089630127 - score 0.8611
Epoch    20: reducing learning rate of group 0 to 1.2500e-02.
2021-05-27 21:34:37,366 BAD EPOCHS (no improvement): 4
2021-05-27 21:34:37,366 ----------------------------------------------------------------------------------------------------
2021-05-27 21:34:38,414 epoch 21 - iter 2/28 - loss 0.41471791 - samples/sec: 61.13 - lr: 0.012500
2021-05-27 21:34:39,440 epoch 21 - iter 4/28 - loss 0.42429326 - samples/sec: 62.41 - lr: 0.012500
2021-05-27 21:34:40,497 epoch 21 - iter 6/28 - loss 0.44899367 - samples/sec: 60.55 - lr: 0.012500
2021-05-27 21:34:41,545 epoch 21 - iter 8/28 - loss 0.47633873 - samples/sec: 61.10 - lr: 0.012500
2021-05-27 21:34:42,613 epoch 21 - iter 10/28 - loss 0.44934582 - samples/sec: 60.00 - lr: 0.012500
2021-05-27 21:34:43,659 epoch 21 - iter 12/28 - loss 0.43798353 - samples/sec: 61.22 - lr: 0.012500
2021-05-27 21:34:44,684 epoch 21 - iter 14/28 - loss 0.42171103 - samples/sec: 62.44 - lr: 0.012500
2021-05-27 21:34:45,749 epoch 21 - iter 16/28 - loss 0.43085842 - samples/sec: 60.11 - lr: 0.012500
2021-05-27 21:34:46,814 epoch 21 - iter 18/28 - loss 0.40865655 - samples/sec: 60.14 - lr: 0.012500
2021-05-27 21:34:47,872 epoch 21 - iter 20/28 - loss 0.44195086 - samples/sec: 60.50 - lr: 0.012500
2021-05-27 21:34:48,906 epoch 21 - iter 22/28 - loss 0.43858856 - samples/sec: 61.96 - lr: 0.012500
2021-05-27 21:34:49,929 epoch 21 - iter 24/28 - loss 0.41388323 - samples/sec: 62.55 - lr: 0.012500
2021-05-27 21:34:50,964 epoch 21 - iter 26/28 - loss 0.39841782 - samples/sec: 61.90 - lr: 0.012500
2021-05-27 21:34:51,553 epoch 21 - iter 28/28 - loss 0.37719802 - samples/sec: 108.74 - lr: 0.012500
2021-05-27 21:34:51,553 ----------------------------------------------------------------------------------------------------
2021-05-27 21:34:51,553 EPOCH 21 done: loss 0.3772 - lr 0.0125000
2021-05-27 21:34:52,641 DEV : loss 0.8042765855789185 - score 0.9002
2021-05-27 21:34:52,660 BAD EPOCHS (no improvement): 1
2021-05-27 21:34:52,660 ----------------------------------------------------------------------------------------------------
2021-05-27 21:34:53,674 epoch 22 - iter 2/28 - loss 0.47860724 - samples/sec: 63.16 - lr: 0.012500
2021-05-27 21:34:54,725 epoch 22 - iter 4/28 - loss 0.42902057 - samples/sec: 60.92 - lr: 0.012500
2021-05-27 21:34:55,776 epoch 22 - iter 6/28 - loss 0.36990724 - samples/sec: 60.92 - lr: 0.012500
2021-05-27 21:34:56,847 epoch 22 - iter 8/28 - loss 0.35354705 - samples/sec: 59.80 - lr: 0.012500
2021-05-27 21:34:57,885 epoch 22 - iter 10/28 - loss 0.34553679 - samples/sec: 61.69 - lr: 0.012500
2021-05-27 21:34:58,943 epoch 22 - iter 12/28 - loss 0.38662177 - samples/sec: 60.52 - lr: 0.012500
2021-05-27 21:34:59,987 epoch 22 - iter 14/28 - loss 0.36368581 - samples/sec: 61.29 - lr: 0.012500
2021-05-27 21:35:01,031 epoch 22 - iter 16/28 - loss 0.36307008 - samples/sec: 61.39 - lr: 0.012500
2021-05-27 21:35:02,104 epoch 22 - iter 18/28 - loss 0.36445386 - samples/sec: 59.64 - lr: 0.012500
2021-05-27 21:35:03,157 epoch 22 - iter 20/28 - loss 0.39951205 - samples/sec: 60.83 - lr: 0.012500
2021-05-27 21:35:04,206 epoch 22 - iter 22/28 - loss 0.39971905 - samples/sec: 61.03 - lr: 0.012500
2021-05-27 21:35:05,230 epoch 22 - iter 24/28 - loss 0.40370274 - samples/sec: 62.51 - lr: 0.012500
2021-05-27 21:35:06,304 epoch 22 - iter 26/28 - loss 0.40498407 - samples/sec: 59.65 - lr: 0.012500
2021-05-27 21:35:06,902 epoch 22 - iter 28/28 - loss 0.38619347 - samples/sec: 107.03 - lr: 0.012500
2021-05-27 21:35:06,902 ----------------------------------------------------------------------------------------------------
2021-05-27 21:35:06,902 EPOCH 22 done: loss 0.3862 - lr 0.0125000
2021-05-27 21:35:07,990 DEV : loss 0.8636431694030762 - score 0.8889
2021-05-27 21:35:08,009 BAD EPOCHS (no improvement): 2
2021-05-27 21:35:08,009 ----------------------------------------------------------------------------------------------------
2021-05-27 21:35:09,063 epoch 23 - iter 2/28 - loss 0.22805989 - samples/sec: 60.76 - lr: 0.012500
2021-05-27 21:35:10,129 epoch 23 - iter 4/28 - loss 0.30299574 - samples/sec: 60.06 - lr: 0.012500
2021-05-27 21:35:11,193 epoch 23 - iter 6/28 - loss 0.32701794 - samples/sec: 60.19 - lr: 0.012500
2021-05-27 21:35:12,243 epoch 23 - iter 8/28 - loss 0.34917980 - samples/sec: 60.97 - lr: 0.012500
2021-05-27 21:35:13,296 epoch 23 - iter 10/28 - loss 0.31308981 - samples/sec: 60.80 - lr: 0.012500
2021-05-27 21:35:14,338 epoch 23 - iter 12/28 - loss 0.30037375 - samples/sec: 61.49 - lr: 0.012500
2021-05-27 21:35:15,396 epoch 23 - iter 14/28 - loss 0.27487213 - samples/sec: 60.51 - lr: 0.012500
2021-05-27 21:35:16,445 epoch 23 - iter 16/28 - loss 0.29786840 - samples/sec: 61.02 - lr: 0.012500
2021-05-27 21:35:17,504 epoch 23 - iter 18/28 - loss 0.29394914 - samples/sec: 60.48 - lr: 0.012500
2021-05-27 21:35:18,544 epoch 23 - iter 20/28 - loss 0.30945334 - samples/sec: 61.59 - lr: 0.012500
2021-05-27 21:35:19,591 epoch 23 - iter 22/28 - loss 0.32982147 - samples/sec: 61.16 - lr: 0.012500
2021-05-27 21:35:20,633 epoch 23 - iter 24/28 - loss 0.36955710 - samples/sec: 61.45 - lr: 0.012500
2021-05-27 21:35:21,679 epoch 23 - iter 26/28 - loss 0.36025757 - samples/sec: 61.21 - lr: 0.012500
2021-05-27 21:35:22,275 epoch 23 - iter 28/28 - loss 0.36055285 - samples/sec: 107.53 - lr: 0.012500
2021-05-27 21:35:22,275 ----------------------------------------------------------------------------------------------------
2021-05-27 21:35:22,275 EPOCH 23 done: loss 0.3606 - lr 0.0125000
2021-05-27 21:35:23,361 DEV : loss 1.099515438079834 - score 0.8586
2021-05-27 21:35:23,381 BAD EPOCHS (no improvement): 3
2021-05-27 21:35:23,381 ----------------------------------------------------------------------------------------------------
2021-05-27 21:35:24,576 epoch 24 - iter 2/28 - loss 0.31441757 - samples/sec: 53.56 - lr: 0.012500
2021-05-27 21:35:25,638 epoch 24 - iter 4/28 - loss 0.45940213 - samples/sec: 60.30 - lr: 0.012500
2021-05-27 21:35:26,707 epoch 24 - iter 6/28 - loss 0.40669006 - samples/sec: 59.88 - lr: 0.012500
2021-05-27 21:35:27,747 epoch 24 - iter 8/28 - loss 0.43561202 - samples/sec: 61.60 - lr: 0.012500
2021-05-27 21:35:28,770 epoch 24 - iter 10/28 - loss 0.43935235 - samples/sec: 62.55 - lr: 0.012500
2021-05-27 21:35:29,811 epoch 24 - iter 12/28 - loss 0.43614463 - samples/sec: 61.54 - lr: 0.012500
2021-05-27 21:35:30,858 epoch 24 - iter 14/28 - loss 0.43360629 - samples/sec: 61.13 - lr: 0.012500
2021-05-27 21:35:31,934 epoch 24 - iter 16/28 - loss 0.41382790 - samples/sec: 59.52 - lr: 0.012500
2021-05-27 21:35:32,987 epoch 24 - iter 18/28 - loss 0.40659280 - samples/sec: 60.84 - lr: 0.012500
2021-05-27 21:35:34,030 epoch 24 - iter 20/28 - loss 0.41661361 - samples/sec: 61.38 - lr: 0.012500
2021-05-27 21:35:35,085 epoch 24 - iter 22/28 - loss 0.42629598 - samples/sec: 60.70 - lr: 0.012500
2021-05-27 21:35:36,136 epoch 24 - iter 24/28 - loss 0.41754492 - samples/sec: 60.91 - lr: 0.012500
2021-05-27 21:35:37,213 epoch 24 - iter 26/28 - loss 0.41916068 - samples/sec: 59.47 - lr: 0.012500
2021-05-27 21:35:37,800 epoch 24 - iter 28/28 - loss 0.43947841 - samples/sec: 109.12 - lr: 0.012500
2021-05-27 21:35:37,800 ----------------------------------------------------------------------------------------------------
2021-05-27 21:35:37,800 EPOCH 24 done: loss 0.4395 - lr 0.0125000
2021-05-27 21:35:38,886 DEV : loss 0.8855570554733276 - score 0.8794
Epoch    24: reducing learning rate of group 0 to 6.2500e-03.
2021-05-27 21:35:38,905 BAD EPOCHS (no improvement): 4
2021-05-27 21:35:38,905 ----------------------------------------------------------------------------------------------------
2021-05-27 21:35:39,937 epoch 25 - iter 2/28 - loss 0.48924965 - samples/sec: 62.05 - lr: 0.006250
2021-05-27 21:35:40,982 epoch 25 - iter 4/28 - loss 0.39179537 - samples/sec: 61.27 - lr: 0.006250
2021-05-27 21:35:42,036 epoch 25 - iter 6/28 - loss 0.51571502 - samples/sec: 60.74 - lr: 0.006250
2021-05-27 21:35:43,078 epoch 25 - iter 8/28 - loss 0.44211591 - samples/sec: 61.47 - lr: 0.006250
2021-05-27 21:35:44,131 epoch 25 - iter 10/28 - loss 0.42515035 - samples/sec: 60.79 - lr: 0.006250
2021-05-27 21:35:45,178 epoch 25 - iter 12/28 - loss 0.41158260 - samples/sec: 61.21 - lr: 0.006250
2021-05-27 21:35:46,238 epoch 25 - iter 14/28 - loss 0.41534223 - samples/sec: 60.37 - lr: 0.006250
2021-05-27 21:35:47,295 epoch 25 - iter 16/28 - loss 0.39372084 - samples/sec: 60.61 - lr: 0.006250
2021-05-27 21:35:48,336 epoch 25 - iter 18/28 - loss 0.39021980 - samples/sec: 61.50 - lr: 0.006250
2021-05-27 21:35:49,379 epoch 25 - iter 20/28 - loss 0.36573093 - samples/sec: 61.39 - lr: 0.006250
2021-05-27 21:35:50,430 epoch 25 - iter 22/28 - loss 0.36142356 - samples/sec: 60.90 - lr: 0.006250
2021-05-27 21:35:51,487 epoch 25 - iter 24/28 - loss 0.37289551 - samples/sec: 60.62 - lr: 0.006250
2021-05-27 21:35:52,544 epoch 25 - iter 26/28 - loss 0.36248448 - samples/sec: 60.54 - lr: 0.006250
2021-05-27 21:35:53,156 epoch 25 - iter 28/28 - loss 0.35727367 - samples/sec: 104.72 - lr: 0.006250
2021-05-27 21:35:53,156 ----------------------------------------------------------------------------------------------------
2021-05-27 21:35:53,156 EPOCH 25 done: loss 0.3573 - lr 0.0062500
2021-05-27 21:35:54,242 DEV : loss 0.9731888771057129 - score 0.8646
2021-05-27 21:35:54,261 BAD EPOCHS (no improvement): 1
2021-05-27 21:35:54,261 ----------------------------------------------------------------------------------------------------
2021-05-27 21:35:55,272 epoch 26 - iter 2/28 - loss 0.50773987 - samples/sec: 63.31 - lr: 0.006250
2021-05-27 21:35:56,321 epoch 26 - iter 4/28 - loss 0.42351286 - samples/sec: 61.06 - lr: 0.006250
2021-05-27 21:35:57,373 epoch 26 - iter 6/28 - loss 0.39121237 - samples/sec: 60.89 - lr: 0.006250
2021-05-27 21:35:58,416 epoch 26 - iter 8/28 - loss 0.39941498 - samples/sec: 61.39 - lr: 0.006250
2021-05-27 21:35:59,454 epoch 26 - iter 10/28 - loss 0.35682579 - samples/sec: 61.69 - lr: 0.006250
2021-05-27 21:36:00,508 epoch 26 - iter 12/28 - loss 0.34266516 - samples/sec: 60.75 - lr: 0.006250
2021-05-27 21:36:01,581 epoch 26 - iter 14/28 - loss 0.36502878 - samples/sec: 59.65 - lr: 0.006250
2021-05-27 21:36:02,659 epoch 26 - iter 16/28 - loss 0.36190816 - samples/sec: 59.42 - lr: 0.006250
2021-05-27 21:36:03,697 epoch 26 - iter 18/28 - loss 0.36061570 - samples/sec: 61.70 - lr: 0.006250
2021-05-27 21:36:04,772 epoch 26 - iter 20/28 - loss 0.38175627 - samples/sec: 59.54 - lr: 0.006250
2021-05-27 21:36:05,828 epoch 26 - iter 22/28 - loss 0.38634095 - samples/sec: 60.66 - lr: 0.006250
2021-05-27 21:36:06,865 epoch 26 - iter 24/28 - loss 0.39193551 - samples/sec: 61.71 - lr: 0.006250
2021-05-27 21:36:07,938 epoch 26 - iter 26/28 - loss 0.40743490 - samples/sec: 59.69 - lr: 0.006250
2021-05-27 21:36:08,534 epoch 26 - iter 28/28 - loss 0.38554928 - samples/sec: 107.54 - lr: 0.006250
2021-05-27 21:36:08,534 ----------------------------------------------------------------------------------------------------
2021-05-27 21:36:08,534 EPOCH 26 done: loss 0.3855 - lr 0.0062500
2021-05-27 21:36:09,621 DEV : loss 0.939033031463623 - score 0.8737
2021-05-27 21:36:09,640 BAD EPOCHS (no improvement): 2
2021-05-27 21:36:09,640 ----------------------------------------------------------------------------------------------------
2021-05-27 21:36:10,672 epoch 27 - iter 2/28 - loss 0.26991966 - samples/sec: 62.02 - lr: 0.006250
2021-05-27 21:36:11,726 epoch 27 - iter 4/28 - loss 0.32081865 - samples/sec: 60.79 - lr: 0.006250
2021-05-27 21:36:12,773 epoch 27 - iter 6/28 - loss 0.33196676 - samples/sec: 61.14 - lr: 0.006250
2021-05-27 21:36:13,802 epoch 27 - iter 8/28 - loss 0.36213104 - samples/sec: 62.22 - lr: 0.006250
2021-05-27 21:36:14,865 epoch 27 - iter 10/28 - loss 0.37538093 - samples/sec: 60.24 - lr: 0.006250
2021-05-27 21:36:15,936 epoch 27 - iter 12/28 - loss 0.36006839 - samples/sec: 59.81 - lr: 0.006250
2021-05-27 21:36:16,991 epoch 27 - iter 14/28 - loss 0.35935455 - samples/sec: 60.70 - lr: 0.006250
2021-05-27 21:36:18,039 epoch 27 - iter 16/28 - loss 0.34070196 - samples/sec: 61.07 - lr: 0.006250
2021-05-27 21:36:19,099 epoch 27 - iter 18/28 - loss 0.34504519 - samples/sec: 60.39 - lr: 0.006250
2021-05-27 21:36:20,151 epoch 27 - iter 20/28 - loss 0.36184071 - samples/sec: 60.92 - lr: 0.006250
2021-05-27 21:36:21,185 epoch 27 - iter 22/28 - loss 0.37166368 - samples/sec: 61.89 - lr: 0.006250
2021-05-27 21:36:22,244 epoch 27 - iter 24/28 - loss 0.39967406 - samples/sec: 60.44 - lr: 0.006250
2021-05-27 21:36:23,310 epoch 27 - iter 26/28 - loss 0.38929689 - samples/sec: 60.08 - lr: 0.006250
2021-05-27 21:36:23,914 epoch 27 - iter 28/28 - loss 0.36833922 - samples/sec: 106.08 - lr: 0.006250
2021-05-27 21:36:23,914 ----------------------------------------------------------------------------------------------------
2021-05-27 21:36:23,914 EPOCH 27 done: loss 0.3683 - lr 0.0062500
2021-05-27 21:36:25,144 DEV : loss 0.8470751643180847 - score 0.8941
2021-05-27 21:36:25,163 BAD EPOCHS (no improvement): 3
2021-05-27 21:36:25,164 ----------------------------------------------------------------------------------------------------
2021-05-27 21:36:26,209 epoch 28 - iter 2/28 - loss 0.35726696 - samples/sec: 61.25 - lr: 0.006250
2021-05-27 21:36:27,247 epoch 28 - iter 4/28 - loss 0.42862321 - samples/sec: 61.70 - lr: 0.006250
2021-05-27 21:36:28,293 epoch 28 - iter 6/28 - loss 0.42243634 - samples/sec: 61.20 - lr: 0.006250
2021-05-27 21:36:29,348 epoch 28 - iter 8/28 - loss 0.45551492 - samples/sec: 60.68 - lr: 0.006250
2021-05-27 21:36:30,416 epoch 28 - iter 10/28 - loss 0.46007581 - samples/sec: 59.98 - lr: 0.006250
2021-05-27 21:36:31,469 epoch 28 - iter 12/28 - loss 0.43094659 - samples/sec: 60.81 - lr: 0.006250
2021-05-27 21:36:32,533 epoch 28 - iter 14/28 - loss 0.40887303 - samples/sec: 60.18 - lr: 0.006250
2021-05-27 21:36:33,576 epoch 28 - iter 16/28 - loss 0.37488152 - samples/sec: 61.40 - lr: 0.006250
2021-05-27 21:36:34,634 epoch 28 - iter 18/28 - loss 0.35218653 - samples/sec: 60.53 - lr: 0.006250
2021-05-27 21:36:35,678 epoch 28 - iter 20/28 - loss 0.34305414 - samples/sec: 61.32 - lr: 0.006250
2021-05-27 21:36:36,712 epoch 28 - iter 22/28 - loss 0.33754639 - samples/sec: 61.92 - lr: 0.006250
2021-05-27 21:36:37,770 epoch 28 - iter 24/28 - loss 0.35758419 - samples/sec: 60.52 - lr: 0.006250
2021-05-27 21:36:38,830 epoch 28 - iter 26/28 - loss 0.37357401 - samples/sec: 60.42 - lr: 0.006250
2021-05-27 21:36:39,427 epoch 28 - iter 28/28 - loss 0.36351162 - samples/sec: 107.23 - lr: 0.006250
2021-05-27 21:36:39,427 ----------------------------------------------------------------------------------------------------
2021-05-27 21:36:39,428 EPOCH 28 done: loss 0.3635 - lr 0.0062500
2021-05-27 21:36:40,517 DEV : loss 0.8929444551467896 - score 0.8909
Epoch    28: reducing learning rate of group 0 to 3.1250e-03.
2021-05-27 21:36:40,536 BAD EPOCHS (no improvement): 4
2021-05-27 21:36:40,536 ----------------------------------------------------------------------------------------------------
2021-05-27 21:36:41,555 epoch 29 - iter 2/28 - loss 0.51734340 - samples/sec: 62.84 - lr: 0.003125
2021-05-27 21:36:42,624 epoch 29 - iter 4/28 - loss 0.46476448 - samples/sec: 59.87 - lr: 0.003125
2021-05-27 21:36:43,654 epoch 29 - iter 6/28 - loss 0.42320902 - samples/sec: 62.18 - lr: 0.003125
2021-05-27 21:36:44,717 epoch 29 - iter 8/28 - loss 0.38459257 - samples/sec: 60.24 - lr: 0.003125
2021-05-27 21:36:45,751 epoch 29 - iter 10/28 - loss 0.38457531 - samples/sec: 61.94 - lr: 0.003125
2021-05-27 21:36:46,824 epoch 29 - iter 12/28 - loss 0.36475852 - samples/sec: 59.68 - lr: 0.003125
2021-05-27 21:36:47,880 epoch 29 - iter 14/28 - loss 0.36006299 - samples/sec: 60.64 - lr: 0.003125
2021-05-27 21:36:48,917 epoch 29 - iter 16/28 - loss 0.36723201 - samples/sec: 61.74 - lr: 0.003125
2021-05-27 21:36:49,969 epoch 29 - iter 18/28 - loss 0.34169850 - samples/sec: 60.86 - lr: 0.003125
2021-05-27 21:36:51,027 epoch 29 - iter 20/28 - loss 0.32780378 - samples/sec: 60.50 - lr: 0.003125
2021-05-27 21:36:52,061 epoch 29 - iter 22/28 - loss 0.32815094 - samples/sec: 61.95 - lr: 0.003125
2021-05-27 21:36:53,121 epoch 29 - iter 24/28 - loss 0.32279432 - samples/sec: 60.38 - lr: 0.003125
2021-05-27 21:36:54,154 epoch 29 - iter 26/28 - loss 0.33163827 - samples/sec: 62.03 - lr: 0.003125
2021-05-27 21:36:54,767 epoch 29 - iter 28/28 - loss 0.49835161 - samples/sec: 104.46 - lr: 0.003125
2021-05-27 21:36:54,767 ----------------------------------------------------------------------------------------------------
2021-05-27 21:36:54,767 EPOCH 29 done: loss 0.4984 - lr 0.0031250
2021-05-27 21:36:55,857 DEV : loss 0.9088149070739746 - score 0.8877
2021-05-27 21:36:55,876 BAD EPOCHS (no improvement): 1
2021-05-27 21:36:55,876 ----------------------------------------------------------------------------------------------------
2021-05-27 21:36:56,896 epoch 30 - iter 2/28 - loss 0.19132873 - samples/sec: 62.76 - lr: 0.003125
2021-05-27 21:36:57,957 epoch 30 - iter 4/28 - loss 0.18096428 - samples/sec: 60.36 - lr: 0.003125
2021-05-27 21:36:58,990 epoch 30 - iter 6/28 - loss 0.30595869 - samples/sec: 62.02 - lr: 0.003125
2021-05-27 21:37:00,013 epoch 30 - iter 8/28 - loss 0.41760410 - samples/sec: 62.56 - lr: 0.003125
2021-05-27 21:37:01,076 epoch 30 - iter 10/28 - loss 0.43076273 - samples/sec: 60.22 - lr: 0.003125
2021-05-27 21:37:02,144 epoch 30 - iter 12/28 - loss 0.40547126 - samples/sec: 59.95 - lr: 0.003125
2021-05-27 21:37:03,218 epoch 30 - iter 14/28 - loss 0.40902667 - samples/sec: 59.67 - lr: 0.003125
2021-05-27 21:37:04,286 epoch 30 - iter 16/28 - loss 0.40364858 - samples/sec: 59.96 - lr: 0.003125
2021-05-27 21:37:05,319 epoch 30 - iter 18/28 - loss 0.38784478 - samples/sec: 61.93 - lr: 0.003125
2021-05-27 21:37:06,385 epoch 30 - iter 20/28 - loss 0.39532885 - samples/sec: 60.08 - lr: 0.003125
2021-05-27 21:37:07,427 epoch 30 - iter 22/28 - loss 0.40588243 - samples/sec: 61.50 - lr: 0.003125
2021-05-27 21:37:08,497 epoch 30 - iter 24/28 - loss 0.41214630 - samples/sec: 59.82 - lr: 0.003125
2021-05-27 21:37:09,556 epoch 30 - iter 26/28 - loss 0.40058378 - samples/sec: 60.43 - lr: 0.003125
2021-05-27 21:37:10,163 epoch 30 - iter 28/28 - loss 0.39591792 - samples/sec: 105.57 - lr: 0.003125
2021-05-27 21:37:10,163 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:10,164 EPOCH 30 done: loss 0.3959 - lr 0.0031250
2021-05-27 21:37:11,394 DEV : loss 0.9455747604370117 - score 0.8737
2021-05-27 21:37:11,413 BAD EPOCHS (no improvement): 2
2021-05-27 21:37:12,396 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:12,396 Testing using best model ...
2021-05-27 21:37:12,396 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/nld.rst.nldt/best-model.pt
2021-05-27 21:37:18,644 0.9740	0.9073	0.9395
2021-05-27 21:37:18,644 
Results:
- F1-score (micro) 0.9395
- F1-score (macro) 0.9395

By class:
SENT       tp: 225 - fp: 6 - fn: 23 - precision: 0.9740 - recall: 0.9073 - f1-score: 0.9395
2021-05-27 21:37:18,644 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/
2021-05-27 21:37:18,666 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn
2021-05-27 21:37:18,666 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/sent_train.txt
2021-05-27 21:37:18,669 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/sent_dev.txt
2021-05-27 21:37:18,669 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/sent_test.txt
Corpus: 2031 train + 282 dev + 164 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 21:37:25,700 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:25,703 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 21:37:25,703 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:25,703 Corpus: "Corpus: 2031 train + 282 dev + 164 test sentences"
2021-05-27 21:37:25,703 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:25,703 Parameters:
2021-05-27 21:37:25,703  - learning_rate: "0.1"
2021-05-27 21:37:25,703  - mini_batch_size: "32"
2021-05-27 21:37:25,703  - patience: "3"
2021-05-27 21:37:25,703  - anneal_factor: "0.5"
2021-05-27 21:37:25,703  - max_epochs: "30"
2021-05-27 21:37:25,703  - shuffle: "True"
2021-05-27 21:37:25,703  - train_with_dev: "False"
2021-05-27 21:37:25,703  - batch_growth_annealing: "False"
2021-05-27 21:37:25,703 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:25,703 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn"
2021-05-27 21:37:25,703 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:25,703 Device: cuda:0
2021-05-27 21:37:25,703 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:25,703 Embeddings storage mode: cpu
2021-05-27 21:37:25,704 ----------------------------------------------------------------------------------------------------
2021-05-27 21:37:33,552 epoch 1 - iter 6/64 - loss 6.89827832 - samples/sec: 24.47 - lr: 0.100000
2021-05-27 21:37:41,445 epoch 1 - iter 12/64 - loss 5.83058806 - samples/sec: 24.33 - lr: 0.100000
2021-05-27 21:37:49,368 epoch 1 - iter 18/64 - loss 5.35719706 - samples/sec: 24.23 - lr: 0.100000
2021-05-27 21:37:57,280 epoch 1 - iter 24/64 - loss 5.01559069 - samples/sec: 24.27 - lr: 0.100000
2021-05-27 21:38:05,184 epoch 1 - iter 30/64 - loss 4.73608319 - samples/sec: 24.29 - lr: 0.100000
2021-05-27 21:38:13,097 epoch 1 - iter 36/64 - loss 4.45219347 - samples/sec: 24.27 - lr: 0.100000
2021-05-27 21:38:21,174 epoch 1 - iter 42/64 - loss 4.22248799 - samples/sec: 23.77 - lr: 0.100000
2021-05-27 21:38:29,108 epoch 1 - iter 48/64 - loss 4.01676499 - samples/sec: 24.20 - lr: 0.100000
2021-05-27 21:38:37,015 epoch 1 - iter 54/64 - loss 3.82830148 - samples/sec: 24.28 - lr: 0.100000
2021-05-27 21:38:44,932 epoch 1 - iter 60/64 - loss 3.65928835 - samples/sec: 24.26 - lr: 0.100000
2021-05-27 21:38:49,497 ----------------------------------------------------------------------------------------------------
2021-05-27 21:38:49,498 EPOCH 1 done: loss 3.5441 - lr 0.1000000
2021-05-27 21:38:56,820 DEV : loss 0.5675808787345886 - score 0.9023
2021-05-27 21:38:56,848 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:38:57,890 ----------------------------------------------------------------------------------------------------
2021-05-27 21:39:01,029 epoch 2 - iter 6/64 - loss 1.17721617 - samples/sec: 61.17 - lr: 0.100000
2021-05-27 21:39:04,159 epoch 2 - iter 12/64 - loss 1.46680782 - samples/sec: 61.36 - lr: 0.100000
2021-05-27 21:39:07,325 epoch 2 - iter 18/64 - loss 1.39343815 - samples/sec: 60.66 - lr: 0.100000
2021-05-27 21:39:10,443 epoch 2 - iter 24/64 - loss 1.34596732 - samples/sec: 61.58 - lr: 0.100000
2021-05-27 21:39:13,550 epoch 2 - iter 30/64 - loss 1.25139186 - samples/sec: 61.82 - lr: 0.100000
2021-05-27 21:39:16,913 epoch 2 - iter 36/64 - loss 1.23714330 - samples/sec: 57.10 - lr: 0.100000
2021-05-27 21:39:20,066 epoch 2 - iter 42/64 - loss 1.21895967 - samples/sec: 60.91 - lr: 0.100000
2021-05-27 21:39:23,218 epoch 2 - iter 48/64 - loss 1.14445677 - samples/sec: 60.94 - lr: 0.100000
2021-05-27 21:39:26,356 epoch 2 - iter 54/64 - loss 1.13037238 - samples/sec: 61.20 - lr: 0.100000
2021-05-27 21:39:29,486 epoch 2 - iter 60/64 - loss 1.11047998 - samples/sec: 61.35 - lr: 0.100000
2021-05-27 21:39:31,323 ----------------------------------------------------------------------------------------------------
2021-05-27 21:39:31,323 EPOCH 2 done: loss 1.0750 - lr 0.1000000
2021-05-27 21:39:32,967 DEV : loss 0.2985941171646118 - score 0.9598
2021-05-27 21:39:32,995 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:39:42,126 ----------------------------------------------------------------------------------------------------
2021-05-27 21:39:45,221 epoch 3 - iter 6/64 - loss 0.72538415 - samples/sec: 62.05 - lr: 0.100000
2021-05-27 21:39:48,348 epoch 3 - iter 12/64 - loss 0.83216684 - samples/sec: 61.41 - lr: 0.100000
2021-05-27 21:39:51,437 epoch 3 - iter 18/64 - loss 0.73279272 - samples/sec: 62.17 - lr: 0.100000
2021-05-27 21:39:54,526 epoch 3 - iter 24/64 - loss 0.72125857 - samples/sec: 62.16 - lr: 0.100000
2021-05-27 21:39:57,652 epoch 3 - iter 30/64 - loss 0.75036041 - samples/sec: 61.44 - lr: 0.100000
2021-05-27 21:40:00,780 epoch 3 - iter 36/64 - loss 0.77412676 - samples/sec: 61.39 - lr: 0.100000
2021-05-27 21:40:03,917 epoch 3 - iter 42/64 - loss 0.72004165 - samples/sec: 61.24 - lr: 0.100000
2021-05-27 21:40:07,040 epoch 3 - iter 48/64 - loss 0.71066984 - samples/sec: 61.49 - lr: 0.100000
2021-05-27 21:40:10,226 epoch 3 - iter 54/64 - loss 0.70485101 - samples/sec: 60.27 - lr: 0.100000
2021-05-27 21:40:13,378 epoch 3 - iter 60/64 - loss 0.69712584 - samples/sec: 60.93 - lr: 0.100000
2021-05-27 21:40:15,244 ----------------------------------------------------------------------------------------------------
2021-05-27 21:40:15,244 EPOCH 3 done: loss 0.6747 - lr 0.1000000
2021-05-27 21:40:16,884 DEV : loss 0.19021308422088623 - score 0.9701
2021-05-27 21:40:16,912 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:40:26,453 ----------------------------------------------------------------------------------------------------
2021-05-27 21:40:29,545 epoch 4 - iter 6/64 - loss 0.56706938 - samples/sec: 62.11 - lr: 0.100000
2021-05-27 21:40:32,650 epoch 4 - iter 12/64 - loss 0.67453985 - samples/sec: 61.86 - lr: 0.100000
2021-05-27 21:40:35,817 epoch 4 - iter 18/64 - loss 0.68632364 - samples/sec: 60.63 - lr: 0.100000
2021-05-27 21:40:38,939 epoch 4 - iter 24/64 - loss 0.64892749 - samples/sec: 61.53 - lr: 0.100000
2021-05-27 21:40:42,112 epoch 4 - iter 30/64 - loss 0.60678162 - samples/sec: 60.51 - lr: 0.100000
2021-05-27 21:40:45,277 epoch 4 - iter 36/64 - loss 0.59762102 - samples/sec: 60.68 - lr: 0.100000
2021-05-27 21:40:48,427 epoch 4 - iter 42/64 - loss 0.57241877 - samples/sec: 60.97 - lr: 0.100000
2021-05-27 21:40:51,557 epoch 4 - iter 48/64 - loss 0.57899963 - samples/sec: 61.34 - lr: 0.100000
2021-05-27 21:40:54,727 epoch 4 - iter 54/64 - loss 0.55263189 - samples/sec: 60.58 - lr: 0.100000
2021-05-27 21:40:57,863 epoch 4 - iter 60/64 - loss 0.53464405 - samples/sec: 61.25 - lr: 0.100000
2021-05-27 21:40:59,676 ----------------------------------------------------------------------------------------------------
2021-05-27 21:40:59,676 EPOCH 4 done: loss 0.5410 - lr 0.1000000
2021-05-27 21:41:01,323 DEV : loss 0.16012607514858246 - score 0.9719
2021-05-27 21:41:01,351 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:41:11,139 ----------------------------------------------------------------------------------------------------
2021-05-27 21:41:14,212 epoch 5 - iter 6/64 - loss 0.36780892 - samples/sec: 62.51 - lr: 0.100000
2021-05-27 21:41:17,358 epoch 5 - iter 12/64 - loss 0.45192646 - samples/sec: 61.04 - lr: 0.100000
2021-05-27 21:41:20,518 epoch 5 - iter 18/64 - loss 0.38314424 - samples/sec: 60.78 - lr: 0.100000
2021-05-27 21:41:23,649 epoch 5 - iter 24/64 - loss 0.39439570 - samples/sec: 61.34 - lr: 0.100000
2021-05-27 21:41:26,779 epoch 5 - iter 30/64 - loss 0.41563753 - samples/sec: 61.36 - lr: 0.100000
2021-05-27 21:41:29,900 epoch 5 - iter 36/64 - loss 0.40318653 - samples/sec: 61.53 - lr: 0.100000
2021-05-27 21:41:33,050 epoch 5 - iter 42/64 - loss 0.39960778 - samples/sec: 60.97 - lr: 0.100000
2021-05-27 21:41:36,198 epoch 5 - iter 48/64 - loss 0.39842546 - samples/sec: 60.99 - lr: 0.100000
2021-05-27 21:41:39,343 epoch 5 - iter 54/64 - loss 0.41763683 - samples/sec: 61.06 - lr: 0.100000
2021-05-27 21:41:42,463 epoch 5 - iter 60/64 - loss 0.41574074 - samples/sec: 61.56 - lr: 0.100000
2021-05-27 21:41:44,542 ----------------------------------------------------------------------------------------------------
2021-05-27 21:41:44,542 EPOCH 5 done: loss 0.4098 - lr 0.1000000
2021-05-27 21:41:46,182 DEV : loss 0.17552198469638824 - score 0.9784
2021-05-27 21:41:46,210 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:41:55,124 ----------------------------------------------------------------------------------------------------
2021-05-27 21:41:58,229 epoch 6 - iter 6/64 - loss 0.46138519 - samples/sec: 61.86 - lr: 0.100000
2021-05-27 21:42:01,385 epoch 6 - iter 12/64 - loss 0.42367197 - samples/sec: 60.83 - lr: 0.100000
2021-05-27 21:42:04,531 epoch 6 - iter 18/64 - loss 0.39450756 - samples/sec: 61.05 - lr: 0.100000
2021-05-27 21:42:07,664 epoch 6 - iter 24/64 - loss 0.39744289 - samples/sec: 61.30 - lr: 0.100000
2021-05-27 21:42:10,824 epoch 6 - iter 30/64 - loss 0.38571265 - samples/sec: 60.78 - lr: 0.100000
2021-05-27 21:42:13,980 epoch 6 - iter 36/64 - loss 0.37930803 - samples/sec: 60.85 - lr: 0.100000
2021-05-27 21:42:17,120 epoch 6 - iter 42/64 - loss 0.36192205 - samples/sec: 61.16 - lr: 0.100000
2021-05-27 21:42:20,261 epoch 6 - iter 48/64 - loss 0.36179579 - samples/sec: 61.13 - lr: 0.100000
2021-05-27 21:42:23,420 epoch 6 - iter 54/64 - loss 0.35123784 - samples/sec: 60.80 - lr: 0.100000
2021-05-27 21:42:26,527 epoch 6 - iter 60/64 - loss 0.35815416 - samples/sec: 61.82 - lr: 0.100000
2021-05-27 21:42:28,353 ----------------------------------------------------------------------------------------------------
2021-05-27 21:42:28,353 EPOCH 6 done: loss 0.3590 - lr 0.1000000
2021-05-27 21:42:29,995 DEV : loss 0.15790796279907227 - score 0.9804
2021-05-27 21:42:30,023 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:42:39,139 ----------------------------------------------------------------------------------------------------
2021-05-27 21:42:42,274 epoch 7 - iter 6/64 - loss 0.43003111 - samples/sec: 61.26 - lr: 0.100000
2021-05-27 21:42:45,427 epoch 7 - iter 12/64 - loss 0.41985405 - samples/sec: 60.91 - lr: 0.100000
2021-05-27 21:42:48,574 epoch 7 - iter 18/64 - loss 0.39320066 - samples/sec: 61.03 - lr: 0.100000
2021-05-27 21:42:51,713 epoch 7 - iter 24/64 - loss 0.39963149 - samples/sec: 61.18 - lr: 0.100000
2021-05-27 21:42:54,874 epoch 7 - iter 30/64 - loss 0.37323687 - samples/sec: 60.76 - lr: 0.100000
2021-05-27 21:42:57,976 epoch 7 - iter 36/64 - loss 0.35098356 - samples/sec: 61.90 - lr: 0.100000
2021-05-27 21:43:01,109 epoch 7 - iter 42/64 - loss 0.33400615 - samples/sec: 61.29 - lr: 0.100000
2021-05-27 21:43:04,235 epoch 7 - iter 48/64 - loss 0.36722540 - samples/sec: 61.44 - lr: 0.100000
2021-05-27 21:43:07,380 epoch 7 - iter 54/64 - loss 0.37367125 - samples/sec: 61.06 - lr: 0.100000
2021-05-27 21:43:10,533 epoch 7 - iter 60/64 - loss 0.37215766 - samples/sec: 60.92 - lr: 0.100000
2021-05-27 21:43:12,351 ----------------------------------------------------------------------------------------------------
2021-05-27 21:43:12,351 EPOCH 7 done: loss 0.3801 - lr 0.1000000
2021-05-27 21:43:13,997 DEV : loss 0.23790499567985535 - score 0.9639
2021-05-27 21:43:14,026 BAD EPOCHS (no improvement): 1
2021-05-27 21:43:14,026 ----------------------------------------------------------------------------------------------------
2021-05-27 21:43:17,156 epoch 8 - iter 6/64 - loss 0.38824685 - samples/sec: 61.36 - lr: 0.100000
2021-05-27 21:43:20,348 epoch 8 - iter 12/64 - loss 0.39391042 - samples/sec: 60.16 - lr: 0.100000
2021-05-27 21:43:23,483 epoch 8 - iter 18/64 - loss 0.35037161 - samples/sec: 61.26 - lr: 0.100000
2021-05-27 21:43:26,624 epoch 8 - iter 24/64 - loss 0.33417885 - samples/sec: 61.13 - lr: 0.100000
2021-05-27 21:43:29,744 epoch 8 - iter 30/64 - loss 0.36381899 - samples/sec: 61.55 - lr: 0.100000
2021-05-27 21:43:32,829 epoch 8 - iter 36/64 - loss 0.34638337 - samples/sec: 62.25 - lr: 0.100000
2021-05-27 21:43:35,922 epoch 8 - iter 42/64 - loss 0.33684274 - samples/sec: 62.09 - lr: 0.100000
2021-05-27 21:43:39,045 epoch 8 - iter 48/64 - loss 0.32627358 - samples/sec: 61.50 - lr: 0.100000
2021-05-27 21:43:42,143 epoch 8 - iter 54/64 - loss 0.31593031 - samples/sec: 61.98 - lr: 0.100000
2021-05-27 21:43:45,500 epoch 8 - iter 60/64 - loss 0.32461608 - samples/sec: 57.21 - lr: 0.100000
2021-05-27 21:43:47,349 ----------------------------------------------------------------------------------------------------
2021-05-27 21:43:47,349 EPOCH 8 done: loss 0.3430 - lr 0.1000000
2021-05-27 21:43:48,991 DEV : loss 0.19735491275787354 - score 0.9802
2021-05-27 21:43:49,020 BAD EPOCHS (no improvement): 2
2021-05-27 21:43:49,020 ----------------------------------------------------------------------------------------------------
2021-05-27 21:43:52,122 epoch 9 - iter 6/64 - loss 0.26010595 - samples/sec: 61.91 - lr: 0.100000
2021-05-27 21:43:55,262 epoch 9 - iter 12/64 - loss 0.26530768 - samples/sec: 61.15 - lr: 0.100000
2021-05-27 21:43:58,399 epoch 9 - iter 18/64 - loss 0.26040864 - samples/sec: 61.22 - lr: 0.100000
2021-05-27 21:44:01,565 epoch 9 - iter 24/64 - loss 0.26302307 - samples/sec: 60.65 - lr: 0.100000
2021-05-27 21:44:04,739 epoch 9 - iter 30/64 - loss 0.28652959 - samples/sec: 60.51 - lr: 0.100000
2021-05-27 21:44:07,852 epoch 9 - iter 36/64 - loss 0.28733357 - samples/sec: 61.70 - lr: 0.100000
2021-05-27 21:44:10,948 epoch 9 - iter 42/64 - loss 0.28309997 - samples/sec: 62.02 - lr: 0.100000
2021-05-27 21:44:14,080 epoch 9 - iter 48/64 - loss 0.29541340 - samples/sec: 61.32 - lr: 0.100000
2021-05-27 21:44:17,187 epoch 9 - iter 54/64 - loss 0.29942738 - samples/sec: 61.81 - lr: 0.100000
2021-05-27 21:44:20,309 epoch 9 - iter 60/64 - loss 0.31104059 - samples/sec: 61.51 - lr: 0.100000
2021-05-27 21:44:22,155 ----------------------------------------------------------------------------------------------------
2021-05-27 21:44:22,156 EPOCH 9 done: loss 0.3091 - lr 0.1000000
2021-05-27 21:44:23,796 DEV : loss 0.2340264618396759 - score 0.9558
2021-05-27 21:44:23,825 BAD EPOCHS (no improvement): 3
2021-05-27 21:44:23,825 ----------------------------------------------------------------------------------------------------
2021-05-27 21:44:26,928 epoch 10 - iter 6/64 - loss 0.41787242 - samples/sec: 61.90 - lr: 0.100000
2021-05-27 21:44:30,030 epoch 10 - iter 12/64 - loss 0.38020028 - samples/sec: 61.91 - lr: 0.100000
2021-05-27 21:44:33,183 epoch 10 - iter 18/64 - loss 0.36653121 - samples/sec: 60.90 - lr: 0.100000
2021-05-27 21:44:36,303 epoch 10 - iter 24/64 - loss 0.36041838 - samples/sec: 61.56 - lr: 0.100000
2021-05-27 21:44:39,434 epoch 10 - iter 30/64 - loss 0.33508237 - samples/sec: 61.33 - lr: 0.100000
2021-05-27 21:44:42,546 epoch 10 - iter 36/64 - loss 0.32792183 - samples/sec: 61.70 - lr: 0.100000
2021-05-27 21:44:45,704 epoch 10 - iter 42/64 - loss 0.31178684 - samples/sec: 60.81 - lr: 0.100000
2021-05-27 21:44:48,791 epoch 10 - iter 48/64 - loss 0.31082539 - samples/sec: 62.22 - lr: 0.100000
2021-05-27 21:44:51,901 epoch 10 - iter 54/64 - loss 0.29569687 - samples/sec: 61.75 - lr: 0.100000
2021-05-27 21:44:55,021 epoch 10 - iter 60/64 - loss 0.29056675 - samples/sec: 61.57 - lr: 0.100000
2021-05-27 21:44:56,844 ----------------------------------------------------------------------------------------------------
2021-05-27 21:44:56,844 EPOCH 10 done: loss 0.2846 - lr 0.1000000
2021-05-27 21:44:58,483 DEV : loss 0.1710226982831955 - score 0.97
Epoch    10: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 21:44:58,512 BAD EPOCHS (no improvement): 4
2021-05-27 21:44:58,512 ----------------------------------------------------------------------------------------------------
2021-05-27 21:45:01,651 epoch 11 - iter 6/64 - loss 0.19918504 - samples/sec: 61.19 - lr: 0.050000
2021-05-27 21:45:04,763 epoch 11 - iter 12/64 - loss 0.19537037 - samples/sec: 61.71 - lr: 0.050000
2021-05-27 21:45:07,867 epoch 11 - iter 18/64 - loss 0.19742987 - samples/sec: 61.87 - lr: 0.050000
2021-05-27 21:45:10,984 epoch 11 - iter 24/64 - loss 0.22238893 - samples/sec: 61.62 - lr: 0.050000
2021-05-27 21:45:14,105 epoch 11 - iter 30/64 - loss 0.22316269 - samples/sec: 61.52 - lr: 0.050000
2021-05-27 21:45:17,239 epoch 11 - iter 36/64 - loss 0.22303970 - samples/sec: 61.28 - lr: 0.050000
2021-05-27 21:45:20,379 epoch 11 - iter 42/64 - loss 0.22457879 - samples/sec: 61.17 - lr: 0.050000
2021-05-27 21:45:23,539 epoch 11 - iter 48/64 - loss 0.22920432 - samples/sec: 60.78 - lr: 0.050000
2021-05-27 21:45:26,693 epoch 11 - iter 54/64 - loss 0.22686511 - samples/sec: 60.88 - lr: 0.050000
2021-05-27 21:45:29,849 epoch 11 - iter 60/64 - loss 0.23820084 - samples/sec: 60.86 - lr: 0.050000
2021-05-27 21:45:31,667 ----------------------------------------------------------------------------------------------------
2021-05-27 21:45:31,667 EPOCH 11 done: loss 0.2369 - lr 0.0500000
2021-05-27 21:45:33,522 DEV : loss 0.1748335212469101 - score 0.9847
2021-05-27 21:45:33,551 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 21:45:42,608 ----------------------------------------------------------------------------------------------------
2021-05-27 21:45:45,723 epoch 12 - iter 6/64 - loss 0.29206802 - samples/sec: 61.66 - lr: 0.050000
2021-05-27 21:45:48,870 epoch 12 - iter 12/64 - loss 0.23345976 - samples/sec: 61.02 - lr: 0.050000
2021-05-27 21:45:51,979 epoch 12 - iter 18/64 - loss 0.22662533 - samples/sec: 61.76 - lr: 0.050000
2021-05-27 21:45:55,138 epoch 12 - iter 24/64 - loss 0.21059902 - samples/sec: 60.79 - lr: 0.050000
2021-05-27 21:45:58,272 epoch 12 - iter 30/64 - loss 0.22179592 - samples/sec: 61.28 - lr: 0.050000
2021-05-27 21:46:01,360 epoch 12 - iter 36/64 - loss 0.21192693 - samples/sec: 62.20 - lr: 0.050000
2021-05-27 21:46:04,491 epoch 12 - iter 42/64 - loss 0.20700152 - samples/sec: 61.33 - lr: 0.050000
2021-05-27 21:46:07,646 epoch 12 - iter 48/64 - loss 0.22109945 - samples/sec: 60.88 - lr: 0.050000
2021-05-27 21:46:10,788 epoch 12 - iter 54/64 - loss 0.20983375 - samples/sec: 61.12 - lr: 0.050000
2021-05-27 21:46:13,927 epoch 12 - iter 60/64 - loss 0.21187957 - samples/sec: 61.17 - lr: 0.050000
2021-05-27 21:46:15,766 ----------------------------------------------------------------------------------------------------
2021-05-27 21:46:15,767 EPOCH 12 done: loss 0.2090 - lr 0.0500000
2021-05-27 21:46:17,402 DEV : loss 0.1550389677286148 - score 0.9784
2021-05-27 21:46:17,431 BAD EPOCHS (no improvement): 1
2021-05-27 21:46:17,431 ----------------------------------------------------------------------------------------------------
2021-05-27 21:46:20,575 epoch 13 - iter 6/64 - loss 0.20184757 - samples/sec: 61.08 - lr: 0.050000
2021-05-27 21:46:23,731 epoch 13 - iter 12/64 - loss 0.21394186 - samples/sec: 60.85 - lr: 0.050000
2021-05-27 21:46:26,828 epoch 13 - iter 18/64 - loss 0.20635876 - samples/sec: 62.02 - lr: 0.050000
2021-05-27 21:46:29,867 epoch 13 - iter 24/64 - loss 0.22488074 - samples/sec: 63.20 - lr: 0.050000
2021-05-27 21:46:33,009 epoch 13 - iter 30/64 - loss 0.21049265 - samples/sec: 61.11 - lr: 0.050000
2021-05-27 21:46:36,100 epoch 13 - iter 36/64 - loss 0.20779379 - samples/sec: 62.14 - lr: 0.050000
2021-05-27 21:46:39,246 epoch 13 - iter 42/64 - loss 0.20282042 - samples/sec: 61.03 - lr: 0.050000
2021-05-27 21:46:42,382 epoch 13 - iter 48/64 - loss 0.19742275 - samples/sec: 61.24 - lr: 0.050000
2021-05-27 21:46:45,503 epoch 13 - iter 54/64 - loss 0.19165345 - samples/sec: 61.54 - lr: 0.050000
2021-05-27 21:46:48,606 epoch 13 - iter 60/64 - loss 0.20668206 - samples/sec: 61.89 - lr: 0.050000
2021-05-27 21:46:50,431 ----------------------------------------------------------------------------------------------------
2021-05-27 21:46:50,431 EPOCH 13 done: loss 0.2094 - lr 0.0500000
2021-05-27 21:46:52,066 DEV : loss 0.14666616916656494 - score 0.9761
2021-05-27 21:46:52,095 BAD EPOCHS (no improvement): 2
2021-05-27 21:46:52,095 ----------------------------------------------------------------------------------------------------
2021-05-27 21:46:55,187 epoch 14 - iter 6/64 - loss 0.17851277 - samples/sec: 62.10 - lr: 0.050000
2021-05-27 21:46:58,325 epoch 14 - iter 12/64 - loss 0.23251859 - samples/sec: 61.21 - lr: 0.050000
2021-05-27 21:47:01,477 epoch 14 - iter 18/64 - loss 0.20606700 - samples/sec: 60.91 - lr: 0.050000
2021-05-27 21:47:04,607 epoch 14 - iter 24/64 - loss 0.20377565 - samples/sec: 61.37 - lr: 0.050000
2021-05-27 21:47:07,711 epoch 14 - iter 30/64 - loss 0.19595678 - samples/sec: 61.86 - lr: 0.050000
2021-05-27 21:47:10,833 epoch 14 - iter 36/64 - loss 0.20323372 - samples/sec: 61.53 - lr: 0.050000
2021-05-27 21:47:13,974 epoch 14 - iter 42/64 - loss 0.19826195 - samples/sec: 61.12 - lr: 0.050000
2021-05-27 21:47:17,084 epoch 14 - iter 48/64 - loss 0.19335698 - samples/sec: 61.77 - lr: 0.050000
2021-05-27 21:47:20,147 epoch 14 - iter 54/64 - loss 0.19386655 - samples/sec: 62.69 - lr: 0.050000
2021-05-27 21:47:23,264 epoch 14 - iter 60/64 - loss 0.19391516 - samples/sec: 61.61 - lr: 0.050000
2021-05-27 21:47:25,098 ----------------------------------------------------------------------------------------------------
2021-05-27 21:47:25,099 EPOCH 14 done: loss 0.1868 - lr 0.0500000
2021-05-27 21:47:26,733 DEV : loss 0.15579962730407715 - score 0.9804
2021-05-27 21:47:26,762 BAD EPOCHS (no improvement): 3
2021-05-27 21:47:26,762 ----------------------------------------------------------------------------------------------------
2021-05-27 21:47:29,905 epoch 15 - iter 6/64 - loss 0.09459627 - samples/sec: 61.10 - lr: 0.050000
2021-05-27 21:47:33,023 epoch 15 - iter 12/64 - loss 0.16796936 - samples/sec: 61.60 - lr: 0.050000
2021-05-27 21:47:36,167 epoch 15 - iter 18/64 - loss 0.20787101 - samples/sec: 61.07 - lr: 0.050000
2021-05-27 21:47:39,261 epoch 15 - iter 24/64 - loss 0.18867422 - samples/sec: 62.08 - lr: 0.050000
2021-05-27 21:47:42,380 epoch 15 - iter 30/64 - loss 0.19123821 - samples/sec: 61.58 - lr: 0.050000
2021-05-27 21:47:45,526 epoch 15 - iter 36/64 - loss 0.18834625 - samples/sec: 61.04 - lr: 0.050000
2021-05-27 21:47:48,603 epoch 15 - iter 42/64 - loss 0.18786785 - samples/sec: 62.41 - lr: 0.050000
2021-05-27 21:47:51,900 epoch 15 - iter 48/64 - loss 0.18098636 - samples/sec: 58.25 - lr: 0.050000
2021-05-27 21:47:55,002 epoch 15 - iter 54/64 - loss 0.17752367 - samples/sec: 61.90 - lr: 0.050000
2021-05-27 21:47:58,108 epoch 15 - iter 60/64 - loss 0.19005920 - samples/sec: 61.84 - lr: 0.050000
2021-05-27 21:47:59,930 ----------------------------------------------------------------------------------------------------
2021-05-27 21:47:59,930 EPOCH 15 done: loss 0.1872 - lr 0.0500000
2021-05-27 21:48:01,562 DEV : loss 0.16654720902442932 - score 0.9741
Epoch    15: reducing learning rate of group 0 to 2.5000e-02.
2021-05-27 21:48:01,591 BAD EPOCHS (no improvement): 4
2021-05-27 21:48:01,591 ----------------------------------------------------------------------------------------------------
2021-05-27 21:48:04,717 epoch 16 - iter 6/64 - loss 0.16042938 - samples/sec: 61.44 - lr: 0.025000
2021-05-27 21:48:07,832 epoch 16 - iter 12/64 - loss 0.17518457 - samples/sec: 61.65 - lr: 0.025000
2021-05-27 21:48:10,938 epoch 16 - iter 18/64 - loss 0.18760587 - samples/sec: 61.82 - lr: 0.025000
2021-05-27 21:48:14,059 epoch 16 - iter 24/64 - loss 0.18480655 - samples/sec: 61.54 - lr: 0.025000
2021-05-27 21:48:17,218 epoch 16 - iter 30/64 - loss 0.18104537 - samples/sec: 60.79 - lr: 0.025000
2021-05-27 21:48:20,318 epoch 16 - iter 36/64 - loss 0.19825293 - samples/sec: 61.95 - lr: 0.025000
2021-05-27 21:48:23,416 epoch 16 - iter 42/64 - loss 0.19639231 - samples/sec: 61.99 - lr: 0.025000
2021-05-27 21:48:26,529 epoch 16 - iter 48/64 - loss 0.19406286 - samples/sec: 61.68 - lr: 0.025000
2021-05-27 21:48:29,657 epoch 16 - iter 54/64 - loss 0.19341153 - samples/sec: 61.41 - lr: 0.025000
2021-05-27 21:48:32,825 epoch 16 - iter 60/64 - loss 0.18910409 - samples/sec: 60.62 - lr: 0.025000
2021-05-27 21:48:34,686 ----------------------------------------------------------------------------------------------------
2021-05-27 21:48:34,686 EPOCH 16 done: loss 0.1859 - lr 0.0250000
2021-05-27 21:48:36,324 DEV : loss 0.1598450243473053 - score 0.9826
2021-05-27 21:48:36,352 BAD EPOCHS (no improvement): 1
2021-05-27 21:48:36,352 ----------------------------------------------------------------------------------------------------
2021-05-27 21:48:39,498 epoch 17 - iter 6/64 - loss 0.17866128 - samples/sec: 61.04 - lr: 0.025000
2021-05-27 21:48:42,643 epoch 17 - iter 12/64 - loss 0.17188154 - samples/sec: 61.06 - lr: 0.025000
2021-05-27 21:48:45,818 epoch 17 - iter 18/64 - loss 0.16412665 - samples/sec: 60.49 - lr: 0.025000
2021-05-27 21:48:48,985 epoch 17 - iter 24/64 - loss 0.18001773 - samples/sec: 60.63 - lr: 0.025000
2021-05-27 21:48:52,129 epoch 17 - iter 30/64 - loss 0.18192188 - samples/sec: 61.09 - lr: 0.025000
2021-05-27 21:48:55,270 epoch 17 - iter 36/64 - loss 0.18445768 - samples/sec: 61.15 - lr: 0.025000
2021-05-27 21:48:58,409 epoch 17 - iter 42/64 - loss 0.17708713 - samples/sec: 61.17 - lr: 0.025000
2021-05-27 21:49:01,563 epoch 17 - iter 48/64 - loss 0.18163502 - samples/sec: 60.89 - lr: 0.025000
2021-05-27 21:49:04,694 epoch 17 - iter 54/64 - loss 0.17992648 - samples/sec: 61.34 - lr: 0.025000
2021-05-27 21:49:07,807 epoch 17 - iter 60/64 - loss 0.18325715 - samples/sec: 61.70 - lr: 0.025000
2021-05-27 21:49:09,652 ----------------------------------------------------------------------------------------------------
2021-05-27 21:49:09,653 EPOCH 17 done: loss 0.1793 - lr 0.0250000
2021-05-27 21:49:11,285 DEV : loss 0.1664549708366394 - score 0.9804
2021-05-27 21:49:11,313 BAD EPOCHS (no improvement): 2
2021-05-27 21:49:11,313 ----------------------------------------------------------------------------------------------------
2021-05-27 21:49:14,429 epoch 18 - iter 6/64 - loss 0.27929682 - samples/sec: 61.64 - lr: 0.025000
2021-05-27 21:49:17,551 epoch 18 - iter 12/64 - loss 0.22929639 - samples/sec: 61.51 - lr: 0.025000
2021-05-27 21:49:20,686 epoch 18 - iter 18/64 - loss 0.18889201 - samples/sec: 61.25 - lr: 0.025000
2021-05-27 21:49:23,829 epoch 18 - iter 24/64 - loss 0.18629002 - samples/sec: 61.12 - lr: 0.025000
2021-05-27 21:49:26,939 epoch 18 - iter 30/64 - loss 0.19625431 - samples/sec: 61.75 - lr: 0.025000
2021-05-27 21:49:30,113 epoch 18 - iter 36/64 - loss 0.18812305 - samples/sec: 60.51 - lr: 0.025000
2021-05-27 21:49:33,243 epoch 18 - iter 42/64 - loss 0.18296175 - samples/sec: 61.36 - lr: 0.025000
2021-05-27 21:49:36,417 epoch 18 - iter 48/64 - loss 0.18228694 - samples/sec: 60.49 - lr: 0.025000
2021-05-27 21:49:39,555 epoch 18 - iter 54/64 - loss 0.18398910 - samples/sec: 61.21 - lr: 0.025000
2021-05-27 21:49:42,686 epoch 18 - iter 60/64 - loss 0.19031549 - samples/sec: 61.34 - lr: 0.025000
2021-05-27 21:49:44,533 ----------------------------------------------------------------------------------------------------
2021-05-27 21:49:44,533 EPOCH 18 done: loss 0.1934 - lr 0.0250000
2021-05-27 21:49:46,381 DEV : loss 0.1580721139907837 - score 0.9762
2021-05-27 21:49:46,409 BAD EPOCHS (no improvement): 3
2021-05-27 21:49:46,409 ----------------------------------------------------------------------------------------------------
2021-05-27 21:49:49,497 epoch 19 - iter 6/64 - loss 0.11532403 - samples/sec: 62.19 - lr: 0.025000
2021-05-27 21:49:52,649 epoch 19 - iter 12/64 - loss 0.11060886 - samples/sec: 60.93 - lr: 0.025000
2021-05-27 21:49:55,811 epoch 19 - iter 18/64 - loss 0.16473115 - samples/sec: 60.72 - lr: 0.025000
2021-05-27 21:49:58,935 epoch 19 - iter 24/64 - loss 0.18566665 - samples/sec: 61.48 - lr: 0.025000
2021-05-27 21:50:02,048 epoch 19 - iter 30/64 - loss 0.17661531 - samples/sec: 61.70 - lr: 0.025000
2021-05-27 21:50:05,193 epoch 19 - iter 36/64 - loss 0.17464283 - samples/sec: 61.05 - lr: 0.025000
2021-05-27 21:50:08,360 epoch 19 - iter 42/64 - loss 0.16911793 - samples/sec: 60.63 - lr: 0.025000
2021-05-27 21:50:11,454 epoch 19 - iter 48/64 - loss 0.17259394 - samples/sec: 62.08 - lr: 0.025000
2021-05-27 21:50:14,627 epoch 19 - iter 54/64 - loss 0.17445665 - samples/sec: 60.52 - lr: 0.025000
2021-05-27 21:50:17,805 epoch 19 - iter 60/64 - loss 0.17174905 - samples/sec: 60.43 - lr: 0.025000
2021-05-27 21:50:19,662 ----------------------------------------------------------------------------------------------------
2021-05-27 21:50:19,662 EPOCH 19 done: loss 0.1738 - lr 0.0250000
2021-05-27 21:50:21,300 DEV : loss 0.14985625445842743 - score 0.9805
Epoch    19: reducing learning rate of group 0 to 1.2500e-02.
2021-05-27 21:50:21,328 BAD EPOCHS (no improvement): 4
2021-05-27 21:50:21,328 ----------------------------------------------------------------------------------------------------
2021-05-27 21:50:24,497 epoch 20 - iter 6/64 - loss 0.14406760 - samples/sec: 60.61 - lr: 0.012500
2021-05-27 21:50:27,621 epoch 20 - iter 12/64 - loss 0.13592202 - samples/sec: 61.47 - lr: 0.012500
2021-05-27 21:50:30,791 epoch 20 - iter 18/64 - loss 0.14753765 - samples/sec: 60.57 - lr: 0.012500
2021-05-27 21:50:33,907 epoch 20 - iter 24/64 - loss 0.19310088 - samples/sec: 61.65 - lr: 0.012500
2021-05-27 21:50:37,032 epoch 20 - iter 30/64 - loss 0.18203310 - samples/sec: 61.44 - lr: 0.012500
2021-05-27 21:50:40,107 epoch 20 - iter 36/64 - loss 0.17801831 - samples/sec: 62.46 - lr: 0.012500
2021-05-27 21:50:43,266 epoch 20 - iter 42/64 - loss 0.17878086 - samples/sec: 60.79 - lr: 0.012500
2021-05-27 21:50:46,387 epoch 20 - iter 48/64 - loss 0.17537789 - samples/sec: 61.52 - lr: 0.012500
2021-05-27 21:50:49,580 epoch 20 - iter 54/64 - loss 0.16989412 - samples/sec: 60.15 - lr: 0.012500
2021-05-27 21:50:52,719 epoch 20 - iter 60/64 - loss 0.17617190 - samples/sec: 61.18 - lr: 0.012500
2021-05-27 21:50:54,576 ----------------------------------------------------------------------------------------------------
2021-05-27 21:50:54,576 EPOCH 20 done: loss 0.1815 - lr 0.0125000
2021-05-27 21:50:56,208 DEV : loss 0.15663568675518036 - score 0.9804
2021-05-27 21:50:56,237 BAD EPOCHS (no improvement): 1
2021-05-27 21:50:56,238 ----------------------------------------------------------------------------------------------------
2021-05-27 21:50:59,338 epoch 21 - iter 6/64 - loss 0.11383276 - samples/sec: 61.95 - lr: 0.012500
2021-05-27 21:51:02,504 epoch 21 - iter 12/64 - loss 0.13945312 - samples/sec: 60.65 - lr: 0.012500
2021-05-27 21:51:05,617 epoch 21 - iter 18/64 - loss 0.17421904 - samples/sec: 61.68 - lr: 0.012500
2021-05-27 21:51:08,727 epoch 21 - iter 24/64 - loss 0.17558279 - samples/sec: 61.77 - lr: 0.012500
2021-05-27 21:51:11,879 epoch 21 - iter 30/64 - loss 0.17750576 - samples/sec: 60.92 - lr: 0.012500
2021-05-27 21:51:15,011 epoch 21 - iter 36/64 - loss 0.17901953 - samples/sec: 61.32 - lr: 0.012500
2021-05-27 21:51:18,096 epoch 21 - iter 42/64 - loss 0.18268706 - samples/sec: 62.26 - lr: 0.012500
2021-05-27 21:51:21,213 epoch 21 - iter 48/64 - loss 0.18109227 - samples/sec: 61.61 - lr: 0.012500
2021-05-27 21:51:24,378 epoch 21 - iter 54/64 - loss 0.17323940 - samples/sec: 60.66 - lr: 0.012500
2021-05-27 21:51:27,485 epoch 21 - iter 60/64 - loss 0.16563228 - samples/sec: 61.82 - lr: 0.012500
2021-05-27 21:51:29,302 ----------------------------------------------------------------------------------------------------
2021-05-27 21:51:29,303 EPOCH 21 done: loss 0.1690 - lr 0.0125000
2021-05-27 21:51:30,933 DEV : loss 0.15807268023490906 - score 0.9783
2021-05-27 21:51:30,961 BAD EPOCHS (no improvement): 2
2021-05-27 21:51:30,962 ----------------------------------------------------------------------------------------------------
2021-05-27 21:51:34,272 epoch 22 - iter 6/64 - loss 0.14934025 - samples/sec: 58.01 - lr: 0.012500
2021-05-27 21:51:37,399 epoch 22 - iter 12/64 - loss 0.16142888 - samples/sec: 61.42 - lr: 0.012500
2021-05-27 21:51:40,525 epoch 22 - iter 18/64 - loss 0.17228184 - samples/sec: 61.43 - lr: 0.012500
2021-05-27 21:51:43,653 epoch 22 - iter 24/64 - loss 0.16030532 - samples/sec: 61.41 - lr: 0.012500
2021-05-27 21:51:46,776 epoch 22 - iter 30/64 - loss 0.16657008 - samples/sec: 61.49 - lr: 0.012500
2021-05-27 21:51:49,887 epoch 22 - iter 36/64 - loss 0.16578008 - samples/sec: 61.73 - lr: 0.012500
2021-05-27 21:51:53,018 epoch 22 - iter 42/64 - loss 0.15788032 - samples/sec: 61.33 - lr: 0.012500
2021-05-27 21:51:56,159 epoch 22 - iter 48/64 - loss 0.15984565 - samples/sec: 61.14 - lr: 0.012500
2021-05-27 21:51:59,301 epoch 22 - iter 54/64 - loss 0.15864475 - samples/sec: 61.12 - lr: 0.012500
2021-05-27 21:52:02,402 epoch 22 - iter 60/64 - loss 0.15580701 - samples/sec: 61.95 - lr: 0.012500
2021-05-27 21:52:04,198 ----------------------------------------------------------------------------------------------------
2021-05-27 21:52:04,198 EPOCH 22 done: loss 0.1497 - lr 0.0125000
2021-05-27 21:52:05,827 DEV : loss 0.16455966234207153 - score 0.9761
2021-05-27 21:52:05,856 BAD EPOCHS (no improvement): 3
2021-05-27 21:52:05,856 ----------------------------------------------------------------------------------------------------
2021-05-27 21:52:08,949 epoch 23 - iter 6/64 - loss 0.23895530 - samples/sec: 62.10 - lr: 0.012500
2021-05-27 21:52:12,036 epoch 23 - iter 12/64 - loss 0.20780680 - samples/sec: 62.20 - lr: 0.012500
2021-05-27 21:52:15,107 epoch 23 - iter 18/64 - loss 0.18299054 - samples/sec: 62.54 - lr: 0.012500
2021-05-27 21:52:18,208 epoch 23 - iter 24/64 - loss 0.19064355 - samples/sec: 61.92 - lr: 0.012500
2021-05-27 21:52:21,340 epoch 23 - iter 30/64 - loss 0.17899311 - samples/sec: 61.32 - lr: 0.012500
2021-05-27 21:52:24,459 epoch 23 - iter 36/64 - loss 0.16714137 - samples/sec: 61.58 - lr: 0.012500
2021-05-27 21:52:27,591 epoch 23 - iter 42/64 - loss 0.16478866 - samples/sec: 61.30 - lr: 0.012500
2021-05-27 21:52:30,684 epoch 23 - iter 48/64 - loss 0.16066616 - samples/sec: 62.10 - lr: 0.012500
2021-05-27 21:52:33,783 epoch 23 - iter 54/64 - loss 0.15770373 - samples/sec: 61.96 - lr: 0.012500
2021-05-27 21:52:36,882 epoch 23 - iter 60/64 - loss 0.15978298 - samples/sec: 61.98 - lr: 0.012500
2021-05-27 21:52:38,672 ----------------------------------------------------------------------------------------------------
2021-05-27 21:52:38,673 EPOCH 23 done: loss 0.1585 - lr 0.0125000
2021-05-27 21:52:40,306 DEV : loss 0.162469744682312 - score 0.9805
Epoch    23: reducing learning rate of group 0 to 6.2500e-03.
2021-05-27 21:52:40,335 BAD EPOCHS (no improvement): 4
2021-05-27 21:52:40,335 ----------------------------------------------------------------------------------------------------
2021-05-27 21:52:43,454 epoch 24 - iter 6/64 - loss 0.16072635 - samples/sec: 61.57 - lr: 0.006250
2021-05-27 21:52:46,575 epoch 24 - iter 12/64 - loss 0.16137286 - samples/sec: 61.54 - lr: 0.006250
2021-05-27 21:52:49,682 epoch 24 - iter 18/64 - loss 0.16509791 - samples/sec: 61.82 - lr: 0.006250
2021-05-27 21:52:52,772 epoch 24 - iter 24/64 - loss 0.17692963 - samples/sec: 62.15 - lr: 0.006250
2021-05-27 21:52:55,890 epoch 24 - iter 30/64 - loss 0.17949541 - samples/sec: 61.58 - lr: 0.006250
2021-05-27 21:52:58,987 epoch 24 - iter 36/64 - loss 0.16771568 - samples/sec: 62.01 - lr: 0.006250
2021-05-27 21:53:02,101 epoch 24 - iter 42/64 - loss 0.16242313 - samples/sec: 61.68 - lr: 0.006250
2021-05-27 21:53:05,237 epoch 24 - iter 48/64 - loss 0.15835359 - samples/sec: 61.23 - lr: 0.006250
2021-05-27 21:53:08,323 epoch 24 - iter 54/64 - loss 0.16325261 - samples/sec: 62.23 - lr: 0.006250
2021-05-27 21:53:11,387 epoch 24 - iter 60/64 - loss 0.16189976 - samples/sec: 62.68 - lr: 0.006250
2021-05-27 21:53:13,199 ----------------------------------------------------------------------------------------------------
2021-05-27 21:53:13,199 EPOCH 24 done: loss 0.1593 - lr 0.0062500
2021-05-27 21:53:14,832 DEV : loss 0.16684463620185852 - score 0.9784
2021-05-27 21:53:14,860 BAD EPOCHS (no improvement): 1
2021-05-27 21:53:14,861 ----------------------------------------------------------------------------------------------------
2021-05-27 21:53:17,957 epoch 25 - iter 6/64 - loss 0.08695675 - samples/sec: 62.02 - lr: 0.006250
2021-05-27 21:53:21,099 epoch 25 - iter 12/64 - loss 0.11868718 - samples/sec: 61.12 - lr: 0.006250
2021-05-27 21:53:24,401 epoch 25 - iter 18/64 - loss 0.15033698 - samples/sec: 58.15 - lr: 0.006250
2021-05-27 21:53:27,497 epoch 25 - iter 24/64 - loss 0.13624861 - samples/sec: 62.04 - lr: 0.006250
2021-05-27 21:53:30,612 epoch 25 - iter 30/64 - loss 0.12696383 - samples/sec: 61.64 - lr: 0.006250
2021-05-27 21:53:33,709 epoch 25 - iter 36/64 - loss 0.13693347 - samples/sec: 62.02 - lr: 0.006250
2021-05-27 21:53:36,783 epoch 25 - iter 42/64 - loss 0.13514872 - samples/sec: 62.48 - lr: 0.006250
2021-05-27 21:53:39,877 epoch 25 - iter 48/64 - loss 0.14887646 - samples/sec: 62.06 - lr: 0.006250
2021-05-27 21:53:42,979 epoch 25 - iter 54/64 - loss 0.14636600 - samples/sec: 61.91 - lr: 0.006250
2021-05-27 21:53:46,092 epoch 25 - iter 60/64 - loss 0.14557785 - samples/sec: 61.69 - lr: 0.006250
2021-05-27 21:53:47,930 ----------------------------------------------------------------------------------------------------
2021-05-27 21:53:47,930 EPOCH 25 done: loss 0.1468 - lr 0.0062500
2021-05-27 21:53:49,569 DEV : loss 0.16339880228042603 - score 0.9783
2021-05-27 21:53:49,598 BAD EPOCHS (no improvement): 2
2021-05-27 21:53:49,598 ----------------------------------------------------------------------------------------------------
2021-05-27 21:53:52,725 epoch 26 - iter 6/64 - loss 0.11128608 - samples/sec: 61.41 - lr: 0.006250
2021-05-27 21:53:55,838 epoch 26 - iter 12/64 - loss 0.16235511 - samples/sec: 61.70 - lr: 0.006250
2021-05-27 21:53:58,933 epoch 26 - iter 18/64 - loss 0.19546403 - samples/sec: 62.04 - lr: 0.006250
2021-05-27 21:54:02,034 epoch 26 - iter 24/64 - loss 0.20483702 - samples/sec: 61.94 - lr: 0.006250
2021-05-27 21:54:05,135 epoch 26 - iter 30/64 - loss 0.19215456 - samples/sec: 61.93 - lr: 0.006250
2021-05-27 21:54:08,205 epoch 26 - iter 36/64 - loss 0.18645397 - samples/sec: 62.55 - lr: 0.006250
2021-05-27 21:54:11,333 epoch 26 - iter 42/64 - loss 0.19339289 - samples/sec: 61.40 - lr: 0.006250
2021-05-27 21:54:14,432 epoch 26 - iter 48/64 - loss 0.18433517 - samples/sec: 61.97 - lr: 0.006250
2021-05-27 21:54:17,535 epoch 26 - iter 54/64 - loss 0.18198982 - samples/sec: 61.88 - lr: 0.006250
2021-05-27 21:54:20,612 epoch 26 - iter 60/64 - loss 0.17496408 - samples/sec: 62.43 - lr: 0.006250
2021-05-27 21:54:22,450 ----------------------------------------------------------------------------------------------------
2021-05-27 21:54:22,450 EPOCH 26 done: loss 0.1740 - lr 0.0062500
2021-05-27 21:54:24,082 DEV : loss 0.16077099740505219 - score 0.9783
2021-05-27 21:54:24,111 BAD EPOCHS (no improvement): 3
2021-05-27 21:54:24,111 ----------------------------------------------------------------------------------------------------
2021-05-27 21:54:27,223 epoch 27 - iter 6/64 - loss 0.11031233 - samples/sec: 61.72 - lr: 0.006250
2021-05-27 21:54:30,355 epoch 27 - iter 12/64 - loss 0.12864332 - samples/sec: 61.32 - lr: 0.006250
2021-05-27 21:54:33,467 epoch 27 - iter 18/64 - loss 0.14685504 - samples/sec: 61.71 - lr: 0.006250
2021-05-27 21:54:36,622 epoch 27 - iter 24/64 - loss 0.13654707 - samples/sec: 60.86 - lr: 0.006250
2021-05-27 21:54:39,788 epoch 27 - iter 30/64 - loss 0.13771748 - samples/sec: 60.66 - lr: 0.006250
2021-05-27 21:54:42,934 epoch 27 - iter 36/64 - loss 0.14487752 - samples/sec: 61.05 - lr: 0.006250
2021-05-27 21:54:46,070 epoch 27 - iter 42/64 - loss 0.14949742 - samples/sec: 61.23 - lr: 0.006250
2021-05-27 21:54:49,200 epoch 27 - iter 48/64 - loss 0.15568603 - samples/sec: 61.36 - lr: 0.006250
2021-05-27 21:54:52,316 epoch 27 - iter 54/64 - loss 0.15281060 - samples/sec: 61.63 - lr: 0.006250
2021-05-27 21:54:55,440 epoch 27 - iter 60/64 - loss 0.14488205 - samples/sec: 61.48 - lr: 0.006250
2021-05-27 21:54:57,280 ----------------------------------------------------------------------------------------------------
2021-05-27 21:54:57,280 EPOCH 27 done: loss 0.1491 - lr 0.0062500
2021-05-27 21:54:58,927 DEV : loss 0.1596785932779312 - score 0.9805
Epoch    27: reducing learning rate of group 0 to 3.1250e-03.
2021-05-27 21:54:58,956 BAD EPOCHS (no improvement): 4
2021-05-27 21:54:58,956 ----------------------------------------------------------------------------------------------------
2021-05-27 21:55:02,079 epoch 28 - iter 6/64 - loss 0.15045007 - samples/sec: 61.50 - lr: 0.003125
2021-05-27 21:55:05,234 epoch 28 - iter 12/64 - loss 0.16031200 - samples/sec: 60.87 - lr: 0.003125
2021-05-27 21:55:08,401 epoch 28 - iter 18/64 - loss 0.16363384 - samples/sec: 60.65 - lr: 0.003125
2021-05-27 21:55:11,521 epoch 28 - iter 24/64 - loss 0.15774193 - samples/sec: 61.55 - lr: 0.003125
2021-05-27 21:55:14,643 epoch 28 - iter 30/64 - loss 0.14925436 - samples/sec: 61.51 - lr: 0.003125
2021-05-27 21:55:17,802 epoch 28 - iter 36/64 - loss 0.14573005 - samples/sec: 60.79 - lr: 0.003125
2021-05-27 21:55:20,930 epoch 28 - iter 42/64 - loss 0.14181601 - samples/sec: 61.40 - lr: 0.003125
2021-05-27 21:55:24,081 epoch 28 - iter 48/64 - loss 0.14650147 - samples/sec: 60.94 - lr: 0.003125
2021-05-27 21:55:27,187 epoch 28 - iter 54/64 - loss 0.15354518 - samples/sec: 61.84 - lr: 0.003125
2021-05-27 21:55:30,320 epoch 28 - iter 60/64 - loss 0.15467980 - samples/sec: 61.29 - lr: 0.003125
2021-05-27 21:55:32,161 ----------------------------------------------------------------------------------------------------
2021-05-27 21:55:32,162 EPOCH 28 done: loss 0.1493 - lr 0.0031250
2021-05-27 21:55:34,006 DEV : loss 0.15851068496704102 - score 0.9805
2021-05-27 21:55:34,034 BAD EPOCHS (no improvement): 1
2021-05-27 21:55:34,035 ----------------------------------------------------------------------------------------------------
2021-05-27 21:55:37,164 epoch 29 - iter 6/64 - loss 0.09170133 - samples/sec: 61.36 - lr: 0.003125
2021-05-27 21:55:40,267 epoch 29 - iter 12/64 - loss 0.09581019 - samples/sec: 61.89 - lr: 0.003125
2021-05-27 21:55:43,448 epoch 29 - iter 18/64 - loss 0.12369550 - samples/sec: 60.37 - lr: 0.003125
2021-05-27 21:55:46,577 epoch 29 - iter 24/64 - loss 0.13157046 - samples/sec: 61.38 - lr: 0.003125
2021-05-27 21:55:49,686 epoch 29 - iter 30/64 - loss 0.13503911 - samples/sec: 61.77 - lr: 0.003125
2021-05-27 21:55:52,793 epoch 29 - iter 36/64 - loss 0.13315660 - samples/sec: 61.81 - lr: 0.003125
2021-05-27 21:55:55,920 epoch 29 - iter 42/64 - loss 0.13317768 - samples/sec: 61.42 - lr: 0.003125
2021-05-27 21:55:59,054 epoch 29 - iter 48/64 - loss 0.12304667 - samples/sec: 61.27 - lr: 0.003125
2021-05-27 21:56:02,190 epoch 29 - iter 54/64 - loss 0.13594124 - samples/sec: 61.24 - lr: 0.003125
2021-05-27 21:56:05,319 epoch 29 - iter 60/64 - loss 0.13381548 - samples/sec: 61.37 - lr: 0.003125
2021-05-27 21:56:07,158 ----------------------------------------------------------------------------------------------------
2021-05-27 21:56:07,159 EPOCH 29 done: loss 0.1281 - lr 0.0031250
2021-05-27 21:56:08,793 DEV : loss 0.1592579483985901 - score 0.9783
2021-05-27 21:56:08,821 BAD EPOCHS (no improvement): 2
2021-05-27 21:56:08,821 ----------------------------------------------------------------------------------------------------
2021-05-27 21:56:11,978 epoch 30 - iter 6/64 - loss 0.08515657 - samples/sec: 60.84 - lr: 0.003125
2021-05-27 21:56:15,120 epoch 30 - iter 12/64 - loss 0.10445090 - samples/sec: 61.11 - lr: 0.003125
2021-05-27 21:56:18,253 epoch 30 - iter 18/64 - loss 0.11154074 - samples/sec: 61.29 - lr: 0.003125
2021-05-27 21:56:21,373 epoch 30 - iter 24/64 - loss 0.12033487 - samples/sec: 61.57 - lr: 0.003125
2021-05-27 21:56:24,482 epoch 30 - iter 30/64 - loss 0.12426305 - samples/sec: 61.75 - lr: 0.003125
2021-05-27 21:56:27,650 epoch 30 - iter 36/64 - loss 0.12972639 - samples/sec: 60.63 - lr: 0.003125
2021-05-27 21:56:30,811 epoch 30 - iter 42/64 - loss 0.13827448 - samples/sec: 60.75 - lr: 0.003125
2021-05-27 21:56:33,982 epoch 30 - iter 48/64 - loss 0.14035677 - samples/sec: 60.58 - lr: 0.003125
2021-05-27 21:56:37,107 epoch 30 - iter 54/64 - loss 0.14845004 - samples/sec: 61.44 - lr: 0.003125
2021-05-27 21:56:40,217 epoch 30 - iter 60/64 - loss 0.14243614 - samples/sec: 61.75 - lr: 0.003125
2021-05-27 21:56:42,063 ----------------------------------------------------------------------------------------------------
2021-05-27 21:56:42,063 EPOCH 30 done: loss 0.1444 - lr 0.0031250
2021-05-27 21:56:43,695 DEV : loss 0.1615944355726242 - score 0.9784
2021-05-27 21:56:43,724 BAD EPOCHS (no improvement): 3
2021-05-27 21:56:44,844 ----------------------------------------------------------------------------------------------------
2021-05-27 21:56:44,844 Testing using best model ...
2021-05-27 21:56:44,844 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/por.rst.cstn/best-model.pt
2021-05-27 21:56:50,421 0.9609	1.0000	0.9801
2021-05-27 21:56:50,421 
Results:
- F1-score (micro) 0.9801
- F1-score (macro) 0.9801

By class:
SENT       tp: 123 - fp: 5 - fn: 0 - precision: 0.9609 - recall: 1.0000 - f1-score: 0.9801
2021-05-27 21:56:50,421 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/
2021-05-27 21:56:50,450 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb
2021-05-27 21:56:50,450 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/sent_train.txt
2021-05-27 21:56:50,452 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/sent_dev.txt
2021-05-27 21:56:50,455 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/sent_test.txt
Corpus: 18701 train + 2362 dev + 2245 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-27 21:57:05,333 ----------------------------------------------------------------------------------------------------
2021-05-27 21:57:05,335 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-27 21:57:05,335 ----------------------------------------------------------------------------------------------------
2021-05-27 21:57:05,335 Corpus: "Corpus: 18701 train + 2362 dev + 2245 test sentences"
2021-05-27 21:57:05,335 ----------------------------------------------------------------------------------------------------
2021-05-27 21:57:05,336 Parameters:
2021-05-27 21:57:05,336  - learning_rate: "0.1"
2021-05-27 21:57:05,336  - mini_batch_size: "32"
2021-05-27 21:57:05,336  - patience: "3"
2021-05-27 21:57:05,336  - anneal_factor: "0.5"
2021-05-27 21:57:05,336  - max_epochs: "30"
2021-05-27 21:57:05,336  - shuffle: "True"
2021-05-27 21:57:05,336  - train_with_dev: "False"
2021-05-27 21:57:05,336  - batch_growth_annealing: "False"
2021-05-27 21:57:05,336 ----------------------------------------------------------------------------------------------------
2021-05-27 21:57:05,336 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb"
2021-05-27 21:57:05,336 ----------------------------------------------------------------------------------------------------
2021-05-27 21:57:05,336 Device: cuda:0
2021-05-27 21:57:05,336 ----------------------------------------------------------------------------------------------------
2021-05-27 21:57:05,336 Embeddings storage mode: cpu
2021-05-27 21:57:05,337 ----------------------------------------------------------------------------------------------------
2021-05-27 21:58:25,884 epoch 1 - iter 58/585 - loss 5.40261882 - samples/sec: 23.04 - lr: 0.100000
2021-05-27 21:59:46,214 epoch 1 - iter 116/585 - loss 3.86613204 - samples/sec: 23.11 - lr: 0.100000
2021-05-27 22:01:11,299 epoch 1 - iter 174/585 - loss 3.14244183 - samples/sec: 21.81 - lr: 0.100000
2021-05-27 22:02:35,316 epoch 1 - iter 232/585 - loss 2.71351894 - samples/sec: 22.09 - lr: 0.100000
2021-05-27 22:03:59,362 epoch 1 - iter 290/585 - loss 2.43423076 - samples/sec: 22.08 - lr: 0.100000
2021-05-27 22:05:23,581 epoch 1 - iter 348/585 - loss 2.22021201 - samples/sec: 22.04 - lr: 0.100000
2021-05-27 22:06:47,632 epoch 1 - iter 406/585 - loss 2.04425652 - samples/sec: 22.08 - lr: 0.100000
2021-05-27 22:08:11,740 epoch 1 - iter 464/585 - loss 1.93344287 - samples/sec: 22.07 - lr: 0.100000
2021-05-27 22:09:36,139 epoch 1 - iter 522/585 - loss 1.81518342 - samples/sec: 21.99 - lr: 0.100000
2021-05-27 22:10:59,160 epoch 1 - iter 580/585 - loss 1.73283847 - samples/sec: 22.36 - lr: 0.100000
2021-05-27 22:11:05,441 ----------------------------------------------------------------------------------------------------
2021-05-27 22:11:05,441 EPOCH 1 done: loss 1.7273 - lr 0.1000000
2021-05-27 22:12:10,141 DEV : loss 0.553177535533905 - score 0.9318
2021-05-27 22:12:10,380 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 22:12:11,635 ----------------------------------------------------------------------------------------------------
2021-05-27 22:12:43,232 epoch 2 - iter 58/585 - loss 0.77525761 - samples/sec: 58.75 - lr: 0.100000
2021-05-27 22:13:14,488 epoch 2 - iter 116/585 - loss 0.82529153 - samples/sec: 59.39 - lr: 0.100000
2021-05-27 22:13:45,729 epoch 2 - iter 174/585 - loss 0.83095020 - samples/sec: 59.41 - lr: 0.100000
2021-05-27 22:14:17,008 epoch 2 - iter 232/585 - loss 0.82645961 - samples/sec: 59.34 - lr: 0.100000
2021-05-27 22:14:48,175 epoch 2 - iter 290/585 - loss 0.83563694 - samples/sec: 59.56 - lr: 0.100000
2021-05-27 22:15:19,421 epoch 2 - iter 348/585 - loss 0.81285300 - samples/sec: 59.41 - lr: 0.100000
2021-05-27 22:15:50,523 epoch 2 - iter 406/585 - loss 0.81032872 - samples/sec: 59.68 - lr: 0.100000
2021-05-27 22:16:21,521 epoch 2 - iter 464/585 - loss 0.79898659 - samples/sec: 59.88 - lr: 0.100000
2021-05-27 22:16:52,506 epoch 2 - iter 522/585 - loss 0.79593842 - samples/sec: 59.90 - lr: 0.100000
2021-05-27 22:17:23,625 epoch 2 - iter 580/585 - loss 0.78954418 - samples/sec: 59.65 - lr: 0.100000
2021-05-27 22:17:26,021 ----------------------------------------------------------------------------------------------------
2021-05-27 22:17:26,021 EPOCH 2 done: loss 0.7874 - lr 0.1000000
2021-05-27 22:17:41,807 DEV : loss 0.720748782157898 - score 0.9115
2021-05-27 22:17:42,046 BAD EPOCHS (no improvement): 1
2021-05-27 22:17:42,046 ----------------------------------------------------------------------------------------------------
2021-05-27 22:18:13,189 epoch 3 - iter 58/585 - loss 0.74597652 - samples/sec: 59.60 - lr: 0.100000
2021-05-27 22:18:44,364 epoch 3 - iter 116/585 - loss 0.67187726 - samples/sec: 59.54 - lr: 0.100000
2021-05-27 22:19:15,597 epoch 3 - iter 174/585 - loss 0.67019021 - samples/sec: 59.43 - lr: 0.100000
2021-05-27 22:19:46,671 epoch 3 - iter 232/585 - loss 0.67012223 - samples/sec: 59.73 - lr: 0.100000
2021-05-27 22:20:17,817 epoch 3 - iter 290/585 - loss 0.68050673 - samples/sec: 59.60 - lr: 0.100000
2021-05-27 22:20:48,599 epoch 3 - iter 348/585 - loss 0.69165619 - samples/sec: 60.30 - lr: 0.100000
2021-05-27 22:21:19,759 epoch 3 - iter 406/585 - loss 0.69914437 - samples/sec: 59.57 - lr: 0.100000
2021-05-27 22:21:50,946 epoch 3 - iter 464/585 - loss 0.69828938 - samples/sec: 59.52 - lr: 0.100000
2021-05-27 22:22:22,190 epoch 3 - iter 522/585 - loss 0.69164124 - samples/sec: 59.41 - lr: 0.100000
2021-05-27 22:22:53,408 epoch 3 - iter 580/585 - loss 0.69062508 - samples/sec: 59.46 - lr: 0.100000
2021-05-27 22:22:55,816 ----------------------------------------------------------------------------------------------------
2021-05-27 22:22:55,817 EPOCH 3 done: loss 0.6899 - lr 0.1000000
2021-05-27 22:23:09,964 DEV : loss 0.5912811160087585 - score 0.9261
2021-05-27 22:23:10,202 BAD EPOCHS (no improvement): 2
2021-05-27 22:23:10,202 ----------------------------------------------------------------------------------------------------
2021-05-27 22:23:41,304 epoch 4 - iter 58/585 - loss 0.63136344 - samples/sec: 59.68 - lr: 0.100000
2021-05-27 22:24:12,388 epoch 4 - iter 116/585 - loss 0.62247157 - samples/sec: 59.71 - lr: 0.100000
2021-05-27 22:24:43,465 epoch 4 - iter 174/585 - loss 0.63742944 - samples/sec: 59.73 - lr: 0.100000
2021-05-27 22:25:14,611 epoch 4 - iter 232/585 - loss 0.64265910 - samples/sec: 59.60 - lr: 0.100000
2021-05-27 22:25:45,807 epoch 4 - iter 290/585 - loss 0.65321237 - samples/sec: 59.50 - lr: 0.100000
2021-05-27 22:26:16,965 epoch 4 - iter 348/585 - loss 0.65569107 - samples/sec: 59.57 - lr: 0.100000
2021-05-27 22:26:48,128 epoch 4 - iter 406/585 - loss 0.64901073 - samples/sec: 59.56 - lr: 0.100000
2021-05-27 22:27:19,193 epoch 4 - iter 464/585 - loss 0.64825347 - samples/sec: 59.75 - lr: 0.100000
2021-05-27 22:27:50,215 epoch 4 - iter 522/585 - loss 0.63717437 - samples/sec: 59.84 - lr: 0.100000
2021-05-27 22:28:21,473 epoch 4 - iter 580/585 - loss 0.63123465 - samples/sec: 59.38 - lr: 0.100000
2021-05-27 22:28:23,883 ----------------------------------------------------------------------------------------------------
2021-05-27 22:28:23,883 EPOCH 4 done: loss 0.6324 - lr 0.1000000
2021-05-27 22:28:38,039 DEV : loss 0.435314804315567 - score 0.9425
2021-05-27 22:28:38,279 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 22:28:47,235 ----------------------------------------------------------------------------------------------------
2021-05-27 22:29:18,452 epoch 5 - iter 58/585 - loss 0.60021930 - samples/sec: 59.46 - lr: 0.100000
2021-05-27 22:29:49,617 epoch 5 - iter 116/585 - loss 0.58075936 - samples/sec: 59.56 - lr: 0.100000
2021-05-27 22:30:20,802 epoch 5 - iter 174/585 - loss 0.58015325 - samples/sec: 59.52 - lr: 0.100000
2021-05-27 22:30:51,930 epoch 5 - iter 232/585 - loss 0.58790310 - samples/sec: 59.63 - lr: 0.100000
2021-05-27 22:31:23,077 epoch 5 - iter 290/585 - loss 0.58179613 - samples/sec: 59.60 - lr: 0.100000
2021-05-27 22:31:54,195 epoch 5 - iter 348/585 - loss 0.59084770 - samples/sec: 59.65 - lr: 0.100000
2021-05-27 22:32:25,403 epoch 5 - iter 406/585 - loss 0.59297850 - samples/sec: 59.48 - lr: 0.100000
2021-05-27 22:32:56,547 epoch 5 - iter 464/585 - loss 0.58299387 - samples/sec: 59.60 - lr: 0.100000
2021-05-27 22:33:27,743 epoch 5 - iter 522/585 - loss 0.58477784 - samples/sec: 59.50 - lr: 0.100000
2021-05-27 22:33:58,857 epoch 5 - iter 580/585 - loss 0.57806340 - samples/sec: 59.66 - lr: 0.100000
2021-05-27 22:34:01,269 ----------------------------------------------------------------------------------------------------
2021-05-27 22:34:01,269 EPOCH 5 done: loss 0.5783 - lr 0.1000000
2021-05-27 22:34:16,920 DEV : loss 0.41285377740859985 - score 0.9451
2021-05-27 22:34:17,158 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 22:34:26,064 ----------------------------------------------------------------------------------------------------
2021-05-27 22:34:57,195 epoch 6 - iter 58/585 - loss 0.52094561 - samples/sec: 59.63 - lr: 0.100000
2021-05-27 22:35:28,445 epoch 6 - iter 116/585 - loss 0.53259210 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 22:35:59,570 epoch 6 - iter 174/585 - loss 0.53388276 - samples/sec: 59.64 - lr: 0.100000
2021-05-27 22:36:30,811 epoch 6 - iter 232/585 - loss 0.53270366 - samples/sec: 59.42 - lr: 0.100000
2021-05-27 22:37:02,085 epoch 6 - iter 290/585 - loss 0.53202045 - samples/sec: 59.35 - lr: 0.100000
2021-05-27 22:37:33,038 epoch 6 - iter 348/585 - loss 0.53426472 - samples/sec: 59.97 - lr: 0.100000
2021-05-27 22:38:03,917 epoch 6 - iter 406/585 - loss 0.53099277 - samples/sec: 60.11 - lr: 0.100000
2021-05-27 22:38:35,073 epoch 6 - iter 464/585 - loss 0.53077353 - samples/sec: 59.58 - lr: 0.100000
2021-05-27 22:39:06,331 epoch 6 - iter 522/585 - loss 0.52813816 - samples/sec: 59.38 - lr: 0.100000
2021-05-27 22:39:37,352 epoch 6 - iter 580/585 - loss 0.53049319 - samples/sec: 59.84 - lr: 0.100000
2021-05-27 22:39:39,724 ----------------------------------------------------------------------------------------------------
2021-05-27 22:39:39,724 EPOCH 6 done: loss 0.5300 - lr 0.1000000
2021-05-27 22:39:53,869 DEV : loss 0.39312058687210083 - score 0.9479
2021-05-27 22:39:54,110 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 22:40:02,935 ----------------------------------------------------------------------------------------------------
2021-05-27 22:40:33,971 epoch 7 - iter 58/585 - loss 0.52623935 - samples/sec: 59.81 - lr: 0.100000
2021-05-27 22:41:05,151 epoch 7 - iter 116/585 - loss 0.54042320 - samples/sec: 59.53 - lr: 0.100000
2021-05-27 22:41:36,184 epoch 7 - iter 174/585 - loss 0.53472514 - samples/sec: 59.81 - lr: 0.100000
2021-05-27 22:42:07,134 epoch 7 - iter 232/585 - loss 0.52730456 - samples/sec: 59.97 - lr: 0.100000
2021-05-27 22:42:38,322 epoch 7 - iter 290/585 - loss 0.53799434 - samples/sec: 59.52 - lr: 0.100000
2021-05-27 22:43:09,557 epoch 7 - iter 348/585 - loss 0.53614606 - samples/sec: 59.43 - lr: 0.100000
2021-05-27 22:43:40,804 epoch 7 - iter 406/585 - loss 0.53629647 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 22:44:11,902 epoch 7 - iter 464/585 - loss 0.53742764 - samples/sec: 59.69 - lr: 0.100000
2021-05-27 22:44:43,005 epoch 7 - iter 522/585 - loss 0.52598441 - samples/sec: 59.68 - lr: 0.100000
2021-05-27 22:45:14,107 epoch 7 - iter 580/585 - loss 0.52285263 - samples/sec: 59.68 - lr: 0.100000
2021-05-27 22:45:16,490 ----------------------------------------------------------------------------------------------------
2021-05-27 22:45:16,490 EPOCH 7 done: loss 0.5235 - lr 0.1000000
2021-05-27 22:45:30,631 DEV : loss 0.39263397455215454 - score 0.944
2021-05-27 22:45:30,872 BAD EPOCHS (no improvement): 1
2021-05-27 22:45:30,872 ----------------------------------------------------------------------------------------------------
2021-05-27 22:46:01,999 epoch 8 - iter 58/585 - loss 0.50099593 - samples/sec: 59.63 - lr: 0.100000
2021-05-27 22:46:33,159 epoch 8 - iter 116/585 - loss 0.49107690 - samples/sec: 59.57 - lr: 0.100000
2021-05-27 22:47:04,411 epoch 8 - iter 174/585 - loss 0.48327814 - samples/sec: 59.39 - lr: 0.100000
2021-05-27 22:47:35,703 epoch 8 - iter 232/585 - loss 0.47879041 - samples/sec: 59.32 - lr: 0.100000
2021-05-27 22:48:06,924 epoch 8 - iter 290/585 - loss 0.48179970 - samples/sec: 59.45 - lr: 0.100000
2021-05-27 22:48:38,188 epoch 8 - iter 348/585 - loss 0.48483796 - samples/sec: 59.37 - lr: 0.100000
2021-05-27 22:49:09,420 epoch 8 - iter 406/585 - loss 0.48382354 - samples/sec: 59.43 - lr: 0.100000
2021-05-27 22:49:40,671 epoch 8 - iter 464/585 - loss 0.48252007 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 22:50:11,920 epoch 8 - iter 522/585 - loss 0.48637686 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 22:50:44,617 epoch 8 - iter 580/585 - loss 0.48978309 - samples/sec: 56.77 - lr: 0.100000
2021-05-27 22:50:47,017 ----------------------------------------------------------------------------------------------------
2021-05-27 22:50:47,018 EPOCH 8 done: loss 0.4886 - lr 0.1000000
2021-05-27 22:51:01,152 DEV : loss 0.38421404361724854 - score 0.9515
2021-05-27 22:51:01,392 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 22:51:10,388 ----------------------------------------------------------------------------------------------------
2021-05-27 22:51:41,686 epoch 9 - iter 58/585 - loss 0.51053064 - samples/sec: 59.31 - lr: 0.100000
2021-05-27 22:52:12,729 epoch 9 - iter 116/585 - loss 0.50721531 - samples/sec: 59.79 - lr: 0.100000
2021-05-27 22:52:44,015 epoch 9 - iter 174/585 - loss 0.51138784 - samples/sec: 59.33 - lr: 0.100000
2021-05-27 22:53:15,270 epoch 9 - iter 232/585 - loss 0.50524010 - samples/sec: 59.39 - lr: 0.100000
2021-05-27 22:53:46,583 epoch 9 - iter 290/585 - loss 0.49649254 - samples/sec: 59.28 - lr: 0.100000
2021-05-27 22:54:17,833 epoch 9 - iter 348/585 - loss 0.48778278 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 22:54:49,089 epoch 9 - iter 406/585 - loss 0.48886683 - samples/sec: 59.39 - lr: 0.100000
2021-05-27 22:55:20,350 epoch 9 - iter 464/585 - loss 0.48607839 - samples/sec: 59.38 - lr: 0.100000
2021-05-27 22:55:51,703 epoch 9 - iter 522/585 - loss 0.48612197 - samples/sec: 59.20 - lr: 0.100000
2021-05-27 22:56:23,029 epoch 9 - iter 580/585 - loss 0.49549546 - samples/sec: 59.25 - lr: 0.100000
2021-05-27 22:56:25,424 ----------------------------------------------------------------------------------------------------
2021-05-27 22:56:25,425 EPOCH 9 done: loss 0.4943 - lr 0.1000000
2021-05-27 22:56:39,568 DEV : loss 0.37202757596969604 - score 0.9481
2021-05-27 22:56:39,812 BAD EPOCHS (no improvement): 1
2021-05-27 22:56:39,812 ----------------------------------------------------------------------------------------------------
2021-05-27 22:57:10,863 epoch 10 - iter 58/585 - loss 0.42579219 - samples/sec: 59.78 - lr: 0.100000
2021-05-27 22:57:41,804 epoch 10 - iter 116/585 - loss 0.43476774 - samples/sec: 59.99 - lr: 0.100000
2021-05-27 22:58:13,034 epoch 10 - iter 174/585 - loss 0.44402668 - samples/sec: 59.44 - lr: 0.100000
2021-05-27 22:58:44,327 epoch 10 - iter 232/585 - loss 0.45668260 - samples/sec: 59.32 - lr: 0.100000
2021-05-27 22:59:15,730 epoch 10 - iter 290/585 - loss 0.46342861 - samples/sec: 59.11 - lr: 0.100000
2021-05-27 22:59:47,079 epoch 10 - iter 348/585 - loss 0.45638924 - samples/sec: 59.21 - lr: 0.100000
2021-05-27 23:00:18,415 epoch 10 - iter 406/585 - loss 0.45444390 - samples/sec: 59.24 - lr: 0.100000
2021-05-27 23:00:49,668 epoch 10 - iter 464/585 - loss 0.45743015 - samples/sec: 59.39 - lr: 0.100000
2021-05-27 23:01:20,831 epoch 10 - iter 522/585 - loss 0.45661419 - samples/sec: 59.56 - lr: 0.100000
2021-05-27 23:01:52,054 epoch 10 - iter 580/585 - loss 0.46075243 - samples/sec: 59.45 - lr: 0.100000
2021-05-27 23:01:54,463 ----------------------------------------------------------------------------------------------------
2021-05-27 23:01:54,463 EPOCH 10 done: loss 0.4602 - lr 0.1000000
2021-05-27 23:02:08,610 DEV : loss 0.37227311730384827 - score 0.9522
2021-05-27 23:02:08,852 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 23:02:17,890 ----------------------------------------------------------------------------------------------------
2021-05-27 23:02:49,139 epoch 11 - iter 58/585 - loss 0.41491565 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 23:03:20,172 epoch 11 - iter 116/585 - loss 0.43880162 - samples/sec: 59.81 - lr: 0.100000
2021-05-27 23:03:51,429 epoch 11 - iter 174/585 - loss 0.44068820 - samples/sec: 59.39 - lr: 0.100000
2021-05-27 23:04:22,701 epoch 11 - iter 232/585 - loss 0.44950409 - samples/sec: 59.36 - lr: 0.100000
2021-05-27 23:04:53,843 epoch 11 - iter 290/585 - loss 0.46434248 - samples/sec: 59.60 - lr: 0.100000
2021-05-27 23:05:25,038 epoch 11 - iter 348/585 - loss 0.46451854 - samples/sec: 59.50 - lr: 0.100000
2021-05-27 23:05:57,768 epoch 11 - iter 406/585 - loss 0.46406725 - samples/sec: 56.71 - lr: 0.100000
2021-05-27 23:06:28,981 epoch 11 - iter 464/585 - loss 0.46763828 - samples/sec: 59.47 - lr: 0.100000
2021-05-27 23:07:00,174 epoch 11 - iter 522/585 - loss 0.46733112 - samples/sec: 59.51 - lr: 0.100000
2021-05-27 23:07:31,413 epoch 11 - iter 580/585 - loss 0.46390602 - samples/sec: 59.42 - lr: 0.100000
2021-05-27 23:07:33,837 ----------------------------------------------------------------------------------------------------
2021-05-27 23:07:33,837 EPOCH 11 done: loss 0.4647 - lr 0.1000000
2021-05-27 23:07:47,982 DEV : loss 0.6224080324172974 - score 0.9178
2021-05-27 23:07:48,226 BAD EPOCHS (no improvement): 1
2021-05-27 23:07:48,227 ----------------------------------------------------------------------------------------------------
2021-05-27 23:08:19,455 epoch 12 - iter 58/585 - loss 0.41430035 - samples/sec: 59.44 - lr: 0.100000
2021-05-27 23:08:50,688 epoch 12 - iter 116/585 - loss 0.42748422 - samples/sec: 59.43 - lr: 0.100000
2021-05-27 23:09:21,880 epoch 12 - iter 174/585 - loss 0.43054950 - samples/sec: 59.51 - lr: 0.100000
2021-05-27 23:09:53,089 epoch 12 - iter 232/585 - loss 0.43882982 - samples/sec: 59.48 - lr: 0.100000
2021-05-27 23:10:24,336 epoch 12 - iter 290/585 - loss 0.44185709 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 23:10:55,644 epoch 12 - iter 348/585 - loss 0.44464222 - samples/sec: 59.29 - lr: 0.100000
2021-05-27 23:11:26,944 epoch 12 - iter 406/585 - loss 0.44373077 - samples/sec: 59.30 - lr: 0.100000
2021-05-27 23:11:58,205 epoch 12 - iter 464/585 - loss 0.44468004 - samples/sec: 59.38 - lr: 0.100000
2021-05-27 23:12:29,431 epoch 12 - iter 522/585 - loss 0.44388811 - samples/sec: 59.44 - lr: 0.100000
2021-05-27 23:13:00,648 epoch 12 - iter 580/585 - loss 0.44402183 - samples/sec: 59.46 - lr: 0.100000
2021-05-27 23:13:03,060 ----------------------------------------------------------------------------------------------------
2021-05-27 23:13:03,061 EPOCH 12 done: loss 0.4437 - lr 0.1000000
2021-05-27 23:13:17,188 DEV : loss 0.33657026290893555 - score 0.9553
2021-05-27 23:13:17,430 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 23:13:26,342 ----------------------------------------------------------------------------------------------------
2021-05-27 23:13:57,561 epoch 13 - iter 58/585 - loss 0.39918320 - samples/sec: 59.46 - lr: 0.100000
2021-05-27 23:14:28,758 epoch 13 - iter 116/585 - loss 0.41780245 - samples/sec: 59.50 - lr: 0.100000
2021-05-27 23:14:59,889 epoch 13 - iter 174/585 - loss 0.41886360 - samples/sec: 59.62 - lr: 0.100000
2021-05-27 23:15:31,039 epoch 13 - iter 232/585 - loss 0.41278862 - samples/sec: 59.59 - lr: 0.100000
2021-05-27 23:16:02,316 epoch 13 - iter 290/585 - loss 0.41867094 - samples/sec: 59.35 - lr: 0.100000
2021-05-27 23:16:33,632 epoch 13 - iter 348/585 - loss 0.41968936 - samples/sec: 59.27 - lr: 0.100000
2021-05-27 23:17:04,911 epoch 13 - iter 406/585 - loss 0.42165103 - samples/sec: 59.34 - lr: 0.100000
2021-05-27 23:17:36,264 epoch 13 - iter 464/585 - loss 0.41662730 - samples/sec: 59.20 - lr: 0.100000
2021-05-27 23:18:07,587 epoch 13 - iter 522/585 - loss 0.41660786 - samples/sec: 59.26 - lr: 0.100000
2021-05-27 23:18:38,877 epoch 13 - iter 580/585 - loss 0.42118793 - samples/sec: 59.32 - lr: 0.100000
2021-05-27 23:18:41,289 ----------------------------------------------------------------------------------------------------
2021-05-27 23:18:41,289 EPOCH 13 done: loss 0.4210 - lr 0.1000000
2021-05-27 23:18:55,430 DEV : loss 0.3474006652832031 - score 0.9547
2021-05-27 23:18:55,672 BAD EPOCHS (no improvement): 1
2021-05-27 23:18:55,672 ----------------------------------------------------------------------------------------------------
2021-05-27 23:19:26,939 epoch 14 - iter 58/585 - loss 0.42338965 - samples/sec: 59.37 - lr: 0.100000
2021-05-27 23:19:58,156 epoch 14 - iter 116/585 - loss 0.42898143 - samples/sec: 59.46 - lr: 0.100000
2021-05-27 23:20:29,362 epoch 14 - iter 174/585 - loss 0.43421449 - samples/sec: 59.48 - lr: 0.100000
2021-05-27 23:21:02,045 epoch 14 - iter 232/585 - loss 0.43495633 - samples/sec: 56.79 - lr: 0.100000
2021-05-27 23:21:33,272 epoch 14 - iter 290/585 - loss 0.42863064 - samples/sec: 59.44 - lr: 0.100000
2021-05-27 23:22:04,511 epoch 14 - iter 348/585 - loss 0.42585764 - samples/sec: 59.42 - lr: 0.100000
2021-05-27 23:22:35,717 epoch 14 - iter 406/585 - loss 0.42247369 - samples/sec: 59.48 - lr: 0.100000
2021-05-27 23:23:06,960 epoch 14 - iter 464/585 - loss 0.42135145 - samples/sec: 59.41 - lr: 0.100000
2021-05-27 23:23:38,188 epoch 14 - iter 522/585 - loss 0.41781553 - samples/sec: 59.44 - lr: 0.100000
2021-05-27 23:24:09,444 epoch 14 - iter 580/585 - loss 0.41505138 - samples/sec: 59.39 - lr: 0.100000
2021-05-27 23:24:11,862 ----------------------------------------------------------------------------------------------------
2021-05-27 23:24:11,862 EPOCH 14 done: loss 0.4158 - lr 0.1000000
2021-05-27 23:24:25,984 DEV : loss 0.3286798596382141 - score 0.9594
2021-05-27 23:24:26,225 BAD EPOCHS (no improvement): 0
saving best model
2021-05-27 23:24:35,349 ----------------------------------------------------------------------------------------------------
2021-05-27 23:25:06,598 epoch 15 - iter 58/585 - loss 0.42688189 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 23:25:37,801 epoch 15 - iter 116/585 - loss 0.40643259 - samples/sec: 59.49 - lr: 0.100000
2021-05-27 23:26:09,003 epoch 15 - iter 174/585 - loss 0.40083995 - samples/sec: 59.49 - lr: 0.100000
2021-05-27 23:26:40,185 epoch 15 - iter 232/585 - loss 0.39723202 - samples/sec: 59.53 - lr: 0.100000
2021-05-27 23:27:11,410 epoch 15 - iter 290/585 - loss 0.40338854 - samples/sec: 59.45 - lr: 0.100000
2021-05-27 23:27:42,695 epoch 15 - iter 348/585 - loss 0.40351188 - samples/sec: 59.33 - lr: 0.100000
2021-05-27 23:28:13,913 epoch 15 - iter 406/585 - loss 0.40707825 - samples/sec: 59.46 - lr: 0.100000
2021-05-27 23:28:45,181 epoch 15 - iter 464/585 - loss 0.40825299 - samples/sec: 59.36 - lr: 0.100000
2021-05-27 23:29:16,506 epoch 15 - iter 522/585 - loss 0.40962116 - samples/sec: 59.25 - lr: 0.100000
2021-05-27 23:29:47,755 epoch 15 - iter 580/585 - loss 0.40971126 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 23:29:50,176 ----------------------------------------------------------------------------------------------------
2021-05-27 23:29:50,177 EPOCH 15 done: loss 0.4107 - lr 0.1000000
2021-05-27 23:30:04,326 DEV : loss 0.34847909212112427 - score 0.9559
2021-05-27 23:30:04,567 BAD EPOCHS (no improvement): 1
2021-05-27 23:30:04,567 ----------------------------------------------------------------------------------------------------
2021-05-27 23:30:35,907 epoch 16 - iter 58/585 - loss 0.39722507 - samples/sec: 59.23 - lr: 0.100000
2021-05-27 23:31:07,156 epoch 16 - iter 116/585 - loss 0.39274335 - samples/sec: 59.40 - lr: 0.100000
2021-05-27 23:31:38,033 epoch 16 - iter 174/585 - loss 0.38933865 - samples/sec: 60.12 - lr: 0.100000
2021-05-27 23:32:09,099 epoch 16 - iter 232/585 - loss 0.39510689 - samples/sec: 59.75 - lr: 0.100000
2021-05-27 23:32:40,268 epoch 16 - iter 290/585 - loss 0.39855066 - samples/sec: 59.55 - lr: 0.100000
2021-05-27 23:33:11,618 epoch 16 - iter 348/585 - loss 0.40316459 - samples/sec: 59.21 - lr: 0.100000
2021-05-27 23:33:42,991 epoch 16 - iter 406/585 - loss 0.40350622 - samples/sec: 59.17 - lr: 0.100000
2021-05-27 23:34:14,153 epoch 16 - iter 464/585 - loss 0.40430089 - samples/sec: 59.57 - lr: 0.100000
2021-05-27 23:34:45,368 epoch 16 - iter 522/585 - loss 0.40333187 - samples/sec: 59.46 - lr: 0.100000
2021-05-27 23:35:16,543 epoch 16 - iter 580/585 - loss 0.40152028 - samples/sec: 59.54 - lr: 0.100000
2021-05-27 23:35:18,929 ----------------------------------------------------------------------------------------------------
2021-05-27 23:35:18,929 EPOCH 16 done: loss 0.4017 - lr 0.1000000
2021-05-27 23:35:34,626 DEV : loss 0.36389121413230896 - score 0.947
2021-05-27 23:35:34,868 BAD EPOCHS (no improvement): 2
2021-05-27 23:35:34,869 ----------------------------------------------------------------------------------------------------
2021-05-27 23:36:06,038 epoch 17 - iter 58/585 - loss 0.40745051 - samples/sec: 59.55 - lr: 0.100000
2021-05-27 23:36:37,302 epoch 17 - iter 116/585 - loss 0.40352537 - samples/sec: 59.37 - lr: 0.100000
2021-05-27 23:37:08,604 epoch 17 - iter 174/585 - loss 0.39988608 - samples/sec: 59.30 - lr: 0.100000
2021-05-27 23:37:39,865 epoch 17 - iter 232/585 - loss 0.40326038 - samples/sec: 59.38 - lr: 0.100000
2021-05-27 23:38:11,185 epoch 17 - iter 290/585 - loss 0.39598033 - samples/sec: 59.27 - lr: 0.100000
2021-05-27 23:38:42,457 epoch 17 - iter 348/585 - loss 0.39609382 - samples/sec: 59.36 - lr: 0.100000
2021-05-27 23:39:13,625 epoch 17 - iter 406/585 - loss 0.39354200 - samples/sec: 59.56 - lr: 0.100000
2021-05-27 23:39:44,997 epoch 17 - iter 464/585 - loss 0.39209734 - samples/sec: 59.17 - lr: 0.100000
2021-05-27 23:40:16,154 epoch 17 - iter 522/585 - loss 0.39252778 - samples/sec: 59.58 - lr: 0.100000
2021-05-27 23:40:47,194 epoch 17 - iter 580/585 - loss 0.39042866 - samples/sec: 59.80 - lr: 0.100000
2021-05-27 23:40:49,624 ----------------------------------------------------------------------------------------------------
2021-05-27 23:40:49,624 EPOCH 17 done: loss 0.3913 - lr 0.1000000
2021-05-27 23:41:03,753 DEV : loss 0.31771981716156006 - score 0.9586
2021-05-27 23:41:03,996 BAD EPOCHS (no improvement): 3
2021-05-27 23:41:03,997 ----------------------------------------------------------------------------------------------------
2021-05-27 23:41:35,183 epoch 18 - iter 58/585 - loss 0.40400011 - samples/sec: 59.52 - lr: 0.100000
2021-05-27 23:42:06,437 epoch 18 - iter 116/585 - loss 0.40273203 - samples/sec: 59.39 - lr: 0.100000
2021-05-27 23:42:37,765 epoch 18 - iter 174/585 - loss 0.39740285 - samples/sec: 59.25 - lr: 0.100000
2021-05-27 23:43:09,054 epoch 18 - iter 232/585 - loss 0.40638712 - samples/sec: 59.32 - lr: 0.100000
2021-05-27 23:43:40,373 epoch 18 - iter 290/585 - loss 0.40783418 - samples/sec: 59.27 - lr: 0.100000
2021-05-27 23:44:11,664 epoch 18 - iter 348/585 - loss 0.41080343 - samples/sec: 59.32 - lr: 0.100000
2021-05-27 23:44:42,942 epoch 18 - iter 406/585 - loss 0.40461112 - samples/sec: 59.34 - lr: 0.100000
2021-05-27 23:45:14,268 epoch 18 - iter 464/585 - loss 0.40159892 - samples/sec: 59.26 - lr: 0.100000
2021-05-27 23:45:45,527 epoch 18 - iter 522/585 - loss 0.39997996 - samples/sec: 59.38 - lr: 0.100000
2021-05-27 23:46:16,853 epoch 18 - iter 580/585 - loss 0.40158086 - samples/sec: 59.25 - lr: 0.100000
2021-05-27 23:46:19,263 ----------------------------------------------------------------------------------------------------
2021-05-27 23:46:19,263 EPOCH 18 done: loss 0.4007 - lr 0.1000000
2021-05-27 23:46:33,425 DEV : loss 0.3324570655822754 - score 0.957
Epoch    18: reducing learning rate of group 0 to 5.0000e-02.
2021-05-27 23:46:33,671 BAD EPOCHS (no improvement): 4
2021-05-27 23:46:33,671 ----------------------------------------------------------------------------------------------------
2021-05-27 23:47:04,803 epoch 19 - iter 58/585 - loss 0.40708751 - samples/sec: 59.62 - lr: 0.050000
2021-05-27 23:47:35,971 epoch 19 - iter 116/585 - loss 0.39794651 - samples/sec: 59.55 - lr: 0.050000
2021-05-27 23:48:07,084 epoch 19 - iter 174/585 - loss 0.39590126 - samples/sec: 59.66 - lr: 0.050000
2021-05-27 23:48:38,329 epoch 19 - iter 232/585 - loss 0.39734717 - samples/sec: 59.41 - lr: 0.050000
2021-05-27 23:49:09,577 epoch 19 - iter 290/585 - loss 0.39060270 - samples/sec: 59.40 - lr: 0.050000
2021-05-27 23:49:40,826 epoch 19 - iter 348/585 - loss 0.38395419 - samples/sec: 59.40 - lr: 0.050000
2021-05-27 23:50:12,102 epoch 19 - iter 406/585 - loss 0.38416611 - samples/sec: 59.35 - lr: 0.050000
2021-05-27 23:50:44,801 epoch 19 - iter 464/585 - loss 0.38333716 - samples/sec: 56.77 - lr: 0.050000
2021-05-27 23:51:16,030 epoch 19 - iter 522/585 - loss 0.37876679 - samples/sec: 59.44 - lr: 0.050000
2021-05-27 23:51:47,323 epoch 19 - iter 580/585 - loss 0.37731939 - samples/sec: 59.31 - lr: 0.050000
2021-05-27 23:51:49,749 ----------------------------------------------------------------------------------------------------
2021-05-27 23:51:49,750 EPOCH 19 done: loss 0.3764 - lr 0.0500000
2021-05-27 23:52:03,916 DEV : loss 0.3302465081214905 - score 0.9561
2021-05-27 23:52:04,162 BAD EPOCHS (no improvement): 1
2021-05-27 23:52:04,162 ----------------------------------------------------------------------------------------------------
2021-05-27 23:52:35,529 epoch 20 - iter 58/585 - loss 0.32402813 - samples/sec: 59.18 - lr: 0.050000
2021-05-27 23:53:06,867 epoch 20 - iter 116/585 - loss 0.35117295 - samples/sec: 59.23 - lr: 0.050000
2021-05-27 23:53:38,165 epoch 20 - iter 174/585 - loss 0.35281919 - samples/sec: 59.31 - lr: 0.050000
2021-05-27 23:54:09,513 epoch 20 - iter 232/585 - loss 0.34909346 - samples/sec: 59.21 - lr: 0.050000
2021-05-27 23:54:40,869 epoch 20 - iter 290/585 - loss 0.35772292 - samples/sec: 59.20 - lr: 0.050000
2021-05-27 23:55:12,257 epoch 20 - iter 348/585 - loss 0.35786551 - samples/sec: 59.14 - lr: 0.050000
2021-05-27 23:55:43,588 epoch 20 - iter 406/585 - loss 0.35706830 - samples/sec: 59.24 - lr: 0.050000
2021-05-27 23:56:15,001 epoch 20 - iter 464/585 - loss 0.35851130 - samples/sec: 59.09 - lr: 0.050000
2021-05-27 23:56:46,401 epoch 20 - iter 522/585 - loss 0.35948454 - samples/sec: 59.11 - lr: 0.050000
2021-05-27 23:57:17,764 epoch 20 - iter 580/585 - loss 0.35888300 - samples/sec: 59.18 - lr: 0.050000
2021-05-27 23:57:20,169 ----------------------------------------------------------------------------------------------------
2021-05-27 23:57:20,169 EPOCH 20 done: loss 0.3586 - lr 0.0500000
2021-05-27 23:57:34,300 DEV : loss 0.3332361876964569 - score 0.9531
2021-05-27 23:57:34,546 BAD EPOCHS (no improvement): 2
2021-05-27 23:57:34,546 ----------------------------------------------------------------------------------------------------
2021-05-27 23:58:05,880 epoch 21 - iter 58/585 - loss 0.36559844 - samples/sec: 59.24 - lr: 0.050000
2021-05-27 23:58:37,156 epoch 21 - iter 116/585 - loss 0.34649744 - samples/sec: 59.35 - lr: 0.050000
2021-05-27 23:59:08,465 epoch 21 - iter 174/585 - loss 0.35014360 - samples/sec: 59.29 - lr: 0.050000
2021-05-27 23:59:39,824 epoch 21 - iter 232/585 - loss 0.35205723 - samples/sec: 59.19 - lr: 0.050000
2021-05-28 00:00:11,180 epoch 21 - iter 290/585 - loss 0.35716792 - samples/sec: 59.20 - lr: 0.050000
2021-05-28 00:00:42,483 epoch 21 - iter 348/585 - loss 0.35575223 - samples/sec: 59.30 - lr: 0.050000
2021-05-28 00:01:13,852 epoch 21 - iter 406/585 - loss 0.35300624 - samples/sec: 59.17 - lr: 0.050000
2021-05-28 00:01:45,183 epoch 21 - iter 464/585 - loss 0.35025293 - samples/sec: 59.25 - lr: 0.050000
2021-05-28 00:02:16,419 epoch 21 - iter 522/585 - loss 0.35174748 - samples/sec: 59.42 - lr: 0.050000
2021-05-28 00:02:47,338 epoch 21 - iter 580/585 - loss 0.35207883 - samples/sec: 60.03 - lr: 0.050000
2021-05-28 00:02:49,724 ----------------------------------------------------------------------------------------------------
2021-05-28 00:02:49,724 EPOCH 21 done: loss 0.3519 - lr 0.0500000
2021-05-28 00:03:03,871 DEV : loss 0.3056470453739166 - score 0.9585
2021-05-28 00:03:04,113 BAD EPOCHS (no improvement): 3
2021-05-28 00:03:04,113 ----------------------------------------------------------------------------------------------------
2021-05-28 00:03:36,696 epoch 22 - iter 58/585 - loss 0.37634880 - samples/sec: 56.97 - lr: 0.050000
2021-05-28 00:04:08,007 epoch 22 - iter 116/585 - loss 0.37224483 - samples/sec: 59.28 - lr: 0.050000
2021-05-28 00:04:39,265 epoch 22 - iter 174/585 - loss 0.37269347 - samples/sec: 59.38 - lr: 0.050000
2021-05-28 00:05:10,568 epoch 22 - iter 232/585 - loss 0.37136288 - samples/sec: 59.30 - lr: 0.050000
2021-05-28 00:05:41,934 epoch 22 - iter 290/585 - loss 0.36544894 - samples/sec: 59.18 - lr: 0.050000
2021-05-28 00:06:13,192 epoch 22 - iter 348/585 - loss 0.35962742 - samples/sec: 59.38 - lr: 0.050000
2021-05-28 00:06:44,554 epoch 22 - iter 406/585 - loss 0.36020143 - samples/sec: 59.19 - lr: 0.050000
2021-05-28 00:07:15,712 epoch 22 - iter 464/585 - loss 0.36149162 - samples/sec: 59.57 - lr: 0.050000
2021-05-28 00:07:47,055 epoch 22 - iter 522/585 - loss 0.35754148 - samples/sec: 59.22 - lr: 0.050000
2021-05-28 00:08:18,360 epoch 22 - iter 580/585 - loss 0.35799107 - samples/sec: 59.29 - lr: 0.050000
2021-05-28 00:08:20,784 ----------------------------------------------------------------------------------------------------
2021-05-28 00:08:20,784 EPOCH 22 done: loss 0.3583 - lr 0.0500000
2021-05-28 00:08:34,939 DEV : loss 0.319743275642395 - score 0.9546
Epoch    22: reducing learning rate of group 0 to 2.5000e-02.
2021-05-28 00:08:35,182 BAD EPOCHS (no improvement): 4
2021-05-28 00:08:35,182 ----------------------------------------------------------------------------------------------------
2021-05-28 00:09:06,485 epoch 23 - iter 58/585 - loss 0.34569374 - samples/sec: 59.30 - lr: 0.025000
2021-05-28 00:09:37,761 epoch 23 - iter 116/585 - loss 0.34815615 - samples/sec: 59.35 - lr: 0.025000
2021-05-28 00:10:08,845 epoch 23 - iter 174/585 - loss 0.35376936 - samples/sec: 59.71 - lr: 0.025000
2021-05-28 00:10:40,219 epoch 23 - iter 232/585 - loss 0.34187323 - samples/sec: 59.16 - lr: 0.025000
2021-05-28 00:11:11,617 epoch 23 - iter 290/585 - loss 0.33992315 - samples/sec: 59.12 - lr: 0.025000
2021-05-28 00:11:42,936 epoch 23 - iter 348/585 - loss 0.34673710 - samples/sec: 59.27 - lr: 0.025000
2021-05-28 00:12:13,879 epoch 23 - iter 406/585 - loss 0.34372761 - samples/sec: 59.99 - lr: 0.025000
2021-05-28 00:12:44,860 epoch 23 - iter 464/585 - loss 0.34459182 - samples/sec: 59.91 - lr: 0.025000
2021-05-28 00:13:15,926 epoch 23 - iter 522/585 - loss 0.34357716 - samples/sec: 59.75 - lr: 0.025000
2021-05-28 00:13:47,223 epoch 23 - iter 580/585 - loss 0.33982169 - samples/sec: 59.31 - lr: 0.025000
2021-05-28 00:13:49,638 ----------------------------------------------------------------------------------------------------
2021-05-28 00:13:49,638 EPOCH 23 done: loss 0.3401 - lr 0.0250000
2021-05-28 00:14:03,796 DEV : loss 0.3002297878265381 - score 0.9592
2021-05-28 00:14:04,039 BAD EPOCHS (no improvement): 1
2021-05-28 00:14:04,039 ----------------------------------------------------------------------------------------------------
2021-05-28 00:14:35,251 epoch 24 - iter 58/585 - loss 0.31053123 - samples/sec: 59.47 - lr: 0.025000
2021-05-28 00:15:06,339 epoch 24 - iter 116/585 - loss 0.32483331 - samples/sec: 59.71 - lr: 0.025000
2021-05-28 00:15:37,665 epoch 24 - iter 174/585 - loss 0.32437327 - samples/sec: 59.25 - lr: 0.025000
2021-05-28 00:16:08,980 epoch 24 - iter 232/585 - loss 0.33305730 - samples/sec: 59.27 - lr: 0.025000
2021-05-28 00:16:40,376 epoch 24 - iter 290/585 - loss 0.33030022 - samples/sec: 59.12 - lr: 0.025000
2021-05-28 00:17:11,644 epoch 24 - iter 348/585 - loss 0.32970907 - samples/sec: 59.36 - lr: 0.025000
2021-05-28 00:17:42,984 epoch 24 - iter 406/585 - loss 0.32706646 - samples/sec: 59.23 - lr: 0.025000
2021-05-28 00:18:14,321 epoch 24 - iter 464/585 - loss 0.33092937 - samples/sec: 59.23 - lr: 0.025000
2021-05-28 00:18:45,589 epoch 24 - iter 522/585 - loss 0.32924905 - samples/sec: 59.36 - lr: 0.025000
2021-05-28 00:19:16,845 epoch 24 - iter 580/585 - loss 0.33068835 - samples/sec: 59.39 - lr: 0.025000
2021-05-28 00:19:19,275 ----------------------------------------------------------------------------------------------------
2021-05-28 00:19:19,275 EPOCH 24 done: loss 0.3310 - lr 0.0250000
2021-05-28 00:19:34,918 DEV : loss 0.30320486426353455 - score 0.9588
2021-05-28 00:19:35,157 BAD EPOCHS (no improvement): 2
2021-05-28 00:19:35,157 ----------------------------------------------------------------------------------------------------
2021-05-28 00:20:06,519 epoch 25 - iter 58/585 - loss 0.31110727 - samples/sec: 59.19 - lr: 0.025000
2021-05-28 00:20:37,686 epoch 25 - iter 116/585 - loss 0.31285218 - samples/sec: 59.55 - lr: 0.025000
2021-05-28 00:21:08,929 epoch 25 - iter 174/585 - loss 0.30951550 - samples/sec: 59.41 - lr: 0.025000
2021-05-28 00:21:40,170 epoch 25 - iter 232/585 - loss 0.31400206 - samples/sec: 59.41 - lr: 0.025000
2021-05-28 00:22:11,340 epoch 25 - iter 290/585 - loss 0.31917378 - samples/sec: 59.55 - lr: 0.025000
2021-05-28 00:22:42,607 epoch 25 - iter 348/585 - loss 0.32052462 - samples/sec: 59.37 - lr: 0.025000
2021-05-28 00:23:13,856 epoch 25 - iter 406/585 - loss 0.32747796 - samples/sec: 59.40 - lr: 0.025000
2021-05-28 00:23:44,905 epoch 25 - iter 464/585 - loss 0.32796796 - samples/sec: 59.78 - lr: 0.025000
2021-05-28 00:24:15,880 epoch 25 - iter 522/585 - loss 0.33313437 - samples/sec: 59.92 - lr: 0.025000
2021-05-28 00:24:47,252 epoch 25 - iter 580/585 - loss 0.33016440 - samples/sec: 59.17 - lr: 0.025000
2021-05-28 00:24:49,683 ----------------------------------------------------------------------------------------------------
2021-05-28 00:24:49,683 EPOCH 25 done: loss 0.3298 - lr 0.0250000
2021-05-28 00:25:03,880 DEV : loss 0.3014221489429474 - score 0.9573
2021-05-28 00:25:04,124 BAD EPOCHS (no improvement): 3
2021-05-28 00:25:04,125 ----------------------------------------------------------------------------------------------------
2021-05-28 00:25:35,435 epoch 26 - iter 58/585 - loss 0.32682916 - samples/sec: 59.29 - lr: 0.025000
2021-05-28 00:26:06,740 epoch 26 - iter 116/585 - loss 0.31139853 - samples/sec: 59.29 - lr: 0.025000
2021-05-28 00:26:38,075 epoch 26 - iter 174/585 - loss 0.31839190 - samples/sec: 59.24 - lr: 0.025000
2021-05-28 00:27:09,407 epoch 26 - iter 232/585 - loss 0.31257677 - samples/sec: 59.24 - lr: 0.025000
2021-05-28 00:27:40,740 epoch 26 - iter 290/585 - loss 0.31696143 - samples/sec: 59.24 - lr: 0.025000
2021-05-28 00:28:12,011 epoch 26 - iter 348/585 - loss 0.32174150 - samples/sec: 59.36 - lr: 0.025000
2021-05-28 00:28:43,285 epoch 26 - iter 406/585 - loss 0.32305569 - samples/sec: 59.35 - lr: 0.025000
2021-05-28 00:29:14,520 epoch 26 - iter 464/585 - loss 0.32335136 - samples/sec: 59.43 - lr: 0.025000
2021-05-28 00:29:45,702 epoch 26 - iter 522/585 - loss 0.32660635 - samples/sec: 59.53 - lr: 0.025000
2021-05-28 00:30:16,935 epoch 26 - iter 580/585 - loss 0.32544603 - samples/sec: 59.43 - lr: 0.025000
2021-05-28 00:30:19,339 ----------------------------------------------------------------------------------------------------
2021-05-28 00:30:19,339 EPOCH 26 done: loss 0.3255 - lr 0.0250000
2021-05-28 00:30:33,515 DEV : loss 0.3060818612575531 - score 0.9604
2021-05-28 00:30:33,761 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 00:30:43,215 ----------------------------------------------------------------------------------------------------
2021-05-28 00:31:14,503 epoch 27 - iter 58/585 - loss 0.30165280 - samples/sec: 59.33 - lr: 0.025000
2021-05-28 00:31:45,740 epoch 27 - iter 116/585 - loss 0.30323097 - samples/sec: 59.42 - lr: 0.025000
2021-05-28 00:32:16,994 epoch 27 - iter 174/585 - loss 0.30567915 - samples/sec: 59.39 - lr: 0.025000
2021-05-28 00:32:48,252 epoch 27 - iter 232/585 - loss 0.30586620 - samples/sec: 59.38 - lr: 0.025000
2021-05-28 00:33:19,591 epoch 27 - iter 290/585 - loss 0.31016110 - samples/sec: 59.23 - lr: 0.025000
2021-05-28 00:33:50,813 epoch 27 - iter 348/585 - loss 0.30932464 - samples/sec: 59.45 - lr: 0.025000
2021-05-28 00:34:23,578 epoch 27 - iter 406/585 - loss 0.31005385 - samples/sec: 56.65 - lr: 0.025000
2021-05-28 00:34:54,959 epoch 27 - iter 464/585 - loss 0.31162428 - samples/sec: 59.15 - lr: 0.025000
2021-05-28 00:35:26,286 epoch 27 - iter 522/585 - loss 0.31193133 - samples/sec: 59.25 - lr: 0.025000
2021-05-28 00:35:57,646 epoch 27 - iter 580/585 - loss 0.31485690 - samples/sec: 59.19 - lr: 0.025000
2021-05-28 00:36:00,058 ----------------------------------------------------------------------------------------------------
2021-05-28 00:36:00,058 EPOCH 27 done: loss 0.3152 - lr 0.0250000
2021-05-28 00:36:14,280 DEV : loss 0.29835233092308044 - score 0.9598
2021-05-28 00:36:14,524 BAD EPOCHS (no improvement): 1
2021-05-28 00:36:14,525 ----------------------------------------------------------------------------------------------------
2021-05-28 00:36:45,909 epoch 28 - iter 58/585 - loss 0.29687454 - samples/sec: 59.15 - lr: 0.025000
2021-05-28 00:37:17,287 epoch 28 - iter 116/585 - loss 0.30400411 - samples/sec: 59.16 - lr: 0.025000
2021-05-28 00:37:48,607 epoch 28 - iter 174/585 - loss 0.32155305 - samples/sec: 59.26 - lr: 0.025000
2021-05-28 00:38:19,933 epoch 28 - iter 232/585 - loss 0.32245150 - samples/sec: 59.25 - lr: 0.025000
2021-05-28 00:38:51,200 epoch 28 - iter 290/585 - loss 0.32743795 - samples/sec: 59.37 - lr: 0.025000
2021-05-28 00:39:22,572 epoch 28 - iter 348/585 - loss 0.32450665 - samples/sec: 59.17 - lr: 0.025000
2021-05-28 00:39:53,858 epoch 28 - iter 406/585 - loss 0.32161493 - samples/sec: 59.33 - lr: 0.025000
2021-05-28 00:40:25,168 epoch 28 - iter 464/585 - loss 0.32046460 - samples/sec: 59.28 - lr: 0.025000
2021-05-28 00:40:56,505 epoch 28 - iter 522/585 - loss 0.32221854 - samples/sec: 59.23 - lr: 0.025000
2021-05-28 00:41:27,823 epoch 28 - iter 580/585 - loss 0.32259172 - samples/sec: 59.27 - lr: 0.025000
2021-05-28 00:41:30,229 ----------------------------------------------------------------------------------------------------
2021-05-28 00:41:30,229 EPOCH 28 done: loss 0.3221 - lr 0.0250000
2021-05-28 00:41:44,443 DEV : loss 0.2942228615283966 - score 0.9615
2021-05-28 00:41:44,688 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 00:41:53,817 ----------------------------------------------------------------------------------------------------
2021-05-28 00:42:25,220 epoch 29 - iter 58/585 - loss 0.35921066 - samples/sec: 59.11 - lr: 0.025000
2021-05-28 00:42:56,600 epoch 29 - iter 116/585 - loss 0.33363874 - samples/sec: 59.15 - lr: 0.025000
2021-05-28 00:43:27,905 epoch 29 - iter 174/585 - loss 0.32525822 - samples/sec: 59.29 - lr: 0.025000
2021-05-28 00:43:59,237 epoch 29 - iter 232/585 - loss 0.32900181 - samples/sec: 59.24 - lr: 0.025000
2021-05-28 00:44:30,678 epoch 29 - iter 290/585 - loss 0.33290991 - samples/sec: 59.04 - lr: 0.025000
2021-05-28 00:45:02,061 epoch 29 - iter 348/585 - loss 0.32867792 - samples/sec: 59.15 - lr: 0.025000
2021-05-28 00:45:33,375 epoch 29 - iter 406/585 - loss 0.32359205 - samples/sec: 59.28 - lr: 0.025000
2021-05-28 00:46:04,731 epoch 29 - iter 464/585 - loss 0.32322870 - samples/sec: 59.20 - lr: 0.025000
2021-05-28 00:46:36,043 epoch 29 - iter 522/585 - loss 0.32074571 - samples/sec: 59.28 - lr: 0.025000
2021-05-28 00:47:07,421 epoch 29 - iter 580/585 - loss 0.31967402 - samples/sec: 59.16 - lr: 0.025000
2021-05-28 00:47:09,840 ----------------------------------------------------------------------------------------------------
2021-05-28 00:47:09,841 EPOCH 29 done: loss 0.3206 - lr 0.0250000
2021-05-28 00:47:24,043 DEV : loss 0.29255709052085876 - score 0.9609
2021-05-28 00:47:24,285 BAD EPOCHS (no improvement): 1
2021-05-28 00:47:24,285 ----------------------------------------------------------------------------------------------------
2021-05-28 00:47:55,647 epoch 30 - iter 58/585 - loss 0.30036243 - samples/sec: 59.19 - lr: 0.025000
2021-05-28 00:48:26,965 epoch 30 - iter 116/585 - loss 0.29632725 - samples/sec: 59.27 - lr: 0.025000
2021-05-28 00:48:59,869 epoch 30 - iter 174/585 - loss 0.30599532 - samples/sec: 56.41 - lr: 0.025000
2021-05-28 00:49:31,172 epoch 30 - iter 232/585 - loss 0.31445755 - samples/sec: 59.30 - lr: 0.025000
2021-05-28 00:50:02,443 epoch 30 - iter 290/585 - loss 0.31477244 - samples/sec: 59.36 - lr: 0.025000
2021-05-28 00:50:33,795 epoch 30 - iter 348/585 - loss 0.31498275 - samples/sec: 59.20 - lr: 0.025000
2021-05-28 00:51:05,083 epoch 30 - iter 406/585 - loss 0.31289226 - samples/sec: 59.33 - lr: 0.025000
2021-05-28 00:51:36,395 epoch 30 - iter 464/585 - loss 0.31484238 - samples/sec: 59.28 - lr: 0.025000
2021-05-28 00:52:07,766 epoch 30 - iter 522/585 - loss 0.31840352 - samples/sec: 59.17 - lr: 0.025000
2021-05-28 00:52:39,163 epoch 30 - iter 580/585 - loss 0.31632351 - samples/sec: 59.12 - lr: 0.025000
2021-05-28 00:52:41,588 ----------------------------------------------------------------------------------------------------
2021-05-28 00:52:41,588 EPOCH 30 done: loss 0.3161 - lr 0.0250000
2021-05-28 00:52:55,814 DEV : loss 0.2907411754131317 - score 0.9621
2021-05-28 00:52:56,059 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 00:53:06,430 ----------------------------------------------------------------------------------------------------
2021-05-28 00:53:06,430 Testing using best model ...
2021-05-28 00:53:06,430 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/tur.pdtb.tdb/best-model.pt
2021-05-28 00:54:05,052 0.9564	0.9564	0.9564
2021-05-28 00:54:05,052 
Results:
- F1-score (micro) 0.9564
- F1-score (macro) 0.9564

By class:
SENT       tp: 2809 - fp: 128 - fn: 128 - precision: 0.9564 - recall: 0.9564 - f1-score: 0.9564
2021-05-28 00:54:05,052 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/
2021-05-28 00:54:05,081 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac
2021-05-28 00:54:05,082 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/sent_train.txt
2021-05-28 00:54:05,084 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/sent_dev.txt
2021-05-28 00:54:05,086 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/sent_test.txt
Corpus: 1751 train + 228 dev + 315 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-28 00:54:10,229 ----------------------------------------------------------------------------------------------------
2021-05-28 00:54:10,232 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-28 00:54:10,232 ----------------------------------------------------------------------------------------------------
2021-05-28 00:54:10,232 Corpus: "Corpus: 1751 train + 228 dev + 315 test sentences"
2021-05-28 00:54:10,232 ----------------------------------------------------------------------------------------------------
2021-05-28 00:54:10,232 Parameters:
2021-05-28 00:54:10,232  - learning_rate: "0.1"
2021-05-28 00:54:10,232  - mini_batch_size: "32"
2021-05-28 00:54:10,232  - patience: "3"
2021-05-28 00:54:10,232  - anneal_factor: "0.5"
2021-05-28 00:54:10,232  - max_epochs: "30"
2021-05-28 00:54:10,232  - shuffle: "True"
2021-05-28 00:54:10,232  - train_with_dev: "False"
2021-05-28 00:54:10,232  - batch_growth_annealing: "False"
2021-05-28 00:54:10,232 ----------------------------------------------------------------------------------------------------
2021-05-28 00:54:10,232 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac"
2021-05-28 00:54:10,232 ----------------------------------------------------------------------------------------------------
2021-05-28 00:54:10,232 Device: cuda:0
2021-05-28 00:54:10,232 ----------------------------------------------------------------------------------------------------
2021-05-28 00:54:10,232 Embeddings storage mode: cpu
2021-05-28 00:54:10,234 ----------------------------------------------------------------------------------------------------
2021-05-28 00:54:16,609 epoch 1 - iter 5/55 - loss 16.47775517 - samples/sec: 25.10 - lr: 0.100000
2021-05-28 00:54:23,025 epoch 1 - iter 10/55 - loss 14.80939322 - samples/sec: 24.94 - lr: 0.100000
2021-05-28 00:54:29,435 epoch 1 - iter 15/55 - loss 14.06416168 - samples/sec: 24.96 - lr: 0.100000
2021-05-28 00:54:35,829 epoch 1 - iter 20/55 - loss 13.57415485 - samples/sec: 25.02 - lr: 0.100000
2021-05-28 00:54:42,282 epoch 1 - iter 25/55 - loss 13.31537868 - samples/sec: 24.80 - lr: 0.100000
2021-05-28 00:54:48,677 epoch 1 - iter 30/55 - loss 13.04063851 - samples/sec: 25.02 - lr: 0.100000
2021-05-28 00:54:55,110 epoch 1 - iter 35/55 - loss 12.75837811 - samples/sec: 24.87 - lr: 0.100000
2021-05-28 00:55:01,554 epoch 1 - iter 40/55 - loss 12.43360801 - samples/sec: 24.83 - lr: 0.100000
2021-05-28 00:55:07,989 epoch 1 - iter 45/55 - loss 12.33846444 - samples/sec: 24.87 - lr: 0.100000
2021-05-28 00:55:14,402 epoch 1 - iter 50/55 - loss 12.12222668 - samples/sec: 24.95 - lr: 0.100000
2021-05-28 00:55:20,467 epoch 1 - iter 55/55 - loss 11.90915467 - samples/sec: 26.38 - lr: 0.100000
2021-05-28 00:55:20,467 ----------------------------------------------------------------------------------------------------
2021-05-28 00:55:20,468 EPOCH 1 done: loss 11.9092 - lr 0.1000000
2021-05-28 00:55:26,291 DEV : loss 9.67265510559082 - score 0.0593
2021-05-28 00:55:26,315 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 00:55:27,385 ----------------------------------------------------------------------------------------------------
2021-05-28 00:55:29,893 epoch 2 - iter 5/55 - loss 9.82537613 - samples/sec: 63.81 - lr: 0.100000
2021-05-28 00:55:32,423 epoch 2 - iter 10/55 - loss 9.78959332 - samples/sec: 63.25 - lr: 0.100000
2021-05-28 00:55:34,951 epoch 2 - iter 15/55 - loss 9.28291394 - samples/sec: 63.30 - lr: 0.100000
2021-05-28 00:55:37,459 epoch 2 - iter 20/55 - loss 9.20849941 - samples/sec: 63.81 - lr: 0.100000
2021-05-28 00:55:40,006 epoch 2 - iter 25/55 - loss 9.05636209 - samples/sec: 62.83 - lr: 0.100000
2021-05-28 00:55:42,542 epoch 2 - iter 30/55 - loss 9.07127725 - samples/sec: 63.12 - lr: 0.100000
2021-05-28 00:55:45,085 epoch 2 - iter 35/55 - loss 8.94382969 - samples/sec: 62.93 - lr: 0.100000
2021-05-28 00:55:47,621 epoch 2 - iter 40/55 - loss 8.88397071 - samples/sec: 63.11 - lr: 0.100000
2021-05-28 00:55:50,129 epoch 2 - iter 45/55 - loss 8.85354976 - samples/sec: 63.82 - lr: 0.100000
2021-05-28 00:55:52,679 epoch 2 - iter 50/55 - loss 8.78078500 - samples/sec: 62.75 - lr: 0.100000
2021-05-28 00:55:55,103 epoch 2 - iter 55/55 - loss 8.73719289 - samples/sec: 66.02 - lr: 0.100000
2021-05-28 00:55:55,104 ----------------------------------------------------------------------------------------------------
2021-05-28 00:55:55,104 EPOCH 2 done: loss 8.7372 - lr 0.1000000
2021-05-28 00:55:56,447 DEV : loss 7.0149054527282715 - score 0.7223
2021-05-28 00:55:56,471 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 00:56:05,541 ----------------------------------------------------------------------------------------------------
2021-05-28 00:56:08,076 epoch 3 - iter 5/55 - loss 7.55879431 - samples/sec: 63.15 - lr: 0.100000
2021-05-28 00:56:10,611 epoch 3 - iter 10/55 - loss 7.84473763 - samples/sec: 63.14 - lr: 0.100000
2021-05-28 00:56:13,129 epoch 3 - iter 15/55 - loss 7.81926966 - samples/sec: 63.54 - lr: 0.100000
2021-05-28 00:56:15,636 epoch 3 - iter 20/55 - loss 7.94948492 - samples/sec: 63.85 - lr: 0.100000
2021-05-28 00:56:18,175 epoch 3 - iter 25/55 - loss 7.91094839 - samples/sec: 63.03 - lr: 0.100000
2021-05-28 00:56:20,716 epoch 3 - iter 30/55 - loss 7.88143509 - samples/sec: 62.97 - lr: 0.100000
2021-05-28 00:56:23,244 epoch 3 - iter 35/55 - loss 7.72462388 - samples/sec: 63.31 - lr: 0.100000
2021-05-28 00:56:25,784 epoch 3 - iter 40/55 - loss 7.70429425 - samples/sec: 63.01 - lr: 0.100000
2021-05-28 00:56:28,306 epoch 3 - iter 45/55 - loss 7.62600774 - samples/sec: 63.46 - lr: 0.100000
2021-05-28 00:56:30,847 epoch 3 - iter 50/55 - loss 7.51101127 - samples/sec: 63.00 - lr: 0.100000
2021-05-28 00:56:33,264 epoch 3 - iter 55/55 - loss 7.42836749 - samples/sec: 66.22 - lr: 0.100000
2021-05-28 00:56:33,264 ----------------------------------------------------------------------------------------------------
2021-05-28 00:56:33,264 EPOCH 3 done: loss 7.4284 - lr 0.1000000
2021-05-28 00:56:34,593 DEV : loss 5.182190418243408 - score 0.7059
2021-05-28 00:56:34,617 BAD EPOCHS (no improvement): 1
2021-05-28 00:56:34,617 ----------------------------------------------------------------------------------------------------
2021-05-28 00:56:37,172 epoch 4 - iter 5/55 - loss 6.21738920 - samples/sec: 62.63 - lr: 0.100000
2021-05-28 00:56:39,735 epoch 4 - iter 10/55 - loss 6.49545913 - samples/sec: 62.45 - lr: 0.100000
2021-05-28 00:56:42,292 epoch 4 - iter 15/55 - loss 6.60891263 - samples/sec: 62.59 - lr: 0.100000
2021-05-28 00:56:44,848 epoch 4 - iter 20/55 - loss 6.55344815 - samples/sec: 62.61 - lr: 0.100000
2021-05-28 00:56:47,399 epoch 4 - iter 25/55 - loss 6.64967524 - samples/sec: 62.75 - lr: 0.100000
2021-05-28 00:56:49,946 epoch 4 - iter 30/55 - loss 6.57244587 - samples/sec: 62.83 - lr: 0.100000
2021-05-28 00:56:52,500 epoch 4 - iter 35/55 - loss 6.55747994 - samples/sec: 62.65 - lr: 0.100000
2021-05-28 00:56:55,066 epoch 4 - iter 40/55 - loss 6.52650290 - samples/sec: 62.37 - lr: 0.100000
2021-05-28 00:56:57,622 epoch 4 - iter 45/55 - loss 6.59686033 - samples/sec: 62.60 - lr: 0.100000
2021-05-28 00:57:00,162 epoch 4 - iter 50/55 - loss 6.52519285 - samples/sec: 63.02 - lr: 0.100000
2021-05-28 00:57:02,577 epoch 4 - iter 55/55 - loss 6.52613325 - samples/sec: 66.27 - lr: 0.100000
2021-05-28 00:57:02,578 ----------------------------------------------------------------------------------------------------
2021-05-28 00:57:02,578 EPOCH 4 done: loss 6.5261 - lr 0.1000000
2021-05-28 00:57:03,924 DEV : loss 5.196498394012451 - score 0.7664
2021-05-28 00:57:03,947 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 00:57:13,112 ----------------------------------------------------------------------------------------------------
2021-05-28 00:57:15,665 epoch 5 - iter 5/55 - loss 6.33113728 - samples/sec: 62.69 - lr: 0.100000
2021-05-28 00:57:18,232 epoch 5 - iter 10/55 - loss 6.31076856 - samples/sec: 62.35 - lr: 0.100000
2021-05-28 00:57:20,781 epoch 5 - iter 15/55 - loss 6.28579985 - samples/sec: 62.79 - lr: 0.100000
2021-05-28 00:57:23,328 epoch 5 - iter 20/55 - loss 6.18223324 - samples/sec: 62.83 - lr: 0.100000
2021-05-28 00:57:25,866 epoch 5 - iter 25/55 - loss 6.21620350 - samples/sec: 63.06 - lr: 0.100000
2021-05-28 00:57:28,419 epoch 5 - iter 30/55 - loss 6.20170321 - samples/sec: 62.69 - lr: 0.100000
2021-05-28 00:57:30,981 epoch 5 - iter 35/55 - loss 6.19828705 - samples/sec: 62.46 - lr: 0.100000
2021-05-28 00:57:33,542 epoch 5 - iter 40/55 - loss 6.14489782 - samples/sec: 62.49 - lr: 0.100000
2021-05-28 00:57:36,109 epoch 5 - iter 45/55 - loss 6.10288395 - samples/sec: 62.35 - lr: 0.100000
2021-05-28 00:57:38,674 epoch 5 - iter 50/55 - loss 6.10816543 - samples/sec: 62.38 - lr: 0.100000
2021-05-28 00:57:41,102 epoch 5 - iter 55/55 - loss 6.11618295 - samples/sec: 65.93 - lr: 0.100000
2021-05-28 00:57:41,102 ----------------------------------------------------------------------------------------------------
2021-05-28 00:57:41,102 EPOCH 5 done: loss 6.1162 - lr 0.1000000
2021-05-28 00:57:48,726 DEV : loss 4.654628753662109 - score 0.7308
2021-05-28 00:57:48,749 BAD EPOCHS (no improvement): 1
2021-05-28 00:57:48,750 ----------------------------------------------------------------------------------------------------
2021-05-28 00:57:51,330 epoch 6 - iter 5/55 - loss 5.82809601 - samples/sec: 62.03 - lr: 0.100000
2021-05-28 00:57:53,887 epoch 6 - iter 10/55 - loss 5.75871034 - samples/sec: 62.59 - lr: 0.100000
2021-05-28 00:57:56,442 epoch 6 - iter 15/55 - loss 5.80137447 - samples/sec: 62.64 - lr: 0.100000
2021-05-28 00:57:58,988 epoch 6 - iter 20/55 - loss 5.75218425 - samples/sec: 62.85 - lr: 0.100000
2021-05-28 00:58:01,529 epoch 6 - iter 25/55 - loss 5.78690914 - samples/sec: 62.97 - lr: 0.100000
2021-05-28 00:58:04,082 epoch 6 - iter 30/55 - loss 5.79405821 - samples/sec: 62.70 - lr: 0.100000
2021-05-28 00:58:06,614 epoch 6 - iter 35/55 - loss 5.80467062 - samples/sec: 63.21 - lr: 0.100000
2021-05-28 00:58:09,166 epoch 6 - iter 40/55 - loss 5.85639699 - samples/sec: 62.72 - lr: 0.100000
2021-05-28 00:58:11,698 epoch 6 - iter 45/55 - loss 5.75440467 - samples/sec: 63.21 - lr: 0.100000
2021-05-28 00:58:14,251 epoch 6 - iter 50/55 - loss 5.79685728 - samples/sec: 62.69 - lr: 0.100000
2021-05-28 00:58:16,638 epoch 6 - iter 55/55 - loss 5.82785906 - samples/sec: 67.03 - lr: 0.100000
2021-05-28 00:58:16,639 ----------------------------------------------------------------------------------------------------
2021-05-28 00:58:16,639 EPOCH 6 done: loss 5.8279 - lr 0.1000000
2021-05-28 00:58:17,982 DEV : loss 4.552862644195557 - score 0.7867
2021-05-28 00:58:18,005 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 00:58:27,193 ----------------------------------------------------------------------------------------------------
2021-05-28 00:58:29,764 epoch 7 - iter 5/55 - loss 5.55957832 - samples/sec: 62.24 - lr: 0.100000
2021-05-28 00:58:32,330 epoch 7 - iter 10/55 - loss 5.68886137 - samples/sec: 62.38 - lr: 0.100000
2021-05-28 00:58:34,889 epoch 7 - iter 15/55 - loss 5.72178513 - samples/sec: 62.55 - lr: 0.100000
2021-05-28 00:58:37,414 epoch 7 - iter 20/55 - loss 5.71080992 - samples/sec: 63.37 - lr: 0.100000
2021-05-28 00:58:39,950 epoch 7 - iter 25/55 - loss 5.60701418 - samples/sec: 63.12 - lr: 0.100000
2021-05-28 00:58:42,517 epoch 7 - iter 30/55 - loss 5.57816782 - samples/sec: 62.35 - lr: 0.100000
2021-05-28 00:58:45,092 epoch 7 - iter 35/55 - loss 5.62158827 - samples/sec: 62.15 - lr: 0.100000
2021-05-28 00:58:47,651 epoch 7 - iter 40/55 - loss 5.61722431 - samples/sec: 62.55 - lr: 0.100000
2021-05-28 00:58:50,202 epoch 7 - iter 45/55 - loss 5.62046154 - samples/sec: 62.73 - lr: 0.100000
2021-05-28 00:58:52,766 epoch 7 - iter 50/55 - loss 5.67671811 - samples/sec: 62.43 - lr: 0.100000
2021-05-28 00:58:55,188 epoch 7 - iter 55/55 - loss 5.66624636 - samples/sec: 66.06 - lr: 0.100000
2021-05-28 00:58:55,189 ----------------------------------------------------------------------------------------------------
2021-05-28 00:58:55,189 EPOCH 7 done: loss 5.6662 - lr 0.1000000
2021-05-28 00:58:56,528 DEV : loss 4.046823978424072 - score 0.7854
2021-05-28 00:58:56,551 BAD EPOCHS (no improvement): 1
2021-05-28 00:58:56,551 ----------------------------------------------------------------------------------------------------
2021-05-28 00:58:59,064 epoch 8 - iter 5/55 - loss 5.44479313 - samples/sec: 63.70 - lr: 0.100000
2021-05-28 00:59:01,596 epoch 8 - iter 10/55 - loss 5.69545341 - samples/sec: 63.20 - lr: 0.100000
2021-05-28 00:59:04,151 epoch 8 - iter 15/55 - loss 5.66387908 - samples/sec: 62.65 - lr: 0.100000
2021-05-28 00:59:06,698 epoch 8 - iter 20/55 - loss 5.72844691 - samples/sec: 62.82 - lr: 0.100000
2021-05-28 00:59:09,242 epoch 8 - iter 25/55 - loss 5.67040415 - samples/sec: 62.92 - lr: 0.100000
2021-05-28 00:59:11,799 epoch 8 - iter 30/55 - loss 5.66362755 - samples/sec: 62.59 - lr: 0.100000
2021-05-28 00:59:14,331 epoch 8 - iter 35/55 - loss 5.65393286 - samples/sec: 63.21 - lr: 0.100000
2021-05-28 00:59:16,875 epoch 8 - iter 40/55 - loss 5.56556888 - samples/sec: 62.89 - lr: 0.100000
2021-05-28 00:59:19,422 epoch 8 - iter 45/55 - loss 5.58698826 - samples/sec: 62.85 - lr: 0.100000
2021-05-28 00:59:21,970 epoch 8 - iter 50/55 - loss 5.58090003 - samples/sec: 62.82 - lr: 0.100000
2021-05-28 00:59:24,400 epoch 8 - iter 55/55 - loss 5.54043060 - samples/sec: 65.84 - lr: 0.100000
2021-05-28 00:59:24,401 ----------------------------------------------------------------------------------------------------
2021-05-28 00:59:24,401 EPOCH 8 done: loss 5.5404 - lr 0.1000000
2021-05-28 00:59:25,953 DEV : loss 5.748988151550293 - score 0.7457
2021-05-28 00:59:25,976 BAD EPOCHS (no improvement): 2
2021-05-28 00:59:25,977 ----------------------------------------------------------------------------------------------------
2021-05-28 00:59:28,507 epoch 9 - iter 5/55 - loss 5.38563061 - samples/sec: 63.26 - lr: 0.100000
2021-05-28 00:59:31,041 epoch 9 - iter 10/55 - loss 5.31970844 - samples/sec: 63.16 - lr: 0.100000
2021-05-28 00:59:33,585 epoch 9 - iter 15/55 - loss 5.20621862 - samples/sec: 62.89 - lr: 0.100000
2021-05-28 00:59:36,132 epoch 9 - iter 20/55 - loss 5.36518590 - samples/sec: 62.85 - lr: 0.100000
2021-05-28 00:59:38,668 epoch 9 - iter 25/55 - loss 5.37287657 - samples/sec: 63.11 - lr: 0.100000
2021-05-28 00:59:41,197 epoch 9 - iter 30/55 - loss 5.31692998 - samples/sec: 63.27 - lr: 0.100000
2021-05-28 00:59:43,734 epoch 9 - iter 35/55 - loss 5.24012758 - samples/sec: 63.10 - lr: 0.100000
2021-05-28 00:59:46,266 epoch 9 - iter 40/55 - loss 5.29081112 - samples/sec: 63.20 - lr: 0.100000
2021-05-28 00:59:48,820 epoch 9 - iter 45/55 - loss 5.32768622 - samples/sec: 62.67 - lr: 0.100000
2021-05-28 00:59:51,372 epoch 9 - iter 50/55 - loss 5.38504958 - samples/sec: 62.73 - lr: 0.100000
2021-05-28 00:59:53,801 epoch 9 - iter 55/55 - loss 5.38280462 - samples/sec: 65.87 - lr: 0.100000
2021-05-28 00:59:53,802 ----------------------------------------------------------------------------------------------------
2021-05-28 00:59:53,802 EPOCH 9 done: loss 5.3828 - lr 0.1000000
2021-05-28 00:59:55,139 DEV : loss 3.716960906982422 - score 0.8267
2021-05-28 00:59:55,162 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:00:04,603 ----------------------------------------------------------------------------------------------------
2021-05-28 01:00:07,177 epoch 10 - iter 5/55 - loss 5.06709442 - samples/sec: 62.20 - lr: 0.100000
2021-05-28 01:00:09,710 epoch 10 - iter 10/55 - loss 5.16627264 - samples/sec: 63.17 - lr: 0.100000
2021-05-28 01:00:12,279 epoch 10 - iter 15/55 - loss 5.05545883 - samples/sec: 62.31 - lr: 0.100000
2021-05-28 01:00:14,844 epoch 10 - iter 20/55 - loss 5.14469738 - samples/sec: 62.40 - lr: 0.100000
2021-05-28 01:00:17,380 epoch 10 - iter 25/55 - loss 5.15810896 - samples/sec: 63.10 - lr: 0.100000
2021-05-28 01:00:19,953 epoch 10 - iter 30/55 - loss 5.17692477 - samples/sec: 62.21 - lr: 0.100000
2021-05-28 01:00:22,525 epoch 10 - iter 35/55 - loss 5.12054702 - samples/sec: 62.22 - lr: 0.100000
2021-05-28 01:00:25,090 epoch 10 - iter 40/55 - loss 5.15345117 - samples/sec: 62.38 - lr: 0.100000
2021-05-28 01:00:27,647 epoch 10 - iter 45/55 - loss 5.22643538 - samples/sec: 62.59 - lr: 0.100000
2021-05-28 01:00:30,190 epoch 10 - iter 50/55 - loss 5.17291031 - samples/sec: 62.93 - lr: 0.100000
2021-05-28 01:00:32,608 epoch 10 - iter 55/55 - loss 5.22024098 - samples/sec: 66.21 - lr: 0.100000
2021-05-28 01:00:32,608 ----------------------------------------------------------------------------------------------------
2021-05-28 01:00:32,608 EPOCH 10 done: loss 5.2202 - lr 0.1000000
2021-05-28 01:00:33,953 DEV : loss 4.3694353103637695 - score 0.8011
2021-05-28 01:00:33,977 BAD EPOCHS (no improvement): 1
2021-05-28 01:00:33,977 ----------------------------------------------------------------------------------------------------
2021-05-28 01:00:36,524 epoch 11 - iter 5/55 - loss 4.98970861 - samples/sec: 62.84 - lr: 0.100000
2021-05-28 01:00:39,073 epoch 11 - iter 10/55 - loss 4.98267832 - samples/sec: 62.79 - lr: 0.100000
2021-05-28 01:00:41,613 epoch 11 - iter 15/55 - loss 4.82541731 - samples/sec: 63.01 - lr: 0.100000
2021-05-28 01:00:44,170 epoch 11 - iter 20/55 - loss 4.95086654 - samples/sec: 62.58 - lr: 0.100000
2021-05-28 01:00:46,725 epoch 11 - iter 25/55 - loss 5.01818458 - samples/sec: 62.64 - lr: 0.100000
2021-05-28 01:00:49,248 epoch 11 - iter 30/55 - loss 5.12074786 - samples/sec: 63.43 - lr: 0.100000
2021-05-28 01:00:51,799 epoch 11 - iter 35/55 - loss 5.12457089 - samples/sec: 62.74 - lr: 0.100000
2021-05-28 01:00:54,354 epoch 11 - iter 40/55 - loss 5.13376009 - samples/sec: 62.64 - lr: 0.100000
2021-05-28 01:00:56,906 epoch 11 - iter 45/55 - loss 5.09974625 - samples/sec: 62.72 - lr: 0.100000
2021-05-28 01:00:59,462 epoch 11 - iter 50/55 - loss 5.14743485 - samples/sec: 62.61 - lr: 0.100000
2021-05-28 01:01:01,884 epoch 11 - iter 55/55 - loss 5.12419181 - samples/sec: 66.09 - lr: 0.100000
2021-05-28 01:01:01,884 ----------------------------------------------------------------------------------------------------
2021-05-28 01:01:01,884 EPOCH 11 done: loss 5.1242 - lr 0.1000000
2021-05-28 01:01:03,228 DEV : loss 3.6508378982543945 - score 0.8355
2021-05-28 01:01:03,252 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:01:12,662 ----------------------------------------------------------------------------------------------------
2021-05-28 01:01:15,217 epoch 12 - iter 5/55 - loss 4.59074898 - samples/sec: 62.65 - lr: 0.100000
2021-05-28 01:01:17,800 epoch 12 - iter 10/55 - loss 5.00479345 - samples/sec: 61.96 - lr: 0.100000
2021-05-28 01:01:20,372 epoch 12 - iter 15/55 - loss 5.01088785 - samples/sec: 62.21 - lr: 0.100000
2021-05-28 01:01:22,903 epoch 12 - iter 20/55 - loss 5.02058425 - samples/sec: 63.24 - lr: 0.100000
2021-05-28 01:01:25,480 epoch 12 - iter 25/55 - loss 5.09178677 - samples/sec: 62.11 - lr: 0.100000
2021-05-28 01:01:28,039 epoch 12 - iter 30/55 - loss 5.08506254 - samples/sec: 62.53 - lr: 0.100000
2021-05-28 01:01:30,612 epoch 12 - iter 35/55 - loss 5.07273051 - samples/sec: 62.20 - lr: 0.100000
2021-05-28 01:01:33,153 epoch 12 - iter 40/55 - loss 5.02529104 - samples/sec: 62.97 - lr: 0.100000
2021-05-28 01:01:35,719 epoch 12 - iter 45/55 - loss 5.04865246 - samples/sec: 62.37 - lr: 0.100000
2021-05-28 01:01:38,298 epoch 12 - iter 50/55 - loss 5.04668256 - samples/sec: 62.06 - lr: 0.100000
2021-05-28 01:01:40,734 epoch 12 - iter 55/55 - loss 5.02821143 - samples/sec: 65.70 - lr: 0.100000
2021-05-28 01:01:40,735 ----------------------------------------------------------------------------------------------------
2021-05-28 01:01:40,735 EPOCH 12 done: loss 5.0282 - lr 0.1000000
2021-05-28 01:01:42,286 DEV : loss 3.9847373962402344 - score 0.8275
2021-05-28 01:01:42,310 BAD EPOCHS (no improvement): 1
2021-05-28 01:01:42,310 ----------------------------------------------------------------------------------------------------
2021-05-28 01:01:44,876 epoch 13 - iter 5/55 - loss 4.62105975 - samples/sec: 62.38 - lr: 0.100000
2021-05-28 01:01:47,452 epoch 13 - iter 10/55 - loss 4.77557719 - samples/sec: 62.14 - lr: 0.100000
2021-05-28 01:01:50,012 epoch 13 - iter 15/55 - loss 4.94778587 - samples/sec: 62.51 - lr: 0.100000
2021-05-28 01:01:52,573 epoch 13 - iter 20/55 - loss 4.78758906 - samples/sec: 62.49 - lr: 0.100000
2021-05-28 01:01:55,131 epoch 13 - iter 25/55 - loss 4.81412578 - samples/sec: 62.55 - lr: 0.100000
2021-05-28 01:01:57,668 epoch 13 - iter 30/55 - loss 4.74917200 - samples/sec: 63.09 - lr: 0.100000
2021-05-28 01:02:00,208 epoch 13 - iter 35/55 - loss 4.80327223 - samples/sec: 63.01 - lr: 0.100000
2021-05-28 01:02:02,759 epoch 13 - iter 40/55 - loss 4.79953957 - samples/sec: 62.74 - lr: 0.100000
2021-05-28 01:02:05,294 epoch 13 - iter 45/55 - loss 4.83388105 - samples/sec: 63.12 - lr: 0.100000
2021-05-28 01:02:07,830 epoch 13 - iter 50/55 - loss 4.89981298 - samples/sec: 63.12 - lr: 0.100000
2021-05-28 01:02:10,253 epoch 13 - iter 55/55 - loss 4.92550386 - samples/sec: 66.04 - lr: 0.100000
2021-05-28 01:02:10,253 ----------------------------------------------------------------------------------------------------
2021-05-28 01:02:10,254 EPOCH 13 done: loss 4.9255 - lr 0.1000000
2021-05-28 01:02:11,593 DEV : loss 3.7476773262023926 - score 0.8049
2021-05-28 01:02:11,617 BAD EPOCHS (no improvement): 2
2021-05-28 01:02:11,617 ----------------------------------------------------------------------------------------------------
2021-05-28 01:02:14,163 epoch 14 - iter 5/55 - loss 5.05716166 - samples/sec: 62.85 - lr: 0.100000
2021-05-28 01:02:16,697 epoch 14 - iter 10/55 - loss 5.11241281 - samples/sec: 63.15 - lr: 0.100000
2021-05-28 01:02:19,257 epoch 14 - iter 15/55 - loss 5.09897043 - samples/sec: 62.52 - lr: 0.100000
2021-05-28 01:02:21,808 epoch 14 - iter 20/55 - loss 5.12162081 - samples/sec: 62.75 - lr: 0.100000
2021-05-28 01:02:24,357 epoch 14 - iter 25/55 - loss 5.14430860 - samples/sec: 62.78 - lr: 0.100000
2021-05-28 01:02:26,869 epoch 14 - iter 30/55 - loss 5.08090826 - samples/sec: 63.70 - lr: 0.100000
2021-05-28 01:02:29,409 epoch 14 - iter 35/55 - loss 5.08534003 - samples/sec: 63.01 - lr: 0.100000
2021-05-28 01:02:31,956 epoch 14 - iter 40/55 - loss 5.04459245 - samples/sec: 62.84 - lr: 0.100000
2021-05-28 01:02:34,508 epoch 14 - iter 45/55 - loss 4.99596693 - samples/sec: 62.72 - lr: 0.100000
2021-05-28 01:02:37,061 epoch 14 - iter 50/55 - loss 4.94028051 - samples/sec: 62.68 - lr: 0.100000
2021-05-28 01:02:39,479 epoch 14 - iter 55/55 - loss 4.99021960 - samples/sec: 66.20 - lr: 0.100000
2021-05-28 01:02:39,479 ----------------------------------------------------------------------------------------------------
2021-05-28 01:02:39,479 EPOCH 14 done: loss 4.9902 - lr 0.1000000
2021-05-28 01:02:40,822 DEV : loss 4.301546096801758 - score 0.8166
2021-05-28 01:02:40,846 BAD EPOCHS (no improvement): 3
2021-05-28 01:02:40,846 ----------------------------------------------------------------------------------------------------
2021-05-28 01:02:43,399 epoch 15 - iter 5/55 - loss 4.40253749 - samples/sec: 62.69 - lr: 0.100000
2021-05-28 01:02:45,951 epoch 15 - iter 10/55 - loss 4.66333325 - samples/sec: 62.70 - lr: 0.100000
2021-05-28 01:02:48,513 epoch 15 - iter 15/55 - loss 4.69315486 - samples/sec: 62.48 - lr: 0.100000
2021-05-28 01:02:51,052 epoch 15 - iter 20/55 - loss 4.73472284 - samples/sec: 63.03 - lr: 0.100000
2021-05-28 01:02:53,623 epoch 15 - iter 25/55 - loss 4.81100211 - samples/sec: 62.25 - lr: 0.100000
2021-05-28 01:02:56,195 epoch 15 - iter 30/55 - loss 4.75767001 - samples/sec: 62.22 - lr: 0.100000
2021-05-28 01:02:58,768 epoch 15 - iter 35/55 - loss 4.71838300 - samples/sec: 62.20 - lr: 0.100000
2021-05-28 01:03:01,315 epoch 15 - iter 40/55 - loss 4.76695467 - samples/sec: 62.84 - lr: 0.100000
2021-05-28 01:03:03,886 epoch 15 - iter 45/55 - loss 4.81003858 - samples/sec: 62.26 - lr: 0.100000
2021-05-28 01:03:06,441 epoch 15 - iter 50/55 - loss 4.82553139 - samples/sec: 62.62 - lr: 0.100000
2021-05-28 01:03:08,878 epoch 15 - iter 55/55 - loss 4.85111117 - samples/sec: 65.69 - lr: 0.100000
2021-05-28 01:03:08,878 ----------------------------------------------------------------------------------------------------
2021-05-28 01:03:08,878 EPOCH 15 done: loss 4.8511 - lr 0.1000000
2021-05-28 01:03:10,222 DEV : loss 3.890598773956299 - score 0.8225
Epoch    15: reducing learning rate of group 0 to 5.0000e-02.
2021-05-28 01:03:10,246 BAD EPOCHS (no improvement): 4
2021-05-28 01:03:10,246 ----------------------------------------------------------------------------------------------------
2021-05-28 01:03:12,800 epoch 16 - iter 5/55 - loss 4.43482037 - samples/sec: 62.68 - lr: 0.050000
2021-05-28 01:03:15,373 epoch 16 - iter 10/55 - loss 4.33625307 - samples/sec: 62.20 - lr: 0.050000
2021-05-28 01:03:17,927 epoch 16 - iter 15/55 - loss 4.46919177 - samples/sec: 62.65 - lr: 0.050000
2021-05-28 01:03:20,479 epoch 16 - iter 20/55 - loss 4.40903291 - samples/sec: 62.71 - lr: 0.050000
2021-05-28 01:03:23,053 epoch 16 - iter 25/55 - loss 4.41977931 - samples/sec: 62.19 - lr: 0.050000
2021-05-28 01:03:25,614 epoch 16 - iter 30/55 - loss 4.38905512 - samples/sec: 62.50 - lr: 0.050000
2021-05-28 01:03:28,166 epoch 16 - iter 35/55 - loss 4.34206295 - samples/sec: 62.69 - lr: 0.050000
2021-05-28 01:03:30,724 epoch 16 - iter 40/55 - loss 4.33202779 - samples/sec: 62.59 - lr: 0.050000
2021-05-28 01:03:33,498 epoch 16 - iter 45/55 - loss 4.31404120 - samples/sec: 57.68 - lr: 0.050000
2021-05-28 01:03:36,066 epoch 16 - iter 50/55 - loss 4.32837281 - samples/sec: 62.33 - lr: 0.050000
2021-05-28 01:03:38,497 epoch 16 - iter 55/55 - loss 4.33131445 - samples/sec: 65.83 - lr: 0.050000
2021-05-28 01:03:38,497 ----------------------------------------------------------------------------------------------------
2021-05-28 01:03:38,498 EPOCH 16 done: loss 4.3313 - lr 0.0500000
2021-05-28 01:03:39,840 DEV : loss 3.6351265907287598 - score 0.8422
2021-05-28 01:03:39,864 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:03:49,080 ----------------------------------------------------------------------------------------------------
2021-05-28 01:03:51,632 epoch 17 - iter 5/55 - loss 4.01109490 - samples/sec: 62.75 - lr: 0.050000
2021-05-28 01:03:54,198 epoch 17 - iter 10/55 - loss 4.06719117 - samples/sec: 62.36 - lr: 0.050000
2021-05-28 01:03:56,734 epoch 17 - iter 15/55 - loss 4.13138121 - samples/sec: 63.11 - lr: 0.050000
2021-05-28 01:03:59,281 epoch 17 - iter 20/55 - loss 4.20563498 - samples/sec: 62.82 - lr: 0.050000
2021-05-28 01:04:01,824 epoch 17 - iter 25/55 - loss 4.19512123 - samples/sec: 62.94 - lr: 0.050000
2021-05-28 01:04:04,388 epoch 17 - iter 30/55 - loss 4.25484451 - samples/sec: 62.41 - lr: 0.050000
2021-05-28 01:04:06,947 epoch 17 - iter 35/55 - loss 4.26700773 - samples/sec: 62.54 - lr: 0.050000
2021-05-28 01:04:09,514 epoch 17 - iter 40/55 - loss 4.33260513 - samples/sec: 62.37 - lr: 0.050000
2021-05-28 01:04:12,086 epoch 17 - iter 45/55 - loss 4.33711595 - samples/sec: 62.23 - lr: 0.050000
2021-05-28 01:04:14,644 epoch 17 - iter 50/55 - loss 4.33028498 - samples/sec: 62.55 - lr: 0.050000
2021-05-28 01:04:17,089 epoch 17 - iter 55/55 - loss 4.32071792 - samples/sec: 65.46 - lr: 0.050000
2021-05-28 01:04:17,089 ----------------------------------------------------------------------------------------------------
2021-05-28 01:04:17,090 EPOCH 17 done: loss 4.3207 - lr 0.0500000
2021-05-28 01:04:18,437 DEV : loss 3.5108115673065186 - score 0.8469
2021-05-28 01:04:18,460 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:04:28,696 ----------------------------------------------------------------------------------------------------
2021-05-28 01:04:31,243 epoch 18 - iter 5/55 - loss 4.21426125 - samples/sec: 62.84 - lr: 0.050000
2021-05-28 01:04:33,803 epoch 18 - iter 10/55 - loss 4.35046964 - samples/sec: 62.54 - lr: 0.050000
2021-05-28 01:04:36,333 epoch 18 - iter 15/55 - loss 4.34187689 - samples/sec: 63.23 - lr: 0.050000
2021-05-28 01:04:38,900 epoch 18 - iter 20/55 - loss 4.37162092 - samples/sec: 62.37 - lr: 0.050000
2021-05-28 01:04:41,473 epoch 18 - iter 25/55 - loss 4.35198404 - samples/sec: 62.19 - lr: 0.050000
2021-05-28 01:04:44,026 epoch 18 - iter 30/55 - loss 4.32435261 - samples/sec: 62.70 - lr: 0.050000
2021-05-28 01:04:46,582 epoch 18 - iter 35/55 - loss 4.32613136 - samples/sec: 62.61 - lr: 0.050000
2021-05-28 01:04:49,149 epoch 18 - iter 40/55 - loss 4.31325902 - samples/sec: 62.34 - lr: 0.050000
2021-05-28 01:04:51,738 epoch 18 - iter 45/55 - loss 4.29024053 - samples/sec: 61.81 - lr: 0.050000
2021-05-28 01:04:54,296 epoch 18 - iter 50/55 - loss 4.25829910 - samples/sec: 62.56 - lr: 0.050000
2021-05-28 01:04:56,720 epoch 18 - iter 55/55 - loss 4.27080662 - samples/sec: 66.03 - lr: 0.050000
2021-05-28 01:04:56,720 ----------------------------------------------------------------------------------------------------
2021-05-28 01:04:56,720 EPOCH 18 done: loss 4.2708 - lr 0.0500000
2021-05-28 01:04:58,066 DEV : loss 3.814899444580078 - score 0.8375
2021-05-28 01:04:58,090 BAD EPOCHS (no improvement): 1
2021-05-28 01:04:58,090 ----------------------------------------------------------------------------------------------------
2021-05-28 01:05:00,650 epoch 19 - iter 5/55 - loss 4.10899611 - samples/sec: 62.52 - lr: 0.050000
2021-05-28 01:05:03,195 epoch 19 - iter 10/55 - loss 4.09434977 - samples/sec: 62.89 - lr: 0.050000
2021-05-28 01:05:05,759 epoch 19 - iter 15/55 - loss 4.00055432 - samples/sec: 62.42 - lr: 0.050000
2021-05-28 01:05:08,312 epoch 19 - iter 20/55 - loss 4.00185795 - samples/sec: 62.69 - lr: 0.050000
2021-05-28 01:05:10,852 epoch 19 - iter 25/55 - loss 4.15259228 - samples/sec: 63.00 - lr: 0.050000
2021-05-28 01:05:13,417 epoch 19 - iter 30/55 - loss 4.15713724 - samples/sec: 62.39 - lr: 0.050000
2021-05-28 01:05:15,992 epoch 19 - iter 35/55 - loss 4.16687741 - samples/sec: 62.16 - lr: 0.050000
2021-05-28 01:05:18,546 epoch 19 - iter 40/55 - loss 4.13282894 - samples/sec: 62.64 - lr: 0.050000
2021-05-28 01:05:21,118 epoch 19 - iter 45/55 - loss 4.12712798 - samples/sec: 62.24 - lr: 0.050000
2021-05-28 01:05:23,681 epoch 19 - iter 50/55 - loss 4.13496071 - samples/sec: 62.43 - lr: 0.050000
2021-05-28 01:05:26,113 epoch 19 - iter 55/55 - loss 4.14508305 - samples/sec: 65.83 - lr: 0.050000
2021-05-28 01:05:26,113 ----------------------------------------------------------------------------------------------------
2021-05-28 01:05:26,113 EPOCH 19 done: loss 4.1451 - lr 0.0500000
2021-05-28 01:05:27,664 DEV : loss 3.621485710144043 - score 0.8369
2021-05-28 01:05:27,687 BAD EPOCHS (no improvement): 2
2021-05-28 01:05:27,688 ----------------------------------------------------------------------------------------------------
2021-05-28 01:05:30,261 epoch 20 - iter 5/55 - loss 4.16494832 - samples/sec: 62.18 - lr: 0.050000
2021-05-28 01:05:32,831 epoch 20 - iter 10/55 - loss 4.12927318 - samples/sec: 62.29 - lr: 0.050000
2021-05-28 01:05:35,392 epoch 20 - iter 15/55 - loss 4.16769114 - samples/sec: 62.49 - lr: 0.050000
2021-05-28 01:05:37,934 epoch 20 - iter 20/55 - loss 4.15892146 - samples/sec: 62.97 - lr: 0.050000
2021-05-28 01:05:40,472 epoch 20 - iter 25/55 - loss 4.12856264 - samples/sec: 63.06 - lr: 0.050000
2021-05-28 01:05:43,034 epoch 20 - iter 30/55 - loss 4.15358715 - samples/sec: 62.46 - lr: 0.050000
2021-05-28 01:05:45,597 epoch 20 - iter 35/55 - loss 4.21289155 - samples/sec: 62.44 - lr: 0.050000
2021-05-28 01:05:48,168 epoch 20 - iter 40/55 - loss 4.20796787 - samples/sec: 62.26 - lr: 0.050000
2021-05-28 01:05:50,712 epoch 20 - iter 45/55 - loss 4.19719277 - samples/sec: 62.90 - lr: 0.050000
2021-05-28 01:05:53,272 epoch 20 - iter 50/55 - loss 4.20241012 - samples/sec: 62.52 - lr: 0.050000
2021-05-28 01:05:55,686 epoch 20 - iter 55/55 - loss 4.20159343 - samples/sec: 66.30 - lr: 0.050000
2021-05-28 01:05:55,687 ----------------------------------------------------------------------------------------------------
2021-05-28 01:05:55,687 EPOCH 20 done: loss 4.2016 - lr 0.0500000
2021-05-28 01:05:57,028 DEV : loss 3.276614189147949 - score 0.8465
2021-05-28 01:05:57,052 BAD EPOCHS (no improvement): 3
2021-05-28 01:05:57,052 ----------------------------------------------------------------------------------------------------
2021-05-28 01:05:59,589 epoch 21 - iter 5/55 - loss 4.31569948 - samples/sec: 63.09 - lr: 0.050000
2021-05-28 01:06:02,138 epoch 21 - iter 10/55 - loss 4.20954208 - samples/sec: 62.77 - lr: 0.050000
2021-05-28 01:06:04,728 epoch 21 - iter 15/55 - loss 4.20981332 - samples/sec: 61.81 - lr: 0.050000
2021-05-28 01:06:07,326 epoch 21 - iter 20/55 - loss 4.28754575 - samples/sec: 61.59 - lr: 0.050000
2021-05-28 01:06:09,884 epoch 21 - iter 25/55 - loss 4.29771847 - samples/sec: 62.57 - lr: 0.050000
2021-05-28 01:06:12,480 epoch 21 - iter 30/55 - loss 4.25815156 - samples/sec: 61.66 - lr: 0.050000
2021-05-28 01:06:15,059 epoch 21 - iter 35/55 - loss 4.30521336 - samples/sec: 62.05 - lr: 0.050000
2021-05-28 01:06:17,633 epoch 21 - iter 40/55 - loss 4.29547843 - samples/sec: 62.19 - lr: 0.050000
2021-05-28 01:06:20,193 epoch 21 - iter 45/55 - loss 4.26948009 - samples/sec: 62.51 - lr: 0.050000
2021-05-28 01:06:22,780 epoch 21 - iter 50/55 - loss 4.22735232 - samples/sec: 61.85 - lr: 0.050000
2021-05-28 01:06:25,237 epoch 21 - iter 55/55 - loss 4.22484942 - samples/sec: 65.15 - lr: 0.050000
2021-05-28 01:06:25,237 ----------------------------------------------------------------------------------------------------
2021-05-28 01:06:25,237 EPOCH 21 done: loss 4.2248 - lr 0.0500000
2021-05-28 01:06:26,591 DEV : loss 3.4777309894561768 - score 0.8459
Epoch    21: reducing learning rate of group 0 to 2.5000e-02.
2021-05-28 01:06:26,614 BAD EPOCHS (no improvement): 4
2021-05-28 01:06:26,615 ----------------------------------------------------------------------------------------------------
2021-05-28 01:06:29,164 epoch 22 - iter 5/55 - loss 4.08873525 - samples/sec: 62.78 - lr: 0.025000
2021-05-28 01:06:31,765 epoch 22 - iter 10/55 - loss 4.20912673 - samples/sec: 61.53 - lr: 0.025000
2021-05-28 01:06:34,334 epoch 22 - iter 15/55 - loss 4.03778278 - samples/sec: 62.29 - lr: 0.025000
2021-05-28 01:06:36,922 epoch 22 - iter 20/55 - loss 3.99591023 - samples/sec: 61.84 - lr: 0.025000
2021-05-28 01:06:39,519 epoch 22 - iter 25/55 - loss 3.97793573 - samples/sec: 61.62 - lr: 0.025000
2021-05-28 01:06:42,086 epoch 22 - iter 30/55 - loss 4.03180493 - samples/sec: 62.36 - lr: 0.025000
2021-05-28 01:06:44,660 epoch 22 - iter 35/55 - loss 4.02914152 - samples/sec: 62.15 - lr: 0.025000
2021-05-28 01:06:47,246 epoch 22 - iter 40/55 - loss 4.03858158 - samples/sec: 61.89 - lr: 0.025000
2021-05-28 01:06:49,812 epoch 22 - iter 45/55 - loss 4.02515476 - samples/sec: 62.38 - lr: 0.025000
2021-05-28 01:06:52,391 epoch 22 - iter 50/55 - loss 4.03466843 - samples/sec: 62.05 - lr: 0.025000
2021-05-28 01:06:54,837 epoch 22 - iter 55/55 - loss 4.02775272 - samples/sec: 65.45 - lr: 0.025000
2021-05-28 01:06:54,837 ----------------------------------------------------------------------------------------------------
2021-05-28 01:06:54,837 EPOCH 22 done: loss 4.0278 - lr 0.0250000
2021-05-28 01:06:56,182 DEV : loss 3.2577455043792725 - score 0.8484
2021-05-28 01:06:56,206 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:07:05,390 ----------------------------------------------------------------------------------------------------
2021-05-28 01:07:07,939 epoch 23 - iter 5/55 - loss 3.80883117 - samples/sec: 62.80 - lr: 0.025000
2021-05-28 01:07:10,519 epoch 23 - iter 10/55 - loss 4.06069586 - samples/sec: 62.04 - lr: 0.025000
2021-05-28 01:07:13,083 epoch 23 - iter 15/55 - loss 3.98333546 - samples/sec: 62.40 - lr: 0.025000
2021-05-28 01:07:15,659 epoch 23 - iter 20/55 - loss 3.99268502 - samples/sec: 62.15 - lr: 0.025000
2021-05-28 01:07:18,222 epoch 23 - iter 25/55 - loss 4.01357001 - samples/sec: 62.45 - lr: 0.025000
2021-05-28 01:07:20,783 epoch 23 - iter 30/55 - loss 4.02597330 - samples/sec: 62.47 - lr: 0.025000
2021-05-28 01:07:23,365 epoch 23 - iter 35/55 - loss 4.04766741 - samples/sec: 62.00 - lr: 0.025000
2021-05-28 01:07:25,938 epoch 23 - iter 40/55 - loss 4.05982531 - samples/sec: 62.19 - lr: 0.025000
2021-05-28 01:07:28,500 epoch 23 - iter 45/55 - loss 4.04682883 - samples/sec: 62.46 - lr: 0.025000
2021-05-28 01:07:31,062 epoch 23 - iter 50/55 - loss 4.01239900 - samples/sec: 62.47 - lr: 0.025000
2021-05-28 01:07:33,523 epoch 23 - iter 55/55 - loss 4.02994548 - samples/sec: 65.03 - lr: 0.025000
2021-05-28 01:07:33,524 ----------------------------------------------------------------------------------------------------
2021-05-28 01:07:33,524 EPOCH 23 done: loss 4.0299 - lr 0.0250000
2021-05-28 01:07:34,866 DEV : loss 3.261113166809082 - score 0.8517
2021-05-28 01:07:34,890 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:07:44,548 ----------------------------------------------------------------------------------------------------
2021-05-28 01:07:47,130 epoch 24 - iter 5/55 - loss 4.03222046 - samples/sec: 62.00 - lr: 0.025000
2021-05-28 01:07:49,700 epoch 24 - iter 10/55 - loss 4.02613609 - samples/sec: 62.27 - lr: 0.025000
2021-05-28 01:07:52,297 epoch 24 - iter 15/55 - loss 4.07208408 - samples/sec: 61.62 - lr: 0.025000
2021-05-28 01:07:54,857 epoch 24 - iter 20/55 - loss 4.05010054 - samples/sec: 62.53 - lr: 0.025000
2021-05-28 01:07:57,437 epoch 24 - iter 25/55 - loss 4.04447724 - samples/sec: 62.02 - lr: 0.025000
2021-05-28 01:08:00,024 epoch 24 - iter 30/55 - loss 3.98841190 - samples/sec: 61.86 - lr: 0.025000
2021-05-28 01:08:02,611 epoch 24 - iter 35/55 - loss 3.94907558 - samples/sec: 61.87 - lr: 0.025000
2021-05-28 01:08:05,166 epoch 24 - iter 40/55 - loss 3.95424175 - samples/sec: 62.66 - lr: 0.025000
2021-05-28 01:08:07,728 epoch 24 - iter 45/55 - loss 3.95613600 - samples/sec: 62.46 - lr: 0.025000
2021-05-28 01:08:10,291 epoch 24 - iter 50/55 - loss 3.97617969 - samples/sec: 62.45 - lr: 0.025000
2021-05-28 01:08:12,722 epoch 24 - iter 55/55 - loss 3.97519822 - samples/sec: 65.84 - lr: 0.025000
2021-05-28 01:08:12,722 ----------------------------------------------------------------------------------------------------
2021-05-28 01:08:12,722 EPOCH 24 done: loss 3.9752 - lr 0.0250000
2021-05-28 01:08:14,067 DEV : loss 3.4665961265563965 - score 0.8453
2021-05-28 01:08:14,091 BAD EPOCHS (no improvement): 1
2021-05-28 01:08:14,091 ----------------------------------------------------------------------------------------------------
2021-05-28 01:08:16,645 epoch 25 - iter 5/55 - loss 3.97085834 - samples/sec: 62.66 - lr: 0.025000
2021-05-28 01:08:19,199 epoch 25 - iter 10/55 - loss 3.78757083 - samples/sec: 62.65 - lr: 0.025000
2021-05-28 01:08:21,766 epoch 25 - iter 15/55 - loss 3.84770439 - samples/sec: 62.37 - lr: 0.025000
2021-05-28 01:08:24,307 epoch 25 - iter 20/55 - loss 3.88870049 - samples/sec: 62.98 - lr: 0.025000
2021-05-28 01:08:26,888 epoch 25 - iter 25/55 - loss 3.92268179 - samples/sec: 62.01 - lr: 0.025000
2021-05-28 01:08:29,471 epoch 25 - iter 30/55 - loss 3.92434449 - samples/sec: 61.97 - lr: 0.025000
2021-05-28 01:08:32,024 epoch 25 - iter 35/55 - loss 3.98646029 - samples/sec: 62.67 - lr: 0.025000
2021-05-28 01:08:34,581 epoch 25 - iter 40/55 - loss 3.96485221 - samples/sec: 62.59 - lr: 0.025000
2021-05-28 01:08:37,171 epoch 25 - iter 45/55 - loss 3.96585142 - samples/sec: 61.80 - lr: 0.025000
2021-05-28 01:08:39,743 epoch 25 - iter 50/55 - loss 3.95759251 - samples/sec: 62.22 - lr: 0.025000
2021-05-28 01:08:42,170 epoch 25 - iter 55/55 - loss 3.97648934 - samples/sec: 65.95 - lr: 0.025000
2021-05-28 01:08:42,170 ----------------------------------------------------------------------------------------------------
2021-05-28 01:08:42,170 EPOCH 25 done: loss 3.9765 - lr 0.0250000
2021-05-28 01:08:43,513 DEV : loss 3.4657175540924072 - score 0.849
2021-05-28 01:08:43,537 BAD EPOCHS (no improvement): 2
2021-05-28 01:08:43,537 ----------------------------------------------------------------------------------------------------
2021-05-28 01:08:46,087 epoch 26 - iter 5/55 - loss 3.80123096 - samples/sec: 62.76 - lr: 0.025000
2021-05-28 01:08:48,642 epoch 26 - iter 10/55 - loss 3.89910533 - samples/sec: 62.64 - lr: 0.025000
2021-05-28 01:08:51,211 epoch 26 - iter 15/55 - loss 3.88589398 - samples/sec: 62.30 - lr: 0.025000
2021-05-28 01:08:53,777 epoch 26 - iter 20/55 - loss 3.95608490 - samples/sec: 62.38 - lr: 0.025000
2021-05-28 01:08:56,314 epoch 26 - iter 25/55 - loss 3.95036539 - samples/sec: 63.09 - lr: 0.025000
2021-05-28 01:08:58,877 epoch 26 - iter 30/55 - loss 3.97461531 - samples/sec: 62.45 - lr: 0.025000
2021-05-28 01:09:01,443 epoch 26 - iter 35/55 - loss 3.94157280 - samples/sec: 62.36 - lr: 0.025000
2021-05-28 01:09:03,999 epoch 26 - iter 40/55 - loss 3.99010821 - samples/sec: 62.62 - lr: 0.025000
2021-05-28 01:09:06,548 epoch 26 - iter 45/55 - loss 3.98062233 - samples/sec: 62.80 - lr: 0.025000
2021-05-28 01:09:09,110 epoch 26 - iter 50/55 - loss 3.97902183 - samples/sec: 62.46 - lr: 0.025000
2021-05-28 01:09:11,556 epoch 26 - iter 55/55 - loss 3.95666047 - samples/sec: 65.42 - lr: 0.025000
2021-05-28 01:09:11,556 ----------------------------------------------------------------------------------------------------
2021-05-28 01:09:11,557 EPOCH 26 done: loss 3.9567 - lr 0.0250000
2021-05-28 01:09:13,111 DEV : loss 3.375305652618408 - score 0.849
2021-05-28 01:09:13,135 BAD EPOCHS (no improvement): 3
2021-05-28 01:09:13,135 ----------------------------------------------------------------------------------------------------
2021-05-28 01:09:15,667 epoch 27 - iter 5/55 - loss 3.87345204 - samples/sec: 63.22 - lr: 0.025000
2021-05-28 01:09:18,223 epoch 27 - iter 10/55 - loss 3.80544884 - samples/sec: 62.61 - lr: 0.025000
2021-05-28 01:09:20,793 epoch 27 - iter 15/55 - loss 3.83500732 - samples/sec: 62.27 - lr: 0.025000
2021-05-28 01:09:23,348 epoch 27 - iter 20/55 - loss 3.91392646 - samples/sec: 62.66 - lr: 0.025000
2021-05-28 01:09:25,906 epoch 27 - iter 25/55 - loss 3.95450187 - samples/sec: 62.54 - lr: 0.025000
2021-05-28 01:09:28,470 epoch 27 - iter 30/55 - loss 3.92625236 - samples/sec: 62.42 - lr: 0.025000
2021-05-28 01:09:31,053 epoch 27 - iter 35/55 - loss 3.96467237 - samples/sec: 61.96 - lr: 0.025000
2021-05-28 01:09:33,620 epoch 27 - iter 40/55 - loss 3.95491171 - samples/sec: 62.35 - lr: 0.025000
2021-05-28 01:09:36,154 epoch 27 - iter 45/55 - loss 3.90339017 - samples/sec: 63.17 - lr: 0.025000
2021-05-28 01:09:38,715 epoch 27 - iter 50/55 - loss 3.93270178 - samples/sec: 62.48 - lr: 0.025000
2021-05-28 01:09:41,119 epoch 27 - iter 55/55 - loss 3.89527813 - samples/sec: 66.58 - lr: 0.025000
2021-05-28 01:09:41,120 ----------------------------------------------------------------------------------------------------
2021-05-28 01:09:41,120 EPOCH 27 done: loss 3.8953 - lr 0.0250000
2021-05-28 01:09:42,462 DEV : loss 3.2783942222595215 - score 0.8553
2021-05-28 01:09:42,485 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:09:51,813 ----------------------------------------------------------------------------------------------------
2021-05-28 01:09:54,375 epoch 28 - iter 5/55 - loss 3.98053770 - samples/sec: 62.48 - lr: 0.025000
2021-05-28 01:09:56,939 epoch 28 - iter 10/55 - loss 3.90891137 - samples/sec: 62.41 - lr: 0.025000
2021-05-28 01:09:59,495 epoch 28 - iter 15/55 - loss 3.83556479 - samples/sec: 62.61 - lr: 0.025000
2021-05-28 01:10:02,052 epoch 28 - iter 20/55 - loss 3.87424394 - samples/sec: 62.60 - lr: 0.025000
2021-05-28 01:10:04,607 epoch 28 - iter 25/55 - loss 3.92185659 - samples/sec: 62.64 - lr: 0.025000
2021-05-28 01:10:07,152 epoch 28 - iter 30/55 - loss 3.89356994 - samples/sec: 62.89 - lr: 0.025000
2021-05-28 01:10:09,694 epoch 28 - iter 35/55 - loss 3.86447097 - samples/sec: 62.95 - lr: 0.025000
2021-05-28 01:10:12,256 epoch 28 - iter 40/55 - loss 3.89966505 - samples/sec: 62.46 - lr: 0.025000
2021-05-28 01:10:14,811 epoch 28 - iter 45/55 - loss 3.89420684 - samples/sec: 62.65 - lr: 0.025000
2021-05-28 01:10:17,382 epoch 28 - iter 50/55 - loss 3.91766299 - samples/sec: 62.25 - lr: 0.025000
2021-05-28 01:10:19,835 epoch 28 - iter 55/55 - loss 3.90351729 - samples/sec: 65.23 - lr: 0.025000
2021-05-28 01:10:19,836 ----------------------------------------------------------------------------------------------------
2021-05-28 01:10:19,836 EPOCH 28 done: loss 3.9035 - lr 0.0250000
2021-05-28 01:10:21,177 DEV : loss 3.172132730484009 - score 0.8537
2021-05-28 01:10:21,201 BAD EPOCHS (no improvement): 1
2021-05-28 01:10:21,201 ----------------------------------------------------------------------------------------------------
2021-05-28 01:10:23,747 epoch 29 - iter 5/55 - loss 3.65747085 - samples/sec: 62.88 - lr: 0.025000
2021-05-28 01:10:26,305 epoch 29 - iter 10/55 - loss 3.79971383 - samples/sec: 62.55 - lr: 0.025000
2021-05-28 01:10:28,868 epoch 29 - iter 15/55 - loss 3.92385705 - samples/sec: 62.46 - lr: 0.025000
2021-05-28 01:10:31,413 epoch 29 - iter 20/55 - loss 3.87447692 - samples/sec: 62.86 - lr: 0.025000
2021-05-28 01:10:33,951 epoch 29 - iter 25/55 - loss 3.84884274 - samples/sec: 63.06 - lr: 0.025000
2021-05-28 01:10:36,512 epoch 29 - iter 30/55 - loss 3.86791753 - samples/sec: 62.50 - lr: 0.025000
2021-05-28 01:10:39,062 epoch 29 - iter 35/55 - loss 3.89023593 - samples/sec: 62.76 - lr: 0.025000
2021-05-28 01:10:41,620 epoch 29 - iter 40/55 - loss 3.94353375 - samples/sec: 62.56 - lr: 0.025000
2021-05-28 01:10:44,189 epoch 29 - iter 45/55 - loss 3.95490768 - samples/sec: 62.30 - lr: 0.025000
2021-05-28 01:10:46,736 epoch 29 - iter 50/55 - loss 3.93279799 - samples/sec: 62.84 - lr: 0.025000
2021-05-28 01:10:49,193 epoch 29 - iter 55/55 - loss 3.91902941 - samples/sec: 65.14 - lr: 0.025000
2021-05-28 01:10:49,194 ----------------------------------------------------------------------------------------------------
2021-05-28 01:10:49,194 EPOCH 29 done: loss 3.9190 - lr 0.0250000
2021-05-28 01:10:50,536 DEV : loss 3.20001220703125 - score 0.8552
2021-05-28 01:10:50,559 BAD EPOCHS (no improvement): 2
2021-05-28 01:10:50,560 ----------------------------------------------------------------------------------------------------
2021-05-28 01:10:53,117 epoch 30 - iter 5/55 - loss 3.94652629 - samples/sec: 62.58 - lr: 0.025000
2021-05-28 01:10:55,668 epoch 30 - iter 10/55 - loss 4.05419965 - samples/sec: 62.73 - lr: 0.025000
2021-05-28 01:10:58,235 epoch 30 - iter 15/55 - loss 3.95755808 - samples/sec: 62.34 - lr: 0.025000
2021-05-28 01:11:00,802 epoch 30 - iter 20/55 - loss 3.92234257 - samples/sec: 62.36 - lr: 0.025000
2021-05-28 01:11:03,377 epoch 30 - iter 25/55 - loss 3.87545313 - samples/sec: 62.14 - lr: 0.025000
2021-05-28 01:11:05,934 epoch 30 - iter 30/55 - loss 3.89569570 - samples/sec: 62.59 - lr: 0.025000
2021-05-28 01:11:08,507 epoch 30 - iter 35/55 - loss 3.91376178 - samples/sec: 62.19 - lr: 0.025000
2021-05-28 01:11:11,034 epoch 30 - iter 40/55 - loss 3.90407557 - samples/sec: 63.35 - lr: 0.025000
2021-05-28 01:11:13,547 epoch 30 - iter 45/55 - loss 3.90491376 - samples/sec: 63.67 - lr: 0.025000
2021-05-28 01:11:16,062 epoch 30 - iter 50/55 - loss 3.89592453 - samples/sec: 63.63 - lr: 0.025000
2021-05-28 01:11:18,491 epoch 30 - iter 55/55 - loss 3.87255174 - samples/sec: 65.89 - lr: 0.025000
2021-05-28 01:11:18,492 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:18,492 EPOCH 30 done: loss 3.8726 - lr 0.0250000
2021-05-28 01:11:20,046 DEV : loss 3.354318857192993 - score 0.8554
2021-05-28 01:11:20,070 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:11:30,369 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:30,369 Testing using best model ...
2021-05-28 01:11:30,370 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eng.sdrt.stac/best-model.pt
2021-05-28 01:11:39,570 0.8004	0.8585	0.8284
2021-05-28 01:11:39,570 
Results:
- F1-score (micro) 0.8284
- F1-score (macro) 0.8284

By class:
SENT       tp: 1159 - fp: 289 - fn: 191 - precision: 0.8004 - recall: 0.8585 - f1-score: 0.8284
2021-05-28 01:11:39,570 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/
2021-05-28 01:11:39,601 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb
2021-05-28 01:11:39,601 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/sent_train.txt
2021-05-28 01:11:39,604 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/sent_dev.txt
2021-05-28 01:11:39,606 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/sent_test.txt
Corpus: 501 train + 119 dev + 186 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-28 01:11:45,481 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:45,484 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-28 01:11:45,484 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:45,484 Corpus: "Corpus: 501 train + 119 dev + 186 test sentences"
2021-05-28 01:11:45,484 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:45,484 Parameters:
2021-05-28 01:11:45,484  - learning_rate: "0.1"
2021-05-28 01:11:45,484  - mini_batch_size: "32"
2021-05-28 01:11:45,484  - patience: "3"
2021-05-28 01:11:45,484  - anneal_factor: "0.5"
2021-05-28 01:11:45,484  - max_epochs: "30"
2021-05-28 01:11:45,484  - shuffle: "True"
2021-05-28 01:11:45,484  - train_with_dev: "False"
2021-05-28 01:11:45,484  - batch_growth_annealing: "False"
2021-05-28 01:11:45,484 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:45,484 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb"
2021-05-28 01:11:45,484 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:45,484 Device: cuda:0
2021-05-28 01:11:45,484 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:45,484 Embeddings storage mode: cpu
2021-05-28 01:11:45,487 ----------------------------------------------------------------------------------------------------
2021-05-28 01:11:46,793 epoch 1 - iter 1/16 - loss 66.57109070 - samples/sec: 24.52 - lr: 0.100000
2021-05-28 01:11:48,105 epoch 1 - iter 2/16 - loss 43.11621284 - samples/sec: 24.39 - lr: 0.100000
2021-05-28 01:11:49,428 epoch 1 - iter 3/16 - loss 30.60763168 - samples/sec: 24.18 - lr: 0.100000
2021-05-28 01:11:50,753 epoch 1 - iter 4/16 - loss 25.06278062 - samples/sec: 24.16 - lr: 0.100000
2021-05-28 01:11:52,072 epoch 1 - iter 5/16 - loss 20.96002789 - samples/sec: 24.26 - lr: 0.100000
2021-05-28 01:11:53,390 epoch 1 - iter 6/16 - loss 18.22618103 - samples/sec: 24.29 - lr: 0.100000
2021-05-28 01:11:54,729 epoch 1 - iter 7/16 - loss 16.40805381 - samples/sec: 23.92 - lr: 0.100000
2021-05-28 01:11:56,042 epoch 1 - iter 8/16 - loss 14.81102249 - samples/sec: 24.36 - lr: 0.100000
2021-05-28 01:11:57,383 epoch 1 - iter 9/16 - loss 13.78204915 - samples/sec: 23.88 - lr: 0.100000
2021-05-28 01:11:58,724 epoch 1 - iter 10/16 - loss 12.81988785 - samples/sec: 23.85 - lr: 0.100000
2021-05-28 01:12:00,049 epoch 1 - iter 11/16 - loss 12.03420537 - samples/sec: 24.16 - lr: 0.100000
2021-05-28 01:12:01,391 epoch 1 - iter 12/16 - loss 11.25289363 - samples/sec: 23.86 - lr: 0.100000
2021-05-28 01:12:02,732 epoch 1 - iter 13/16 - loss 10.65140128 - samples/sec: 23.86 - lr: 0.100000
2021-05-28 01:12:04,062 epoch 1 - iter 14/16 - loss 10.04641906 - samples/sec: 24.08 - lr: 0.100000
2021-05-28 01:12:05,400 epoch 1 - iter 15/16 - loss 9.68124779 - samples/sec: 23.92 - lr: 0.100000
2021-05-28 01:12:06,286 epoch 1 - iter 16/16 - loss 9.20561786 - samples/sec: 36.12 - lr: 0.100000
2021-05-28 01:12:06,286 ----------------------------------------------------------------------------------------------------
2021-05-28 01:12:06,286 EPOCH 1 done: loss 9.2056 - lr 0.1000000
2021-05-28 01:12:09,562 DEV : loss 3.7109358310699463 - score 0.0
2021-05-28 01:12:09,574 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:12:10,563 ----------------------------------------------------------------------------------------------------
2021-05-28 01:12:11,087 epoch 2 - iter 1/16 - loss 2.49894476 - samples/sec: 61.13 - lr: 0.100000
2021-05-28 01:12:11,624 epoch 2 - iter 2/16 - loss 2.24896365 - samples/sec: 59.60 - lr: 0.100000
2021-05-28 01:12:12,153 epoch 2 - iter 3/16 - loss 3.12642737 - samples/sec: 60.64 - lr: 0.100000
2021-05-28 01:12:12,684 epoch 2 - iter 4/16 - loss 3.10771993 - samples/sec: 60.32 - lr: 0.100000
2021-05-28 01:12:13,207 epoch 2 - iter 5/16 - loss 3.13585517 - samples/sec: 61.20 - lr: 0.100000
2021-05-28 01:12:13,740 epoch 2 - iter 6/16 - loss 2.97121189 - samples/sec: 60.14 - lr: 0.100000
2021-05-28 01:12:14,252 epoch 2 - iter 7/16 - loss 2.99017325 - samples/sec: 62.49 - lr: 0.100000
2021-05-28 01:12:14,791 epoch 2 - iter 8/16 - loss 3.04130588 - samples/sec: 59.42 - lr: 0.100000
2021-05-28 01:12:15,315 epoch 2 - iter 9/16 - loss 2.96904520 - samples/sec: 61.14 - lr: 0.100000
2021-05-28 01:12:15,848 epoch 2 - iter 10/16 - loss 2.95577949 - samples/sec: 60.14 - lr: 0.100000
2021-05-28 01:12:16,377 epoch 2 - iter 11/16 - loss 2.92267274 - samples/sec: 60.53 - lr: 0.100000
2021-05-28 01:12:16,878 epoch 2 - iter 12/16 - loss 2.84256466 - samples/sec: 63.90 - lr: 0.100000
2021-05-28 01:12:17,406 epoch 2 - iter 13/16 - loss 2.89799465 - samples/sec: 60.64 - lr: 0.100000
2021-05-28 01:12:17,938 epoch 2 - iter 14/16 - loss 2.86144275 - samples/sec: 60.24 - lr: 0.100000
2021-05-28 01:12:18,461 epoch 2 - iter 15/16 - loss 2.82007432 - samples/sec: 61.29 - lr: 0.100000
2021-05-28 01:12:18,814 epoch 2 - iter 16/16 - loss 2.73024961 - samples/sec: 90.69 - lr: 0.100000
2021-05-28 01:12:18,814 ----------------------------------------------------------------------------------------------------
2021-05-28 01:12:18,814 EPOCH 2 done: loss 2.7302 - lr 0.1000000
2021-05-28 01:12:19,513 DEV : loss 2.837196111679077 - score 0.0
2021-05-28 01:12:19,525 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:12:28,803 ----------------------------------------------------------------------------------------------------
2021-05-28 01:12:29,337 epoch 3 - iter 1/16 - loss 2.26199389 - samples/sec: 60.10 - lr: 0.100000
2021-05-28 01:12:29,873 epoch 3 - iter 2/16 - loss 1.99634516 - samples/sec: 59.76 - lr: 0.100000
2021-05-28 01:12:30,386 epoch 3 - iter 3/16 - loss 2.04962643 - samples/sec: 62.36 - lr: 0.100000
2021-05-28 01:12:30,917 epoch 3 - iter 4/16 - loss 1.92765343 - samples/sec: 60.31 - lr: 0.100000
2021-05-28 01:12:31,440 epoch 3 - iter 5/16 - loss 2.05366416 - samples/sec: 61.28 - lr: 0.100000
2021-05-28 01:12:31,970 epoch 3 - iter 6/16 - loss 2.08498180 - samples/sec: 60.45 - lr: 0.100000
2021-05-28 01:12:32,497 epoch 3 - iter 7/16 - loss 2.21357860 - samples/sec: 60.71 - lr: 0.100000
2021-05-28 01:12:33,020 epoch 3 - iter 8/16 - loss 2.12501974 - samples/sec: 61.30 - lr: 0.100000
2021-05-28 01:12:33,546 epoch 3 - iter 9/16 - loss 2.22149040 - samples/sec: 60.85 - lr: 0.100000
2021-05-28 01:12:34,076 epoch 3 - iter 10/16 - loss 2.14825953 - samples/sec: 60.43 - lr: 0.100000
2021-05-28 01:12:34,599 epoch 3 - iter 11/16 - loss 2.20248982 - samples/sec: 61.24 - lr: 0.100000
2021-05-28 01:12:35,112 epoch 3 - iter 12/16 - loss 2.17502608 - samples/sec: 62.44 - lr: 0.100000
2021-05-28 01:12:35,645 epoch 3 - iter 13/16 - loss 2.27695223 - samples/sec: 60.10 - lr: 0.100000
2021-05-28 01:12:36,182 epoch 3 - iter 14/16 - loss 2.21591953 - samples/sec: 59.64 - lr: 0.100000
2021-05-28 01:12:36,705 epoch 3 - iter 15/16 - loss 2.14124777 - samples/sec: 61.24 - lr: 0.100000
2021-05-28 01:12:37,065 epoch 3 - iter 16/16 - loss 2.13101088 - samples/sec: 89.10 - lr: 0.100000
2021-05-28 01:12:37,065 ----------------------------------------------------------------------------------------------------
2021-05-28 01:12:37,065 EPOCH 3 done: loss 2.1310 - lr 0.1000000
2021-05-28 01:12:37,762 DEV : loss 1.6318787336349487 - score 0.0
2021-05-28 01:12:37,774 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:12:47,248 ----------------------------------------------------------------------------------------------------
2021-05-28 01:12:47,780 epoch 4 - iter 1/16 - loss 2.49192333 - samples/sec: 60.27 - lr: 0.100000
2021-05-28 01:12:48,304 epoch 4 - iter 2/16 - loss 2.14637339 - samples/sec: 61.10 - lr: 0.100000
2021-05-28 01:12:48,840 epoch 4 - iter 3/16 - loss 2.08820415 - samples/sec: 59.82 - lr: 0.100000
2021-05-28 01:12:49,358 epoch 4 - iter 4/16 - loss 1.83255118 - samples/sec: 61.80 - lr: 0.100000
2021-05-28 01:12:49,880 epoch 4 - iter 5/16 - loss 1.64607747 - samples/sec: 61.40 - lr: 0.100000
2021-05-28 01:12:50,401 epoch 4 - iter 6/16 - loss 1.61396521 - samples/sec: 61.45 - lr: 0.100000
2021-05-28 01:12:50,936 epoch 4 - iter 7/16 - loss 1.70054867 - samples/sec: 59.92 - lr: 0.100000
2021-05-28 01:12:51,459 epoch 4 - iter 8/16 - loss 1.58305785 - samples/sec: 61.23 - lr: 0.100000
2021-05-28 01:12:51,992 epoch 4 - iter 9/16 - loss 1.69359891 - samples/sec: 60.00 - lr: 0.100000
2021-05-28 01:12:52,534 epoch 4 - iter 10/16 - loss 1.61815057 - samples/sec: 59.10 - lr: 0.100000
2021-05-28 01:12:53,060 epoch 4 - iter 11/16 - loss 1.58000562 - samples/sec: 60.95 - lr: 0.100000
2021-05-28 01:12:53,591 epoch 4 - iter 12/16 - loss 1.53826753 - samples/sec: 60.26 - lr: 0.100000
2021-05-28 01:12:54,120 epoch 4 - iter 13/16 - loss 1.53107149 - samples/sec: 60.64 - lr: 0.100000
2021-05-28 01:12:54,650 epoch 4 - iter 14/16 - loss 1.49824971 - samples/sec: 60.38 - lr: 0.100000
2021-05-28 01:12:55,200 epoch 4 - iter 15/16 - loss 1.55162313 - samples/sec: 60.23 - lr: 0.100000
2021-05-28 01:12:55,566 epoch 4 - iter 16/16 - loss 1.51598231 - samples/sec: 87.57 - lr: 0.100000
2021-05-28 01:12:55,566 ----------------------------------------------------------------------------------------------------
2021-05-28 01:12:55,566 EPOCH 4 done: loss 1.5160 - lr 0.1000000
2021-05-28 01:12:56,271 DEV : loss 1.5507797002792358 - score 0.1026
2021-05-28 01:12:56,283 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:13:05,543 ----------------------------------------------------------------------------------------------------
2021-05-28 01:13:06,081 epoch 5 - iter 1/16 - loss 1.91453493 - samples/sec: 59.68 - lr: 0.100000
2021-05-28 01:13:06,608 epoch 5 - iter 2/16 - loss 1.64117235 - samples/sec: 60.73 - lr: 0.100000
2021-05-28 01:13:07,124 epoch 5 - iter 3/16 - loss 1.51817127 - samples/sec: 62.09 - lr: 0.100000
2021-05-28 01:13:07,665 epoch 5 - iter 4/16 - loss 1.41503796 - samples/sec: 59.22 - lr: 0.100000
2021-05-28 01:13:08,190 epoch 5 - iter 5/16 - loss 1.42219021 - samples/sec: 60.94 - lr: 0.100000
2021-05-28 01:13:08,727 epoch 5 - iter 6/16 - loss 1.37455573 - samples/sec: 59.63 - lr: 0.100000
2021-05-28 01:13:09,252 epoch 5 - iter 7/16 - loss 1.42805398 - samples/sec: 61.08 - lr: 0.100000
2021-05-28 01:13:09,769 epoch 5 - iter 8/16 - loss 1.33526593 - samples/sec: 61.86 - lr: 0.100000
2021-05-28 01:13:10,301 epoch 5 - iter 9/16 - loss 1.36197620 - samples/sec: 60.21 - lr: 0.100000
2021-05-28 01:13:10,836 epoch 5 - iter 10/16 - loss 1.31567459 - samples/sec: 59.86 - lr: 0.100000
2021-05-28 01:13:11,361 epoch 5 - iter 11/16 - loss 1.28456487 - samples/sec: 61.01 - lr: 0.100000
2021-05-28 01:13:11,897 epoch 5 - iter 12/16 - loss 1.34564428 - samples/sec: 59.76 - lr: 0.100000
2021-05-28 01:13:12,433 epoch 5 - iter 13/16 - loss 1.29526927 - samples/sec: 59.84 - lr: 0.100000
2021-05-28 01:13:12,959 epoch 5 - iter 14/16 - loss 1.23401570 - samples/sec: 60.82 - lr: 0.100000
2021-05-28 01:13:13,489 epoch 5 - iter 15/16 - loss 1.18333317 - samples/sec: 60.43 - lr: 0.100000
2021-05-28 01:13:13,840 epoch 5 - iter 16/16 - loss 1.14993693 - samples/sec: 91.51 - lr: 0.100000
2021-05-28 01:13:13,840 ----------------------------------------------------------------------------------------------------
2021-05-28 01:13:13,840 EPOCH 5 done: loss 1.1499 - lr 0.1000000
2021-05-28 01:13:14,542 DEV : loss 0.39613282680511475 - score 0.879
2021-05-28 01:13:14,554 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:13:23,708 ----------------------------------------------------------------------------------------------------
2021-05-28 01:13:24,233 epoch 6 - iter 1/16 - loss 0.60455704 - samples/sec: 61.03 - lr: 0.100000
2021-05-28 01:13:24,761 epoch 6 - iter 2/16 - loss 1.24766386 - samples/sec: 60.64 - lr: 0.100000
2021-05-28 01:13:25,291 epoch 6 - iter 3/16 - loss 1.47586544 - samples/sec: 60.52 - lr: 0.100000
2021-05-28 01:13:25,816 epoch 6 - iter 4/16 - loss 1.28213429 - samples/sec: 60.96 - lr: 0.100000
2021-05-28 01:13:26,343 epoch 6 - iter 5/16 - loss 1.23587441 - samples/sec: 60.75 - lr: 0.100000
2021-05-28 01:13:26,876 epoch 6 - iter 6/16 - loss 1.10042310 - samples/sec: 60.18 - lr: 0.100000
2021-05-28 01:13:27,390 epoch 6 - iter 7/16 - loss 1.03059474 - samples/sec: 62.25 - lr: 0.100000
2021-05-28 01:13:27,920 epoch 6 - iter 8/16 - loss 0.99136935 - samples/sec: 60.43 - lr: 0.100000
2021-05-28 01:13:28,450 epoch 6 - iter 9/16 - loss 0.98905370 - samples/sec: 60.44 - lr: 0.100000
2021-05-28 01:13:28,977 epoch 6 - iter 10/16 - loss 0.93602279 - samples/sec: 60.81 - lr: 0.100000
2021-05-28 01:13:29,490 epoch 6 - iter 11/16 - loss 0.90267928 - samples/sec: 62.42 - lr: 0.100000
2021-05-28 01:13:30,000 epoch 6 - iter 12/16 - loss 0.85793548 - samples/sec: 62.80 - lr: 0.100000
2021-05-28 01:13:30,543 epoch 6 - iter 13/16 - loss 0.84959809 - samples/sec: 58.99 - lr: 0.100000
2021-05-28 01:13:31,070 epoch 6 - iter 14/16 - loss 0.86512202 - samples/sec: 60.75 - lr: 0.100000
2021-05-28 01:13:31,596 epoch 6 - iter 15/16 - loss 0.90335755 - samples/sec: 60.89 - lr: 0.100000
2021-05-28 01:13:31,963 epoch 6 - iter 16/16 - loss 0.90177626 - samples/sec: 87.45 - lr: 0.100000
2021-05-28 01:13:31,963 ----------------------------------------------------------------------------------------------------
2021-05-28 01:13:31,963 EPOCH 6 done: loss 0.9018 - lr 0.1000000
2021-05-28 01:13:32,775 DEV : loss 0.7981883883476257 - score 0.6549
2021-05-28 01:13:32,787 BAD EPOCHS (no improvement): 1
2021-05-28 01:13:32,787 ----------------------------------------------------------------------------------------------------
2021-05-28 01:13:33,312 epoch 7 - iter 1/16 - loss 0.92851353 - samples/sec: 60.96 - lr: 0.100000
2021-05-28 01:13:33,823 epoch 7 - iter 2/16 - loss 0.66840927 - samples/sec: 62.75 - lr: 0.100000
2021-05-28 01:13:34,349 epoch 7 - iter 3/16 - loss 0.65898859 - samples/sec: 60.86 - lr: 0.100000
2021-05-28 01:13:34,873 epoch 7 - iter 4/16 - loss 0.88180109 - samples/sec: 61.05 - lr: 0.100000
2021-05-28 01:13:35,396 epoch 7 - iter 5/16 - loss 1.06024844 - samples/sec: 61.35 - lr: 0.100000
2021-05-28 01:13:35,920 epoch 7 - iter 6/16 - loss 1.10793606 - samples/sec: 61.01 - lr: 0.100000
2021-05-28 01:13:36,453 epoch 7 - iter 7/16 - loss 1.17416293 - samples/sec: 60.09 - lr: 0.100000
2021-05-28 01:13:36,981 epoch 7 - iter 8/16 - loss 1.08619907 - samples/sec: 60.66 - lr: 0.100000
2021-05-28 01:13:37,515 epoch 7 - iter 9/16 - loss 1.13639023 - samples/sec: 60.06 - lr: 0.100000
2021-05-28 01:13:38,035 epoch 7 - iter 10/16 - loss 1.08546385 - samples/sec: 61.52 - lr: 0.100000
2021-05-28 01:13:38,556 epoch 7 - iter 11/16 - loss 1.03094113 - samples/sec: 61.53 - lr: 0.100000
2021-05-28 01:13:39,070 epoch 7 - iter 12/16 - loss 0.99312817 - samples/sec: 62.35 - lr: 0.100000
2021-05-28 01:13:39,596 epoch 7 - iter 13/16 - loss 0.97700682 - samples/sec: 60.89 - lr: 0.100000
2021-05-28 01:13:40,132 epoch 7 - iter 14/16 - loss 1.04357105 - samples/sec: 59.67 - lr: 0.100000
2021-05-28 01:13:40,670 epoch 7 - iter 15/16 - loss 1.01212238 - samples/sec: 59.57 - lr: 0.100000
2021-05-28 01:13:41,038 epoch 7 - iter 16/16 - loss 1.00866161 - samples/sec: 87.03 - lr: 0.100000
2021-05-28 01:13:41,039 ----------------------------------------------------------------------------------------------------
2021-05-28 01:13:41,039 EPOCH 7 done: loss 1.0087 - lr 0.1000000
2021-05-28 01:13:41,743 DEV : loss 0.34712663292884827 - score 0.8831
2021-05-28 01:13:41,755 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:13:50,913 ----------------------------------------------------------------------------------------------------
2021-05-28 01:13:51,439 epoch 8 - iter 1/16 - loss 0.99168968 - samples/sec: 60.90 - lr: 0.100000
2021-05-28 01:13:51,975 epoch 8 - iter 2/16 - loss 0.72236943 - samples/sec: 59.78 - lr: 0.100000
2021-05-28 01:13:52,508 epoch 8 - iter 3/16 - loss 0.82895239 - samples/sec: 60.06 - lr: 0.100000
2021-05-28 01:13:53,039 epoch 8 - iter 4/16 - loss 0.96002281 - samples/sec: 60.27 - lr: 0.100000
2021-05-28 01:13:53,573 epoch 8 - iter 5/16 - loss 0.98825879 - samples/sec: 60.05 - lr: 0.100000
2021-05-28 01:13:54,108 epoch 8 - iter 6/16 - loss 1.01208850 - samples/sec: 59.87 - lr: 0.100000
2021-05-28 01:13:54,623 epoch 8 - iter 7/16 - loss 0.97120363 - samples/sec: 62.19 - lr: 0.100000
2021-05-28 01:13:55,157 epoch 8 - iter 8/16 - loss 0.96739056 - samples/sec: 59.90 - lr: 0.100000
2021-05-28 01:13:55,684 epoch 8 - iter 9/16 - loss 0.94438642 - samples/sec: 60.87 - lr: 0.100000
2021-05-28 01:13:56,215 epoch 8 - iter 10/16 - loss 0.93263690 - samples/sec: 60.31 - lr: 0.100000
2021-05-28 01:13:56,745 epoch 8 - iter 11/16 - loss 0.88455171 - samples/sec: 60.38 - lr: 0.100000
2021-05-28 01:13:57,271 epoch 8 - iter 12/16 - loss 0.87320839 - samples/sec: 60.94 - lr: 0.100000
2021-05-28 01:13:57,786 epoch 8 - iter 13/16 - loss 0.90311249 - samples/sec: 62.10 - lr: 0.100000
2021-05-28 01:13:58,296 epoch 8 - iter 14/16 - loss 0.86801165 - samples/sec: 62.83 - lr: 0.100000
2021-05-28 01:13:58,817 epoch 8 - iter 15/16 - loss 0.85480577 - samples/sec: 61.48 - lr: 0.100000
2021-05-28 01:13:59,177 epoch 8 - iter 16/16 - loss 0.86596114 - samples/sec: 88.92 - lr: 0.100000
2021-05-28 01:13:59,178 ----------------------------------------------------------------------------------------------------
2021-05-28 01:13:59,178 EPOCH 8 done: loss 0.8660 - lr 0.1000000
2021-05-28 01:13:59,878 DEV : loss 0.6576135158538818 - score 0.7009
2021-05-28 01:13:59,890 BAD EPOCHS (no improvement): 1
2021-05-28 01:13:59,890 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:00,405 epoch 9 - iter 1/16 - loss 1.47262359 - samples/sec: 62.20 - lr: 0.100000
2021-05-28 01:14:00,921 epoch 9 - iter 2/16 - loss 1.42818594 - samples/sec: 62.03 - lr: 0.100000
2021-05-28 01:14:01,449 epoch 9 - iter 3/16 - loss 1.32286676 - samples/sec: 60.62 - lr: 0.100000
2021-05-28 01:14:01,993 epoch 9 - iter 4/16 - loss 1.23272634 - samples/sec: 58.92 - lr: 0.100000
2021-05-28 01:14:02,509 epoch 9 - iter 5/16 - loss 1.20492988 - samples/sec: 62.02 - lr: 0.100000
2021-05-28 01:14:03,044 epoch 9 - iter 6/16 - loss 1.14690785 - samples/sec: 59.89 - lr: 0.100000
2021-05-28 01:14:03,577 epoch 9 - iter 7/16 - loss 1.07497185 - samples/sec: 60.08 - lr: 0.100000
2021-05-28 01:14:04,091 epoch 9 - iter 8/16 - loss 0.98363250 - samples/sec: 62.31 - lr: 0.100000
2021-05-28 01:14:04,620 epoch 9 - iter 9/16 - loss 0.95803550 - samples/sec: 60.58 - lr: 0.100000
2021-05-28 01:14:05,149 epoch 9 - iter 10/16 - loss 0.96725676 - samples/sec: 60.50 - lr: 0.100000
2021-05-28 01:14:05,672 epoch 9 - iter 11/16 - loss 0.98821660 - samples/sec: 61.31 - lr: 0.100000
2021-05-28 01:14:06,195 epoch 9 - iter 12/16 - loss 0.93804614 - samples/sec: 61.16 - lr: 0.100000
2021-05-28 01:14:06,724 epoch 9 - iter 13/16 - loss 0.92831999 - samples/sec: 60.56 - lr: 0.100000
2021-05-28 01:14:07,252 epoch 9 - iter 14/16 - loss 0.93336305 - samples/sec: 60.71 - lr: 0.100000
2021-05-28 01:14:07,788 epoch 9 - iter 15/16 - loss 0.90573179 - samples/sec: 59.70 - lr: 0.100000
2021-05-28 01:14:08,153 epoch 9 - iter 16/16 - loss 0.92431789 - samples/sec: 87.84 - lr: 0.100000
2021-05-28 01:14:08,154 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:08,154 EPOCH 9 done: loss 0.9243 - lr 0.1000000
2021-05-28 01:14:08,853 DEV : loss 0.39669275283813477 - score 0.8917
2021-05-28 01:14:08,865 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:14:18,014 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:18,529 epoch 10 - iter 1/16 - loss 0.65906501 - samples/sec: 62.22 - lr: 0.100000
2021-05-28 01:14:19,053 epoch 10 - iter 2/16 - loss 0.68519163 - samples/sec: 61.20 - lr: 0.100000
2021-05-28 01:14:19,586 epoch 10 - iter 3/16 - loss 0.71759303 - samples/sec: 60.05 - lr: 0.100000
2021-05-28 01:14:20,116 epoch 10 - iter 4/16 - loss 0.75915533 - samples/sec: 60.49 - lr: 0.100000
2021-05-28 01:14:20,650 epoch 10 - iter 5/16 - loss 0.77318511 - samples/sec: 59.94 - lr: 0.100000
2021-05-28 01:14:21,171 epoch 10 - iter 6/16 - loss 0.73468190 - samples/sec: 61.48 - lr: 0.100000
2021-05-28 01:14:21,691 epoch 10 - iter 7/16 - loss 0.66215285 - samples/sec: 61.64 - lr: 0.100000
2021-05-28 01:14:22,220 epoch 10 - iter 8/16 - loss 0.63527428 - samples/sec: 60.53 - lr: 0.100000
2021-05-28 01:14:22,730 epoch 10 - iter 9/16 - loss 0.59379450 - samples/sec: 62.83 - lr: 0.100000
2021-05-28 01:14:23,251 epoch 10 - iter 10/16 - loss 0.60702925 - samples/sec: 61.37 - lr: 0.100000
2021-05-28 01:14:23,775 epoch 10 - iter 11/16 - loss 0.57388060 - samples/sec: 61.20 - lr: 0.100000
2021-05-28 01:14:24,295 epoch 10 - iter 12/16 - loss 0.57882526 - samples/sec: 61.61 - lr: 0.100000
2021-05-28 01:14:24,816 epoch 10 - iter 13/16 - loss 0.60282610 - samples/sec: 61.45 - lr: 0.100000
2021-05-28 01:14:25,331 epoch 10 - iter 14/16 - loss 0.62479698 - samples/sec: 62.17 - lr: 0.100000
2021-05-28 01:14:25,858 epoch 10 - iter 15/16 - loss 0.67938360 - samples/sec: 60.77 - lr: 0.100000
2021-05-28 01:14:26,223 epoch 10 - iter 16/16 - loss 0.69206892 - samples/sec: 87.80 - lr: 0.100000
2021-05-28 01:14:26,223 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:26,224 EPOCH 10 done: loss 0.6921 - lr 0.1000000
2021-05-28 01:14:26,928 DEV : loss 0.6395488381385803 - score 0.7179
2021-05-28 01:14:26,940 BAD EPOCHS (no improvement): 1
2021-05-28 01:14:26,940 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:27,464 epoch 11 - iter 1/16 - loss 0.90659010 - samples/sec: 61.19 - lr: 0.100000
2021-05-28 01:14:28,005 epoch 11 - iter 2/16 - loss 0.99722415 - samples/sec: 59.22 - lr: 0.100000
2021-05-28 01:14:28,531 epoch 11 - iter 3/16 - loss 0.86844230 - samples/sec: 60.89 - lr: 0.100000
2021-05-28 01:14:29,057 epoch 11 - iter 4/16 - loss 0.84315354 - samples/sec: 60.89 - lr: 0.100000
2021-05-28 01:14:29,600 epoch 11 - iter 5/16 - loss 0.89468799 - samples/sec: 58.93 - lr: 0.100000
2021-05-28 01:14:30,137 epoch 11 - iter 6/16 - loss 0.93468698 - samples/sec: 59.68 - lr: 0.100000
2021-05-28 01:14:30,666 epoch 11 - iter 7/16 - loss 0.87435837 - samples/sec: 60.50 - lr: 0.100000
2021-05-28 01:14:31,198 epoch 11 - iter 8/16 - loss 0.82987716 - samples/sec: 60.23 - lr: 0.100000
2021-05-28 01:14:31,733 epoch 11 - iter 9/16 - loss 0.83239700 - samples/sec: 59.85 - lr: 0.100000
2021-05-28 01:14:32,265 epoch 11 - iter 10/16 - loss 0.82438404 - samples/sec: 60.20 - lr: 0.100000
2021-05-28 01:14:32,785 epoch 11 - iter 11/16 - loss 0.82589132 - samples/sec: 61.62 - lr: 0.100000
2021-05-28 01:14:33,303 epoch 11 - iter 12/16 - loss 0.78887203 - samples/sec: 61.90 - lr: 0.100000
2021-05-28 01:14:33,839 epoch 11 - iter 13/16 - loss 0.77620626 - samples/sec: 59.66 - lr: 0.100000
2021-05-28 01:14:34,483 epoch 11 - iter 14/16 - loss 0.74567248 - samples/sec: 49.75 - lr: 0.100000
2021-05-28 01:14:35,022 epoch 11 - iter 15/16 - loss 0.72782884 - samples/sec: 59.47 - lr: 0.100000
2021-05-28 01:14:35,394 epoch 11 - iter 16/16 - loss 0.70202274 - samples/sec: 85.95 - lr: 0.100000
2021-05-28 01:14:35,395 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:35,395 EPOCH 11 done: loss 0.7020 - lr 0.1000000
2021-05-28 01:14:36,099 DEV : loss 0.4794410467147827 - score 0.8485
2021-05-28 01:14:36,111 BAD EPOCHS (no improvement): 2
2021-05-28 01:14:36,111 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:36,632 epoch 12 - iter 1/16 - loss 1.63028502 - samples/sec: 61.49 - lr: 0.100000
2021-05-28 01:14:37,159 epoch 12 - iter 2/16 - loss 1.02192605 - samples/sec: 60.71 - lr: 0.100000
2021-05-28 01:14:37,663 epoch 12 - iter 3/16 - loss 1.04044497 - samples/sec: 63.59 - lr: 0.100000
2021-05-28 01:14:38,180 epoch 12 - iter 4/16 - loss 0.86194605 - samples/sec: 61.94 - lr: 0.100000
2021-05-28 01:14:38,721 epoch 12 - iter 5/16 - loss 0.80736413 - samples/sec: 59.20 - lr: 0.100000
2021-05-28 01:14:39,259 epoch 12 - iter 6/16 - loss 0.80049610 - samples/sec: 59.54 - lr: 0.100000
2021-05-28 01:14:39,801 epoch 12 - iter 7/16 - loss 0.79855353 - samples/sec: 59.14 - lr: 0.100000
2021-05-28 01:14:40,341 epoch 12 - iter 8/16 - loss 0.73529363 - samples/sec: 59.25 - lr: 0.100000
2021-05-28 01:14:40,879 epoch 12 - iter 9/16 - loss 0.68271955 - samples/sec: 59.57 - lr: 0.100000
2021-05-28 01:14:41,415 epoch 12 - iter 10/16 - loss 0.66097236 - samples/sec: 59.68 - lr: 0.100000
2021-05-28 01:14:41,948 epoch 12 - iter 11/16 - loss 0.66753242 - samples/sec: 60.14 - lr: 0.100000
2021-05-28 01:14:42,485 epoch 12 - iter 12/16 - loss 0.66106951 - samples/sec: 59.61 - lr: 0.100000
2021-05-28 01:14:43,021 epoch 12 - iter 13/16 - loss 0.66169830 - samples/sec: 59.80 - lr: 0.100000
2021-05-28 01:14:43,537 epoch 12 - iter 14/16 - loss 0.64422175 - samples/sec: 62.04 - lr: 0.100000
2021-05-28 01:14:44,067 epoch 12 - iter 15/16 - loss 0.63426754 - samples/sec: 60.43 - lr: 0.100000
2021-05-28 01:14:44,443 epoch 12 - iter 16/16 - loss 0.66468444 - samples/sec: 85.14 - lr: 0.100000
2021-05-28 01:14:44,444 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:44,444 EPOCH 12 done: loss 0.6647 - lr 0.1000000
2021-05-28 01:14:45,147 DEV : loss 0.49775445461273193 - score 0.8281
2021-05-28 01:14:45,159 BAD EPOCHS (no improvement): 3
2021-05-28 01:14:45,159 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:45,688 epoch 13 - iter 1/16 - loss 0.42987776 - samples/sec: 60.54 - lr: 0.100000
2021-05-28 01:14:46,219 epoch 13 - iter 2/16 - loss 0.58155751 - samples/sec: 60.32 - lr: 0.100000
2021-05-28 01:14:46,744 epoch 13 - iter 3/16 - loss 0.61418442 - samples/sec: 61.08 - lr: 0.100000
2021-05-28 01:14:47,269 epoch 13 - iter 4/16 - loss 0.59216571 - samples/sec: 60.93 - lr: 0.100000
2021-05-28 01:14:47,805 epoch 13 - iter 5/16 - loss 0.56633234 - samples/sec: 59.82 - lr: 0.100000
2021-05-28 01:14:48,341 epoch 13 - iter 6/16 - loss 0.55905501 - samples/sec: 59.67 - lr: 0.100000
2021-05-28 01:14:48,885 epoch 13 - iter 7/16 - loss 0.52764906 - samples/sec: 58.92 - lr: 0.100000
2021-05-28 01:14:49,415 epoch 13 - iter 8/16 - loss 0.52544080 - samples/sec: 60.37 - lr: 0.100000
2021-05-28 01:14:49,939 epoch 13 - iter 9/16 - loss 0.51406737 - samples/sec: 61.14 - lr: 0.100000
2021-05-28 01:14:50,473 epoch 13 - iter 10/16 - loss 0.52859133 - samples/sec: 59.98 - lr: 0.100000
2021-05-28 01:14:50,989 epoch 13 - iter 11/16 - loss 0.56259013 - samples/sec: 62.09 - lr: 0.100000
2021-05-28 01:14:51,514 epoch 13 - iter 12/16 - loss 0.63224718 - samples/sec: 61.05 - lr: 0.100000
2021-05-28 01:14:52,040 epoch 13 - iter 13/16 - loss 0.61844062 - samples/sec: 60.86 - lr: 0.100000
2021-05-28 01:14:52,582 epoch 13 - iter 14/16 - loss 0.61120277 - samples/sec: 59.05 - lr: 0.100000
2021-05-28 01:14:53,121 epoch 13 - iter 15/16 - loss 0.60216013 - samples/sec: 59.51 - lr: 0.100000
2021-05-28 01:14:53,489 epoch 13 - iter 16/16 - loss 0.63677698 - samples/sec: 86.96 - lr: 0.100000
2021-05-28 01:14:53,490 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:53,490 EPOCH 13 done: loss 0.6368 - lr 0.1000000
2021-05-28 01:14:54,195 DEV : loss 0.5663827061653137 - score 0.8324
Epoch    13: reducing learning rate of group 0 to 5.0000e-02.
2021-05-28 01:14:54,207 BAD EPOCHS (no improvement): 4
2021-05-28 01:14:54,207 ----------------------------------------------------------------------------------------------------
2021-05-28 01:14:54,707 epoch 14 - iter 1/16 - loss 0.32417905 - samples/sec: 64.03 - lr: 0.050000
2021-05-28 01:14:55,247 epoch 14 - iter 2/16 - loss 0.63045639 - samples/sec: 59.32 - lr: 0.050000
2021-05-28 01:14:55,775 epoch 14 - iter 3/16 - loss 0.50109551 - samples/sec: 60.62 - lr: 0.050000
2021-05-28 01:14:56,303 epoch 14 - iter 4/16 - loss 0.47241962 - samples/sec: 60.72 - lr: 0.050000
2021-05-28 01:14:56,832 epoch 14 - iter 5/16 - loss 0.43312426 - samples/sec: 60.47 - lr: 0.050000
2021-05-28 01:14:57,350 epoch 14 - iter 6/16 - loss 0.42636599 - samples/sec: 61.84 - lr: 0.050000
2021-05-28 01:14:57,872 epoch 14 - iter 7/16 - loss 0.38520981 - samples/sec: 61.33 - lr: 0.050000
2021-05-28 01:14:58,394 epoch 14 - iter 8/16 - loss 0.37126486 - samples/sec: 61.36 - lr: 0.050000
2021-05-28 01:14:58,923 epoch 14 - iter 9/16 - loss 0.40061538 - samples/sec: 60.55 - lr: 0.050000
2021-05-28 01:14:59,462 epoch 14 - iter 10/16 - loss 0.40427566 - samples/sec: 59.53 - lr: 0.050000
2021-05-28 01:14:59,999 epoch 14 - iter 11/16 - loss 0.41074227 - samples/sec: 59.62 - lr: 0.050000
2021-05-28 01:15:00,522 epoch 14 - iter 12/16 - loss 0.41104938 - samples/sec: 61.22 - lr: 0.050000
2021-05-28 01:15:01,058 epoch 14 - iter 13/16 - loss 0.39766273 - samples/sec: 59.80 - lr: 0.050000
2021-05-28 01:15:01,591 epoch 14 - iter 14/16 - loss 0.38433453 - samples/sec: 60.06 - lr: 0.050000
2021-05-28 01:15:02,127 epoch 14 - iter 15/16 - loss 0.39330562 - samples/sec: 59.78 - lr: 0.050000
2021-05-28 01:15:02,500 epoch 14 - iter 16/16 - loss 0.38613548 - samples/sec: 85.70 - lr: 0.050000
2021-05-28 01:15:02,501 ----------------------------------------------------------------------------------------------------
2021-05-28 01:15:02,501 EPOCH 14 done: loss 0.3861 - lr 0.0500000
2021-05-28 01:15:03,207 DEV : loss 0.3033037781715393 - score 0.8931
2021-05-28 01:15:03,219 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:15:12,503 ----------------------------------------------------------------------------------------------------
2021-05-28 01:15:13,036 epoch 15 - iter 1/16 - loss 0.17900324 - samples/sec: 60.23 - lr: 0.050000
2021-05-28 01:15:13,575 epoch 15 - iter 2/16 - loss 0.20178890 - samples/sec: 59.37 - lr: 0.050000
2021-05-28 01:15:14,107 epoch 15 - iter 3/16 - loss 0.25942643 - samples/sec: 60.19 - lr: 0.050000
2021-05-28 01:15:14,644 epoch 15 - iter 4/16 - loss 0.28066576 - samples/sec: 59.68 - lr: 0.050000
2021-05-28 01:15:15,180 epoch 15 - iter 5/16 - loss 0.32372065 - samples/sec: 59.81 - lr: 0.050000
2021-05-28 01:15:15,698 epoch 15 - iter 6/16 - loss 0.29572499 - samples/sec: 61.74 - lr: 0.050000
2021-05-28 01:15:16,204 epoch 15 - iter 7/16 - loss 0.30820778 - samples/sec: 63.30 - lr: 0.050000
2021-05-28 01:15:16,727 epoch 15 - iter 8/16 - loss 0.32598273 - samples/sec: 61.27 - lr: 0.050000
2021-05-28 01:15:17,265 epoch 15 - iter 9/16 - loss 0.32810239 - samples/sec: 59.51 - lr: 0.050000
2021-05-28 01:15:17,800 epoch 15 - iter 10/16 - loss 0.34676648 - samples/sec: 59.90 - lr: 0.050000
2021-05-28 01:15:18,331 epoch 15 - iter 11/16 - loss 0.36626544 - samples/sec: 60.34 - lr: 0.050000
2021-05-28 01:15:18,858 epoch 15 - iter 12/16 - loss 0.36331542 - samples/sec: 60.75 - lr: 0.050000
2021-05-28 01:15:19,381 epoch 15 - iter 13/16 - loss 0.36172650 - samples/sec: 61.22 - lr: 0.050000
2021-05-28 01:15:19,911 epoch 15 - iter 14/16 - loss 0.35228006 - samples/sec: 60.44 - lr: 0.050000
2021-05-28 01:15:20,445 epoch 15 - iter 15/16 - loss 0.35886754 - samples/sec: 60.03 - lr: 0.050000
2021-05-28 01:15:20,819 epoch 15 - iter 16/16 - loss 0.37636730 - samples/sec: 85.67 - lr: 0.050000
2021-05-28 01:15:20,819 ----------------------------------------------------------------------------------------------------
2021-05-28 01:15:20,819 EPOCH 15 done: loss 0.3764 - lr 0.0500000
2021-05-28 01:15:21,526 DEV : loss 0.25469914078712463 - score 0.9091
2021-05-28 01:15:21,537 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:15:31,025 ----------------------------------------------------------------------------------------------------
2021-05-28 01:15:31,562 epoch 16 - iter 1/16 - loss 0.30392504 - samples/sec: 59.62 - lr: 0.050000
2021-05-28 01:15:32,085 epoch 16 - iter 2/16 - loss 0.31346679 - samples/sec: 61.24 - lr: 0.050000
2021-05-28 01:15:32,625 epoch 16 - iter 3/16 - loss 0.29648558 - samples/sec: 59.33 - lr: 0.050000
2021-05-28 01:15:33,165 epoch 16 - iter 4/16 - loss 0.28433681 - samples/sec: 59.34 - lr: 0.050000
2021-05-28 01:15:33,681 epoch 16 - iter 5/16 - loss 0.28830686 - samples/sec: 62.01 - lr: 0.050000
2021-05-28 01:15:34,223 epoch 16 - iter 6/16 - loss 0.34948822 - samples/sec: 59.14 - lr: 0.050000
2021-05-28 01:15:34,756 epoch 16 - iter 7/16 - loss 0.35935317 - samples/sec: 60.08 - lr: 0.050000
2021-05-28 01:15:35,291 epoch 16 - iter 8/16 - loss 0.33270136 - samples/sec: 59.80 - lr: 0.050000
2021-05-28 01:15:35,820 epoch 16 - iter 9/16 - loss 0.33806636 - samples/sec: 60.65 - lr: 0.050000
2021-05-28 01:15:36,357 epoch 16 - iter 10/16 - loss 0.32690649 - samples/sec: 59.62 - lr: 0.050000
2021-05-28 01:15:36,888 epoch 16 - iter 11/16 - loss 0.31768142 - samples/sec: 60.28 - lr: 0.050000
2021-05-28 01:15:37,400 epoch 16 - iter 12/16 - loss 0.32102803 - samples/sec: 62.59 - lr: 0.050000
2021-05-28 01:15:37,936 epoch 16 - iter 13/16 - loss 0.31599477 - samples/sec: 59.70 - lr: 0.050000
2021-05-28 01:15:38,461 epoch 16 - iter 14/16 - loss 0.31606192 - samples/sec: 61.05 - lr: 0.050000
2021-05-28 01:15:38,989 epoch 16 - iter 15/16 - loss 0.31710235 - samples/sec: 60.66 - lr: 0.050000
2021-05-28 01:15:39,361 epoch 16 - iter 16/16 - loss 0.32334647 - samples/sec: 86.20 - lr: 0.050000
2021-05-28 01:15:39,361 ----------------------------------------------------------------------------------------------------
2021-05-28 01:15:39,361 EPOCH 16 done: loss 0.3233 - lr 0.0500000
2021-05-28 01:15:40,072 DEV : loss 0.2621403634548187 - score 0.9139
2021-05-28 01:15:40,084 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:15:49,557 ----------------------------------------------------------------------------------------------------
2021-05-28 01:15:50,089 epoch 17 - iter 1/16 - loss 0.41262770 - samples/sec: 60.26 - lr: 0.050000
2021-05-28 01:15:50,623 epoch 17 - iter 2/16 - loss 0.36068782 - samples/sec: 59.93 - lr: 0.050000
2021-05-28 01:15:51,153 epoch 17 - iter 3/16 - loss 0.28654907 - samples/sec: 60.43 - lr: 0.050000
2021-05-28 01:15:51,693 epoch 17 - iter 4/16 - loss 0.30560432 - samples/sec: 59.28 - lr: 0.050000
2021-05-28 01:15:52,221 epoch 17 - iter 5/16 - loss 0.28114675 - samples/sec: 60.76 - lr: 0.050000
2021-05-28 01:15:52,754 epoch 17 - iter 6/16 - loss 0.25210535 - samples/sec: 60.11 - lr: 0.050000
2021-05-28 01:15:53,294 epoch 17 - iter 7/16 - loss 0.23736643 - samples/sec: 59.29 - lr: 0.050000
2021-05-28 01:15:53,819 epoch 17 - iter 8/16 - loss 0.25752658 - samples/sec: 61.02 - lr: 0.050000
2021-05-28 01:15:54,358 epoch 17 - iter 9/16 - loss 0.28392357 - samples/sec: 59.41 - lr: 0.050000
2021-05-28 01:15:54,880 epoch 17 - iter 10/16 - loss 0.28604599 - samples/sec: 61.28 - lr: 0.050000
2021-05-28 01:15:55,409 epoch 17 - iter 11/16 - loss 0.28694154 - samples/sec: 60.64 - lr: 0.050000
2021-05-28 01:15:55,945 epoch 17 - iter 12/16 - loss 0.28823235 - samples/sec: 59.69 - lr: 0.050000
2021-05-28 01:15:56,470 epoch 17 - iter 13/16 - loss 0.30646442 - samples/sec: 60.97 - lr: 0.050000
2021-05-28 01:15:56,994 epoch 17 - iter 14/16 - loss 0.29898016 - samples/sec: 61.18 - lr: 0.050000
2021-05-28 01:15:57,519 epoch 17 - iter 15/16 - loss 0.29115110 - samples/sec: 60.97 - lr: 0.050000
2021-05-28 01:15:57,896 epoch 17 - iter 16/16 - loss 0.28946408 - samples/sec: 85.06 - lr: 0.050000
2021-05-28 01:15:57,896 ----------------------------------------------------------------------------------------------------
2021-05-28 01:15:57,896 EPOCH 17 done: loss 0.2895 - lr 0.0500000
2021-05-28 01:15:58,601 DEV : loss 0.32098057866096497 - score 0.8944
2021-05-28 01:15:58,613 BAD EPOCHS (no improvement): 1
2021-05-28 01:15:58,613 ----------------------------------------------------------------------------------------------------
2021-05-28 01:15:59,141 epoch 18 - iter 1/16 - loss 0.21337235 - samples/sec: 60.72 - lr: 0.050000
2021-05-28 01:15:59,678 epoch 18 - iter 2/16 - loss 0.32462603 - samples/sec: 59.56 - lr: 0.050000
2021-05-28 01:16:00,200 epoch 18 - iter 3/16 - loss 0.29905571 - samples/sec: 61.44 - lr: 0.050000
2021-05-28 01:16:00,725 epoch 18 - iter 4/16 - loss 0.27815736 - samples/sec: 60.94 - lr: 0.050000
2021-05-28 01:16:01,251 epoch 18 - iter 5/16 - loss 0.25462638 - samples/sec: 60.93 - lr: 0.050000
2021-05-28 01:16:01,777 epoch 18 - iter 6/16 - loss 0.26410960 - samples/sec: 60.91 - lr: 0.050000
2021-05-28 01:16:02,314 epoch 18 - iter 7/16 - loss 0.25543981 - samples/sec: 59.62 - lr: 0.050000
2021-05-28 01:16:02,853 epoch 18 - iter 8/16 - loss 0.25229828 - samples/sec: 59.39 - lr: 0.050000
2021-05-28 01:16:03,392 epoch 18 - iter 9/16 - loss 0.26631317 - samples/sec: 59.45 - lr: 0.050000
2021-05-28 01:16:03,931 epoch 18 - iter 10/16 - loss 0.26853684 - samples/sec: 59.47 - lr: 0.050000
2021-05-28 01:16:04,469 epoch 18 - iter 11/16 - loss 0.29047926 - samples/sec: 59.50 - lr: 0.050000
2021-05-28 01:16:04,995 epoch 18 - iter 12/16 - loss 0.29158230 - samples/sec: 60.87 - lr: 0.050000
2021-05-28 01:16:05,500 epoch 18 - iter 13/16 - loss 0.31329343 - samples/sec: 63.50 - lr: 0.050000
2021-05-28 01:16:06,037 epoch 18 - iter 14/16 - loss 0.33081936 - samples/sec: 59.61 - lr: 0.050000
2021-05-28 01:16:06,572 epoch 18 - iter 15/16 - loss 0.33136812 - samples/sec: 59.83 - lr: 0.050000
2021-05-28 01:16:06,932 epoch 18 - iter 16/16 - loss 0.33152748 - samples/sec: 89.01 - lr: 0.050000
2021-05-28 01:16:06,933 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:06,933 EPOCH 18 done: loss 0.3315 - lr 0.0500000
2021-05-28 01:16:07,637 DEV : loss 0.26763656735420227 - score 0.9139
2021-05-28 01:16:07,649 BAD EPOCHS (no improvement): 2
2021-05-28 01:16:07,649 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:08,166 epoch 19 - iter 1/16 - loss 0.27928019 - samples/sec: 61.94 - lr: 0.050000
2021-05-28 01:16:08,691 epoch 19 - iter 2/16 - loss 0.31747374 - samples/sec: 61.02 - lr: 0.050000
2021-05-28 01:16:09,216 epoch 19 - iter 3/16 - loss 0.27305629 - samples/sec: 60.96 - lr: 0.050000
2021-05-28 01:16:09,746 epoch 19 - iter 4/16 - loss 0.30174519 - samples/sec: 60.46 - lr: 0.050000
2021-05-28 01:16:10,285 epoch 19 - iter 5/16 - loss 0.37842003 - samples/sec: 59.41 - lr: 0.050000
2021-05-28 01:16:10,827 epoch 19 - iter 6/16 - loss 0.37457026 - samples/sec: 59.13 - lr: 0.050000
2021-05-28 01:16:11,343 epoch 19 - iter 7/16 - loss 0.34887887 - samples/sec: 62.08 - lr: 0.050000
2021-05-28 01:16:11,849 epoch 19 - iter 8/16 - loss 0.33877691 - samples/sec: 63.30 - lr: 0.050000
2021-05-28 01:16:12,390 epoch 19 - iter 9/16 - loss 0.33109947 - samples/sec: 59.18 - lr: 0.050000
2021-05-28 01:16:12,925 epoch 19 - iter 10/16 - loss 0.32992965 - samples/sec: 59.83 - lr: 0.050000
2021-05-28 01:16:13,449 epoch 19 - iter 11/16 - loss 0.31905541 - samples/sec: 61.15 - lr: 0.050000
2021-05-28 01:16:13,981 epoch 19 - iter 12/16 - loss 0.31591805 - samples/sec: 60.23 - lr: 0.050000
2021-05-28 01:16:14,516 epoch 19 - iter 13/16 - loss 0.30165214 - samples/sec: 59.87 - lr: 0.050000
2021-05-28 01:16:15,059 epoch 19 - iter 14/16 - loss 0.30034106 - samples/sec: 58.93 - lr: 0.050000
2021-05-28 01:16:15,597 epoch 19 - iter 15/16 - loss 0.28788036 - samples/sec: 59.54 - lr: 0.050000
2021-05-28 01:16:15,963 epoch 19 - iter 16/16 - loss 0.28031368 - samples/sec: 87.72 - lr: 0.050000
2021-05-28 01:16:15,963 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:15,963 EPOCH 19 done: loss 0.2803 - lr 0.0500000
2021-05-28 01:16:16,669 DEV : loss 0.3007677495479584 - score 0.9
2021-05-28 01:16:16,681 BAD EPOCHS (no improvement): 3
2021-05-28 01:16:16,681 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:17,204 epoch 20 - iter 1/16 - loss 0.12735796 - samples/sec: 61.22 - lr: 0.050000
2021-05-28 01:16:17,744 epoch 20 - iter 2/16 - loss 0.13805723 - samples/sec: 59.25 - lr: 0.050000
2021-05-28 01:16:18,275 epoch 20 - iter 3/16 - loss 0.19739744 - samples/sec: 60.33 - lr: 0.050000
2021-05-28 01:16:18,817 epoch 20 - iter 4/16 - loss 0.20748500 - samples/sec: 59.12 - lr: 0.050000
2021-05-28 01:16:19,355 epoch 20 - iter 5/16 - loss 0.28545926 - samples/sec: 59.58 - lr: 0.050000
2021-05-28 01:16:19,888 epoch 20 - iter 6/16 - loss 0.36195153 - samples/sec: 60.06 - lr: 0.050000
2021-05-28 01:16:20,418 epoch 20 - iter 7/16 - loss 0.34413728 - samples/sec: 60.46 - lr: 0.050000
2021-05-28 01:16:20,953 epoch 20 - iter 8/16 - loss 0.31648259 - samples/sec: 59.79 - lr: 0.050000
2021-05-28 01:16:21,482 epoch 20 - iter 9/16 - loss 0.30270788 - samples/sec: 60.65 - lr: 0.050000
2021-05-28 01:16:22,006 epoch 20 - iter 10/16 - loss 0.29121186 - samples/sec: 61.07 - lr: 0.050000
2021-05-28 01:16:22,533 epoch 20 - iter 11/16 - loss 0.29638563 - samples/sec: 60.79 - lr: 0.050000
2021-05-28 01:16:23,074 epoch 20 - iter 12/16 - loss 0.27665965 - samples/sec: 59.21 - lr: 0.050000
2021-05-28 01:16:23,615 epoch 20 - iter 13/16 - loss 0.27139634 - samples/sec: 59.13 - lr: 0.050000
2021-05-28 01:16:24,124 epoch 20 - iter 14/16 - loss 0.27037033 - samples/sec: 62.96 - lr: 0.050000
2021-05-28 01:16:24,655 epoch 20 - iter 15/16 - loss 0.27245832 - samples/sec: 60.31 - lr: 0.050000
2021-05-28 01:16:25,017 epoch 20 - iter 16/16 - loss 0.26369624 - samples/sec: 88.67 - lr: 0.050000
2021-05-28 01:16:25,017 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:25,017 EPOCH 20 done: loss 0.2637 - lr 0.0500000
2021-05-28 01:16:25,837 DEV : loss 0.22714635729789734 - score 0.9342
2021-05-28 01:16:25,849 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:16:35,324 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:35,858 epoch 21 - iter 1/16 - loss 0.25114393 - samples/sec: 60.01 - lr: 0.050000
2021-05-28 01:16:36,396 epoch 21 - iter 2/16 - loss 0.27106738 - samples/sec: 59.51 - lr: 0.050000
2021-05-28 01:16:36,932 epoch 21 - iter 3/16 - loss 0.24586121 - samples/sec: 59.71 - lr: 0.050000
2021-05-28 01:16:37,453 epoch 21 - iter 4/16 - loss 0.21720875 - samples/sec: 61.55 - lr: 0.050000
2021-05-28 01:16:37,990 epoch 21 - iter 5/16 - loss 0.23801785 - samples/sec: 59.61 - lr: 0.050000
2021-05-28 01:16:38,501 epoch 21 - iter 6/16 - loss 0.24261460 - samples/sec: 62.69 - lr: 0.050000
2021-05-28 01:16:39,021 epoch 21 - iter 7/16 - loss 0.24332802 - samples/sec: 61.58 - lr: 0.050000
2021-05-28 01:16:39,560 epoch 21 - iter 8/16 - loss 0.23745292 - samples/sec: 59.49 - lr: 0.050000
2021-05-28 01:16:40,088 epoch 21 - iter 9/16 - loss 0.23010336 - samples/sec: 60.63 - lr: 0.050000
2021-05-28 01:16:40,621 epoch 21 - iter 10/16 - loss 0.21984853 - samples/sec: 60.13 - lr: 0.050000
2021-05-28 01:16:41,157 epoch 21 - iter 11/16 - loss 0.22738756 - samples/sec: 59.71 - lr: 0.050000
2021-05-28 01:16:41,684 epoch 21 - iter 12/16 - loss 0.22601725 - samples/sec: 60.80 - lr: 0.050000
2021-05-28 01:16:42,222 epoch 21 - iter 13/16 - loss 0.23154326 - samples/sec: 59.51 - lr: 0.050000
2021-05-28 01:16:42,749 epoch 21 - iter 14/16 - loss 0.24569045 - samples/sec: 60.76 - lr: 0.050000
2021-05-28 01:16:43,273 epoch 21 - iter 15/16 - loss 0.24508025 - samples/sec: 61.19 - lr: 0.050000
2021-05-28 01:16:43,643 epoch 21 - iter 16/16 - loss 0.24978835 - samples/sec: 86.58 - lr: 0.050000
2021-05-28 01:16:43,643 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:43,643 EPOCH 21 done: loss 0.2498 - lr 0.0500000
2021-05-28 01:16:44,350 DEV : loss 0.5030834674835205 - score 0.8571
2021-05-28 01:16:44,362 BAD EPOCHS (no improvement): 1
2021-05-28 01:16:44,362 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:44,893 epoch 22 - iter 1/16 - loss 0.26187706 - samples/sec: 60.28 - lr: 0.050000
2021-05-28 01:16:45,417 epoch 22 - iter 2/16 - loss 0.26449460 - samples/sec: 61.17 - lr: 0.050000
2021-05-28 01:16:45,957 epoch 22 - iter 3/16 - loss 0.26773703 - samples/sec: 59.34 - lr: 0.050000
2021-05-28 01:16:46,497 epoch 22 - iter 4/16 - loss 0.25903735 - samples/sec: 59.34 - lr: 0.050000
2021-05-28 01:16:47,025 epoch 22 - iter 5/16 - loss 0.28321137 - samples/sec: 60.57 - lr: 0.050000
2021-05-28 01:16:47,567 epoch 22 - iter 6/16 - loss 0.26784853 - samples/sec: 59.15 - lr: 0.050000
2021-05-28 01:16:48,088 epoch 22 - iter 7/16 - loss 0.24401896 - samples/sec: 61.43 - lr: 0.050000
2021-05-28 01:16:48,627 epoch 22 - iter 8/16 - loss 0.23053014 - samples/sec: 59.42 - lr: 0.050000
2021-05-28 01:16:49,154 epoch 22 - iter 9/16 - loss 0.21960106 - samples/sec: 60.83 - lr: 0.050000
2021-05-28 01:16:49,680 epoch 22 - iter 10/16 - loss 0.21601274 - samples/sec: 60.87 - lr: 0.050000
2021-05-28 01:16:50,217 epoch 22 - iter 11/16 - loss 0.22047257 - samples/sec: 59.68 - lr: 0.050000
2021-05-28 01:16:50,732 epoch 22 - iter 12/16 - loss 0.21580094 - samples/sec: 62.10 - lr: 0.050000
2021-05-28 01:16:51,257 epoch 22 - iter 13/16 - loss 0.21440626 - samples/sec: 61.11 - lr: 0.050000
2021-05-28 01:16:51,785 epoch 22 - iter 14/16 - loss 0.20758266 - samples/sec: 60.63 - lr: 0.050000
2021-05-28 01:16:52,322 epoch 22 - iter 15/16 - loss 0.19842082 - samples/sec: 59.65 - lr: 0.050000
2021-05-28 01:16:52,689 epoch 22 - iter 16/16 - loss 0.20121233 - samples/sec: 87.31 - lr: 0.050000
2021-05-28 01:16:52,689 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:52,689 EPOCH 22 done: loss 0.2012 - lr 0.0500000
2021-05-28 01:16:53,396 DEV : loss 0.22356754541397095 - score 0.9315
2021-05-28 01:16:53,408 BAD EPOCHS (no improvement): 2
2021-05-28 01:16:53,408 ----------------------------------------------------------------------------------------------------
2021-05-28 01:16:53,921 epoch 23 - iter 1/16 - loss 0.19439477 - samples/sec: 62.34 - lr: 0.050000
2021-05-28 01:16:54,459 epoch 23 - iter 2/16 - loss 0.16378698 - samples/sec: 59.58 - lr: 0.050000
2021-05-28 01:16:54,998 epoch 23 - iter 3/16 - loss 0.14747578 - samples/sec: 59.48 - lr: 0.050000
2021-05-28 01:16:55,527 epoch 23 - iter 4/16 - loss 0.15154064 - samples/sec: 60.52 - lr: 0.050000
2021-05-28 01:16:56,057 epoch 23 - iter 5/16 - loss 0.14336742 - samples/sec: 60.45 - lr: 0.050000
2021-05-28 01:16:56,598 epoch 23 - iter 6/16 - loss 0.14585283 - samples/sec: 59.19 - lr: 0.050000
2021-05-28 01:16:57,124 epoch 23 - iter 7/16 - loss 0.17104008 - samples/sec: 60.82 - lr: 0.050000
2021-05-28 01:16:57,659 epoch 23 - iter 8/16 - loss 0.18513503 - samples/sec: 59.93 - lr: 0.050000
2021-05-28 01:16:58,187 epoch 23 - iter 9/16 - loss 0.19023687 - samples/sec: 60.62 - lr: 0.050000
2021-05-28 01:16:58,713 epoch 23 - iter 10/16 - loss 0.19782842 - samples/sec: 60.95 - lr: 0.050000
2021-05-28 01:16:59,227 epoch 23 - iter 11/16 - loss 0.19475562 - samples/sec: 62.30 - lr: 0.050000
2021-05-28 01:16:59,766 epoch 23 - iter 12/16 - loss 0.18819418 - samples/sec: 59.42 - lr: 0.050000
2021-05-28 01:17:00,296 epoch 23 - iter 13/16 - loss 0.19177061 - samples/sec: 60.45 - lr: 0.050000
2021-05-28 01:17:00,820 epoch 23 - iter 14/16 - loss 0.19867801 - samples/sec: 61.04 - lr: 0.050000
2021-05-28 01:17:01,360 epoch 23 - iter 15/16 - loss 0.21337563 - samples/sec: 59.36 - lr: 0.050000
2021-05-28 01:17:01,726 epoch 23 - iter 16/16 - loss 0.21543504 - samples/sec: 87.62 - lr: 0.050000
2021-05-28 01:17:01,726 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:01,726 EPOCH 23 done: loss 0.2154 - lr 0.0500000
2021-05-28 01:17:02,432 DEV : loss 0.23228411376476288 - score 0.9172
2021-05-28 01:17:02,444 BAD EPOCHS (no improvement): 3
2021-05-28 01:17:02,444 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:02,967 epoch 24 - iter 1/16 - loss 0.15368631 - samples/sec: 61.26 - lr: 0.050000
2021-05-28 01:17:03,507 epoch 24 - iter 2/16 - loss 0.12438764 - samples/sec: 59.32 - lr: 0.050000
2021-05-28 01:17:04,019 epoch 24 - iter 3/16 - loss 0.20311689 - samples/sec: 62.56 - lr: 0.050000
2021-05-28 01:17:04,549 epoch 24 - iter 4/16 - loss 0.21592350 - samples/sec: 60.41 - lr: 0.050000
2021-05-28 01:17:05,089 epoch 24 - iter 5/16 - loss 0.20442101 - samples/sec: 59.33 - lr: 0.050000
2021-05-28 01:17:05,621 epoch 24 - iter 6/16 - loss 0.18052118 - samples/sec: 60.17 - lr: 0.050000
2021-05-28 01:17:06,146 epoch 24 - iter 7/16 - loss 0.21493180 - samples/sec: 61.07 - lr: 0.050000
2021-05-28 01:17:06,674 epoch 24 - iter 8/16 - loss 0.22790579 - samples/sec: 60.65 - lr: 0.050000
2021-05-28 01:17:07,201 epoch 24 - iter 9/16 - loss 0.22437679 - samples/sec: 60.80 - lr: 0.050000
2021-05-28 01:17:07,743 epoch 24 - iter 10/16 - loss 0.22991815 - samples/sec: 59.07 - lr: 0.050000
2021-05-28 01:17:08,283 epoch 24 - iter 11/16 - loss 0.23544091 - samples/sec: 59.31 - lr: 0.050000
2021-05-28 01:17:08,817 epoch 24 - iter 12/16 - loss 0.23049780 - samples/sec: 59.98 - lr: 0.050000
2021-05-28 01:17:09,334 epoch 24 - iter 13/16 - loss 0.22118551 - samples/sec: 61.94 - lr: 0.050000
2021-05-28 01:17:09,849 epoch 24 - iter 14/16 - loss 0.21359378 - samples/sec: 62.17 - lr: 0.050000
2021-05-28 01:17:10,386 epoch 24 - iter 15/16 - loss 0.20423866 - samples/sec: 59.63 - lr: 0.050000
2021-05-28 01:17:10,762 epoch 24 - iter 16/16 - loss 0.19928774 - samples/sec: 85.25 - lr: 0.050000
2021-05-28 01:17:10,763 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:10,763 EPOCH 24 done: loss 0.1993 - lr 0.0500000
2021-05-28 01:17:11,469 DEV : loss 0.2596296966075897 - score 0.9
Epoch    24: reducing learning rate of group 0 to 2.5000e-02.
2021-05-28 01:17:11,481 BAD EPOCHS (no improvement): 4
2021-05-28 01:17:11,481 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:12,016 epoch 25 - iter 1/16 - loss 0.38166046 - samples/sec: 59.94 - lr: 0.025000
2021-05-28 01:17:12,543 epoch 25 - iter 2/16 - loss 0.21585435 - samples/sec: 60.70 - lr: 0.025000
2021-05-28 01:17:13,069 epoch 25 - iter 3/16 - loss 0.18778042 - samples/sec: 60.91 - lr: 0.025000
2021-05-28 01:17:13,598 epoch 25 - iter 4/16 - loss 0.17535571 - samples/sec: 60.51 - lr: 0.025000
2021-05-28 01:17:14,131 epoch 25 - iter 5/16 - loss 0.22798331 - samples/sec: 60.11 - lr: 0.025000
2021-05-28 01:17:14,658 epoch 25 - iter 6/16 - loss 0.20187460 - samples/sec: 60.85 - lr: 0.025000
2021-05-28 01:17:15,192 epoch 25 - iter 7/16 - loss 0.28937648 - samples/sec: 59.96 - lr: 0.025000
2021-05-28 01:17:15,728 epoch 25 - iter 8/16 - loss 0.26882674 - samples/sec: 59.78 - lr: 0.025000
2021-05-28 01:17:16,380 epoch 25 - iter 9/16 - loss 0.26782777 - samples/sec: 49.10 - lr: 0.025000
2021-05-28 01:17:16,884 epoch 25 - iter 10/16 - loss 0.27114523 - samples/sec: 63.58 - lr: 0.025000
2021-05-28 01:17:17,407 epoch 25 - iter 11/16 - loss 0.27205745 - samples/sec: 61.15 - lr: 0.025000
2021-05-28 01:17:17,941 epoch 25 - iter 12/16 - loss 0.26049403 - samples/sec: 60.02 - lr: 0.025000
2021-05-28 01:17:18,468 epoch 25 - iter 13/16 - loss 0.25551621 - samples/sec: 60.73 - lr: 0.025000
2021-05-28 01:17:19,005 epoch 25 - iter 14/16 - loss 0.24662550 - samples/sec: 59.73 - lr: 0.025000
2021-05-28 01:17:19,530 epoch 25 - iter 15/16 - loss 0.23859370 - samples/sec: 60.98 - lr: 0.025000
2021-05-28 01:17:19,897 epoch 25 - iter 16/16 - loss 0.23105290 - samples/sec: 87.30 - lr: 0.025000
2021-05-28 01:17:19,897 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:19,897 EPOCH 25 done: loss 0.2311 - lr 0.0250000
2021-05-28 01:17:20,603 DEV : loss 0.34155741333961487 - score 0.8902
2021-05-28 01:17:20,614 BAD EPOCHS (no improvement): 1
2021-05-28 01:17:20,615 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:21,131 epoch 26 - iter 1/16 - loss 0.16918421 - samples/sec: 61.96 - lr: 0.025000
2021-05-28 01:17:21,659 epoch 26 - iter 2/16 - loss 0.13816553 - samples/sec: 60.76 - lr: 0.025000
2021-05-28 01:17:22,187 epoch 26 - iter 3/16 - loss 0.27250906 - samples/sec: 60.56 - lr: 0.025000
2021-05-28 01:17:22,721 epoch 26 - iter 4/16 - loss 0.24281701 - samples/sec: 60.02 - lr: 0.025000
2021-05-28 01:17:23,256 epoch 26 - iter 5/16 - loss 0.22012641 - samples/sec: 59.91 - lr: 0.025000
2021-05-28 01:17:23,794 epoch 26 - iter 6/16 - loss 0.20337119 - samples/sec: 59.48 - lr: 0.025000
2021-05-28 01:17:24,307 epoch 26 - iter 7/16 - loss 0.20608129 - samples/sec: 62.52 - lr: 0.025000
2021-05-28 01:17:24,844 epoch 26 - iter 8/16 - loss 0.18410036 - samples/sec: 59.62 - lr: 0.025000
2021-05-28 01:17:25,368 epoch 26 - iter 9/16 - loss 0.17528817 - samples/sec: 61.08 - lr: 0.025000
2021-05-28 01:17:25,908 epoch 26 - iter 10/16 - loss 0.18964393 - samples/sec: 59.28 - lr: 0.025000
2021-05-28 01:17:26,432 epoch 26 - iter 11/16 - loss 0.18960832 - samples/sec: 61.18 - lr: 0.025000
2021-05-28 01:17:26,966 epoch 26 - iter 12/16 - loss 0.19352262 - samples/sec: 60.01 - lr: 0.025000
2021-05-28 01:17:27,507 epoch 26 - iter 13/16 - loss 0.18489977 - samples/sec: 59.20 - lr: 0.025000
2021-05-28 01:17:28,029 epoch 26 - iter 14/16 - loss 0.19103445 - samples/sec: 61.35 - lr: 0.025000
2021-05-28 01:17:28,558 epoch 26 - iter 15/16 - loss 0.18481916 - samples/sec: 60.54 - lr: 0.025000
2021-05-28 01:17:28,936 epoch 26 - iter 16/16 - loss 0.18550456 - samples/sec: 84.76 - lr: 0.025000
2021-05-28 01:17:28,936 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:28,937 EPOCH 26 done: loss 0.1855 - lr 0.0250000
2021-05-28 01:17:29,641 DEV : loss 0.35563546419143677 - score 0.8902
2021-05-28 01:17:29,653 BAD EPOCHS (no improvement): 2
2021-05-28 01:17:29,653 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:30,181 epoch 27 - iter 1/16 - loss 0.16204357 - samples/sec: 60.69 - lr: 0.025000
2021-05-28 01:17:30,717 epoch 27 - iter 2/16 - loss 0.16320729 - samples/sec: 59.71 - lr: 0.025000
2021-05-28 01:17:31,245 epoch 27 - iter 3/16 - loss 0.17063936 - samples/sec: 60.67 - lr: 0.025000
2021-05-28 01:17:31,783 epoch 27 - iter 4/16 - loss 0.21861375 - samples/sec: 59.52 - lr: 0.025000
2021-05-28 01:17:32,326 epoch 27 - iter 5/16 - loss 0.20143004 - samples/sec: 59.07 - lr: 0.025000
2021-05-28 01:17:32,846 epoch 27 - iter 6/16 - loss 0.17713781 - samples/sec: 61.48 - lr: 0.025000
2021-05-28 01:17:33,384 epoch 27 - iter 7/16 - loss 0.17813482 - samples/sec: 59.63 - lr: 0.025000
2021-05-28 01:17:33,901 epoch 27 - iter 8/16 - loss 0.16238122 - samples/sec: 61.90 - lr: 0.025000
2021-05-28 01:17:34,420 epoch 27 - iter 9/16 - loss 0.15455081 - samples/sec: 61.73 - lr: 0.025000
2021-05-28 01:17:34,948 epoch 27 - iter 10/16 - loss 0.14841408 - samples/sec: 60.60 - lr: 0.025000
2021-05-28 01:17:35,481 epoch 27 - iter 11/16 - loss 0.15604508 - samples/sec: 60.16 - lr: 0.025000
2021-05-28 01:17:35,996 epoch 27 - iter 12/16 - loss 0.15400787 - samples/sec: 62.16 - lr: 0.025000
2021-05-28 01:17:36,536 epoch 27 - iter 13/16 - loss 0.16278751 - samples/sec: 59.30 - lr: 0.025000
2021-05-28 01:17:37,068 epoch 27 - iter 14/16 - loss 0.16784981 - samples/sec: 60.23 - lr: 0.025000
2021-05-28 01:17:37,597 epoch 27 - iter 15/16 - loss 0.16510292 - samples/sec: 60.58 - lr: 0.025000
2021-05-28 01:17:37,968 epoch 27 - iter 16/16 - loss 0.16469062 - samples/sec: 86.30 - lr: 0.025000
2021-05-28 01:17:37,968 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:37,968 EPOCH 27 done: loss 0.1647 - lr 0.0250000
2021-05-28 01:17:38,678 DEV : loss 0.5308961272239685 - score 0.8488
2021-05-28 01:17:38,689 BAD EPOCHS (no improvement): 3
2021-05-28 01:17:38,690 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:39,214 epoch 28 - iter 1/16 - loss 0.13528299 - samples/sec: 61.12 - lr: 0.025000
2021-05-28 01:17:39,756 epoch 28 - iter 2/16 - loss 0.14264441 - samples/sec: 59.09 - lr: 0.025000
2021-05-28 01:17:40,283 epoch 28 - iter 3/16 - loss 0.17208801 - samples/sec: 60.70 - lr: 0.025000
2021-05-28 01:17:40,821 epoch 28 - iter 4/16 - loss 0.14930786 - samples/sec: 59.61 - lr: 0.025000
2021-05-28 01:17:41,356 epoch 28 - iter 5/16 - loss 0.15872661 - samples/sec: 59.79 - lr: 0.025000
2021-05-28 01:17:41,900 epoch 28 - iter 6/16 - loss 0.17542498 - samples/sec: 58.96 - lr: 0.025000
2021-05-28 01:17:42,413 epoch 28 - iter 7/16 - loss 0.18836262 - samples/sec: 62.42 - lr: 0.025000
2021-05-28 01:17:42,925 epoch 28 - iter 8/16 - loss 0.21460062 - samples/sec: 62.55 - lr: 0.025000
2021-05-28 01:17:43,466 epoch 28 - iter 9/16 - loss 0.24646186 - samples/sec: 59.22 - lr: 0.025000
2021-05-28 01:17:43,988 epoch 28 - iter 10/16 - loss 0.23608880 - samples/sec: 61.31 - lr: 0.025000
2021-05-28 01:17:44,517 epoch 28 - iter 11/16 - loss 0.22658996 - samples/sec: 60.57 - lr: 0.025000
2021-05-28 01:17:45,049 epoch 28 - iter 12/16 - loss 0.21757419 - samples/sec: 60.13 - lr: 0.025000
2021-05-28 01:17:45,586 epoch 28 - iter 13/16 - loss 0.21079293 - samples/sec: 59.68 - lr: 0.025000
2021-05-28 01:17:46,131 epoch 28 - iter 14/16 - loss 0.20659793 - samples/sec: 58.75 - lr: 0.025000
2021-05-28 01:17:46,664 epoch 28 - iter 15/16 - loss 0.19623048 - samples/sec: 60.16 - lr: 0.025000
2021-05-28 01:17:47,027 epoch 28 - iter 16/16 - loss 0.19623529 - samples/sec: 88.31 - lr: 0.025000
2021-05-28 01:17:47,027 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:47,027 EPOCH 28 done: loss 0.1962 - lr 0.0250000
2021-05-28 01:17:47,732 DEV : loss 0.18970920145511627 - score 0.9396
2021-05-28 01:17:47,744 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:17:57,130 ----------------------------------------------------------------------------------------------------
2021-05-28 01:17:57,654 epoch 29 - iter 1/16 - loss 0.24206483 - samples/sec: 61.06 - lr: 0.025000
2021-05-28 01:17:58,178 epoch 29 - iter 2/16 - loss 0.33595026 - samples/sec: 61.13 - lr: 0.025000
2021-05-28 01:17:58,719 epoch 29 - iter 3/16 - loss 0.24825533 - samples/sec: 59.29 - lr: 0.025000
2021-05-28 01:17:59,256 epoch 29 - iter 4/16 - loss 0.21607965 - samples/sec: 59.56 - lr: 0.025000
2021-05-28 01:17:59,789 epoch 29 - iter 5/16 - loss 0.19376330 - samples/sec: 60.12 - lr: 0.025000
2021-05-28 01:18:00,316 epoch 29 - iter 6/16 - loss 0.17586303 - samples/sec: 60.80 - lr: 0.025000
2021-05-28 01:18:00,847 epoch 29 - iter 7/16 - loss 0.16850713 - samples/sec: 60.27 - lr: 0.025000
2021-05-28 01:18:01,385 epoch 29 - iter 8/16 - loss 0.16831580 - samples/sec: 59.61 - lr: 0.025000
2021-05-28 01:18:01,911 epoch 29 - iter 9/16 - loss 0.17114138 - samples/sec: 60.92 - lr: 0.025000
2021-05-28 01:18:02,440 epoch 29 - iter 10/16 - loss 0.17513453 - samples/sec: 60.52 - lr: 0.025000
2021-05-28 01:18:02,985 epoch 29 - iter 11/16 - loss 0.17201005 - samples/sec: 58.77 - lr: 0.025000
2021-05-28 01:18:03,510 epoch 29 - iter 12/16 - loss 0.16508919 - samples/sec: 60.99 - lr: 0.025000
2021-05-28 01:18:04,046 epoch 29 - iter 13/16 - loss 0.15778503 - samples/sec: 59.80 - lr: 0.025000
2021-05-28 01:18:04,565 epoch 29 - iter 14/16 - loss 0.15857053 - samples/sec: 61.69 - lr: 0.025000
2021-05-28 01:18:05,104 epoch 29 - iter 15/16 - loss 0.15084734 - samples/sec: 59.41 - lr: 0.025000
2021-05-28 01:18:05,460 epoch 29 - iter 16/16 - loss 0.14774997 - samples/sec: 89.91 - lr: 0.025000
2021-05-28 01:18:05,461 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:05,461 EPOCH 29 done: loss 0.1477 - lr 0.0250000
2021-05-28 01:18:06,284 DEV : loss 0.29054251313209534 - score 0.9
2021-05-28 01:18:06,296 BAD EPOCHS (no improvement): 1
2021-05-28 01:18:06,296 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:06,823 epoch 30 - iter 1/16 - loss 0.06606483 - samples/sec: 60.72 - lr: 0.025000
2021-05-28 01:18:07,359 epoch 30 - iter 2/16 - loss 0.13213587 - samples/sec: 59.77 - lr: 0.025000
2021-05-28 01:18:07,891 epoch 30 - iter 3/16 - loss 0.13983933 - samples/sec: 60.18 - lr: 0.025000
2021-05-28 01:18:08,422 epoch 30 - iter 4/16 - loss 0.15683770 - samples/sec: 60.37 - lr: 0.025000
2021-05-28 01:18:08,935 epoch 30 - iter 5/16 - loss 0.13591859 - samples/sec: 62.40 - lr: 0.025000
2021-05-28 01:18:09,460 epoch 30 - iter 6/16 - loss 0.15452093 - samples/sec: 61.03 - lr: 0.025000
2021-05-28 01:18:09,990 epoch 30 - iter 7/16 - loss 0.14719651 - samples/sec: 60.46 - lr: 0.025000
2021-05-28 01:18:10,520 epoch 30 - iter 8/16 - loss 0.14191879 - samples/sec: 60.41 - lr: 0.025000
2021-05-28 01:18:11,053 epoch 30 - iter 9/16 - loss 0.15276290 - samples/sec: 60.11 - lr: 0.025000
2021-05-28 01:18:11,568 epoch 30 - iter 10/16 - loss 0.14983662 - samples/sec: 62.24 - lr: 0.025000
2021-05-28 01:18:12,101 epoch 30 - iter 11/16 - loss 0.14039467 - samples/sec: 60.04 - lr: 0.025000
2021-05-28 01:18:12,624 epoch 30 - iter 12/16 - loss 0.13697943 - samples/sec: 61.30 - lr: 0.025000
2021-05-28 01:18:13,155 epoch 30 - iter 13/16 - loss 0.15039007 - samples/sec: 60.29 - lr: 0.025000
2021-05-28 01:18:13,694 epoch 30 - iter 14/16 - loss 0.14316389 - samples/sec: 59.36 - lr: 0.025000
2021-05-28 01:18:14,228 epoch 30 - iter 15/16 - loss 0.13956854 - samples/sec: 59.97 - lr: 0.025000
2021-05-28 01:18:14,605 epoch 30 - iter 16/16 - loss 0.13850664 - samples/sec: 85.18 - lr: 0.025000
2021-05-28 01:18:14,605 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:14,605 EPOCH 30 done: loss 0.1385 - lr 0.0250000
2021-05-28 01:18:15,310 DEV : loss 0.1976471245288849 - score 0.929
2021-05-28 01:18:15,322 BAD EPOCHS (no improvement): 2
2021-05-28 01:18:16,332 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:16,332 Testing using best model ...
2021-05-28 01:18:16,332 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/spa.rst.sctb/best-model.pt
2021-05-28 01:18:23,441 0.7795	0.9900	0.8722
2021-05-28 01:18:23,441 
Results:
- F1-score (micro) 0.8722
- F1-score (macro) 0.8722

By class:
SENT       tp: 99 - fp: 28 - fn: 1 - precision: 0.7795 - recall: 0.9900 - f1-score: 0.8722
2021-05-28 01:18:23,441 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/
2021-05-28 01:18:23,471 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt
2021-05-28 01:18:23,471 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/sent_train.txt
2021-05-28 01:18:23,473 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/sent_dev.txt
2021-05-28 01:18:23,476 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/sent_test.txt
Corpus: 8099 train + 840 dev + 1047 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-28 01:18:32,885 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:32,888 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-28 01:18:32,888 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:32,888 Corpus: "Corpus: 8099 train + 840 dev + 1047 test sentences"
2021-05-28 01:18:32,888 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:32,888 Parameters:
2021-05-28 01:18:32,888  - learning_rate: "0.1"
2021-05-28 01:18:32,888  - mini_batch_size: "32"
2021-05-28 01:18:32,888  - patience: "3"
2021-05-28 01:18:32,888  - anneal_factor: "0.5"
2021-05-28 01:18:32,888  - max_epochs: "30"
2021-05-28 01:18:32,888  - shuffle: "True"
2021-05-28 01:18:32,888  - train_with_dev: "False"
2021-05-28 01:18:32,888  - batch_growth_annealing: "False"
2021-05-28 01:18:32,888 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:32,888 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt"
2021-05-28 01:18:32,888 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:32,888 Device: cuda:0
2021-05-28 01:18:32,888 ----------------------------------------------------------------------------------------------------
2021-05-28 01:18:32,888 Embeddings storage mode: cpu
2021-05-28 01:18:32,889 ----------------------------------------------------------------------------------------------------
2021-05-28 01:19:06,023 epoch 1 - iter 25/254 - loss 6.26939066 - samples/sec: 24.15 - lr: 0.100000
2021-05-28 01:19:38,877 epoch 1 - iter 50/254 - loss 4.68697880 - samples/sec: 24.35 - lr: 0.100000
2021-05-28 01:20:11,699 epoch 1 - iter 75/254 - loss 3.79803922 - samples/sec: 24.38 - lr: 0.100000
2021-05-28 01:20:44,371 epoch 1 - iter 100/254 - loss 3.24010889 - samples/sec: 24.49 - lr: 0.100000
2021-05-28 01:21:17,193 epoch 1 - iter 125/254 - loss 2.85915977 - samples/sec: 24.38 - lr: 0.100000
2021-05-28 01:21:49,932 epoch 1 - iter 150/254 - loss 2.56263148 - samples/sec: 24.44 - lr: 0.100000
2021-05-28 01:22:23,277 epoch 1 - iter 175/254 - loss 2.35508570 - samples/sec: 23.99 - lr: 0.100000
2021-05-28 01:22:56,073 epoch 1 - iter 200/254 - loss 2.15524149 - samples/sec: 24.39 - lr: 0.100000
2021-05-28 01:23:28,912 epoch 1 - iter 225/254 - loss 2.01462411 - samples/sec: 24.36 - lr: 0.100000
2021-05-28 01:24:01,871 epoch 1 - iter 250/254 - loss 1.89890978 - samples/sec: 24.27 - lr: 0.100000
2021-05-28 01:24:05,998 ----------------------------------------------------------------------------------------------------
2021-05-28 01:24:05,998 EPOCH 1 done: loss 1.8865 - lr 0.1000000
2021-05-28 01:24:27,701 DEV : loss 0.43095162510871887 - score 0.8689
2021-05-28 01:24:27,784 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:24:28,796 ----------------------------------------------------------------------------------------------------
2021-05-28 01:24:41,876 epoch 2 - iter 25/254 - loss 0.77281977 - samples/sec: 61.17 - lr: 0.100000
2021-05-28 01:24:55,552 epoch 2 - iter 50/254 - loss 0.75625534 - samples/sec: 58.50 - lr: 0.100000
2021-05-28 01:25:08,617 epoch 2 - iter 75/254 - loss 0.73740775 - samples/sec: 61.24 - lr: 0.100000
2021-05-28 01:25:21,681 epoch 2 - iter 100/254 - loss 0.71025405 - samples/sec: 61.24 - lr: 0.100000
2021-05-28 01:25:34,739 epoch 2 - iter 125/254 - loss 0.67632313 - samples/sec: 61.27 - lr: 0.100000
2021-05-28 01:25:47,915 epoch 2 - iter 150/254 - loss 0.66518206 - samples/sec: 60.73 - lr: 0.100000
2021-05-28 01:26:01,104 epoch 2 - iter 175/254 - loss 0.65303718 - samples/sec: 60.67 - lr: 0.100000
2021-05-28 01:26:14,296 epoch 2 - iter 200/254 - loss 0.63595353 - samples/sec: 60.65 - lr: 0.100000
2021-05-28 01:26:27,420 epoch 2 - iter 225/254 - loss 0.63000392 - samples/sec: 60.96 - lr: 0.100000
2021-05-28 01:26:40,666 epoch 2 - iter 250/254 - loss 0.63789468 - samples/sec: 60.40 - lr: 0.100000
2021-05-28 01:26:42,336 ----------------------------------------------------------------------------------------------------
2021-05-28 01:26:42,336 EPOCH 2 done: loss 0.6450 - lr 0.1000000
2021-05-28 01:26:47,293 DEV : loss 0.3361983895301819 - score 0.8964
2021-05-28 01:26:47,377 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:26:56,764 ----------------------------------------------------------------------------------------------------
2021-05-28 01:27:09,907 epoch 3 - iter 25/254 - loss 0.43669576 - samples/sec: 60.88 - lr: 0.100000
2021-05-28 01:27:23,207 epoch 3 - iter 50/254 - loss 0.43223380 - samples/sec: 60.16 - lr: 0.100000
2021-05-28 01:27:36,395 epoch 3 - iter 75/254 - loss 0.44232248 - samples/sec: 60.67 - lr: 0.100000
2021-05-28 01:27:49,623 epoch 3 - iter 100/254 - loss 0.45762454 - samples/sec: 60.49 - lr: 0.100000
2021-05-28 01:28:02,765 epoch 3 - iter 125/254 - loss 0.45760486 - samples/sec: 60.88 - lr: 0.100000
2021-05-28 01:28:15,926 epoch 3 - iter 150/254 - loss 0.45887472 - samples/sec: 60.79 - lr: 0.100000
2021-05-28 01:28:29,101 epoch 3 - iter 175/254 - loss 0.45378300 - samples/sec: 60.73 - lr: 0.100000
2021-05-28 01:28:42,366 epoch 3 - iter 200/254 - loss 0.46219548 - samples/sec: 60.32 - lr: 0.100000
2021-05-28 01:28:55,476 epoch 3 - iter 225/254 - loss 0.46288041 - samples/sec: 61.03 - lr: 0.100000
2021-05-28 01:29:08,676 epoch 3 - iter 250/254 - loss 0.46043921 - samples/sec: 60.62 - lr: 0.100000
2021-05-28 01:29:10,376 ----------------------------------------------------------------------------------------------------
2021-05-28 01:29:10,377 EPOCH 3 done: loss 0.4633 - lr 0.1000000
2021-05-28 01:29:15,300 DEV : loss 0.406910240650177 - score 0.8798
2021-05-28 01:29:15,384 BAD EPOCHS (no improvement): 1
2021-05-28 01:29:15,384 ----------------------------------------------------------------------------------------------------
2021-05-28 01:29:28,600 epoch 4 - iter 25/254 - loss 0.46688741 - samples/sec: 60.54 - lr: 0.100000
2021-05-28 01:29:41,792 epoch 4 - iter 50/254 - loss 0.50748492 - samples/sec: 60.65 - lr: 0.100000
2021-05-28 01:29:54,969 epoch 4 - iter 75/254 - loss 0.50170442 - samples/sec: 60.72 - lr: 0.100000
2021-05-28 01:30:08,216 epoch 4 - iter 100/254 - loss 0.49775708 - samples/sec: 60.40 - lr: 0.100000
2021-05-28 01:30:21,286 epoch 4 - iter 125/254 - loss 0.47938908 - samples/sec: 61.22 - lr: 0.100000
2021-05-28 01:30:34,518 epoch 4 - iter 150/254 - loss 0.46999703 - samples/sec: 60.47 - lr: 0.100000
2021-05-28 01:30:47,545 epoch 4 - iter 175/254 - loss 0.46904712 - samples/sec: 61.42 - lr: 0.100000
2021-05-28 01:31:00,702 epoch 4 - iter 200/254 - loss 0.46644940 - samples/sec: 60.81 - lr: 0.100000
2021-05-28 01:31:13,863 epoch 4 - iter 225/254 - loss 0.46168864 - samples/sec: 60.79 - lr: 0.100000
2021-05-28 01:31:27,048 epoch 4 - iter 250/254 - loss 0.47029014 - samples/sec: 60.68 - lr: 0.100000
2021-05-28 01:31:28,740 ----------------------------------------------------------------------------------------------------
2021-05-28 01:31:28,741 EPOCH 4 done: loss 0.4745 - lr 0.1000000
2021-05-28 01:31:33,665 DEV : loss 0.32142335176467896 - score 0.9063
2021-05-28 01:31:33,750 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:31:43,337 ----------------------------------------------------------------------------------------------------
2021-05-28 01:31:57,264 epoch 5 - iter 25/254 - loss 0.39468554 - samples/sec: 57.45 - lr: 0.100000
2021-05-28 01:32:10,486 epoch 5 - iter 50/254 - loss 0.42111653 - samples/sec: 60.51 - lr: 0.100000
2021-05-28 01:32:23,724 epoch 5 - iter 75/254 - loss 0.39620058 - samples/sec: 60.44 - lr: 0.100000
2021-05-28 01:32:36,892 epoch 5 - iter 100/254 - loss 0.39541919 - samples/sec: 60.76 - lr: 0.100000
2021-05-28 01:32:50,049 epoch 5 - iter 125/254 - loss 0.40008940 - samples/sec: 60.81 - lr: 0.100000
2021-05-28 01:33:03,268 epoch 5 - iter 150/254 - loss 0.39676599 - samples/sec: 60.53 - lr: 0.100000
2021-05-28 01:33:16,470 epoch 5 - iter 175/254 - loss 0.39638656 - samples/sec: 60.61 - lr: 0.100000
2021-05-28 01:33:29,706 epoch 5 - iter 200/254 - loss 0.40465148 - samples/sec: 60.45 - lr: 0.100000
2021-05-28 01:33:42,956 epoch 5 - iter 225/254 - loss 0.41383038 - samples/sec: 60.39 - lr: 0.100000
2021-05-28 01:33:56,163 epoch 5 - iter 250/254 - loss 0.40603497 - samples/sec: 60.58 - lr: 0.100000
2021-05-28 01:33:57,856 ----------------------------------------------------------------------------------------------------
2021-05-28 01:33:57,856 EPOCH 5 done: loss 0.4103 - lr 0.1000000
2021-05-28 01:34:02,787 DEV : loss 0.4982036352157593 - score 0.8752
2021-05-28 01:34:02,871 BAD EPOCHS (no improvement): 1
2021-05-28 01:34:02,871 ----------------------------------------------------------------------------------------------------
2021-05-28 01:34:16,106 epoch 6 - iter 25/254 - loss 0.32424924 - samples/sec: 60.45 - lr: 0.100000
2021-05-28 01:34:29,365 epoch 6 - iter 50/254 - loss 0.40505515 - samples/sec: 60.35 - lr: 0.100000
2021-05-28 01:34:42,518 epoch 6 - iter 75/254 - loss 0.42441077 - samples/sec: 60.83 - lr: 0.100000
2021-05-28 01:34:55,756 epoch 6 - iter 100/254 - loss 0.43948650 - samples/sec: 60.44 - lr: 0.100000
2021-05-28 01:35:08,955 epoch 6 - iter 125/254 - loss 0.41066388 - samples/sec: 60.62 - lr: 0.100000
2021-05-28 01:35:22,089 epoch 6 - iter 150/254 - loss 0.41352650 - samples/sec: 60.92 - lr: 0.100000
2021-05-28 01:35:35,335 epoch 6 - iter 175/254 - loss 0.40590689 - samples/sec: 60.40 - lr: 0.100000
2021-05-28 01:35:48,577 epoch 6 - iter 200/254 - loss 0.40801048 - samples/sec: 60.42 - lr: 0.100000
2021-05-28 01:36:01,707 epoch 6 - iter 225/254 - loss 0.40620890 - samples/sec: 60.94 - lr: 0.100000
2021-05-28 01:36:14,848 epoch 6 - iter 250/254 - loss 0.40374983 - samples/sec: 60.89 - lr: 0.100000
2021-05-28 01:36:16,522 ----------------------------------------------------------------------------------------------------
2021-05-28 01:36:16,522 EPOCH 6 done: loss 0.4019 - lr 0.1000000
2021-05-28 01:36:21,448 DEV : loss 0.24104391038417816 - score 0.9277
2021-05-28 01:36:21,531 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:36:31,118 ----------------------------------------------------------------------------------------------------
2021-05-28 01:36:44,276 epoch 7 - iter 25/254 - loss 0.37420384 - samples/sec: 60.81 - lr: 0.100000
2021-05-28 01:36:57,454 epoch 7 - iter 50/254 - loss 0.37433748 - samples/sec: 60.72 - lr: 0.100000
2021-05-28 01:37:10,568 epoch 7 - iter 75/254 - loss 0.37531246 - samples/sec: 61.01 - lr: 0.100000
2021-05-28 01:37:23,671 epoch 7 - iter 100/254 - loss 0.37160052 - samples/sec: 61.06 - lr: 0.100000
2021-05-28 01:37:36,730 epoch 7 - iter 125/254 - loss 0.37931804 - samples/sec: 61.27 - lr: 0.100000
2021-05-28 01:37:49,807 epoch 7 - iter 150/254 - loss 0.36536838 - samples/sec: 61.18 - lr: 0.100000
2021-05-28 01:38:02,955 epoch 7 - iter 175/254 - loss 0.36810273 - samples/sec: 60.85 - lr: 0.100000
2021-05-28 01:38:15,973 epoch 7 - iter 200/254 - loss 0.36821313 - samples/sec: 61.46 - lr: 0.100000
2021-05-28 01:38:29,034 epoch 7 - iter 225/254 - loss 0.36293616 - samples/sec: 61.26 - lr: 0.100000
2021-05-28 01:38:42,069 epoch 7 - iter 250/254 - loss 0.36780541 - samples/sec: 61.38 - lr: 0.100000
2021-05-28 01:38:43,736 ----------------------------------------------------------------------------------------------------
2021-05-28 01:38:43,737 EPOCH 7 done: loss 0.3650 - lr 0.1000000
2021-05-28 01:38:48,674 DEV : loss 0.3143564760684967 - score 0.9183
2021-05-28 01:38:48,758 BAD EPOCHS (no improvement): 1
2021-05-28 01:38:48,759 ----------------------------------------------------------------------------------------------------
2021-05-28 01:39:02,512 epoch 8 - iter 25/254 - loss 0.34520295 - samples/sec: 58.17 - lr: 0.100000
2021-05-28 01:39:15,764 epoch 8 - iter 50/254 - loss 0.34441631 - samples/sec: 60.38 - lr: 0.100000
2021-05-28 01:39:28,941 epoch 8 - iter 75/254 - loss 0.33530319 - samples/sec: 60.72 - lr: 0.100000
2021-05-28 01:39:42,077 epoch 8 - iter 100/254 - loss 0.32565584 - samples/sec: 60.91 - lr: 0.100000
2021-05-28 01:39:55,230 epoch 8 - iter 125/254 - loss 0.32840486 - samples/sec: 60.83 - lr: 0.100000
2021-05-28 01:40:08,450 epoch 8 - iter 150/254 - loss 0.33013301 - samples/sec: 60.52 - lr: 0.100000
2021-05-28 01:40:21,667 epoch 8 - iter 175/254 - loss 0.32805158 - samples/sec: 60.54 - lr: 0.100000
2021-05-28 01:40:34,845 epoch 8 - iter 200/254 - loss 0.33144635 - samples/sec: 60.71 - lr: 0.100000
2021-05-28 01:40:48,058 epoch 8 - iter 225/254 - loss 0.33787783 - samples/sec: 60.55 - lr: 0.100000
2021-05-28 01:41:01,174 epoch 8 - iter 250/254 - loss 0.33532319 - samples/sec: 61.00 - lr: 0.100000
2021-05-28 01:41:02,880 ----------------------------------------------------------------------------------------------------
2021-05-28 01:41:02,881 EPOCH 8 done: loss 0.3330 - lr 0.1000000
2021-05-28 01:41:07,806 DEV : loss 0.20394107699394226 - score 0.9378
2021-05-28 01:41:07,890 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:41:17,380 ----------------------------------------------------------------------------------------------------
2021-05-28 01:41:30,513 epoch 9 - iter 25/254 - loss 0.35519382 - samples/sec: 60.93 - lr: 0.100000
2021-05-28 01:41:43,743 epoch 9 - iter 50/254 - loss 0.37602470 - samples/sec: 60.47 - lr: 0.100000
2021-05-28 01:41:56,903 epoch 9 - iter 75/254 - loss 0.38243858 - samples/sec: 60.80 - lr: 0.100000
2021-05-28 01:42:10,032 epoch 9 - iter 100/254 - loss 0.37696418 - samples/sec: 60.94 - lr: 0.100000
2021-05-28 01:42:23,120 epoch 9 - iter 125/254 - loss 0.35628364 - samples/sec: 61.13 - lr: 0.100000
2021-05-28 01:42:36,294 epoch 9 - iter 150/254 - loss 0.35876298 - samples/sec: 60.74 - lr: 0.100000
2021-05-28 01:42:49,334 epoch 9 - iter 175/254 - loss 0.34626950 - samples/sec: 61.35 - lr: 0.100000
2021-05-28 01:43:02,485 epoch 9 - iter 200/254 - loss 0.34916486 - samples/sec: 60.84 - lr: 0.100000
2021-05-28 01:43:15,573 epoch 9 - iter 225/254 - loss 0.34345293 - samples/sec: 61.13 - lr: 0.100000
2021-05-28 01:43:28,637 epoch 9 - iter 250/254 - loss 0.33891000 - samples/sec: 61.24 - lr: 0.100000
2021-05-28 01:43:30,315 ----------------------------------------------------------------------------------------------------
2021-05-28 01:43:30,315 EPOCH 9 done: loss 0.3373 - lr 0.1000000
2021-05-28 01:43:35,248 DEV : loss 0.2008693665266037 - score 0.9414
2021-05-28 01:43:35,334 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:43:44,807 ----------------------------------------------------------------------------------------------------
2021-05-28 01:43:57,911 epoch 10 - iter 25/254 - loss 0.30003208 - samples/sec: 61.06 - lr: 0.100000
2021-05-28 01:44:11,117 epoch 10 - iter 50/254 - loss 0.31912488 - samples/sec: 60.58 - lr: 0.100000
2021-05-28 01:44:24,385 epoch 10 - iter 75/254 - loss 0.33270146 - samples/sec: 60.30 - lr: 0.100000
2021-05-28 01:44:37,601 epoch 10 - iter 100/254 - loss 0.33237556 - samples/sec: 60.54 - lr: 0.100000
2021-05-28 01:44:50,839 epoch 10 - iter 125/254 - loss 0.33135403 - samples/sec: 60.44 - lr: 0.100000
2021-05-28 01:45:04,013 epoch 10 - iter 150/254 - loss 0.32993819 - samples/sec: 60.73 - lr: 0.100000
2021-05-28 01:45:17,203 epoch 10 - iter 175/254 - loss 0.32232961 - samples/sec: 60.66 - lr: 0.100000
2021-05-28 01:45:31,051 epoch 10 - iter 200/254 - loss 0.31974387 - samples/sec: 57.78 - lr: 0.100000
2021-05-28 01:45:44,260 epoch 10 - iter 225/254 - loss 0.31386778 - samples/sec: 60.57 - lr: 0.100000
2021-05-28 01:45:57,323 epoch 10 - iter 250/254 - loss 0.31187042 - samples/sec: 61.25 - lr: 0.100000
2021-05-28 01:45:59,020 ----------------------------------------------------------------------------------------------------
2021-05-28 01:45:59,020 EPOCH 10 done: loss 0.3140 - lr 0.1000000
2021-05-28 01:46:03,961 DEV : loss 0.5086476802825928 - score 0.8907
2021-05-28 01:46:04,046 BAD EPOCHS (no improvement): 1
2021-05-28 01:46:04,046 ----------------------------------------------------------------------------------------------------
2021-05-28 01:46:17,256 epoch 11 - iter 25/254 - loss 0.32026165 - samples/sec: 60.57 - lr: 0.100000
2021-05-28 01:46:30,450 epoch 11 - iter 50/254 - loss 0.29523273 - samples/sec: 60.64 - lr: 0.100000
2021-05-28 01:46:43,673 epoch 11 - iter 75/254 - loss 0.29576085 - samples/sec: 60.51 - lr: 0.100000
2021-05-28 01:46:56,888 epoch 11 - iter 100/254 - loss 0.29401036 - samples/sec: 60.55 - lr: 0.100000
2021-05-28 01:47:10,130 epoch 11 - iter 125/254 - loss 0.29139446 - samples/sec: 60.42 - lr: 0.100000
2021-05-28 01:47:23,242 epoch 11 - iter 150/254 - loss 0.28064355 - samples/sec: 61.02 - lr: 0.100000
2021-05-28 01:47:36,351 epoch 11 - iter 175/254 - loss 0.28586488 - samples/sec: 61.03 - lr: 0.100000
2021-05-28 01:47:49,510 epoch 11 - iter 200/254 - loss 0.28751784 - samples/sec: 60.80 - lr: 0.100000
2021-05-28 01:48:02,752 epoch 11 - iter 225/254 - loss 0.29186257 - samples/sec: 60.42 - lr: 0.100000
2021-05-28 01:48:15,971 epoch 11 - iter 250/254 - loss 0.29032260 - samples/sec: 60.53 - lr: 0.100000
2021-05-28 01:48:17,679 ----------------------------------------------------------------------------------------------------
2021-05-28 01:48:17,679 EPOCH 11 done: loss 0.2883 - lr 0.1000000
2021-05-28 01:48:22,618 DEV : loss 0.22393137216567993 - score 0.925
2021-05-28 01:48:22,703 BAD EPOCHS (no improvement): 2
2021-05-28 01:48:22,704 ----------------------------------------------------------------------------------------------------
2021-05-28 01:48:35,940 epoch 12 - iter 25/254 - loss 0.30188580 - samples/sec: 60.45 - lr: 0.100000
2021-05-28 01:48:49,107 epoch 12 - iter 50/254 - loss 0.29317386 - samples/sec: 60.76 - lr: 0.100000
2021-05-28 01:49:02,283 epoch 12 - iter 75/254 - loss 0.27938320 - samples/sec: 60.72 - lr: 0.100000
2021-05-28 01:49:15,413 epoch 12 - iter 100/254 - loss 0.27377773 - samples/sec: 60.94 - lr: 0.100000
2021-05-28 01:49:28,573 epoch 12 - iter 125/254 - loss 0.27079143 - samples/sec: 60.80 - lr: 0.100000
2021-05-28 01:49:41,760 epoch 12 - iter 150/254 - loss 0.27312605 - samples/sec: 60.67 - lr: 0.100000
2021-05-28 01:49:55,001 epoch 12 - iter 175/254 - loss 0.26794682 - samples/sec: 60.43 - lr: 0.100000
2021-05-28 01:50:08,193 epoch 12 - iter 200/254 - loss 0.27583046 - samples/sec: 60.65 - lr: 0.100000
2021-05-28 01:50:21,338 epoch 12 - iter 225/254 - loss 0.27962900 - samples/sec: 60.87 - lr: 0.100000
2021-05-28 01:50:34,508 epoch 12 - iter 250/254 - loss 0.28390513 - samples/sec: 60.75 - lr: 0.100000
2021-05-28 01:50:36,186 ----------------------------------------------------------------------------------------------------
2021-05-28 01:50:36,186 EPOCH 12 done: loss 0.2829 - lr 0.1000000
2021-05-28 01:50:41,110 DEV : loss 0.2656143605709076 - score 0.9147
2021-05-28 01:50:41,195 BAD EPOCHS (no improvement): 3
2021-05-28 01:50:41,196 ----------------------------------------------------------------------------------------------------
2021-05-28 01:50:54,362 epoch 13 - iter 25/254 - loss 0.21933707 - samples/sec: 60.77 - lr: 0.100000
2021-05-28 01:51:07,504 epoch 13 - iter 50/254 - loss 0.22922482 - samples/sec: 60.88 - lr: 0.100000
2021-05-28 01:51:20,744 epoch 13 - iter 75/254 - loss 0.23121536 - samples/sec: 60.43 - lr: 0.100000
2021-05-28 01:51:33,777 epoch 13 - iter 100/254 - loss 0.24253874 - samples/sec: 61.39 - lr: 0.100000
2021-05-28 01:51:46,823 epoch 13 - iter 125/254 - loss 0.25137520 - samples/sec: 61.33 - lr: 0.100000
2021-05-28 01:51:59,972 epoch 13 - iter 150/254 - loss 0.25140974 - samples/sec: 60.85 - lr: 0.100000
2021-05-28 01:52:13,074 epoch 13 - iter 175/254 - loss 0.25575690 - samples/sec: 61.07 - lr: 0.100000
2021-05-28 01:52:26,911 epoch 13 - iter 200/254 - loss 0.25581546 - samples/sec: 57.82 - lr: 0.100000
2021-05-28 01:52:40,045 epoch 13 - iter 225/254 - loss 0.26176445 - samples/sec: 60.92 - lr: 0.100000
2021-05-28 01:52:53,179 epoch 13 - iter 250/254 - loss 0.26516633 - samples/sec: 60.92 - lr: 0.100000
2021-05-28 01:52:54,867 ----------------------------------------------------------------------------------------------------
2021-05-28 01:52:54,867 EPOCH 13 done: loss 0.2639 - lr 0.1000000
2021-05-28 01:52:59,801 DEV : loss 0.23450753092765808 - score 0.9291
Epoch    13: reducing learning rate of group 0 to 5.0000e-02.
2021-05-28 01:52:59,887 BAD EPOCHS (no improvement): 4
2021-05-28 01:52:59,888 ----------------------------------------------------------------------------------------------------
2021-05-28 01:53:13,001 epoch 14 - iter 25/254 - loss 0.30855264 - samples/sec: 61.01 - lr: 0.050000
2021-05-28 01:53:26,059 epoch 14 - iter 50/254 - loss 0.28676946 - samples/sec: 61.27 - lr: 0.050000
2021-05-28 01:53:39,253 epoch 14 - iter 75/254 - loss 0.28027136 - samples/sec: 60.64 - lr: 0.050000
2021-05-28 01:53:52,439 epoch 14 - iter 100/254 - loss 0.26157944 - samples/sec: 60.67 - lr: 0.050000
2021-05-28 01:54:05,535 epoch 14 - iter 125/254 - loss 0.25777563 - samples/sec: 61.09 - lr: 0.050000
2021-05-28 01:54:18,653 epoch 14 - iter 150/254 - loss 0.25357083 - samples/sec: 60.99 - lr: 0.050000
2021-05-28 01:54:31,711 epoch 14 - iter 175/254 - loss 0.24894219 - samples/sec: 61.27 - lr: 0.050000
2021-05-28 01:54:44,789 epoch 14 - iter 200/254 - loss 0.24461501 - samples/sec: 61.18 - lr: 0.050000
2021-05-28 01:54:57,852 epoch 14 - iter 225/254 - loss 0.24530066 - samples/sec: 61.25 - lr: 0.050000
2021-05-28 01:55:10,873 epoch 14 - iter 250/254 - loss 0.24597123 - samples/sec: 61.44 - lr: 0.050000
2021-05-28 01:55:12,556 ----------------------------------------------------------------------------------------------------
2021-05-28 01:55:12,556 EPOCH 14 done: loss 0.2475 - lr 0.0500000
2021-05-28 01:55:17,490 DEV : loss 0.161178857088089 - score 0.9475
2021-05-28 01:55:17,575 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 01:55:27,056 ----------------------------------------------------------------------------------------------------
2021-05-28 01:55:40,028 epoch 15 - iter 25/254 - loss 0.25923994 - samples/sec: 61.68 - lr: 0.050000
2021-05-28 01:55:53,059 epoch 15 - iter 50/254 - loss 0.23767626 - samples/sec: 61.40 - lr: 0.050000
2021-05-28 01:56:06,101 epoch 15 - iter 75/254 - loss 0.21995273 - samples/sec: 61.35 - lr: 0.050000
2021-05-28 01:56:19,127 epoch 15 - iter 100/254 - loss 0.21690121 - samples/sec: 61.42 - lr: 0.050000
2021-05-28 01:56:32,301 epoch 15 - iter 125/254 - loss 0.22271649 - samples/sec: 60.73 - lr: 0.050000
2021-05-28 01:56:45,536 epoch 15 - iter 150/254 - loss 0.22491164 - samples/sec: 60.45 - lr: 0.050000
2021-05-28 01:56:58,697 epoch 15 - iter 175/254 - loss 0.22953310 - samples/sec: 60.79 - lr: 0.050000
2021-05-28 01:57:11,858 epoch 15 - iter 200/254 - loss 0.22639216 - samples/sec: 60.79 - lr: 0.050000
2021-05-28 01:57:25,036 epoch 15 - iter 225/254 - loss 0.23063946 - samples/sec: 60.72 - lr: 0.050000
2021-05-28 01:57:38,282 epoch 15 - iter 250/254 - loss 0.23092181 - samples/sec: 60.40 - lr: 0.050000
2021-05-28 01:57:39,961 ----------------------------------------------------------------------------------------------------
2021-05-28 01:57:39,961 EPOCH 15 done: loss 0.2295 - lr 0.0500000
2021-05-28 01:57:44,894 DEV : loss 0.2586941719055176 - score 0.9215
2021-05-28 01:57:44,979 BAD EPOCHS (no improvement): 1
2021-05-28 01:57:44,979 ----------------------------------------------------------------------------------------------------
2021-05-28 01:57:58,203 epoch 16 - iter 25/254 - loss 0.22899549 - samples/sec: 60.50 - lr: 0.050000
2021-05-28 01:58:11,385 epoch 16 - iter 50/254 - loss 0.22207473 - samples/sec: 60.70 - lr: 0.050000
2021-05-28 01:58:24,607 epoch 16 - iter 75/254 - loss 0.23393579 - samples/sec: 60.51 - lr: 0.050000
2021-05-28 01:58:37,888 epoch 16 - iter 100/254 - loss 0.23418381 - samples/sec: 60.25 - lr: 0.050000
2021-05-28 01:58:51,080 epoch 16 - iter 125/254 - loss 0.23152432 - samples/sec: 60.65 - lr: 0.050000
2021-05-28 01:59:04,407 epoch 16 - iter 150/254 - loss 0.22706110 - samples/sec: 60.04 - lr: 0.050000
2021-05-28 01:59:18,304 epoch 16 - iter 175/254 - loss 0.22427299 - samples/sec: 57.57 - lr: 0.050000
2021-05-28 01:59:31,439 epoch 16 - iter 200/254 - loss 0.22257172 - samples/sec: 60.92 - lr: 0.050000
2021-05-28 01:59:44,644 epoch 16 - iter 225/254 - loss 0.22110819 - samples/sec: 60.59 - lr: 0.050000
2021-05-28 01:59:57,796 epoch 16 - iter 250/254 - loss 0.22489632 - samples/sec: 60.84 - lr: 0.050000
2021-05-28 01:59:59,483 ----------------------------------------------------------------------------------------------------
2021-05-28 01:59:59,484 EPOCH 16 done: loss 0.2244 - lr 0.0500000
2021-05-28 02:00:04,415 DEV : loss 0.21732358634471893 - score 0.9345
2021-05-28 02:00:04,501 BAD EPOCHS (no improvement): 2
2021-05-28 02:00:04,501 ----------------------------------------------------------------------------------------------------
2021-05-28 02:00:17,704 epoch 17 - iter 25/254 - loss 0.20071280 - samples/sec: 60.60 - lr: 0.050000
2021-05-28 02:00:30,853 epoch 17 - iter 50/254 - loss 0.20667463 - samples/sec: 60.85 - lr: 0.050000
2021-05-28 02:00:44,013 epoch 17 - iter 75/254 - loss 0.21178881 - samples/sec: 60.80 - lr: 0.050000
2021-05-28 02:00:57,177 epoch 17 - iter 100/254 - loss 0.20594999 - samples/sec: 60.78 - lr: 0.050000
2021-05-28 02:01:10,296 epoch 17 - iter 125/254 - loss 0.21158240 - samples/sec: 60.99 - lr: 0.050000
2021-05-28 02:01:23,453 epoch 17 - iter 150/254 - loss 0.21305213 - samples/sec: 60.81 - lr: 0.050000
2021-05-28 02:01:36,669 epoch 17 - iter 175/254 - loss 0.21526495 - samples/sec: 60.54 - lr: 0.050000
2021-05-28 02:01:49,928 epoch 17 - iter 200/254 - loss 0.21464763 - samples/sec: 60.35 - lr: 0.050000
2021-05-28 02:02:03,124 epoch 17 - iter 225/254 - loss 0.21539911 - samples/sec: 60.63 - lr: 0.050000
2021-05-28 02:02:16,277 epoch 17 - iter 250/254 - loss 0.21485156 - samples/sec: 60.83 - lr: 0.050000
2021-05-28 02:02:17,967 ----------------------------------------------------------------------------------------------------
2021-05-28 02:02:17,967 EPOCH 17 done: loss 0.2158 - lr 0.0500000
2021-05-28 02:02:22,896 DEV : loss 0.1587672233581543 - score 0.9475
2021-05-28 02:02:22,981 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:02:32,580 ----------------------------------------------------------------------------------------------------
2021-05-28 02:02:45,741 epoch 18 - iter 25/254 - loss 0.16379883 - samples/sec: 60.80 - lr: 0.050000
2021-05-28 02:02:58,922 epoch 18 - iter 50/254 - loss 0.18359200 - samples/sec: 60.70 - lr: 0.050000
2021-05-28 02:03:12,048 epoch 18 - iter 75/254 - loss 0.19243001 - samples/sec: 60.95 - lr: 0.050000
2021-05-28 02:03:25,273 epoch 18 - iter 100/254 - loss 0.21112692 - samples/sec: 60.50 - lr: 0.050000
2021-05-28 02:03:38,473 epoch 18 - iter 125/254 - loss 0.21719766 - samples/sec: 60.61 - lr: 0.050000
2021-05-28 02:03:51,635 epoch 18 - iter 150/254 - loss 0.21767544 - samples/sec: 60.79 - lr: 0.050000
2021-05-28 02:04:04,796 epoch 18 - iter 175/254 - loss 0.21483468 - samples/sec: 60.79 - lr: 0.050000
2021-05-28 02:04:17,908 epoch 18 - iter 200/254 - loss 0.21800403 - samples/sec: 61.02 - lr: 0.050000
2021-05-28 02:04:31,081 epoch 18 - iter 225/254 - loss 0.21789618 - samples/sec: 60.74 - lr: 0.050000
2021-05-28 02:04:44,226 epoch 18 - iter 250/254 - loss 0.21999109 - samples/sec: 60.86 - lr: 0.050000
2021-05-28 02:04:45,916 ----------------------------------------------------------------------------------------------------
2021-05-28 02:04:45,916 EPOCH 18 done: loss 0.2189 - lr 0.0500000
2021-05-28 02:04:50,853 DEV : loss 0.1942601352930069 - score 0.9355
2021-05-28 02:04:50,940 BAD EPOCHS (no improvement): 1
2021-05-28 02:04:50,941 ----------------------------------------------------------------------------------------------------
2021-05-28 02:05:04,144 epoch 19 - iter 25/254 - loss 0.19450205 - samples/sec: 60.60 - lr: 0.050000
2021-05-28 02:05:17,296 epoch 19 - iter 50/254 - loss 0.20743383 - samples/sec: 60.84 - lr: 0.050000
2021-05-28 02:05:30,362 epoch 19 - iter 75/254 - loss 0.20396913 - samples/sec: 61.24 - lr: 0.050000
2021-05-28 02:05:43,542 epoch 19 - iter 100/254 - loss 0.20862474 - samples/sec: 60.70 - lr: 0.050000
2021-05-28 02:05:56,785 epoch 19 - iter 125/254 - loss 0.21153461 - samples/sec: 60.42 - lr: 0.050000
2021-05-28 02:06:09,982 epoch 19 - iter 150/254 - loss 0.21007842 - samples/sec: 60.62 - lr: 0.050000
2021-05-28 02:06:23,807 epoch 19 - iter 175/254 - loss 0.21112932 - samples/sec: 57.87 - lr: 0.050000
2021-05-28 02:06:37,001 epoch 19 - iter 200/254 - loss 0.20796197 - samples/sec: 60.64 - lr: 0.050000
2021-05-28 02:06:50,265 epoch 19 - iter 225/254 - loss 0.21038649 - samples/sec: 60.32 - lr: 0.050000
2021-05-28 02:07:03,392 epoch 19 - iter 250/254 - loss 0.21319651 - samples/sec: 60.95 - lr: 0.050000
2021-05-28 02:07:05,098 ----------------------------------------------------------------------------------------------------
2021-05-28 02:07:05,098 EPOCH 19 done: loss 0.2123 - lr 0.0500000
2021-05-28 02:07:10,027 DEV : loss 0.1461593061685562 - score 0.9568
2021-05-28 02:07:10,112 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:07:19,616 ----------------------------------------------------------------------------------------------------
2021-05-28 02:07:32,755 epoch 20 - iter 25/254 - loss 0.23272383 - samples/sec: 60.90 - lr: 0.050000
2021-05-28 02:07:45,998 epoch 20 - iter 50/254 - loss 0.21429170 - samples/sec: 60.42 - lr: 0.050000
2021-05-28 02:07:59,197 epoch 20 - iter 75/254 - loss 0.19676999 - samples/sec: 60.61 - lr: 0.050000
2021-05-28 02:08:12,334 epoch 20 - iter 100/254 - loss 0.20796612 - samples/sec: 60.90 - lr: 0.050000
2021-05-28 02:08:25,514 epoch 20 - iter 125/254 - loss 0.21525904 - samples/sec: 60.71 - lr: 0.050000
2021-05-28 02:08:38,743 epoch 20 - iter 150/254 - loss 0.20942997 - samples/sec: 60.48 - lr: 0.050000
2021-05-28 02:08:51,903 epoch 20 - iter 175/254 - loss 0.20449587 - samples/sec: 60.80 - lr: 0.050000
2021-05-28 02:09:05,023 epoch 20 - iter 200/254 - loss 0.19999419 - samples/sec: 60.98 - lr: 0.050000
2021-05-28 02:09:18,089 epoch 20 - iter 225/254 - loss 0.19814171 - samples/sec: 61.24 - lr: 0.050000
2021-05-28 02:09:31,166 epoch 20 - iter 250/254 - loss 0.19725713 - samples/sec: 61.19 - lr: 0.050000
2021-05-28 02:09:32,837 ----------------------------------------------------------------------------------------------------
2021-05-28 02:09:32,837 EPOCH 20 done: loss 0.1961 - lr 0.0500000
2021-05-28 02:09:37,773 DEV : loss 0.18134747445583344 - score 0.943
2021-05-28 02:09:37,859 BAD EPOCHS (no improvement): 1
2021-05-28 02:09:37,859 ----------------------------------------------------------------------------------------------------
2021-05-28 02:09:50,961 epoch 21 - iter 25/254 - loss 0.18396042 - samples/sec: 61.07 - lr: 0.050000
2021-05-28 02:10:04,166 epoch 21 - iter 50/254 - loss 0.21212020 - samples/sec: 60.59 - lr: 0.050000
2021-05-28 02:10:17,385 epoch 21 - iter 75/254 - loss 0.20303340 - samples/sec: 60.53 - lr: 0.050000
2021-05-28 02:10:30,584 epoch 21 - iter 100/254 - loss 0.19356196 - samples/sec: 60.62 - lr: 0.050000
2021-05-28 02:10:43,736 epoch 21 - iter 125/254 - loss 0.19270822 - samples/sec: 60.84 - lr: 0.050000
2021-05-28 02:10:56,980 epoch 21 - iter 150/254 - loss 0.19044032 - samples/sec: 60.41 - lr: 0.050000
2021-05-28 02:11:10,130 epoch 21 - iter 175/254 - loss 0.19513514 - samples/sec: 60.84 - lr: 0.050000
2021-05-28 02:11:23,402 epoch 21 - iter 200/254 - loss 0.19203353 - samples/sec: 60.29 - lr: 0.050000
2021-05-28 02:11:36,629 epoch 21 - iter 225/254 - loss 0.18844699 - samples/sec: 60.49 - lr: 0.050000
2021-05-28 02:11:49,821 epoch 21 - iter 250/254 - loss 0.19189151 - samples/sec: 60.65 - lr: 0.050000
2021-05-28 02:11:51,530 ----------------------------------------------------------------------------------------------------
2021-05-28 02:11:51,531 EPOCH 21 done: loss 0.1926 - lr 0.0500000
2021-05-28 02:11:56,463 DEV : loss 0.14941561222076416 - score 0.9556
2021-05-28 02:11:56,549 BAD EPOCHS (no improvement): 2
2021-05-28 02:11:56,549 ----------------------------------------------------------------------------------------------------
2021-05-28 02:12:09,678 epoch 22 - iter 25/254 - loss 0.19142295 - samples/sec: 60.94 - lr: 0.050000
2021-05-28 02:12:22,893 epoch 22 - iter 50/254 - loss 0.21353293 - samples/sec: 60.55 - lr: 0.050000
2021-05-28 02:12:36,083 epoch 22 - iter 75/254 - loss 0.20364229 - samples/sec: 60.66 - lr: 0.050000
2021-05-28 02:12:49,214 epoch 22 - iter 100/254 - loss 0.20577939 - samples/sec: 60.93 - lr: 0.050000
2021-05-28 02:13:02,394 epoch 22 - iter 125/254 - loss 0.21304737 - samples/sec: 60.71 - lr: 0.050000
2021-05-28 02:13:16,178 epoch 22 - iter 150/254 - loss 0.20966096 - samples/sec: 58.04 - lr: 0.050000
2021-05-28 02:13:29,355 epoch 22 - iter 175/254 - loss 0.20733581 - samples/sec: 60.72 - lr: 0.050000
2021-05-28 02:13:42,519 epoch 22 - iter 200/254 - loss 0.20642446 - samples/sec: 60.78 - lr: 0.050000
2021-05-28 02:13:55,589 epoch 22 - iter 225/254 - loss 0.20948208 - samples/sec: 61.21 - lr: 0.050000
2021-05-28 02:14:08,818 epoch 22 - iter 250/254 - loss 0.20524004 - samples/sec: 60.48 - lr: 0.050000
2021-05-28 02:14:10,500 ----------------------------------------------------------------------------------------------------
2021-05-28 02:14:10,500 EPOCH 22 done: loss 0.2049 - lr 0.0500000
2021-05-28 02:14:15,426 DEV : loss 0.16869793832302094 - score 0.9429
2021-05-28 02:14:15,512 BAD EPOCHS (no improvement): 3
2021-05-28 02:14:15,512 ----------------------------------------------------------------------------------------------------
2021-05-28 02:14:28,679 epoch 23 - iter 25/254 - loss 0.21948052 - samples/sec: 60.77 - lr: 0.050000
2021-05-28 02:14:41,856 epoch 23 - iter 50/254 - loss 0.23192849 - samples/sec: 60.72 - lr: 0.050000
2021-05-28 02:14:54,974 epoch 23 - iter 75/254 - loss 0.22976858 - samples/sec: 60.99 - lr: 0.050000
2021-05-28 02:15:08,206 epoch 23 - iter 100/254 - loss 0.22582105 - samples/sec: 60.47 - lr: 0.050000
2021-05-28 02:15:21,228 epoch 23 - iter 125/254 - loss 0.21456997 - samples/sec: 61.44 - lr: 0.050000
2021-05-28 02:15:34,406 epoch 23 - iter 150/254 - loss 0.21508017 - samples/sec: 60.72 - lr: 0.050000
2021-05-28 02:15:47,564 epoch 23 - iter 175/254 - loss 0.21366602 - samples/sec: 60.81 - lr: 0.050000
2021-05-28 02:16:00,754 epoch 23 - iter 200/254 - loss 0.20760059 - samples/sec: 60.66 - lr: 0.050000
2021-05-28 02:16:13,865 epoch 23 - iter 225/254 - loss 0.20466208 - samples/sec: 61.02 - lr: 0.050000
2021-05-28 02:16:26,970 epoch 23 - iter 250/254 - loss 0.20189461 - samples/sec: 61.05 - lr: 0.050000
2021-05-28 02:16:28,655 ----------------------------------------------------------------------------------------------------
2021-05-28 02:16:28,655 EPOCH 23 done: loss 0.2017 - lr 0.0500000
2021-05-28 02:16:33,586 DEV : loss 0.17377203702926636 - score 0.9484
Epoch    23: reducing learning rate of group 0 to 2.5000e-02.
2021-05-28 02:16:33,672 BAD EPOCHS (no improvement): 4
2021-05-28 02:16:33,673 ----------------------------------------------------------------------------------------------------
2021-05-28 02:16:46,755 epoch 24 - iter 25/254 - loss 0.19764195 - samples/sec: 61.16 - lr: 0.025000
2021-05-28 02:16:59,944 epoch 24 - iter 50/254 - loss 0.17490407 - samples/sec: 60.67 - lr: 0.025000
2021-05-28 02:17:13,128 epoch 24 - iter 75/254 - loss 0.19176700 - samples/sec: 60.69 - lr: 0.025000
2021-05-28 02:17:26,316 epoch 24 - iter 100/254 - loss 0.20216072 - samples/sec: 60.67 - lr: 0.025000
2021-05-28 02:17:39,448 epoch 24 - iter 125/254 - loss 0.20555135 - samples/sec: 60.93 - lr: 0.025000
2021-05-28 02:17:52,573 epoch 24 - iter 150/254 - loss 0.19835096 - samples/sec: 60.96 - lr: 0.025000
2021-05-28 02:18:05,827 epoch 24 - iter 175/254 - loss 0.19508394 - samples/sec: 60.37 - lr: 0.025000
2021-05-28 02:18:19,040 epoch 24 - iter 200/254 - loss 0.19225239 - samples/sec: 60.55 - lr: 0.025000
2021-05-28 02:18:32,252 epoch 24 - iter 225/254 - loss 0.19291947 - samples/sec: 60.56 - lr: 0.025000
2021-05-28 02:18:45,428 epoch 24 - iter 250/254 - loss 0.19459337 - samples/sec: 60.72 - lr: 0.025000
2021-05-28 02:18:47,131 ----------------------------------------------------------------------------------------------------
2021-05-28 02:18:47,131 EPOCH 24 done: loss 0.1931 - lr 0.0250000
2021-05-28 02:18:52,063 DEV : loss 0.19805996119976044 - score 0.9412
2021-05-28 02:18:52,149 BAD EPOCHS (no improvement): 1
2021-05-28 02:18:52,149 ----------------------------------------------------------------------------------------------------
2021-05-28 02:19:05,325 epoch 25 - iter 25/254 - loss 0.15776112 - samples/sec: 60.72 - lr: 0.025000
2021-05-28 02:19:18,521 epoch 25 - iter 50/254 - loss 0.16563039 - samples/sec: 60.63 - lr: 0.025000
2021-05-28 02:19:31,721 epoch 25 - iter 75/254 - loss 0.17403908 - samples/sec: 60.61 - lr: 0.025000
2021-05-28 02:19:44,873 epoch 25 - iter 100/254 - loss 0.16671517 - samples/sec: 60.83 - lr: 0.025000
2021-05-28 02:19:58,086 epoch 25 - iter 125/254 - loss 0.16888755 - samples/sec: 60.56 - lr: 0.025000
2021-05-28 02:20:11,907 epoch 25 - iter 150/254 - loss 0.16923759 - samples/sec: 57.89 - lr: 0.025000
2021-05-28 02:20:25,051 epoch 25 - iter 175/254 - loss 0.17292706 - samples/sec: 60.87 - lr: 0.025000
2021-05-28 02:20:38,249 epoch 25 - iter 200/254 - loss 0.18066663 - samples/sec: 60.63 - lr: 0.025000
2021-05-28 02:20:51,441 epoch 25 - iter 225/254 - loss 0.18423702 - samples/sec: 60.65 - lr: 0.025000
2021-05-28 02:21:04,613 epoch 25 - iter 250/254 - loss 0.18482712 - samples/sec: 60.74 - lr: 0.025000
2021-05-28 02:21:06,317 ----------------------------------------------------------------------------------------------------
2021-05-28 02:21:06,317 EPOCH 25 done: loss 0.1839 - lr 0.0250000
2021-05-28 02:21:11,254 DEV : loss 0.16797208786010742 - score 0.9524
2021-05-28 02:21:11,339 BAD EPOCHS (no improvement): 2
2021-05-28 02:21:11,339 ----------------------------------------------------------------------------------------------------
2021-05-28 02:21:24,476 epoch 26 - iter 25/254 - loss 0.17855698 - samples/sec: 60.91 - lr: 0.025000
2021-05-28 02:21:37,658 epoch 26 - iter 50/254 - loss 0.17963204 - samples/sec: 60.69 - lr: 0.025000
2021-05-28 02:21:50,822 epoch 26 - iter 75/254 - loss 0.17429870 - samples/sec: 60.78 - lr: 0.025000
2021-05-28 02:22:03,875 epoch 26 - iter 100/254 - loss 0.18201809 - samples/sec: 61.29 - lr: 0.025000
2021-05-28 02:22:17,030 epoch 26 - iter 125/254 - loss 0.18189813 - samples/sec: 60.82 - lr: 0.025000
2021-05-28 02:22:30,136 epoch 26 - iter 150/254 - loss 0.18026506 - samples/sec: 61.04 - lr: 0.025000
2021-05-28 02:22:43,324 epoch 26 - iter 175/254 - loss 0.18085463 - samples/sec: 60.67 - lr: 0.025000
2021-05-28 02:22:56,571 epoch 26 - iter 200/254 - loss 0.18067497 - samples/sec: 60.40 - lr: 0.025000
2021-05-28 02:23:09,767 epoch 26 - iter 225/254 - loss 0.18280229 - samples/sec: 60.63 - lr: 0.025000
2021-05-28 02:23:22,966 epoch 26 - iter 250/254 - loss 0.18183570 - samples/sec: 60.62 - lr: 0.025000
2021-05-28 02:23:24,688 ----------------------------------------------------------------------------------------------------
2021-05-28 02:23:24,688 EPOCH 26 done: loss 0.1814 - lr 0.0250000
2021-05-28 02:23:29,627 DEV : loss 0.1912643164396286 - score 0.9474
2021-05-28 02:23:29,713 BAD EPOCHS (no improvement): 3
2021-05-28 02:23:29,713 ----------------------------------------------------------------------------------------------------
2021-05-28 02:23:42,839 epoch 27 - iter 25/254 - loss 0.17608867 - samples/sec: 60.96 - lr: 0.025000
2021-05-28 02:23:55,977 epoch 27 - iter 50/254 - loss 0.17405873 - samples/sec: 60.90 - lr: 0.025000
2021-05-28 02:24:09,106 epoch 27 - iter 75/254 - loss 0.17945232 - samples/sec: 60.94 - lr: 0.025000
2021-05-28 02:24:22,313 epoch 27 - iter 100/254 - loss 0.17455843 - samples/sec: 60.58 - lr: 0.025000
2021-05-28 02:24:35,448 epoch 27 - iter 125/254 - loss 0.18175654 - samples/sec: 60.91 - lr: 0.025000
2021-05-28 02:24:48,538 epoch 27 - iter 150/254 - loss 0.17842516 - samples/sec: 61.12 - lr: 0.025000
2021-05-28 02:25:01,721 epoch 27 - iter 175/254 - loss 0.17867037 - samples/sec: 60.69 - lr: 0.025000
2021-05-28 02:25:14,884 epoch 27 - iter 200/254 - loss 0.17768657 - samples/sec: 60.78 - lr: 0.025000
2021-05-28 02:25:27,977 epoch 27 - iter 225/254 - loss 0.17985616 - samples/sec: 61.11 - lr: 0.025000
2021-05-28 02:25:41,069 epoch 27 - iter 250/254 - loss 0.18304348 - samples/sec: 61.11 - lr: 0.025000
2021-05-28 02:25:42,721 ----------------------------------------------------------------------------------------------------
2021-05-28 02:25:42,722 EPOCH 27 done: loss 0.1829 - lr 0.0250000
2021-05-28 02:25:47,646 DEV : loss 0.1652989238500595 - score 0.9504
Epoch    27: reducing learning rate of group 0 to 1.2500e-02.
2021-05-28 02:25:47,731 BAD EPOCHS (no improvement): 4
2021-05-28 02:25:47,732 ----------------------------------------------------------------------------------------------------
2021-05-28 02:26:00,782 epoch 28 - iter 25/254 - loss 0.13400500 - samples/sec: 61.31 - lr: 0.012500
2021-05-28 02:26:13,865 epoch 28 - iter 50/254 - loss 0.14782775 - samples/sec: 61.16 - lr: 0.012500
2021-05-28 02:26:26,985 epoch 28 - iter 75/254 - loss 0.16623462 - samples/sec: 60.98 - lr: 0.012500
2021-05-28 02:26:39,974 epoch 28 - iter 100/254 - loss 0.16170054 - samples/sec: 61.60 - lr: 0.012500
2021-05-28 02:26:53,079 epoch 28 - iter 125/254 - loss 0.15973743 - samples/sec: 61.05 - lr: 0.012500
2021-05-28 02:27:06,880 epoch 28 - iter 150/254 - loss 0.16033831 - samples/sec: 57.97 - lr: 0.012500
2021-05-28 02:27:20,004 epoch 28 - iter 175/254 - loss 0.16604953 - samples/sec: 60.96 - lr: 0.012500
2021-05-28 02:27:33,116 epoch 28 - iter 200/254 - loss 0.16694932 - samples/sec: 61.02 - lr: 0.012500
2021-05-28 02:27:46,217 epoch 28 - iter 225/254 - loss 0.16230631 - samples/sec: 61.07 - lr: 0.012500
2021-05-28 02:27:59,346 epoch 28 - iter 250/254 - loss 0.16302835 - samples/sec: 60.94 - lr: 0.012500
2021-05-28 02:28:01,008 ----------------------------------------------------------------------------------------------------
2021-05-28 02:28:01,009 EPOCH 28 done: loss 0.1618 - lr 0.0125000
2021-05-28 02:28:05,932 DEV : loss 0.18450920283794403 - score 0.9432
2021-05-28 02:28:06,017 BAD EPOCHS (no improvement): 1
2021-05-28 02:28:06,018 ----------------------------------------------------------------------------------------------------
2021-05-28 02:28:18,927 epoch 29 - iter 25/254 - loss 0.19231357 - samples/sec: 61.98 - lr: 0.012500
2021-05-28 02:28:32,068 epoch 29 - iter 50/254 - loss 0.18766795 - samples/sec: 60.89 - lr: 0.012500
2021-05-28 02:28:45,214 epoch 29 - iter 75/254 - loss 0.18453480 - samples/sec: 60.86 - lr: 0.012500
2021-05-28 02:28:58,460 epoch 29 - iter 100/254 - loss 0.17679463 - samples/sec: 60.40 - lr: 0.012500
2021-05-28 02:29:11,620 epoch 29 - iter 125/254 - loss 0.17687509 - samples/sec: 60.80 - lr: 0.012500
2021-05-28 02:29:24,817 epoch 29 - iter 150/254 - loss 0.17567086 - samples/sec: 60.63 - lr: 0.012500
2021-05-28 02:29:38,111 epoch 29 - iter 175/254 - loss 0.17639122 - samples/sec: 60.18 - lr: 0.012500
2021-05-28 02:29:51,303 epoch 29 - iter 200/254 - loss 0.17580480 - samples/sec: 60.65 - lr: 0.012500
2021-05-28 02:30:04,430 epoch 29 - iter 225/254 - loss 0.17626616 - samples/sec: 60.95 - lr: 0.012500
2021-05-28 02:30:17,697 epoch 29 - iter 250/254 - loss 0.18037267 - samples/sec: 60.31 - lr: 0.012500
2021-05-28 02:30:19,396 ----------------------------------------------------------------------------------------------------
2021-05-28 02:30:19,396 EPOCH 29 done: loss 0.1784 - lr 0.0125000
2021-05-28 02:30:24,319 DEV : loss 0.18847855925559998 - score 0.9407
2021-05-28 02:30:24,404 BAD EPOCHS (no improvement): 2
2021-05-28 02:30:24,405 ----------------------------------------------------------------------------------------------------
2021-05-28 02:30:37,577 epoch 30 - iter 25/254 - loss 0.17773203 - samples/sec: 60.74 - lr: 0.012500
2021-05-28 02:30:50,736 epoch 30 - iter 50/254 - loss 0.17075556 - samples/sec: 60.80 - lr: 0.012500
2021-05-28 02:31:03,895 epoch 30 - iter 75/254 - loss 0.18126686 - samples/sec: 60.80 - lr: 0.012500
2021-05-28 02:31:17,111 epoch 30 - iter 100/254 - loss 0.17265828 - samples/sec: 60.54 - lr: 0.012500
2021-05-28 02:31:30,287 epoch 30 - iter 125/254 - loss 0.17587748 - samples/sec: 60.72 - lr: 0.012500
2021-05-28 02:31:43,504 epoch 30 - iter 150/254 - loss 0.17258091 - samples/sec: 60.54 - lr: 0.012500
2021-05-28 02:31:56,662 epoch 30 - iter 175/254 - loss 0.17121693 - samples/sec: 60.80 - lr: 0.012500
2021-05-28 02:32:09,956 epoch 30 - iter 200/254 - loss 0.17252382 - samples/sec: 60.19 - lr: 0.012500
2021-05-28 02:32:23,188 epoch 30 - iter 225/254 - loss 0.17086654 - samples/sec: 60.46 - lr: 0.012500
2021-05-28 02:32:36,238 epoch 30 - iter 250/254 - loss 0.16995708 - samples/sec: 61.31 - lr: 0.012500
2021-05-28 02:32:37,897 ----------------------------------------------------------------------------------------------------
2021-05-28 02:32:37,897 EPOCH 30 done: loss 0.1691 - lr 0.0125000
2021-05-28 02:32:42,820 DEV : loss 0.1768874228000641 - score 0.9432
2021-05-28 02:32:42,904 BAD EPOCHS (no improvement): 3
2021-05-28 02:32:43,915 ----------------------------------------------------------------------------------------------------
2021-05-28 02:32:43,915 Testing using best model ...
2021-05-28 02:32:43,915 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/eng.rst.rstdt/best-model.pt
2021-05-28 02:33:11,919 0.9388	0.9569	0.9478
2021-05-28 02:33:11,919 
Results:
- F1-score (micro) 0.9478
- F1-score (macro) 0.9478

By class:
SENT       tp: 889 - fp: 58 - fn: 40 - precision: 0.9388 - recall: 0.9569 - f1-score: 0.9478
2021-05-28 02:33:11,919 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/
2021-05-28 02:33:11,944 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc
2021-05-28 02:33:11,944 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/sent_train.txt
2021-05-28 02:33:11,947 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/sent_dev.txt
2021-05-28 02:33:11,947 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/sent_test.txt
Corpus: 1343 train + 158 dev + 161 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-28 02:33:17,244 ----------------------------------------------------------------------------------------------------
2021-05-28 02:33:17,247 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-28 02:33:17,247 ----------------------------------------------------------------------------------------------------
2021-05-28 02:33:17,247 Corpus: "Corpus: 1343 train + 158 dev + 161 test sentences"
2021-05-28 02:33:17,247 ----------------------------------------------------------------------------------------------------
2021-05-28 02:33:17,247 Parameters:
2021-05-28 02:33:17,247  - learning_rate: "0.1"
2021-05-28 02:33:17,247  - mini_batch_size: "32"
2021-05-28 02:33:17,247  - patience: "3"
2021-05-28 02:33:17,247  - anneal_factor: "0.5"
2021-05-28 02:33:17,247  - max_epochs: "30"
2021-05-28 02:33:17,247  - shuffle: "True"
2021-05-28 02:33:17,247  - train_with_dev: "False"
2021-05-28 02:33:17,247  - batch_growth_annealing: "False"
2021-05-28 02:33:17,247 ----------------------------------------------------------------------------------------------------
2021-05-28 02:33:17,247 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc"
2021-05-28 02:33:17,247 ----------------------------------------------------------------------------------------------------
2021-05-28 02:33:17,247 Device: cuda:0
2021-05-28 02:33:17,247 ----------------------------------------------------------------------------------------------------
2021-05-28 02:33:17,247 Embeddings storage mode: cpu
2021-05-28 02:33:17,248 ----------------------------------------------------------------------------------------------------
2021-05-28 02:33:22,560 epoch 1 - iter 4/42 - loss 13.53355432 - samples/sec: 24.10 - lr: 0.100000
2021-05-28 02:33:27,817 epoch 1 - iter 8/42 - loss 10.35974377 - samples/sec: 24.35 - lr: 0.100000
2021-05-28 02:33:33,158 epoch 1 - iter 12/42 - loss 9.07494835 - samples/sec: 23.97 - lr: 0.100000
2021-05-28 02:33:38,467 epoch 1 - iter 16/42 - loss 8.43670583 - samples/sec: 24.11 - lr: 0.100000
2021-05-28 02:33:43,801 epoch 1 - iter 20/42 - loss 7.97646344 - samples/sec: 24.00 - lr: 0.100000
2021-05-28 02:33:49,120 epoch 1 - iter 24/42 - loss 7.49015349 - samples/sec: 24.07 - lr: 0.100000
2021-05-28 02:33:54,458 epoch 1 - iter 28/42 - loss 7.15320247 - samples/sec: 23.98 - lr: 0.100000
2021-05-28 02:33:59,753 epoch 1 - iter 32/42 - loss 6.82816504 - samples/sec: 24.18 - lr: 0.100000
2021-05-28 02:34:05,081 epoch 1 - iter 36/42 - loss 6.53242882 - samples/sec: 24.02 - lr: 0.100000
2021-05-28 02:34:10,392 epoch 1 - iter 40/42 - loss 6.36244512 - samples/sec: 24.10 - lr: 0.100000
2021-05-28 02:34:13,037 ----------------------------------------------------------------------------------------------------
2021-05-28 02:34:13,037 EPOCH 1 done: loss 6.3087 - lr 0.1000000
2021-05-28 02:34:17,211 DEV : loss 2.865086317062378 - score 0.7931
2021-05-28 02:34:17,227 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:34:18,214 ----------------------------------------------------------------------------------------------------
2021-05-28 02:34:20,320 epoch 2 - iter 4/42 - loss 3.44571769 - samples/sec: 60.80 - lr: 0.100000
2021-05-28 02:34:22,438 epoch 2 - iter 8/42 - loss 3.41985717 - samples/sec: 60.47 - lr: 0.100000
2021-05-28 02:34:24,501 epoch 2 - iter 12/42 - loss 3.42523380 - samples/sec: 62.06 - lr: 0.100000
2021-05-28 02:34:26,592 epoch 2 - iter 16/42 - loss 3.37515214 - samples/sec: 61.24 - lr: 0.100000
2021-05-28 02:34:28,648 epoch 2 - iter 20/42 - loss 3.25510469 - samples/sec: 62.26 - lr: 0.100000
2021-05-28 02:34:30,730 epoch 2 - iter 24/42 - loss 3.18644021 - samples/sec: 61.51 - lr: 0.100000
2021-05-28 02:34:32,854 epoch 2 - iter 28/42 - loss 3.06655952 - samples/sec: 60.26 - lr: 0.100000
2021-05-28 02:34:34,925 epoch 2 - iter 32/42 - loss 2.93352571 - samples/sec: 61.85 - lr: 0.100000
2021-05-28 02:34:37,038 epoch 2 - iter 36/42 - loss 2.83756833 - samples/sec: 60.59 - lr: 0.100000
2021-05-28 02:34:39,101 epoch 2 - iter 40/42 - loss 2.70211689 - samples/sec: 62.07 - lr: 0.100000
2021-05-28 02:34:40,152 ----------------------------------------------------------------------------------------------------
2021-05-28 02:34:40,152 EPOCH 2 done: loss 2.6453 - lr 0.1000000
2021-05-28 02:34:41,079 DEV : loss 1.1994256973266602 - score 0.8542
2021-05-28 02:34:41,094 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:34:50,758 ----------------------------------------------------------------------------------------------------
2021-05-28 02:34:52,892 epoch 3 - iter 4/42 - loss 1.67906269 - samples/sec: 59.99 - lr: 0.100000
2021-05-28 02:34:54,992 epoch 3 - iter 8/42 - loss 1.70582560 - samples/sec: 60.97 - lr: 0.100000
2021-05-28 02:34:57,066 epoch 3 - iter 12/42 - loss 1.68709256 - samples/sec: 61.74 - lr: 0.100000
2021-05-28 02:34:59,174 epoch 3 - iter 16/42 - loss 1.79651916 - samples/sec: 60.73 - lr: 0.100000
2021-05-28 02:35:01,308 epoch 3 - iter 20/42 - loss 1.72921928 - samples/sec: 59.99 - lr: 0.100000
2021-05-28 02:35:03,424 epoch 3 - iter 24/42 - loss 1.65074206 - samples/sec: 60.52 - lr: 0.100000
2021-05-28 02:35:05,548 epoch 3 - iter 28/42 - loss 1.61324112 - samples/sec: 60.28 - lr: 0.100000
2021-05-28 02:35:07,668 epoch 3 - iter 32/42 - loss 1.60482519 - samples/sec: 60.38 - lr: 0.100000
2021-05-28 02:35:09,801 epoch 3 - iter 36/42 - loss 1.54331930 - samples/sec: 60.04 - lr: 0.100000
2021-05-28 02:35:11,928 epoch 3 - iter 40/42 - loss 1.53235925 - samples/sec: 60.19 - lr: 0.100000
2021-05-28 02:35:13,004 ----------------------------------------------------------------------------------------------------
2021-05-28 02:35:13,004 EPOCH 3 done: loss 1.5159 - lr 0.1000000
2021-05-28 02:35:13,928 DEV : loss 0.9891360402107239 - score 0.8761
2021-05-28 02:35:13,944 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:35:23,505 ----------------------------------------------------------------------------------------------------
2021-05-28 02:35:25,554 epoch 4 - iter 4/42 - loss 1.35107446 - samples/sec: 62.48 - lr: 0.100000
2021-05-28 02:35:27,647 epoch 4 - iter 8/42 - loss 1.26522799 - samples/sec: 61.19 - lr: 0.100000
2021-05-28 02:35:29,709 epoch 4 - iter 12/42 - loss 1.17937500 - samples/sec: 62.09 - lr: 0.100000
2021-05-28 02:35:31,800 epoch 4 - iter 16/42 - loss 1.17362183 - samples/sec: 61.21 - lr: 0.100000
2021-05-28 02:35:33,940 epoch 4 - iter 20/42 - loss 1.20247744 - samples/sec: 59.85 - lr: 0.100000
2021-05-28 02:35:36,058 epoch 4 - iter 24/42 - loss 1.23281939 - samples/sec: 60.44 - lr: 0.100000
2021-05-28 02:35:38,173 epoch 4 - iter 28/42 - loss 1.20459610 - samples/sec: 60.54 - lr: 0.100000
2021-05-28 02:35:40,295 epoch 4 - iter 32/42 - loss 1.14763403 - samples/sec: 60.33 - lr: 0.100000
2021-05-28 02:35:42,440 epoch 4 - iter 36/42 - loss 1.16098636 - samples/sec: 59.68 - lr: 0.100000
2021-05-28 02:35:44,550 epoch 4 - iter 40/42 - loss 1.18110522 - samples/sec: 60.69 - lr: 0.100000
2021-05-28 02:35:45,621 ----------------------------------------------------------------------------------------------------
2021-05-28 02:35:45,621 EPOCH 4 done: loss 1.1890 - lr 0.1000000
2021-05-28 02:35:49,137 DEV : loss 1.1009019613265991 - score 0.8637
2021-05-28 02:35:49,152 BAD EPOCHS (no improvement): 1
2021-05-28 02:35:49,153 ----------------------------------------------------------------------------------------------------
2021-05-28 02:35:51,235 epoch 5 - iter 4/42 - loss 1.21922177 - samples/sec: 61.48 - lr: 0.100000
2021-05-28 02:35:53,303 epoch 5 - iter 8/42 - loss 1.19485620 - samples/sec: 61.90 - lr: 0.100000
2021-05-28 02:35:55,418 epoch 5 - iter 12/42 - loss 1.27582289 - samples/sec: 60.53 - lr: 0.100000
2021-05-28 02:35:57,523 epoch 5 - iter 16/42 - loss 1.23366340 - samples/sec: 60.84 - lr: 0.100000
2021-05-28 02:35:59,653 epoch 5 - iter 20/42 - loss 1.19170323 - samples/sec: 60.10 - lr: 0.100000
2021-05-28 02:36:01,774 epoch 5 - iter 24/42 - loss 1.15901630 - samples/sec: 60.38 - lr: 0.100000
2021-05-28 02:36:03,863 epoch 5 - iter 28/42 - loss 1.15984738 - samples/sec: 61.30 - lr: 0.100000
2021-05-28 02:36:05,983 epoch 5 - iter 32/42 - loss 1.16633352 - samples/sec: 60.37 - lr: 0.100000
2021-05-28 02:36:08,130 epoch 5 - iter 36/42 - loss 1.13037216 - samples/sec: 59.65 - lr: 0.100000
2021-05-28 02:36:10,254 epoch 5 - iter 40/42 - loss 1.07221595 - samples/sec: 60.28 - lr: 0.100000
2021-05-28 02:36:11,291 ----------------------------------------------------------------------------------------------------
2021-05-28 02:36:11,291 EPOCH 5 done: loss 1.0518 - lr 0.1000000
2021-05-28 02:36:12,216 DEV : loss 1.066408395767212 - score 0.853
2021-05-28 02:36:12,232 BAD EPOCHS (no improvement): 2
2021-05-28 02:36:12,232 ----------------------------------------------------------------------------------------------------
2021-05-28 02:36:14,325 epoch 6 - iter 4/42 - loss 1.02731048 - samples/sec: 61.18 - lr: 0.100000
2021-05-28 02:36:16,462 epoch 6 - iter 8/42 - loss 0.85282367 - samples/sec: 59.91 - lr: 0.100000
2021-05-28 02:36:18,583 epoch 6 - iter 12/42 - loss 1.05801321 - samples/sec: 60.37 - lr: 0.100000
2021-05-28 02:36:20,681 epoch 6 - iter 16/42 - loss 1.07418137 - samples/sec: 61.01 - lr: 0.100000
2021-05-28 02:36:22,789 epoch 6 - iter 20/42 - loss 1.02117783 - samples/sec: 60.75 - lr: 0.100000
2021-05-28 02:36:24,915 epoch 6 - iter 24/42 - loss 1.00324336 - samples/sec: 60.23 - lr: 0.100000
2021-05-28 02:36:27,045 epoch 6 - iter 28/42 - loss 1.00791553 - samples/sec: 60.09 - lr: 0.100000
2021-05-28 02:36:29,152 epoch 6 - iter 32/42 - loss 0.96362838 - samples/sec: 60.78 - lr: 0.100000
2021-05-28 02:36:31,271 epoch 6 - iter 36/42 - loss 0.92326052 - samples/sec: 60.41 - lr: 0.100000
2021-05-28 02:36:33,389 epoch 6 - iter 40/42 - loss 0.89364081 - samples/sec: 60.45 - lr: 0.100000
2021-05-28 02:36:34,411 ----------------------------------------------------------------------------------------------------
2021-05-28 02:36:34,412 EPOCH 6 done: loss 0.8961 - lr 0.1000000
2021-05-28 02:36:35,340 DEV : loss 1.8988970518112183 - score 0.7818
2021-05-28 02:36:35,355 BAD EPOCHS (no improvement): 3
2021-05-28 02:36:35,355 ----------------------------------------------------------------------------------------------------
2021-05-28 02:36:37,468 epoch 7 - iter 4/42 - loss 0.73333122 - samples/sec: 60.61 - lr: 0.100000
2021-05-28 02:36:39,560 epoch 7 - iter 8/42 - loss 0.87721828 - samples/sec: 61.18 - lr: 0.100000
2021-05-28 02:36:41,683 epoch 7 - iter 12/42 - loss 0.90756953 - samples/sec: 60.31 - lr: 0.100000
2021-05-28 02:36:43,819 epoch 7 - iter 16/42 - loss 0.97040757 - samples/sec: 59.96 - lr: 0.100000
2021-05-28 02:36:45,944 epoch 7 - iter 20/42 - loss 0.92372932 - samples/sec: 60.25 - lr: 0.100000
2021-05-28 02:36:48,036 epoch 7 - iter 24/42 - loss 0.88761678 - samples/sec: 61.20 - lr: 0.100000
2021-05-28 02:36:50,154 epoch 7 - iter 28/42 - loss 0.90033381 - samples/sec: 60.45 - lr: 0.100000
2021-05-28 02:36:52,299 epoch 7 - iter 32/42 - loss 0.88278647 - samples/sec: 59.69 - lr: 0.100000
2021-05-28 02:36:54,390 epoch 7 - iter 36/42 - loss 0.89929793 - samples/sec: 61.23 - lr: 0.100000
2021-05-28 02:36:56,482 epoch 7 - iter 40/42 - loss 0.90624460 - samples/sec: 61.20 - lr: 0.100000
2021-05-28 02:36:57,543 ----------------------------------------------------------------------------------------------------
2021-05-28 02:36:57,543 EPOCH 7 done: loss 0.9031 - lr 0.1000000
2021-05-28 02:36:58,470 DEV : loss 0.422518253326416 - score 0.9381
2021-05-28 02:36:58,485 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:37:08,292 ----------------------------------------------------------------------------------------------------
2021-05-28 02:37:10,428 epoch 8 - iter 4/42 - loss 0.38929524 - samples/sec: 59.95 - lr: 0.100000
2021-05-28 02:37:12,559 epoch 8 - iter 8/42 - loss 0.47704872 - samples/sec: 60.08 - lr: 0.100000
2021-05-28 02:37:14,695 epoch 8 - iter 12/42 - loss 0.69532206 - samples/sec: 59.96 - lr: 0.100000
2021-05-28 02:37:16,842 epoch 8 - iter 16/42 - loss 0.86210395 - samples/sec: 59.62 - lr: 0.100000
2021-05-28 02:37:18,950 epoch 8 - iter 20/42 - loss 0.83701660 - samples/sec: 60.74 - lr: 0.100000
2021-05-28 02:37:21,097 epoch 8 - iter 24/42 - loss 0.83151230 - samples/sec: 59.65 - lr: 0.100000
2021-05-28 02:37:23,215 epoch 8 - iter 28/42 - loss 0.80049216 - samples/sec: 60.45 - lr: 0.100000
2021-05-28 02:37:25,320 epoch 8 - iter 32/42 - loss 0.80319577 - samples/sec: 60.83 - lr: 0.100000
2021-05-28 02:37:27,398 epoch 8 - iter 36/42 - loss 0.79534973 - samples/sec: 61.61 - lr: 0.100000
2021-05-28 02:37:29,473 epoch 8 - iter 40/42 - loss 0.82076766 - samples/sec: 61.70 - lr: 0.100000
2021-05-28 02:37:30,497 ----------------------------------------------------------------------------------------------------
2021-05-28 02:37:30,498 EPOCH 8 done: loss 0.8205 - lr 0.1000000
2021-05-28 02:37:31,425 DEV : loss 0.6471636891365051 - score 0.8998
2021-05-28 02:37:31,440 BAD EPOCHS (no improvement): 1
2021-05-28 02:37:31,440 ----------------------------------------------------------------------------------------------------
2021-05-28 02:37:33,514 epoch 9 - iter 4/42 - loss 0.82598498 - samples/sec: 61.76 - lr: 0.100000
2021-05-28 02:37:35,649 epoch 9 - iter 8/42 - loss 0.71156961 - samples/sec: 59.97 - lr: 0.100000
2021-05-28 02:37:37,795 epoch 9 - iter 12/42 - loss 0.91774023 - samples/sec: 59.66 - lr: 0.100000
2021-05-28 02:37:39,863 epoch 9 - iter 16/42 - loss 0.92187874 - samples/sec: 61.91 - lr: 0.100000
2021-05-28 02:37:41,978 epoch 9 - iter 20/42 - loss 0.98766477 - samples/sec: 60.51 - lr: 0.100000
2021-05-28 02:37:44,085 epoch 9 - iter 24/42 - loss 0.93176831 - samples/sec: 60.79 - lr: 0.100000
2021-05-28 02:37:46,180 epoch 9 - iter 28/42 - loss 0.97109298 - samples/sec: 61.11 - lr: 0.100000
2021-05-28 02:37:48,282 epoch 9 - iter 32/42 - loss 0.95052410 - samples/sec: 60.91 - lr: 0.100000
2021-05-28 02:37:50,408 epoch 9 - iter 36/42 - loss 0.91116528 - samples/sec: 60.22 - lr: 0.100000
2021-05-28 02:37:52,524 epoch 9 - iter 40/42 - loss 0.86329924 - samples/sec: 60.52 - lr: 0.100000
2021-05-28 02:37:53,582 ----------------------------------------------------------------------------------------------------
2021-05-28 02:37:53,582 EPOCH 9 done: loss 0.8560 - lr 0.1000000
2021-05-28 02:37:54,508 DEV : loss 0.4197535514831543 - score 0.9333
2021-05-28 02:37:54,523 BAD EPOCHS (no improvement): 2
2021-05-28 02:37:54,523 ----------------------------------------------------------------------------------------------------
2021-05-28 02:37:56,655 epoch 10 - iter 4/42 - loss 0.92434586 - samples/sec: 60.08 - lr: 0.100000
2021-05-28 02:37:58,777 epoch 10 - iter 8/42 - loss 0.73546844 - samples/sec: 60.31 - lr: 0.100000
2021-05-28 02:38:00,873 epoch 10 - iter 12/42 - loss 0.66286123 - samples/sec: 61.09 - lr: 0.100000
2021-05-28 02:38:03,016 epoch 10 - iter 16/42 - loss 0.71683164 - samples/sec: 59.76 - lr: 0.100000
2021-05-28 02:38:05,151 epoch 10 - iter 20/42 - loss 0.75683605 - samples/sec: 59.96 - lr: 0.100000
2021-05-28 02:38:07,276 epoch 10 - iter 24/42 - loss 0.75049740 - samples/sec: 60.25 - lr: 0.100000
2021-05-28 02:38:09,396 epoch 10 - iter 28/42 - loss 0.78245902 - samples/sec: 60.39 - lr: 0.100000
2021-05-28 02:38:11,513 epoch 10 - iter 32/42 - loss 0.79551666 - samples/sec: 60.49 - lr: 0.100000
2021-05-28 02:38:13,637 epoch 10 - iter 36/42 - loss 0.81836961 - samples/sec: 60.27 - lr: 0.100000
2021-05-28 02:38:15,740 epoch 10 - iter 40/42 - loss 0.82091815 - samples/sec: 60.90 - lr: 0.100000
2021-05-28 02:38:16,762 ----------------------------------------------------------------------------------------------------
2021-05-28 02:38:16,762 EPOCH 10 done: loss 0.8096 - lr 0.1000000
2021-05-28 02:38:17,689 DEV : loss 0.8839349746704102 - score 0.8769
2021-05-28 02:38:17,704 BAD EPOCHS (no improvement): 3
2021-05-28 02:38:17,705 ----------------------------------------------------------------------------------------------------
2021-05-28 02:38:19,883 epoch 11 - iter 4/42 - loss 0.82935873 - samples/sec: 58.77 - lr: 0.100000
2021-05-28 02:38:21,952 epoch 11 - iter 8/42 - loss 0.70695001 - samples/sec: 61.88 - lr: 0.100000
2021-05-28 02:38:24,103 epoch 11 - iter 12/42 - loss 0.79868587 - samples/sec: 59.54 - lr: 0.100000
2021-05-28 02:38:26,247 epoch 11 - iter 16/42 - loss 0.76635327 - samples/sec: 59.72 - lr: 0.100000
2021-05-28 02:38:28,338 epoch 11 - iter 20/42 - loss 0.79185578 - samples/sec: 61.22 - lr: 0.100000
2021-05-28 02:38:30,429 epoch 11 - iter 24/42 - loss 0.83321697 - samples/sec: 61.23 - lr: 0.100000
2021-05-28 02:38:32,558 epoch 11 - iter 28/42 - loss 0.87597000 - samples/sec: 60.14 - lr: 0.100000
2021-05-28 02:38:34,654 epoch 11 - iter 32/42 - loss 0.83929387 - samples/sec: 61.11 - lr: 0.100000
2021-05-28 02:38:36,785 epoch 11 - iter 36/42 - loss 0.80707849 - samples/sec: 60.08 - lr: 0.100000
2021-05-28 02:38:38,889 epoch 11 - iter 40/42 - loss 0.77839687 - samples/sec: 60.85 - lr: 0.100000
2021-05-28 02:38:39,944 ----------------------------------------------------------------------------------------------------
2021-05-28 02:38:39,944 EPOCH 11 done: loss 0.7752 - lr 0.1000000
2021-05-28 02:38:40,870 DEV : loss 0.4025132358074188 - score 0.9484
2021-05-28 02:38:40,886 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:38:50,611 ----------------------------------------------------------------------------------------------------
2021-05-28 02:38:52,768 epoch 12 - iter 4/42 - loss 0.75165947 - samples/sec: 59.36 - lr: 0.100000
2021-05-28 02:38:54,884 epoch 12 - iter 8/42 - loss 0.72507612 - samples/sec: 60.51 - lr: 0.100000
2021-05-28 02:38:56,960 epoch 12 - iter 12/42 - loss 0.68736596 - samples/sec: 61.68 - lr: 0.100000
2021-05-28 02:38:59,067 epoch 12 - iter 16/42 - loss 0.74913133 - samples/sec: 60.76 - lr: 0.100000
2021-05-28 02:39:01,189 epoch 12 - iter 20/42 - loss 0.70369785 - samples/sec: 60.35 - lr: 0.100000
2021-05-28 02:39:03,284 epoch 12 - iter 24/42 - loss 0.71046755 - samples/sec: 61.11 - lr: 0.100000
2021-05-28 02:39:05,393 epoch 12 - iter 28/42 - loss 0.69456243 - samples/sec: 60.70 - lr: 0.100000
2021-05-28 02:39:07,538 epoch 12 - iter 32/42 - loss 0.69827659 - samples/sec: 59.68 - lr: 0.100000
2021-05-28 02:39:09,669 epoch 12 - iter 36/42 - loss 0.71017657 - samples/sec: 60.09 - lr: 0.100000
2021-05-28 02:39:11,756 epoch 12 - iter 40/42 - loss 0.71797760 - samples/sec: 61.35 - lr: 0.100000
2021-05-28 02:39:12,810 ----------------------------------------------------------------------------------------------------
2021-05-28 02:39:12,811 EPOCH 12 done: loss 0.7246 - lr 0.1000000
2021-05-28 02:39:13,901 DEV : loss 0.5461057424545288 - score 0.9161
2021-05-28 02:39:13,916 BAD EPOCHS (no improvement): 1
2021-05-28 02:39:13,917 ----------------------------------------------------------------------------------------------------
2021-05-28 02:39:16,044 epoch 13 - iter 4/42 - loss 0.72657861 - samples/sec: 60.18 - lr: 0.100000
2021-05-28 02:39:18,158 epoch 13 - iter 8/42 - loss 0.81875838 - samples/sec: 60.57 - lr: 0.100000
2021-05-28 02:39:20,275 epoch 13 - iter 12/42 - loss 0.77043372 - samples/sec: 60.48 - lr: 0.100000
2021-05-28 02:39:22,413 epoch 13 - iter 16/42 - loss 0.77776029 - samples/sec: 59.88 - lr: 0.100000
2021-05-28 02:39:24,519 epoch 13 - iter 20/42 - loss 0.78915194 - samples/sec: 60.82 - lr: 0.100000
2021-05-28 02:39:26,644 epoch 13 - iter 24/42 - loss 0.83412407 - samples/sec: 60.23 - lr: 0.100000
2021-05-28 02:39:28,714 epoch 13 - iter 28/42 - loss 0.80645526 - samples/sec: 61.87 - lr: 0.100000
2021-05-28 02:39:30,905 epoch 13 - iter 32/42 - loss 0.76446218 - samples/sec: 58.43 - lr: 0.100000
2021-05-28 02:39:33,033 epoch 13 - iter 36/42 - loss 0.78479591 - samples/sec: 60.18 - lr: 0.100000
2021-05-28 02:39:35,130 epoch 13 - iter 40/42 - loss 0.76910744 - samples/sec: 61.03 - lr: 0.100000
2021-05-28 02:39:36,141 ----------------------------------------------------------------------------------------------------
2021-05-28 02:39:36,141 EPOCH 13 done: loss 0.7623 - lr 0.1000000
2021-05-28 02:39:37,069 DEV : loss 0.807891309261322 - score 0.885
2021-05-28 02:39:37,085 BAD EPOCHS (no improvement): 2
2021-05-28 02:39:37,085 ----------------------------------------------------------------------------------------------------
2021-05-28 02:39:39,152 epoch 14 - iter 4/42 - loss 0.71190230 - samples/sec: 61.96 - lr: 0.100000
2021-05-28 02:39:41,276 epoch 14 - iter 8/42 - loss 0.68159092 - samples/sec: 60.26 - lr: 0.100000
2021-05-28 02:39:43,393 epoch 14 - iter 12/42 - loss 0.67310363 - samples/sec: 60.50 - lr: 0.100000
2021-05-28 02:39:45,498 epoch 14 - iter 16/42 - loss 0.71349794 - samples/sec: 60.80 - lr: 0.100000
2021-05-28 02:39:47,653 epoch 14 - iter 20/42 - loss 0.66629628 - samples/sec: 59.42 - lr: 0.100000
2021-05-28 02:39:49,767 epoch 14 - iter 24/42 - loss 0.66263921 - samples/sec: 60.56 - lr: 0.100000
2021-05-28 02:39:51,896 epoch 14 - iter 28/42 - loss 0.70841767 - samples/sec: 60.16 - lr: 0.100000
2021-05-28 02:39:54,014 epoch 14 - iter 32/42 - loss 0.69756265 - samples/sec: 60.46 - lr: 0.100000
2021-05-28 02:39:56,109 epoch 14 - iter 36/42 - loss 0.69122367 - samples/sec: 61.12 - lr: 0.100000
2021-05-28 02:39:58,259 epoch 14 - iter 40/42 - loss 0.70650321 - samples/sec: 59.53 - lr: 0.100000
2021-05-28 02:39:59,281 ----------------------------------------------------------------------------------------------------
2021-05-28 02:39:59,281 EPOCH 14 done: loss 0.6942 - lr 0.1000000
2021-05-28 02:40:00,208 DEV : loss 0.37661629915237427 - score 0.9456
2021-05-28 02:40:00,224 BAD EPOCHS (no improvement): 3
2021-05-28 02:40:00,224 ----------------------------------------------------------------------------------------------------
2021-05-28 02:40:02,388 epoch 15 - iter 4/42 - loss 0.63014135 - samples/sec: 59.18 - lr: 0.100000
2021-05-28 02:40:04,525 epoch 15 - iter 8/42 - loss 0.62495527 - samples/sec: 59.89 - lr: 0.100000
2021-05-28 02:40:06,636 epoch 15 - iter 12/42 - loss 0.75386119 - samples/sec: 60.65 - lr: 0.100000
2021-05-28 02:40:08,749 epoch 15 - iter 16/42 - loss 0.73713506 - samples/sec: 60.61 - lr: 0.100000
2021-05-28 02:40:10,784 epoch 15 - iter 20/42 - loss 0.76495194 - samples/sec: 62.92 - lr: 0.100000
2021-05-28 02:40:12,883 epoch 15 - iter 24/42 - loss 0.75102163 - samples/sec: 60.99 - lr: 0.100000
2021-05-28 02:40:14,978 epoch 15 - iter 28/42 - loss 0.71034065 - samples/sec: 61.12 - lr: 0.100000
2021-05-28 02:40:17,089 epoch 15 - iter 32/42 - loss 0.69627567 - samples/sec: 60.67 - lr: 0.100000
2021-05-28 02:40:19,204 epoch 15 - iter 36/42 - loss 0.68656145 - samples/sec: 60.52 - lr: 0.100000
2021-05-28 02:40:21,316 epoch 15 - iter 40/42 - loss 0.66845467 - samples/sec: 60.64 - lr: 0.100000
2021-05-28 02:40:22,383 ----------------------------------------------------------------------------------------------------
2021-05-28 02:40:22,383 EPOCH 15 done: loss 0.7003 - lr 0.1000000
2021-05-28 02:40:23,309 DEV : loss 0.5348692536354065 - score 0.9203
Epoch    15: reducing learning rate of group 0 to 5.0000e-02.
2021-05-28 02:40:23,325 BAD EPOCHS (no improvement): 4
2021-05-28 02:40:23,325 ----------------------------------------------------------------------------------------------------
2021-05-28 02:40:25,460 epoch 16 - iter 4/42 - loss 0.49570759 - samples/sec: 59.98 - lr: 0.050000
2021-05-28 02:40:27,558 epoch 16 - iter 8/42 - loss 0.44230180 - samples/sec: 61.01 - lr: 0.050000
2021-05-28 02:40:29,663 epoch 16 - iter 12/42 - loss 0.53452618 - samples/sec: 60.82 - lr: 0.050000
2021-05-28 02:40:31,757 epoch 16 - iter 16/42 - loss 0.51944565 - samples/sec: 61.14 - lr: 0.050000
2021-05-28 02:40:33,873 epoch 16 - iter 20/42 - loss 0.53286401 - samples/sec: 60.52 - lr: 0.050000
2021-05-28 02:40:35,998 epoch 16 - iter 24/42 - loss 0.51447626 - samples/sec: 60.26 - lr: 0.050000
2021-05-28 02:40:38,097 epoch 16 - iter 28/42 - loss 0.53585704 - samples/sec: 60.98 - lr: 0.050000
2021-05-28 02:40:40,162 epoch 16 - iter 32/42 - loss 0.55005139 - samples/sec: 62.02 - lr: 0.050000
2021-05-28 02:40:42,306 epoch 16 - iter 36/42 - loss 0.55927568 - samples/sec: 59.72 - lr: 0.050000
2021-05-28 02:40:44,420 epoch 16 - iter 40/42 - loss 0.54514064 - samples/sec: 60.57 - lr: 0.050000
2021-05-28 02:40:45,467 ----------------------------------------------------------------------------------------------------
2021-05-28 02:40:45,467 EPOCH 16 done: loss 0.5430 - lr 0.0500000
2021-05-28 02:40:46,393 DEV : loss 0.3348604440689087 - score 0.9517
2021-05-28 02:40:46,409 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:40:55,745 ----------------------------------------------------------------------------------------------------
2021-05-28 02:40:57,884 epoch 17 - iter 4/42 - loss 0.50144802 - samples/sec: 59.88 - lr: 0.050000
2021-05-28 02:40:59,973 epoch 17 - iter 8/42 - loss 0.50777283 - samples/sec: 61.29 - lr: 0.050000
2021-05-28 02:41:02,092 epoch 17 - iter 12/42 - loss 0.53683898 - samples/sec: 60.41 - lr: 0.050000
2021-05-28 02:41:04,194 epoch 17 - iter 16/42 - loss 0.50036581 - samples/sec: 60.90 - lr: 0.050000
2021-05-28 02:41:06,297 epoch 17 - iter 20/42 - loss 0.49400734 - samples/sec: 60.89 - lr: 0.050000
2021-05-28 02:41:08,417 epoch 17 - iter 24/42 - loss 0.46611406 - samples/sec: 60.40 - lr: 0.050000
2021-05-28 02:41:10,513 epoch 17 - iter 28/42 - loss 0.46756964 - samples/sec: 61.09 - lr: 0.050000
2021-05-28 02:41:12,616 epoch 17 - iter 32/42 - loss 0.46840152 - samples/sec: 60.88 - lr: 0.050000
2021-05-28 02:41:14,751 epoch 17 - iter 36/42 - loss 0.48965992 - samples/sec: 59.98 - lr: 0.050000
2021-05-28 02:41:16,840 epoch 17 - iter 40/42 - loss 0.50841830 - samples/sec: 61.28 - lr: 0.050000
2021-05-28 02:41:17,881 ----------------------------------------------------------------------------------------------------
2021-05-28 02:41:17,881 EPOCH 17 done: loss 0.5119 - lr 0.0500000
2021-05-28 02:41:18,807 DEV : loss 0.3607548773288727 - score 0.9464
2021-05-28 02:41:18,822 BAD EPOCHS (no improvement): 1
2021-05-28 02:41:18,823 ----------------------------------------------------------------------------------------------------
2021-05-28 02:41:20,940 epoch 18 - iter 4/42 - loss 0.43737005 - samples/sec: 60.47 - lr: 0.050000
2021-05-28 02:41:23,052 epoch 18 - iter 8/42 - loss 0.45605706 - samples/sec: 60.64 - lr: 0.050000
2021-05-28 02:41:25,157 epoch 18 - iter 12/42 - loss 0.47809969 - samples/sec: 60.82 - lr: 0.050000
2021-05-28 02:41:27,264 epoch 18 - iter 16/42 - loss 0.48210604 - samples/sec: 60.75 - lr: 0.050000
2021-05-28 02:41:29,400 epoch 18 - iter 20/42 - loss 0.46969853 - samples/sec: 59.96 - lr: 0.050000
2021-05-28 02:41:31,500 epoch 18 - iter 24/42 - loss 0.45886313 - samples/sec: 60.96 - lr: 0.050000
2021-05-28 02:41:33,636 epoch 18 - iter 28/42 - loss 0.49460924 - samples/sec: 59.93 - lr: 0.050000
2021-05-28 02:41:35,892 epoch 18 - iter 32/42 - loss 0.49690203 - samples/sec: 56.77 - lr: 0.050000
2021-05-28 02:41:38,043 epoch 18 - iter 36/42 - loss 0.51036422 - samples/sec: 59.52 - lr: 0.050000
2021-05-28 02:41:40,085 epoch 18 - iter 40/42 - loss 0.50336944 - samples/sec: 62.69 - lr: 0.050000
2021-05-28 02:41:41,089 ----------------------------------------------------------------------------------------------------
2021-05-28 02:41:41,090 EPOCH 18 done: loss 0.4992 - lr 0.0500000
2021-05-28 02:41:42,016 DEV : loss 0.37026721239089966 - score 0.9412
2021-05-28 02:41:42,032 BAD EPOCHS (no improvement): 2
2021-05-28 02:41:42,032 ----------------------------------------------------------------------------------------------------
2021-05-28 02:41:44,153 epoch 19 - iter 4/42 - loss 0.52009042 - samples/sec: 60.37 - lr: 0.050000
2021-05-28 02:41:46,258 epoch 19 - iter 8/42 - loss 0.49268870 - samples/sec: 60.82 - lr: 0.050000
2021-05-28 02:41:48,392 epoch 19 - iter 12/42 - loss 0.51724469 - samples/sec: 60.00 - lr: 0.050000
2021-05-28 02:41:50,506 epoch 19 - iter 16/42 - loss 0.51676676 - samples/sec: 60.56 - lr: 0.050000
2021-05-28 02:41:52,634 epoch 19 - iter 20/42 - loss 0.50621302 - samples/sec: 60.15 - lr: 0.050000
2021-05-28 02:41:54,693 epoch 19 - iter 24/42 - loss 0.50481869 - samples/sec: 62.19 - lr: 0.050000
2021-05-28 02:41:56,790 epoch 19 - iter 28/42 - loss 0.50701930 - samples/sec: 61.06 - lr: 0.050000
2021-05-28 02:41:58,893 epoch 19 - iter 32/42 - loss 0.50133096 - samples/sec: 60.88 - lr: 0.050000
2021-05-28 02:42:00,986 epoch 19 - iter 36/42 - loss 0.48441203 - samples/sec: 61.19 - lr: 0.050000
2021-05-28 02:42:03,079 epoch 19 - iter 40/42 - loss 0.49377786 - samples/sec: 61.16 - lr: 0.050000
2021-05-28 02:42:04,112 ----------------------------------------------------------------------------------------------------
2021-05-28 02:42:04,113 EPOCH 19 done: loss 0.4875 - lr 0.0500000
2021-05-28 02:42:05,040 DEV : loss 0.3174367845058441 - score 0.9517
2021-05-28 02:42:05,055 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:42:14,408 ----------------------------------------------------------------------------------------------------
2021-05-28 02:42:16,498 epoch 20 - iter 4/42 - loss 0.41298620 - samples/sec: 61.27 - lr: 0.050000
2021-05-28 02:42:18,572 epoch 20 - iter 8/42 - loss 0.46568624 - samples/sec: 61.73 - lr: 0.050000
2021-05-28 02:42:20,647 epoch 20 - iter 12/42 - loss 0.49079234 - samples/sec: 61.69 - lr: 0.050000
2021-05-28 02:42:22,731 epoch 20 - iter 16/42 - loss 0.47159971 - samples/sec: 61.44 - lr: 0.050000
2021-05-28 02:42:24,827 epoch 20 - iter 20/42 - loss 0.48127552 - samples/sec: 61.09 - lr: 0.050000
2021-05-28 02:42:26,912 epoch 20 - iter 24/42 - loss 0.47495470 - samples/sec: 61.42 - lr: 0.050000
2021-05-28 02:42:29,037 epoch 20 - iter 28/42 - loss 0.47229869 - samples/sec: 60.23 - lr: 0.050000
2021-05-28 02:42:31,154 epoch 20 - iter 32/42 - loss 0.49380148 - samples/sec: 60.48 - lr: 0.050000
2021-05-28 02:42:33,182 epoch 20 - iter 36/42 - loss 0.48050516 - samples/sec: 63.16 - lr: 0.050000
2021-05-28 02:42:35,279 epoch 20 - iter 40/42 - loss 0.47815305 - samples/sec: 61.05 - lr: 0.050000
2021-05-28 02:42:36,323 ----------------------------------------------------------------------------------------------------
2021-05-28 02:42:36,323 EPOCH 20 done: loss 0.4833 - lr 0.0500000
2021-05-28 02:42:37,253 DEV : loss 0.41200223565101624 - score 0.9333
2021-05-28 02:42:37,268 BAD EPOCHS (no improvement): 1
2021-05-28 02:42:37,268 ----------------------------------------------------------------------------------------------------
2021-05-28 02:42:39,331 epoch 21 - iter 4/42 - loss 0.37713046 - samples/sec: 62.08 - lr: 0.050000
2021-05-28 02:42:41,437 epoch 21 - iter 8/42 - loss 0.40412805 - samples/sec: 60.78 - lr: 0.050000
2021-05-28 02:42:43,529 epoch 21 - iter 12/42 - loss 0.44527406 - samples/sec: 61.22 - lr: 0.050000
2021-05-28 02:42:45,597 epoch 21 - iter 16/42 - loss 0.43829023 - samples/sec: 61.89 - lr: 0.050000
2021-05-28 02:42:47,688 epoch 21 - iter 20/42 - loss 0.46265513 - samples/sec: 61.25 - lr: 0.050000
2021-05-28 02:42:49,782 epoch 21 - iter 24/42 - loss 0.46391792 - samples/sec: 61.13 - lr: 0.050000
2021-05-28 02:42:51,875 epoch 21 - iter 28/42 - loss 0.47706419 - samples/sec: 61.18 - lr: 0.050000
2021-05-28 02:42:53,968 epoch 21 - iter 32/42 - loss 0.46703241 - samples/sec: 61.18 - lr: 0.050000
2021-05-28 02:42:56,092 epoch 21 - iter 36/42 - loss 0.46127045 - samples/sec: 60.28 - lr: 0.050000
2021-05-28 02:42:58,183 epoch 21 - iter 40/42 - loss 0.45773480 - samples/sec: 61.23 - lr: 0.050000
2021-05-28 02:42:59,251 ----------------------------------------------------------------------------------------------------
2021-05-28 02:42:59,251 EPOCH 21 done: loss 0.4568 - lr 0.0500000
2021-05-28 02:43:00,178 DEV : loss 0.44852128624916077 - score 0.9376
2021-05-28 02:43:00,194 BAD EPOCHS (no improvement): 2
2021-05-28 02:43:00,194 ----------------------------------------------------------------------------------------------------
2021-05-28 02:43:02,291 epoch 22 - iter 4/42 - loss 0.54301789 - samples/sec: 61.04 - lr: 0.050000
2021-05-28 02:43:04,578 epoch 22 - iter 8/42 - loss 0.46106824 - samples/sec: 55.99 - lr: 0.050000
2021-05-28 02:43:06,702 epoch 22 - iter 12/42 - loss 0.48595033 - samples/sec: 60.29 - lr: 0.050000
2021-05-28 02:43:08,795 epoch 22 - iter 16/42 - loss 0.49111181 - samples/sec: 61.17 - lr: 0.050000
2021-05-28 02:43:10,885 epoch 22 - iter 20/42 - loss 0.46973523 - samples/sec: 61.24 - lr: 0.050000
2021-05-28 02:43:13,003 epoch 22 - iter 24/42 - loss 0.47083146 - samples/sec: 60.46 - lr: 0.050000
2021-05-28 02:43:15,150 epoch 22 - iter 28/42 - loss 0.43490982 - samples/sec: 59.64 - lr: 0.050000
2021-05-28 02:43:17,279 epoch 22 - iter 32/42 - loss 0.43402028 - samples/sec: 60.13 - lr: 0.050000
2021-05-28 02:43:19,393 epoch 22 - iter 36/42 - loss 0.45019573 - samples/sec: 60.57 - lr: 0.050000
2021-05-28 02:43:21,478 epoch 22 - iter 40/42 - loss 0.45482243 - samples/sec: 61.41 - lr: 0.050000
2021-05-28 02:43:22,493 ----------------------------------------------------------------------------------------------------
2021-05-28 02:43:22,493 EPOCH 22 done: loss 0.4545 - lr 0.0500000
2021-05-28 02:43:23,421 DEV : loss 0.348626047372818 - score 0.9479
2021-05-28 02:43:23,436 BAD EPOCHS (no improvement): 3
2021-05-28 02:43:23,437 ----------------------------------------------------------------------------------------------------
2021-05-28 02:43:25,510 epoch 23 - iter 4/42 - loss 0.52848309 - samples/sec: 61.74 - lr: 0.050000
2021-05-28 02:43:27,579 epoch 23 - iter 8/42 - loss 0.45901694 - samples/sec: 61.89 - lr: 0.050000
2021-05-28 02:43:29,630 epoch 23 - iter 12/42 - loss 0.40513157 - samples/sec: 62.43 - lr: 0.050000
2021-05-28 02:43:31,728 epoch 23 - iter 16/42 - loss 0.40946096 - samples/sec: 61.02 - lr: 0.050000
2021-05-28 02:43:33,852 epoch 23 - iter 20/42 - loss 0.44048306 - samples/sec: 60.28 - lr: 0.050000
2021-05-28 02:43:35,959 epoch 23 - iter 24/42 - loss 0.46626503 - samples/sec: 60.77 - lr: 0.050000
2021-05-28 02:43:38,083 epoch 23 - iter 28/42 - loss 0.46606655 - samples/sec: 60.28 - lr: 0.050000
2021-05-28 02:43:40,168 epoch 23 - iter 32/42 - loss 0.47126205 - samples/sec: 61.40 - lr: 0.050000
2021-05-28 02:43:42,293 epoch 23 - iter 36/42 - loss 0.48956935 - samples/sec: 60.27 - lr: 0.050000
2021-05-28 02:43:44,411 epoch 23 - iter 40/42 - loss 0.47825675 - samples/sec: 60.43 - lr: 0.050000
2021-05-28 02:43:45,472 ----------------------------------------------------------------------------------------------------
2021-05-28 02:43:45,472 EPOCH 23 done: loss 0.4714 - lr 0.0500000
2021-05-28 02:43:46,399 DEV : loss 0.2850024104118347 - score 0.9567
2021-05-28 02:43:46,415 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:43:56,062 ----------------------------------------------------------------------------------------------------
2021-05-28 02:43:58,173 epoch 24 - iter 4/42 - loss 0.57847558 - samples/sec: 60.66 - lr: 0.050000
2021-05-28 02:44:00,301 epoch 24 - iter 8/42 - loss 0.56996202 - samples/sec: 60.17 - lr: 0.050000
2021-05-28 02:44:02,432 epoch 24 - iter 12/42 - loss 0.48615822 - samples/sec: 60.08 - lr: 0.050000
2021-05-28 02:44:04,522 epoch 24 - iter 16/42 - loss 0.47033520 - samples/sec: 61.25 - lr: 0.050000
2021-05-28 02:44:06,624 epoch 24 - iter 20/42 - loss 0.45245528 - samples/sec: 60.93 - lr: 0.050000
2021-05-28 02:44:08,741 epoch 24 - iter 24/42 - loss 0.45354793 - samples/sec: 60.46 - lr: 0.050000
2021-05-28 02:44:10,836 epoch 24 - iter 28/42 - loss 0.44358847 - samples/sec: 61.11 - lr: 0.050000
2021-05-28 02:44:12,958 epoch 24 - iter 32/42 - loss 0.46644590 - samples/sec: 60.35 - lr: 0.050000
2021-05-28 02:44:15,020 epoch 24 - iter 36/42 - loss 0.45516822 - samples/sec: 62.09 - lr: 0.050000
2021-05-28 02:44:17,100 epoch 24 - iter 40/42 - loss 0.44934800 - samples/sec: 61.55 - lr: 0.050000
2021-05-28 02:44:18,162 ----------------------------------------------------------------------------------------------------
2021-05-28 02:44:18,162 EPOCH 24 done: loss 0.4528 - lr 0.0500000
2021-05-28 02:44:19,089 DEV : loss 0.2852533757686615 - score 0.9542
2021-05-28 02:44:19,105 BAD EPOCHS (no improvement): 1
2021-05-28 02:44:19,105 ----------------------------------------------------------------------------------------------------
2021-05-28 02:44:21,213 epoch 25 - iter 4/42 - loss 0.47974618 - samples/sec: 60.76 - lr: 0.050000
2021-05-28 02:44:23,495 epoch 25 - iter 8/42 - loss 0.40624373 - samples/sec: 56.09 - lr: 0.050000
2021-05-28 02:44:25,626 epoch 25 - iter 12/42 - loss 0.47899149 - samples/sec: 60.07 - lr: 0.050000
2021-05-28 02:44:27,727 epoch 25 - iter 16/42 - loss 0.47355466 - samples/sec: 60.96 - lr: 0.050000
2021-05-28 02:44:29,823 epoch 25 - iter 20/42 - loss 0.47881604 - samples/sec: 61.09 - lr: 0.050000
2021-05-28 02:44:31,923 epoch 25 - iter 24/42 - loss 0.47721821 - samples/sec: 60.97 - lr: 0.050000
2021-05-28 02:44:34,020 epoch 25 - iter 28/42 - loss 0.45360425 - samples/sec: 61.04 - lr: 0.050000
2021-05-28 02:44:36,113 epoch 25 - iter 32/42 - loss 0.46284652 - samples/sec: 61.19 - lr: 0.050000
2021-05-28 02:44:38,218 epoch 25 - iter 36/42 - loss 0.45391606 - samples/sec: 60.83 - lr: 0.050000
2021-05-28 02:44:40,283 epoch 25 - iter 40/42 - loss 0.44471209 - samples/sec: 61.99 - lr: 0.050000
2021-05-28 02:44:41,326 ----------------------------------------------------------------------------------------------------
2021-05-28 02:44:41,326 EPOCH 25 done: loss 0.4521 - lr 0.0500000
2021-05-28 02:44:42,252 DEV : loss 0.38097986578941345 - score 0.9379
2021-05-28 02:44:42,267 BAD EPOCHS (no improvement): 2
2021-05-28 02:44:42,267 ----------------------------------------------------------------------------------------------------
2021-05-28 02:44:44,371 epoch 26 - iter 4/42 - loss 0.50640847 - samples/sec: 60.85 - lr: 0.050000
2021-05-28 02:44:46,440 epoch 26 - iter 8/42 - loss 0.49334271 - samples/sec: 61.89 - lr: 0.050000
2021-05-28 02:44:48,545 epoch 26 - iter 12/42 - loss 0.52649638 - samples/sec: 60.82 - lr: 0.050000
2021-05-28 02:44:50,661 epoch 26 - iter 16/42 - loss 0.50387782 - samples/sec: 60.51 - lr: 0.050000
2021-05-28 02:44:52,773 epoch 26 - iter 20/42 - loss 0.48004413 - samples/sec: 60.64 - lr: 0.050000
2021-05-28 02:44:54,856 epoch 26 - iter 24/42 - loss 0.46191903 - samples/sec: 61.46 - lr: 0.050000
2021-05-28 02:44:56,962 epoch 26 - iter 28/42 - loss 0.45863497 - samples/sec: 60.80 - lr: 0.050000
2021-05-28 02:44:59,059 epoch 26 - iter 32/42 - loss 0.45808285 - samples/sec: 61.05 - lr: 0.050000
2021-05-28 02:45:01,192 epoch 26 - iter 36/42 - loss 0.46985233 - samples/sec: 60.01 - lr: 0.050000
2021-05-28 02:45:03,331 epoch 26 - iter 40/42 - loss 0.45055011 - samples/sec: 59.86 - lr: 0.050000
2021-05-28 02:45:04,364 ----------------------------------------------------------------------------------------------------
2021-05-28 02:45:04,365 EPOCH 26 done: loss 0.4430 - lr 0.0500000
2021-05-28 02:45:05,292 DEV : loss 0.27436456084251404 - score 0.9615
2021-05-28 02:45:05,308 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:45:14,818 ----------------------------------------------------------------------------------------------------
2021-05-28 02:45:16,976 epoch 27 - iter 4/42 - loss 0.44117095 - samples/sec: 59.35 - lr: 0.050000
2021-05-28 02:45:19,037 epoch 27 - iter 8/42 - loss 0.38043641 - samples/sec: 62.10 - lr: 0.050000
2021-05-28 02:45:21,104 epoch 27 - iter 12/42 - loss 0.45782856 - samples/sec: 61.95 - lr: 0.050000
2021-05-28 02:45:23,234 epoch 27 - iter 16/42 - loss 0.45624108 - samples/sec: 60.12 - lr: 0.050000
2021-05-28 02:45:25,341 epoch 27 - iter 20/42 - loss 0.43734566 - samples/sec: 60.78 - lr: 0.050000
2021-05-28 02:45:27,394 epoch 27 - iter 24/42 - loss 0.42942924 - samples/sec: 62.36 - lr: 0.050000
2021-05-28 02:45:29,484 epoch 27 - iter 28/42 - loss 0.42904675 - samples/sec: 61.24 - lr: 0.050000
2021-05-28 02:45:31,597 epoch 27 - iter 32/42 - loss 0.44123112 - samples/sec: 60.62 - lr: 0.050000
2021-05-28 02:45:33,751 epoch 27 - iter 36/42 - loss 0.44479854 - samples/sec: 59.43 - lr: 0.050000
2021-05-28 02:45:35,851 epoch 27 - iter 40/42 - loss 0.45506439 - samples/sec: 60.97 - lr: 0.050000
2021-05-28 02:45:36,875 ----------------------------------------------------------------------------------------------------
2021-05-28 02:45:36,876 EPOCH 27 done: loss 0.4648 - lr 0.0500000
2021-05-28 02:45:37,803 DEV : loss 0.4198726713657379 - score 0.9339
2021-05-28 02:45:37,818 BAD EPOCHS (no improvement): 1
2021-05-28 02:45:37,819 ----------------------------------------------------------------------------------------------------
2021-05-28 02:45:39,968 epoch 28 - iter 4/42 - loss 0.42775096 - samples/sec: 59.57 - lr: 0.050000
2021-05-28 02:45:42,085 epoch 28 - iter 8/42 - loss 0.48994467 - samples/sec: 60.47 - lr: 0.050000
2021-05-28 02:45:44,172 epoch 28 - iter 12/42 - loss 0.47855724 - samples/sec: 61.36 - lr: 0.050000
2021-05-28 02:45:46,252 epoch 28 - iter 16/42 - loss 0.45324854 - samples/sec: 61.55 - lr: 0.050000
2021-05-28 02:45:48,340 epoch 28 - iter 20/42 - loss 0.42999377 - samples/sec: 61.31 - lr: 0.050000
2021-05-28 02:45:50,416 epoch 28 - iter 24/42 - loss 0.45002913 - samples/sec: 61.69 - lr: 0.050000
2021-05-28 02:45:52,534 epoch 28 - iter 28/42 - loss 0.44227257 - samples/sec: 60.44 - lr: 0.050000
2021-05-28 02:45:54,643 epoch 28 - iter 32/42 - loss 0.43360846 - samples/sec: 60.73 - lr: 0.050000
2021-05-28 02:45:56,752 epoch 28 - iter 36/42 - loss 0.43124921 - samples/sec: 60.68 - lr: 0.050000
2021-05-28 02:45:58,887 epoch 28 - iter 40/42 - loss 0.42913833 - samples/sec: 59.99 - lr: 0.050000
2021-05-28 02:45:59,908 ----------------------------------------------------------------------------------------------------
2021-05-28 02:45:59,909 EPOCH 28 done: loss 0.4339 - lr 0.0500000
2021-05-28 02:46:00,835 DEV : loss 0.3887096047401428 - score 0.9442
2021-05-28 02:46:00,851 BAD EPOCHS (no improvement): 2
2021-05-28 02:46:00,851 ----------------------------------------------------------------------------------------------------
2021-05-28 02:46:02,931 epoch 29 - iter 4/42 - loss 0.38937123 - samples/sec: 61.55 - lr: 0.050000
2021-05-28 02:46:05,025 epoch 29 - iter 8/42 - loss 0.44165083 - samples/sec: 61.14 - lr: 0.050000
2021-05-28 02:46:07,126 epoch 29 - iter 12/42 - loss 0.49445913 - samples/sec: 60.95 - lr: 0.050000
2021-05-28 02:46:09,251 epoch 29 - iter 16/42 - loss 0.49570301 - samples/sec: 60.26 - lr: 0.050000
2021-05-28 02:46:11,361 epoch 29 - iter 20/42 - loss 0.47886419 - samples/sec: 60.67 - lr: 0.050000
2021-05-28 02:46:13,435 epoch 29 - iter 24/42 - loss 0.45892636 - samples/sec: 61.74 - lr: 0.050000
2021-05-28 02:46:15,523 epoch 29 - iter 28/42 - loss 0.47524044 - samples/sec: 61.31 - lr: 0.050000
2021-05-28 02:46:17,624 epoch 29 - iter 32/42 - loss 0.48043450 - samples/sec: 60.97 - lr: 0.050000
2021-05-28 02:46:19,746 epoch 29 - iter 36/42 - loss 0.46261169 - samples/sec: 60.33 - lr: 0.050000
2021-05-28 02:46:21,839 epoch 29 - iter 40/42 - loss 0.44386134 - samples/sec: 61.17 - lr: 0.050000
2021-05-28 02:46:22,878 ----------------------------------------------------------------------------------------------------
2021-05-28 02:46:22,879 EPOCH 29 done: loss 0.4468 - lr 0.0500000
2021-05-28 02:46:23,805 DEV : loss 0.9037159085273743 - score 0.8661
2021-05-28 02:46:23,821 BAD EPOCHS (no improvement): 3
2021-05-28 02:46:23,821 ----------------------------------------------------------------------------------------------------
2021-05-28 02:46:25,924 epoch 30 - iter 4/42 - loss 0.31433935 - samples/sec: 60.88 - lr: 0.050000
2021-05-28 02:46:28,009 epoch 30 - iter 8/42 - loss 0.32675491 - samples/sec: 61.42 - lr: 0.050000
2021-05-28 02:46:30,083 epoch 30 - iter 12/42 - loss 0.34147256 - samples/sec: 61.73 - lr: 0.050000
2021-05-28 02:46:32,213 epoch 30 - iter 16/42 - loss 0.36322653 - samples/sec: 60.11 - lr: 0.050000
2021-05-28 02:46:34,266 epoch 30 - iter 20/42 - loss 0.35193244 - samples/sec: 62.36 - lr: 0.050000
2021-05-28 02:46:36,359 epoch 30 - iter 24/42 - loss 0.41635746 - samples/sec: 61.18 - lr: 0.050000
2021-05-28 02:46:38,448 epoch 30 - iter 28/42 - loss 0.42038365 - samples/sec: 61.29 - lr: 0.050000
2021-05-28 02:46:40,597 epoch 30 - iter 32/42 - loss 0.44557994 - samples/sec: 59.56 - lr: 0.050000
2021-05-28 02:46:42,691 epoch 30 - iter 36/42 - loss 0.43925847 - samples/sec: 61.17 - lr: 0.050000
2021-05-28 02:46:44,956 epoch 30 - iter 40/42 - loss 0.44576164 - samples/sec: 56.51 - lr: 0.050000
2021-05-28 02:46:46,028 ----------------------------------------------------------------------------------------------------
2021-05-28 02:46:46,028 EPOCH 30 done: loss 0.4326 - lr 0.0500000
2021-05-28 02:46:46,955 DEV : loss 0.2655670642852783 - score 0.9619
2021-05-28 02:46:46,970 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:46:57,928 ----------------------------------------------------------------------------------------------------
2021-05-28 02:46:57,928 Testing using best model ...
2021-05-28 02:46:57,929 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/deu.rst.pcc/best-model.pt
2021-05-28 02:47:03,477 0.9805	0.9437	0.9617
2021-05-28 02:47:03,478 
Results:
- F1-score (micro) 0.9617
- F1-score (macro) 0.9617

By class:
SENT       tp: 201 - fp: 4 - fn: 12 - precision: 0.9805 - recall: 0.9437 - f1-score: 0.9617
2021-05-28 02:47:03,478 ----------------------------------------------------------------------------------------------------
/home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/
2021-05-28 02:47:03,514 Reading data from /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt
2021-05-28 02:47:03,516 Train: /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/sent_train.txt
2021-05-28 02:47:03,519 Dev: /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/sent_dev.txt
2021-05-28 02:47:03,521 Test: /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/sent_test.txt
Corpus: 10286 train + 1410 dev + 1379 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-05-28 02:47:13,869 ----------------------------------------------------------------------------------------------------
2021-05-28 02:47:13,872 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): DistilBertModel(
        (embeddings): Embeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (transformer): Transformer(
          (layer): ModuleList(
            (0): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (1): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (2): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (3): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (4): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
            (5): TransformerBlock(
              (attention): MultiHeadSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (q_lin): Linear(in_features=768, out_features=768, bias=True)
                (k_lin): Linear(in_features=768, out_features=768, bias=True)
                (v_lin): Linear(in_features=768, out_features=768, bias=True)
                (out_lin): Linear(in_features=768, out_features=768, bias=True)
              )
              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (ffn): FFN(
                (dropout): Dropout(p=0.1, inplace=False)
                (lin1): Linear(in_features=768, out_features=3072, bias=True)
                (lin2): Linear(in_features=3072, out_features=768, bias=True)
              )
              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            )
          )
        )
      )
    )
    (list_embedding_2): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=6194, out_features=6194, bias=True)
  (rnn): LSTM(6194, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-05-28 02:47:13,872 ----------------------------------------------------------------------------------------------------
2021-05-28 02:47:13,872 Corpus: "Corpus: 10286 train + 1410 dev + 1379 test sentences"
2021-05-28 02:47:13,872 ----------------------------------------------------------------------------------------------------
2021-05-28 02:47:13,872 Parameters:
2021-05-28 02:47:13,872  - learning_rate: "0.1"
2021-05-28 02:47:13,872  - mini_batch_size: "32"
2021-05-28 02:47:13,872  - patience: "3"
2021-05-28 02:47:13,872  - anneal_factor: "0.5"
2021-05-28 02:47:13,872  - max_epochs: "30"
2021-05-28 02:47:13,872  - shuffle: "True"
2021-05-28 02:47:13,872  - train_with_dev: "False"
2021-05-28 02:47:13,872  - batch_growth_annealing: "False"
2021-05-28 02:47:13,872 ----------------------------------------------------------------------------------------------------
2021-05-28 02:47:13,872 Model training base path: "/home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt"
2021-05-28 02:47:13,872 ----------------------------------------------------------------------------------------------------
2021-05-28 02:47:13,872 Device: cuda:0
2021-05-28 02:47:13,872 ----------------------------------------------------------------------------------------------------
2021-05-28 02:47:13,872 Embeddings storage mode: cpu
2021-05-28 02:47:13,874 ----------------------------------------------------------------------------------------------------
2021-05-28 02:47:58,462 epoch 1 - iter 32/322 - loss 7.24191079 - samples/sec: 22.97 - lr: 0.100000
2021-05-28 02:48:43,149 epoch 1 - iter 64/322 - loss 5.03425728 - samples/sec: 22.92 - lr: 0.100000
2021-05-28 02:49:27,703 epoch 1 - iter 96/322 - loss 3.96165953 - samples/sec: 22.98 - lr: 0.100000
2021-05-28 02:50:12,836 epoch 1 - iter 128/322 - loss 3.35347492 - samples/sec: 22.69 - lr: 0.100000
2021-05-28 02:50:57,483 epoch 1 - iter 160/322 - loss 2.95778827 - samples/sec: 22.94 - lr: 0.100000
2021-05-28 02:51:42,095 epoch 1 - iter 192/322 - loss 2.64461555 - samples/sec: 22.95 - lr: 0.100000
2021-05-28 02:52:26,659 epoch 1 - iter 224/322 - loss 2.42247832 - samples/sec: 22.98 - lr: 0.100000
2021-05-28 02:53:11,122 epoch 1 - iter 256/322 - loss 2.23665042 - samples/sec: 23.03 - lr: 0.100000
2021-05-28 02:53:55,699 epoch 1 - iter 288/322 - loss 2.09602006 - samples/sec: 22.97 - lr: 0.100000
2021-05-28 02:54:41,011 epoch 1 - iter 320/322 - loss 1.97899677 - samples/sec: 22.60 - lr: 0.100000
2021-05-28 02:54:43,041 ----------------------------------------------------------------------------------------------------
2021-05-28 02:54:43,041 EPOCH 1 done: loss 1.9745 - lr 0.1000000
2021-05-28 02:55:22,543 DEV : loss 0.4493630826473236 - score 0.8973
2021-05-28 02:55:22,686 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:55:23,702 ----------------------------------------------------------------------------------------------------
2021-05-28 02:55:41,234 epoch 2 - iter 32/322 - loss 0.74959924 - samples/sec: 58.42 - lr: 0.100000
2021-05-28 02:55:58,732 epoch 2 - iter 64/322 - loss 0.79680436 - samples/sec: 58.53 - lr: 0.100000
2021-05-28 02:56:16,165 epoch 2 - iter 96/322 - loss 0.84113202 - samples/sec: 58.75 - lr: 0.100000
2021-05-28 02:56:33,687 epoch 2 - iter 128/322 - loss 0.83466721 - samples/sec: 58.45 - lr: 0.100000
2021-05-28 02:56:51,218 epoch 2 - iter 160/322 - loss 0.80237708 - samples/sec: 58.42 - lr: 0.100000
2021-05-28 02:57:08,759 epoch 2 - iter 192/322 - loss 0.76922329 - samples/sec: 58.39 - lr: 0.100000
2021-05-28 02:57:26,297 epoch 2 - iter 224/322 - loss 0.76354491 - samples/sec: 58.39 - lr: 0.100000
2021-05-28 02:57:43,794 epoch 2 - iter 256/322 - loss 0.76468598 - samples/sec: 58.53 - lr: 0.100000
2021-05-28 02:58:01,223 epoch 2 - iter 288/322 - loss 0.75191867 - samples/sec: 58.76 - lr: 0.100000
2021-05-28 02:58:18,673 epoch 2 - iter 320/322 - loss 0.73570358 - samples/sec: 58.69 - lr: 0.100000
2021-05-28 02:58:19,479 ----------------------------------------------------------------------------------------------------
2021-05-28 02:58:19,480 EPOCH 2 done: loss 0.7359 - lr 0.1000000
2021-05-28 02:58:28,076 DEV : loss 0.35553616285324097 - score 0.9203
2021-05-28 02:58:28,220 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 02:58:37,250 ----------------------------------------------------------------------------------------------------
2021-05-28 02:58:54,721 epoch 3 - iter 32/322 - loss 0.52387555 - samples/sec: 58.62 - lr: 0.100000
2021-05-28 02:59:12,215 epoch 3 - iter 64/322 - loss 0.54842493 - samples/sec: 58.54 - lr: 0.100000
2021-05-28 02:59:29,617 epoch 3 - iter 96/322 - loss 0.52578545 - samples/sec: 58.85 - lr: 0.100000
2021-05-28 02:59:47,048 epoch 3 - iter 128/322 - loss 0.56909958 - samples/sec: 58.75 - lr: 0.100000
2021-05-28 03:00:04,572 epoch 3 - iter 160/322 - loss 0.56807037 - samples/sec: 58.44 - lr: 0.100000
2021-05-28 03:00:22,028 epoch 3 - iter 192/322 - loss 0.56143577 - samples/sec: 58.67 - lr: 0.100000
2021-05-28 03:00:40,399 epoch 3 - iter 224/322 - loss 0.55520467 - samples/sec: 55.75 - lr: 0.100000
2021-05-28 03:00:57,919 epoch 3 - iter 256/322 - loss 0.55419220 - samples/sec: 58.45 - lr: 0.100000
2021-05-28 03:01:15,384 epoch 3 - iter 288/322 - loss 0.55661208 - samples/sec: 58.64 - lr: 0.100000
2021-05-28 03:01:32,821 epoch 3 - iter 320/322 - loss 0.54772218 - samples/sec: 58.73 - lr: 0.100000
2021-05-28 03:01:33,650 ----------------------------------------------------------------------------------------------------
2021-05-28 03:01:33,651 EPOCH 3 done: loss 0.5490 - lr 0.1000000
2021-05-28 03:01:42,211 DEV : loss 0.3227651119232178 - score 0.934
2021-05-28 03:01:42,354 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 03:01:51,637 ----------------------------------------------------------------------------------------------------
2021-05-28 03:02:09,161 epoch 4 - iter 32/322 - loss 0.49365093 - samples/sec: 58.44 - lr: 0.100000
2021-05-28 03:02:26,613 epoch 4 - iter 64/322 - loss 0.49925948 - samples/sec: 58.68 - lr: 0.100000
2021-05-28 03:02:44,077 epoch 4 - iter 96/322 - loss 0.49641347 - samples/sec: 58.64 - lr: 0.100000
2021-05-28 03:03:01,573 epoch 4 - iter 128/322 - loss 0.49718064 - samples/sec: 58.53 - lr: 0.100000
2021-05-28 03:03:19,125 epoch 4 - iter 160/322 - loss 0.50643162 - samples/sec: 58.35 - lr: 0.100000
2021-05-28 03:03:36,667 epoch 4 - iter 192/322 - loss 0.50349906 - samples/sec: 58.38 - lr: 0.100000
2021-05-28 03:03:54,220 epoch 4 - iter 224/322 - loss 0.50841269 - samples/sec: 58.34 - lr: 0.100000
2021-05-28 03:04:11,765 epoch 4 - iter 256/322 - loss 0.51234548 - samples/sec: 58.37 - lr: 0.100000
2021-05-28 03:04:29,270 epoch 4 - iter 288/322 - loss 0.51153203 - samples/sec: 58.50 - lr: 0.100000
2021-05-28 03:04:46,709 epoch 4 - iter 320/322 - loss 0.50834382 - samples/sec: 58.73 - lr: 0.100000
2021-05-28 03:04:47,541 ----------------------------------------------------------------------------------------------------
2021-05-28 03:04:47,541 EPOCH 4 done: loss 0.5079 - lr 0.1000000
2021-05-28 03:04:56,098 DEV : loss 0.313581645488739 - score 0.9437
2021-05-28 03:04:56,241 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 03:05:05,611 ----------------------------------------------------------------------------------------------------
2021-05-28 03:05:23,122 epoch 5 - iter 32/322 - loss 0.43722476 - samples/sec: 58.49 - lr: 0.100000
2021-05-28 03:05:40,619 epoch 5 - iter 64/322 - loss 0.43373184 - samples/sec: 58.53 - lr: 0.100000
2021-05-28 03:05:58,162 epoch 5 - iter 96/322 - loss 0.43877378 - samples/sec: 58.38 - lr: 0.100000
2021-05-28 03:06:15,631 epoch 5 - iter 128/322 - loss 0.42244034 - samples/sec: 58.62 - lr: 0.100000
2021-05-28 03:06:33,155 epoch 5 - iter 160/322 - loss 0.41588102 - samples/sec: 58.44 - lr: 0.100000
2021-05-28 03:06:50,675 epoch 5 - iter 192/322 - loss 0.41599361 - samples/sec: 58.45 - lr: 0.100000
2021-05-28 03:07:08,136 epoch 5 - iter 224/322 - loss 0.42282547 - samples/sec: 58.65 - lr: 0.100000
2021-05-28 03:07:25,598 epoch 5 - iter 256/322 - loss 0.42474563 - samples/sec: 58.65 - lr: 0.100000
2021-05-28 03:07:43,069 epoch 5 - iter 288/322 - loss 0.43058695 - samples/sec: 58.62 - lr: 0.100000
2021-05-28 03:08:00,589 epoch 5 - iter 320/322 - loss 0.43016105 - samples/sec: 58.46 - lr: 0.100000
2021-05-28 03:08:01,394 ----------------------------------------------------------------------------------------------------
2021-05-28 03:08:01,394 EPOCH 5 done: loss 0.4295 - lr 0.1000000
2021-05-28 03:08:10,868 DEV : loss 0.27284491062164307 - score 0.9414
2021-05-28 03:08:11,012 BAD EPOCHS (no improvement): 1
2021-05-28 03:08:11,012 ----------------------------------------------------------------------------------------------------
2021-05-28 03:08:28,561 epoch 6 - iter 32/322 - loss 0.39630627 - samples/sec: 58.36 - lr: 0.100000
2021-05-28 03:08:46,046 epoch 6 - iter 64/322 - loss 0.38215778 - samples/sec: 58.57 - lr: 0.100000
2021-05-28 03:09:03,552 epoch 6 - iter 96/322 - loss 0.40383381 - samples/sec: 58.50 - lr: 0.100000
2021-05-28 03:09:21,054 epoch 6 - iter 128/322 - loss 0.38717862 - samples/sec: 58.51 - lr: 0.100000
2021-05-28 03:09:38,490 epoch 6 - iter 160/322 - loss 0.39490826 - samples/sec: 58.74 - lr: 0.100000
2021-05-28 03:09:55,665 epoch 6 - iter 192/322 - loss 0.39637214 - samples/sec: 59.63 - lr: 0.100000
2021-05-28 03:10:12,904 epoch 6 - iter 224/322 - loss 0.40679796 - samples/sec: 59.41 - lr: 0.100000
2021-05-28 03:10:30,117 epoch 6 - iter 256/322 - loss 0.40982603 - samples/sec: 59.50 - lr: 0.100000
2021-05-28 03:10:47,364 epoch 6 - iter 288/322 - loss 0.41037722 - samples/sec: 59.38 - lr: 0.100000
2021-05-28 03:11:04,649 epoch 6 - iter 320/322 - loss 0.41191453 - samples/sec: 59.25 - lr: 0.100000
2021-05-28 03:11:05,459 ----------------------------------------------------------------------------------------------------
2021-05-28 03:11:05,459 EPOCH 6 done: loss 0.4122 - lr 0.1000000
2021-05-28 03:11:14,015 DEV : loss 0.3058234751224518 - score 0.9512
2021-05-28 03:11:14,161 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 03:11:23,183 ----------------------------------------------------------------------------------------------------
2021-05-28 03:11:40,587 epoch 7 - iter 32/322 - loss 0.43373326 - samples/sec: 58.85 - lr: 0.100000
2021-05-28 03:11:57,914 epoch 7 - iter 64/322 - loss 0.45263193 - samples/sec: 59.10 - lr: 0.100000
2021-05-28 03:12:15,301 epoch 7 - iter 96/322 - loss 0.43564196 - samples/sec: 58.90 - lr: 0.100000
2021-05-28 03:12:32,805 epoch 7 - iter 128/322 - loss 0.43052573 - samples/sec: 58.51 - lr: 0.100000
2021-05-28 03:12:50,269 epoch 7 - iter 160/322 - loss 0.42185175 - samples/sec: 58.64 - lr: 0.100000
2021-05-28 03:13:07,741 epoch 7 - iter 192/322 - loss 0.41600958 - samples/sec: 58.62 - lr: 0.100000
2021-05-28 03:13:25,213 epoch 7 - iter 224/322 - loss 0.41238460 - samples/sec: 58.62 - lr: 0.100000
2021-05-28 03:13:42,682 epoch 7 - iter 256/322 - loss 0.39972032 - samples/sec: 58.62 - lr: 0.100000
2021-05-28 03:14:00,209 epoch 7 - iter 288/322 - loss 0.38965834 - samples/sec: 58.43 - lr: 0.100000
2021-05-28 03:14:17,659 epoch 7 - iter 320/322 - loss 0.38319469 - samples/sec: 58.69 - lr: 0.100000
2021-05-28 03:14:18,473 ----------------------------------------------------------------------------------------------------
2021-05-28 03:14:18,473 EPOCH 7 done: loss 0.3820 - lr 0.1000000
2021-05-28 03:14:27,017 DEV : loss 0.2731582820415497 - score 0.9532
2021-05-28 03:14:27,160 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 03:14:36,210 ----------------------------------------------------------------------------------------------------
2021-05-28 03:14:53,548 epoch 8 - iter 32/322 - loss 0.27797380 - samples/sec: 59.07 - lr: 0.100000
2021-05-28 03:15:10,981 epoch 8 - iter 64/322 - loss 0.37060783 - samples/sec: 58.75 - lr: 0.100000
2021-05-28 03:15:28,449 epoch 8 - iter 96/322 - loss 0.37969518 - samples/sec: 58.63 - lr: 0.100000
2021-05-28 03:15:45,884 epoch 8 - iter 128/322 - loss 0.37755416 - samples/sec: 58.74 - lr: 0.100000
2021-05-28 03:16:03,328 epoch 8 - iter 160/322 - loss 0.36677800 - samples/sec: 58.71 - lr: 0.100000
2021-05-28 03:16:20,699 epoch 8 - iter 192/322 - loss 0.37369329 - samples/sec: 58.96 - lr: 0.100000
2021-05-28 03:16:38,112 epoch 8 - iter 224/322 - loss 0.38331177 - samples/sec: 58.81 - lr: 0.100000
2021-05-28 03:16:55,523 epoch 8 - iter 256/322 - loss 0.37895233 - samples/sec: 58.82 - lr: 0.100000
2021-05-28 03:17:13,002 epoch 8 - iter 288/322 - loss 0.37242594 - samples/sec: 58.59 - lr: 0.100000
2021-05-28 03:17:30,482 epoch 8 - iter 320/322 - loss 0.36754917 - samples/sec: 58.59 - lr: 0.100000
2021-05-28 03:17:31,302 ----------------------------------------------------------------------------------------------------
2021-05-28 03:17:31,302 EPOCH 8 done: loss 0.3666 - lr 0.1000000
2021-05-28 03:17:40,748 DEV : loss 0.34028691053390503 - score 0.9451
2021-05-28 03:17:40,892 BAD EPOCHS (no improvement): 1
2021-05-28 03:17:40,892 ----------------------------------------------------------------------------------------------------
2021-05-28 03:17:58,397 epoch 9 - iter 32/322 - loss 0.29471426 - samples/sec: 58.51 - lr: 0.100000
2021-05-28 03:18:15,735 epoch 9 - iter 64/322 - loss 0.31968870 - samples/sec: 59.07 - lr: 0.100000
2021-05-28 03:18:33,060 epoch 9 - iter 96/322 - loss 0.34146538 - samples/sec: 59.11 - lr: 0.100000
2021-05-28 03:18:50,351 epoch 9 - iter 128/322 - loss 0.34062303 - samples/sec: 59.23 - lr: 0.100000
2021-05-28 03:19:07,633 epoch 9 - iter 160/322 - loss 0.34935926 - samples/sec: 59.26 - lr: 0.100000
2021-05-28 03:19:24,878 epoch 9 - iter 192/322 - loss 0.34809010 - samples/sec: 59.39 - lr: 0.100000
2021-05-28 03:19:42,157 epoch 9 - iter 224/322 - loss 0.34711972 - samples/sec: 59.27 - lr: 0.100000
2021-05-28 03:19:59,468 epoch 9 - iter 256/322 - loss 0.35743123 - samples/sec: 59.16 - lr: 0.100000
2021-05-28 03:20:16,730 epoch 9 - iter 288/322 - loss 0.35419550 - samples/sec: 59.33 - lr: 0.100000
2021-05-28 03:20:33,960 epoch 9 - iter 320/322 - loss 0.35120437 - samples/sec: 59.44 - lr: 0.100000
2021-05-28 03:20:34,759 ----------------------------------------------------------------------------------------------------
2021-05-28 03:20:34,759 EPOCH 9 done: loss 0.3515 - lr 0.1000000
2021-05-28 03:20:43,311 DEV : loss 0.2266543060541153 - score 0.9576
2021-05-28 03:20:43,456 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 03:20:52,737 ----------------------------------------------------------------------------------------------------
2021-05-28 03:21:10,237 epoch 10 - iter 32/322 - loss 0.35211390 - samples/sec: 58.53 - lr: 0.100000
2021-05-28 03:21:27,647 epoch 10 - iter 64/322 - loss 0.35915207 - samples/sec: 58.82 - lr: 0.100000
2021-05-28 03:21:45,000 epoch 10 - iter 96/322 - loss 0.35396998 - samples/sec: 59.02 - lr: 0.100000
2021-05-28 03:22:02,575 epoch 10 - iter 128/322 - loss 0.34785534 - samples/sec: 58.27 - lr: 0.100000
2021-05-28 03:22:20,062 epoch 10 - iter 160/322 - loss 0.34736474 - samples/sec: 58.57 - lr: 0.100000
2021-05-28 03:22:37,464 epoch 10 - iter 192/322 - loss 0.34129161 - samples/sec: 58.85 - lr: 0.100000
2021-05-28 03:22:54,999 epoch 10 - iter 224/322 - loss 0.34151654 - samples/sec: 58.41 - lr: 0.100000
2021-05-28 03:23:12,307 epoch 10 - iter 256/322 - loss 0.34818020 - samples/sec: 59.17 - lr: 0.100000
2021-05-28 03:23:29,643 epoch 10 - iter 288/322 - loss 0.34789328 - samples/sec: 59.07 - lr: 0.100000
2021-05-28 03:23:46,846 epoch 10 - iter 320/322 - loss 0.34541722 - samples/sec: 59.53 - lr: 0.100000
2021-05-28 03:23:47,648 ----------------------------------------------------------------------------------------------------
2021-05-28 03:23:47,648 EPOCH 10 done: loss 0.3456 - lr 0.1000000
2021-05-28 03:23:56,187 DEV : loss 0.24644239246845245 - score 0.96
2021-05-28 03:23:56,333 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 03:24:05,743 ----------------------------------------------------------------------------------------------------
2021-05-28 03:24:23,064 epoch 11 - iter 32/322 - loss 0.32631321 - samples/sec: 59.13 - lr: 0.100000
2021-05-28 03:24:40,394 epoch 11 - iter 64/322 - loss 0.32515515 - samples/sec: 59.09 - lr: 0.100000
2021-05-28 03:24:57,695 epoch 11 - iter 96/322 - loss 0.33063366 - samples/sec: 59.19 - lr: 0.100000
2021-05-28 03:25:15,131 epoch 11 - iter 128/322 - loss 0.33256994 - samples/sec: 58.74 - lr: 0.100000
2021-05-28 03:25:32,624 epoch 11 - iter 160/322 - loss 0.33382055 - samples/sec: 58.54 - lr: 0.100000
2021-05-28 03:25:50,125 epoch 11 - iter 192/322 - loss 0.33103517 - samples/sec: 58.52 - lr: 0.100000
2021-05-28 03:26:07,623 epoch 11 - iter 224/322 - loss 0.32477643 - samples/sec: 58.53 - lr: 0.100000
2021-05-28 03:26:25,120 epoch 11 - iter 256/322 - loss 0.32129168 - samples/sec: 58.53 - lr: 0.100000
2021-05-28 03:26:42,595 epoch 11 - iter 288/322 - loss 0.31820228 - samples/sec: 58.60 - lr: 0.100000
2021-05-28 03:27:00,132 epoch 11 - iter 320/322 - loss 0.31427492 - samples/sec: 58.40 - lr: 0.100000
2021-05-28 03:27:00,963 ----------------------------------------------------------------------------------------------------
2021-05-28 03:27:00,963 EPOCH 11 done: loss 0.3139 - lr 0.1000000
2021-05-28 03:27:09,516 DEV : loss 0.2579028606414795 - score 0.9526
2021-05-28 03:27:09,661 BAD EPOCHS (no improvement): 1
2021-05-28 03:27:09,661 ----------------------------------------------------------------------------------------------------
2021-05-28 03:27:27,095 epoch 12 - iter 32/322 - loss 0.36655637 - samples/sec: 58.74 - lr: 0.100000
2021-05-28 03:27:45,364 epoch 12 - iter 64/322 - loss 0.32455268 - samples/sec: 56.06 - lr: 0.100000
2021-05-28 03:28:02,801 epoch 12 - iter 96/322 - loss 0.32248155 - samples/sec: 58.73 - lr: 0.100000
2021-05-28 03:28:20,098 epoch 12 - iter 128/322 - loss 0.32551814 - samples/sec: 59.21 - lr: 0.100000
2021-05-28 03:28:37,383 epoch 12 - iter 160/322 - loss 0.31567335 - samples/sec: 59.25 - lr: 0.100000
2021-05-28 03:28:54,604 epoch 12 - iter 192/322 - loss 0.31213648 - samples/sec: 59.47 - lr: 0.100000
2021-05-28 03:29:11,983 epoch 12 - iter 224/322 - loss 0.31736303 - samples/sec: 58.93 - lr: 0.100000
2021-05-28 03:29:29,407 epoch 12 - iter 256/322 - loss 0.31638567 - samples/sec: 58.78 - lr: 0.100000
2021-05-28 03:29:46,971 epoch 12 - iter 288/322 - loss 0.31323475 - samples/sec: 58.31 - lr: 0.100000
2021-05-28 03:30:04,470 epoch 12 - iter 320/322 - loss 0.31064497 - samples/sec: 58.52 - lr: 0.100000
2021-05-28 03:30:05,292 ----------------------------------------------------------------------------------------------------
2021-05-28 03:30:05,292 EPOCH 12 done: loss 0.3110 - lr 0.1000000
2021-05-28 03:30:13,806 DEV : loss 0.22615808248519897 - score 0.958
2021-05-28 03:30:13,949 BAD EPOCHS (no improvement): 2
2021-05-28 03:30:13,949 ----------------------------------------------------------------------------------------------------
2021-05-28 03:30:31,375 epoch 13 - iter 32/322 - loss 0.29467600 - samples/sec: 58.77 - lr: 0.100000
2021-05-28 03:30:48,860 epoch 13 - iter 64/322 - loss 0.31725936 - samples/sec: 58.57 - lr: 0.100000
2021-05-28 03:31:06,374 epoch 13 - iter 96/322 - loss 0.29951255 - samples/sec: 58.47 - lr: 0.100000
2021-05-28 03:31:23,823 epoch 13 - iter 128/322 - loss 0.29382160 - samples/sec: 58.69 - lr: 0.100000
2021-05-28 03:31:41,289 epoch 13 - iter 160/322 - loss 0.30206533 - samples/sec: 58.63 - lr: 0.100000
2021-05-28 03:31:58,795 epoch 13 - iter 192/322 - loss 0.29804525 - samples/sec: 58.50 - lr: 0.100000
2021-05-28 03:32:16,246 epoch 13 - iter 224/322 - loss 0.29467253 - samples/sec: 58.68 - lr: 0.100000
2021-05-28 03:32:33,666 epoch 13 - iter 256/322 - loss 0.29581819 - samples/sec: 58.79 - lr: 0.100000
2021-05-28 03:32:51,135 epoch 13 - iter 288/322 - loss 0.30148527 - samples/sec: 58.63 - lr: 0.100000
2021-05-28 03:33:08,588 epoch 13 - iter 320/322 - loss 0.30356190 - samples/sec: 58.68 - lr: 0.100000
2021-05-28 03:33:09,401 ----------------------------------------------------------------------------------------------------
2021-05-28 03:33:09,402 EPOCH 13 done: loss 0.3056 - lr 0.1000000
2021-05-28 03:33:17,910 DEV : loss 0.4499908685684204 - score 0.9215
2021-05-28 03:33:18,054 BAD EPOCHS (no improvement): 3
2021-05-28 03:33:18,055 ----------------------------------------------------------------------------------------------------
2021-05-28 03:33:35,474 epoch 14 - iter 32/322 - loss 0.30499327 - samples/sec: 58.79 - lr: 0.100000
2021-05-28 03:33:52,660 epoch 14 - iter 64/322 - loss 0.29347955 - samples/sec: 59.59 - lr: 0.100000
2021-05-28 03:34:10,122 epoch 14 - iter 96/322 - loss 0.30871153 - samples/sec: 58.65 - lr: 0.100000
2021-05-28 03:34:27,545 epoch 14 - iter 128/322 - loss 0.30210917 - samples/sec: 58.78 - lr: 0.100000
2021-05-28 03:34:45,000 epoch 14 - iter 160/322 - loss 0.30235225 - samples/sec: 58.67 - lr: 0.100000
2021-05-28 03:35:02,428 epoch 14 - iter 192/322 - loss 0.29454071 - samples/sec: 58.76 - lr: 0.100000
2021-05-28 03:35:19,884 epoch 14 - iter 224/322 - loss 0.29092521 - samples/sec: 58.67 - lr: 0.100000
2021-05-28 03:35:37,293 epoch 14 - iter 256/322 - loss 0.29572323 - samples/sec: 58.83 - lr: 0.100000
2021-05-28 03:35:54,670 epoch 14 - iter 288/322 - loss 0.30008214 - samples/sec: 58.93 - lr: 0.100000
2021-05-28 03:36:12,139 epoch 14 - iter 320/322 - loss 0.30755293 - samples/sec: 58.63 - lr: 0.100000
2021-05-28 03:36:12,960 ----------------------------------------------------------------------------------------------------
2021-05-28 03:36:12,961 EPOCH 14 done: loss 0.3070 - lr 0.1000000
2021-05-28 03:36:22,390 DEV : loss 0.2420797199010849 - score 0.9606
2021-05-28 03:36:22,536 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 03:36:31,814 ----------------------------------------------------------------------------------------------------
2021-05-28 03:36:49,272 epoch 15 - iter 32/322 - loss 0.27462291 - samples/sec: 58.66 - lr: 0.100000
2021-05-28 03:37:06,727 epoch 15 - iter 64/322 - loss 0.29701743 - samples/sec: 58.67 - lr: 0.100000
2021-05-28 03:37:24,258 epoch 15 - iter 96/322 - loss 0.29800933 - samples/sec: 58.42 - lr: 0.100000
2021-05-28 03:37:41,785 epoch 15 - iter 128/322 - loss 0.28438418 - samples/sec: 58.43 - lr: 0.100000
2021-05-28 03:37:59,326 epoch 15 - iter 160/322 - loss 0.28833973 - samples/sec: 58.38 - lr: 0.100000
2021-05-28 03:38:16,802 epoch 15 - iter 192/322 - loss 0.28897080 - samples/sec: 58.60 - lr: 0.100000
2021-05-28 03:38:34,263 epoch 15 - iter 224/322 - loss 0.28808677 - samples/sec: 58.65 - lr: 0.100000
2021-05-28 03:38:51,768 epoch 15 - iter 256/322 - loss 0.28802555 - samples/sec: 58.50 - lr: 0.100000
2021-05-28 03:39:09,279 epoch 15 - iter 288/322 - loss 0.28890413 - samples/sec: 58.48 - lr: 0.100000
2021-05-28 03:39:26,822 epoch 15 - iter 320/322 - loss 0.28734971 - samples/sec: 58.38 - lr: 0.100000
2021-05-28 03:39:27,643 ----------------------------------------------------------------------------------------------------
2021-05-28 03:39:27,643 EPOCH 15 done: loss 0.2881 - lr 0.1000000
2021-05-28 03:39:36,177 DEV : loss 0.1910487711429596 - score 0.9684
2021-05-28 03:39:36,323 BAD EPOCHS (no improvement): 0
saving best model
2021-05-28 03:39:45,804 ----------------------------------------------------------------------------------------------------
2021-05-28 03:40:03,207 epoch 16 - iter 32/322 - loss 0.28092602 - samples/sec: 58.85 - lr: 0.100000
2021-05-28 03:40:20,665 epoch 16 - iter 64/322 - loss 0.29605958 - samples/sec: 58.66 - lr: 0.100000
2021-05-28 03:40:38,012 epoch 16 - iter 96/322 - loss 0.29145112 - samples/sec: 59.04 - lr: 0.100000
2021-05-28 03:40:55,299 epoch 16 - iter 128/322 - loss 0.29641641 - samples/sec: 59.24 - lr: 0.100000
2021-05-28 03:41:12,594 epoch 16 - iter 160/322 - loss 0.28634766 - samples/sec: 59.22 - lr: 0.100000
2021-05-28 03:41:29,844 epoch 16 - iter 192/322 - loss 0.28234985 - samples/sec: 59.37 - lr: 0.100000
2021-05-28 03:41:47,140 epoch 16 - iter 224/322 - loss 0.28133938 - samples/sec: 59.21 - lr: 0.100000
2021-05-28 03:42:04,431 epoch 16 - iter 256/322 - loss 0.27760356 - samples/sec: 59.23 - lr: 0.100000
2021-05-28 03:42:21,747 epoch 16 - iter 288/322 - loss 0.27325683 - samples/sec: 59.14 - lr: 0.100000
2021-05-28 03:42:38,998 epoch 16 - iter 320/322 - loss 0.27204637 - samples/sec: 59.37 - lr: 0.100000
2021-05-28 03:42:39,818 ----------------------------------------------------------------------------------------------------
2021-05-28 03:42:39,818 EPOCH 16 done: loss 0.2720 - lr 0.1000000
2021-05-28 03:42:48,350 DEV : loss 0.37204617261886597 - score 0.946
2021-05-28 03:42:48,496 BAD EPOCHS (no improvement): 1
2021-05-28 03:42:48,496 ----------------------------------------------------------------------------------------------------
2021-05-28 03:43:05,919 epoch 17 - iter 32/322 - loss 0.32110443 - samples/sec: 58.78 - lr: 0.100000
2021-05-28 03:43:23,398 epoch 17 - iter 64/322 - loss 0.30042849 - samples/sec: 58.59 - lr: 0.100000
2021-05-28 03:43:40,849 epoch 17 - iter 96/322 - loss 0.28840335 - samples/sec: 58.69 - lr: 0.100000
2021-05-28 03:43:58,239 epoch 17 - iter 128/322 - loss 0.29162710 - samples/sec: 58.89 - lr: 0.100000
2021-05-28 03:44:15,647 epoch 17 - iter 160/322 - loss 0.28410089 - samples/sec: 58.83 - lr: 0.100000
2021-05-28 03:44:33,057 epoch 17 - iter 192/322 - loss 0.27954202 - samples/sec: 58.82 - lr: 0.100000
2021-05-28 03:44:50,496 epoch 17 - iter 224/322 - loss 0.28419545 - samples/sec: 58.73 - lr: 0.100000
2021-05-28 03:45:07,952 epoch 17 - iter 256/322 - loss 0.27892116 - samples/sec: 58.67 - lr: 0.100000
2021-05-28 03:45:26,330 epoch 17 - iter 288/322 - loss 0.27832868 - samples/sec: 55.73 - lr: 0.100000
2021-05-28 03:45:43,894 epoch 17 - iter 320/322 - loss 0.28259625 - samples/sec: 58.31 - lr: 0.100000
2021-05-28 03:45:44,714 ----------------------------------------------------------------------------------------------------
2021-05-28 03:45:44,714 EPOCH 17 done: loss 0.2826 - lr 0.1000000
2021-05-28 03:45:53,240 DEV : loss 0.3897242844104767 - score 0.9288
2021-05-28 03:45:53,385 BAD EPOCHS (no improvement): 2
2021-05-28 03:45:53,386 ----------------------------------------------------------------------------------------------------
2021-05-28 03:46:10,866 epoch 18 - iter 32/322 - loss 0.27106317 - samples/sec: 58.59 - lr: 0.100000
2021-05-28 03:46:28,352 epoch 18 - iter 64/322 - loss 0.25581963 - samples/sec: 58.57 - lr: 0.100000
2021-05-28 03:46:45,760 epoch 18 - iter 96/322 - loss 0.26537908 - samples/sec: 58.83 - lr: 0.100000
2021-05-28 03:47:03,195 epoch 18 - iter 128/322 - loss 0.26508433 - samples/sec: 58.74 - lr: 0.100000
2021-05-28 03:47:20,601 epoch 18 - iter 160/322 - loss 0.25928124 - samples/sec: 58.84 - lr: 0.100000
2021-05-28 03:47:38,073 epoch 18 - iter 192/322 - loss 0.25602888 - samples/sec: 58.62 - lr: 0.100000
2021-05-28 03:47:55,463 epoch 18 - iter 224/322 - loss 0.26089194 - samples/sec: 58.89 - lr: 0.100000
2021-05-28 03:48:12,910 epoch 18 - iter 256/322 - loss 0.26060836 - samples/sec: 58.70 - lr: 0.100000
2021-05-28 03:48:30,357 epoch 18 - iter 288/322 - loss 0.26202496 - samples/sec: 58.70 - lr: 0.100000
2021-05-28 03:48:47,867 epoch 18 - iter 320/322 - loss 0.25951945 - samples/sec: 58.49 - lr: 0.100000
2021-05-28 03:48:48,691 ----------------------------------------------------------------------------------------------------
2021-05-28 03:48:48,691 EPOCH 18 done: loss 0.2607 - lr 0.1000000
2021-05-28 03:48:57,221 DEV : loss 0.2195420265197754 - score 0.965
2021-05-28 03:48:57,366 BAD EPOCHS (no improvement): 3
2021-05-28 03:48:57,366 ----------------------------------------------------------------------------------------------------
2021-05-28 03:49:14,749 epoch 19 - iter 32/322 - loss 0.25429879 - samples/sec: 58.92 - lr: 0.100000
2021-05-28 03:49:32,182 epoch 19 - iter 64/322 - loss 0.26976126 - samples/sec: 58.75 - lr: 0.100000
2021-05-28 03:49:49,655 epoch 19 - iter 96/322 - loss 0.27610829 - samples/sec: 58.61 - lr: 0.100000
2021-05-28 03:50:07,091 epoch 19 - iter 128/322 - loss 0.28007627 - samples/sec: 58.74 - lr: 0.100000
2021-05-28 03:50:24,515 epoch 19 - iter 160/322 - loss 0.27563290 - samples/sec: 58.77 - lr: 0.100000
2021-05-28 03:50:41,934 epoch 19 - iter 192/322 - loss 0.26785909 - samples/sec: 58.79 - lr: 0.100000
2021-05-28 03:50:59,287 epoch 19 - iter 224/322 - loss 0.26712793 - samples/sec: 59.02 - lr: 0.100000
2021-05-28 03:51:16,535 epoch 19 - iter 256/322 - loss 0.26570938 - samples/sec: 59.38 - lr: 0.100000
2021-05-28 03:51:33,724 epoch 19 - iter 288/322 - loss 0.26822877 - samples/sec: 59.58 - lr: 0.100000
2021-05-28 03:51:51,040 epoch 19 - iter 320/322 - loss 0.26660524 - samples/sec: 59.15 - lr: 0.100000
2021-05-28 03:51:51,862 ----------------------------------------------------------------------------------------------------
2021-05-28 03:51:51,862 EPOCH 19 done: loss 0.2670 - lr 0.1000000
2021-05-28 03:52:01,304 DEV : loss 0.21963368356227875 - score 0.9609
Epoch    19: reducing learning rate of group 0 to 5.0000e-02.
2021-05-28 03:52:01,449 BAD EPOCHS (no improvement): 4
2021-05-28 03:52:01,450 ----------------------------------------------------------------------------------------------------
2021-05-28 03:52:18,727 epoch 20 - iter 32/322 - loss 0.28121623 - samples/sec: 59.28 - lr: 0.050000
2021-05-28 03:52:35,991 epoch 20 - iter 64/322 - loss 0.26726117 - samples/sec: 59.32 - lr: 0.050000
2021-05-28 03:52:53,292 epoch 20 - iter 96/322 - loss 0.25501527 - samples/sec: 59.19 - lr: 0.050000
2021-05-28 03:53:10,558 epoch 20 - iter 128/322 - loss 0.24957227 - samples/sec: 59.32 - lr: 0.050000
2021-05-28 03:53:27,766 epoch 20 - iter 160/322 - loss 0.24638160 - samples/sec: 59.51 - lr: 0.050000
2021-05-28 03:53:45,030 epoch 20 - iter 192/322 - loss 0.24392010 - samples/sec: 59.32 - lr: 0.050000
2021-05-28 03:54:02,305 epoch 20 - iter 224/322 - loss 0.24174474 - samples/sec: 59.28 - lr: 0.050000
2021-05-28 03:54:19,571 epoch 20 - iter 256/322 - loss 0.24213121 - samples/sec: 59.32 - lr: 0.050000
2021-05-28 03:54:36,880 epoch 20 - iter 288/322 - loss 0.24439555 - samples/sec: 59.16 - lr: 0.050000
2021-05-28 03:54:54,114 epoch 20 - iter 320/322 - loss 0.24343999 - samples/sec: 59.42 - lr: 0.050000
2021-05-28 03:54:54,914 ----------------------------------------------------------------------------------------------------
2021-05-28 03:54:54,914 EPOCH 20 done: loss 0.2460 - lr 0.0500000
2021-05-28 03:55:03,435 DEV : loss 0.22601130604743958 - score 0.9582
2021-05-28 03:55:03,580 BAD EPOCHS (no improvement): 1
2021-05-28 03:55:03,580 ----------------------------------------------------------------------------------------------------
2021-05-28 03:55:20,796 epoch 21 - iter 32/322 - loss 0.21941572 - samples/sec: 59.49 - lr: 0.050000
2021-05-28 03:55:38,140 epoch 21 - iter 64/322 - loss 0.21900786 - samples/sec: 59.05 - lr: 0.050000
2021-05-28 03:55:55,555 epoch 21 - iter 96/322 - loss 0.22954447 - samples/sec: 58.81 - lr: 0.050000
2021-05-28 03:56:13,067 epoch 21 - iter 128/322 - loss 0.23851832 - samples/sec: 58.48 - lr: 0.050000
2021-05-28 03:56:30,504 epoch 21 - iter 160/322 - loss 0.23859131 - samples/sec: 58.73 - lr: 0.050000
2021-05-28 03:56:48,019 epoch 21 - iter 192/322 - loss 0.23677929 - samples/sec: 58.47 - lr: 0.050000
2021-05-28 03:57:05,501 epoch 21 - iter 224/322 - loss 0.23387265 - samples/sec: 58.58 - lr: 0.050000
2021-05-28 03:57:23,036 epoch 21 - iter 256/322 - loss 0.23822041 - samples/sec: 58.40 - lr: 0.050000
2021-05-28 03:57:40,559 epoch 21 - iter 288/322 - loss 0.23601448 - samples/sec: 58.44 - lr: 0.050000
2021-05-28 03:57:58,073 epoch 21 - iter 320/322 - loss 0.23565414 - samples/sec: 58.47 - lr: 0.050000
2021-05-28 03:57:58,898 ----------------------------------------------------------------------------------------------------
2021-05-28 03:57:58,898 EPOCH 21 done: loss 0.2353 - lr 0.0500000
2021-05-28 03:58:08,350 DEV : loss 0.19796359539031982 - score 0.9663
2021-05-28 03:58:08,495 BAD EPOCHS (no improvement): 2
2021-05-28 03:58:08,496 ----------------------------------------------------------------------------------------------------
2021-05-28 03:58:25,973 epoch 22 - iter 32/322 - loss 0.26250817 - samples/sec: 58.60 - lr: 0.050000
2021-05-28 03:58:43,399 epoch 22 - iter 64/322 - loss 0.22582162 - samples/sec: 58.77 - lr: 0.050000
2021-05-28 03:59:00,844 epoch 22 - iter 96/322 - loss 0.21629944 - samples/sec: 58.70 - lr: 0.050000
2021-05-28 03:59:18,312 epoch 22 - iter 128/322 - loss 0.22454880 - samples/sec: 58.63 - lr: 0.050000
2021-05-28 03:59:35,712 epoch 22 - iter 160/322 - loss 0.22243252 - samples/sec: 58.86 - lr: 0.050000
2021-05-28 03:59:53,000 epoch 22 - iter 192/322 - loss 0.22090768 - samples/sec: 59.24 - lr: 0.050000
2021-05-28 04:00:10,308 epoch 22 - iter 224/322 - loss 0.22481098 - samples/sec: 59.17 - lr: 0.050000
2021-05-28 04:00:27,799 epoch 22 - iter 256/322 - loss 0.22625369 - samples/sec: 58.55 - lr: 0.050000
2021-05-28 04:00:45,227 epoch 22 - iter 288/322 - loss 0.22451212 - samples/sec: 58.76 - lr: 0.050000
2021-05-28 04:01:02,587 epoch 22 - iter 320/322 - loss 0.22511122 - samples/sec: 58.99 - lr: 0.050000
2021-05-28 04:01:03,400 ----------------------------------------------------------------------------------------------------
2021-05-28 04:01:03,400 EPOCH 22 done: loss 0.2257 - lr 0.0500000
2021-05-28 04:01:11,930 DEV : loss 0.2567465007305145 - score 0.961
2021-05-28 04:01:12,076 BAD EPOCHS (no improvement): 3
2021-05-28 04:01:12,076 ----------------------------------------------------------------------------------------------------
2021-05-28 04:01:29,427 epoch 23 - iter 32/322 - loss 0.22684345 - samples/sec: 59.02 - lr: 0.050000
2021-05-28 04:01:46,727 epoch 23 - iter 64/322 - loss 0.25050654 - samples/sec: 59.20 - lr: 0.050000
2021-05-28 04:02:04,102 epoch 23 - iter 96/322 - loss 0.23870824 - samples/sec: 58.94 - lr: 0.050000
2021-05-28 04:02:21,534 epoch 23 - iter 128/322 - loss 0.23507204 - samples/sec: 58.75 - lr: 0.050000
2021-05-28 04:02:38,836 epoch 23 - iter 160/322 - loss 0.23184777 - samples/sec: 59.19 - lr: 0.050000
2021-05-28 04:02:56,136 epoch 23 - iter 192/322 - loss 0.23178172 - samples/sec: 59.20 - lr: 0.050000
2021-05-28 04:03:13,538 epoch 23 - iter 224/322 - loss 0.22494810 - samples/sec: 58.85 - lr: 0.050000
2021-05-28 04:03:30,825 epoch 23 - iter 256/322 - loss 0.22191509 - samples/sec: 59.24 - lr: 0.050000
2021-05-28 04:03:48,157 epoch 23 - iter 288/322 - loss 0.22073504 - samples/sec: 59.09 - lr: 0.050000
2021-05-28 04:04:05,562 epoch 23 - iter 320/322 - loss 0.22302994 - samples/sec: 58.84 - lr: 0.050000
2021-05-28 04:04:06,380 ----------------------------------------------------------------------------------------------------
2021-05-28 04:04:06,380 EPOCH 23 done: loss 0.2236 - lr 0.0500000
2021-05-28 04:04:14,901 DEV : loss 0.22533562779426575 - score 0.9648
Epoch    23: reducing learning rate of group 0 to 2.5000e-02.
2021-05-28 04:04:15,047 BAD EPOCHS (no improvement): 4
2021-05-28 04:04:15,047 ----------------------------------------------------------------------------------------------------
2021-05-28 04:04:32,479 epoch 24 - iter 32/322 - loss 0.23630714 - samples/sec: 58.75 - lr: 0.025000
2021-05-28 04:04:49,849 epoch 24 - iter 64/322 - loss 0.22304694 - samples/sec: 58.96 - lr: 0.025000
2021-05-28 04:05:07,261 epoch 24 - iter 96/322 - loss 0.22470107 - samples/sec: 58.82 - lr: 0.025000
2021-05-28 04:05:24,554 epoch 24 - iter 128/322 - loss 0.22509878 - samples/sec: 59.22 - lr: 0.025000
2021-05-28 04:05:41,954 epoch 24 - iter 160/322 - loss 0.23239866 - samples/sec: 58.86 - lr: 0.025000
2021-05-28 04:05:59,372 epoch 24 - iter 192/322 - loss 0.22431520 - samples/sec: 58.79 - lr: 0.025000
2021-05-28 04:06:17,741 epoch 24 - iter 224/322 - loss 0.22204510 - samples/sec: 55.75 - lr: 0.025000
2021-05-28 04:06:35,123 epoch 24 - iter 256/322 - loss 0.21768805 - samples/sec: 58.92 - lr: 0.025000
2021-05-28 04:06:52,419 epoch 24 - iter 288/322 - loss 0.22005948 - samples/sec: 59.21 - lr: 0.025000
2021-05-28 04:07:09,850 epoch 24 - iter 320/322 - loss 0.21638493 - samples/sec: 58.75 - lr: 0.025000
2021-05-28 04:07:10,666 ----------------------------------------------------------------------------------------------------
2021-05-28 04:07:10,666 EPOCH 24 done: loss 0.2159 - lr 0.0250000
2021-05-28 04:07:19,207 DEV : loss 0.24977518618106842 - score 0.9592
2021-05-28 04:07:19,351 BAD EPOCHS (no improvement): 1
2021-05-28 04:07:19,351 ----------------------------------------------------------------------------------------------------
2021-05-28 04:07:36,803 epoch 25 - iter 32/322 - loss 0.18516037 - samples/sec: 58.68 - lr: 0.025000
2021-05-28 04:07:54,243 epoch 25 - iter 64/322 - loss 0.18486159 - samples/sec: 58.72 - lr: 0.025000
2021-05-28 04:08:11,642 epoch 25 - iter 96/322 - loss 0.18591031 - samples/sec: 58.86 - lr: 0.025000
2021-05-28 04:08:29,077 epoch 25 - iter 128/322 - loss 0.19775293 - samples/sec: 58.74 - lr: 0.025000
2021-05-28 04:08:46,497 epoch 25 - iter 160/322 - loss 0.20409326 - samples/sec: 58.79 - lr: 0.025000
2021-05-28 04:09:03,949 epoch 25 - iter 192/322 - loss 0.20917228 - samples/sec: 58.68 - lr: 0.025000
2021-05-28 04:09:21,346 epoch 25 - iter 224/322 - loss 0.21305602 - samples/sec: 58.87 - lr: 0.025000
2021-05-28 04:09:38,782 epoch 25 - iter 256/322 - loss 0.21217580 - samples/sec: 58.73 - lr: 0.025000
2021-05-28 04:09:56,216 epoch 25 - iter 288/322 - loss 0.21372524 - samples/sec: 58.74 - lr: 0.025000
2021-05-28 04:10:13,606 epoch 25 - iter 320/322 - loss 0.21065963 - samples/sec: 58.89 - lr: 0.025000
2021-05-28 04:10:14,428 ----------------------------------------------------------------------------------------------------
2021-05-28 04:10:14,428 EPOCH 25 done: loss 0.2103 - lr 0.0250000
2021-05-28 04:10:22,959 DEV : loss 0.2422282099723816 - score 0.9613
2021-05-28 04:10:23,105 BAD EPOCHS (no improvement): 2
2021-05-28 04:10:23,105 ----------------------------------------------------------------------------------------------------
2021-05-28 04:10:40,536 epoch 26 - iter 32/322 - loss 0.21379234 - samples/sec: 58.75 - lr: 0.025000
2021-05-28 04:10:57,872 epoch 26 - iter 64/322 - loss 0.21123655 - samples/sec: 59.07 - lr: 0.025000
2021-05-28 04:11:15,311 epoch 26 - iter 96/322 - loss 0.21483296 - samples/sec: 58.73 - lr: 0.025000
2021-05-28 04:11:32,767 epoch 26 - iter 128/322 - loss 0.20714801 - samples/sec: 58.67 - lr: 0.025000
2021-05-28 04:11:50,291 epoch 26 - iter 160/322 - loss 0.21184576 - samples/sec: 58.44 - lr: 0.025000
2021-05-28 04:12:07,742 epoch 26 - iter 192/322 - loss 0.20993229 - samples/sec: 58.69 - lr: 0.025000
2021-05-28 04:12:25,282 epoch 26 - iter 224/322 - loss 0.20627894 - samples/sec: 58.39 - lr: 0.025000
2021-05-28 04:12:42,804 epoch 26 - iter 256/322 - loss 0.20477873 - samples/sec: 58.45 - lr: 0.025000
2021-05-28 04:13:00,181 epoch 26 - iter 288/322 - loss 0.20459489 - samples/sec: 58.94 - lr: 0.025000
2021-05-28 04:13:17,437 epoch 26 - iter 320/322 - loss 0.20273586 - samples/sec: 59.35 - lr: 0.025000
2021-05-28 04:13:18,237 ----------------------------------------------------------------------------------------------------
2021-05-28 04:13:18,237 EPOCH 26 done: loss 0.2028 - lr 0.0250000
2021-05-28 04:13:27,674 DEV : loss 0.1993420571088791 - score 0.9672
2021-05-28 04:13:27,818 BAD EPOCHS (no improvement): 3
2021-05-28 04:13:27,818 ----------------------------------------------------------------------------------------------------
2021-05-28 04:13:45,059 epoch 27 - iter 32/322 - loss 0.23556210 - samples/sec: 59.40 - lr: 0.025000
2021-05-28 04:14:02,253 epoch 27 - iter 64/322 - loss 0.20866023 - samples/sec: 59.56 - lr: 0.025000
2021-05-28 04:14:19,453 epoch 27 - iter 96/322 - loss 0.21087294 - samples/sec: 59.54 - lr: 0.025000
2021-05-28 04:14:36,698 epoch 27 - iter 128/322 - loss 0.20721769 - samples/sec: 59.39 - lr: 0.025000
2021-05-28 04:14:54,083 epoch 27 - iter 160/322 - loss 0.21375165 - samples/sec: 58.91 - lr: 0.025000
2021-05-28 04:15:11,516 epoch 27 - iter 192/322 - loss 0.20868113 - samples/sec: 58.75 - lr: 0.025000
2021-05-28 04:15:28,948 epoch 27 - iter 224/322 - loss 0.20740562 - samples/sec: 58.75 - lr: 0.025000
2021-05-28 04:15:46,353 epoch 27 - iter 256/322 - loss 0.20982232 - samples/sec: 58.84 - lr: 0.025000
2021-05-28 04:16:03,826 epoch 27 - iter 288/322 - loss 0.20664441 - samples/sec: 58.61 - lr: 0.025000
2021-05-28 04:16:21,245 epoch 27 - iter 320/322 - loss 0.20350273 - samples/sec: 58.79 - lr: 0.025000
2021-05-28 04:16:22,054 ----------------------------------------------------------------------------------------------------
2021-05-28 04:16:22,054 EPOCH 27 done: loss 0.2030 - lr 0.0250000
2021-05-28 04:16:30,594 DEV : loss 0.20028525590896606 - score 0.9654
Epoch    27: reducing learning rate of group 0 to 1.2500e-02.
2021-05-28 04:16:30,739 BAD EPOCHS (no improvement): 4
2021-05-28 04:16:30,739 ----------------------------------------------------------------------------------------------------
2021-05-28 04:16:48,143 epoch 28 - iter 32/322 - loss 0.18889119 - samples/sec: 58.85 - lr: 0.012500
2021-05-28 04:17:05,610 epoch 28 - iter 64/322 - loss 0.20922922 - samples/sec: 58.63 - lr: 0.012500
2021-05-28 04:17:23,012 epoch 28 - iter 96/322 - loss 0.20697182 - samples/sec: 58.85 - lr: 0.012500
2021-05-28 04:17:40,465 epoch 28 - iter 128/322 - loss 0.21118709 - samples/sec: 58.68 - lr: 0.012500
2021-05-28 04:17:57,905 epoch 28 - iter 160/322 - loss 0.21418039 - samples/sec: 58.72 - lr: 0.012500
2021-05-28 04:18:15,319 epoch 28 - iter 192/322 - loss 0.21210941 - samples/sec: 58.81 - lr: 0.012500
2021-05-28 04:18:32,751 epoch 28 - iter 224/322 - loss 0.21381733 - samples/sec: 58.75 - lr: 0.012500
2021-05-28 04:18:50,202 epoch 28 - iter 256/322 - loss 0.21212328 - samples/sec: 58.69 - lr: 0.012500
2021-05-28 04:19:07,660 epoch 28 - iter 288/322 - loss 0.21239734 - samples/sec: 58.66 - lr: 0.012500
2021-05-28 04:19:25,101 epoch 28 - iter 320/322 - loss 0.21251524 - samples/sec: 58.72 - lr: 0.012500
2021-05-28 04:19:25,920 ----------------------------------------------------------------------------------------------------
2021-05-28 04:19:25,921 EPOCH 28 done: loss 0.2143 - lr 0.0125000
2021-05-28 04:19:34,469 DEV : loss 0.19659452140331268 - score 0.9655
2021-05-28 04:19:34,614 BAD EPOCHS (no improvement): 1
2021-05-28 04:19:34,614 ----------------------------------------------------------------------------------------------------
2021-05-28 04:19:52,084 epoch 29 - iter 32/322 - loss 0.22776876 - samples/sec: 58.62 - lr: 0.012500
2021-05-28 04:20:09,383 epoch 29 - iter 64/322 - loss 0.21617370 - samples/sec: 59.20 - lr: 0.012500
2021-05-28 04:20:26,781 epoch 29 - iter 96/322 - loss 0.20130407 - samples/sec: 58.86 - lr: 0.012500
2021-05-28 04:20:45,008 epoch 29 - iter 128/322 - loss 0.20918414 - samples/sec: 56.19 - lr: 0.012500
2021-05-28 04:21:02,353 epoch 29 - iter 160/322 - loss 0.20487697 - samples/sec: 59.04 - lr: 0.012500
2021-05-28 04:21:19,775 epoch 29 - iter 192/322 - loss 0.20114880 - samples/sec: 58.78 - lr: 0.012500
2021-05-28 04:21:37,041 epoch 29 - iter 224/322 - loss 0.20051806 - samples/sec: 59.31 - lr: 0.012500
2021-05-28 04:21:54,439 epoch 29 - iter 256/322 - loss 0.19298719 - samples/sec: 58.86 - lr: 0.012500
2021-05-28 04:22:11,828 epoch 29 - iter 288/322 - loss 0.19886824 - samples/sec: 58.89 - lr: 0.012500
2021-05-28 04:22:29,226 epoch 29 - iter 320/322 - loss 0.19689641 - samples/sec: 58.86 - lr: 0.012500
2021-05-28 04:22:30,045 ----------------------------------------------------------------------------------------------------
2021-05-28 04:22:30,045 EPOCH 29 done: loss 0.1961 - lr 0.0125000
2021-05-28 04:22:38,582 DEV : loss 0.21263247728347778 - score 0.9631
2021-05-28 04:22:38,727 BAD EPOCHS (no improvement): 2
2021-05-28 04:22:38,727 ----------------------------------------------------------------------------------------------------
2021-05-28 04:22:56,076 epoch 30 - iter 32/322 - loss 0.24602968 - samples/sec: 59.03 - lr: 0.012500
2021-05-28 04:23:13,385 epoch 30 - iter 64/322 - loss 0.23084280 - samples/sec: 59.16 - lr: 0.012500
2021-05-28 04:23:30,749 epoch 30 - iter 96/322 - loss 0.22224031 - samples/sec: 58.98 - lr: 0.012500
2021-05-28 04:23:48,133 epoch 30 - iter 128/322 - loss 0.20659455 - samples/sec: 58.91 - lr: 0.012500
2021-05-28 04:24:05,472 epoch 30 - iter 160/322 - loss 0.20649776 - samples/sec: 59.07 - lr: 0.012500
2021-05-28 04:24:22,821 epoch 30 - iter 192/322 - loss 0.20675290 - samples/sec: 59.03 - lr: 0.012500
2021-05-28 04:24:40,262 epoch 30 - iter 224/322 - loss 0.20496252 - samples/sec: 58.72 - lr: 0.012500
2021-05-28 04:24:57,678 epoch 30 - iter 256/322 - loss 0.20080736 - samples/sec: 58.80 - lr: 0.012500
2021-05-28 04:25:14,986 epoch 30 - iter 288/322 - loss 0.20104871 - samples/sec: 59.17 - lr: 0.012500
2021-05-28 04:25:32,224 epoch 30 - iter 320/322 - loss 0.20181166 - samples/sec: 59.41 - lr: 0.012500
2021-05-28 04:25:33,036 ----------------------------------------------------------------------------------------------------
2021-05-28 04:25:33,037 EPOCH 30 done: loss 0.2018 - lr 0.0125000
2021-05-28 04:25:41,563 DEV : loss 0.20310313999652863 - score 0.9654
2021-05-28 04:25:41,708 BAD EPOCHS (no improvement): 3
2021-05-28 04:25:42,749 ----------------------------------------------------------------------------------------------------
2021-05-28 04:25:42,749 Testing using best model ...
2021-05-28 04:25:42,749 loading file /home/shabnam/data/codes/data/dstrpt/2019-output/rus.rst.rrt/best-model.pt
2021-05-28 04:26:20,346 0.9615	0.9593	0.9604
2021-05-28 04:26:20,346 
Results:
- F1-score (micro) 0.9604
- F1-score (macro) 0.9604

By class:
SENT       tp: 1273 - fp: 51 - fn: 54 - precision: 0.9615 - recall: 0.9593 - f1-score: 0.9604
2021-05-28 04:26:20,346 ----------------------------------------------------------------------------------------------------
