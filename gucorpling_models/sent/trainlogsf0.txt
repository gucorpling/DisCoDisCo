/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.rstdt/
2021-07-22 12:40:10,080 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.rstdt
2021-07-22 12:40:10,081 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.rstdt/sent_train.txt
2021-07-22 12:40:10,081 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.rstdt/sent_dev.txt
2021-07-22 12:40:10,081 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.rstdt/sent_test.txt
Corpus: 17213 train + 2332 dev + 5062 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 12:40:17,039 ----------------------------------------------------------------------------------------------------
2021-07-22 12:40:17,041 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 12:40:17,041 ----------------------------------------------------------------------------------------------------
2021-07-22 12:40:17,041 Corpus: "Corpus: 17213 train + 2332 dev + 5062 test sentences"
2021-07-22 12:40:17,041 ----------------------------------------------------------------------------------------------------
2021-07-22 12:40:17,041 Parameters:
2021-07-22 12:40:17,041  - learning_rate: "3e-05"
2021-07-22 12:40:17,041  - mini_batch_size: "32"
2021-07-22 12:40:17,041  - patience: "3"
2021-07-22 12:40:17,041  - anneal_factor: "0.5"
2021-07-22 12:40:17,041  - max_epochs: "40"
2021-07-22 12:40:17,041  - shuffle: "True"
2021-07-22 12:40:17,042  - train_with_dev: "False"
2021-07-22 12:40:17,042  - batch_growth_annealing: "False"
2021-07-22 12:40:17,042 ----------------------------------------------------------------------------------------------------
2021-07-22 12:40:17,042 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.rstdt"
2021-07-22 12:40:17,042 ----------------------------------------------------------------------------------------------------
2021-07-22 12:40:17,042 Device: cuda:0
2021-07-22 12:40:17,042 ----------------------------------------------------------------------------------------------------
2021-07-22 12:40:17,042 Embeddings storage mode: cpu
2021-07-22 12:40:17,044 ----------------------------------------------------------------------------------------------------
2021-07-22 12:40:46,824 epoch 1 - iter 53/538 - loss 15.43163076 - samples/sec: 56.96 - lr: 0.000030
2021-07-22 12:41:17,516 epoch 1 - iter 106/538 - loss 11.04480835 - samples/sec: 55.26 - lr: 0.000030
2021-07-22 12:41:47,889 epoch 1 - iter 159/538 - loss 7.98546591 - samples/sec: 55.84 - lr: 0.000030
2021-07-22 12:42:18,241 epoch 1 - iter 212/538 - loss 6.19422045 - samples/sec: 55.88 - lr: 0.000030
2021-07-22 12:42:48,497 epoch 1 - iter 265/538 - loss 5.06885606 - samples/sec: 56.06 - lr: 0.000030
2021-07-22 12:43:18,974 epoch 1 - iter 318/538 - loss 4.30114704 - samples/sec: 55.65 - lr: 0.000030
2021-07-22 12:43:49,321 epoch 1 - iter 371/538 - loss 3.74305583 - samples/sec: 55.89 - lr: 0.000030
2021-07-22 12:44:19,917 epoch 1 - iter 424/538 - loss 3.31528240 - samples/sec: 55.44 - lr: 0.000030
2021-07-22 12:44:50,682 epoch 1 - iter 477/538 - loss 2.98265085 - samples/sec: 55.13 - lr: 0.000030
2021-07-22 12:45:21,327 epoch 1 - iter 530/538 - loss 2.71120146 - samples/sec: 55.35 - lr: 0.000030
2021-07-22 12:45:25,948 ----------------------------------------------------------------------------------------------------
2021-07-22 12:45:25,948 EPOCH 1 done: loss 2.6746 - lr 0.0000300
2021-07-22 12:45:56,690 DEV : loss 0.12838631868362427 - score 0.9701
2021-07-22 12:45:56,752 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:45:57,333 ----------------------------------------------------------------------------------------------------
2021-07-22 12:46:09,752 epoch 2 - iter 53/538 - loss 0.29084866 - samples/sec: 136.62 - lr: 0.000030
2021-07-22 12:46:22,263 epoch 2 - iter 106/538 - loss 0.28404857 - samples/sec: 135.59 - lr: 0.000030
2021-07-22 12:46:34,716 epoch 2 - iter 159/538 - loss 0.26164104 - samples/sec: 136.22 - lr: 0.000030
2021-07-22 12:46:47,253 epoch 2 - iter 212/538 - loss 0.25844972 - samples/sec: 135.31 - lr: 0.000030
2021-07-22 12:46:59,815 epoch 2 - iter 265/538 - loss 0.25287854 - samples/sec: 135.04 - lr: 0.000030
2021-07-22 12:47:12,388 epoch 2 - iter 318/538 - loss 0.24713203 - samples/sec: 134.92 - lr: 0.000030
2021-07-22 12:47:24,862 epoch 2 - iter 371/538 - loss 0.24319010 - samples/sec: 135.99 - lr: 0.000030
2021-07-22 12:47:37,646 epoch 2 - iter 424/538 - loss 0.24116801 - samples/sec: 132.69 - lr: 0.000030
2021-07-22 12:47:50,126 epoch 2 - iter 477/538 - loss 0.23988871 - samples/sec: 135.93 - lr: 0.000030
2021-07-22 12:48:02,651 epoch 2 - iter 530/538 - loss 0.23548597 - samples/sec: 135.44 - lr: 0.000030
2021-07-22 12:48:04,448 ----------------------------------------------------------------------------------------------------
2021-07-22 12:48:04,448 EPOCH 2 done: loss 0.2354 - lr 0.0000300
2021-07-22 12:48:09,993 DEV : loss 0.0840492844581604 - score 0.9753
2021-07-22 12:48:10,054 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:48:12,187 ----------------------------------------------------------------------------------------------------
2021-07-22 12:48:24,684 epoch 3 - iter 53/538 - loss 0.19479781 - samples/sec: 135.77 - lr: 0.000030
2021-07-22 12:48:37,319 epoch 3 - iter 106/538 - loss 0.20444781 - samples/sec: 134.26 - lr: 0.000030
2021-07-22 12:48:49,775 epoch 3 - iter 159/538 - loss 0.20611902 - samples/sec: 136.18 - lr: 0.000030
2021-07-22 12:49:02,056 epoch 3 - iter 212/538 - loss 0.20908925 - samples/sec: 138.14 - lr: 0.000030
2021-07-22 12:49:14,707 epoch 3 - iter 265/538 - loss 0.20627784 - samples/sec: 134.09 - lr: 0.000030
2021-07-22 12:49:27,235 epoch 3 - iter 318/538 - loss 0.20536493 - samples/sec: 135.40 - lr: 0.000030
2021-07-22 12:49:39,811 epoch 3 - iter 371/538 - loss 0.20293722 - samples/sec: 134.89 - lr: 0.000030
2021-07-22 12:49:52,437 epoch 3 - iter 424/538 - loss 0.20310148 - samples/sec: 134.36 - lr: 0.000030
2021-07-22 12:50:04,578 epoch 3 - iter 477/538 - loss 0.20167000 - samples/sec: 139.73 - lr: 0.000030
2021-07-22 12:50:17,215 epoch 3 - iter 530/538 - loss 0.20069705 - samples/sec: 134.24 - lr: 0.000030
2021-07-22 12:50:19,025 ----------------------------------------------------------------------------------------------------
2021-07-22 12:50:19,025 EPOCH 3 done: loss 0.2000 - lr 0.0000300
2021-07-22 12:50:24,571 DEV : loss 0.07584420591592789 - score 0.9795
2021-07-22 12:50:24,634 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:50:26,754 ----------------------------------------------------------------------------------------------------
2021-07-22 12:50:39,382 epoch 4 - iter 53/538 - loss 0.15415079 - samples/sec: 134.37 - lr: 0.000030
2021-07-22 12:50:51,740 epoch 4 - iter 106/538 - loss 0.16799563 - samples/sec: 137.26 - lr: 0.000030
2021-07-22 12:51:04,387 epoch 4 - iter 159/538 - loss 0.16963977 - samples/sec: 134.13 - lr: 0.000030
2021-07-22 12:51:17,119 epoch 4 - iter 212/538 - loss 0.17977642 - samples/sec: 133.24 - lr: 0.000030
2021-07-22 12:51:29,651 epoch 4 - iter 265/538 - loss 0.18000558 - samples/sec: 135.36 - lr: 0.000030
2021-07-22 12:51:42,410 epoch 4 - iter 318/538 - loss 0.17432632 - samples/sec: 132.96 - lr: 0.000030
2021-07-22 12:51:54,706 epoch 4 - iter 371/538 - loss 0.17252229 - samples/sec: 137.96 - lr: 0.000030
2021-07-22 12:52:07,260 epoch 4 - iter 424/538 - loss 0.17519395 - samples/sec: 135.13 - lr: 0.000030
2021-07-22 12:52:20,032 epoch 4 - iter 477/538 - loss 0.17981953 - samples/sec: 132.81 - lr: 0.000030
2021-07-22 12:52:32,535 epoch 4 - iter 530/538 - loss 0.18160440 - samples/sec: 135.68 - lr: 0.000030
2021-07-22 12:52:34,557 ----------------------------------------------------------------------------------------------------
2021-07-22 12:52:34,557 EPOCH 4 done: loss 0.1812 - lr 0.0000300
2021-07-22 12:52:40,134 DEV : loss 0.07147429883480072 - score 0.9785
2021-07-22 12:52:40,196 BAD EPOCHS (no improvement): 1
2021-07-22 12:52:40,196 ----------------------------------------------------------------------------------------------------
2021-07-22 12:52:52,828 epoch 5 - iter 53/538 - loss 0.14916172 - samples/sec: 134.31 - lr: 0.000030
2021-07-22 12:53:05,287 epoch 5 - iter 106/538 - loss 0.15982297 - samples/sec: 136.16 - lr: 0.000030
2021-07-22 12:53:17,843 epoch 5 - iter 159/538 - loss 0.16708805 - samples/sec: 135.10 - lr: 0.000030
2021-07-22 12:53:30,552 epoch 5 - iter 212/538 - loss 0.16282278 - samples/sec: 133.48 - lr: 0.000030
2021-07-22 12:53:43,244 epoch 5 - iter 265/538 - loss 0.16146681 - samples/sec: 133.66 - lr: 0.000030
2021-07-22 12:53:55,855 epoch 5 - iter 318/538 - loss 0.16664015 - samples/sec: 134.51 - lr: 0.000030
2021-07-22 12:54:08,576 epoch 5 - iter 371/538 - loss 0.16896540 - samples/sec: 133.35 - lr: 0.000030
2021-07-22 12:54:21,087 epoch 5 - iter 424/538 - loss 0.16988082 - samples/sec: 135.59 - lr: 0.000030
2021-07-22 12:54:33,488 epoch 5 - iter 477/538 - loss 0.16696351 - samples/sec: 136.80 - lr: 0.000030
2021-07-22 12:54:46,356 epoch 5 - iter 530/538 - loss 0.16452695 - samples/sec: 131.83 - lr: 0.000030
2021-07-22 12:54:48,272 ----------------------------------------------------------------------------------------------------
2021-07-22 12:54:48,272 EPOCH 5 done: loss 0.1646 - lr 0.0000300
2021-07-22 12:54:53,853 DEV : loss 0.07452606409788132 - score 0.9788
2021-07-22 12:54:53,915 BAD EPOCHS (no improvement): 2
2021-07-22 12:54:53,916 ----------------------------------------------------------------------------------------------------
2021-07-22 12:55:06,960 epoch 6 - iter 53/538 - loss 0.17729279 - samples/sec: 130.07 - lr: 0.000030
2021-07-22 12:55:19,547 epoch 6 - iter 106/538 - loss 0.18151421 - samples/sec: 134.77 - lr: 0.000030
2021-07-22 12:55:32,043 epoch 6 - iter 159/538 - loss 0.17080508 - samples/sec: 135.75 - lr: 0.000030
2021-07-22 12:55:44,724 epoch 6 - iter 212/538 - loss 0.16941940 - samples/sec: 133.78 - lr: 0.000030
2021-07-22 12:55:57,278 epoch 6 - iter 265/538 - loss 0.17286437 - samples/sec: 135.12 - lr: 0.000030
2021-07-22 12:56:10,080 epoch 6 - iter 318/538 - loss 0.16884243 - samples/sec: 132.50 - lr: 0.000030
2021-07-22 12:56:22,424 epoch 6 - iter 371/538 - loss 0.16696685 - samples/sec: 137.43 - lr: 0.000030
2021-07-22 12:56:35,287 epoch 6 - iter 424/538 - loss 0.16577042 - samples/sec: 131.88 - lr: 0.000030
2021-07-22 12:56:48,135 epoch 6 - iter 477/538 - loss 0.16472984 - samples/sec: 132.03 - lr: 0.000030
2021-07-22 12:57:00,415 epoch 6 - iter 530/538 - loss 0.16195911 - samples/sec: 138.14 - lr: 0.000030
2021-07-22 12:57:02,314 ----------------------------------------------------------------------------------------------------
2021-07-22 12:57:02,314 EPOCH 6 done: loss 0.1622 - lr 0.0000300
2021-07-22 12:57:07,921 DEV : loss 0.07064603269100189 - score 0.9788
2021-07-22 12:57:07,983 BAD EPOCHS (no improvement): 3
2021-07-22 12:57:07,984 ----------------------------------------------------------------------------------------------------
2021-07-22 12:57:20,608 epoch 7 - iter 53/538 - loss 0.16203563 - samples/sec: 134.39 - lr: 0.000030
2021-07-22 12:57:33,091 epoch 7 - iter 106/538 - loss 0.15504949 - samples/sec: 135.89 - lr: 0.000030
2021-07-22 12:57:46,128 epoch 7 - iter 159/538 - loss 0.15393304 - samples/sec: 130.12 - lr: 0.000030
2021-07-22 12:57:58,583 epoch 7 - iter 212/538 - loss 0.15342400 - samples/sec: 136.20 - lr: 0.000030
2021-07-22 12:58:11,205 epoch 7 - iter 265/538 - loss 0.15460063 - samples/sec: 134.40 - lr: 0.000030
2021-07-22 12:58:23,959 epoch 7 - iter 318/538 - loss 0.15749656 - samples/sec: 133.01 - lr: 0.000030
2021-07-22 12:58:36,556 epoch 7 - iter 371/538 - loss 0.15511538 - samples/sec: 134.66 - lr: 0.000030
2021-07-22 12:58:49,112 epoch 7 - iter 424/538 - loss 0.15102185 - samples/sec: 135.10 - lr: 0.000030
2021-07-22 12:59:01,784 epoch 7 - iter 477/538 - loss 0.14955075 - samples/sec: 133.87 - lr: 0.000030
2021-07-22 12:59:14,419 epoch 7 - iter 530/538 - loss 0.14943169 - samples/sec: 134.26 - lr: 0.000030
2021-07-22 12:59:16,196 ----------------------------------------------------------------------------------------------------
2021-07-22 12:59:16,196 EPOCH 7 done: loss 0.1489 - lr 0.0000300
2021-07-22 12:59:21,799 DEV : loss 0.05997951701283455 - score 0.9809
2021-07-22 12:59:21,863 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:59:24,205 ----------------------------------------------------------------------------------------------------
2021-07-22 12:59:36,913 epoch 8 - iter 53/538 - loss 0.14306452 - samples/sec: 133.51 - lr: 0.000030
2021-07-22 12:59:49,552 epoch 8 - iter 106/538 - loss 0.13351185 - samples/sec: 134.22 - lr: 0.000030
2021-07-22 13:00:01,817 epoch 8 - iter 159/538 - loss 0.14296994 - samples/sec: 138.31 - lr: 0.000030
2021-07-22 13:00:14,511 epoch 8 - iter 212/538 - loss 0.14070076 - samples/sec: 133.64 - lr: 0.000030
2021-07-22 13:00:27,332 epoch 8 - iter 265/538 - loss 0.14510377 - samples/sec: 132.31 - lr: 0.000030
2021-07-22 13:00:40,083 epoch 8 - iter 318/538 - loss 0.14104841 - samples/sec: 133.03 - lr: 0.000030
2021-07-22 13:00:52,828 epoch 8 - iter 371/538 - loss 0.14271642 - samples/sec: 133.10 - lr: 0.000030
2021-07-22 13:01:05,404 epoch 8 - iter 424/538 - loss 0.14265230 - samples/sec: 134.89 - lr: 0.000030
2021-07-22 13:01:18,248 epoch 8 - iter 477/538 - loss 0.14040545 - samples/sec: 132.07 - lr: 0.000030
2021-07-22 13:01:30,623 epoch 8 - iter 530/538 - loss 0.13880097 - samples/sec: 137.07 - lr: 0.000030
2021-07-22 13:01:32,411 ----------------------------------------------------------------------------------------------------
2021-07-22 13:01:32,411 EPOCH 8 done: loss 0.1391 - lr 0.0000300
2021-07-22 13:01:38,025 DEV : loss 0.060980018228292465 - score 0.9807
2021-07-22 13:01:38,089 BAD EPOCHS (no improvement): 1
2021-07-22 13:01:38,090 ----------------------------------------------------------------------------------------------------
2021-07-22 13:01:50,683 epoch 9 - iter 53/538 - loss 0.12060907 - samples/sec: 134.72 - lr: 0.000030
2021-07-22 13:02:03,497 epoch 9 - iter 106/538 - loss 0.11964856 - samples/sec: 132.39 - lr: 0.000030
2021-07-22 13:02:15,840 epoch 9 - iter 159/538 - loss 0.12535485 - samples/sec: 137.44 - lr: 0.000030
2021-07-22 13:02:28,251 epoch 9 - iter 212/538 - loss 0.12004284 - samples/sec: 136.69 - lr: 0.000030
2021-07-22 13:02:41,048 epoch 9 - iter 265/538 - loss 0.12422801 - samples/sec: 132.55 - lr: 0.000030
2021-07-22 13:02:53,608 epoch 9 - iter 318/538 - loss 0.12461528 - samples/sec: 135.07 - lr: 0.000030
2021-07-22 13:03:06,374 epoch 9 - iter 371/538 - loss 0.12553107 - samples/sec: 132.88 - lr: 0.000030
2021-07-22 13:03:18,940 epoch 9 - iter 424/538 - loss 0.12497679 - samples/sec: 135.00 - lr: 0.000030
2021-07-22 13:03:31,334 epoch 9 - iter 477/538 - loss 0.12415858 - samples/sec: 136.87 - lr: 0.000030
2021-07-22 13:03:44,156 epoch 9 - iter 530/538 - loss 0.12359274 - samples/sec: 132.30 - lr: 0.000030
2021-07-22 13:03:45,958 ----------------------------------------------------------------------------------------------------
2021-07-22 13:03:45,958 EPOCH 9 done: loss 0.1238 - lr 0.0000300
2021-07-22 13:03:51,566 DEV : loss 0.05629200488328934 - score 0.9818
2021-07-22 13:03:51,632 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:03:53,626 ----------------------------------------------------------------------------------------------------
2021-07-22 13:04:06,024 epoch 10 - iter 53/538 - loss 0.10829150 - samples/sec: 136.86 - lr: 0.000030
2021-07-22 13:04:18,804 epoch 10 - iter 106/538 - loss 0.11597949 - samples/sec: 132.73 - lr: 0.000030
2021-07-22 13:04:31,371 epoch 10 - iter 159/538 - loss 0.11024193 - samples/sec: 134.98 - lr: 0.000030
2021-07-22 13:04:44,198 epoch 10 - iter 212/538 - loss 0.11403102 - samples/sec: 132.26 - lr: 0.000030
2021-07-22 13:04:56,712 epoch 10 - iter 265/538 - loss 0.11028400 - samples/sec: 135.55 - lr: 0.000030
2021-07-22 13:05:09,359 epoch 10 - iter 318/538 - loss 0.10854337 - samples/sec: 134.13 - lr: 0.000030
2021-07-22 13:05:22,024 epoch 10 - iter 371/538 - loss 0.10955294 - samples/sec: 133.94 - lr: 0.000030
2021-07-22 13:05:34,732 epoch 10 - iter 424/538 - loss 0.11036769 - samples/sec: 133.49 - lr: 0.000030
2021-07-22 13:05:47,380 epoch 10 - iter 477/538 - loss 0.10881443 - samples/sec: 134.12 - lr: 0.000030
2021-07-22 13:05:59,892 epoch 10 - iter 530/538 - loss 0.10848932 - samples/sec: 135.58 - lr: 0.000030
2021-07-22 13:06:01,927 ----------------------------------------------------------------------------------------------------
2021-07-22 13:06:01,928 EPOCH 10 done: loss 0.1086 - lr 0.0000300
2021-07-22 13:06:08,111 DEV : loss 0.057681310921907425 - score 0.9822
2021-07-22 13:06:08,175 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:06:10,259 ----------------------------------------------------------------------------------------------------
2021-07-22 13:06:22,762 epoch 11 - iter 53/538 - loss 0.11249376 - samples/sec: 135.71 - lr: 0.000030
2021-07-22 13:06:35,240 epoch 11 - iter 106/538 - loss 0.10482599 - samples/sec: 135.95 - lr: 0.000030
2021-07-22 13:06:48,050 epoch 11 - iter 159/538 - loss 0.10390796 - samples/sec: 132.43 - lr: 0.000030
2021-07-22 13:07:00,655 epoch 11 - iter 212/538 - loss 0.09988699 - samples/sec: 134.58 - lr: 0.000030
2021-07-22 13:07:13,348 epoch 11 - iter 265/538 - loss 0.09666230 - samples/sec: 133.65 - lr: 0.000030
2021-07-22 13:07:25,800 epoch 11 - iter 318/538 - loss 0.09437945 - samples/sec: 136.23 - lr: 0.000030
2021-07-22 13:07:38,519 epoch 11 - iter 371/538 - loss 0.09224716 - samples/sec: 133.38 - lr: 0.000030
2021-07-22 13:07:50,976 epoch 11 - iter 424/538 - loss 0.09162961 - samples/sec: 136.18 - lr: 0.000030
2021-07-22 13:08:03,279 epoch 11 - iter 477/538 - loss 0.09171437 - samples/sec: 137.88 - lr: 0.000030
2021-07-22 13:08:15,922 epoch 11 - iter 530/538 - loss 0.09167601 - samples/sec: 134.17 - lr: 0.000030
2021-07-22 13:08:17,748 ----------------------------------------------------------------------------------------------------
2021-07-22 13:08:17,748 EPOCH 11 done: loss 0.0923 - lr 0.0000300
2021-07-22 13:08:23,367 DEV : loss 0.05182754993438721 - score 0.9841
2021-07-22 13:08:23,431 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:08:25,586 ----------------------------------------------------------------------------------------------------
2021-07-22 13:08:38,116 epoch 12 - iter 53/538 - loss 0.07508770 - samples/sec: 135.41 - lr: 0.000030
2021-07-22 13:08:50,659 epoch 12 - iter 106/538 - loss 0.08467609 - samples/sec: 135.24 - lr: 0.000030
2021-07-22 13:09:03,219 epoch 12 - iter 159/538 - loss 0.08232319 - samples/sec: 135.06 - lr: 0.000030
2021-07-22 13:09:16,167 epoch 12 - iter 212/538 - loss 0.08423227 - samples/sec: 131.01 - lr: 0.000030
2021-07-22 13:09:28,763 epoch 12 - iter 265/538 - loss 0.08208455 - samples/sec: 134.67 - lr: 0.000030
2021-07-22 13:09:41,387 epoch 12 - iter 318/538 - loss 0.08080341 - samples/sec: 134.38 - lr: 0.000030
2021-07-22 13:09:53,940 epoch 12 - iter 371/538 - loss 0.07923969 - samples/sec: 135.13 - lr: 0.000030
2021-07-22 13:10:06,644 epoch 12 - iter 424/538 - loss 0.07905557 - samples/sec: 133.53 - lr: 0.000030
2021-07-22 13:10:19,403 epoch 12 - iter 477/538 - loss 0.07857599 - samples/sec: 132.95 - lr: 0.000030
2021-07-22 13:10:32,101 epoch 12 - iter 530/538 - loss 0.07866950 - samples/sec: 133.60 - lr: 0.000030
2021-07-22 13:10:33,992 ----------------------------------------------------------------------------------------------------
2021-07-22 13:10:33,993 EPOCH 12 done: loss 0.0789 - lr 0.0000300
2021-07-22 13:10:39,612 DEV : loss 0.04895486682653427 - score 0.9844
2021-07-22 13:10:39,676 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:10:41,754 ----------------------------------------------------------------------------------------------------
2021-07-22 13:10:54,296 epoch 13 - iter 53/538 - loss 0.07133807 - samples/sec: 135.30 - lr: 0.000030
2021-07-22 13:11:06,940 epoch 13 - iter 106/538 - loss 0.06724338 - samples/sec: 134.17 - lr: 0.000030
2021-07-22 13:11:19,525 epoch 13 - iter 159/538 - loss 0.06937701 - samples/sec: 134.79 - lr: 0.000030
2021-07-22 13:11:31,978 epoch 13 - iter 212/538 - loss 0.07050701 - samples/sec: 136.22 - lr: 0.000030
2021-07-22 13:11:44,584 epoch 13 - iter 265/538 - loss 0.07013803 - samples/sec: 134.57 - lr: 0.000030
2021-07-22 13:11:57,477 epoch 13 - iter 318/538 - loss 0.06962514 - samples/sec: 131.58 - lr: 0.000030
2021-07-22 13:12:10,077 epoch 13 - iter 371/538 - loss 0.07075491 - samples/sec: 134.64 - lr: 0.000030
2021-07-22 13:12:22,697 epoch 13 - iter 424/538 - loss 0.07083835 - samples/sec: 134.41 - lr: 0.000030
2021-07-22 13:12:35,226 epoch 13 - iter 477/538 - loss 0.07077542 - samples/sec: 135.40 - lr: 0.000030
2021-07-22 13:12:47,849 epoch 13 - iter 530/538 - loss 0.07017231 - samples/sec: 134.38 - lr: 0.000030
2021-07-22 13:12:49,736 ----------------------------------------------------------------------------------------------------
2021-07-22 13:12:49,737 EPOCH 13 done: loss 0.0706 - lr 0.0000300
2021-07-22 13:12:55,338 DEV : loss 0.053157538175582886 - score 0.9832
2021-07-22 13:12:55,401 BAD EPOCHS (no improvement): 1
2021-07-22 13:12:55,402 ----------------------------------------------------------------------------------------------------
2021-07-22 13:13:07,880 epoch 14 - iter 53/538 - loss 0.06967504 - samples/sec: 135.96 - lr: 0.000030
2021-07-22 13:13:20,389 epoch 14 - iter 106/538 - loss 0.06670611 - samples/sec: 135.62 - lr: 0.000030
2021-07-22 13:13:33,168 epoch 14 - iter 159/538 - loss 0.06657845 - samples/sec: 132.74 - lr: 0.000030
2021-07-22 13:13:45,676 epoch 14 - iter 212/538 - loss 0.06960937 - samples/sec: 135.63 - lr: 0.000030
2021-07-22 13:13:58,347 epoch 14 - iter 265/538 - loss 0.06833927 - samples/sec: 133.87 - lr: 0.000030
2021-07-22 13:14:11,115 epoch 14 - iter 318/538 - loss 0.06810850 - samples/sec: 132.86 - lr: 0.000030
2021-07-22 13:14:23,744 epoch 14 - iter 371/538 - loss 0.06996385 - samples/sec: 134.33 - lr: 0.000030
2021-07-22 13:14:36,215 epoch 14 - iter 424/538 - loss 0.06868084 - samples/sec: 136.03 - lr: 0.000030
2021-07-22 13:14:49,128 epoch 14 - iter 477/538 - loss 0.06757477 - samples/sec: 131.37 - lr: 0.000030
2021-07-22 13:15:01,757 epoch 14 - iter 530/538 - loss 0.06878617 - samples/sec: 134.32 - lr: 0.000030
2021-07-22 13:15:03,728 ----------------------------------------------------------------------------------------------------
2021-07-22 13:15:03,728 EPOCH 14 done: loss 0.0689 - lr 0.0000300
2021-07-22 13:15:09,346 DEV : loss 0.047954678535461426 - score 0.9831
2021-07-22 13:15:09,410 BAD EPOCHS (no improvement): 2
2021-07-22 13:15:09,410 ----------------------------------------------------------------------------------------------------
2021-07-22 13:15:22,243 epoch 15 - iter 53/538 - loss 0.05483642 - samples/sec: 132.20 - lr: 0.000030
2021-07-22 13:15:34,979 epoch 15 - iter 106/538 - loss 0.06002220 - samples/sec: 133.20 - lr: 0.000030
2021-07-22 13:15:47,643 epoch 15 - iter 159/538 - loss 0.06384438 - samples/sec: 133.95 - lr: 0.000030
2021-07-22 13:16:00,247 epoch 15 - iter 212/538 - loss 0.06541063 - samples/sec: 134.59 - lr: 0.000030
2021-07-22 13:16:12,716 epoch 15 - iter 265/538 - loss 0.06404159 - samples/sec: 136.04 - lr: 0.000030
2021-07-22 13:16:25,649 epoch 15 - iter 318/538 - loss 0.06446863 - samples/sec: 131.17 - lr: 0.000030
2021-07-22 13:16:38,081 epoch 15 - iter 371/538 - loss 0.06557793 - samples/sec: 136.45 - lr: 0.000030
2021-07-22 13:16:50,396 epoch 15 - iter 424/538 - loss 0.06407122 - samples/sec: 137.74 - lr: 0.000030
2021-07-22 13:17:03,443 epoch 15 - iter 477/538 - loss 0.06434008 - samples/sec: 130.02 - lr: 0.000030
2021-07-22 13:17:15,887 epoch 15 - iter 530/538 - loss 0.06432317 - samples/sec: 136.31 - lr: 0.000030
2021-07-22 13:17:17,699 ----------------------------------------------------------------------------------------------------
2021-07-22 13:17:17,699 EPOCH 15 done: loss 0.0644 - lr 0.0000300
2021-07-22 13:17:23,890 DEV : loss 0.04910237714648247 - score 0.985
2021-07-22 13:17:23,955 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:17:25,679 ----------------------------------------------------------------------------------------------------
2021-07-22 13:17:38,360 epoch 16 - iter 53/538 - loss 0.07485041 - samples/sec: 133.79 - lr: 0.000030
2021-07-22 13:17:50,976 epoch 16 - iter 106/538 - loss 0.06552352 - samples/sec: 134.46 - lr: 0.000030
2021-07-22 13:18:03,476 epoch 16 - iter 159/538 - loss 0.06459333 - samples/sec: 135.72 - lr: 0.000030
2021-07-22 13:18:16,126 epoch 16 - iter 212/538 - loss 0.06422743 - samples/sec: 134.09 - lr: 0.000030
2021-07-22 13:18:28,523 epoch 16 - iter 265/538 - loss 0.06285805 - samples/sec: 136.84 - lr: 0.000030
2021-07-22 13:18:41,124 epoch 16 - iter 318/538 - loss 0.06212705 - samples/sec: 134.63 - lr: 0.000030
2021-07-22 13:18:53,507 epoch 16 - iter 371/538 - loss 0.06529082 - samples/sec: 136.98 - lr: 0.000030
2021-07-22 13:19:06,075 epoch 16 - iter 424/538 - loss 0.06490666 - samples/sec: 134.98 - lr: 0.000030
2021-07-22 13:19:18,776 epoch 16 - iter 477/538 - loss 0.06366898 - samples/sec: 133.56 - lr: 0.000030
2021-07-22 13:19:31,376 epoch 16 - iter 530/538 - loss 0.06499816 - samples/sec: 134.64 - lr: 0.000030
2021-07-22 13:19:33,336 ----------------------------------------------------------------------------------------------------
2021-07-22 13:19:33,336 EPOCH 16 done: loss 0.0657 - lr 0.0000300
2021-07-22 13:19:38,960 DEV : loss 0.04974330961704254 - score 0.9844
2021-07-22 13:19:39,024 BAD EPOCHS (no improvement): 1
2021-07-22 13:19:39,025 ----------------------------------------------------------------------------------------------------
2021-07-22 13:19:51,458 epoch 17 - iter 53/538 - loss 0.05743675 - samples/sec: 136.46 - lr: 0.000030
2021-07-22 13:20:04,230 epoch 17 - iter 106/538 - loss 0.06114164 - samples/sec: 132.81 - lr: 0.000030
2021-07-22 13:20:16,940 epoch 17 - iter 159/538 - loss 0.06129949 - samples/sec: 133.47 - lr: 0.000030
2021-07-22 13:20:29,491 epoch 17 - iter 212/538 - loss 0.06138490 - samples/sec: 135.16 - lr: 0.000030
2021-07-22 13:20:42,237 epoch 17 - iter 265/538 - loss 0.06232938 - samples/sec: 133.09 - lr: 0.000030
2021-07-22 13:20:54,789 epoch 17 - iter 318/538 - loss 0.06349263 - samples/sec: 135.15 - lr: 0.000030
2021-07-22 13:21:07,547 epoch 17 - iter 371/538 - loss 0.06253662 - samples/sec: 132.96 - lr: 0.000030
2021-07-22 13:21:20,203 epoch 17 - iter 424/538 - loss 0.06297547 - samples/sec: 134.04 - lr: 0.000030
2021-07-22 13:21:32,623 epoch 17 - iter 477/538 - loss 0.06146574 - samples/sec: 136.58 - lr: 0.000030
2021-07-22 13:21:45,333 epoch 17 - iter 530/538 - loss 0.06201420 - samples/sec: 133.48 - lr: 0.000030
2021-07-22 13:21:47,225 ----------------------------------------------------------------------------------------------------
2021-07-22 13:21:47,225 EPOCH 17 done: loss 0.0616 - lr 0.0000300
2021-07-22 13:21:52,853 DEV : loss 0.048493701964616776 - score 0.9843
2021-07-22 13:21:52,916 BAD EPOCHS (no improvement): 2
2021-07-22 13:21:52,916 ----------------------------------------------------------------------------------------------------
2021-07-22 13:22:05,573 epoch 18 - iter 53/538 - loss 0.06266732 - samples/sec: 134.04 - lr: 0.000030
2021-07-22 13:22:18,303 epoch 18 - iter 106/538 - loss 0.05918019 - samples/sec: 133.26 - lr: 0.000030
2021-07-22 13:22:30,695 epoch 18 - iter 159/538 - loss 0.05896781 - samples/sec: 136.90 - lr: 0.000030
2021-07-22 13:22:43,293 epoch 18 - iter 212/538 - loss 0.05955747 - samples/sec: 134.66 - lr: 0.000030
2021-07-22 13:22:55,955 epoch 18 - iter 265/538 - loss 0.05964701 - samples/sec: 133.97 - lr: 0.000030
2021-07-22 13:23:08,603 epoch 18 - iter 318/538 - loss 0.05899038 - samples/sec: 134.12 - lr: 0.000030
2021-07-22 13:23:21,156 epoch 18 - iter 371/538 - loss 0.05875433 - samples/sec: 135.14 - lr: 0.000030
2021-07-22 13:23:33,672 epoch 18 - iter 424/538 - loss 0.05968088 - samples/sec: 135.54 - lr: 0.000030
2021-07-22 13:23:46,151 epoch 18 - iter 477/538 - loss 0.05928503 - samples/sec: 135.93 - lr: 0.000030
2021-07-22 13:23:58,667 epoch 18 - iter 530/538 - loss 0.05903875 - samples/sec: 135.53 - lr: 0.000030
2021-07-22 13:24:00,532 ----------------------------------------------------------------------------------------------------
2021-07-22 13:24:00,533 EPOCH 18 done: loss 0.0591 - lr 0.0000300
2021-07-22 13:24:06,162 DEV : loss 0.0466650016605854 - score 0.9853
2021-07-22 13:24:06,227 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:24:08,167 ----------------------------------------------------------------------------------------------------
2021-07-22 13:24:20,927 epoch 19 - iter 53/538 - loss 0.05121331 - samples/sec: 132.97 - lr: 0.000030
2021-07-22 13:24:33,438 epoch 19 - iter 106/538 - loss 0.06463416 - samples/sec: 135.59 - lr: 0.000030
2021-07-22 13:24:46,219 epoch 19 - iter 159/538 - loss 0.06024284 - samples/sec: 132.72 - lr: 0.000030
2021-07-22 13:24:58,864 epoch 19 - iter 212/538 - loss 0.06161945 - samples/sec: 134.15 - lr: 0.000030
2021-07-22 13:25:11,171 epoch 19 - iter 265/538 - loss 0.06056834 - samples/sec: 137.85 - lr: 0.000030
2021-07-22 13:25:23,800 epoch 19 - iter 318/538 - loss 0.06067512 - samples/sec: 134.32 - lr: 0.000030
2021-07-22 13:25:36,171 epoch 19 - iter 371/538 - loss 0.05880855 - samples/sec: 137.12 - lr: 0.000030
2021-07-22 13:25:48,788 epoch 19 - iter 424/538 - loss 0.05817597 - samples/sec: 134.45 - lr: 0.000030
2021-07-22 13:26:01,403 epoch 19 - iter 477/538 - loss 0.05743561 - samples/sec: 134.47 - lr: 0.000030
2021-07-22 13:26:13,914 epoch 19 - iter 530/538 - loss 0.05757528 - samples/sec: 135.59 - lr: 0.000030
2021-07-22 13:26:15,836 ----------------------------------------------------------------------------------------------------
2021-07-22 13:26:15,836 EPOCH 19 done: loss 0.0573 - lr 0.0000300
2021-07-22 13:26:21,440 DEV : loss 0.052478376775979996 - score 0.9841
2021-07-22 13:26:21,503 BAD EPOCHS (no improvement): 1
2021-07-22 13:26:21,503 ----------------------------------------------------------------------------------------------------
2021-07-22 13:26:33,902 epoch 20 - iter 53/538 - loss 0.05070227 - samples/sec: 136.83 - lr: 0.000030
2021-07-22 13:26:46,512 epoch 20 - iter 106/538 - loss 0.04763936 - samples/sec: 134.54 - lr: 0.000030
2021-07-22 13:26:59,069 epoch 20 - iter 159/538 - loss 0.05470112 - samples/sec: 135.09 - lr: 0.000030
2021-07-22 13:27:12,267 epoch 20 - iter 212/538 - loss 0.05311362 - samples/sec: 128.53 - lr: 0.000030
2021-07-22 13:27:24,688 epoch 20 - iter 265/538 - loss 0.05597685 - samples/sec: 136.57 - lr: 0.000030
2021-07-22 13:27:37,312 epoch 20 - iter 318/538 - loss 0.05907905 - samples/sec: 134.38 - lr: 0.000030
2021-07-22 13:27:49,868 epoch 20 - iter 371/538 - loss 0.05798184 - samples/sec: 135.11 - lr: 0.000030
2021-07-22 13:28:02,760 epoch 20 - iter 424/538 - loss 0.05769280 - samples/sec: 131.58 - lr: 0.000030
2021-07-22 13:28:15,352 epoch 20 - iter 477/538 - loss 0.05649558 - samples/sec: 134.72 - lr: 0.000030
2021-07-22 13:28:27,964 epoch 20 - iter 530/538 - loss 0.05632543 - samples/sec: 134.51 - lr: 0.000030
2021-07-22 13:28:29,861 ----------------------------------------------------------------------------------------------------
2021-07-22 13:28:29,861 EPOCH 20 done: loss 0.0564 - lr 0.0000300
2021-07-22 13:28:35,467 DEV : loss 0.047062426805496216 - score 0.9863
2021-07-22 13:28:35,530 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:28:37,692 ----------------------------------------------------------------------------------------------------
2021-07-22 13:28:50,482 epoch 21 - iter 53/538 - loss 0.06890728 - samples/sec: 132.65 - lr: 0.000030
2021-07-22 13:29:02,880 epoch 21 - iter 106/538 - loss 0.05378485 - samples/sec: 136.83 - lr: 0.000030
2021-07-22 13:29:15,556 epoch 21 - iter 159/538 - loss 0.05552542 - samples/sec: 133.83 - lr: 0.000030
2021-07-22 13:29:28,319 epoch 21 - iter 212/538 - loss 0.05497618 - samples/sec: 132.92 - lr: 0.000030
2021-07-22 13:29:40,955 epoch 21 - iter 265/538 - loss 0.05511640 - samples/sec: 134.24 - lr: 0.000030
2021-07-22 13:29:53,607 epoch 21 - iter 318/538 - loss 0.05793708 - samples/sec: 134.08 - lr: 0.000030
2021-07-22 13:30:06,205 epoch 21 - iter 371/538 - loss 0.05870857 - samples/sec: 134.65 - lr: 0.000030
2021-07-22 13:30:18,666 epoch 21 - iter 424/538 - loss 0.05767927 - samples/sec: 136.13 - lr: 0.000030
2021-07-22 13:30:31,758 epoch 21 - iter 477/538 - loss 0.05711499 - samples/sec: 129.57 - lr: 0.000030
2021-07-22 13:30:44,119 epoch 21 - iter 530/538 - loss 0.05757285 - samples/sec: 137.24 - lr: 0.000030
2021-07-22 13:30:46,044 ----------------------------------------------------------------------------------------------------
2021-07-22 13:30:46,044 EPOCH 21 done: loss 0.0584 - lr 0.0000300
2021-07-22 13:30:51,677 DEV : loss 0.05049842223525047 - score 0.9853
2021-07-22 13:30:51,741 BAD EPOCHS (no improvement): 1
2021-07-22 13:30:51,741 ----------------------------------------------------------------------------------------------------
2021-07-22 13:31:04,381 epoch 22 - iter 53/538 - loss 0.06257014 - samples/sec: 134.23 - lr: 0.000030
2021-07-22 13:31:17,000 epoch 22 - iter 106/538 - loss 0.05554996 - samples/sec: 134.43 - lr: 0.000030
2021-07-22 13:31:29,719 epoch 22 - iter 159/538 - loss 0.05471900 - samples/sec: 133.36 - lr: 0.000030
2021-07-22 13:31:42,224 epoch 22 - iter 212/538 - loss 0.05765698 - samples/sec: 135.66 - lr: 0.000030
2021-07-22 13:31:54,900 epoch 22 - iter 265/538 - loss 0.05532004 - samples/sec: 133.82 - lr: 0.000030
2021-07-22 13:32:07,703 epoch 22 - iter 318/538 - loss 0.05512168 - samples/sec: 132.50 - lr: 0.000030
2021-07-22 13:32:20,003 epoch 22 - iter 371/538 - loss 0.05775502 - samples/sec: 137.92 - lr: 0.000030
2021-07-22 13:32:32,672 epoch 22 - iter 424/538 - loss 0.05607929 - samples/sec: 133.90 - lr: 0.000030
2021-07-22 13:32:45,336 epoch 22 - iter 477/538 - loss 0.05646422 - samples/sec: 133.96 - lr: 0.000030
2021-07-22 13:32:58,165 epoch 22 - iter 530/538 - loss 0.05596912 - samples/sec: 132.23 - lr: 0.000030
2021-07-22 13:33:00,084 ----------------------------------------------------------------------------------------------------
2021-07-22 13:33:00,085 EPOCH 22 done: loss 0.0558 - lr 0.0000300
2021-07-22 13:33:05,719 DEV : loss 0.04591542109847069 - score 0.9856
2021-07-22 13:33:05,784 BAD EPOCHS (no improvement): 2
2021-07-22 13:33:05,784 ----------------------------------------------------------------------------------------------------
2021-07-22 13:33:18,342 epoch 23 - iter 53/538 - loss 0.04685403 - samples/sec: 135.10 - lr: 0.000030
2021-07-22 13:33:30,959 epoch 23 - iter 106/538 - loss 0.05182084 - samples/sec: 134.45 - lr: 0.000030
2021-07-22 13:33:43,487 epoch 23 - iter 159/538 - loss 0.05254553 - samples/sec: 135.41 - lr: 0.000030
2021-07-22 13:33:56,351 epoch 23 - iter 212/538 - loss 0.05164576 - samples/sec: 131.86 - lr: 0.000030
2021-07-22 13:34:08,766 epoch 23 - iter 265/538 - loss 0.05389537 - samples/sec: 136.65 - lr: 0.000030
2021-07-22 13:34:21,427 epoch 23 - iter 318/538 - loss 0.05387595 - samples/sec: 133.98 - lr: 0.000030
2021-07-22 13:34:34,008 epoch 23 - iter 371/538 - loss 0.05346126 - samples/sec: 134.83 - lr: 0.000030
2021-07-22 13:34:46,691 epoch 23 - iter 424/538 - loss 0.05393411 - samples/sec: 133.75 - lr: 0.000030
2021-07-22 13:34:59,227 epoch 23 - iter 477/538 - loss 0.05389134 - samples/sec: 135.32 - lr: 0.000030
2021-07-22 13:35:11,764 epoch 23 - iter 530/538 - loss 0.05262366 - samples/sec: 135.31 - lr: 0.000030
2021-07-22 13:35:13,612 ----------------------------------------------------------------------------------------------------
2021-07-22 13:35:13,612 EPOCH 23 done: loss 0.0524 - lr 0.0000300
2021-07-22 13:35:19,221 DEV : loss 0.04764634743332863 - score 0.985
2021-07-22 13:35:19,285 BAD EPOCHS (no improvement): 3
2021-07-22 13:35:19,286 ----------------------------------------------------------------------------------------------------
2021-07-22 13:35:31,707 epoch 24 - iter 53/538 - loss 0.04662241 - samples/sec: 136.58 - lr: 0.000030
2021-07-22 13:35:44,213 epoch 24 - iter 106/538 - loss 0.04821172 - samples/sec: 135.65 - lr: 0.000030
2021-07-22 13:35:56,824 epoch 24 - iter 159/538 - loss 0.05218835 - samples/sec: 134.51 - lr: 0.000030
2021-07-22 13:36:09,600 epoch 24 - iter 212/538 - loss 0.05168594 - samples/sec: 132.78 - lr: 0.000030
2021-07-22 13:36:22,182 epoch 24 - iter 265/538 - loss 0.05110763 - samples/sec: 134.82 - lr: 0.000030
2021-07-22 13:36:34,996 epoch 24 - iter 318/538 - loss 0.05054241 - samples/sec: 132.38 - lr: 0.000030
2021-07-22 13:36:47,440 epoch 24 - iter 371/538 - loss 0.05031545 - samples/sec: 136.33 - lr: 0.000030
2021-07-22 13:37:00,193 epoch 24 - iter 424/538 - loss 0.05115728 - samples/sec: 133.01 - lr: 0.000030
2021-07-22 13:37:12,839 epoch 24 - iter 477/538 - loss 0.05160882 - samples/sec: 134.15 - lr: 0.000030
2021-07-22 13:37:25,539 epoch 24 - iter 530/538 - loss 0.05188992 - samples/sec: 133.57 - lr: 0.000030
2021-07-22 13:37:27,396 ----------------------------------------------------------------------------------------------------
2021-07-22 13:37:27,396 EPOCH 24 done: loss 0.0523 - lr 0.0000300
2021-07-22 13:37:33,593 DEV : loss 0.047056350857019424 - score 0.9859
Epoch    24: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 13:37:33,658 BAD EPOCHS (no improvement): 4
2021-07-22 13:37:33,658 ----------------------------------------------------------------------------------------------------
2021-07-22 13:37:46,245 epoch 25 - iter 53/538 - loss 0.04514685 - samples/sec: 134.79 - lr: 0.000015
2021-07-22 13:37:58,839 epoch 25 - iter 106/538 - loss 0.04839902 - samples/sec: 134.69 - lr: 0.000015
2021-07-22 13:38:11,406 epoch 25 - iter 159/538 - loss 0.05213587 - samples/sec: 134.99 - lr: 0.000015
2021-07-22 13:38:24,066 epoch 25 - iter 212/538 - loss 0.05061129 - samples/sec: 133.99 - lr: 0.000015
2021-07-22 13:38:36,822 epoch 25 - iter 265/538 - loss 0.04851249 - samples/sec: 132.98 - lr: 0.000015
2021-07-22 13:38:49,440 epoch 25 - iter 318/538 - loss 0.04762355 - samples/sec: 134.45 - lr: 0.000015
2021-07-22 13:39:01,925 epoch 25 - iter 371/538 - loss 0.04742282 - samples/sec: 135.87 - lr: 0.000015
2021-07-22 13:39:14,484 epoch 25 - iter 424/538 - loss 0.04675961 - samples/sec: 135.07 - lr: 0.000015
2021-07-22 13:39:27,060 epoch 25 - iter 477/538 - loss 0.04856439 - samples/sec: 134.89 - lr: 0.000015
2021-07-22 13:39:39,765 epoch 25 - iter 530/538 - loss 0.04921511 - samples/sec: 133.52 - lr: 0.000015
2021-07-22 13:39:41,733 ----------------------------------------------------------------------------------------------------
2021-07-22 13:39:41,733 EPOCH 25 done: loss 0.0489 - lr 0.0000150
2021-07-22 13:39:47,358 DEV : loss 0.04659892991185188 - score 0.9862
2021-07-22 13:39:47,420 BAD EPOCHS (no improvement): 1
2021-07-22 13:39:47,421 ----------------------------------------------------------------------------------------------------
2021-07-22 13:39:59,812 epoch 26 - iter 53/538 - loss 0.04597635 - samples/sec: 136.92 - lr: 0.000015
2021-07-22 13:40:12,365 epoch 26 - iter 106/538 - loss 0.05290685 - samples/sec: 135.14 - lr: 0.000015
2021-07-22 13:40:24,967 epoch 26 - iter 159/538 - loss 0.05408546 - samples/sec: 134.61 - lr: 0.000015
2021-07-22 13:40:37,384 epoch 26 - iter 212/538 - loss 0.05406324 - samples/sec: 136.61 - lr: 0.000015
2021-07-22 13:40:50,272 epoch 26 - iter 265/538 - loss 0.05330086 - samples/sec: 131.63 - lr: 0.000015
2021-07-22 13:41:02,986 epoch 26 - iter 318/538 - loss 0.05234130 - samples/sec: 133.43 - lr: 0.000015
2021-07-22 13:41:15,600 epoch 26 - iter 371/538 - loss 0.05138277 - samples/sec: 134.48 - lr: 0.000015
2021-07-22 13:41:28,136 epoch 26 - iter 424/538 - loss 0.04979990 - samples/sec: 135.32 - lr: 0.000015
2021-07-22 13:41:40,575 epoch 26 - iter 477/538 - loss 0.05023360 - samples/sec: 136.38 - lr: 0.000015
2021-07-22 13:41:53,195 epoch 26 - iter 530/538 - loss 0.04936805 - samples/sec: 134.41 - lr: 0.000015
2021-07-22 13:41:55,024 ----------------------------------------------------------------------------------------------------
2021-07-22 13:41:55,024 EPOCH 26 done: loss 0.0492 - lr 0.0000150
2021-07-22 13:42:00,647 DEV : loss 0.04507211968302727 - score 0.9859
2021-07-22 13:42:00,711 BAD EPOCHS (no improvement): 2
2021-07-22 13:42:00,711 ----------------------------------------------------------------------------------------------------
2021-07-22 13:42:13,285 epoch 27 - iter 53/538 - loss 0.03478213 - samples/sec: 134.92 - lr: 0.000015
2021-07-22 13:42:25,794 epoch 27 - iter 106/538 - loss 0.03500094 - samples/sec: 135.62 - lr: 0.000015
2021-07-22 13:42:38,280 epoch 27 - iter 159/538 - loss 0.04162994 - samples/sec: 135.85 - lr: 0.000015
2021-07-22 13:42:50,876 epoch 27 - iter 212/538 - loss 0.04442225 - samples/sec: 134.68 - lr: 0.000015
2021-07-22 13:43:03,300 epoch 27 - iter 265/538 - loss 0.04533159 - samples/sec: 136.53 - lr: 0.000015
2021-07-22 13:43:15,719 epoch 27 - iter 318/538 - loss 0.04569454 - samples/sec: 136.60 - lr: 0.000015
2021-07-22 13:43:28,274 epoch 27 - iter 371/538 - loss 0.04564538 - samples/sec: 135.12 - lr: 0.000015
2021-07-22 13:43:41,013 epoch 27 - iter 424/538 - loss 0.04693110 - samples/sec: 133.16 - lr: 0.000015
2021-07-22 13:43:53,559 epoch 27 - iter 477/538 - loss 0.04650662 - samples/sec: 135.21 - lr: 0.000015
2021-07-22 13:44:06,220 epoch 27 - iter 530/538 - loss 0.04640014 - samples/sec: 133.98 - lr: 0.000015
2021-07-22 13:44:08,124 ----------------------------------------------------------------------------------------------------
2021-07-22 13:44:08,124 EPOCH 27 done: loss 0.0462 - lr 0.0000150
2021-07-22 13:44:13,753 DEV : loss 0.04616105183959007 - score 0.9872
2021-07-22 13:44:13,817 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:44:15,919 ----------------------------------------------------------------------------------------------------
2021-07-22 13:44:28,633 epoch 28 - iter 53/538 - loss 0.04618511 - samples/sec: 133.46 - lr: 0.000015
2021-07-22 13:44:41,429 epoch 28 - iter 106/538 - loss 0.04683425 - samples/sec: 132.57 - lr: 0.000015
2021-07-22 13:44:53,971 epoch 28 - iter 159/538 - loss 0.04423499 - samples/sec: 135.25 - lr: 0.000015
2021-07-22 13:45:06,624 epoch 28 - iter 212/538 - loss 0.04625282 - samples/sec: 134.07 - lr: 0.000015
2021-07-22 13:45:19,438 epoch 28 - iter 265/538 - loss 0.04586277 - samples/sec: 132.39 - lr: 0.000015
2021-07-22 13:45:32,160 epoch 28 - iter 318/538 - loss 0.04535486 - samples/sec: 133.34 - lr: 0.000015
2021-07-22 13:45:44,494 epoch 28 - iter 371/538 - loss 0.04526200 - samples/sec: 137.54 - lr: 0.000015
2021-07-22 13:45:56,988 epoch 28 - iter 424/538 - loss 0.04446832 - samples/sec: 135.77 - lr: 0.000015
2021-07-22 13:46:09,577 epoch 28 - iter 477/538 - loss 0.04566255 - samples/sec: 134.75 - lr: 0.000015
2021-07-22 13:46:22,280 epoch 28 - iter 530/538 - loss 0.04740428 - samples/sec: 133.54 - lr: 0.000015
2021-07-22 13:46:24,189 ----------------------------------------------------------------------------------------------------
2021-07-22 13:46:24,189 EPOCH 28 done: loss 0.0471 - lr 0.0000150
2021-07-22 13:46:29,795 DEV : loss 0.045541051775217056 - score 0.9872
2021-07-22 13:46:29,858 BAD EPOCHS (no improvement): 1
2021-07-22 13:46:29,858 ----------------------------------------------------------------------------------------------------
2021-07-22 13:46:42,508 epoch 29 - iter 53/538 - loss 0.05566726 - samples/sec: 134.12 - lr: 0.000015
2021-07-22 13:46:54,884 epoch 29 - iter 106/538 - loss 0.05484097 - samples/sec: 137.07 - lr: 0.000015
2021-07-22 13:47:07,469 epoch 29 - iter 159/538 - loss 0.05742691 - samples/sec: 134.79 - lr: 0.000015
2021-07-22 13:47:20,158 epoch 29 - iter 212/538 - loss 0.05414790 - samples/sec: 133.70 - lr: 0.000015
2021-07-22 13:47:32,715 epoch 29 - iter 265/538 - loss 0.05297985 - samples/sec: 135.09 - lr: 0.000015
2021-07-22 13:47:45,257 epoch 29 - iter 318/538 - loss 0.05209137 - samples/sec: 135.26 - lr: 0.000015
2021-07-22 13:47:57,779 epoch 29 - iter 371/538 - loss 0.05194161 - samples/sec: 135.47 - lr: 0.000015
2021-07-22 13:48:10,416 epoch 29 - iter 424/538 - loss 0.05077011 - samples/sec: 134.24 - lr: 0.000015
2021-07-22 13:48:23,256 epoch 29 - iter 477/538 - loss 0.05088111 - samples/sec: 132.11 - lr: 0.000015
2021-07-22 13:48:35,751 epoch 29 - iter 530/538 - loss 0.04997659 - samples/sec: 135.76 - lr: 0.000015
2021-07-22 13:48:37,625 ----------------------------------------------------------------------------------------------------
2021-07-22 13:48:37,625 EPOCH 29 done: loss 0.0497 - lr 0.0000150
2021-07-22 13:48:43,812 DEV : loss 0.045539695769548416 - score 0.9849
2021-07-22 13:48:43,876 BAD EPOCHS (no improvement): 2
2021-07-22 13:48:43,876 ----------------------------------------------------------------------------------------------------
2021-07-22 13:48:56,444 epoch 30 - iter 53/538 - loss 0.04337963 - samples/sec: 135.00 - lr: 0.000015
2021-07-22 13:49:09,137 epoch 30 - iter 106/538 - loss 0.04794087 - samples/sec: 133.65 - lr: 0.000015
2021-07-22 13:49:21,764 epoch 30 - iter 159/538 - loss 0.04814295 - samples/sec: 134.34 - lr: 0.000015
2021-07-22 13:49:34,388 epoch 30 - iter 212/538 - loss 0.04864216 - samples/sec: 134.38 - lr: 0.000015
2021-07-22 13:49:46,907 epoch 30 - iter 265/538 - loss 0.05011136 - samples/sec: 135.50 - lr: 0.000015
2021-07-22 13:49:59,388 epoch 30 - iter 318/538 - loss 0.05018358 - samples/sec: 135.92 - lr: 0.000015
2021-07-22 13:50:12,239 epoch 30 - iter 371/538 - loss 0.04842534 - samples/sec: 132.00 - lr: 0.000015
2021-07-22 13:50:24,952 epoch 30 - iter 424/538 - loss 0.04897228 - samples/sec: 133.44 - lr: 0.000015
2021-07-22 13:50:37,660 epoch 30 - iter 477/538 - loss 0.04869197 - samples/sec: 133.48 - lr: 0.000015
2021-07-22 13:50:50,235 epoch 30 - iter 530/538 - loss 0.04810023 - samples/sec: 134.90 - lr: 0.000015
2021-07-22 13:50:52,196 ----------------------------------------------------------------------------------------------------
2021-07-22 13:50:52,197 EPOCH 30 done: loss 0.0478 - lr 0.0000150
2021-07-22 13:50:57,805 DEV : loss 0.04598327353596687 - score 0.9865
2021-07-22 13:50:57,869 BAD EPOCHS (no improvement): 3
2021-07-22 13:50:57,869 ----------------------------------------------------------------------------------------------------
2021-07-22 13:51:10,333 epoch 31 - iter 53/538 - loss 0.03651200 - samples/sec: 136.12 - lr: 0.000015
2021-07-22 13:51:22,797 epoch 31 - iter 106/538 - loss 0.04390628 - samples/sec: 136.10 - lr: 0.000015
2021-07-22 13:51:35,525 epoch 31 - iter 159/538 - loss 0.04434315 - samples/sec: 133.28 - lr: 0.000015
2021-07-22 13:51:48,238 epoch 31 - iter 212/538 - loss 0.04641361 - samples/sec: 133.43 - lr: 0.000015
2021-07-22 13:52:00,956 epoch 31 - iter 265/538 - loss 0.04467075 - samples/sec: 133.39 - lr: 0.000015
2021-07-22 13:52:13,499 epoch 31 - iter 318/538 - loss 0.04394132 - samples/sec: 135.24 - lr: 0.000015
2021-07-22 13:52:26,428 epoch 31 - iter 371/538 - loss 0.04432261 - samples/sec: 131.21 - lr: 0.000015
2021-07-22 13:52:39,016 epoch 31 - iter 424/538 - loss 0.04457172 - samples/sec: 134.77 - lr: 0.000015
2021-07-22 13:52:51,534 epoch 31 - iter 477/538 - loss 0.04611865 - samples/sec: 135.51 - lr: 0.000015
2021-07-22 13:53:04,092 epoch 31 - iter 530/538 - loss 0.04600900 - samples/sec: 135.09 - lr: 0.000015
2021-07-22 13:53:05,949 ----------------------------------------------------------------------------------------------------
2021-07-22 13:53:05,949 EPOCH 31 done: loss 0.0458 - lr 0.0000150
2021-07-22 13:53:11,560 DEV : loss 0.045624326914548874 - score 0.9862
Epoch    31: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 13:53:11,625 BAD EPOCHS (no improvement): 4
2021-07-22 13:53:11,625 ----------------------------------------------------------------------------------------------------
2021-07-22 13:53:23,888 epoch 32 - iter 53/538 - loss 0.04014241 - samples/sec: 138.35 - lr: 0.000008
2021-07-22 13:53:36,451 epoch 32 - iter 106/538 - loss 0.04747619 - samples/sec: 135.02 - lr: 0.000008
2021-07-22 13:53:48,872 epoch 32 - iter 159/538 - loss 0.04451296 - samples/sec: 136.58 - lr: 0.000008
2021-07-22 13:54:01,371 epoch 32 - iter 212/538 - loss 0.04376517 - samples/sec: 135.71 - lr: 0.000008
2021-07-22 13:54:14,481 epoch 32 - iter 265/538 - loss 0.04498497 - samples/sec: 129.40 - lr: 0.000008
2021-07-22 13:54:26,915 epoch 32 - iter 318/538 - loss 0.04401389 - samples/sec: 136.42 - lr: 0.000008
2021-07-22 13:54:39,423 epoch 32 - iter 371/538 - loss 0.04460549 - samples/sec: 135.63 - lr: 0.000008
2021-07-22 13:54:52,086 epoch 32 - iter 424/538 - loss 0.04438394 - samples/sec: 133.96 - lr: 0.000008
2021-07-22 13:55:04,743 epoch 32 - iter 477/538 - loss 0.04479656 - samples/sec: 134.03 - lr: 0.000008
2021-07-22 13:55:17,371 epoch 32 - iter 530/538 - loss 0.04559205 - samples/sec: 134.33 - lr: 0.000008
2021-07-22 13:55:19,336 ----------------------------------------------------------------------------------------------------
2021-07-22 13:55:19,336 EPOCH 32 done: loss 0.0455 - lr 0.0000075
2021-07-22 13:55:24,967 DEV : loss 0.04509836807847023 - score 0.9852
2021-07-22 13:55:25,031 BAD EPOCHS (no improvement): 1
2021-07-22 13:55:25,032 ----------------------------------------------------------------------------------------------------
2021-07-22 13:55:37,888 epoch 33 - iter 53/538 - loss 0.04476131 - samples/sec: 131.96 - lr: 0.000008
2021-07-22 13:55:50,669 epoch 33 - iter 106/538 - loss 0.04274362 - samples/sec: 132.72 - lr: 0.000008
2021-07-22 13:56:03,179 epoch 33 - iter 159/538 - loss 0.04340441 - samples/sec: 135.60 - lr: 0.000008
2021-07-22 13:56:15,608 epoch 33 - iter 212/538 - loss 0.04417758 - samples/sec: 136.48 - lr: 0.000008
2021-07-22 13:56:28,354 epoch 33 - iter 265/538 - loss 0.04399488 - samples/sec: 133.09 - lr: 0.000008
2021-07-22 13:56:40,966 epoch 33 - iter 318/538 - loss 0.04361897 - samples/sec: 134.50 - lr: 0.000008
2021-07-22 13:56:53,694 epoch 33 - iter 371/538 - loss 0.04368227 - samples/sec: 133.28 - lr: 0.000008
2021-07-22 13:57:06,263 epoch 33 - iter 424/538 - loss 0.04602129 - samples/sec: 134.97 - lr: 0.000008
2021-07-22 13:57:18,969 epoch 33 - iter 477/538 - loss 0.04605548 - samples/sec: 133.51 - lr: 0.000008
2021-07-22 13:57:31,544 epoch 33 - iter 530/538 - loss 0.04541557 - samples/sec: 134.90 - lr: 0.000008
2021-07-22 13:57:33,396 ----------------------------------------------------------------------------------------------------
2021-07-22 13:57:33,396 EPOCH 33 done: loss 0.0454 - lr 0.0000075
2021-07-22 13:57:39,015 DEV : loss 0.04432978481054306 - score 0.9872
2021-07-22 13:57:39,079 BAD EPOCHS (no improvement): 2
2021-07-22 13:57:39,079 ----------------------------------------------------------------------------------------------------
2021-07-22 13:57:51,918 epoch 34 - iter 53/538 - loss 0.04618002 - samples/sec: 132.15 - lr: 0.000008
2021-07-22 13:58:04,477 epoch 34 - iter 106/538 - loss 0.03691569 - samples/sec: 135.07 - lr: 0.000008
2021-07-22 13:58:16,986 epoch 34 - iter 159/538 - loss 0.04114784 - samples/sec: 135.61 - lr: 0.000008
2021-07-22 13:58:29,775 epoch 34 - iter 212/538 - loss 0.04076072 - samples/sec: 132.64 - lr: 0.000008
2021-07-22 13:58:42,259 epoch 34 - iter 265/538 - loss 0.04340700 - samples/sec: 135.88 - lr: 0.000008
2021-07-22 13:58:55,144 epoch 34 - iter 318/538 - loss 0.04335331 - samples/sec: 131.66 - lr: 0.000008
2021-07-22 13:59:07,754 epoch 34 - iter 371/538 - loss 0.04342548 - samples/sec: 134.53 - lr: 0.000008
2021-07-22 13:59:20,460 epoch 34 - iter 424/538 - loss 0.04233954 - samples/sec: 133.51 - lr: 0.000008
2021-07-22 13:59:33,116 epoch 34 - iter 477/538 - loss 0.04359615 - samples/sec: 134.03 - lr: 0.000008
2021-07-22 13:59:45,769 epoch 34 - iter 530/538 - loss 0.04249704 - samples/sec: 134.07 - lr: 0.000008
2021-07-22 13:59:47,673 ----------------------------------------------------------------------------------------------------
2021-07-22 13:59:47,674 EPOCH 34 done: loss 0.0432 - lr 0.0000075
2021-07-22 13:59:53,295 DEV : loss 0.04436963424086571 - score 0.9849
2021-07-22 13:59:53,358 BAD EPOCHS (no improvement): 3
2021-07-22 13:59:53,359 ----------------------------------------------------------------------------------------------------
2021-07-22 14:00:06,231 epoch 35 - iter 53/538 - loss 0.06074479 - samples/sec: 131.79 - lr: 0.000008
2021-07-22 14:00:18,760 epoch 35 - iter 106/538 - loss 0.05438418 - samples/sec: 135.40 - lr: 0.000008
2021-07-22 14:00:31,539 epoch 35 - iter 159/538 - loss 0.04647463 - samples/sec: 132.75 - lr: 0.000008
2021-07-22 14:00:44,130 epoch 35 - iter 212/538 - loss 0.04557069 - samples/sec: 134.72 - lr: 0.000008
2021-07-22 14:00:56,793 epoch 35 - iter 265/538 - loss 0.04702880 - samples/sec: 133.97 - lr: 0.000008
2021-07-22 14:01:09,320 epoch 35 - iter 318/538 - loss 0.04807938 - samples/sec: 135.42 - lr: 0.000008
2021-07-22 14:01:21,925 epoch 35 - iter 371/538 - loss 0.04666386 - samples/sec: 134.58 - lr: 0.000008
2021-07-22 14:01:34,178 epoch 35 - iter 424/538 - loss 0.04634291 - samples/sec: 138.44 - lr: 0.000008
2021-07-22 14:01:46,791 epoch 35 - iter 477/538 - loss 0.04477226 - samples/sec: 134.50 - lr: 0.000008
2021-07-22 14:01:59,232 epoch 35 - iter 530/538 - loss 0.04452103 - samples/sec: 136.36 - lr: 0.000008
2021-07-22 14:02:01,249 ----------------------------------------------------------------------------------------------------
2021-07-22 14:02:01,249 EPOCH 35 done: loss 0.0447 - lr 0.0000075
2021-07-22 14:02:06,883 DEV : loss 0.044049546122550964 - score 0.9865
Epoch    35: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 14:02:06,947 BAD EPOCHS (no improvement): 4
2021-07-22 14:02:06,947 ----------------------------------------------------------------------------------------------------
2021-07-22 14:02:19,628 epoch 36 - iter 53/538 - loss 0.03891849 - samples/sec: 133.79 - lr: 0.000004
2021-07-22 14:02:32,475 epoch 36 - iter 106/538 - loss 0.04221421 - samples/sec: 132.04 - lr: 0.000004
2021-07-22 14:02:45,095 epoch 36 - iter 159/538 - loss 0.04343655 - samples/sec: 134.42 - lr: 0.000004
2021-07-22 14:02:57,900 epoch 36 - iter 212/538 - loss 0.04344288 - samples/sec: 132.48 - lr: 0.000004
2021-07-22 14:03:10,529 epoch 36 - iter 265/538 - loss 0.04617301 - samples/sec: 134.32 - lr: 0.000004
2021-07-22 14:03:22,928 epoch 36 - iter 318/538 - loss 0.04546982 - samples/sec: 136.81 - lr: 0.000004
2021-07-22 14:03:35,508 epoch 36 - iter 371/538 - loss 0.04568067 - samples/sec: 134.84 - lr: 0.000004
2021-07-22 14:03:48,107 epoch 36 - iter 424/538 - loss 0.04560771 - samples/sec: 134.65 - lr: 0.000004
2021-07-22 14:04:00,876 epoch 36 - iter 477/538 - loss 0.04473818 - samples/sec: 132.85 - lr: 0.000004
2021-07-22 14:04:13,449 epoch 36 - iter 530/538 - loss 0.04422864 - samples/sec: 134.92 - lr: 0.000004
2021-07-22 14:04:15,408 ----------------------------------------------------------------------------------------------------
2021-07-22 14:04:15,409 EPOCH 36 done: loss 0.0445 - lr 0.0000038
2021-07-22 14:04:21,040 DEV : loss 0.04413178935647011 - score 0.9865
2021-07-22 14:04:21,105 BAD EPOCHS (no improvement): 1
2021-07-22 14:04:21,105 ----------------------------------------------------------------------------------------------------
2021-07-22 14:04:33,793 epoch 37 - iter 53/538 - loss 0.04376095 - samples/sec: 133.71 - lr: 0.000004
2021-07-22 14:04:46,606 epoch 37 - iter 106/538 - loss 0.04650710 - samples/sec: 132.40 - lr: 0.000004
2021-07-22 14:04:59,386 epoch 37 - iter 159/538 - loss 0.04980563 - samples/sec: 132.73 - lr: 0.000004
2021-07-22 14:05:12,190 epoch 37 - iter 212/538 - loss 0.04836565 - samples/sec: 132.50 - lr: 0.000004
2021-07-22 14:05:24,824 epoch 37 - iter 265/538 - loss 0.04751591 - samples/sec: 134.27 - lr: 0.000004
2021-07-22 14:05:37,673 epoch 37 - iter 318/538 - loss 0.04449530 - samples/sec: 132.02 - lr: 0.000004
2021-07-22 14:05:50,197 epoch 37 - iter 371/538 - loss 0.04615359 - samples/sec: 135.46 - lr: 0.000004
2021-07-22 14:06:02,489 epoch 37 - iter 424/538 - loss 0.04574113 - samples/sec: 138.00 - lr: 0.000004
2021-07-22 14:06:14,967 epoch 37 - iter 477/538 - loss 0.04586396 - samples/sec: 135.96 - lr: 0.000004
2021-07-22 14:06:27,148 epoch 37 - iter 530/538 - loss 0.04555322 - samples/sec: 139.26 - lr: 0.000004
2021-07-22 14:06:29,121 ----------------------------------------------------------------------------------------------------
2021-07-22 14:06:29,121 EPOCH 37 done: loss 0.0456 - lr 0.0000038
2021-07-22 14:06:34,755 DEV : loss 0.044250212609767914 - score 0.9869
2021-07-22 14:06:34,819 BAD EPOCHS (no improvement): 2
2021-07-22 14:06:34,819 ----------------------------------------------------------------------------------------------------
2021-07-22 14:06:47,511 epoch 38 - iter 53/538 - loss 0.03450283 - samples/sec: 133.68 - lr: 0.000004
2021-07-22 14:07:00,177 epoch 38 - iter 106/538 - loss 0.03561210 - samples/sec: 133.93 - lr: 0.000004
2021-07-22 14:07:12,996 epoch 38 - iter 159/538 - loss 0.04221732 - samples/sec: 132.33 - lr: 0.000004
2021-07-22 14:07:25,800 epoch 38 - iter 212/538 - loss 0.04316324 - samples/sec: 132.49 - lr: 0.000004
2021-07-22 14:07:37,912 epoch 38 - iter 265/538 - loss 0.04232228 - samples/sec: 140.06 - lr: 0.000004
2021-07-22 14:07:50,376 epoch 38 - iter 318/538 - loss 0.04156152 - samples/sec: 136.10 - lr: 0.000004
2021-07-22 14:08:03,052 epoch 38 - iter 371/538 - loss 0.04290885 - samples/sec: 133.83 - lr: 0.000004
2021-07-22 14:08:15,746 epoch 38 - iter 424/538 - loss 0.04186049 - samples/sec: 133.63 - lr: 0.000004
2021-07-22 14:08:28,419 epoch 38 - iter 477/538 - loss 0.04116926 - samples/sec: 133.85 - lr: 0.000004
2021-07-22 14:08:40,867 epoch 38 - iter 530/538 - loss 0.04126832 - samples/sec: 136.28 - lr: 0.000004
2021-07-22 14:08:42,912 ----------------------------------------------------------------------------------------------------
2021-07-22 14:08:42,912 EPOCH 38 done: loss 0.0413 - lr 0.0000038
2021-07-22 14:08:49,095 DEV : loss 0.04365984722971916 - score 0.9856
2021-07-22 14:08:49,158 BAD EPOCHS (no improvement): 3
2021-07-22 14:08:49,159 ----------------------------------------------------------------------------------------------------
2021-07-22 14:09:01,724 epoch 39 - iter 53/538 - loss 0.03049771 - samples/sec: 135.02 - lr: 0.000004
2021-07-22 14:09:14,203 epoch 39 - iter 106/538 - loss 0.03867025 - samples/sec: 135.94 - lr: 0.000004
2021-07-22 14:09:26,629 epoch 39 - iter 159/538 - loss 0.03834836 - samples/sec: 136.52 - lr: 0.000004
2021-07-22 14:09:39,059 epoch 39 - iter 212/538 - loss 0.04016358 - samples/sec: 136.47 - lr: 0.000004
2021-07-22 14:09:51,819 epoch 39 - iter 265/538 - loss 0.03907078 - samples/sec: 132.95 - lr: 0.000004
2021-07-22 14:10:04,459 epoch 39 - iter 318/538 - loss 0.04221532 - samples/sec: 134.20 - lr: 0.000004
2021-07-22 14:10:17,081 epoch 39 - iter 371/538 - loss 0.04370594 - samples/sec: 134.40 - lr: 0.000004
2021-07-22 14:10:29,458 epoch 39 - iter 424/538 - loss 0.04308566 - samples/sec: 137.06 - lr: 0.000004
2021-07-22 14:10:42,143 epoch 39 - iter 477/538 - loss 0.04529359 - samples/sec: 133.72 - lr: 0.000004
2021-07-22 14:10:54,800 epoch 39 - iter 530/538 - loss 0.04409121 - samples/sec: 134.03 - lr: 0.000004
2021-07-22 14:10:56,603 ----------------------------------------------------------------------------------------------------
2021-07-22 14:10:56,604 EPOCH 39 done: loss 0.0444 - lr 0.0000038
2021-07-22 14:11:02,215 DEV : loss 0.04383529722690582 - score 0.9862
Epoch    39: reducing learning rate of group 0 to 1.8750e-06.
2021-07-22 14:11:02,279 BAD EPOCHS (no improvement): 4
2021-07-22 14:11:02,280 ----------------------------------------------------------------------------------------------------
2021-07-22 14:11:02,280 ----------------------------------------------------------------------------------------------------
2021-07-22 14:11:02,280 learning rate too small - quitting training!
2021-07-22 14:11:02,280 ----------------------------------------------------------------------------------------------------
2021-07-22 14:11:02,867 ----------------------------------------------------------------------------------------------------
2021-07-22 14:11:02,867 Testing using best model ...
2021-07-22 14:11:02,868 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/eng.rst.rstdt/best-model.pt
2021-07-22 14:12:10,115 0.9841	0.9938	0.9889
2021-07-22 14:12:10,115 
Results:
- F1-score (micro) 0.9889
- F1-score (macro) 0.9877

By class:
SENT       tp: 1485 - fp: 54 - fn: 21 - precision: 0.9649 - recall: 0.9861 - f1-score: 0.9754
X          tp: 1855 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 14:12:10,115 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/tur.pdtb.tdb/
2021-07-22 14:12:10,147 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/tur.pdtb.tdb
2021-07-22 14:12:10,148 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/tur.pdtb.tdb/sent_train.txt
2021-07-22 14:12:10,150 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/tur.pdtb.tdb/sent_dev.txt
2021-07-22 14:12:10,151 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/tur.pdtb.tdb/sent_test.txt
Corpus: 45639 train + 7479 dev + 15335 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 14:12:26,814 ----------------------------------------------------------------------------------------------------
2021-07-22 14:12:26,816 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(32000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 14:12:26,816 ----------------------------------------------------------------------------------------------------
2021-07-22 14:12:26,816 Corpus: "Corpus: 45639 train + 7479 dev + 15335 test sentences"
2021-07-22 14:12:26,816 ----------------------------------------------------------------------------------------------------
2021-07-22 14:12:26,816 Parameters:
2021-07-22 14:12:26,816  - learning_rate: "3e-05"
2021-07-22 14:12:26,816  - mini_batch_size: "32"
2021-07-22 14:12:26,816  - patience: "3"
2021-07-22 14:12:26,816  - anneal_factor: "0.5"
2021-07-22 14:12:26,816  - max_epochs: "40"
2021-07-22 14:12:26,817  - shuffle: "True"
2021-07-22 14:12:26,817  - train_with_dev: "False"
2021-07-22 14:12:26,817  - batch_growth_annealing: "False"
2021-07-22 14:12:26,817 ----------------------------------------------------------------------------------------------------
2021-07-22 14:12:26,817 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/tur.pdtb.tdb"
2021-07-22 14:12:26,817 ----------------------------------------------------------------------------------------------------
2021-07-22 14:12:26,817 Device: cuda:0
2021-07-22 14:12:26,817 ----------------------------------------------------------------------------------------------------
2021-07-22 14:12:26,817 Embeddings storage mode: cpu
2021-07-22 14:12:26,819 ----------------------------------------------------------------------------------------------------
2021-07-22 14:13:45,359 epoch 1 - iter 142/1427 - loss 5.88921981 - samples/sec: 57.86 - lr: 0.000030
2021-07-22 14:15:04,389 epoch 1 - iter 284/1427 - loss 3.46729945 - samples/sec: 57.50 - lr: 0.000030
2021-07-22 14:16:25,285 epoch 1 - iter 426/1427 - loss 2.46445123 - samples/sec: 56.17 - lr: 0.000030
2021-07-22 14:17:49,960 epoch 1 - iter 568/1427 - loss 1.93625026 - samples/sec: 53.67 - lr: 0.000030
2021-07-22 14:19:16,853 epoch 1 - iter 710/1427 - loss 1.60595502 - samples/sec: 52.30 - lr: 0.000030
2021-07-22 14:20:41,368 epoch 1 - iter 852/1427 - loss 1.38472344 - samples/sec: 53.77 - lr: 0.000030
2021-07-22 14:22:02,874 epoch 1 - iter 994/1427 - loss 1.22364695 - samples/sec: 55.75 - lr: 0.000030
2021-07-22 14:23:23,314 epoch 1 - iter 1136/1427 - loss 1.10539318 - samples/sec: 56.49 - lr: 0.000030
2021-07-22 14:24:44,384 epoch 1 - iter 1278/1427 - loss 1.00970023 - samples/sec: 56.05 - lr: 0.000030
2021-07-22 14:26:04,791 epoch 1 - iter 1420/1427 - loss 0.93243749 - samples/sec: 56.52 - lr: 0.000030
2021-07-22 14:26:08,326 ----------------------------------------------------------------------------------------------------
2021-07-22 14:26:08,326 EPOCH 1 done: loss 0.9293 - lr 0.0000300
2021-07-22 14:27:43,510 DEV : loss 0.17409351468086243 - score 0.957
2021-07-22 14:27:43,686 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:27:44,351 ----------------------------------------------------------------------------------------------------
2021-07-22 14:28:16,270 epoch 2 - iter 142/1427 - loss 0.21271016 - samples/sec: 142.41 - lr: 0.000030
2021-07-22 14:28:48,408 epoch 2 - iter 284/1427 - loss 0.21051358 - samples/sec: 141.42 - lr: 0.000030
2021-07-22 14:29:20,286 epoch 2 - iter 426/1427 - loss 0.20879247 - samples/sec: 142.58 - lr: 0.000030
2021-07-22 14:29:52,219 epoch 2 - iter 568/1427 - loss 0.20710828 - samples/sec: 142.33 - lr: 0.000030
2021-07-22 14:30:24,595 epoch 2 - iter 710/1427 - loss 0.20829859 - samples/sec: 140.38 - lr: 0.000030
2021-07-22 14:30:56,487 epoch 2 - iter 852/1427 - loss 0.20768038 - samples/sec: 142.51 - lr: 0.000030
2021-07-22 14:31:28,816 epoch 2 - iter 994/1427 - loss 0.20589507 - samples/sec: 140.59 - lr: 0.000030
2021-07-22 14:32:00,856 epoch 2 - iter 1136/1427 - loss 0.20576589 - samples/sec: 141.85 - lr: 0.000030
2021-07-22 14:32:32,544 epoch 2 - iter 1278/1427 - loss 0.20557978 - samples/sec: 143.43 - lr: 0.000030
2021-07-22 14:33:04,296 epoch 2 - iter 1420/1427 - loss 0.20457545 - samples/sec: 143.15 - lr: 0.000030
2021-07-22 14:33:05,748 ----------------------------------------------------------------------------------------------------
2021-07-22 14:33:05,748 EPOCH 2 done: loss 0.2045 - lr 0.0000300
2021-07-22 14:33:24,176 DEV : loss 0.16124509274959564 - score 0.9627
2021-07-22 14:33:24,357 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:33:26,625 ----------------------------------------------------------------------------------------------------
2021-07-22 14:33:58,865 epoch 3 - iter 142/1427 - loss 0.16357969 - samples/sec: 141.00 - lr: 0.000030
2021-07-22 14:34:30,957 epoch 3 - iter 284/1427 - loss 0.17047726 - samples/sec: 141.63 - lr: 0.000030
2021-07-22 14:35:02,931 epoch 3 - iter 426/1427 - loss 0.17643707 - samples/sec: 142.15 - lr: 0.000030
2021-07-22 14:35:34,700 epoch 3 - iter 568/1427 - loss 0.17811685 - samples/sec: 143.07 - lr: 0.000030
2021-07-22 14:36:06,943 epoch 3 - iter 710/1427 - loss 0.17995018 - samples/sec: 140.96 - lr: 0.000030
2021-07-22 14:36:39,038 epoch 3 - iter 852/1427 - loss 0.18150826 - samples/sec: 141.61 - lr: 0.000030
2021-07-22 14:37:11,280 epoch 3 - iter 994/1427 - loss 0.18181653 - samples/sec: 140.97 - lr: 0.000030
2021-07-22 14:37:43,411 epoch 3 - iter 1136/1427 - loss 0.18221213 - samples/sec: 141.45 - lr: 0.000030
2021-07-22 14:38:15,892 epoch 3 - iter 1278/1427 - loss 0.18069114 - samples/sec: 139.93 - lr: 0.000030
2021-07-22 14:38:48,215 epoch 3 - iter 1420/1427 - loss 0.17997130 - samples/sec: 140.61 - lr: 0.000030
2021-07-22 14:38:49,763 ----------------------------------------------------------------------------------------------------
2021-07-22 14:38:49,763 EPOCH 3 done: loss 0.1803 - lr 0.0000300
2021-07-22 14:39:06,824 DEV : loss 0.1514495313167572 - score 0.9633
2021-07-22 14:39:07,001 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:39:09,296 ----------------------------------------------------------------------------------------------------
2021-07-22 14:39:41,167 epoch 4 - iter 142/1427 - loss 0.17451243 - samples/sec: 142.62 - lr: 0.000030
2021-07-22 14:40:13,823 epoch 4 - iter 284/1427 - loss 0.17037203 - samples/sec: 139.18 - lr: 0.000030
2021-07-22 14:40:46,174 epoch 4 - iter 426/1427 - loss 0.16852883 - samples/sec: 140.49 - lr: 0.000030
2021-07-22 14:41:18,538 epoch 4 - iter 568/1427 - loss 0.16638490 - samples/sec: 140.43 - lr: 0.000030
2021-07-22 14:41:50,743 epoch 4 - iter 710/1427 - loss 0.16313712 - samples/sec: 141.13 - lr: 0.000030
2021-07-22 14:42:23,555 epoch 4 - iter 852/1427 - loss 0.16541240 - samples/sec: 138.52 - lr: 0.000030
2021-07-22 14:42:55,971 epoch 4 - iter 994/1427 - loss 0.16410240 - samples/sec: 140.21 - lr: 0.000030
2021-07-22 14:43:28,370 epoch 4 - iter 1136/1427 - loss 0.16363087 - samples/sec: 140.28 - lr: 0.000030
2021-07-22 14:44:00,555 epoch 4 - iter 1278/1427 - loss 0.16159458 - samples/sec: 141.22 - lr: 0.000030
2021-07-22 14:44:32,568 epoch 4 - iter 1420/1427 - loss 0.16109628 - samples/sec: 141.98 - lr: 0.000030
2021-07-22 14:44:34,030 ----------------------------------------------------------------------------------------------------
2021-07-22 14:44:34,031 EPOCH 4 done: loss 0.1614 - lr 0.0000300
2021-07-22 14:44:51,319 DEV : loss 0.14434385299682617 - score 0.9632
2021-07-22 14:44:51,500 BAD EPOCHS (no improvement): 1
2021-07-22 14:44:51,500 ----------------------------------------------------------------------------------------------------
2021-07-22 14:45:23,896 epoch 5 - iter 142/1427 - loss 0.15206303 - samples/sec: 140.31 - lr: 0.000030
2021-07-22 14:45:55,975 epoch 5 - iter 284/1427 - loss 0.15039736 - samples/sec: 141.69 - lr: 0.000030
2021-07-22 14:46:28,382 epoch 5 - iter 426/1427 - loss 0.14789382 - samples/sec: 140.24 - lr: 0.000030
2021-07-22 14:47:00,460 epoch 5 - iter 568/1427 - loss 0.14814863 - samples/sec: 141.69 - lr: 0.000030
2021-07-22 14:47:33,041 epoch 5 - iter 710/1427 - loss 0.14634677 - samples/sec: 139.50 - lr: 0.000030
2021-07-22 14:48:05,135 epoch 5 - iter 852/1427 - loss 0.14472412 - samples/sec: 141.62 - lr: 0.000030
2021-07-22 14:48:37,616 epoch 5 - iter 994/1427 - loss 0.14536486 - samples/sec: 139.93 - lr: 0.000030
2021-07-22 14:49:10,071 epoch 5 - iter 1136/1427 - loss 0.14502923 - samples/sec: 140.04 - lr: 0.000030
2021-07-22 14:49:42,476 epoch 5 - iter 1278/1427 - loss 0.14502541 - samples/sec: 140.26 - lr: 0.000030
2021-07-22 14:50:14,699 epoch 5 - iter 1420/1427 - loss 0.14412938 - samples/sec: 141.05 - lr: 0.000030
2021-07-22 14:50:16,115 ----------------------------------------------------------------------------------------------------
2021-07-22 14:50:16,115 EPOCH 5 done: loss 0.1440 - lr 0.0000300
2021-07-22 14:50:33,507 DEV : loss 0.14168952405452728 - score 0.9627
2021-07-22 14:50:33,685 BAD EPOCHS (no improvement): 2
2021-07-22 14:50:33,686 ----------------------------------------------------------------------------------------------------
2021-07-22 14:51:06,293 epoch 6 - iter 142/1427 - loss 0.13683764 - samples/sec: 139.40 - lr: 0.000030
2021-07-22 14:51:39,382 epoch 6 - iter 284/1427 - loss 0.14029594 - samples/sec: 137.36 - lr: 0.000030
2021-07-22 14:52:11,660 epoch 6 - iter 426/1427 - loss 0.13833222 - samples/sec: 140.81 - lr: 0.000030
2021-07-22 14:52:44,128 epoch 6 - iter 568/1427 - loss 0.13429977 - samples/sec: 139.99 - lr: 0.000030
2021-07-22 14:53:16,704 epoch 6 - iter 710/1427 - loss 0.13493217 - samples/sec: 139.52 - lr: 0.000030
2021-07-22 14:53:49,064 epoch 6 - iter 852/1427 - loss 0.13438812 - samples/sec: 140.45 - lr: 0.000030
2021-07-22 14:54:21,572 epoch 6 - iter 994/1427 - loss 0.13382102 - samples/sec: 139.81 - lr: 0.000030
2021-07-22 14:54:53,795 epoch 6 - iter 1136/1427 - loss 0.13257800 - samples/sec: 141.05 - lr: 0.000030
2021-07-22 14:55:26,347 epoch 6 - iter 1278/1427 - loss 0.13435949 - samples/sec: 139.63 - lr: 0.000030
2021-07-22 14:55:58,722 epoch 6 - iter 1420/1427 - loss 0.13390982 - samples/sec: 140.38 - lr: 0.000030
2021-07-22 14:56:00,206 ----------------------------------------------------------------------------------------------------
2021-07-22 14:56:00,206 EPOCH 6 done: loss 0.1336 - lr 0.0000300
2021-07-22 14:56:17,609 DEV : loss 0.13253895938396454 - score 0.9646
2021-07-22 14:56:17,790 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:56:21,302 ----------------------------------------------------------------------------------------------------
2021-07-22 14:56:53,715 epoch 7 - iter 142/1427 - loss 0.13880354 - samples/sec: 140.24 - lr: 0.000030
2021-07-22 14:57:25,772 epoch 7 - iter 284/1427 - loss 0.13064278 - samples/sec: 141.78 - lr: 0.000030
2021-07-22 14:57:58,392 epoch 7 - iter 426/1427 - loss 0.13011062 - samples/sec: 139.33 - lr: 0.000030
2021-07-22 14:58:30,801 epoch 7 - iter 568/1427 - loss 0.12826100 - samples/sec: 140.24 - lr: 0.000030
2021-07-22 14:59:03,616 epoch 7 - iter 710/1427 - loss 0.12814249 - samples/sec: 138.50 - lr: 0.000030
2021-07-22 14:59:36,404 epoch 7 - iter 852/1427 - loss 0.12788164 - samples/sec: 138.62 - lr: 0.000030
2021-07-22 15:00:08,921 epoch 7 - iter 994/1427 - loss 0.12738624 - samples/sec: 139.77 - lr: 0.000030
2021-07-22 15:00:41,023 epoch 7 - iter 1136/1427 - loss 0.12682069 - samples/sec: 141.58 - lr: 0.000030
2021-07-22 15:01:13,099 epoch 7 - iter 1278/1427 - loss 0.12661053 - samples/sec: 141.69 - lr: 0.000030
2021-07-22 15:01:45,882 epoch 7 - iter 1420/1427 - loss 0.12542852 - samples/sec: 138.64 - lr: 0.000030
2021-07-22 15:01:47,272 ----------------------------------------------------------------------------------------------------
2021-07-22 15:01:47,272 EPOCH 7 done: loss 0.1262 - lr 0.0000300
2021-07-22 15:02:04,650 DEV : loss 0.1371130347251892 - score 0.9652
2021-07-22 15:02:04,829 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:02:06,988 ----------------------------------------------------------------------------------------------------
2021-07-22 15:02:39,070 epoch 8 - iter 142/1427 - loss 0.12228504 - samples/sec: 141.69 - lr: 0.000030
2021-07-22 15:03:11,244 epoch 8 - iter 284/1427 - loss 0.12051019 - samples/sec: 141.26 - lr: 0.000030
2021-07-22 15:03:43,643 epoch 8 - iter 426/1427 - loss 0.12082903 - samples/sec: 140.28 - lr: 0.000030
2021-07-22 15:04:15,837 epoch 8 - iter 568/1427 - loss 0.11976410 - samples/sec: 141.18 - lr: 0.000030
2021-07-22 15:04:48,336 epoch 8 - iter 710/1427 - loss 0.12325277 - samples/sec: 139.85 - lr: 0.000030
2021-07-22 15:05:20,699 epoch 8 - iter 852/1427 - loss 0.12230203 - samples/sec: 140.44 - lr: 0.000030
2021-07-22 15:05:53,220 epoch 8 - iter 994/1427 - loss 0.12163622 - samples/sec: 139.76 - lr: 0.000030
2021-07-22 15:06:25,836 epoch 8 - iter 1136/1427 - loss 0.12331340 - samples/sec: 139.35 - lr: 0.000030
2021-07-22 15:06:58,547 epoch 8 - iter 1278/1427 - loss 0.12420101 - samples/sec: 138.94 - lr: 0.000030
2021-07-22 15:07:30,878 epoch 8 - iter 1420/1427 - loss 0.12421357 - samples/sec: 140.58 - lr: 0.000030
2021-07-22 15:07:32,386 ----------------------------------------------------------------------------------------------------
2021-07-22 15:07:32,387 EPOCH 8 done: loss 0.1243 - lr 0.0000300
2021-07-22 15:07:49,714 DEV : loss 0.13263532519340515 - score 0.967
2021-07-22 15:07:49,897 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:07:52,313 ----------------------------------------------------------------------------------------------------
2021-07-22 15:08:25,034 epoch 9 - iter 142/1427 - loss 0.12162140 - samples/sec: 138.92 - lr: 0.000030
2021-07-22 15:08:57,344 epoch 9 - iter 284/1427 - loss 0.12332779 - samples/sec: 140.67 - lr: 0.000030
2021-07-22 15:09:29,698 epoch 9 - iter 426/1427 - loss 0.12360015 - samples/sec: 140.48 - lr: 0.000030
2021-07-22 15:10:02,110 epoch 9 - iter 568/1427 - loss 0.12410948 - samples/sec: 140.23 - lr: 0.000030
2021-07-22 15:10:34,399 epoch 9 - iter 710/1427 - loss 0.12131199 - samples/sec: 140.76 - lr: 0.000030
2021-07-22 15:11:06,768 epoch 9 - iter 852/1427 - loss 0.11974271 - samples/sec: 140.41 - lr: 0.000030
2021-07-22 15:11:39,324 epoch 9 - iter 994/1427 - loss 0.11964539 - samples/sec: 139.60 - lr: 0.000030
2021-07-22 15:12:12,056 epoch 9 - iter 1136/1427 - loss 0.11991074 - samples/sec: 138.86 - lr: 0.000030
2021-07-22 15:12:44,693 epoch 9 - iter 1278/1427 - loss 0.12001572 - samples/sec: 139.26 - lr: 0.000030
2021-07-22 15:13:16,725 epoch 9 - iter 1420/1427 - loss 0.12003789 - samples/sec: 141.89 - lr: 0.000030
2021-07-22 15:13:18,197 ----------------------------------------------------------------------------------------------------
2021-07-22 15:13:18,197 EPOCH 9 done: loss 0.1201 - lr 0.0000300
2021-07-22 15:13:35,485 DEV : loss 0.1297789216041565 - score 0.9673
2021-07-22 15:13:35,665 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:13:37,929 ----------------------------------------------------------------------------------------------------
2021-07-22 15:14:10,716 epoch 10 - iter 142/1427 - loss 0.11883895 - samples/sec: 138.64 - lr: 0.000030
2021-07-22 15:14:42,906 epoch 10 - iter 284/1427 - loss 0.11372682 - samples/sec: 141.19 - lr: 0.000030
2021-07-22 15:15:15,103 epoch 10 - iter 426/1427 - loss 0.11421962 - samples/sec: 141.16 - lr: 0.000030
2021-07-22 15:15:47,773 epoch 10 - iter 568/1427 - loss 0.11955295 - samples/sec: 139.12 - lr: 0.000030
2021-07-22 15:16:20,167 epoch 10 - iter 710/1427 - loss 0.11982585 - samples/sec: 140.30 - lr: 0.000030
2021-07-22 15:16:52,601 epoch 10 - iter 852/1427 - loss 0.11899858 - samples/sec: 140.13 - lr: 0.000030
2021-07-22 15:17:25,111 epoch 10 - iter 994/1427 - loss 0.12002416 - samples/sec: 139.81 - lr: 0.000030
2021-07-22 15:17:57,745 epoch 10 - iter 1136/1427 - loss 0.11933905 - samples/sec: 139.27 - lr: 0.000030
2021-07-22 15:18:30,227 epoch 10 - iter 1278/1427 - loss 0.11861440 - samples/sec: 139.92 - lr: 0.000030
2021-07-22 15:19:02,379 epoch 10 - iter 1420/1427 - loss 0.11856717 - samples/sec: 141.36 - lr: 0.000030
2021-07-22 15:19:03,906 ----------------------------------------------------------------------------------------------------
2021-07-22 15:19:03,907 EPOCH 10 done: loss 0.1189 - lr 0.0000300
2021-07-22 15:19:21,195 DEV : loss 0.12914538383483887 - score 0.9674
2021-07-22 15:19:21,377 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:19:23,594 ----------------------------------------------------------------------------------------------------
2021-07-22 15:19:56,217 epoch 11 - iter 142/1427 - loss 0.12579889 - samples/sec: 139.34 - lr: 0.000030
2021-07-22 15:20:28,982 epoch 11 - iter 284/1427 - loss 0.11976468 - samples/sec: 138.72 - lr: 0.000030
2021-07-22 15:21:01,123 epoch 11 - iter 426/1427 - loss 0.11425742 - samples/sec: 141.41 - lr: 0.000030
2021-07-22 15:21:33,603 epoch 11 - iter 568/1427 - loss 0.11332375 - samples/sec: 139.94 - lr: 0.000030
2021-07-22 15:22:05,793 epoch 11 - iter 710/1427 - loss 0.11376642 - samples/sec: 141.19 - lr: 0.000030
2021-07-22 15:22:37,684 epoch 11 - iter 852/1427 - loss 0.11325968 - samples/sec: 142.52 - lr: 0.000030
2021-07-22 15:23:11,516 epoch 11 - iter 994/1427 - loss 0.11254354 - samples/sec: 134.34 - lr: 0.000030
2021-07-22 15:23:43,865 epoch 11 - iter 1136/1427 - loss 0.11292524 - samples/sec: 140.50 - lr: 0.000030
2021-07-22 15:24:16,052 epoch 11 - iter 1278/1427 - loss 0.11369243 - samples/sec: 141.21 - lr: 0.000030
2021-07-22 15:24:48,175 epoch 11 - iter 1420/1427 - loss 0.11368484 - samples/sec: 141.49 - lr: 0.000030
2021-07-22 15:24:49,693 ----------------------------------------------------------------------------------------------------
2021-07-22 15:24:49,693 EPOCH 11 done: loss 0.1137 - lr 0.0000300
2021-07-22 15:25:06,940 DEV : loss 0.1265944391489029 - score 0.9681
2021-07-22 15:25:07,120 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:25:09,174 ----------------------------------------------------------------------------------------------------
2021-07-22 15:25:41,088 epoch 12 - iter 142/1427 - loss 0.12016173 - samples/sec: 142.43 - lr: 0.000030
2021-07-22 15:26:13,460 epoch 12 - iter 284/1427 - loss 0.11303120 - samples/sec: 140.40 - lr: 0.000030
2021-07-22 15:26:45,935 epoch 12 - iter 426/1427 - loss 0.11256586 - samples/sec: 139.95 - lr: 0.000030
2021-07-22 15:27:18,372 epoch 12 - iter 568/1427 - loss 0.11256621 - samples/sec: 140.12 - lr: 0.000030
2021-07-22 15:27:50,660 epoch 12 - iter 710/1427 - loss 0.11189435 - samples/sec: 140.77 - lr: 0.000030
2021-07-22 15:28:23,024 epoch 12 - iter 852/1427 - loss 0.11238169 - samples/sec: 140.44 - lr: 0.000030
2021-07-22 15:28:55,463 epoch 12 - iter 994/1427 - loss 0.11403615 - samples/sec: 140.11 - lr: 0.000030
2021-07-22 15:29:27,879 epoch 12 - iter 1136/1427 - loss 0.11187677 - samples/sec: 140.21 - lr: 0.000030
2021-07-22 15:30:00,635 epoch 12 - iter 1278/1427 - loss 0.11231605 - samples/sec: 138.76 - lr: 0.000030
2021-07-22 15:30:33,332 epoch 12 - iter 1420/1427 - loss 0.11158105 - samples/sec: 139.01 - lr: 0.000030
2021-07-22 15:30:34,746 ----------------------------------------------------------------------------------------------------
2021-07-22 15:30:34,746 EPOCH 12 done: loss 0.1114 - lr 0.0000300
2021-07-22 15:30:51,960 DEV : loss 0.12759722769260406 - score 0.9682
2021-07-22 15:30:52,140 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:30:54,395 ----------------------------------------------------------------------------------------------------
2021-07-22 15:31:26,606 epoch 13 - iter 142/1427 - loss 0.09427598 - samples/sec: 141.29 - lr: 0.000030
2021-07-22 15:31:59,598 epoch 13 - iter 284/1427 - loss 0.10577303 - samples/sec: 137.76 - lr: 0.000030
2021-07-22 15:32:31,953 epoch 13 - iter 426/1427 - loss 0.10724845 - samples/sec: 140.48 - lr: 0.000030
2021-07-22 15:33:04,091 epoch 13 - iter 568/1427 - loss 0.10776973 - samples/sec: 141.42 - lr: 0.000030
2021-07-22 15:33:36,519 epoch 13 - iter 710/1427 - loss 0.10700498 - samples/sec: 140.16 - lr: 0.000030
2021-07-22 15:34:08,639 epoch 13 - iter 852/1427 - loss 0.10698134 - samples/sec: 141.50 - lr: 0.000030
2021-07-22 15:34:41,169 epoch 13 - iter 994/1427 - loss 0.10654588 - samples/sec: 139.72 - lr: 0.000030
2021-07-22 15:35:13,348 epoch 13 - iter 1136/1427 - loss 0.10656596 - samples/sec: 141.25 - lr: 0.000030
2021-07-22 15:35:45,450 epoch 13 - iter 1278/1427 - loss 0.10694912 - samples/sec: 141.58 - lr: 0.000030
2021-07-22 15:36:17,911 epoch 13 - iter 1420/1427 - loss 0.10837476 - samples/sec: 140.01 - lr: 0.000030
2021-07-22 15:36:19,345 ----------------------------------------------------------------------------------------------------
2021-07-22 15:36:19,346 EPOCH 13 done: loss 0.1083 - lr 0.0000300
2021-07-22 15:36:36,601 DEV : loss 0.12280941754579544 - score 0.9685
2021-07-22 15:36:36,782 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:36:39,052 ----------------------------------------------------------------------------------------------------
2021-07-22 15:37:11,191 epoch 14 - iter 142/1427 - loss 0.11139108 - samples/sec: 141.44 - lr: 0.000030
2021-07-22 15:37:43,462 epoch 14 - iter 284/1427 - loss 0.10899943 - samples/sec: 140.84 - lr: 0.000030
2021-07-22 15:38:16,091 epoch 14 - iter 426/1427 - loss 0.11136039 - samples/sec: 139.29 - lr: 0.000030
2021-07-22 15:38:48,708 epoch 14 - iter 568/1427 - loss 0.10952642 - samples/sec: 139.35 - lr: 0.000030
2021-07-22 15:39:21,275 epoch 14 - iter 710/1427 - loss 0.10691021 - samples/sec: 139.56 - lr: 0.000030
2021-07-22 15:39:53,814 epoch 14 - iter 852/1427 - loss 0.10761674 - samples/sec: 139.68 - lr: 0.000030
2021-07-22 15:40:25,823 epoch 14 - iter 994/1427 - loss 0.10606371 - samples/sec: 141.99 - lr: 0.000030
2021-07-22 15:40:57,942 epoch 14 - iter 1136/1427 - loss 0.10505324 - samples/sec: 141.51 - lr: 0.000030
2021-07-22 15:41:30,067 epoch 14 - iter 1278/1427 - loss 0.10517678 - samples/sec: 141.48 - lr: 0.000030
2021-07-22 15:42:02,624 epoch 14 - iter 1420/1427 - loss 0.10513517 - samples/sec: 139.60 - lr: 0.000030
2021-07-22 15:42:03,974 ----------------------------------------------------------------------------------------------------
2021-07-22 15:42:03,974 EPOCH 14 done: loss 0.1050 - lr 0.0000300
2021-07-22 15:42:21,250 DEV : loss 0.1220579594373703 - score 0.9695
2021-07-22 15:42:21,432 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:42:23,731 ----------------------------------------------------------------------------------------------------
2021-07-22 15:42:56,524 epoch 15 - iter 142/1427 - loss 0.10311520 - samples/sec: 138.62 - lr: 0.000030
2021-07-22 15:43:28,552 epoch 15 - iter 284/1427 - loss 0.10858952 - samples/sec: 141.91 - lr: 0.000030
2021-07-22 15:44:00,831 epoch 15 - iter 426/1427 - loss 0.10933977 - samples/sec: 140.81 - lr: 0.000030
2021-07-22 15:44:33,028 epoch 15 - iter 568/1427 - loss 0.10748752 - samples/sec: 141.16 - lr: 0.000030
2021-07-22 15:45:05,695 epoch 15 - iter 710/1427 - loss 0.10532443 - samples/sec: 139.13 - lr: 0.000030
2021-07-22 15:45:37,992 epoch 15 - iter 852/1427 - loss 0.10525585 - samples/sec: 140.73 - lr: 0.000030
2021-07-22 15:46:10,236 epoch 15 - iter 994/1427 - loss 0.10473471 - samples/sec: 140.96 - lr: 0.000030
2021-07-22 15:46:42,893 epoch 15 - iter 1136/1427 - loss 0.10307463 - samples/sec: 139.17 - lr: 0.000030
2021-07-22 15:47:15,332 epoch 15 - iter 1278/1427 - loss 0.10270710 - samples/sec: 140.11 - lr: 0.000030
2021-07-22 15:47:47,155 epoch 15 - iter 1420/1427 - loss 0.10346785 - samples/sec: 142.82 - lr: 0.000030
2021-07-22 15:47:48,649 ----------------------------------------------------------------------------------------------------
2021-07-22 15:47:48,650 EPOCH 15 done: loss 0.1035 - lr 0.0000300
2021-07-22 15:48:07,305 DEV : loss 0.11879833787679672 - score 0.9693
2021-07-22 15:48:07,487 BAD EPOCHS (no improvement): 1
2021-07-22 15:48:07,487 ----------------------------------------------------------------------------------------------------
2021-07-22 15:48:39,772 epoch 16 - iter 142/1427 - loss 0.10125683 - samples/sec: 140.80 - lr: 0.000030
2021-07-22 15:49:11,979 epoch 16 - iter 284/1427 - loss 0.10452617 - samples/sec: 141.12 - lr: 0.000030
2021-07-22 15:49:44,844 epoch 16 - iter 426/1427 - loss 0.10346451 - samples/sec: 138.29 - lr: 0.000030
2021-07-22 15:50:17,568 epoch 16 - iter 568/1427 - loss 0.10318112 - samples/sec: 138.89 - lr: 0.000030
2021-07-22 15:50:50,117 epoch 16 - iter 710/1427 - loss 0.10180579 - samples/sec: 139.64 - lr: 0.000030
2021-07-22 15:51:23,033 epoch 16 - iter 852/1427 - loss 0.10097332 - samples/sec: 138.08 - lr: 0.000030
2021-07-22 15:51:54,988 epoch 16 - iter 994/1427 - loss 0.10149008 - samples/sec: 142.23 - lr: 0.000030
2021-07-22 15:52:27,237 epoch 16 - iter 1136/1427 - loss 0.10209067 - samples/sec: 140.94 - lr: 0.000030
2021-07-22 15:52:59,603 epoch 16 - iter 1278/1427 - loss 0.10226110 - samples/sec: 140.42 - lr: 0.000030
2021-07-22 15:53:31,700 epoch 16 - iter 1420/1427 - loss 0.10169190 - samples/sec: 141.60 - lr: 0.000030
2021-07-22 15:53:33,162 ----------------------------------------------------------------------------------------------------
2021-07-22 15:53:33,162 EPOCH 16 done: loss 0.1018 - lr 0.0000300
2021-07-22 15:53:50,406 DEV : loss 0.12534701824188232 - score 0.9677
2021-07-22 15:53:50,587 BAD EPOCHS (no improvement): 2
2021-07-22 15:53:50,587 ----------------------------------------------------------------------------------------------------
2021-07-22 15:54:23,304 epoch 17 - iter 142/1427 - loss 0.08778272 - samples/sec: 138.93 - lr: 0.000030
2021-07-22 15:54:55,441 epoch 17 - iter 284/1427 - loss 0.09393684 - samples/sec: 141.43 - lr: 0.000030
2021-07-22 15:55:27,787 epoch 17 - iter 426/1427 - loss 0.09710848 - samples/sec: 140.51 - lr: 0.000030
2021-07-22 15:56:00,408 epoch 17 - iter 568/1427 - loss 0.09938666 - samples/sec: 139.33 - lr: 0.000030
2021-07-22 15:56:32,884 epoch 17 - iter 710/1427 - loss 0.10102862 - samples/sec: 139.95 - lr: 0.000030
2021-07-22 15:57:05,296 epoch 17 - iter 852/1427 - loss 0.10020074 - samples/sec: 140.23 - lr: 0.000030
2021-07-22 15:57:37,530 epoch 17 - iter 994/1427 - loss 0.09905950 - samples/sec: 141.00 - lr: 0.000030
2021-07-22 15:58:10,435 epoch 17 - iter 1136/1427 - loss 0.09969712 - samples/sec: 138.13 - lr: 0.000030
2021-07-22 15:58:42,737 epoch 17 - iter 1278/1427 - loss 0.09884398 - samples/sec: 140.70 - lr: 0.000030
2021-07-22 15:59:15,095 epoch 17 - iter 1420/1427 - loss 0.09904493 - samples/sec: 140.46 - lr: 0.000030
2021-07-22 15:59:16,608 ----------------------------------------------------------------------------------------------------
2021-07-22 15:59:16,608 EPOCH 17 done: loss 0.0990 - lr 0.0000300
2021-07-22 15:59:33,905 DEV : loss 0.12187670916318893 - score 0.9697
2021-07-22 15:59:34,085 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:59:36,716 ----------------------------------------------------------------------------------------------------
2021-07-22 16:00:09,192 epoch 18 - iter 142/1427 - loss 0.09397457 - samples/sec: 139.97 - lr: 0.000030
2021-07-22 16:00:41,563 epoch 18 - iter 284/1427 - loss 0.09594841 - samples/sec: 140.41 - lr: 0.000030
2021-07-22 16:01:13,603 epoch 18 - iter 426/1427 - loss 0.09591059 - samples/sec: 141.86 - lr: 0.000030
2021-07-22 16:01:46,004 epoch 18 - iter 568/1427 - loss 0.09692777 - samples/sec: 140.27 - lr: 0.000030
2021-07-22 16:02:18,071 epoch 18 - iter 710/1427 - loss 0.09593165 - samples/sec: 141.74 - lr: 0.000030
2021-07-22 16:02:50,022 epoch 18 - iter 852/1427 - loss 0.09667033 - samples/sec: 142.25 - lr: 0.000030
2021-07-22 16:03:22,490 epoch 18 - iter 994/1427 - loss 0.09750652 - samples/sec: 139.98 - lr: 0.000030
2021-07-22 16:03:55,407 epoch 18 - iter 1136/1427 - loss 0.09753662 - samples/sec: 138.07 - lr: 0.000030
2021-07-22 16:04:28,178 epoch 18 - iter 1278/1427 - loss 0.09798605 - samples/sec: 138.69 - lr: 0.000030
2021-07-22 16:05:00,162 epoch 18 - iter 1420/1427 - loss 0.09863578 - samples/sec: 142.10 - lr: 0.000030
2021-07-22 16:05:01,563 ----------------------------------------------------------------------------------------------------
2021-07-22 16:05:01,563 EPOCH 18 done: loss 0.0987 - lr 0.0000300
2021-07-22 16:05:18,834 DEV : loss 0.11758232861757278 - score 0.9697
2021-07-22 16:05:19,015 BAD EPOCHS (no improvement): 1
2021-07-22 16:05:19,015 ----------------------------------------------------------------------------------------------------
2021-07-22 16:05:51,173 epoch 19 - iter 142/1427 - loss 0.09550823 - samples/sec: 141.35 - lr: 0.000030
2021-07-22 16:06:23,527 epoch 19 - iter 284/1427 - loss 0.09561649 - samples/sec: 140.48 - lr: 0.000030
2021-07-22 16:06:56,405 epoch 19 - iter 426/1427 - loss 0.09526347 - samples/sec: 138.24 - lr: 0.000030
2021-07-22 16:07:28,774 epoch 19 - iter 568/1427 - loss 0.09207747 - samples/sec: 140.41 - lr: 0.000030
2021-07-22 16:08:01,046 epoch 19 - iter 710/1427 - loss 0.09198873 - samples/sec: 140.84 - lr: 0.000030
2021-07-22 16:08:33,604 epoch 19 - iter 852/1427 - loss 0.09349235 - samples/sec: 139.60 - lr: 0.000030
2021-07-22 16:09:06,364 epoch 19 - iter 994/1427 - loss 0.09428306 - samples/sec: 138.74 - lr: 0.000030
2021-07-22 16:09:38,275 epoch 19 - iter 1136/1427 - loss 0.09361531 - samples/sec: 142.43 - lr: 0.000030
2021-07-22 16:10:10,540 epoch 19 - iter 1278/1427 - loss 0.09459882 - samples/sec: 140.87 - lr: 0.000030
2021-07-22 16:10:43,059 epoch 19 - iter 1420/1427 - loss 0.09453559 - samples/sec: 139.77 - lr: 0.000030
2021-07-22 16:10:44,561 ----------------------------------------------------------------------------------------------------
2021-07-22 16:10:44,561 EPOCH 19 done: loss 0.0948 - lr 0.0000300
2021-07-22 16:11:03,178 DEV : loss 0.12060148268938065 - score 0.9687
2021-07-22 16:11:03,360 BAD EPOCHS (no improvement): 2
2021-07-22 16:11:03,360 ----------------------------------------------------------------------------------------------------
2021-07-22 16:11:35,777 epoch 20 - iter 142/1427 - loss 0.09331558 - samples/sec: 140.22 - lr: 0.000030
2021-07-22 16:12:08,176 epoch 20 - iter 284/1427 - loss 0.09575841 - samples/sec: 140.28 - lr: 0.000030
2021-07-22 16:12:40,799 epoch 20 - iter 426/1427 - loss 0.09767464 - samples/sec: 139.32 - lr: 0.000030
2021-07-22 16:13:12,862 epoch 20 - iter 568/1427 - loss 0.09650087 - samples/sec: 141.75 - lr: 0.000030
2021-07-22 16:13:45,291 epoch 20 - iter 710/1427 - loss 0.09613055 - samples/sec: 140.15 - lr: 0.000030
2021-07-22 16:14:17,606 epoch 20 - iter 852/1427 - loss 0.09427827 - samples/sec: 140.65 - lr: 0.000030
2021-07-22 16:14:50,072 epoch 20 - iter 994/1427 - loss 0.09318190 - samples/sec: 139.99 - lr: 0.000030
2021-07-22 16:15:22,555 epoch 20 - iter 1136/1427 - loss 0.09346764 - samples/sec: 139.92 - lr: 0.000030
2021-07-22 16:15:54,663 epoch 20 - iter 1278/1427 - loss 0.09342104 - samples/sec: 141.55 - lr: 0.000030
2021-07-22 16:16:27,249 epoch 20 - iter 1420/1427 - loss 0.09320784 - samples/sec: 139.48 - lr: 0.000030
2021-07-22 16:16:28,721 ----------------------------------------------------------------------------------------------------
2021-07-22 16:16:28,721 EPOCH 20 done: loss 0.0932 - lr 0.0000300
2021-07-22 16:16:45,975 DEV : loss 0.12175992131233215 - score 0.9695
2021-07-22 16:16:46,155 BAD EPOCHS (no improvement): 3
2021-07-22 16:16:46,156 ----------------------------------------------------------------------------------------------------
2021-07-22 16:17:18,557 epoch 21 - iter 142/1427 - loss 0.09655332 - samples/sec: 140.29 - lr: 0.000030
2021-07-22 16:17:51,014 epoch 21 - iter 284/1427 - loss 0.09648938 - samples/sec: 140.03 - lr: 0.000030
2021-07-22 16:18:23,707 epoch 21 - iter 426/1427 - loss 0.09467363 - samples/sec: 139.02 - lr: 0.000030
2021-07-22 16:18:55,895 epoch 21 - iter 568/1427 - loss 0.09406908 - samples/sec: 141.20 - lr: 0.000030
2021-07-22 16:19:27,804 epoch 21 - iter 710/1427 - loss 0.09214027 - samples/sec: 142.44 - lr: 0.000030
2021-07-22 16:20:00,358 epoch 21 - iter 852/1427 - loss 0.09106803 - samples/sec: 139.61 - lr: 0.000030
2021-07-22 16:20:32,872 epoch 21 - iter 994/1427 - loss 0.09167993 - samples/sec: 139.79 - lr: 0.000030
2021-07-22 16:21:05,012 epoch 21 - iter 1136/1427 - loss 0.09125423 - samples/sec: 141.41 - lr: 0.000030
2021-07-22 16:21:37,628 epoch 21 - iter 1278/1427 - loss 0.09081443 - samples/sec: 139.35 - lr: 0.000030
2021-07-22 16:22:10,215 epoch 21 - iter 1420/1427 - loss 0.09116696 - samples/sec: 139.47 - lr: 0.000030
2021-07-22 16:22:11,746 ----------------------------------------------------------------------------------------------------
2021-07-22 16:22:11,747 EPOCH 21 done: loss 0.0911 - lr 0.0000300
2021-07-22 16:22:29,047 DEV : loss 0.12118975818157196 - score 0.9698
2021-07-22 16:22:29,229 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 16:22:31,538 ----------------------------------------------------------------------------------------------------
2021-07-22 16:23:04,036 epoch 22 - iter 142/1427 - loss 0.09892123 - samples/sec: 139.88 - lr: 0.000030
2021-07-22 16:23:36,607 epoch 22 - iter 284/1427 - loss 0.09313351 - samples/sec: 139.54 - lr: 0.000030
2021-07-22 16:24:08,810 epoch 22 - iter 426/1427 - loss 0.09189792 - samples/sec: 141.14 - lr: 0.000030
2021-07-22 16:24:40,855 epoch 22 - iter 568/1427 - loss 0.09256598 - samples/sec: 141.83 - lr: 0.000030
2021-07-22 16:25:13,664 epoch 22 - iter 710/1427 - loss 0.09303918 - samples/sec: 138.53 - lr: 0.000030
2021-07-22 16:25:45,707 epoch 22 - iter 852/1427 - loss 0.09339444 - samples/sec: 141.84 - lr: 0.000030
2021-07-22 16:26:18,112 epoch 22 - iter 994/1427 - loss 0.09417468 - samples/sec: 140.25 - lr: 0.000030
2021-07-22 16:26:50,724 epoch 22 - iter 1136/1427 - loss 0.09423649 - samples/sec: 139.37 - lr: 0.000030
2021-07-22 16:27:23,319 epoch 22 - iter 1278/1427 - loss 0.09403333 - samples/sec: 139.44 - lr: 0.000030
2021-07-22 16:27:55,668 epoch 22 - iter 1420/1427 - loss 0.09386640 - samples/sec: 140.50 - lr: 0.000030
2021-07-22 16:27:57,111 ----------------------------------------------------------------------------------------------------
2021-07-22 16:27:57,111 EPOCH 22 done: loss 0.0937 - lr 0.0000300
2021-07-22 16:28:14,430 DEV : loss 0.12432285398244858 - score 0.9697
2021-07-22 16:28:14,611 BAD EPOCHS (no improvement): 1
2021-07-22 16:28:14,612 ----------------------------------------------------------------------------------------------------
2021-07-22 16:28:46,978 epoch 23 - iter 142/1427 - loss 0.08268744 - samples/sec: 140.44 - lr: 0.000030
2021-07-22 16:29:19,737 epoch 23 - iter 284/1427 - loss 0.09052193 - samples/sec: 138.74 - lr: 0.000030
2021-07-22 16:29:52,211 epoch 23 - iter 426/1427 - loss 0.08935283 - samples/sec: 139.96 - lr: 0.000030
2021-07-22 16:30:24,037 epoch 23 - iter 568/1427 - loss 0.08702553 - samples/sec: 142.81 - lr: 0.000030
2021-07-22 16:30:56,427 epoch 23 - iter 710/1427 - loss 0.08699593 - samples/sec: 140.32 - lr: 0.000030
2021-07-22 16:31:28,967 epoch 23 - iter 852/1427 - loss 0.08686857 - samples/sec: 139.67 - lr: 0.000030
2021-07-22 16:32:01,227 epoch 23 - iter 994/1427 - loss 0.08776795 - samples/sec: 140.88 - lr: 0.000030
2021-07-22 16:32:33,623 epoch 23 - iter 1136/1427 - loss 0.08810163 - samples/sec: 140.30 - lr: 0.000030
2021-07-22 16:33:06,119 epoch 23 - iter 1278/1427 - loss 0.08900846 - samples/sec: 139.86 - lr: 0.000030
2021-07-22 16:33:38,602 epoch 23 - iter 1420/1427 - loss 0.08926546 - samples/sec: 139.92 - lr: 0.000030
2021-07-22 16:33:40,016 ----------------------------------------------------------------------------------------------------
2021-07-22 16:33:40,016 EPOCH 23 done: loss 0.0890 - lr 0.0000300
2021-07-22 16:33:58,706 DEV : loss 0.1250738948583603 - score 0.9695
2021-07-22 16:33:58,889 BAD EPOCHS (no improvement): 2
2021-07-22 16:33:58,889 ----------------------------------------------------------------------------------------------------
2021-07-22 16:34:30,859 epoch 24 - iter 142/1427 - loss 0.08854357 - samples/sec: 142.18 - lr: 0.000030
2021-07-22 16:35:03,408 epoch 24 - iter 284/1427 - loss 0.09071073 - samples/sec: 139.64 - lr: 0.000030
2021-07-22 16:35:35,376 epoch 24 - iter 426/1427 - loss 0.09082701 - samples/sec: 142.17 - lr: 0.000030
2021-07-22 16:36:07,356 epoch 24 - iter 568/1427 - loss 0.08988002 - samples/sec: 142.12 - lr: 0.000030
2021-07-22 16:36:40,040 epoch 24 - iter 710/1427 - loss 0.09107324 - samples/sec: 139.06 - lr: 0.000030
2021-07-22 16:37:12,655 epoch 24 - iter 852/1427 - loss 0.09026435 - samples/sec: 139.35 - lr: 0.000030
2021-07-22 16:37:44,969 epoch 24 - iter 994/1427 - loss 0.08954624 - samples/sec: 140.65 - lr: 0.000030
2021-07-22 16:38:17,408 epoch 24 - iter 1136/1427 - loss 0.08926440 - samples/sec: 140.11 - lr: 0.000030
2021-07-22 16:38:49,789 epoch 24 - iter 1278/1427 - loss 0.08806831 - samples/sec: 140.36 - lr: 0.000030
2021-07-22 16:39:22,474 epoch 24 - iter 1420/1427 - loss 0.08836741 - samples/sec: 139.05 - lr: 0.000030
2021-07-22 16:39:23,878 ----------------------------------------------------------------------------------------------------
2021-07-22 16:39:23,878 EPOCH 24 done: loss 0.0885 - lr 0.0000300
2021-07-22 16:39:41,158 DEV : loss 0.11918799579143524 - score 0.971
2021-07-22 16:39:41,338 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 16:39:43,565 ----------------------------------------------------------------------------------------------------
2021-07-22 16:40:16,104 epoch 25 - iter 142/1427 - loss 0.08329328 - samples/sec: 139.70 - lr: 0.000030
2021-07-22 16:40:48,484 epoch 25 - iter 284/1427 - loss 0.08422798 - samples/sec: 140.37 - lr: 0.000030
2021-07-22 16:41:21,079 epoch 25 - iter 426/1427 - loss 0.08347164 - samples/sec: 139.44 - lr: 0.000030
2021-07-22 16:41:53,414 epoch 25 - iter 568/1427 - loss 0.08284269 - samples/sec: 140.56 - lr: 0.000030
2021-07-22 16:42:25,999 epoch 25 - iter 710/1427 - loss 0.08418607 - samples/sec: 139.48 - lr: 0.000030
2021-07-22 16:42:58,271 epoch 25 - iter 852/1427 - loss 0.08501331 - samples/sec: 140.83 - lr: 0.000030
2021-07-22 16:43:30,726 epoch 25 - iter 994/1427 - loss 0.08367842 - samples/sec: 140.04 - lr: 0.000030
2021-07-22 16:44:03,100 epoch 25 - iter 1136/1427 - loss 0.08496150 - samples/sec: 140.39 - lr: 0.000030
2021-07-22 16:44:35,168 epoch 25 - iter 1278/1427 - loss 0.08544626 - samples/sec: 141.73 - lr: 0.000030
2021-07-22 16:45:07,691 epoch 25 - iter 1420/1427 - loss 0.08587602 - samples/sec: 139.74 - lr: 0.000030
2021-07-22 16:45:09,138 ----------------------------------------------------------------------------------------------------
2021-07-22 16:45:09,138 EPOCH 25 done: loss 0.0858 - lr 0.0000300
2021-07-22 16:45:26,412 DEV : loss 0.1232478991150856 - score 0.9699
2021-07-22 16:45:26,597 BAD EPOCHS (no improvement): 1
2021-07-22 16:45:26,597 ----------------------------------------------------------------------------------------------------
2021-07-22 16:45:59,089 epoch 26 - iter 142/1427 - loss 0.08989918 - samples/sec: 139.89 - lr: 0.000030
2021-07-22 16:46:31,697 epoch 26 - iter 284/1427 - loss 0.08787232 - samples/sec: 139.38 - lr: 0.000030
2021-07-22 16:47:04,451 epoch 26 - iter 426/1427 - loss 0.08632452 - samples/sec: 138.76 - lr: 0.000030
2021-07-22 16:47:36,682 epoch 26 - iter 568/1427 - loss 0.08874655 - samples/sec: 141.02 - lr: 0.000030
2021-07-22 16:48:09,148 epoch 26 - iter 710/1427 - loss 0.08809212 - samples/sec: 139.99 - lr: 0.000030
2021-07-22 16:48:41,619 epoch 26 - iter 852/1427 - loss 0.08691683 - samples/sec: 139.97 - lr: 0.000030
2021-07-22 16:49:13,855 epoch 26 - iter 994/1427 - loss 0.08711539 - samples/sec: 140.99 - lr: 0.000030
2021-07-22 16:49:45,824 epoch 26 - iter 1136/1427 - loss 0.08674613 - samples/sec: 142.17 - lr: 0.000030
2021-07-22 16:50:18,332 epoch 26 - iter 1278/1427 - loss 0.08613447 - samples/sec: 139.81 - lr: 0.000030
2021-07-22 16:50:50,656 epoch 26 - iter 1420/1427 - loss 0.08649082 - samples/sec: 140.61 - lr: 0.000030
2021-07-22 16:50:52,148 ----------------------------------------------------------------------------------------------------
2021-07-22 16:50:52,148 EPOCH 26 done: loss 0.0865 - lr 0.0000300
2021-07-22 16:51:09,430 DEV : loss 0.12757854163646698 - score 0.9679
2021-07-22 16:51:09,611 BAD EPOCHS (no improvement): 2
2021-07-22 16:51:09,611 ----------------------------------------------------------------------------------------------------
2021-07-22 16:51:42,393 epoch 27 - iter 142/1427 - loss 0.07830389 - samples/sec: 138.66 - lr: 0.000030
2021-07-22 16:52:14,459 epoch 27 - iter 284/1427 - loss 0.07549383 - samples/sec: 141.74 - lr: 0.000030
2021-07-22 16:52:46,435 epoch 27 - iter 426/1427 - loss 0.07816576 - samples/sec: 142.14 - lr: 0.000030
2021-07-22 16:53:18,640 epoch 27 - iter 568/1427 - loss 0.07893097 - samples/sec: 141.13 - lr: 0.000030
2021-07-22 16:53:51,171 epoch 27 - iter 710/1427 - loss 0.08124309 - samples/sec: 139.71 - lr: 0.000030
2021-07-22 16:54:24,168 epoch 27 - iter 852/1427 - loss 0.08231535 - samples/sec: 137.74 - lr: 0.000030
2021-07-22 16:54:56,667 epoch 27 - iter 994/1427 - loss 0.08390725 - samples/sec: 139.85 - lr: 0.000030
2021-07-22 16:55:29,140 epoch 27 - iter 1136/1427 - loss 0.08416729 - samples/sec: 139.96 - lr: 0.000030
2021-07-22 16:56:01,510 epoch 27 - iter 1278/1427 - loss 0.08424470 - samples/sec: 140.41 - lr: 0.000030
2021-07-22 16:56:33,792 epoch 27 - iter 1420/1427 - loss 0.08341891 - samples/sec: 140.79 - lr: 0.000030
2021-07-22 16:56:35,307 ----------------------------------------------------------------------------------------------------
2021-07-22 16:56:35,307 EPOCH 27 done: loss 0.0833 - lr 0.0000300
2021-07-22 16:56:53,960 DEV : loss 0.12203861027956009 - score 0.9706
2021-07-22 16:56:54,140 BAD EPOCHS (no improvement): 3
2021-07-22 16:56:54,140 ----------------------------------------------------------------------------------------------------
2021-07-22 16:57:26,435 epoch 28 - iter 142/1427 - loss 0.08275788 - samples/sec: 140.75 - lr: 0.000030
2021-07-22 16:57:58,938 epoch 28 - iter 284/1427 - loss 0.08289014 - samples/sec: 139.83 - lr: 0.000030
2021-07-22 16:58:31,560 epoch 28 - iter 426/1427 - loss 0.08378960 - samples/sec: 139.33 - lr: 0.000030
2021-07-22 16:59:03,876 epoch 28 - iter 568/1427 - loss 0.08310383 - samples/sec: 140.64 - lr: 0.000030
2021-07-22 16:59:36,016 epoch 28 - iter 710/1427 - loss 0.08401820 - samples/sec: 141.42 - lr: 0.000030
2021-07-22 17:00:08,223 epoch 28 - iter 852/1427 - loss 0.08380473 - samples/sec: 141.12 - lr: 0.000030
2021-07-22 17:00:40,671 epoch 28 - iter 994/1427 - loss 0.08356106 - samples/sec: 140.07 - lr: 0.000030
2021-07-22 17:01:13,154 epoch 28 - iter 1136/1427 - loss 0.08351866 - samples/sec: 139.92 - lr: 0.000030
2021-07-22 17:01:45,519 epoch 28 - iter 1278/1427 - loss 0.08347835 - samples/sec: 140.43 - lr: 0.000030
2021-07-22 17:02:17,759 epoch 28 - iter 1420/1427 - loss 0.08289549 - samples/sec: 140.97 - lr: 0.000030
2021-07-22 17:02:19,258 ----------------------------------------------------------------------------------------------------
2021-07-22 17:02:19,259 EPOCH 28 done: loss 0.0828 - lr 0.0000300
2021-07-22 17:02:36,573 DEV : loss 0.12404555827379227 - score 0.9709
Epoch    28: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 17:02:36,755 BAD EPOCHS (no improvement): 4
2021-07-22 17:02:36,756 ----------------------------------------------------------------------------------------------------
2021-07-22 17:03:09,042 epoch 29 - iter 142/1427 - loss 0.07284664 - samples/sec: 140.83 - lr: 0.000015
2021-07-22 17:03:41,569 epoch 29 - iter 284/1427 - loss 0.07206634 - samples/sec: 139.77 - lr: 0.000015
2021-07-22 17:04:14,421 epoch 29 - iter 426/1427 - loss 0.07586902 - samples/sec: 138.39 - lr: 0.000015
2021-07-22 17:04:46,839 epoch 29 - iter 568/1427 - loss 0.07698605 - samples/sec: 140.24 - lr: 0.000015
2021-07-22 17:05:19,015 epoch 29 - iter 710/1427 - loss 0.07675812 - samples/sec: 141.30 - lr: 0.000015
2021-07-22 17:05:51,029 epoch 29 - iter 852/1427 - loss 0.07577272 - samples/sec: 142.01 - lr: 0.000015
2021-07-22 17:06:23,303 epoch 29 - iter 994/1427 - loss 0.07584472 - samples/sec: 140.86 - lr: 0.000015
2021-07-22 17:06:55,884 epoch 29 - iter 1136/1427 - loss 0.07682703 - samples/sec: 139.54 - lr: 0.000015
2021-07-22 17:07:28,617 epoch 29 - iter 1278/1427 - loss 0.07752315 - samples/sec: 138.89 - lr: 0.000015
2021-07-22 17:08:01,124 epoch 29 - iter 1420/1427 - loss 0.07778845 - samples/sec: 139.86 - lr: 0.000015
2021-07-22 17:08:02,630 ----------------------------------------------------------------------------------------------------
2021-07-22 17:08:02,630 EPOCH 29 done: loss 0.0779 - lr 0.0000150
2021-07-22 17:08:19,937 DEV : loss 0.12393923848867416 - score 0.9699
2021-07-22 17:08:20,118 BAD EPOCHS (no improvement): 1
2021-07-22 17:08:20,118 ----------------------------------------------------------------------------------------------------
2021-07-22 17:08:52,725 epoch 30 - iter 142/1427 - loss 0.07315814 - samples/sec: 139.41 - lr: 0.000015
2021-07-22 17:09:24,746 epoch 30 - iter 284/1427 - loss 0.07181732 - samples/sec: 141.94 - lr: 0.000015
2021-07-22 17:09:56,788 epoch 30 - iter 426/1427 - loss 0.07503048 - samples/sec: 141.85 - lr: 0.000015
2021-07-22 17:10:28,833 epoch 30 - iter 568/1427 - loss 0.07689008 - samples/sec: 141.83 - lr: 0.000015
2021-07-22 17:11:01,523 epoch 30 - iter 710/1427 - loss 0.07703853 - samples/sec: 139.03 - lr: 0.000015
2021-07-22 17:11:34,172 epoch 30 - iter 852/1427 - loss 0.07689219 - samples/sec: 139.21 - lr: 0.000015
2021-07-22 17:12:06,375 epoch 30 - iter 994/1427 - loss 0.07567762 - samples/sec: 141.13 - lr: 0.000015
2021-07-22 17:12:38,731 epoch 30 - iter 1136/1427 - loss 0.07618296 - samples/sec: 140.47 - lr: 0.000015
2021-07-22 17:13:11,463 epoch 30 - iter 1278/1427 - loss 0.07680397 - samples/sec: 138.85 - lr: 0.000015
2021-07-22 17:13:44,007 epoch 30 - iter 1420/1427 - loss 0.07772913 - samples/sec: 139.66 - lr: 0.000015
2021-07-22 17:13:45,506 ----------------------------------------------------------------------------------------------------
2021-07-22 17:13:45,506 EPOCH 30 done: loss 0.0777 - lr 0.0000150
2021-07-22 17:14:02,809 DEV : loss 0.12127291411161423 - score 0.9699
2021-07-22 17:14:02,989 BAD EPOCHS (no improvement): 2
2021-07-22 17:14:02,990 ----------------------------------------------------------------------------------------------------
2021-07-22 17:14:35,239 epoch 31 - iter 142/1427 - loss 0.08291107 - samples/sec: 140.95 - lr: 0.000015
2021-07-22 17:15:08,016 epoch 31 - iter 284/1427 - loss 0.08044243 - samples/sec: 138.67 - lr: 0.000015
2021-07-22 17:15:40,335 epoch 31 - iter 426/1427 - loss 0.07791257 - samples/sec: 140.63 - lr: 0.000015
2021-07-22 17:16:12,633 epoch 31 - iter 568/1427 - loss 0.07851968 - samples/sec: 140.73 - lr: 0.000015
2021-07-22 17:16:45,083 epoch 31 - iter 710/1427 - loss 0.07794523 - samples/sec: 140.06 - lr: 0.000015
2021-07-22 17:17:17,156 epoch 31 - iter 852/1427 - loss 0.07684694 - samples/sec: 141.71 - lr: 0.000015
2021-07-22 17:17:48,972 epoch 31 - iter 994/1427 - loss 0.07607122 - samples/sec: 142.86 - lr: 0.000015
2021-07-22 17:18:21,879 epoch 31 - iter 1136/1427 - loss 0.07752795 - samples/sec: 138.11 - lr: 0.000015
2021-07-22 17:18:54,387 epoch 31 - iter 1278/1427 - loss 0.07760083 - samples/sec: 139.81 - lr: 0.000015
2021-07-22 17:19:26,995 epoch 31 - iter 1420/1427 - loss 0.07777198 - samples/sec: 139.38 - lr: 0.000015
2021-07-22 17:19:28,447 ----------------------------------------------------------------------------------------------------
2021-07-22 17:19:28,447 EPOCH 31 done: loss 0.0777 - lr 0.0000150
2021-07-22 17:19:45,761 DEV : loss 0.12353956699371338 - score 0.9705
2021-07-22 17:19:45,944 BAD EPOCHS (no improvement): 3
2021-07-22 17:19:45,944 ----------------------------------------------------------------------------------------------------
2021-07-22 17:20:18,116 epoch 32 - iter 142/1427 - loss 0.08631742 - samples/sec: 141.28 - lr: 0.000015
2021-07-22 17:20:50,739 epoch 32 - iter 284/1427 - loss 0.07630361 - samples/sec: 139.32 - lr: 0.000015
2021-07-22 17:21:23,372 epoch 32 - iter 426/1427 - loss 0.07654961 - samples/sec: 139.28 - lr: 0.000015
2021-07-22 17:21:55,549 epoch 32 - iter 568/1427 - loss 0.07558525 - samples/sec: 141.25 - lr: 0.000015
2021-07-22 17:22:27,940 epoch 32 - iter 710/1427 - loss 0.07648376 - samples/sec: 140.32 - lr: 0.000015
2021-07-22 17:22:59,920 epoch 32 - iter 852/1427 - loss 0.07530258 - samples/sec: 142.12 - lr: 0.000015
2021-07-22 17:23:31,928 epoch 32 - iter 994/1427 - loss 0.07664465 - samples/sec: 142.00 - lr: 0.000015
2021-07-22 17:24:05,540 epoch 32 - iter 1136/1427 - loss 0.07689311 - samples/sec: 135.22 - lr: 0.000015
2021-07-22 17:24:38,084 epoch 32 - iter 1278/1427 - loss 0.07749659 - samples/sec: 139.66 - lr: 0.000015
2021-07-22 17:25:10,575 epoch 32 - iter 1420/1427 - loss 0.07741215 - samples/sec: 139.88 - lr: 0.000015
2021-07-22 17:25:12,022 ----------------------------------------------------------------------------------------------------
2021-07-22 17:25:12,022 EPOCH 32 done: loss 0.0774 - lr 0.0000150
2021-07-22 17:25:29,340 DEV : loss 0.12343321740627289 - score 0.9709
Epoch    32: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 17:25:29,522 BAD EPOCHS (no improvement): 4
2021-07-22 17:25:29,522 ----------------------------------------------------------------------------------------------------
2021-07-22 17:26:01,919 epoch 33 - iter 142/1427 - loss 0.07502444 - samples/sec: 140.30 - lr: 0.000008
2021-07-22 17:26:34,435 epoch 33 - iter 284/1427 - loss 0.07493142 - samples/sec: 139.78 - lr: 0.000008
2021-07-22 17:27:06,689 epoch 33 - iter 426/1427 - loss 0.07630957 - samples/sec: 140.91 - lr: 0.000008
2021-07-22 17:27:39,398 epoch 33 - iter 568/1427 - loss 0.07623013 - samples/sec: 138.95 - lr: 0.000008
2021-07-22 17:28:11,814 epoch 33 - iter 710/1427 - loss 0.07561162 - samples/sec: 140.21 - lr: 0.000008
2021-07-22 17:28:44,135 epoch 33 - iter 852/1427 - loss 0.07500035 - samples/sec: 140.62 - lr: 0.000008
2021-07-22 17:29:16,687 epoch 33 - iter 994/1427 - loss 0.07499481 - samples/sec: 139.62 - lr: 0.000008
2021-07-22 17:29:48,843 epoch 33 - iter 1136/1427 - loss 0.07568559 - samples/sec: 141.34 - lr: 0.000008
2021-07-22 17:30:21,122 epoch 33 - iter 1278/1427 - loss 0.07685799 - samples/sec: 140.80 - lr: 0.000008
2021-07-22 17:30:53,216 epoch 33 - iter 1420/1427 - loss 0.07627184 - samples/sec: 141.62 - lr: 0.000008
2021-07-22 17:30:54,714 ----------------------------------------------------------------------------------------------------
2021-07-22 17:30:54,714 EPOCH 33 done: loss 0.0762 - lr 0.0000075
2021-07-22 17:31:11,991 DEV : loss 0.1220945194363594 - score 0.9705
2021-07-22 17:31:12,173 BAD EPOCHS (no improvement): 1
2021-07-22 17:31:12,174 ----------------------------------------------------------------------------------------------------
2021-07-22 17:31:44,060 epoch 34 - iter 142/1427 - loss 0.08437490 - samples/sec: 142.55 - lr: 0.000008
2021-07-22 17:32:16,504 epoch 34 - iter 284/1427 - loss 0.07811320 - samples/sec: 140.09 - lr: 0.000008
2021-07-22 17:32:49,516 epoch 34 - iter 426/1427 - loss 0.07806297 - samples/sec: 137.68 - lr: 0.000008
2021-07-22 17:33:21,640 epoch 34 - iter 568/1427 - loss 0.07554474 - samples/sec: 141.48 - lr: 0.000008
2021-07-22 17:33:54,319 epoch 34 - iter 710/1427 - loss 0.07647401 - samples/sec: 139.08 - lr: 0.000008
2021-07-22 17:34:26,809 epoch 34 - iter 852/1427 - loss 0.07530753 - samples/sec: 139.89 - lr: 0.000008
2021-07-22 17:34:59,571 epoch 34 - iter 994/1427 - loss 0.07536788 - samples/sec: 138.73 - lr: 0.000008
2021-07-22 17:35:31,930 epoch 34 - iter 1136/1427 - loss 0.07593906 - samples/sec: 140.46 - lr: 0.000008
2021-07-22 17:36:04,140 epoch 34 - iter 1278/1427 - loss 0.07638606 - samples/sec: 141.11 - lr: 0.000008
2021-07-22 17:36:36,163 epoch 34 - iter 1420/1427 - loss 0.07589462 - samples/sec: 141.93 - lr: 0.000008
2021-07-22 17:36:37,627 ----------------------------------------------------------------------------------------------------
2021-07-22 17:36:37,627 EPOCH 34 done: loss 0.0758 - lr 0.0000075
2021-07-22 17:36:54,885 DEV : loss 0.12724004685878754 - score 0.969
2021-07-22 17:36:55,066 BAD EPOCHS (no improvement): 2
2021-07-22 17:36:55,066 ----------------------------------------------------------------------------------------------------
2021-07-22 17:37:27,464 epoch 35 - iter 142/1427 - loss 0.07163582 - samples/sec: 140.30 - lr: 0.000008
2021-07-22 17:37:59,515 epoch 35 - iter 284/1427 - loss 0.06996976 - samples/sec: 141.81 - lr: 0.000008
2021-07-22 17:38:31,448 epoch 35 - iter 426/1427 - loss 0.07225110 - samples/sec: 142.33 - lr: 0.000008
2021-07-22 17:39:03,954 epoch 35 - iter 568/1427 - loss 0.07246975 - samples/sec: 139.82 - lr: 0.000008
2021-07-22 17:39:36,195 epoch 35 - iter 710/1427 - loss 0.07321540 - samples/sec: 140.97 - lr: 0.000008
2021-07-22 17:40:08,280 epoch 35 - iter 852/1427 - loss 0.07289241 - samples/sec: 141.66 - lr: 0.000008
2021-07-22 17:40:40,595 epoch 35 - iter 994/1427 - loss 0.07239299 - samples/sec: 140.65 - lr: 0.000008
2021-07-22 17:41:13,161 epoch 35 - iter 1136/1427 - loss 0.07293441 - samples/sec: 139.56 - lr: 0.000008
2021-07-22 17:41:46,083 epoch 35 - iter 1278/1427 - loss 0.07353409 - samples/sec: 138.05 - lr: 0.000008
2021-07-22 17:42:18,460 epoch 35 - iter 1420/1427 - loss 0.07396813 - samples/sec: 140.38 - lr: 0.000008
2021-07-22 17:42:19,943 ----------------------------------------------------------------------------------------------------
2021-07-22 17:42:19,943 EPOCH 35 done: loss 0.0741 - lr 0.0000075
2021-07-22 17:42:37,285 DEV : loss 0.12339352071285248 - score 0.9707
2021-07-22 17:42:37,467 BAD EPOCHS (no improvement): 3
2021-07-22 17:42:37,467 ----------------------------------------------------------------------------------------------------
2021-07-22 17:43:09,488 epoch 36 - iter 142/1427 - loss 0.07332966 - samples/sec: 141.95 - lr: 0.000008
2021-07-22 17:43:42,044 epoch 36 - iter 284/1427 - loss 0.07570272 - samples/sec: 139.61 - lr: 0.000008
2021-07-22 17:44:14,331 epoch 36 - iter 426/1427 - loss 0.07626391 - samples/sec: 140.77 - lr: 0.000008
2021-07-22 17:44:46,659 epoch 36 - iter 568/1427 - loss 0.07506796 - samples/sec: 140.59 - lr: 0.000008
2021-07-22 17:45:19,127 epoch 36 - iter 710/1427 - loss 0.07434146 - samples/sec: 139.98 - lr: 0.000008
2021-07-22 17:45:51,516 epoch 36 - iter 852/1427 - loss 0.07522830 - samples/sec: 140.33 - lr: 0.000008
2021-07-22 17:46:23,625 epoch 36 - iter 994/1427 - loss 0.07530333 - samples/sec: 141.55 - lr: 0.000008
2021-07-22 17:46:56,454 epoch 36 - iter 1136/1427 - loss 0.07437418 - samples/sec: 138.44 - lr: 0.000008
2021-07-22 17:47:29,201 epoch 36 - iter 1278/1427 - loss 0.07497972 - samples/sec: 138.79 - lr: 0.000008
2021-07-22 17:48:02,072 epoch 36 - iter 1420/1427 - loss 0.07552623 - samples/sec: 138.27 - lr: 0.000008
2021-07-22 17:48:03,447 ----------------------------------------------------------------------------------------------------
2021-07-22 17:48:03,447 EPOCH 36 done: loss 0.0754 - lr 0.0000075
2021-07-22 17:48:22,128 DEV : loss 0.12523457407951355 - score 0.9707
Epoch    36: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 17:48:22,310 BAD EPOCHS (no improvement): 4
2021-07-22 17:48:22,310 ----------------------------------------------------------------------------------------------------
2021-07-22 17:48:54,791 epoch 37 - iter 142/1427 - loss 0.07242713 - samples/sec: 139.94 - lr: 0.000004
2021-07-22 17:49:27,323 epoch 37 - iter 284/1427 - loss 0.06903339 - samples/sec: 139.71 - lr: 0.000004
2021-07-22 17:49:59,364 epoch 37 - iter 426/1427 - loss 0.07109299 - samples/sec: 141.85 - lr: 0.000004
2021-07-22 17:50:31,656 epoch 37 - iter 568/1427 - loss 0.07042023 - samples/sec: 140.75 - lr: 0.000004
2021-07-22 17:51:03,623 epoch 37 - iter 710/1427 - loss 0.07083879 - samples/sec: 142.18 - lr: 0.000004
2021-07-22 17:51:35,751 epoch 37 - iter 852/1427 - loss 0.07066279 - samples/sec: 141.46 - lr: 0.000004
2021-07-22 17:52:08,095 epoch 37 - iter 994/1427 - loss 0.07165620 - samples/sec: 140.52 - lr: 0.000004
2021-07-22 17:52:40,865 epoch 37 - iter 1136/1427 - loss 0.07326345 - samples/sec: 138.69 - lr: 0.000004
2021-07-22 17:53:13,475 epoch 37 - iter 1278/1427 - loss 0.07306773 - samples/sec: 139.38 - lr: 0.000004
2021-07-22 17:53:45,709 epoch 37 - iter 1420/1427 - loss 0.07300872 - samples/sec: 141.00 - lr: 0.000004
2021-07-22 17:53:47,165 ----------------------------------------------------------------------------------------------------
2021-07-22 17:53:47,165 EPOCH 37 done: loss 0.0730 - lr 0.0000038
2021-07-22 17:54:04,476 DEV : loss 0.12395361065864563 - score 0.9707
2021-07-22 17:54:04,658 BAD EPOCHS (no improvement): 1
2021-07-22 17:54:04,659 ----------------------------------------------------------------------------------------------------
2021-07-22 17:54:37,047 epoch 38 - iter 142/1427 - loss 0.07898877 - samples/sec: 140.34 - lr: 0.000004
2021-07-22 17:55:09,367 epoch 38 - iter 284/1427 - loss 0.07163035 - samples/sec: 140.63 - lr: 0.000004
2021-07-22 17:55:41,920 epoch 38 - iter 426/1427 - loss 0.07213200 - samples/sec: 139.62 - lr: 0.000004
2021-07-22 17:56:14,162 epoch 38 - iter 568/1427 - loss 0.07289910 - samples/sec: 140.96 - lr: 0.000004
2021-07-22 17:56:46,552 epoch 38 - iter 710/1427 - loss 0.07526765 - samples/sec: 140.32 - lr: 0.000004
2021-07-22 17:57:18,796 epoch 38 - iter 852/1427 - loss 0.07441109 - samples/sec: 140.96 - lr: 0.000004
2021-07-22 17:57:51,096 epoch 38 - iter 994/1427 - loss 0.07388903 - samples/sec: 140.71 - lr: 0.000004
2021-07-22 17:58:23,531 epoch 38 - iter 1136/1427 - loss 0.07585744 - samples/sec: 140.13 - lr: 0.000004
2021-07-22 17:58:56,079 epoch 38 - iter 1278/1427 - loss 0.07563133 - samples/sec: 139.64 - lr: 0.000004
2021-07-22 17:59:28,516 epoch 38 - iter 1420/1427 - loss 0.07488472 - samples/sec: 140.12 - lr: 0.000004
2021-07-22 17:59:29,909 ----------------------------------------------------------------------------------------------------
2021-07-22 17:59:29,909 EPOCH 38 done: loss 0.0747 - lr 0.0000038
2021-07-22 17:59:47,205 DEV : loss 0.12458290904760361 - score 0.9705
2021-07-22 17:59:47,384 BAD EPOCHS (no improvement): 2
2021-07-22 17:59:47,385 ----------------------------------------------------------------------------------------------------
2021-07-22 18:00:19,785 epoch 39 - iter 142/1427 - loss 0.07504651 - samples/sec: 140.29 - lr: 0.000004
2021-07-22 18:00:52,453 epoch 39 - iter 284/1427 - loss 0.07638725 - samples/sec: 139.13 - lr: 0.000004
2021-07-22 18:01:25,163 epoch 39 - iter 426/1427 - loss 0.07463881 - samples/sec: 138.95 - lr: 0.000004
2021-07-22 18:01:57,310 epoch 39 - iter 568/1427 - loss 0.07419144 - samples/sec: 141.38 - lr: 0.000004
2021-07-22 18:02:29,528 epoch 39 - iter 710/1427 - loss 0.07515618 - samples/sec: 141.07 - lr: 0.000004
2021-07-22 18:03:01,957 epoch 39 - iter 852/1427 - loss 0.07458347 - samples/sec: 140.16 - lr: 0.000004
2021-07-22 18:03:34,068 epoch 39 - iter 994/1427 - loss 0.07429063 - samples/sec: 141.54 - lr: 0.000004
2021-07-22 18:04:06,250 epoch 39 - iter 1136/1427 - loss 0.07352354 - samples/sec: 141.23 - lr: 0.000004
2021-07-22 18:04:38,981 epoch 39 - iter 1278/1427 - loss 0.07368825 - samples/sec: 138.86 - lr: 0.000004
2021-07-22 18:05:11,775 epoch 39 - iter 1420/1427 - loss 0.07315969 - samples/sec: 138.59 - lr: 0.000004
2021-07-22 18:05:13,268 ----------------------------------------------------------------------------------------------------
2021-07-22 18:05:13,269 EPOCH 39 done: loss 0.0730 - lr 0.0000038
2021-07-22 18:05:30,569 DEV : loss 0.1239108294248581 - score 0.9704
2021-07-22 18:05:30,753 BAD EPOCHS (no improvement): 3
2021-07-22 18:05:30,753 ----------------------------------------------------------------------------------------------------
2021-07-22 18:06:03,339 epoch 40 - iter 142/1427 - loss 0.06739018 - samples/sec: 139.49 - lr: 0.000004
2021-07-22 18:06:35,544 epoch 40 - iter 284/1427 - loss 0.07439316 - samples/sec: 141.13 - lr: 0.000004
2021-07-22 18:07:07,460 epoch 40 - iter 426/1427 - loss 0.07383388 - samples/sec: 142.40 - lr: 0.000004
2021-07-22 18:07:39,899 epoch 40 - iter 568/1427 - loss 0.07451784 - samples/sec: 140.11 - lr: 0.000004
2021-07-22 18:08:11,940 epoch 40 - iter 710/1427 - loss 0.07215651 - samples/sec: 141.85 - lr: 0.000004
2021-07-22 18:08:44,548 epoch 40 - iter 852/1427 - loss 0.07128685 - samples/sec: 139.38 - lr: 0.000004
2021-07-22 18:09:17,241 epoch 40 - iter 994/1427 - loss 0.07180380 - samples/sec: 139.02 - lr: 0.000004
2021-07-22 18:09:50,092 epoch 40 - iter 1136/1427 - loss 0.07370248 - samples/sec: 138.35 - lr: 0.000004
2021-07-22 18:10:22,600 epoch 40 - iter 1278/1427 - loss 0.07344028 - samples/sec: 139.81 - lr: 0.000004
2021-07-22 18:10:54,423 epoch 40 - iter 1420/1427 - loss 0.07315770 - samples/sec: 142.82 - lr: 0.000004
2021-07-22 18:10:55,857 ----------------------------------------------------------------------------------------------------
2021-07-22 18:10:55,858 EPOCH 40 done: loss 0.0734 - lr 0.0000038
2021-07-22 18:11:14,495 DEV : loss 0.1246851310133934 - score 0.9707
Epoch    40: reducing learning rate of group 0 to 1.8750e-06.
2021-07-22 18:11:14,678 BAD EPOCHS (no improvement): 4
2021-07-22 18:11:15,350 ----------------------------------------------------------------------------------------------------
2021-07-22 18:11:15,350 Testing using best model ...
2021-07-22 18:11:15,351 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/tur.pdtb.tdb/best-model.pt
2021-07-22 18:14:35,723 0.9732	0.9844	0.9788
2021-07-22 18:14:35,724 
Results:
- F1-score (micro) 0.9788
- F1-score (macro) 0.9818

By class:
SENT       tp: 6230 - fp: 299 - fn: 172 - precision: 0.9542 - recall: 0.9731 - f1-score: 0.9636
X          tp: 4643 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 18:14:35,724 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/fas.rst.prstc/
2021-07-22 18:14:35,755 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/fas.rst.prstc
2021-07-22 18:14:35,756 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/fas.rst.prstc/sent_train.txt
2021-07-22 18:14:35,758 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/fas.rst.prstc/sent_dev.txt
2021-07-22 18:14:35,760 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/fas.rst.prstc/sent_test.txt
Corpus: 4851 train + 863 dev + 1768 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 18:14:39,826 ----------------------------------------------------------------------------------------------------
2021-07-22 18:14:39,828 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(100000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 18:14:39,828 ----------------------------------------------------------------------------------------------------
2021-07-22 18:14:39,828 Corpus: "Corpus: 4851 train + 863 dev + 1768 test sentences"
2021-07-22 18:14:39,828 ----------------------------------------------------------------------------------------------------
2021-07-22 18:14:39,828 Parameters:
2021-07-22 18:14:39,828  - learning_rate: "3e-05"
2021-07-22 18:14:39,828  - mini_batch_size: "32"
2021-07-22 18:14:39,828  - patience: "3"
2021-07-22 18:14:39,828  - anneal_factor: "0.5"
2021-07-22 18:14:39,828  - max_epochs: "40"
2021-07-22 18:14:39,828  - shuffle: "True"
2021-07-22 18:14:39,828  - train_with_dev: "False"
2021-07-22 18:14:39,828  - batch_growth_annealing: "False"
2021-07-22 18:14:39,829 ----------------------------------------------------------------------------------------------------
2021-07-22 18:14:39,829 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-0/fas.rst.prstc"
2021-07-22 18:14:39,829 ----------------------------------------------------------------------------------------------------
2021-07-22 18:14:39,829 Device: cuda:0
2021-07-22 18:14:39,829 ----------------------------------------------------------------------------------------------------
2021-07-22 18:14:39,829 Embeddings storage mode: cpu
2021-07-22 18:14:39,831 ----------------------------------------------------------------------------------------------------
