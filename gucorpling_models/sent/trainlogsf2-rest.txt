/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.rstdt/
2021-07-23 14:57:47,387 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.rstdt
2021-07-23 14:57:47,387 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.rstdt/sent_train.txt
2021-07-23 14:57:47,387 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.rstdt/sent_dev.txt
2021-07-23 14:57:47,387 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.rstdt/sent_test.txt
Corpus: 16498 train + 2332 dev + 5777 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 14:57:54,418 ----------------------------------------------------------------------------------------------------
2021-07-23 14:57:54,419 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 14:57:54,419 ----------------------------------------------------------------------------------------------------
2021-07-23 14:57:54,419 Corpus: "Corpus: 16498 train + 2332 dev + 5777 test sentences"
2021-07-23 14:57:54,419 ----------------------------------------------------------------------------------------------------
2021-07-23 14:57:54,419 Parameters:
2021-07-23 14:57:54,419  - learning_rate: "3e-05"
2021-07-23 14:57:54,419  - mini_batch_size: "32"
2021-07-23 14:57:54,419  - patience: "3"
2021-07-23 14:57:54,420  - anneal_factor: "0.5"
2021-07-23 14:57:54,420  - max_epochs: "40"
2021-07-23 14:57:54,420  - shuffle: "True"
2021-07-23 14:57:54,420  - train_with_dev: "False"
2021-07-23 14:57:54,420  - batch_growth_annealing: "False"
2021-07-23 14:57:54,420 ----------------------------------------------------------------------------------------------------
2021-07-23 14:57:54,420 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.rstdt"
2021-07-23 14:57:54,420 ----------------------------------------------------------------------------------------------------
2021-07-23 14:57:54,420 Device: cuda:0
2021-07-23 14:57:54,420 ----------------------------------------------------------------------------------------------------
2021-07-23 14:57:54,420 Embeddings storage mode: cpu
2021-07-23 14:57:54,422 ----------------------------------------------------------------------------------------------------
2021-07-23 14:58:23,278 epoch 1 - iter 51/516 - loss 14.92362284 - samples/sec: 56.56 - lr: 0.000030
2021-07-23 14:58:52,947 epoch 1 - iter 102/516 - loss 10.53892611 - samples/sec: 55.01 - lr: 0.000030
2021-07-23 14:59:22,344 epoch 1 - iter 153/516 - loss 7.67058804 - samples/sec: 55.52 - lr: 0.000030
2021-07-23 14:59:51,606 epoch 1 - iter 204/516 - loss 6.00637052 - samples/sec: 55.78 - lr: 0.000030
2021-07-23 15:00:21,220 epoch 1 - iter 255/516 - loss 4.93914611 - samples/sec: 55.11 - lr: 0.000030
2021-07-23 15:00:50,729 epoch 1 - iter 306/516 - loss 4.20114115 - samples/sec: 55.31 - lr: 0.000030
2021-07-23 15:01:20,193 epoch 1 - iter 357/516 - loss 3.66017533 - samples/sec: 55.39 - lr: 0.000030
2021-07-23 15:01:49,839 epoch 1 - iter 408/516 - loss 3.24679539 - samples/sec: 55.05 - lr: 0.000030
2021-07-23 15:02:19,474 epoch 1 - iter 459/516 - loss 2.91891907 - samples/sec: 55.07 - lr: 0.000030
2021-07-23 15:02:49,038 epoch 1 - iter 510/516 - loss 2.65422183 - samples/sec: 55.21 - lr: 0.000030
2021-07-23 15:02:52,282 ----------------------------------------------------------------------------------------------------
2021-07-23 15:02:52,282 EPOCH 1 done: loss 2.6265 - lr 0.0000300
2021-07-23 15:03:23,306 DEV : loss 0.12963466346263885 - score 0.9664
2021-07-23 15:03:23,369 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:03:23,957 ----------------------------------------------------------------------------------------------------
2021-07-23 15:03:36,241 epoch 2 - iter 51/516 - loss 0.26540950 - samples/sec: 132.90 - lr: 0.000030
2021-07-23 15:03:48,407 epoch 2 - iter 102/516 - loss 0.25290254 - samples/sec: 134.17 - lr: 0.000030
2021-07-23 15:04:00,648 epoch 2 - iter 153/516 - loss 0.24989114 - samples/sec: 133.35 - lr: 0.000030
2021-07-23 15:04:12,720 epoch 2 - iter 204/516 - loss 0.24006727 - samples/sec: 135.22 - lr: 0.000030
2021-07-23 15:04:24,620 epoch 2 - iter 255/516 - loss 0.23766899 - samples/sec: 137.17 - lr: 0.000030
2021-07-23 15:04:36,551 epoch 2 - iter 306/516 - loss 0.23495242 - samples/sec: 136.81 - lr: 0.000030
2021-07-23 15:04:48,663 epoch 2 - iter 357/516 - loss 0.23217347 - samples/sec: 134.77 - lr: 0.000030
2021-07-23 15:05:00,745 epoch 2 - iter 408/516 - loss 0.23234292 - samples/sec: 135.11 - lr: 0.000030
2021-07-23 15:05:12,549 epoch 2 - iter 459/516 - loss 0.22939097 - samples/sec: 138.29 - lr: 0.000030
2021-07-23 15:05:24,375 epoch 2 - iter 510/516 - loss 0.22690901 - samples/sec: 138.03 - lr: 0.000030
2021-07-23 15:05:25,716 ----------------------------------------------------------------------------------------------------
2021-07-23 15:05:25,716 EPOCH 2 done: loss 0.2262 - lr 0.0000300
2021-07-23 15:05:31,260 DEV : loss 0.08797827363014221 - score 0.9763
2021-07-23 15:05:31,323 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:05:33,466 ----------------------------------------------------------------------------------------------------
2021-07-23 15:05:45,542 epoch 3 - iter 51/516 - loss 0.20103628 - samples/sec: 135.21 - lr: 0.000030
2021-07-23 15:05:57,606 epoch 3 - iter 102/516 - loss 0.19532660 - samples/sec: 135.31 - lr: 0.000030
2021-07-23 15:06:09,889 epoch 3 - iter 153/516 - loss 0.19133822 - samples/sec: 132.89 - lr: 0.000030
2021-07-23 15:06:21,943 epoch 3 - iter 204/516 - loss 0.18364426 - samples/sec: 135.42 - lr: 0.000030
2021-07-23 15:06:33,887 epoch 3 - iter 255/516 - loss 0.18235350 - samples/sec: 136.67 - lr: 0.000030
2021-07-23 15:06:46,302 epoch 3 - iter 306/516 - loss 0.18286807 - samples/sec: 131.48 - lr: 0.000030
2021-07-23 15:06:58,195 epoch 3 - iter 357/516 - loss 0.18407834 - samples/sec: 137.25 - lr: 0.000030
2021-07-23 15:07:10,400 epoch 3 - iter 408/516 - loss 0.18610744 - samples/sec: 133.75 - lr: 0.000030
2021-07-23 15:07:22,350 epoch 3 - iter 459/516 - loss 0.18641350 - samples/sec: 136.60 - lr: 0.000030
2021-07-23 15:07:34,227 epoch 3 - iter 510/516 - loss 0.18538762 - samples/sec: 137.44 - lr: 0.000030
2021-07-23 15:07:35,595 ----------------------------------------------------------------------------------------------------
2021-07-23 15:07:35,595 EPOCH 3 done: loss 0.1848 - lr 0.0000300
2021-07-23 15:07:41,142 DEV : loss 0.07461103796958923 - score 0.9807
2021-07-23 15:07:41,205 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:07:43,451 ----------------------------------------------------------------------------------------------------
2021-07-23 15:07:55,696 epoch 4 - iter 51/516 - loss 0.18355625 - samples/sec: 133.33 - lr: 0.000030
2021-07-23 15:08:07,874 epoch 4 - iter 102/516 - loss 0.18862066 - samples/sec: 134.04 - lr: 0.000030
2021-07-23 15:08:20,200 epoch 4 - iter 153/516 - loss 0.18377105 - samples/sec: 132.44 - lr: 0.000030
2021-07-23 15:08:32,331 epoch 4 - iter 204/516 - loss 0.17459504 - samples/sec: 134.55 - lr: 0.000030
2021-07-23 15:08:44,236 epoch 4 - iter 255/516 - loss 0.17400601 - samples/sec: 137.12 - lr: 0.000030
2021-07-23 15:08:56,267 epoch 4 - iter 306/516 - loss 0.17375923 - samples/sec: 135.68 - lr: 0.000030
2021-07-23 15:09:08,287 epoch 4 - iter 357/516 - loss 0.17245150 - samples/sec: 135.80 - lr: 0.000030
2021-07-23 15:09:20,371 epoch 4 - iter 408/516 - loss 0.17384819 - samples/sec: 135.08 - lr: 0.000030
2021-07-23 15:09:32,424 epoch 4 - iter 459/516 - loss 0.17637972 - samples/sec: 135.43 - lr: 0.000030
2021-07-23 15:09:44,458 epoch 4 - iter 510/516 - loss 0.17714114 - samples/sec: 135.65 - lr: 0.000030
2021-07-23 15:09:45,779 ----------------------------------------------------------------------------------------------------
2021-07-23 15:09:45,780 EPOCH 4 done: loss 0.1771 - lr 0.0000300
2021-07-23 15:09:51,359 DEV : loss 0.06992930173873901 - score 0.979
2021-07-23 15:09:51,423 BAD EPOCHS (no improvement): 1
2021-07-23 15:09:51,423 ----------------------------------------------------------------------------------------------------
2021-07-23 15:10:03,619 epoch 5 - iter 51/516 - loss 0.14107237 - samples/sec: 133.86 - lr: 0.000030
2021-07-23 15:10:15,731 epoch 5 - iter 102/516 - loss 0.14362746 - samples/sec: 134.77 - lr: 0.000030
2021-07-23 15:10:27,686 epoch 5 - iter 153/516 - loss 0.15030315 - samples/sec: 136.54 - lr: 0.000030
2021-07-23 15:10:40,014 epoch 5 - iter 204/516 - loss 0.14836756 - samples/sec: 132.41 - lr: 0.000030
2021-07-23 15:10:52,112 epoch 5 - iter 255/516 - loss 0.15314230 - samples/sec: 134.92 - lr: 0.000030
2021-07-23 15:11:04,162 epoch 5 - iter 306/516 - loss 0.15648015 - samples/sec: 135.47 - lr: 0.000030
2021-07-23 15:11:16,363 epoch 5 - iter 357/516 - loss 0.15897612 - samples/sec: 133.79 - lr: 0.000030
2021-07-23 15:11:28,648 epoch 5 - iter 408/516 - loss 0.15813236 - samples/sec: 132.87 - lr: 0.000030
2021-07-23 15:11:40,778 epoch 5 - iter 459/516 - loss 0.15766793 - samples/sec: 134.57 - lr: 0.000030
2021-07-23 15:11:53,002 epoch 5 - iter 510/516 - loss 0.15920304 - samples/sec: 133.53 - lr: 0.000030
2021-07-23 15:11:54,302 ----------------------------------------------------------------------------------------------------
2021-07-23 15:11:54,302 EPOCH 5 done: loss 0.1588 - lr 0.0000300
2021-07-23 15:11:59,881 DEV : loss 0.06608694791793823 - score 0.9804
2021-07-23 15:11:59,945 BAD EPOCHS (no improvement): 2
2021-07-23 15:11:59,945 ----------------------------------------------------------------------------------------------------
2021-07-23 15:12:11,902 epoch 6 - iter 51/516 - loss 0.18585285 - samples/sec: 136.53 - lr: 0.000030
2021-07-23 15:12:24,195 epoch 6 - iter 102/516 - loss 0.16225246 - samples/sec: 132.79 - lr: 0.000030
2021-07-23 15:12:36,291 epoch 6 - iter 153/516 - loss 0.15540769 - samples/sec: 134.95 - lr: 0.000030
2021-07-23 15:12:48,337 epoch 6 - iter 204/516 - loss 0.15707899 - samples/sec: 135.51 - lr: 0.000030
2021-07-23 15:13:01,180 epoch 6 - iter 255/516 - loss 0.15634432 - samples/sec: 127.10 - lr: 0.000030
2021-07-23 15:13:13,321 epoch 6 - iter 306/516 - loss 0.15496209 - samples/sec: 134.44 - lr: 0.000030
2021-07-23 15:13:25,731 epoch 6 - iter 357/516 - loss 0.15570859 - samples/sec: 131.54 - lr: 0.000030
2021-07-23 15:13:37,935 epoch 6 - iter 408/516 - loss 0.15768295 - samples/sec: 133.76 - lr: 0.000030
2021-07-23 15:13:49,851 epoch 6 - iter 459/516 - loss 0.15424767 - samples/sec: 136.98 - lr: 0.000030
2021-07-23 15:14:01,967 epoch 6 - iter 510/516 - loss 0.15414502 - samples/sec: 134.73 - lr: 0.000030
2021-07-23 15:14:03,395 ----------------------------------------------------------------------------------------------------
2021-07-23 15:14:03,395 EPOCH 6 done: loss 0.1535 - lr 0.0000300
2021-07-23 15:14:08,982 DEV : loss 0.06053946539759636 - score 0.9819
2021-07-23 15:14:09,046 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:14:11,252 ----------------------------------------------------------------------------------------------------
2021-07-23 15:14:23,557 epoch 7 - iter 51/516 - loss 0.15087200 - samples/sec: 132.69 - lr: 0.000030
2021-07-23 15:14:35,908 epoch 7 - iter 102/516 - loss 0.15024000 - samples/sec: 132.16 - lr: 0.000030
2021-07-23 15:14:48,067 epoch 7 - iter 153/516 - loss 0.14925451 - samples/sec: 134.24 - lr: 0.000030
2021-07-23 15:15:00,399 epoch 7 - iter 204/516 - loss 0.14986341 - samples/sec: 132.37 - lr: 0.000030
2021-07-23 15:15:12,464 epoch 7 - iter 255/516 - loss 0.15137795 - samples/sec: 135.30 - lr: 0.000030
2021-07-23 15:15:24,536 epoch 7 - iter 306/516 - loss 0.14820912 - samples/sec: 135.21 - lr: 0.000030
2021-07-23 15:15:36,617 epoch 7 - iter 357/516 - loss 0.14882206 - samples/sec: 135.12 - lr: 0.000030
2021-07-23 15:15:48,867 epoch 7 - iter 408/516 - loss 0.14844536 - samples/sec: 133.26 - lr: 0.000030
2021-07-23 15:16:00,945 epoch 7 - iter 459/516 - loss 0.15035948 - samples/sec: 135.15 - lr: 0.000030
2021-07-23 15:16:13,145 epoch 7 - iter 510/516 - loss 0.14968905 - samples/sec: 133.80 - lr: 0.000030
2021-07-23 15:16:14,476 ----------------------------------------------------------------------------------------------------
2021-07-23 15:16:14,476 EPOCH 7 done: loss 0.1492 - lr 0.0000300
2021-07-23 15:16:20,090 DEV : loss 0.05952000245451927 - score 0.9826
2021-07-23 15:16:20,154 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:16:22,358 ----------------------------------------------------------------------------------------------------
2021-07-23 15:16:34,641 epoch 8 - iter 51/516 - loss 0.13897784 - samples/sec: 132.93 - lr: 0.000030
2021-07-23 15:16:46,532 epoch 8 - iter 102/516 - loss 0.14471585 - samples/sec: 137.28 - lr: 0.000030
2021-07-23 15:16:58,840 epoch 8 - iter 153/516 - loss 0.13941078 - samples/sec: 132.62 - lr: 0.000030
2021-07-23 15:17:10,861 epoch 8 - iter 204/516 - loss 0.13814279 - samples/sec: 135.79 - lr: 0.000030
2021-07-23 15:17:23,255 epoch 8 - iter 255/516 - loss 0.13994299 - samples/sec: 131.71 - lr: 0.000030
2021-07-23 15:17:35,499 epoch 8 - iter 306/516 - loss 0.13942574 - samples/sec: 133.31 - lr: 0.000030
2021-07-23 15:17:47,683 epoch 8 - iter 357/516 - loss 0.13709174 - samples/sec: 133.98 - lr: 0.000030
2021-07-23 15:17:59,869 epoch 8 - iter 408/516 - loss 0.13436862 - samples/sec: 133.95 - lr: 0.000030
2021-07-23 15:18:11,835 epoch 8 - iter 459/516 - loss 0.13354330 - samples/sec: 136.41 - lr: 0.000030
2021-07-23 15:18:23,889 epoch 8 - iter 510/516 - loss 0.13295854 - samples/sec: 135.42 - lr: 0.000030
2021-07-23 15:18:25,191 ----------------------------------------------------------------------------------------------------
2021-07-23 15:18:25,192 EPOCH 8 done: loss 0.1336 - lr 0.0000300
2021-07-23 15:18:30,803 DEV : loss 0.05957729369401932 - score 0.9835
2021-07-23 15:18:30,866 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:18:33,008 ----------------------------------------------------------------------------------------------------
2021-07-23 15:18:44,916 epoch 9 - iter 51/516 - loss 0.12317331 - samples/sec: 137.11 - lr: 0.000030
2021-07-23 15:18:57,060 epoch 9 - iter 102/516 - loss 0.12771086 - samples/sec: 134.42 - lr: 0.000030
2021-07-23 15:19:09,132 epoch 9 - iter 153/516 - loss 0.12644682 - samples/sec: 135.22 - lr: 0.000030
2021-07-23 15:19:21,523 epoch 9 - iter 204/516 - loss 0.12757410 - samples/sec: 131.74 - lr: 0.000030
2021-07-23 15:19:33,780 epoch 9 - iter 255/516 - loss 0.12449969 - samples/sec: 133.17 - lr: 0.000030
2021-07-23 15:19:46,013 epoch 9 - iter 306/516 - loss 0.12388231 - samples/sec: 133.44 - lr: 0.000030
2021-07-23 15:19:58,288 epoch 9 - iter 357/516 - loss 0.12395700 - samples/sec: 132.98 - lr: 0.000030
2021-07-23 15:20:10,063 epoch 9 - iter 408/516 - loss 0.12266814 - samples/sec: 138.63 - lr: 0.000030
2021-07-23 15:20:22,273 epoch 9 - iter 459/516 - loss 0.11958541 - samples/sec: 133.68 - lr: 0.000030
2021-07-23 15:20:34,600 epoch 9 - iter 510/516 - loss 0.11909981 - samples/sec: 132.43 - lr: 0.000030
2021-07-23 15:20:35,896 ----------------------------------------------------------------------------------------------------
2021-07-23 15:20:35,896 EPOCH 9 done: loss 0.1202 - lr 0.0000300
2021-07-23 15:20:41,514 DEV : loss 0.054542332887649536 - score 0.9848
2021-07-23 15:20:41,578 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:20:44,009 ----------------------------------------------------------------------------------------------------
2021-07-23 15:20:56,092 epoch 10 - iter 51/516 - loss 0.12302961 - samples/sec: 135.13 - lr: 0.000030
2021-07-23 15:21:08,354 epoch 10 - iter 102/516 - loss 0.10823110 - samples/sec: 133.12 - lr: 0.000030
2021-07-23 15:21:20,456 epoch 10 - iter 153/516 - loss 0.10247261 - samples/sec: 134.89 - lr: 0.000030
2021-07-23 15:21:32,752 epoch 10 - iter 204/516 - loss 0.09937228 - samples/sec: 132.76 - lr: 0.000030
2021-07-23 15:21:44,980 epoch 10 - iter 255/516 - loss 0.10040595 - samples/sec: 133.49 - lr: 0.000030
2021-07-23 15:21:57,203 epoch 10 - iter 306/516 - loss 0.10024126 - samples/sec: 133.54 - lr: 0.000030
2021-07-23 15:22:09,619 epoch 10 - iter 357/516 - loss 0.09908508 - samples/sec: 131.47 - lr: 0.000030
2021-07-23 15:22:21,408 epoch 10 - iter 408/516 - loss 0.09852405 - samples/sec: 138.47 - lr: 0.000030
2021-07-23 15:22:33,493 epoch 10 - iter 459/516 - loss 0.09779656 - samples/sec: 135.07 - lr: 0.000030
2021-07-23 15:22:45,892 epoch 10 - iter 510/516 - loss 0.09854196 - samples/sec: 131.65 - lr: 0.000030
2021-07-23 15:22:47,199 ----------------------------------------------------------------------------------------------------
2021-07-23 15:22:47,199 EPOCH 10 done: loss 0.0985 - lr 0.0000300
2021-07-23 15:22:53,361 DEV : loss 0.05545695871114731 - score 0.9826
2021-07-23 15:22:53,425 BAD EPOCHS (no improvement): 1
2021-07-23 15:22:53,426 ----------------------------------------------------------------------------------------------------
2021-07-23 15:23:05,652 epoch 11 - iter 51/516 - loss 0.10102959 - samples/sec: 133.53 - lr: 0.000030
2021-07-23 15:23:17,791 epoch 11 - iter 102/516 - loss 0.09356045 - samples/sec: 134.46 - lr: 0.000030
2021-07-23 15:23:30,287 epoch 11 - iter 153/516 - loss 0.09130070 - samples/sec: 130.63 - lr: 0.000030
2021-07-23 15:23:42,532 epoch 11 - iter 204/516 - loss 0.08951181 - samples/sec: 133.31 - lr: 0.000030
2021-07-23 15:23:54,326 epoch 11 - iter 255/516 - loss 0.09100012 - samples/sec: 138.40 - lr: 0.000030
2021-07-23 15:24:06,503 epoch 11 - iter 306/516 - loss 0.09009888 - samples/sec: 134.06 - lr: 0.000030
2021-07-23 15:24:18,414 epoch 11 - iter 357/516 - loss 0.08832890 - samples/sec: 137.05 - lr: 0.000030
2021-07-23 15:24:30,971 epoch 11 - iter 408/516 - loss 0.08777656 - samples/sec: 129.99 - lr: 0.000030
2021-07-23 15:24:43,325 epoch 11 - iter 459/516 - loss 0.08782616 - samples/sec: 132.13 - lr: 0.000030
2021-07-23 15:24:55,500 epoch 11 - iter 510/516 - loss 0.08675244 - samples/sec: 134.08 - lr: 0.000030
2021-07-23 15:24:56,816 ----------------------------------------------------------------------------------------------------
2021-07-23 15:24:56,816 EPOCH 11 done: loss 0.0864 - lr 0.0000300
2021-07-23 15:25:02,444 DEV : loss 0.061949945986270905 - score 0.9814
2021-07-23 15:25:02,509 BAD EPOCHS (no improvement): 2
2021-07-23 15:25:02,509 ----------------------------------------------------------------------------------------------------
2021-07-23 15:25:14,505 epoch 12 - iter 51/516 - loss 0.07413210 - samples/sec: 136.09 - lr: 0.000030
2021-07-23 15:25:26,736 epoch 12 - iter 102/516 - loss 0.07523015 - samples/sec: 133.46 - lr: 0.000030
2021-07-23 15:25:38,947 epoch 12 - iter 153/516 - loss 0.07722117 - samples/sec: 133.68 - lr: 0.000030
2021-07-23 15:25:50,971 epoch 12 - iter 204/516 - loss 0.07599525 - samples/sec: 135.76 - lr: 0.000030
2021-07-23 15:26:03,145 epoch 12 - iter 255/516 - loss 0.07837275 - samples/sec: 134.09 - lr: 0.000030
2021-07-23 15:26:15,342 epoch 12 - iter 306/516 - loss 0.07796608 - samples/sec: 133.83 - lr: 0.000030
2021-07-23 15:26:27,696 epoch 12 - iter 357/516 - loss 0.07544099 - samples/sec: 132.13 - lr: 0.000030
2021-07-23 15:26:39,976 epoch 12 - iter 408/516 - loss 0.07526443 - samples/sec: 132.93 - lr: 0.000030
2021-07-23 15:26:52,244 epoch 12 - iter 459/516 - loss 0.07609914 - samples/sec: 133.06 - lr: 0.000030
2021-07-23 15:27:04,574 epoch 12 - iter 510/516 - loss 0.07556004 - samples/sec: 132.38 - lr: 0.000030
2021-07-23 15:27:05,913 ----------------------------------------------------------------------------------------------------
2021-07-23 15:27:05,913 EPOCH 12 done: loss 0.0756 - lr 0.0000300
2021-07-23 15:27:11,519 DEV : loss 0.051362402737140656 - score 0.9848
2021-07-23 15:27:11,586 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:27:13,765 ----------------------------------------------------------------------------------------------------
2021-07-23 15:27:26,068 epoch 13 - iter 51/516 - loss 0.07022856 - samples/sec: 132.71 - lr: 0.000030
2021-07-23 15:27:38,500 epoch 13 - iter 102/516 - loss 0.07459538 - samples/sec: 131.31 - lr: 0.000030
2021-07-23 15:27:50,382 epoch 13 - iter 153/516 - loss 0.06938005 - samples/sec: 137.37 - lr: 0.000030
2021-07-23 15:28:02,489 epoch 13 - iter 204/516 - loss 0.06659358 - samples/sec: 134.83 - lr: 0.000030
2021-07-23 15:28:14,740 epoch 13 - iter 255/516 - loss 0.06860596 - samples/sec: 133.23 - lr: 0.000030
2021-07-23 15:28:27,105 epoch 13 - iter 306/516 - loss 0.06987255 - samples/sec: 132.01 - lr: 0.000030
2021-07-23 15:28:39,228 epoch 13 - iter 357/516 - loss 0.07056032 - samples/sec: 134.65 - lr: 0.000030
2021-07-23 15:28:51,709 epoch 13 - iter 408/516 - loss 0.07161248 - samples/sec: 130.79 - lr: 0.000030
2021-07-23 15:29:03,781 epoch 13 - iter 459/516 - loss 0.07198993 - samples/sec: 135.22 - lr: 0.000030
2021-07-23 15:29:15,872 epoch 13 - iter 510/516 - loss 0.07179852 - samples/sec: 135.00 - lr: 0.000030
2021-07-23 15:29:17,238 ----------------------------------------------------------------------------------------------------
2021-07-23 15:29:17,238 EPOCH 13 done: loss 0.0721 - lr 0.0000300
2021-07-23 15:29:22,853 DEV : loss 0.05050598829984665 - score 0.9843
2021-07-23 15:29:22,918 BAD EPOCHS (no improvement): 1
2021-07-23 15:29:22,918 ----------------------------------------------------------------------------------------------------
2021-07-23 15:29:35,049 epoch 14 - iter 51/516 - loss 0.07148859 - samples/sec: 134.57 - lr: 0.000030
2021-07-23 15:29:47,259 epoch 14 - iter 102/516 - loss 0.07637040 - samples/sec: 133.69 - lr: 0.000030
2021-07-23 15:29:59,124 epoch 14 - iter 153/516 - loss 0.07554046 - samples/sec: 137.58 - lr: 0.000030
2021-07-23 15:30:11,555 epoch 14 - iter 204/516 - loss 0.07121657 - samples/sec: 131.32 - lr: 0.000030
2021-07-23 15:30:23,941 epoch 14 - iter 255/516 - loss 0.06954425 - samples/sec: 131.79 - lr: 0.000030
2021-07-23 15:30:36,019 epoch 14 - iter 306/516 - loss 0.06986220 - samples/sec: 135.15 - lr: 0.000030
2021-07-23 15:30:48,272 epoch 14 - iter 357/516 - loss 0.06957044 - samples/sec: 133.22 - lr: 0.000030
2021-07-23 15:31:00,218 epoch 14 - iter 408/516 - loss 0.06887179 - samples/sec: 136.64 - lr: 0.000030
2021-07-23 15:31:12,652 epoch 14 - iter 459/516 - loss 0.06844696 - samples/sec: 131.29 - lr: 0.000030
2021-07-23 15:31:24,943 epoch 14 - iter 510/516 - loss 0.06925797 - samples/sec: 132.81 - lr: 0.000030
2021-07-23 15:31:26,336 ----------------------------------------------------------------------------------------------------
2021-07-23 15:31:26,336 EPOCH 14 done: loss 0.0695 - lr 0.0000300
2021-07-23 15:31:31,963 DEV : loss 0.04765304550528526 - score 0.9856
2021-07-23 15:31:32,027 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:31:34,244 ----------------------------------------------------------------------------------------------------
2021-07-23 15:31:46,584 epoch 15 - iter 51/516 - loss 0.07538901 - samples/sec: 132.31 - lr: 0.000030
2021-07-23 15:31:58,776 epoch 15 - iter 102/516 - loss 0.07427770 - samples/sec: 133.89 - lr: 0.000030
2021-07-23 15:32:10,867 epoch 15 - iter 153/516 - loss 0.06907703 - samples/sec: 135.01 - lr: 0.000030
2021-07-23 15:32:23,287 epoch 15 - iter 204/516 - loss 0.07185743 - samples/sec: 131.43 - lr: 0.000030
2021-07-23 15:32:35,372 epoch 15 - iter 255/516 - loss 0.06786421 - samples/sec: 135.07 - lr: 0.000030
2021-07-23 15:32:47,452 epoch 15 - iter 306/516 - loss 0.06907309 - samples/sec: 135.13 - lr: 0.000030
2021-07-23 15:32:59,697 epoch 15 - iter 357/516 - loss 0.07207773 - samples/sec: 133.31 - lr: 0.000030
2021-07-23 15:33:11,580 epoch 15 - iter 408/516 - loss 0.07003599 - samples/sec: 137.37 - lr: 0.000030
2021-07-23 15:33:23,860 epoch 15 - iter 459/516 - loss 0.06978010 - samples/sec: 132.93 - lr: 0.000030
2021-07-23 15:33:36,147 epoch 15 - iter 510/516 - loss 0.06873946 - samples/sec: 132.85 - lr: 0.000030
2021-07-23 15:33:37,529 ----------------------------------------------------------------------------------------------------
2021-07-23 15:33:37,529 EPOCH 15 done: loss 0.0685 - lr 0.0000300
2021-07-23 15:33:43,697 DEV : loss 0.04657595977187157 - score 0.9866
2021-07-23 15:33:43,762 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:33:46,097 ----------------------------------------------------------------------------------------------------
2021-07-23 15:33:58,341 epoch 16 - iter 51/516 - loss 0.06714773 - samples/sec: 133.34 - lr: 0.000030
2021-07-23 15:34:10,487 epoch 16 - iter 102/516 - loss 0.06197561 - samples/sec: 134.40 - lr: 0.000030
2021-07-23 15:34:22,689 epoch 16 - iter 153/516 - loss 0.06209753 - samples/sec: 133.78 - lr: 0.000030
2021-07-23 15:34:34,923 epoch 16 - iter 204/516 - loss 0.06074764 - samples/sec: 133.42 - lr: 0.000030
2021-07-23 15:34:47,066 epoch 16 - iter 255/516 - loss 0.06298713 - samples/sec: 134.44 - lr: 0.000030
2021-07-23 15:34:59,655 epoch 16 - iter 306/516 - loss 0.06585322 - samples/sec: 129.66 - lr: 0.000030
2021-07-23 15:35:11,796 epoch 16 - iter 357/516 - loss 0.06702204 - samples/sec: 134.45 - lr: 0.000030
2021-07-23 15:35:24,147 epoch 16 - iter 408/516 - loss 0.06491132 - samples/sec: 132.16 - lr: 0.000030
2021-07-23 15:35:36,498 epoch 16 - iter 459/516 - loss 0.06504467 - samples/sec: 132.16 - lr: 0.000030
2021-07-23 15:35:48,451 epoch 16 - iter 510/516 - loss 0.06561066 - samples/sec: 136.57 - lr: 0.000030
2021-07-23 15:35:49,706 ----------------------------------------------------------------------------------------------------
2021-07-23 15:35:49,706 EPOCH 16 done: loss 0.0657 - lr 0.0000300
2021-07-23 15:35:55,333 DEV : loss 0.04913284629583359 - score 0.9851
2021-07-23 15:35:55,398 BAD EPOCHS (no improvement): 1
2021-07-23 15:35:55,398 ----------------------------------------------------------------------------------------------------
2021-07-23 15:36:07,688 epoch 17 - iter 51/516 - loss 0.08237787 - samples/sec: 132.84 - lr: 0.000030
2021-07-23 15:36:20,012 epoch 17 - iter 102/516 - loss 0.07954637 - samples/sec: 132.45 - lr: 0.000030
2021-07-23 15:36:32,099 epoch 17 - iter 153/516 - loss 0.07191903 - samples/sec: 135.05 - lr: 0.000030
2021-07-23 15:36:44,208 epoch 17 - iter 204/516 - loss 0.06903518 - samples/sec: 134.80 - lr: 0.000030
2021-07-23 15:36:56,212 epoch 17 - iter 255/516 - loss 0.06779517 - samples/sec: 135.99 - lr: 0.000030
2021-07-23 15:37:08,294 epoch 17 - iter 306/516 - loss 0.06939816 - samples/sec: 135.10 - lr: 0.000030
2021-07-23 15:37:20,604 epoch 17 - iter 357/516 - loss 0.06623413 - samples/sec: 132.60 - lr: 0.000030
2021-07-23 15:37:32,944 epoch 17 - iter 408/516 - loss 0.06616625 - samples/sec: 132.29 - lr: 0.000030
2021-07-23 15:37:45,084 epoch 17 - iter 459/516 - loss 0.06596077 - samples/sec: 134.46 - lr: 0.000030
2021-07-23 15:37:57,304 epoch 17 - iter 510/516 - loss 0.06436829 - samples/sec: 133.57 - lr: 0.000030
2021-07-23 15:37:58,596 ----------------------------------------------------------------------------------------------------
2021-07-23 15:37:58,596 EPOCH 17 done: loss 0.0647 - lr 0.0000300
2021-07-23 15:38:04,219 DEV : loss 0.0497560054063797 - score 0.985
2021-07-23 15:38:04,283 BAD EPOCHS (no improvement): 2
2021-07-23 15:38:04,283 ----------------------------------------------------------------------------------------------------
2021-07-23 15:38:16,391 epoch 18 - iter 51/516 - loss 0.06313517 - samples/sec: 134.83 - lr: 0.000030
2021-07-23 15:38:28,907 epoch 18 - iter 102/516 - loss 0.06377852 - samples/sec: 130.42 - lr: 0.000030
2021-07-23 15:38:41,047 epoch 18 - iter 153/516 - loss 0.06350698 - samples/sec: 134.45 - lr: 0.000030
2021-07-23 15:38:53,396 epoch 18 - iter 204/516 - loss 0.06548970 - samples/sec: 132.19 - lr: 0.000030
2021-07-23 15:39:05,632 epoch 18 - iter 255/516 - loss 0.06562001 - samples/sec: 133.41 - lr: 0.000030
2021-07-23 15:39:17,640 epoch 18 - iter 306/516 - loss 0.06637208 - samples/sec: 135.93 - lr: 0.000030
2021-07-23 15:39:29,842 epoch 18 - iter 357/516 - loss 0.06534449 - samples/sec: 133.78 - lr: 0.000030
2021-07-23 15:39:42,380 epoch 18 - iter 408/516 - loss 0.06442274 - samples/sec: 130.19 - lr: 0.000030
2021-07-23 15:39:54,513 epoch 18 - iter 459/516 - loss 0.06338308 - samples/sec: 134.55 - lr: 0.000030
2021-07-23 15:40:06,444 epoch 18 - iter 510/516 - loss 0.06248593 - samples/sec: 136.81 - lr: 0.000030
2021-07-23 15:40:07,823 ----------------------------------------------------------------------------------------------------
2021-07-23 15:40:07,823 EPOCH 18 done: loss 0.0623 - lr 0.0000300
2021-07-23 15:40:13,453 DEV : loss 0.04785671457648277 - score 0.9873
2021-07-23 15:40:13,517 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:40:15,888 ----------------------------------------------------------------------------------------------------
2021-07-23 15:40:28,220 epoch 19 - iter 51/516 - loss 0.06276698 - samples/sec: 132.39 - lr: 0.000030
2021-07-23 15:40:40,451 epoch 19 - iter 102/516 - loss 0.05649937 - samples/sec: 133.45 - lr: 0.000030
2021-07-23 15:40:52,700 epoch 19 - iter 153/516 - loss 0.05774019 - samples/sec: 133.27 - lr: 0.000030
2021-07-23 15:41:04,591 epoch 19 - iter 204/516 - loss 0.05627775 - samples/sec: 137.28 - lr: 0.000030
2021-07-23 15:41:16,692 epoch 19 - iter 255/516 - loss 0.05795432 - samples/sec: 134.90 - lr: 0.000030
2021-07-23 15:41:29,051 epoch 19 - iter 306/516 - loss 0.05957672 - samples/sec: 132.07 - lr: 0.000030
2021-07-23 15:41:41,253 epoch 19 - iter 357/516 - loss 0.05846506 - samples/sec: 133.78 - lr: 0.000030
2021-07-23 15:41:53,211 epoch 19 - iter 408/516 - loss 0.05973979 - samples/sec: 136.51 - lr: 0.000030
2021-07-23 15:42:05,648 epoch 19 - iter 459/516 - loss 0.05996295 - samples/sec: 131.25 - lr: 0.000030
2021-07-23 15:42:18,138 epoch 19 - iter 510/516 - loss 0.05937444 - samples/sec: 130.69 - lr: 0.000030
2021-07-23 15:42:19,406 ----------------------------------------------------------------------------------------------------
2021-07-23 15:42:19,406 EPOCH 19 done: loss 0.0594 - lr 0.0000300
2021-07-23 15:42:25,039 DEV : loss 0.043733689934015274 - score 0.9888
2021-07-23 15:42:25,104 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:42:27,294 ----------------------------------------------------------------------------------------------------
2021-07-23 15:42:39,583 epoch 20 - iter 51/516 - loss 0.06942435 - samples/sec: 132.86 - lr: 0.000030
2021-07-23 15:42:51,547 epoch 20 - iter 102/516 - loss 0.05916224 - samples/sec: 136.44 - lr: 0.000030
2021-07-23 15:43:03,736 epoch 20 - iter 153/516 - loss 0.06068918 - samples/sec: 133.92 - lr: 0.000030
2021-07-23 15:43:15,989 epoch 20 - iter 204/516 - loss 0.05949772 - samples/sec: 133.22 - lr: 0.000030
2021-07-23 15:43:28,302 epoch 20 - iter 255/516 - loss 0.05857192 - samples/sec: 132.57 - lr: 0.000030
2021-07-23 15:43:40,430 epoch 20 - iter 306/516 - loss 0.05696929 - samples/sec: 134.59 - lr: 0.000030
2021-07-23 15:43:52,543 epoch 20 - iter 357/516 - loss 0.05865128 - samples/sec: 134.76 - lr: 0.000030
2021-07-23 15:44:04,796 epoch 20 - iter 408/516 - loss 0.05930188 - samples/sec: 133.22 - lr: 0.000030
2021-07-23 15:44:16,990 epoch 20 - iter 459/516 - loss 0.05942408 - samples/sec: 133.86 - lr: 0.000030
2021-07-23 15:44:29,197 epoch 20 - iter 510/516 - loss 0.06052165 - samples/sec: 133.73 - lr: 0.000030
2021-07-23 15:44:30,554 ----------------------------------------------------------------------------------------------------
2021-07-23 15:44:30,554 EPOCH 20 done: loss 0.0603 - lr 0.0000300
2021-07-23 15:44:36,741 DEV : loss 0.04350006952881813 - score 0.9879
2021-07-23 15:44:36,807 BAD EPOCHS (no improvement): 1
2021-07-23 15:44:36,807 ----------------------------------------------------------------------------------------------------
2021-07-23 15:44:48,881 epoch 21 - iter 51/516 - loss 0.04620800 - samples/sec: 135.21 - lr: 0.000030
2021-07-23 15:45:01,393 epoch 21 - iter 102/516 - loss 0.05281289 - samples/sec: 130.46 - lr: 0.000030
2021-07-23 15:45:13,771 epoch 21 - iter 153/516 - loss 0.05118800 - samples/sec: 131.87 - lr: 0.000030
2021-07-23 15:45:25,975 epoch 21 - iter 204/516 - loss 0.04966825 - samples/sec: 133.76 - lr: 0.000030
2021-07-23 15:45:38,143 epoch 21 - iter 255/516 - loss 0.05311969 - samples/sec: 134.15 - lr: 0.000030
2021-07-23 15:45:50,151 epoch 21 - iter 306/516 - loss 0.05397145 - samples/sec: 135.94 - lr: 0.000030
2021-07-23 15:46:02,469 epoch 21 - iter 357/516 - loss 0.05490267 - samples/sec: 132.52 - lr: 0.000030
2021-07-23 15:46:14,862 epoch 21 - iter 408/516 - loss 0.05449945 - samples/sec: 131.71 - lr: 0.000030
2021-07-23 15:46:26,871 epoch 21 - iter 459/516 - loss 0.05458490 - samples/sec: 135.93 - lr: 0.000030
2021-07-23 15:46:39,075 epoch 21 - iter 510/516 - loss 0.05637170 - samples/sec: 133.75 - lr: 0.000030
2021-07-23 15:46:40,372 ----------------------------------------------------------------------------------------------------
2021-07-23 15:46:40,372 EPOCH 21 done: loss 0.0567 - lr 0.0000300
2021-07-23 15:46:46,014 DEV : loss 0.045712850987911224 - score 0.9869
2021-07-23 15:46:46,079 BAD EPOCHS (no improvement): 2
2021-07-23 15:46:46,079 ----------------------------------------------------------------------------------------------------
2021-07-23 15:46:58,188 epoch 22 - iter 51/516 - loss 0.05913282 - samples/sec: 134.82 - lr: 0.000030
2021-07-23 15:47:10,363 epoch 22 - iter 102/516 - loss 0.05609488 - samples/sec: 134.08 - lr: 0.000030
2021-07-23 15:47:22,511 epoch 22 - iter 153/516 - loss 0.05683437 - samples/sec: 134.37 - lr: 0.000030
2021-07-23 15:47:34,594 epoch 22 - iter 204/516 - loss 0.06049120 - samples/sec: 135.09 - lr: 0.000030
2021-07-23 15:47:46,523 epoch 22 - iter 255/516 - loss 0.06017880 - samples/sec: 136.84 - lr: 0.000030
2021-07-23 15:47:58,792 epoch 22 - iter 306/516 - loss 0.05983620 - samples/sec: 133.05 - lr: 0.000030
2021-07-23 15:48:10,844 epoch 22 - iter 357/516 - loss 0.05870113 - samples/sec: 135.44 - lr: 0.000030
2021-07-23 15:48:23,250 epoch 22 - iter 408/516 - loss 0.05840553 - samples/sec: 131.58 - lr: 0.000030
2021-07-23 15:48:35,284 epoch 22 - iter 459/516 - loss 0.05872362 - samples/sec: 135.65 - lr: 0.000030
2021-07-23 15:48:47,356 epoch 22 - iter 510/516 - loss 0.05727824 - samples/sec: 135.22 - lr: 0.000030
2021-07-23 15:48:48,796 ----------------------------------------------------------------------------------------------------
2021-07-23 15:48:48,796 EPOCH 22 done: loss 0.0572 - lr 0.0000300
2021-07-23 15:48:54,413 DEV : loss 0.04662999510765076 - score 0.9859
2021-07-23 15:48:54,479 BAD EPOCHS (no improvement): 3
2021-07-23 15:48:54,479 ----------------------------------------------------------------------------------------------------
2021-07-23 15:49:06,534 epoch 23 - iter 51/516 - loss 0.05435814 - samples/sec: 135.43 - lr: 0.000030
2021-07-23 15:49:18,338 epoch 23 - iter 102/516 - loss 0.05655475 - samples/sec: 138.29 - lr: 0.000030
2021-07-23 15:49:30,560 epoch 23 - iter 153/516 - loss 0.05925200 - samples/sec: 133.56 - lr: 0.000030
2021-07-23 15:49:42,760 epoch 23 - iter 204/516 - loss 0.05704202 - samples/sec: 133.80 - lr: 0.000030
2021-07-23 15:49:55,243 epoch 23 - iter 255/516 - loss 0.05539888 - samples/sec: 130.76 - lr: 0.000030
2021-07-23 15:50:07,484 epoch 23 - iter 306/516 - loss 0.05645778 - samples/sec: 133.35 - lr: 0.000030
2021-07-23 15:50:19,717 epoch 23 - iter 357/516 - loss 0.05616720 - samples/sec: 133.44 - lr: 0.000030
2021-07-23 15:50:32,046 epoch 23 - iter 408/516 - loss 0.05687965 - samples/sec: 132.39 - lr: 0.000030
2021-07-23 15:50:44,227 epoch 23 - iter 459/516 - loss 0.05743146 - samples/sec: 134.01 - lr: 0.000030
2021-07-23 15:50:56,604 epoch 23 - iter 510/516 - loss 0.05791540 - samples/sec: 131.88 - lr: 0.000030
2021-07-23 15:50:57,951 ----------------------------------------------------------------------------------------------------
2021-07-23 15:50:57,951 EPOCH 23 done: loss 0.0582 - lr 0.0000300
2021-07-23 15:51:03,588 DEV : loss 0.04922514036297798 - score 0.986
Epoch    23: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 15:51:03,652 BAD EPOCHS (no improvement): 4
2021-07-23 15:51:03,653 ----------------------------------------------------------------------------------------------------
2021-07-23 15:51:15,904 epoch 24 - iter 51/516 - loss 0.04313891 - samples/sec: 133.26 - lr: 0.000015
2021-07-23 15:51:28,100 epoch 24 - iter 102/516 - loss 0.05407412 - samples/sec: 133.83 - lr: 0.000015
2021-07-23 15:51:39,911 epoch 24 - iter 153/516 - loss 0.05353243 - samples/sec: 138.22 - lr: 0.000015
2021-07-23 15:51:52,147 epoch 24 - iter 204/516 - loss 0.05236374 - samples/sec: 133.40 - lr: 0.000015
2021-07-23 15:52:04,693 epoch 24 - iter 255/516 - loss 0.05057389 - samples/sec: 130.11 - lr: 0.000015
2021-07-23 15:52:16,851 epoch 24 - iter 306/516 - loss 0.05207957 - samples/sec: 134.26 - lr: 0.000015
2021-07-23 15:52:28,973 epoch 24 - iter 357/516 - loss 0.05362453 - samples/sec: 134.66 - lr: 0.000015
2021-07-23 15:52:41,119 epoch 24 - iter 408/516 - loss 0.05365953 - samples/sec: 134.39 - lr: 0.000015
2021-07-23 15:52:53,599 epoch 24 - iter 459/516 - loss 0.05461859 - samples/sec: 130.79 - lr: 0.000015
2021-07-23 15:53:05,847 epoch 24 - iter 510/516 - loss 0.05446583 - samples/sec: 133.28 - lr: 0.000015
2021-07-23 15:53:07,200 ----------------------------------------------------------------------------------------------------
2021-07-23 15:53:07,200 EPOCH 24 done: loss 0.0544 - lr 0.0000150
2021-07-23 15:53:12,828 DEV : loss 0.04823429509997368 - score 0.986
2021-07-23 15:53:12,892 BAD EPOCHS (no improvement): 1
2021-07-23 15:53:12,893 ----------------------------------------------------------------------------------------------------
2021-07-23 15:53:25,644 epoch 25 - iter 51/516 - loss 0.05762202 - samples/sec: 128.03 - lr: 0.000015
2021-07-23 15:53:37,559 epoch 25 - iter 102/516 - loss 0.05161823 - samples/sec: 137.00 - lr: 0.000015
2021-07-23 15:53:49,631 epoch 25 - iter 153/516 - loss 0.05342649 - samples/sec: 135.23 - lr: 0.000015
2021-07-23 15:54:01,701 epoch 25 - iter 204/516 - loss 0.05314403 - samples/sec: 135.24 - lr: 0.000015
2021-07-23 15:54:13,907 epoch 25 - iter 255/516 - loss 0.05179319 - samples/sec: 133.73 - lr: 0.000015
2021-07-23 15:54:26,003 epoch 25 - iter 306/516 - loss 0.05290947 - samples/sec: 134.95 - lr: 0.000015
2021-07-23 15:54:38,204 epoch 25 - iter 357/516 - loss 0.05273565 - samples/sec: 133.78 - lr: 0.000015
2021-07-23 15:54:50,515 epoch 25 - iter 408/516 - loss 0.05144725 - samples/sec: 132.59 - lr: 0.000015
2021-07-23 15:55:02,631 epoch 25 - iter 459/516 - loss 0.05119982 - samples/sec: 134.73 - lr: 0.000015
2021-07-23 15:55:14,678 epoch 25 - iter 510/516 - loss 0.05197213 - samples/sec: 135.50 - lr: 0.000015
2021-07-23 15:55:16,084 ----------------------------------------------------------------------------------------------------
2021-07-23 15:55:16,085 EPOCH 25 done: loss 0.0517 - lr 0.0000150
2021-07-23 15:55:21,700 DEV : loss 0.04411717504262924 - score 0.9879
2021-07-23 15:55:21,765 BAD EPOCHS (no improvement): 2
2021-07-23 15:55:21,766 ----------------------------------------------------------------------------------------------------
2021-07-23 15:55:33,732 epoch 26 - iter 51/516 - loss 0.04595512 - samples/sec: 136.43 - lr: 0.000015
2021-07-23 15:55:45,797 epoch 26 - iter 102/516 - loss 0.04506500 - samples/sec: 135.30 - lr: 0.000015
2021-07-23 15:55:57,901 epoch 26 - iter 153/516 - loss 0.04875505 - samples/sec: 134.87 - lr: 0.000015
2021-07-23 15:56:10,059 epoch 26 - iter 204/516 - loss 0.05098268 - samples/sec: 134.26 - lr: 0.000015
2021-07-23 15:56:22,408 epoch 26 - iter 255/516 - loss 0.04836815 - samples/sec: 132.18 - lr: 0.000015
2021-07-23 15:56:34,508 epoch 26 - iter 306/516 - loss 0.04822247 - samples/sec: 134.90 - lr: 0.000015
2021-07-23 15:56:46,851 epoch 26 - iter 357/516 - loss 0.04794799 - samples/sec: 132.24 - lr: 0.000015
2021-07-23 15:56:59,007 epoch 26 - iter 408/516 - loss 0.04811396 - samples/sec: 134.29 - lr: 0.000015
2021-07-23 15:57:11,205 epoch 26 - iter 459/516 - loss 0.04821676 - samples/sec: 133.82 - lr: 0.000015
2021-07-23 15:57:23,413 epoch 26 - iter 510/516 - loss 0.04894513 - samples/sec: 133.72 - lr: 0.000015
2021-07-23 15:57:24,794 ----------------------------------------------------------------------------------------------------
2021-07-23 15:57:24,794 EPOCH 26 done: loss 0.0489 - lr 0.0000150
2021-07-23 15:57:30,424 DEV : loss 0.045165568590164185 - score 0.9856
2021-07-23 15:57:30,489 BAD EPOCHS (no improvement): 3
2021-07-23 15:57:30,490 ----------------------------------------------------------------------------------------------------
2021-07-23 15:57:42,251 epoch 27 - iter 51/516 - loss 0.04531888 - samples/sec: 138.81 - lr: 0.000015
2021-07-23 15:57:54,380 epoch 27 - iter 102/516 - loss 0.04631443 - samples/sec: 134.58 - lr: 0.000015
2021-07-23 15:58:06,653 epoch 27 - iter 153/516 - loss 0.04804437 - samples/sec: 133.01 - lr: 0.000015
2021-07-23 15:58:19,056 epoch 27 - iter 204/516 - loss 0.05021899 - samples/sec: 131.60 - lr: 0.000015
2021-07-23 15:58:31,060 epoch 27 - iter 255/516 - loss 0.04893463 - samples/sec: 135.98 - lr: 0.000015
2021-07-23 15:58:43,356 epoch 27 - iter 306/516 - loss 0.04928348 - samples/sec: 132.76 - lr: 0.000015
2021-07-23 15:58:55,540 epoch 27 - iter 357/516 - loss 0.04813394 - samples/sec: 133.98 - lr: 0.000015
2021-07-23 15:59:07,539 epoch 27 - iter 408/516 - loss 0.04840870 - samples/sec: 136.04 - lr: 0.000015
2021-07-23 15:59:19,779 epoch 27 - iter 459/516 - loss 0.04851892 - samples/sec: 133.36 - lr: 0.000015
2021-07-23 15:59:31,929 epoch 27 - iter 510/516 - loss 0.04855418 - samples/sec: 134.35 - lr: 0.000015
2021-07-23 15:59:33,335 ----------------------------------------------------------------------------------------------------
2021-07-23 15:59:33,335 EPOCH 27 done: loss 0.0487 - lr 0.0000150
2021-07-23 15:59:38,966 DEV : loss 0.04242841526865959 - score 0.9891
2021-07-23 15:59:39,030 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:59:41,241 ----------------------------------------------------------------------------------------------------
2021-07-23 15:59:53,479 epoch 28 - iter 51/516 - loss 0.06789324 - samples/sec: 133.41 - lr: 0.000015
2021-07-23 16:00:05,767 epoch 28 - iter 102/516 - loss 0.05719190 - samples/sec: 132.84 - lr: 0.000015
2021-07-23 16:00:18,022 epoch 28 - iter 153/516 - loss 0.05477266 - samples/sec: 133.19 - lr: 0.000015
2021-07-23 16:00:30,508 epoch 28 - iter 204/516 - loss 0.05151096 - samples/sec: 130.74 - lr: 0.000015
2021-07-23 16:00:42,808 epoch 28 - iter 255/516 - loss 0.05156354 - samples/sec: 132.71 - lr: 0.000015
2021-07-23 16:00:54,642 epoch 28 - iter 306/516 - loss 0.04892510 - samples/sec: 137.94 - lr: 0.000015
2021-07-23 16:01:06,791 epoch 28 - iter 357/516 - loss 0.04876997 - samples/sec: 134.36 - lr: 0.000015
2021-07-23 16:01:19,019 epoch 28 - iter 408/516 - loss 0.04886679 - samples/sec: 133.50 - lr: 0.000015
2021-07-23 16:01:31,074 epoch 28 - iter 459/516 - loss 0.04975902 - samples/sec: 135.40 - lr: 0.000015
2021-07-23 16:01:43,452 epoch 28 - iter 510/516 - loss 0.04940875 - samples/sec: 131.88 - lr: 0.000015
2021-07-23 16:01:44,879 ----------------------------------------------------------------------------------------------------
2021-07-23 16:01:44,880 EPOCH 28 done: loss 0.0494 - lr 0.0000150
2021-07-23 16:01:50,512 DEV : loss 0.043979354202747345 - score 0.9872
2021-07-23 16:01:50,577 BAD EPOCHS (no improvement): 1
2021-07-23 16:01:50,577 ----------------------------------------------------------------------------------------------------
2021-07-23 16:02:02,924 epoch 29 - iter 51/516 - loss 0.04989175 - samples/sec: 132.22 - lr: 0.000015
2021-07-23 16:02:15,115 epoch 29 - iter 102/516 - loss 0.04227100 - samples/sec: 133.90 - lr: 0.000015
2021-07-23 16:02:27,240 epoch 29 - iter 153/516 - loss 0.04373488 - samples/sec: 134.63 - lr: 0.000015
2021-07-23 16:02:39,670 epoch 29 - iter 204/516 - loss 0.04561133 - samples/sec: 131.32 - lr: 0.000015
2021-07-23 16:02:52,005 epoch 29 - iter 255/516 - loss 0.04670904 - samples/sec: 132.33 - lr: 0.000015
2021-07-23 16:03:04,190 epoch 29 - iter 306/516 - loss 0.04608390 - samples/sec: 133.96 - lr: 0.000015
2021-07-23 16:03:16,519 epoch 29 - iter 357/516 - loss 0.04734792 - samples/sec: 132.40 - lr: 0.000015
2021-07-23 16:03:28,667 epoch 29 - iter 408/516 - loss 0.04762839 - samples/sec: 134.37 - lr: 0.000015
2021-07-23 16:03:40,650 epoch 29 - iter 459/516 - loss 0.04829143 - samples/sec: 136.22 - lr: 0.000015
2021-07-23 16:03:52,891 epoch 29 - iter 510/516 - loss 0.04845654 - samples/sec: 133.35 - lr: 0.000015
2021-07-23 16:03:54,200 ----------------------------------------------------------------------------------------------------
2021-07-23 16:03:54,200 EPOCH 29 done: loss 0.0484 - lr 0.0000150
2021-07-23 16:04:00,395 DEV : loss 0.04413807764649391 - score 0.9888
2021-07-23 16:04:00,460 BAD EPOCHS (no improvement): 2
2021-07-23 16:04:00,460 ----------------------------------------------------------------------------------------------------
2021-07-23 16:04:12,660 epoch 30 - iter 51/516 - loss 0.06827895 - samples/sec: 133.82 - lr: 0.000015
2021-07-23 16:04:24,812 epoch 30 - iter 102/516 - loss 0.05588905 - samples/sec: 134.32 - lr: 0.000015
2021-07-23 16:04:36,949 epoch 30 - iter 153/516 - loss 0.05834854 - samples/sec: 134.50 - lr: 0.000015
2021-07-23 16:04:49,183 epoch 30 - iter 204/516 - loss 0.05542964 - samples/sec: 133.42 - lr: 0.000015
2021-07-23 16:05:01,120 epoch 30 - iter 255/516 - loss 0.05441632 - samples/sec: 136.76 - lr: 0.000015
2021-07-23 16:05:13,184 epoch 30 - iter 306/516 - loss 0.05317954 - samples/sec: 135.31 - lr: 0.000015
2021-07-23 16:05:25,699 epoch 30 - iter 357/516 - loss 0.05314529 - samples/sec: 130.43 - lr: 0.000015
2021-07-23 16:05:37,781 epoch 30 - iter 408/516 - loss 0.05405313 - samples/sec: 135.11 - lr: 0.000015
2021-07-23 16:05:49,700 epoch 30 - iter 459/516 - loss 0.05302383 - samples/sec: 136.95 - lr: 0.000015
2021-07-23 16:06:01,851 epoch 30 - iter 510/516 - loss 0.05238432 - samples/sec: 134.34 - lr: 0.000015
2021-07-23 16:06:03,214 ----------------------------------------------------------------------------------------------------
2021-07-23 16:06:03,214 EPOCH 30 done: loss 0.0523 - lr 0.0000150
2021-07-23 16:06:08,839 DEV : loss 0.043163228780031204 - score 0.9892
2021-07-23 16:06:08,904 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:06:11,063 ----------------------------------------------------------------------------------------------------
2021-07-23 16:06:23,298 epoch 31 - iter 51/516 - loss 0.04250810 - samples/sec: 133.44 - lr: 0.000015
2021-07-23 16:06:35,308 epoch 31 - iter 102/516 - loss 0.04838061 - samples/sec: 135.92 - lr: 0.000015
2021-07-23 16:06:47,600 epoch 31 - iter 153/516 - loss 0.05099925 - samples/sec: 132.80 - lr: 0.000015
2021-07-23 16:06:59,618 epoch 31 - iter 204/516 - loss 0.04933549 - samples/sec: 135.82 - lr: 0.000015
2021-07-23 16:07:11,888 epoch 31 - iter 255/516 - loss 0.04760527 - samples/sec: 133.04 - lr: 0.000015
2021-07-23 16:07:23,864 epoch 31 - iter 306/516 - loss 0.04799728 - samples/sec: 136.31 - lr: 0.000015
2021-07-23 16:07:36,007 epoch 31 - iter 357/516 - loss 0.04952407 - samples/sec: 134.43 - lr: 0.000015
2021-07-23 16:07:48,270 epoch 31 - iter 408/516 - loss 0.04965192 - samples/sec: 133.12 - lr: 0.000015
2021-07-23 16:08:00,499 epoch 31 - iter 459/516 - loss 0.04944610 - samples/sec: 133.48 - lr: 0.000015
2021-07-23 16:08:12,635 epoch 31 - iter 510/516 - loss 0.04944830 - samples/sec: 134.50 - lr: 0.000015
2021-07-23 16:08:13,952 ----------------------------------------------------------------------------------------------------
2021-07-23 16:08:13,952 EPOCH 31 done: loss 0.0494 - lr 0.0000150
2021-07-23 16:08:19,568 DEV : loss 0.04186871647834778 - score 0.9875
2021-07-23 16:08:19,634 BAD EPOCHS (no improvement): 1
2021-07-23 16:08:19,635 ----------------------------------------------------------------------------------------------------
2021-07-23 16:08:31,628 epoch 32 - iter 51/516 - loss 0.04543221 - samples/sec: 136.12 - lr: 0.000015
2021-07-23 16:08:43,481 epoch 32 - iter 102/516 - loss 0.04599106 - samples/sec: 137.72 - lr: 0.000015
2021-07-23 16:08:55,516 epoch 32 - iter 153/516 - loss 0.04685341 - samples/sec: 135.63 - lr: 0.000015
2021-07-23 16:09:07,556 epoch 32 - iter 204/516 - loss 0.04677684 - samples/sec: 135.58 - lr: 0.000015
2021-07-23 16:09:19,751 epoch 32 - iter 255/516 - loss 0.04939173 - samples/sec: 133.85 - lr: 0.000015
2021-07-23 16:09:32,135 epoch 32 - iter 306/516 - loss 0.04980569 - samples/sec: 131.81 - lr: 0.000015
2021-07-23 16:09:44,595 epoch 32 - iter 357/516 - loss 0.04884130 - samples/sec: 131.01 - lr: 0.000015
2021-07-23 16:09:56,952 epoch 32 - iter 408/516 - loss 0.05053114 - samples/sec: 132.10 - lr: 0.000015
2021-07-23 16:10:09,041 epoch 32 - iter 459/516 - loss 0.04953532 - samples/sec: 135.03 - lr: 0.000015
2021-07-23 16:10:21,263 epoch 32 - iter 510/516 - loss 0.04977538 - samples/sec: 133.56 - lr: 0.000015
2021-07-23 16:10:22,603 ----------------------------------------------------------------------------------------------------
2021-07-23 16:10:22,604 EPOCH 32 done: loss 0.0497 - lr 0.0000150
2021-07-23 16:10:28,217 DEV : loss 0.04135432094335556 - score 0.9901
2021-07-23 16:10:28,281 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:10:30,553 ----------------------------------------------------------------------------------------------------
2021-07-23 16:10:42,781 epoch 33 - iter 51/516 - loss 0.06184327 - samples/sec: 133.52 - lr: 0.000015
2021-07-23 16:10:55,214 epoch 33 - iter 102/516 - loss 0.05439019 - samples/sec: 131.28 - lr: 0.000015
2021-07-23 16:11:07,476 epoch 33 - iter 153/516 - loss 0.05019259 - samples/sec: 133.13 - lr: 0.000015
2021-07-23 16:11:19,519 epoch 33 - iter 204/516 - loss 0.05024560 - samples/sec: 135.54 - lr: 0.000015
2021-07-23 16:11:31,782 epoch 33 - iter 255/516 - loss 0.05088711 - samples/sec: 133.11 - lr: 0.000015
2021-07-23 16:11:44,175 epoch 33 - iter 306/516 - loss 0.05102216 - samples/sec: 131.71 - lr: 0.000015
2021-07-23 16:11:56,153 epoch 33 - iter 357/516 - loss 0.05018559 - samples/sec: 136.28 - lr: 0.000015
2021-07-23 16:12:08,475 epoch 33 - iter 408/516 - loss 0.05022570 - samples/sec: 132.47 - lr: 0.000015
2021-07-23 16:12:20,620 epoch 33 - iter 459/516 - loss 0.04912609 - samples/sec: 134.41 - lr: 0.000015
2021-07-23 16:12:32,638 epoch 33 - iter 510/516 - loss 0.04858649 - samples/sec: 135.83 - lr: 0.000015
2021-07-23 16:12:33,883 ----------------------------------------------------------------------------------------------------
2021-07-23 16:12:33,884 EPOCH 33 done: loss 0.0484 - lr 0.0000150
2021-07-23 16:12:39,509 DEV : loss 0.04159414395689964 - score 0.9878
2021-07-23 16:12:39,574 BAD EPOCHS (no improvement): 1
2021-07-23 16:12:39,574 ----------------------------------------------------------------------------------------------------
2021-07-23 16:12:51,991 epoch 34 - iter 51/516 - loss 0.05349052 - samples/sec: 131.48 - lr: 0.000015
2021-07-23 16:13:04,215 epoch 34 - iter 102/516 - loss 0.05274655 - samples/sec: 133.53 - lr: 0.000015
2021-07-23 16:13:16,164 epoch 34 - iter 153/516 - loss 0.04781510 - samples/sec: 136.62 - lr: 0.000015
2021-07-23 16:13:28,016 epoch 34 - iter 204/516 - loss 0.04726619 - samples/sec: 137.72 - lr: 0.000015
2021-07-23 16:13:40,083 epoch 34 - iter 255/516 - loss 0.04525325 - samples/sec: 135.28 - lr: 0.000015
2021-07-23 16:13:52,220 epoch 34 - iter 306/516 - loss 0.04711715 - samples/sec: 134.49 - lr: 0.000015
2021-07-23 16:14:04,529 epoch 34 - iter 357/516 - loss 0.04642530 - samples/sec: 132.62 - lr: 0.000015
2021-07-23 16:14:16,883 epoch 34 - iter 408/516 - loss 0.04623304 - samples/sec: 132.13 - lr: 0.000015
2021-07-23 16:14:29,664 epoch 34 - iter 459/516 - loss 0.04674134 - samples/sec: 127.71 - lr: 0.000015
2021-07-23 16:14:41,842 epoch 34 - iter 510/516 - loss 0.04780180 - samples/sec: 134.05 - lr: 0.000015
2021-07-23 16:14:43,230 ----------------------------------------------------------------------------------------------------
2021-07-23 16:14:43,231 EPOCH 34 done: loss 0.0480 - lr 0.0000150
2021-07-23 16:14:48,852 DEV : loss 0.04294849559664726 - score 0.9872
2021-07-23 16:14:48,917 BAD EPOCHS (no improvement): 2
2021-07-23 16:14:48,917 ----------------------------------------------------------------------------------------------------
2021-07-23 16:15:01,108 epoch 35 - iter 51/516 - loss 0.04282494 - samples/sec: 133.92 - lr: 0.000015
2021-07-23 16:15:13,319 epoch 35 - iter 102/516 - loss 0.04641616 - samples/sec: 133.68 - lr: 0.000015
2021-07-23 16:15:25,709 epoch 35 - iter 153/516 - loss 0.04912326 - samples/sec: 131.75 - lr: 0.000015
2021-07-23 16:15:37,917 epoch 35 - iter 204/516 - loss 0.05003016 - samples/sec: 133.71 - lr: 0.000015
2021-07-23 16:15:50,141 epoch 35 - iter 255/516 - loss 0.05001238 - samples/sec: 133.53 - lr: 0.000015
2021-07-23 16:16:02,546 epoch 35 - iter 306/516 - loss 0.05000462 - samples/sec: 131.59 - lr: 0.000015
2021-07-23 16:16:14,423 epoch 35 - iter 357/516 - loss 0.04811144 - samples/sec: 137.44 - lr: 0.000015
2021-07-23 16:16:26,380 epoch 35 - iter 408/516 - loss 0.04780829 - samples/sec: 136.52 - lr: 0.000015
2021-07-23 16:16:38,553 epoch 35 - iter 459/516 - loss 0.04737907 - samples/sec: 134.09 - lr: 0.000015
2021-07-23 16:16:50,588 epoch 35 - iter 510/516 - loss 0.04676057 - samples/sec: 135.63 - lr: 0.000015
2021-07-23 16:16:51,951 ----------------------------------------------------------------------------------------------------
2021-07-23 16:16:51,951 EPOCH 35 done: loss 0.0466 - lr 0.0000150
2021-07-23 16:16:57,566 DEV : loss 0.041593216359615326 - score 0.9869
2021-07-23 16:16:57,630 BAD EPOCHS (no improvement): 3
2021-07-23 16:16:57,630 ----------------------------------------------------------------------------------------------------
2021-07-23 16:17:09,570 epoch 36 - iter 51/516 - loss 0.03207929 - samples/sec: 136.73 - lr: 0.000015
2021-07-23 16:17:21,717 epoch 36 - iter 102/516 - loss 0.03630645 - samples/sec: 134.38 - lr: 0.000015
2021-07-23 16:17:33,484 epoch 36 - iter 153/516 - loss 0.03641937 - samples/sec: 138.72 - lr: 0.000015
2021-07-23 16:17:45,651 epoch 36 - iter 204/516 - loss 0.03743876 - samples/sec: 134.17 - lr: 0.000015
2021-07-23 16:17:57,803 epoch 36 - iter 255/516 - loss 0.03820994 - samples/sec: 134.33 - lr: 0.000015
2021-07-23 16:18:10,016 epoch 36 - iter 306/516 - loss 0.03878266 - samples/sec: 133.66 - lr: 0.000015
2021-07-23 16:18:22,251 epoch 36 - iter 357/516 - loss 0.04062397 - samples/sec: 133.41 - lr: 0.000015
2021-07-23 16:18:34,567 epoch 36 - iter 408/516 - loss 0.04123457 - samples/sec: 132.54 - lr: 0.000015
2021-07-23 16:18:46,923 epoch 36 - iter 459/516 - loss 0.04047527 - samples/sec: 132.11 - lr: 0.000015
2021-07-23 16:18:59,604 epoch 36 - iter 510/516 - loss 0.04176588 - samples/sec: 128.72 - lr: 0.000015
2021-07-23 16:19:00,971 ----------------------------------------------------------------------------------------------------
2021-07-23 16:19:00,971 EPOCH 36 done: loss 0.0416 - lr 0.0000150
2021-07-23 16:19:06,596 DEV : loss 0.04237672686576843 - score 0.9859
Epoch    36: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 16:19:06,660 BAD EPOCHS (no improvement): 4
2021-07-23 16:19:06,660 ----------------------------------------------------------------------------------------------------
2021-07-23 16:19:18,895 epoch 37 - iter 51/516 - loss 0.05521735 - samples/sec: 133.44 - lr: 0.000008
2021-07-23 16:19:31,182 epoch 37 - iter 102/516 - loss 0.04632496 - samples/sec: 132.85 - lr: 0.000008
2021-07-23 16:19:43,640 epoch 37 - iter 153/516 - loss 0.04722741 - samples/sec: 131.03 - lr: 0.000008
2021-07-23 16:19:55,600 epoch 37 - iter 204/516 - loss 0.04681273 - samples/sec: 136.49 - lr: 0.000008
2021-07-23 16:20:07,966 epoch 37 - iter 255/516 - loss 0.04523776 - samples/sec: 131.99 - lr: 0.000008
2021-07-23 16:20:20,172 epoch 37 - iter 306/516 - loss 0.04549930 - samples/sec: 133.74 - lr: 0.000008
2021-07-23 16:20:32,230 epoch 37 - iter 357/516 - loss 0.04676408 - samples/sec: 135.37 - lr: 0.000008
2021-07-23 16:20:44,280 epoch 37 - iter 408/516 - loss 0.04648474 - samples/sec: 135.46 - lr: 0.000008
2021-07-23 16:20:56,416 epoch 37 - iter 459/516 - loss 0.04608084 - samples/sec: 134.50 - lr: 0.000008
2021-07-23 16:21:08,664 epoch 37 - iter 510/516 - loss 0.04550422 - samples/sec: 133.28 - lr: 0.000008
2021-07-23 16:21:10,066 ----------------------------------------------------------------------------------------------------
2021-07-23 16:21:10,067 EPOCH 37 done: loss 0.0456 - lr 0.0000075
2021-07-23 16:21:15,690 DEV : loss 0.043464623391628265 - score 0.9882
2021-07-23 16:21:15,755 BAD EPOCHS (no improvement): 1
2021-07-23 16:21:15,756 ----------------------------------------------------------------------------------------------------
2021-07-23 16:21:28,035 epoch 38 - iter 51/516 - loss 0.04656340 - samples/sec: 132.95 - lr: 0.000008
2021-07-23 16:21:40,199 epoch 38 - iter 102/516 - loss 0.04747491 - samples/sec: 134.20 - lr: 0.000008
2021-07-23 16:21:52,388 epoch 38 - iter 153/516 - loss 0.04553679 - samples/sec: 133.92 - lr: 0.000008
2021-07-23 16:22:04,659 epoch 38 - iter 204/516 - loss 0.04576938 - samples/sec: 133.02 - lr: 0.000008
2021-07-23 16:22:16,792 epoch 38 - iter 255/516 - loss 0.04754177 - samples/sec: 134.54 - lr: 0.000008
2021-07-23 16:22:28,852 epoch 38 - iter 306/516 - loss 0.04715295 - samples/sec: 135.35 - lr: 0.000008
2021-07-23 16:22:41,060 epoch 38 - iter 357/516 - loss 0.04745607 - samples/sec: 133.71 - lr: 0.000008
2021-07-23 16:22:53,161 epoch 38 - iter 408/516 - loss 0.04688121 - samples/sec: 134.90 - lr: 0.000008
2021-07-23 16:23:05,375 epoch 38 - iter 459/516 - loss 0.04679526 - samples/sec: 133.64 - lr: 0.000008
2021-07-23 16:23:17,406 epoch 38 - iter 510/516 - loss 0.04595660 - samples/sec: 135.68 - lr: 0.000008
2021-07-23 16:23:18,736 ----------------------------------------------------------------------------------------------------
2021-07-23 16:23:18,736 EPOCH 38 done: loss 0.0457 - lr 0.0000075
2021-07-23 16:23:24,376 DEV : loss 0.04133285582065582 - score 0.9885
2021-07-23 16:23:24,440 BAD EPOCHS (no improvement): 2
2021-07-23 16:23:24,441 ----------------------------------------------------------------------------------------------------
2021-07-23 16:23:37,459 epoch 39 - iter 51/516 - loss 0.05117076 - samples/sec: 125.40 - lr: 0.000008
2021-07-23 16:23:49,437 epoch 39 - iter 102/516 - loss 0.04422211 - samples/sec: 136.29 - lr: 0.000008
2021-07-23 16:24:01,444 epoch 39 - iter 153/516 - loss 0.04100241 - samples/sec: 135.95 - lr: 0.000008
2021-07-23 16:24:13,265 epoch 39 - iter 204/516 - loss 0.04171424 - samples/sec: 138.09 - lr: 0.000008
2021-07-23 16:24:25,475 epoch 39 - iter 255/516 - loss 0.04389486 - samples/sec: 133.69 - lr: 0.000008
2021-07-23 16:24:37,425 epoch 39 - iter 306/516 - loss 0.04542077 - samples/sec: 136.60 - lr: 0.000008
2021-07-23 16:24:49,583 epoch 39 - iter 357/516 - loss 0.04418081 - samples/sec: 134.25 - lr: 0.000008
2021-07-23 16:25:01,807 epoch 39 - iter 408/516 - loss 0.04460011 - samples/sec: 133.54 - lr: 0.000008
2021-07-23 16:25:14,096 epoch 39 - iter 459/516 - loss 0.04533096 - samples/sec: 132.83 - lr: 0.000008
2021-07-23 16:25:26,303 epoch 39 - iter 510/516 - loss 0.04462633 - samples/sec: 133.73 - lr: 0.000008
2021-07-23 16:25:27,648 ----------------------------------------------------------------------------------------------------
2021-07-23 16:25:27,648 EPOCH 39 done: loss 0.0446 - lr 0.0000075
2021-07-23 16:25:33,269 DEV : loss 0.04146546125411987 - score 0.9875
2021-07-23 16:25:33,335 BAD EPOCHS (no improvement): 3
2021-07-23 16:25:33,335 ----------------------------------------------------------------------------------------------------
2021-07-23 16:25:45,315 epoch 40 - iter 51/516 - loss 0.03721338 - samples/sec: 136.28 - lr: 0.000008
2021-07-23 16:25:57,436 epoch 40 - iter 102/516 - loss 0.04098321 - samples/sec: 134.67 - lr: 0.000008
2021-07-23 16:26:09,694 epoch 40 - iter 153/516 - loss 0.04076763 - samples/sec: 133.16 - lr: 0.000008
2021-07-23 16:26:21,714 epoch 40 - iter 204/516 - loss 0.04248085 - samples/sec: 135.80 - lr: 0.000008
2021-07-23 16:26:33,761 epoch 40 - iter 255/516 - loss 0.04320998 - samples/sec: 135.50 - lr: 0.000008
2021-07-23 16:26:45,934 epoch 40 - iter 306/516 - loss 0.04391874 - samples/sec: 134.09 - lr: 0.000008
2021-07-23 16:26:58,449 epoch 40 - iter 357/516 - loss 0.04333603 - samples/sec: 130.43 - lr: 0.000008
2021-07-23 16:27:10,699 epoch 40 - iter 408/516 - loss 0.04445239 - samples/sec: 133.24 - lr: 0.000008
2021-07-23 16:27:22,860 epoch 40 - iter 459/516 - loss 0.04411648 - samples/sec: 134.23 - lr: 0.000008
2021-07-23 16:27:35,016 epoch 40 - iter 510/516 - loss 0.04481429 - samples/sec: 134.28 - lr: 0.000008
2021-07-23 16:27:36,304 ----------------------------------------------------------------------------------------------------
2021-07-23 16:27:36,304 EPOCH 40 done: loss 0.0446 - lr 0.0000075
2021-07-23 16:27:41,954 DEV : loss 0.04308471083641052 - score 0.9863
Epoch    40: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 16:27:42,018 BAD EPOCHS (no improvement): 4
2021-07-23 16:27:42,602 ----------------------------------------------------------------------------------------------------
2021-07-23 16:27:42,603 Testing using best model ...
2021-07-23 16:27:42,604 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.rstdt/best-model.pt
2021-07-23 16:28:57,695 0.9888	0.9901	0.9895
2021-07-23 16:28:57,696 
Results:
- F1-score (micro) 0.9895
- F1-score (macro) 0.9885

By class:
SENT       tp: 1723 - fp: 43 - fn: 38 - precision: 0.9757 - recall: 0.9784 - f1-score: 0.9770
X          tp: 2088 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 16:28:57,696 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/tur.pdtb.tdb/
2021-07-23 16:28:57,718 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/tur.pdtb.tdb
2021-07-23 16:28:57,720 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/tur.pdtb.tdb/sent_train.txt
2021-07-23 16:28:57,722 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/tur.pdtb.tdb/sent_dev.txt
2021-07-23 16:28:57,723 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/tur.pdtb.tdb/sent_test.txt
Corpus: 47360 train + 7479 dev + 13614 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 16:29:09,445 ----------------------------------------------------------------------------------------------------
2021-07-23 16:29:09,447 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(32000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 16:29:09,447 ----------------------------------------------------------------------------------------------------
2021-07-23 16:29:09,447 Corpus: "Corpus: 47360 train + 7479 dev + 13614 test sentences"
2021-07-23 16:29:09,447 ----------------------------------------------------------------------------------------------------
2021-07-23 16:29:09,447 Parameters:
2021-07-23 16:29:09,447  - learning_rate: "3e-05"
2021-07-23 16:29:09,447  - mini_batch_size: "32"
2021-07-23 16:29:09,447  - patience: "3"
2021-07-23 16:29:09,447  - anneal_factor: "0.5"
2021-07-23 16:29:09,447  - max_epochs: "40"
2021-07-23 16:29:09,447  - shuffle: "True"
2021-07-23 16:29:09,447  - train_with_dev: "False"
2021-07-23 16:29:09,447  - batch_growth_annealing: "False"
2021-07-23 16:29:09,447 ----------------------------------------------------------------------------------------------------
2021-07-23 16:29:09,447 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/tur.pdtb.tdb"
2021-07-23 16:29:09,447 ----------------------------------------------------------------------------------------------------
2021-07-23 16:29:09,448 Device: cuda:0
2021-07-23 16:29:09,448 ----------------------------------------------------------------------------------------------------
2021-07-23 16:29:09,448 Embeddings storage mode: cpu
2021-07-23 16:29:09,450 ----------------------------------------------------------------------------------------------------
2021-07-23 16:30:30,055 epoch 1 - iter 148/1480 - loss 4.79211432 - samples/sec: 58.76 - lr: 0.000030
2021-07-23 16:31:53,767 epoch 1 - iter 296/1480 - loss 2.80054363 - samples/sec: 56.58 - lr: 0.000030
2021-07-23 16:33:24,344 epoch 1 - iter 444/1480 - loss 2.01600474 - samples/sec: 52.29 - lr: 0.000030
2021-07-23 16:34:50,997 epoch 1 - iter 592/1480 - loss 1.57889821 - samples/sec: 54.66 - lr: 0.000030
2021-07-23 16:36:18,498 epoch 1 - iter 740/1480 - loss 1.31097446 - samples/sec: 54.13 - lr: 0.000030
2021-07-23 16:37:42,565 epoch 1 - iter 888/1480 - loss 1.12276921 - samples/sec: 56.34 - lr: 0.000030
2021-07-23 16:39:06,580 epoch 1 - iter 1036/1480 - loss 0.99789795 - samples/sec: 56.38 - lr: 0.000030
2021-07-23 16:40:30,903 epoch 1 - iter 1184/1480 - loss 0.90601643 - samples/sec: 56.17 - lr: 0.000030
2021-07-23 16:41:55,915 epoch 1 - iter 1332/1480 - loss 0.83263529 - samples/sec: 55.71 - lr: 0.000030
2021-07-23 16:43:20,320 epoch 1 - iter 1480/1480 - loss 0.77367469 - samples/sec: 56.11 - lr: 0.000030
2021-07-23 16:43:20,321 ----------------------------------------------------------------------------------------------------
2021-07-23 16:43:20,321 EPOCH 1 done: loss 0.7737 - lr 0.0000300
2021-07-23 16:44:57,678 DEV : loss 0.1704966127872467 - score 0.959
2021-07-23 16:44:57,862 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:44:58,455 ----------------------------------------------------------------------------------------------------
2021-07-23 16:45:31,300 epoch 2 - iter 148/1480 - loss 0.21496940 - samples/sec: 144.24 - lr: 0.000030
2021-07-23 16:46:03,857 epoch 2 - iter 296/1480 - loss 0.21680767 - samples/sec: 145.50 - lr: 0.000030
2021-07-23 16:46:36,735 epoch 2 - iter 444/1480 - loss 0.21675677 - samples/sec: 144.08 - lr: 0.000030
2021-07-23 16:47:09,803 epoch 2 - iter 592/1480 - loss 0.21459360 - samples/sec: 143.25 - lr: 0.000030
2021-07-23 16:47:42,555 epoch 2 - iter 740/1480 - loss 0.21316335 - samples/sec: 144.63 - lr: 0.000030
2021-07-23 16:48:15,482 epoch 2 - iter 888/1480 - loss 0.21145668 - samples/sec: 143.87 - lr: 0.000030
2021-07-23 16:48:48,634 epoch 2 - iter 1036/1480 - loss 0.21018125 - samples/sec: 142.89 - lr: 0.000030
2021-07-23 16:49:21,824 epoch 2 - iter 1184/1480 - loss 0.20724044 - samples/sec: 142.72 - lr: 0.000030
2021-07-23 16:49:55,190 epoch 2 - iter 1332/1480 - loss 0.20513661 - samples/sec: 141.97 - lr: 0.000030
2021-07-23 16:50:28,179 epoch 2 - iter 1480/1480 - loss 0.20418441 - samples/sec: 143.60 - lr: 0.000030
2021-07-23 16:50:28,180 ----------------------------------------------------------------------------------------------------
2021-07-23 16:50:28,180 EPOCH 2 done: loss 0.2042 - lr 0.0000300
2021-07-23 16:50:45,272 DEV : loss 0.15783092379570007 - score 0.9624
2021-07-23 16:50:45,453 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:50:47,745 ----------------------------------------------------------------------------------------------------
2021-07-23 16:51:20,991 epoch 3 - iter 148/1480 - loss 0.19134956 - samples/sec: 142.51 - lr: 0.000030
2021-07-23 16:51:54,290 epoch 3 - iter 296/1480 - loss 0.19872138 - samples/sec: 142.26 - lr: 0.000030
2021-07-23 16:52:27,196 epoch 3 - iter 444/1480 - loss 0.19897150 - samples/sec: 143.96 - lr: 0.000030
2021-07-23 16:53:00,604 epoch 3 - iter 592/1480 - loss 0.20104310 - samples/sec: 141.79 - lr: 0.000030
2021-07-23 16:53:33,518 epoch 3 - iter 740/1480 - loss 0.19665031 - samples/sec: 143.92 - lr: 0.000030
2021-07-23 16:54:06,639 epoch 3 - iter 888/1480 - loss 0.19182397 - samples/sec: 143.02 - lr: 0.000030
2021-07-23 16:54:39,920 epoch 3 - iter 1036/1480 - loss 0.19140972 - samples/sec: 142.34 - lr: 0.000030
2021-07-23 16:55:12,762 epoch 3 - iter 1184/1480 - loss 0.19008705 - samples/sec: 144.23 - lr: 0.000030
2021-07-23 16:55:46,042 epoch 3 - iter 1332/1480 - loss 0.18868405 - samples/sec: 142.34 - lr: 0.000030
2021-07-23 16:56:18,958 epoch 3 - iter 1480/1480 - loss 0.18904003 - samples/sec: 143.92 - lr: 0.000030
2021-07-23 16:56:18,960 ----------------------------------------------------------------------------------------------------
2021-07-23 16:56:18,960 EPOCH 3 done: loss 0.1890 - lr 0.0000300
2021-07-23 16:56:36,048 DEV : loss 0.14709046483039856 - score 0.963
2021-07-23 16:56:36,232 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:56:38,428 ----------------------------------------------------------------------------------------------------
2021-07-23 16:57:12,004 epoch 4 - iter 148/1480 - loss 0.17126143 - samples/sec: 141.10 - lr: 0.000030
2021-07-23 16:57:45,640 epoch 4 - iter 296/1480 - loss 0.17127146 - samples/sec: 140.83 - lr: 0.000030
2021-07-23 16:58:19,407 epoch 4 - iter 444/1480 - loss 0.16988201 - samples/sec: 140.29 - lr: 0.000030
2021-07-23 16:58:52,579 epoch 4 - iter 592/1480 - loss 0.17132856 - samples/sec: 142.80 - lr: 0.000030
2021-07-23 16:59:26,214 epoch 4 - iter 740/1480 - loss 0.17147827 - samples/sec: 140.83 - lr: 0.000030
2021-07-23 16:59:59,076 epoch 4 - iter 888/1480 - loss 0.16993022 - samples/sec: 144.15 - lr: 0.000030
2021-07-23 17:00:32,782 epoch 4 - iter 1036/1480 - loss 0.16760325 - samples/sec: 140.54 - lr: 0.000030
2021-07-23 17:01:06,188 epoch 4 - iter 1184/1480 - loss 0.16693211 - samples/sec: 141.80 - lr: 0.000030
2021-07-23 17:01:39,395 epoch 4 - iter 1332/1480 - loss 0.16543449 - samples/sec: 142.65 - lr: 0.000030
2021-07-23 17:02:12,384 epoch 4 - iter 1480/1480 - loss 0.16436830 - samples/sec: 143.60 - lr: 0.000030
2021-07-23 17:02:12,386 ----------------------------------------------------------------------------------------------------
2021-07-23 17:02:12,386 EPOCH 4 done: loss 0.1644 - lr 0.0000300
2021-07-23 17:02:31,078 DEV : loss 0.13976411521434784 - score 0.963
2021-07-23 17:02:31,260 BAD EPOCHS (no improvement): 1
2021-07-23 17:02:31,261 ----------------------------------------------------------------------------------------------------
2021-07-23 17:03:04,818 epoch 5 - iter 148/1480 - loss 0.15450479 - samples/sec: 141.17 - lr: 0.000030
2021-07-23 17:03:38,307 epoch 5 - iter 296/1480 - loss 0.14628883 - samples/sec: 141.45 - lr: 0.000030
2021-07-23 17:04:11,947 epoch 5 - iter 444/1480 - loss 0.14449937 - samples/sec: 140.81 - lr: 0.000030
2021-07-23 17:04:44,999 epoch 5 - iter 592/1480 - loss 0.14184341 - samples/sec: 143.32 - lr: 0.000030
2021-07-23 17:05:18,616 epoch 5 - iter 740/1480 - loss 0.14192809 - samples/sec: 140.91 - lr: 0.000030
2021-07-23 17:05:51,759 epoch 5 - iter 888/1480 - loss 0.14393792 - samples/sec: 142.93 - lr: 0.000030
2021-07-23 17:06:25,625 epoch 5 - iter 1036/1480 - loss 0.14328986 - samples/sec: 139.88 - lr: 0.000030
2021-07-23 17:06:59,026 epoch 5 - iter 1184/1480 - loss 0.14137857 - samples/sec: 141.82 - lr: 0.000030
2021-07-23 17:07:32,659 epoch 5 - iter 1332/1480 - loss 0.14173889 - samples/sec: 140.84 - lr: 0.000030
2021-07-23 17:08:06,015 epoch 5 - iter 1480/1480 - loss 0.14093921 - samples/sec: 142.02 - lr: 0.000030
2021-07-23 17:08:06,016 ----------------------------------------------------------------------------------------------------
2021-07-23 17:08:06,016 EPOCH 5 done: loss 0.1409 - lr 0.0000300
2021-07-23 17:08:23,404 DEV : loss 0.14106912910938263 - score 0.9636
2021-07-23 17:08:23,587 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:08:25,977 ----------------------------------------------------------------------------------------------------
2021-07-23 17:08:59,408 epoch 6 - iter 148/1480 - loss 0.12710896 - samples/sec: 141.72 - lr: 0.000030
2021-07-23 17:09:33,135 epoch 6 - iter 296/1480 - loss 0.12918217 - samples/sec: 140.45 - lr: 0.000030
2021-07-23 17:10:06,364 epoch 6 - iter 444/1480 - loss 0.13123116 - samples/sec: 142.56 - lr: 0.000030
2021-07-23 17:10:40,013 epoch 6 - iter 592/1480 - loss 0.13241086 - samples/sec: 140.78 - lr: 0.000030
2021-07-23 17:11:13,246 epoch 6 - iter 740/1480 - loss 0.13148221 - samples/sec: 142.54 - lr: 0.000030
2021-07-23 17:11:46,855 epoch 6 - iter 888/1480 - loss 0.13125308 - samples/sec: 140.94 - lr: 0.000030
2021-07-23 17:12:20,120 epoch 6 - iter 1036/1480 - loss 0.13095336 - samples/sec: 142.40 - lr: 0.000030
2021-07-23 17:12:53,996 epoch 6 - iter 1184/1480 - loss 0.12901453 - samples/sec: 139.84 - lr: 0.000030
2021-07-23 17:13:27,679 epoch 6 - iter 1332/1480 - loss 0.12948322 - samples/sec: 140.63 - lr: 0.000030
2021-07-23 17:14:00,764 epoch 6 - iter 1480/1480 - loss 0.12936325 - samples/sec: 143.18 - lr: 0.000030
2021-07-23 17:14:00,765 ----------------------------------------------------------------------------------------------------
2021-07-23 17:14:00,765 EPOCH 6 done: loss 0.1294 - lr 0.0000300
2021-07-23 17:14:18,140 DEV : loss 0.1398933231830597 - score 0.9647
2021-07-23 17:14:18,322 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:14:20,574 ----------------------------------------------------------------------------------------------------
2021-07-23 17:14:53,698 epoch 7 - iter 148/1480 - loss 0.12861367 - samples/sec: 143.04 - lr: 0.000030
2021-07-23 17:15:27,183 epoch 7 - iter 296/1480 - loss 0.12482455 - samples/sec: 141.47 - lr: 0.000030
2021-07-23 17:16:00,627 epoch 7 - iter 444/1480 - loss 0.12601893 - samples/sec: 141.64 - lr: 0.000030
2021-07-23 17:16:34,022 epoch 7 - iter 592/1480 - loss 0.12468633 - samples/sec: 141.85 - lr: 0.000030
2021-07-23 17:17:07,331 epoch 7 - iter 740/1480 - loss 0.12452295 - samples/sec: 142.21 - lr: 0.000030
2021-07-23 17:17:40,292 epoch 7 - iter 888/1480 - loss 0.12545330 - samples/sec: 143.72 - lr: 0.000030
2021-07-23 17:18:13,855 epoch 7 - iter 1036/1480 - loss 0.12657725 - samples/sec: 141.14 - lr: 0.000030
2021-07-23 17:18:47,404 epoch 7 - iter 1184/1480 - loss 0.12553432 - samples/sec: 141.20 - lr: 0.000030
2021-07-23 17:19:20,674 epoch 7 - iter 1332/1480 - loss 0.12426928 - samples/sec: 142.38 - lr: 0.000030
2021-07-23 17:19:53,979 epoch 7 - iter 1480/1480 - loss 0.12436336 - samples/sec: 142.23 - lr: 0.000030
2021-07-23 17:19:53,981 ----------------------------------------------------------------------------------------------------
2021-07-23 17:19:53,981 EPOCH 7 done: loss 0.1244 - lr 0.0000300
2021-07-23 17:20:11,333 DEV : loss 0.13600526750087738 - score 0.9661
2021-07-23 17:20:11,516 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:20:13,840 ----------------------------------------------------------------------------------------------------
2021-07-23 17:20:47,519 epoch 8 - iter 148/1480 - loss 0.12089827 - samples/sec: 140.67 - lr: 0.000030
2021-07-23 17:21:21,072 epoch 8 - iter 296/1480 - loss 0.11758334 - samples/sec: 141.18 - lr: 0.000030
2021-07-23 17:21:54,438 epoch 8 - iter 444/1480 - loss 0.12184821 - samples/sec: 141.97 - lr: 0.000030
2021-07-23 17:22:27,936 epoch 8 - iter 592/1480 - loss 0.12188444 - samples/sec: 141.41 - lr: 0.000030
2021-07-23 17:23:01,251 epoch 8 - iter 740/1480 - loss 0.12298581 - samples/sec: 142.19 - lr: 0.000030
2021-07-23 17:23:34,558 epoch 8 - iter 888/1480 - loss 0.12357214 - samples/sec: 142.22 - lr: 0.000030
2021-07-23 17:24:07,847 epoch 8 - iter 1036/1480 - loss 0.12199908 - samples/sec: 142.30 - lr: 0.000030
2021-07-23 17:24:41,130 epoch 8 - iter 1184/1480 - loss 0.12121083 - samples/sec: 142.32 - lr: 0.000030
2021-07-23 17:25:14,448 epoch 8 - iter 1332/1480 - loss 0.12069545 - samples/sec: 142.18 - lr: 0.000030
2021-07-23 17:25:47,807 epoch 8 - iter 1480/1480 - loss 0.12016670 - samples/sec: 142.00 - lr: 0.000030
2021-07-23 17:25:47,808 ----------------------------------------------------------------------------------------------------
2021-07-23 17:25:47,808 EPOCH 8 done: loss 0.1202 - lr 0.0000300
2021-07-23 17:26:05,079 DEV : loss 0.13338522613048553 - score 0.9669
2021-07-23 17:26:05,267 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:26:07,550 ----------------------------------------------------------------------------------------------------
2021-07-23 17:26:40,492 epoch 9 - iter 148/1480 - loss 0.10215417 - samples/sec: 143.82 - lr: 0.000030
2021-07-23 17:27:15,336 epoch 9 - iter 296/1480 - loss 0.10769441 - samples/sec: 135.95 - lr: 0.000030
2021-07-23 17:27:48,820 epoch 9 - iter 444/1480 - loss 0.10601513 - samples/sec: 141.47 - lr: 0.000030
2021-07-23 17:28:21,832 epoch 9 - iter 592/1480 - loss 0.11001257 - samples/sec: 143.50 - lr: 0.000030
2021-07-23 17:28:55,171 epoch 9 - iter 740/1480 - loss 0.11147999 - samples/sec: 142.08 - lr: 0.000030
2021-07-23 17:29:28,895 epoch 9 - iter 888/1480 - loss 0.11155084 - samples/sec: 140.46 - lr: 0.000030
2021-07-23 17:30:02,632 epoch 9 - iter 1036/1480 - loss 0.11400102 - samples/sec: 140.41 - lr: 0.000030
2021-07-23 17:30:36,251 epoch 9 - iter 1184/1480 - loss 0.11400417 - samples/sec: 140.90 - lr: 0.000030
2021-07-23 17:31:09,939 epoch 9 - iter 1332/1480 - loss 0.11584564 - samples/sec: 140.61 - lr: 0.000030
2021-07-23 17:31:43,231 epoch 9 - iter 1480/1480 - loss 0.11633761 - samples/sec: 142.29 - lr: 0.000030
2021-07-23 17:31:43,233 ----------------------------------------------------------------------------------------------------
2021-07-23 17:31:43,233 EPOCH 9 done: loss 0.1163 - lr 0.0000300
2021-07-23 17:32:00,504 DEV : loss 0.12823210656642914 - score 0.9668
2021-07-23 17:32:00,687 BAD EPOCHS (no improvement): 1
2021-07-23 17:32:00,688 ----------------------------------------------------------------------------------------------------
2021-07-23 17:32:33,706 epoch 10 - iter 148/1480 - loss 0.11244582 - samples/sec: 143.48 - lr: 0.000030
2021-07-23 17:33:06,894 epoch 10 - iter 296/1480 - loss 0.11339037 - samples/sec: 142.73 - lr: 0.000030
2021-07-23 17:33:40,001 epoch 10 - iter 444/1480 - loss 0.11314598 - samples/sec: 143.08 - lr: 0.000030
2021-07-23 17:34:13,100 epoch 10 - iter 592/1480 - loss 0.11138929 - samples/sec: 143.12 - lr: 0.000030
2021-07-23 17:34:46,471 epoch 10 - iter 740/1480 - loss 0.11033378 - samples/sec: 141.95 - lr: 0.000030
2021-07-23 17:35:19,775 epoch 10 - iter 888/1480 - loss 0.11232130 - samples/sec: 142.24 - lr: 0.000030
2021-07-23 17:35:53,022 epoch 10 - iter 1036/1480 - loss 0.11223197 - samples/sec: 142.48 - lr: 0.000030
2021-07-23 17:36:26,743 epoch 10 - iter 1184/1480 - loss 0.11251070 - samples/sec: 140.48 - lr: 0.000030
2021-07-23 17:37:00,174 epoch 10 - iter 1332/1480 - loss 0.11342444 - samples/sec: 141.70 - lr: 0.000030
2021-07-23 17:37:34,157 epoch 10 - iter 1480/1480 - loss 0.11397992 - samples/sec: 139.40 - lr: 0.000030
2021-07-23 17:37:34,158 ----------------------------------------------------------------------------------------------------
2021-07-23 17:37:34,158 EPOCH 10 done: loss 0.1140 - lr 0.0000300
2021-07-23 17:37:51,381 DEV : loss 0.12764260172843933 - score 0.9663
2021-07-23 17:37:51,563 BAD EPOCHS (no improvement): 2
2021-07-23 17:37:51,564 ----------------------------------------------------------------------------------------------------
2021-07-23 17:38:24,799 epoch 11 - iter 148/1480 - loss 0.11266568 - samples/sec: 142.55 - lr: 0.000030
2021-07-23 17:38:58,664 epoch 11 - iter 296/1480 - loss 0.11456422 - samples/sec: 139.88 - lr: 0.000030
2021-07-23 17:39:32,339 epoch 11 - iter 444/1480 - loss 0.11635721 - samples/sec: 140.67 - lr: 0.000030
2021-07-23 17:40:06,159 epoch 11 - iter 592/1480 - loss 0.11710453 - samples/sec: 140.07 - lr: 0.000030
2021-07-23 17:40:39,203 epoch 11 - iter 740/1480 - loss 0.11766002 - samples/sec: 143.35 - lr: 0.000030
2021-07-23 17:41:12,401 epoch 11 - iter 888/1480 - loss 0.11653684 - samples/sec: 142.69 - lr: 0.000030
2021-07-23 17:41:45,884 epoch 11 - iter 1036/1480 - loss 0.11598342 - samples/sec: 141.47 - lr: 0.000030
2021-07-23 17:42:19,330 epoch 11 - iter 1184/1480 - loss 0.11427308 - samples/sec: 141.63 - lr: 0.000030
2021-07-23 17:42:52,742 epoch 11 - iter 1332/1480 - loss 0.11359504 - samples/sec: 141.78 - lr: 0.000030
2021-07-23 17:43:26,115 epoch 11 - iter 1480/1480 - loss 0.11311353 - samples/sec: 141.94 - lr: 0.000030
2021-07-23 17:43:26,117 ----------------------------------------------------------------------------------------------------
2021-07-23 17:43:26,117 EPOCH 11 done: loss 0.1131 - lr 0.0000300
2021-07-23 17:43:43,330 DEV : loss 0.1252414435148239 - score 0.9687
2021-07-23 17:43:43,513 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:43:45,781 ----------------------------------------------------------------------------------------------------
2021-07-23 17:44:19,005 epoch 12 - iter 148/1480 - loss 0.10913684 - samples/sec: 142.60 - lr: 0.000030
2021-07-23 17:44:52,380 epoch 12 - iter 296/1480 - loss 0.10895896 - samples/sec: 141.94 - lr: 0.000030
2021-07-23 17:45:25,955 epoch 12 - iter 444/1480 - loss 0.10899319 - samples/sec: 141.09 - lr: 0.000030
2021-07-23 17:45:59,354 epoch 12 - iter 592/1480 - loss 0.10940057 - samples/sec: 141.83 - lr: 0.000030
2021-07-23 17:46:32,946 epoch 12 - iter 740/1480 - loss 0.10930846 - samples/sec: 141.02 - lr: 0.000030
2021-07-23 17:47:06,500 epoch 12 - iter 888/1480 - loss 0.10932792 - samples/sec: 141.18 - lr: 0.000030
2021-07-23 17:47:40,132 epoch 12 - iter 1036/1480 - loss 0.10815299 - samples/sec: 140.85 - lr: 0.000030
2021-07-23 17:48:13,590 epoch 12 - iter 1184/1480 - loss 0.10891888 - samples/sec: 141.58 - lr: 0.000030
2021-07-23 17:48:46,658 epoch 12 - iter 1332/1480 - loss 0.10917983 - samples/sec: 143.25 - lr: 0.000030
2021-07-23 17:49:19,651 epoch 12 - iter 1480/1480 - loss 0.10887333 - samples/sec: 143.58 - lr: 0.000030
2021-07-23 17:49:19,652 ----------------------------------------------------------------------------------------------------
2021-07-23 17:49:19,653 EPOCH 12 done: loss 0.1089 - lr 0.0000300
2021-07-23 17:49:36,929 DEV : loss 0.12419118732213974 - score 0.9686
2021-07-23 17:49:37,116 BAD EPOCHS (no improvement): 1
2021-07-23 17:49:37,116 ----------------------------------------------------------------------------------------------------
2021-07-23 17:50:10,540 epoch 13 - iter 148/1480 - loss 0.09955669 - samples/sec: 141.74 - lr: 0.000030
2021-07-23 17:50:43,416 epoch 13 - iter 296/1480 - loss 0.10283939 - samples/sec: 144.09 - lr: 0.000030
2021-07-23 17:51:16,683 epoch 13 - iter 444/1480 - loss 0.10230042 - samples/sec: 142.39 - lr: 0.000030
2021-07-23 17:51:50,151 epoch 13 - iter 592/1480 - loss 0.10147635 - samples/sec: 141.54 - lr: 0.000030
2021-07-23 17:52:23,467 epoch 13 - iter 740/1480 - loss 0.10403331 - samples/sec: 142.18 - lr: 0.000030
2021-07-23 17:52:56,665 epoch 13 - iter 888/1480 - loss 0.10328114 - samples/sec: 142.69 - lr: 0.000030
2021-07-23 17:53:29,873 epoch 13 - iter 1036/1480 - loss 0.10224618 - samples/sec: 142.65 - lr: 0.000030
2021-07-23 17:54:03,514 epoch 13 - iter 1184/1480 - loss 0.10420373 - samples/sec: 140.81 - lr: 0.000030
2021-07-23 17:54:36,698 epoch 13 - iter 1332/1480 - loss 0.10517252 - samples/sec: 142.75 - lr: 0.000030
2021-07-23 17:55:10,046 epoch 13 - iter 1480/1480 - loss 0.10537514 - samples/sec: 142.05 - lr: 0.000030
2021-07-23 17:55:10,048 ----------------------------------------------------------------------------------------------------
2021-07-23 17:55:10,048 EPOCH 13 done: loss 0.1054 - lr 0.0000300
2021-07-23 17:55:28,694 DEV : loss 0.12427078187465668 - score 0.9686
2021-07-23 17:55:28,879 BAD EPOCHS (no improvement): 2
2021-07-23 17:55:28,879 ----------------------------------------------------------------------------------------------------
2021-07-23 17:56:02,239 epoch 14 - iter 148/1480 - loss 0.10392047 - samples/sec: 142.01 - lr: 0.000030
2021-07-23 17:56:35,769 epoch 14 - iter 296/1480 - loss 0.10881441 - samples/sec: 141.28 - lr: 0.000030
2021-07-23 17:57:09,156 epoch 14 - iter 444/1480 - loss 0.10410585 - samples/sec: 141.88 - lr: 0.000030
2021-07-23 17:57:42,388 epoch 14 - iter 592/1480 - loss 0.10116454 - samples/sec: 142.54 - lr: 0.000030
2021-07-23 17:58:15,903 epoch 14 - iter 740/1480 - loss 0.10324336 - samples/sec: 141.34 - lr: 0.000030
2021-07-23 17:58:49,046 epoch 14 - iter 888/1480 - loss 0.10407220 - samples/sec: 142.93 - lr: 0.000030
2021-07-23 17:59:22,252 epoch 14 - iter 1036/1480 - loss 0.10526669 - samples/sec: 142.65 - lr: 0.000030
2021-07-23 17:59:55,587 epoch 14 - iter 1184/1480 - loss 0.10613645 - samples/sec: 142.11 - lr: 0.000030
2021-07-23 18:00:28,483 epoch 14 - iter 1332/1480 - loss 0.10534701 - samples/sec: 144.00 - lr: 0.000030
2021-07-23 18:01:01,704 epoch 14 - iter 1480/1480 - loss 0.10528050 - samples/sec: 142.59 - lr: 0.000030
2021-07-23 18:01:01,706 ----------------------------------------------------------------------------------------------------
2021-07-23 18:01:01,706 EPOCH 14 done: loss 0.1053 - lr 0.0000300
2021-07-23 18:01:18,954 DEV : loss 0.1231391504406929 - score 0.9691
2021-07-23 18:01:19,136 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:01:21,381 ----------------------------------------------------------------------------------------------------
2021-07-23 18:01:54,595 epoch 15 - iter 148/1480 - loss 0.09266148 - samples/sec: 142.65 - lr: 0.000030
2021-07-23 18:02:27,959 epoch 15 - iter 296/1480 - loss 0.09563698 - samples/sec: 141.99 - lr: 0.000030
2021-07-23 18:03:01,363 epoch 15 - iter 444/1480 - loss 0.09993105 - samples/sec: 141.81 - lr: 0.000030
2021-07-23 18:03:34,519 epoch 15 - iter 592/1480 - loss 0.09852404 - samples/sec: 142.87 - lr: 0.000030
2021-07-23 18:04:08,112 epoch 15 - iter 740/1480 - loss 0.09870692 - samples/sec: 141.01 - lr: 0.000030
2021-07-23 18:04:41,535 epoch 15 - iter 888/1480 - loss 0.10012442 - samples/sec: 141.73 - lr: 0.000030
2021-07-23 18:05:14,987 epoch 15 - iter 1036/1480 - loss 0.10033246 - samples/sec: 141.60 - lr: 0.000030
2021-07-23 18:05:48,166 epoch 15 - iter 1184/1480 - loss 0.09992205 - samples/sec: 142.77 - lr: 0.000030
2021-07-23 18:06:21,362 epoch 15 - iter 1332/1480 - loss 0.09966419 - samples/sec: 142.70 - lr: 0.000030
2021-07-23 18:06:54,577 epoch 15 - iter 1480/1480 - loss 0.10007973 - samples/sec: 142.62 - lr: 0.000030
2021-07-23 18:06:54,578 ----------------------------------------------------------------------------------------------------
2021-07-23 18:06:54,578 EPOCH 15 done: loss 0.1001 - lr 0.0000300
2021-07-23 18:07:11,850 DEV : loss 0.1283872276544571 - score 0.9695
2021-07-23 18:07:12,033 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:07:14,295 ----------------------------------------------------------------------------------------------------
2021-07-23 18:07:47,256 epoch 16 - iter 148/1480 - loss 0.09568121 - samples/sec: 143.74 - lr: 0.000030
2021-07-23 18:08:20,229 epoch 16 - iter 296/1480 - loss 0.09639027 - samples/sec: 143.66 - lr: 0.000030
2021-07-23 18:08:53,020 epoch 16 - iter 444/1480 - loss 0.09704762 - samples/sec: 144.46 - lr: 0.000030
2021-07-23 18:09:26,416 epoch 16 - iter 592/1480 - loss 0.09704655 - samples/sec: 141.84 - lr: 0.000030
2021-07-23 18:09:59,475 epoch 16 - iter 740/1480 - loss 0.09982034 - samples/sec: 143.29 - lr: 0.000030
2021-07-23 18:10:32,901 epoch 16 - iter 888/1480 - loss 0.10138305 - samples/sec: 141.72 - lr: 0.000030
2021-07-23 18:11:06,507 epoch 16 - iter 1036/1480 - loss 0.10088871 - samples/sec: 140.96 - lr: 0.000030
2021-07-23 18:11:39,516 epoch 16 - iter 1184/1480 - loss 0.10064707 - samples/sec: 143.51 - lr: 0.000030
2021-07-23 18:12:12,559 epoch 16 - iter 1332/1480 - loss 0.10045442 - samples/sec: 143.36 - lr: 0.000030
2021-07-23 18:12:46,176 epoch 16 - iter 1480/1480 - loss 0.10049018 - samples/sec: 140.91 - lr: 0.000030
2021-07-23 18:12:46,177 ----------------------------------------------------------------------------------------------------
2021-07-23 18:12:46,177 EPOCH 16 done: loss 0.1005 - lr 0.0000300
2021-07-23 18:13:03,484 DEV : loss 0.12424029409885406 - score 0.9688
2021-07-23 18:13:03,667 BAD EPOCHS (no improvement): 1
2021-07-23 18:13:03,667 ----------------------------------------------------------------------------------------------------
2021-07-23 18:13:36,716 epoch 17 - iter 148/1480 - loss 0.09895315 - samples/sec: 143.35 - lr: 0.000030
2021-07-23 18:14:09,899 epoch 17 - iter 296/1480 - loss 0.09197735 - samples/sec: 142.76 - lr: 0.000030
2021-07-23 18:14:43,231 epoch 17 - iter 444/1480 - loss 0.09354976 - samples/sec: 142.12 - lr: 0.000030
2021-07-23 18:15:16,754 epoch 17 - iter 592/1480 - loss 0.09388305 - samples/sec: 141.31 - lr: 0.000030
2021-07-23 18:15:50,171 epoch 17 - iter 740/1480 - loss 0.09529955 - samples/sec: 141.75 - lr: 0.000030
2021-07-23 18:16:23,307 epoch 17 - iter 888/1480 - loss 0.09558329 - samples/sec: 142.96 - lr: 0.000030
2021-07-23 18:16:56,994 epoch 17 - iter 1036/1480 - loss 0.09704133 - samples/sec: 140.62 - lr: 0.000030
2021-07-23 18:17:30,238 epoch 17 - iter 1184/1480 - loss 0.09876378 - samples/sec: 142.49 - lr: 0.000030
2021-07-23 18:18:03,300 epoch 17 - iter 1332/1480 - loss 0.09938329 - samples/sec: 143.28 - lr: 0.000030
2021-07-23 18:18:36,711 epoch 17 - iter 1480/1480 - loss 0.09842338 - samples/sec: 141.78 - lr: 0.000030
2021-07-23 18:18:36,712 ----------------------------------------------------------------------------------------------------
2021-07-23 18:18:36,712 EPOCH 17 done: loss 0.0984 - lr 0.0000300
2021-07-23 18:18:55,401 DEV : loss 0.11989760398864746 - score 0.9698
2021-07-23 18:18:55,587 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:18:57,838 ----------------------------------------------------------------------------------------------------
2021-07-23 18:19:31,395 epoch 18 - iter 148/1480 - loss 0.09337949 - samples/sec: 141.18 - lr: 0.000030
2021-07-23 18:20:04,934 epoch 18 - iter 296/1480 - loss 0.09202932 - samples/sec: 141.24 - lr: 0.000030
2021-07-23 18:20:38,258 epoch 18 - iter 444/1480 - loss 0.09285032 - samples/sec: 142.15 - lr: 0.000030
2021-07-23 18:21:11,738 epoch 18 - iter 592/1480 - loss 0.09520345 - samples/sec: 141.49 - lr: 0.000030
2021-07-23 18:21:44,617 epoch 18 - iter 740/1480 - loss 0.09678468 - samples/sec: 144.08 - lr: 0.000030
2021-07-23 18:22:17,800 epoch 18 - iter 888/1480 - loss 0.09665319 - samples/sec: 142.75 - lr: 0.000030
2021-07-23 18:22:51,312 epoch 18 - iter 1036/1480 - loss 0.09669696 - samples/sec: 141.36 - lr: 0.000030
2021-07-23 18:23:24,860 epoch 18 - iter 1184/1480 - loss 0.09614934 - samples/sec: 141.20 - lr: 0.000030
2021-07-23 18:23:58,022 epoch 18 - iter 1332/1480 - loss 0.09630988 - samples/sec: 142.85 - lr: 0.000030
2021-07-23 18:24:31,040 epoch 18 - iter 1480/1480 - loss 0.09699693 - samples/sec: 143.47 - lr: 0.000030
2021-07-23 18:24:31,042 ----------------------------------------------------------------------------------------------------
2021-07-23 18:24:31,042 EPOCH 18 done: loss 0.0970 - lr 0.0000300
2021-07-23 18:24:48,329 DEV : loss 0.12160570174455643 - score 0.9702
2021-07-23 18:24:48,515 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:24:50,745 ----------------------------------------------------------------------------------------------------
2021-07-23 18:25:23,629 epoch 19 - iter 148/1480 - loss 0.10112768 - samples/sec: 144.07 - lr: 0.000030
2021-07-23 18:25:56,491 epoch 19 - iter 296/1480 - loss 0.09902472 - samples/sec: 144.15 - lr: 0.000030
2021-07-23 18:26:29,522 epoch 19 - iter 444/1480 - loss 0.09586939 - samples/sec: 143.41 - lr: 0.000030
2021-07-23 18:27:02,818 epoch 19 - iter 592/1480 - loss 0.09531439 - samples/sec: 142.27 - lr: 0.000030
2021-07-23 18:27:35,739 epoch 19 - iter 740/1480 - loss 0.09512623 - samples/sec: 143.89 - lr: 0.000030
2021-07-23 18:28:09,119 epoch 19 - iter 888/1480 - loss 0.09687762 - samples/sec: 141.91 - lr: 0.000030
2021-07-23 18:28:42,492 epoch 19 - iter 1036/1480 - loss 0.09663348 - samples/sec: 141.94 - lr: 0.000030
2021-07-23 18:29:15,788 epoch 19 - iter 1184/1480 - loss 0.09666662 - samples/sec: 142.27 - lr: 0.000030
2021-07-23 18:29:49,579 epoch 19 - iter 1332/1480 - loss 0.09562929 - samples/sec: 140.18 - lr: 0.000030
2021-07-23 18:30:22,918 epoch 19 - iter 1480/1480 - loss 0.09663367 - samples/sec: 142.09 - lr: 0.000030
2021-07-23 18:30:22,920 ----------------------------------------------------------------------------------------------------
2021-07-23 18:30:22,920 EPOCH 19 done: loss 0.0966 - lr 0.0000300
2021-07-23 18:30:40,178 DEV : loss 0.12212987244129181 - score 0.9704
2021-07-23 18:30:40,361 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:30:42,610 ----------------------------------------------------------------------------------------------------
2021-07-23 18:31:15,907 epoch 20 - iter 148/1480 - loss 0.09850985 - samples/sec: 142.29 - lr: 0.000030
2021-07-23 18:31:49,409 epoch 20 - iter 296/1480 - loss 0.09640920 - samples/sec: 141.40 - lr: 0.000030
2021-07-23 18:32:22,872 epoch 20 - iter 444/1480 - loss 0.09648351 - samples/sec: 141.56 - lr: 0.000030
2021-07-23 18:32:56,092 epoch 20 - iter 592/1480 - loss 0.09603063 - samples/sec: 142.59 - lr: 0.000030
2021-07-23 18:33:29,516 epoch 20 - iter 740/1480 - loss 0.09478963 - samples/sec: 141.73 - lr: 0.000030
2021-07-23 18:34:02,847 epoch 20 - iter 888/1480 - loss 0.09430618 - samples/sec: 142.12 - lr: 0.000030
2021-07-23 18:34:36,152 epoch 20 - iter 1036/1480 - loss 0.09384935 - samples/sec: 142.23 - lr: 0.000030
2021-07-23 18:35:09,120 epoch 20 - iter 1184/1480 - loss 0.09480313 - samples/sec: 143.69 - lr: 0.000030
2021-07-23 18:35:42,231 epoch 20 - iter 1332/1480 - loss 0.09437246 - samples/sec: 143.07 - lr: 0.000030
2021-07-23 18:36:15,700 epoch 20 - iter 1480/1480 - loss 0.09326465 - samples/sec: 141.53 - lr: 0.000030
2021-07-23 18:36:15,701 ----------------------------------------------------------------------------------------------------
2021-07-23 18:36:15,701 EPOCH 20 done: loss 0.0933 - lr 0.0000300
2021-07-23 18:36:32,994 DEV : loss 0.12688660621643066 - score 0.9686
2021-07-23 18:36:33,179 BAD EPOCHS (no improvement): 1
2021-07-23 18:36:33,180 ----------------------------------------------------------------------------------------------------
2021-07-23 18:37:06,695 epoch 21 - iter 148/1480 - loss 0.09177464 - samples/sec: 141.35 - lr: 0.000030
2021-07-23 18:37:40,148 epoch 21 - iter 296/1480 - loss 0.09323846 - samples/sec: 141.61 - lr: 0.000030
2021-07-23 18:38:13,614 epoch 21 - iter 444/1480 - loss 0.09613961 - samples/sec: 141.54 - lr: 0.000030
2021-07-23 18:38:46,595 epoch 21 - iter 592/1480 - loss 0.09264179 - samples/sec: 143.63 - lr: 0.000030
2021-07-23 18:39:19,784 epoch 21 - iter 740/1480 - loss 0.09156747 - samples/sec: 142.73 - lr: 0.000030
2021-07-23 18:39:52,806 epoch 21 - iter 888/1480 - loss 0.09094053 - samples/sec: 143.45 - lr: 0.000030
2021-07-23 18:40:25,795 epoch 21 - iter 1036/1480 - loss 0.09066005 - samples/sec: 143.60 - lr: 0.000030
2021-07-23 18:40:59,028 epoch 21 - iter 1184/1480 - loss 0.09091725 - samples/sec: 142.54 - lr: 0.000030
2021-07-23 18:41:32,584 epoch 21 - iter 1332/1480 - loss 0.09060371 - samples/sec: 141.17 - lr: 0.000030
2021-07-23 18:42:05,648 epoch 21 - iter 1480/1480 - loss 0.09138244 - samples/sec: 143.27 - lr: 0.000030
2021-07-23 18:42:05,650 ----------------------------------------------------------------------------------------------------
2021-07-23 18:42:05,650 EPOCH 21 done: loss 0.0914 - lr 0.0000300
2021-07-23 18:42:22,919 DEV : loss 0.12393157184123993 - score 0.971
2021-07-23 18:42:23,104 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:42:25,327 ----------------------------------------------------------------------------------------------------
2021-07-23 18:43:00,360 epoch 22 - iter 148/1480 - loss 0.09895306 - samples/sec: 135.23 - lr: 0.000030
2021-07-23 18:43:33,636 epoch 22 - iter 296/1480 - loss 0.09519234 - samples/sec: 142.35 - lr: 0.000030
2021-07-23 18:44:07,029 epoch 22 - iter 444/1480 - loss 0.09385742 - samples/sec: 141.86 - lr: 0.000030
2021-07-23 18:44:40,108 epoch 22 - iter 592/1480 - loss 0.09458078 - samples/sec: 143.20 - lr: 0.000030
2021-07-23 18:45:13,123 epoch 22 - iter 740/1480 - loss 0.09355471 - samples/sec: 143.48 - lr: 0.000030
2021-07-23 18:45:46,644 epoch 22 - iter 888/1480 - loss 0.09411106 - samples/sec: 141.32 - lr: 0.000030
2021-07-23 18:46:20,392 epoch 22 - iter 1036/1480 - loss 0.09267713 - samples/sec: 140.37 - lr: 0.000030
2021-07-23 18:46:53,615 epoch 22 - iter 1184/1480 - loss 0.09175684 - samples/sec: 142.58 - lr: 0.000030
2021-07-23 18:47:26,412 epoch 22 - iter 1332/1480 - loss 0.09040481 - samples/sec: 144.44 - lr: 0.000030
2021-07-23 18:47:59,910 epoch 22 - iter 1480/1480 - loss 0.09097171 - samples/sec: 141.41 - lr: 0.000030
2021-07-23 18:47:59,912 ----------------------------------------------------------------------------------------------------
2021-07-23 18:47:59,912 EPOCH 22 done: loss 0.0910 - lr 0.0000300
2021-07-23 18:48:17,195 DEV : loss 0.1228349432349205 - score 0.9713
2021-07-23 18:48:17,379 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:48:19,694 ----------------------------------------------------------------------------------------------------
2021-07-23 18:48:52,567 epoch 23 - iter 148/1480 - loss 0.08735754 - samples/sec: 144.12 - lr: 0.000030
2021-07-23 18:49:25,517 epoch 23 - iter 296/1480 - loss 0.08418747 - samples/sec: 143.77 - lr: 0.000030
2021-07-23 18:49:58,794 epoch 23 - iter 444/1480 - loss 0.08557525 - samples/sec: 142.35 - lr: 0.000030
2021-07-23 18:50:31,698 epoch 23 - iter 592/1480 - loss 0.08765454 - samples/sec: 143.97 - lr: 0.000030
2021-07-23 18:51:05,375 epoch 23 - iter 740/1480 - loss 0.08719481 - samples/sec: 140.66 - lr: 0.000030
2021-07-23 18:51:38,524 epoch 23 - iter 888/1480 - loss 0.08721821 - samples/sec: 142.90 - lr: 0.000030
2021-07-23 18:52:11,775 epoch 23 - iter 1036/1480 - loss 0.08792561 - samples/sec: 142.46 - lr: 0.000030
2021-07-23 18:52:45,020 epoch 23 - iter 1184/1480 - loss 0.08796075 - samples/sec: 142.49 - lr: 0.000030
2021-07-23 18:53:18,648 epoch 23 - iter 1332/1480 - loss 0.08772970 - samples/sec: 140.87 - lr: 0.000030
2021-07-23 18:53:52,319 epoch 23 - iter 1480/1480 - loss 0.08890003 - samples/sec: 140.69 - lr: 0.000030
2021-07-23 18:53:52,321 ----------------------------------------------------------------------------------------------------
2021-07-23 18:53:52,321 EPOCH 23 done: loss 0.0889 - lr 0.0000300
2021-07-23 18:54:09,651 DEV : loss 0.12200184911489487 - score 0.9701
2021-07-23 18:54:09,838 BAD EPOCHS (no improvement): 1
2021-07-23 18:54:09,838 ----------------------------------------------------------------------------------------------------
2021-07-23 18:54:43,575 epoch 24 - iter 148/1480 - loss 0.08164519 - samples/sec: 140.42 - lr: 0.000030
2021-07-23 18:55:16,943 epoch 24 - iter 296/1480 - loss 0.08604343 - samples/sec: 141.97 - lr: 0.000030
2021-07-23 18:55:50,189 epoch 24 - iter 444/1480 - loss 0.08608872 - samples/sec: 142.49 - lr: 0.000030
2021-07-23 18:56:23,807 epoch 24 - iter 592/1480 - loss 0.08777826 - samples/sec: 140.91 - lr: 0.000030
2021-07-23 18:56:57,144 epoch 24 - iter 740/1480 - loss 0.08731258 - samples/sec: 142.09 - lr: 0.000030
2021-07-23 18:57:30,391 epoch 24 - iter 888/1480 - loss 0.08814346 - samples/sec: 142.48 - lr: 0.000030
2021-07-23 18:58:03,853 epoch 24 - iter 1036/1480 - loss 0.08961659 - samples/sec: 141.56 - lr: 0.000030
2021-07-23 18:58:36,996 epoch 24 - iter 1184/1480 - loss 0.08856726 - samples/sec: 142.93 - lr: 0.000030
2021-07-23 18:59:10,492 epoch 24 - iter 1332/1480 - loss 0.08955143 - samples/sec: 141.42 - lr: 0.000030
2021-07-23 18:59:43,280 epoch 24 - iter 1480/1480 - loss 0.08875224 - samples/sec: 144.48 - lr: 0.000030
2021-07-23 18:59:43,281 ----------------------------------------------------------------------------------------------------
2021-07-23 18:59:43,281 EPOCH 24 done: loss 0.0888 - lr 0.0000300
2021-07-23 19:00:00,629 DEV : loss 0.12878334522247314 - score 0.9672
2021-07-23 19:00:00,815 BAD EPOCHS (no improvement): 2
2021-07-23 19:00:00,815 ----------------------------------------------------------------------------------------------------
2021-07-23 19:00:34,118 epoch 25 - iter 148/1480 - loss 0.08079495 - samples/sec: 142.25 - lr: 0.000030
2021-07-23 19:01:07,478 epoch 25 - iter 296/1480 - loss 0.08871971 - samples/sec: 142.00 - lr: 0.000030
2021-07-23 19:01:40,767 epoch 25 - iter 444/1480 - loss 0.08550820 - samples/sec: 142.30 - lr: 0.000030
2021-07-23 19:02:14,011 epoch 25 - iter 592/1480 - loss 0.08656466 - samples/sec: 142.49 - lr: 0.000030
2021-07-23 19:02:47,473 epoch 25 - iter 740/1480 - loss 0.08676642 - samples/sec: 141.57 - lr: 0.000030
2021-07-23 19:03:20,611 epoch 25 - iter 888/1480 - loss 0.08766904 - samples/sec: 142.95 - lr: 0.000030
2021-07-23 19:03:53,814 epoch 25 - iter 1036/1480 - loss 0.08748911 - samples/sec: 142.67 - lr: 0.000030
2021-07-23 19:04:26,869 epoch 25 - iter 1184/1480 - loss 0.08765085 - samples/sec: 143.31 - lr: 0.000030
2021-07-23 19:05:00,547 epoch 25 - iter 1332/1480 - loss 0.08776582 - samples/sec: 140.66 - lr: 0.000030
2021-07-23 19:05:34,123 epoch 25 - iter 1480/1480 - loss 0.08730406 - samples/sec: 141.08 - lr: 0.000030
2021-07-23 19:05:34,125 ----------------------------------------------------------------------------------------------------
2021-07-23 19:05:34,125 EPOCH 25 done: loss 0.0873 - lr 0.0000300
2021-07-23 19:05:51,413 DEV : loss 0.12042071670293808 - score 0.9705
2021-07-23 19:05:51,598 BAD EPOCHS (no improvement): 3
2021-07-23 19:05:51,598 ----------------------------------------------------------------------------------------------------
2021-07-23 19:06:24,557 epoch 26 - iter 148/1480 - loss 0.08500073 - samples/sec: 143.74 - lr: 0.000030
2021-07-23 19:06:57,867 epoch 26 - iter 296/1480 - loss 0.08635469 - samples/sec: 142.21 - lr: 0.000030
2021-07-23 19:07:31,473 epoch 26 - iter 444/1480 - loss 0.08819842 - samples/sec: 140.96 - lr: 0.000030
2021-07-23 19:08:04,162 epoch 26 - iter 592/1480 - loss 0.09001447 - samples/sec: 144.91 - lr: 0.000030
2021-07-23 19:08:37,995 epoch 26 - iter 740/1480 - loss 0.09019432 - samples/sec: 140.01 - lr: 0.000030
2021-07-23 19:09:10,960 epoch 26 - iter 888/1480 - loss 0.08943541 - samples/sec: 143.70 - lr: 0.000030
2021-07-23 19:09:44,167 epoch 26 - iter 1036/1480 - loss 0.08927406 - samples/sec: 142.65 - lr: 0.000030
2021-07-23 19:10:17,464 epoch 26 - iter 1184/1480 - loss 0.08872038 - samples/sec: 142.27 - lr: 0.000030
2021-07-23 19:10:50,800 epoch 26 - iter 1332/1480 - loss 0.08812845 - samples/sec: 142.10 - lr: 0.000030
2021-07-23 19:11:23,875 epoch 26 - iter 1480/1480 - loss 0.08832836 - samples/sec: 143.23 - lr: 0.000030
2021-07-23 19:11:23,876 ----------------------------------------------------------------------------------------------------
2021-07-23 19:11:23,876 EPOCH 26 done: loss 0.0883 - lr 0.0000300
2021-07-23 19:11:42,593 DEV : loss 0.11872056871652603 - score 0.9706
Epoch    26: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 19:11:42,781 BAD EPOCHS (no improvement): 4
2021-07-23 19:11:42,781 ----------------------------------------------------------------------------------------------------
2021-07-23 19:12:15,868 epoch 27 - iter 148/1480 - loss 0.07384514 - samples/sec: 143.19 - lr: 0.000015
2021-07-23 19:12:49,363 epoch 27 - iter 296/1480 - loss 0.08067870 - samples/sec: 141.42 - lr: 0.000015
2021-07-23 19:13:22,556 epoch 27 - iter 444/1480 - loss 0.08063820 - samples/sec: 142.71 - lr: 0.000015
2021-07-23 19:13:56,089 epoch 27 - iter 592/1480 - loss 0.08041841 - samples/sec: 141.27 - lr: 0.000015
2021-07-23 19:14:29,556 epoch 27 - iter 740/1480 - loss 0.08135325 - samples/sec: 141.55 - lr: 0.000015
2021-07-23 19:15:02,851 epoch 27 - iter 888/1480 - loss 0.08283306 - samples/sec: 142.28 - lr: 0.000015
2021-07-23 19:15:35,922 epoch 27 - iter 1036/1480 - loss 0.08250848 - samples/sec: 143.24 - lr: 0.000015
2021-07-23 19:16:08,987 epoch 27 - iter 1184/1480 - loss 0.08129013 - samples/sec: 143.26 - lr: 0.000015
2021-07-23 19:16:42,070 epoch 27 - iter 1332/1480 - loss 0.08215379 - samples/sec: 143.19 - lr: 0.000015
2021-07-23 19:17:15,560 epoch 27 - iter 1480/1480 - loss 0.08261676 - samples/sec: 141.45 - lr: 0.000015
2021-07-23 19:17:15,561 ----------------------------------------------------------------------------------------------------
2021-07-23 19:17:15,561 EPOCH 27 done: loss 0.0826 - lr 0.0000150
2021-07-23 19:17:32,860 DEV : loss 0.11965688318014145 - score 0.9703
2021-07-23 19:17:33,046 BAD EPOCHS (no improvement): 1
2021-07-23 19:17:33,046 ----------------------------------------------------------------------------------------------------
2021-07-23 19:18:06,523 epoch 28 - iter 148/1480 - loss 0.09053509 - samples/sec: 141.52 - lr: 0.000015
2021-07-23 19:18:39,956 epoch 28 - iter 296/1480 - loss 0.08421968 - samples/sec: 141.69 - lr: 0.000015
2021-07-23 19:19:12,883 epoch 28 - iter 444/1480 - loss 0.08553906 - samples/sec: 143.86 - lr: 0.000015
2021-07-23 19:19:45,875 epoch 28 - iter 592/1480 - loss 0.08477762 - samples/sec: 143.58 - lr: 0.000015
2021-07-23 19:20:19,129 epoch 28 - iter 740/1480 - loss 0.08517860 - samples/sec: 142.45 - lr: 0.000015
2021-07-23 19:20:52,092 epoch 28 - iter 888/1480 - loss 0.08336035 - samples/sec: 143.71 - lr: 0.000015
2021-07-23 19:21:25,160 epoch 28 - iter 1036/1480 - loss 0.08302821 - samples/sec: 143.25 - lr: 0.000015
2021-07-23 19:21:58,396 epoch 28 - iter 1184/1480 - loss 0.08329486 - samples/sec: 142.52 - lr: 0.000015
2021-07-23 19:22:31,736 epoch 28 - iter 1332/1480 - loss 0.08319301 - samples/sec: 142.08 - lr: 0.000015
2021-07-23 19:23:05,269 epoch 28 - iter 1480/1480 - loss 0.08464941 - samples/sec: 141.26 - lr: 0.000015
2021-07-23 19:23:05,271 ----------------------------------------------------------------------------------------------------
2021-07-23 19:23:05,271 EPOCH 28 done: loss 0.0846 - lr 0.0000150
2021-07-23 19:23:22,570 DEV : loss 0.1182110607624054 - score 0.9702
2021-07-23 19:23:22,756 BAD EPOCHS (no improvement): 2
2021-07-23 19:23:22,756 ----------------------------------------------------------------------------------------------------
2021-07-23 19:23:55,599 epoch 29 - iter 148/1480 - loss 0.09088116 - samples/sec: 144.25 - lr: 0.000015
2021-07-23 19:24:29,428 epoch 29 - iter 296/1480 - loss 0.08427201 - samples/sec: 140.03 - lr: 0.000015
2021-07-23 19:25:02,647 epoch 29 - iter 444/1480 - loss 0.08520056 - samples/sec: 142.60 - lr: 0.000015
2021-07-23 19:25:35,858 epoch 29 - iter 592/1480 - loss 0.08520215 - samples/sec: 142.63 - lr: 0.000015
2021-07-23 19:26:09,328 epoch 29 - iter 740/1480 - loss 0.08426590 - samples/sec: 141.53 - lr: 0.000015
2021-07-23 19:26:42,791 epoch 29 - iter 888/1480 - loss 0.08292495 - samples/sec: 141.56 - lr: 0.000015
2021-07-23 19:27:16,479 epoch 29 - iter 1036/1480 - loss 0.08387352 - samples/sec: 140.62 - lr: 0.000015
2021-07-23 19:27:49,733 epoch 29 - iter 1184/1480 - loss 0.08336643 - samples/sec: 142.45 - lr: 0.000015
2021-07-23 19:28:23,323 epoch 29 - iter 1332/1480 - loss 0.08307707 - samples/sec: 141.02 - lr: 0.000015
2021-07-23 19:28:56,426 epoch 29 - iter 1480/1480 - loss 0.08227334 - samples/sec: 143.10 - lr: 0.000015
2021-07-23 19:28:56,428 ----------------------------------------------------------------------------------------------------
2021-07-23 19:28:56,428 EPOCH 29 done: loss 0.0823 - lr 0.0000150
2021-07-23 19:29:13,771 DEV : loss 0.1207161396741867 - score 0.9713
2021-07-23 19:29:13,956 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 19:29:16,181 ----------------------------------------------------------------------------------------------------
2021-07-23 19:29:49,112 epoch 30 - iter 148/1480 - loss 0.09207938 - samples/sec: 143.87 - lr: 0.000015
2021-07-23 19:30:22,739 epoch 30 - iter 296/1480 - loss 0.08704785 - samples/sec: 140.87 - lr: 0.000015
2021-07-23 19:30:56,109 epoch 30 - iter 444/1480 - loss 0.08540025 - samples/sec: 141.95 - lr: 0.000015
2021-07-23 19:31:29,555 epoch 30 - iter 592/1480 - loss 0.08337022 - samples/sec: 141.63 - lr: 0.000015
2021-07-23 19:32:02,871 epoch 30 - iter 740/1480 - loss 0.08124747 - samples/sec: 142.18 - lr: 0.000015
2021-07-23 19:32:36,584 epoch 30 - iter 888/1480 - loss 0.08002113 - samples/sec: 140.51 - lr: 0.000015
2021-07-23 19:33:09,758 epoch 30 - iter 1036/1480 - loss 0.07969665 - samples/sec: 142.79 - lr: 0.000015
2021-07-23 19:33:43,194 epoch 30 - iter 1184/1480 - loss 0.07988829 - samples/sec: 141.68 - lr: 0.000015
2021-07-23 19:34:16,604 epoch 30 - iter 1332/1480 - loss 0.08045559 - samples/sec: 141.78 - lr: 0.000015
2021-07-23 19:34:49,811 epoch 30 - iter 1480/1480 - loss 0.08085170 - samples/sec: 142.65 - lr: 0.000015
2021-07-23 19:34:49,813 ----------------------------------------------------------------------------------------------------
2021-07-23 19:34:49,813 EPOCH 30 done: loss 0.0809 - lr 0.0000150
2021-07-23 19:35:08,469 DEV : loss 0.1217794120311737 - score 0.9712
2021-07-23 19:35:08,653 BAD EPOCHS (no improvement): 1
2021-07-23 19:35:08,653 ----------------------------------------------------------------------------------------------------
2021-07-23 19:35:41,924 epoch 31 - iter 148/1480 - loss 0.06704258 - samples/sec: 142.39 - lr: 0.000015
2021-07-23 19:36:14,812 epoch 31 - iter 296/1480 - loss 0.07524399 - samples/sec: 144.04 - lr: 0.000015
2021-07-23 19:36:48,551 epoch 31 - iter 444/1480 - loss 0.08098301 - samples/sec: 140.40 - lr: 0.000015
2021-07-23 19:37:21,879 epoch 31 - iter 592/1480 - loss 0.08034835 - samples/sec: 142.13 - lr: 0.000015
2021-07-23 19:37:55,383 epoch 31 - iter 740/1480 - loss 0.08266162 - samples/sec: 141.39 - lr: 0.000015
2021-07-23 19:38:29,029 epoch 31 - iter 888/1480 - loss 0.08252938 - samples/sec: 140.79 - lr: 0.000015
2021-07-23 19:39:02,119 epoch 31 - iter 1036/1480 - loss 0.08099486 - samples/sec: 143.15 - lr: 0.000015
2021-07-23 19:39:35,443 epoch 31 - iter 1184/1480 - loss 0.08060175 - samples/sec: 142.15 - lr: 0.000015
2021-07-23 19:40:08,357 epoch 31 - iter 1332/1480 - loss 0.08040597 - samples/sec: 143.93 - lr: 0.000015
2021-07-23 19:40:41,443 epoch 31 - iter 1480/1480 - loss 0.08148244 - samples/sec: 143.17 - lr: 0.000015
2021-07-23 19:40:41,445 ----------------------------------------------------------------------------------------------------
2021-07-23 19:40:41,445 EPOCH 31 done: loss 0.0815 - lr 0.0000150
2021-07-23 19:40:58,733 DEV : loss 0.11786068230867386 - score 0.9724
2021-07-23 19:40:58,918 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 19:41:01,088 ----------------------------------------------------------------------------------------------------
2021-07-23 19:41:34,417 epoch 32 - iter 148/1480 - loss 0.08582974 - samples/sec: 142.15 - lr: 0.000015
2021-07-23 19:42:07,793 epoch 32 - iter 296/1480 - loss 0.08399870 - samples/sec: 141.93 - lr: 0.000015
2021-07-23 19:42:41,363 epoch 32 - iter 444/1480 - loss 0.08101016 - samples/sec: 141.11 - lr: 0.000015
2021-07-23 19:43:14,649 epoch 32 - iter 592/1480 - loss 0.07938813 - samples/sec: 142.32 - lr: 0.000015
2021-07-23 19:43:48,044 epoch 32 - iter 740/1480 - loss 0.08090518 - samples/sec: 141.84 - lr: 0.000015
2021-07-23 19:44:21,212 epoch 32 - iter 888/1480 - loss 0.07990441 - samples/sec: 142.82 - lr: 0.000015
2021-07-23 19:44:54,726 epoch 32 - iter 1036/1480 - loss 0.08147564 - samples/sec: 141.35 - lr: 0.000015
2021-07-23 19:45:27,804 epoch 32 - iter 1184/1480 - loss 0.08079135 - samples/sec: 143.21 - lr: 0.000015
2021-07-23 19:46:01,016 epoch 32 - iter 1332/1480 - loss 0.08144338 - samples/sec: 142.63 - lr: 0.000015
2021-07-23 19:46:34,482 epoch 32 - iter 1480/1480 - loss 0.08063677 - samples/sec: 141.54 - lr: 0.000015
2021-07-23 19:46:34,484 ----------------------------------------------------------------------------------------------------
2021-07-23 19:46:34,484 EPOCH 32 done: loss 0.0806 - lr 0.0000150
2021-07-23 19:46:51,802 DEV : loss 0.12374643236398697 - score 0.9713
2021-07-23 19:46:51,986 BAD EPOCHS (no improvement): 1
2021-07-23 19:46:51,986 ----------------------------------------------------------------------------------------------------
2021-07-23 19:47:25,296 epoch 33 - iter 148/1480 - loss 0.07306636 - samples/sec: 142.22 - lr: 0.000015
2021-07-23 19:47:59,165 epoch 33 - iter 296/1480 - loss 0.07342703 - samples/sec: 139.87 - lr: 0.000015
2021-07-23 19:48:32,695 epoch 33 - iter 444/1480 - loss 0.07430283 - samples/sec: 141.28 - lr: 0.000015
2021-07-23 19:49:05,491 epoch 33 - iter 592/1480 - loss 0.07706913 - samples/sec: 144.44 - lr: 0.000015
2021-07-23 19:49:38,656 epoch 33 - iter 740/1480 - loss 0.07796140 - samples/sec: 142.83 - lr: 0.000015
2021-07-23 19:50:12,111 epoch 33 - iter 888/1480 - loss 0.07838580 - samples/sec: 141.60 - lr: 0.000015
2021-07-23 19:50:45,274 epoch 33 - iter 1036/1480 - loss 0.07978389 - samples/sec: 142.84 - lr: 0.000015
2021-07-23 19:51:18,762 epoch 33 - iter 1184/1480 - loss 0.08020705 - samples/sec: 141.46 - lr: 0.000015
2021-07-23 19:51:52,184 epoch 33 - iter 1332/1480 - loss 0.08021076 - samples/sec: 141.73 - lr: 0.000015
2021-07-23 19:52:25,423 epoch 33 - iter 1480/1480 - loss 0.08047179 - samples/sec: 142.51 - lr: 0.000015
2021-07-23 19:52:25,424 ----------------------------------------------------------------------------------------------------
2021-07-23 19:52:25,424 EPOCH 33 done: loss 0.0805 - lr 0.0000150
2021-07-23 19:52:42,711 DEV : loss 0.11974546313285828 - score 0.9717
2021-07-23 19:52:42,894 BAD EPOCHS (no improvement): 2
2021-07-23 19:52:42,895 ----------------------------------------------------------------------------------------------------
2021-07-23 19:53:16,383 epoch 34 - iter 148/1480 - loss 0.07230630 - samples/sec: 141.47 - lr: 0.000015
2021-07-23 19:53:49,581 epoch 34 - iter 296/1480 - loss 0.07640661 - samples/sec: 142.69 - lr: 0.000015
2021-07-23 19:54:22,931 epoch 34 - iter 444/1480 - loss 0.08107506 - samples/sec: 142.04 - lr: 0.000015
2021-07-23 19:54:56,215 epoch 34 - iter 592/1480 - loss 0.07936873 - samples/sec: 142.32 - lr: 0.000015
2021-07-23 19:55:29,572 epoch 34 - iter 740/1480 - loss 0.07925549 - samples/sec: 142.01 - lr: 0.000015
2021-07-23 19:56:03,402 epoch 34 - iter 888/1480 - loss 0.07750249 - samples/sec: 140.03 - lr: 0.000015
2021-07-23 19:56:36,753 epoch 34 - iter 1036/1480 - loss 0.07821035 - samples/sec: 142.04 - lr: 0.000015
2021-07-23 19:57:09,816 epoch 34 - iter 1184/1480 - loss 0.07862818 - samples/sec: 143.27 - lr: 0.000015
2021-07-23 19:57:42,976 epoch 34 - iter 1332/1480 - loss 0.07777364 - samples/sec: 142.86 - lr: 0.000015
2021-07-23 19:58:16,714 epoch 34 - iter 1480/1480 - loss 0.07783113 - samples/sec: 140.41 - lr: 0.000015
2021-07-23 19:58:16,716 ----------------------------------------------------------------------------------------------------
2021-07-23 19:58:16,716 EPOCH 34 done: loss 0.0778 - lr 0.0000150
2021-07-23 19:58:35,483 DEV : loss 0.12114614248275757 - score 0.9715
2021-07-23 19:58:35,670 BAD EPOCHS (no improvement): 3
2021-07-23 19:58:35,670 ----------------------------------------------------------------------------------------------------
2021-07-23 19:59:09,036 epoch 35 - iter 148/1480 - loss 0.07816264 - samples/sec: 141.99 - lr: 0.000015
2021-07-23 19:59:42,232 epoch 35 - iter 296/1480 - loss 0.08157203 - samples/sec: 142.70 - lr: 0.000015
2021-07-23 20:00:15,971 epoch 35 - iter 444/1480 - loss 0.07802641 - samples/sec: 140.40 - lr: 0.000015
2021-07-23 20:00:49,624 epoch 35 - iter 592/1480 - loss 0.07845090 - samples/sec: 140.76 - lr: 0.000015
2021-07-23 20:01:22,864 epoch 35 - iter 740/1480 - loss 0.07812516 - samples/sec: 142.51 - lr: 0.000015
2021-07-23 20:01:56,099 epoch 35 - iter 888/1480 - loss 0.07806522 - samples/sec: 142.53 - lr: 0.000015
2021-07-23 20:02:29,668 epoch 35 - iter 1036/1480 - loss 0.07860049 - samples/sec: 141.11 - lr: 0.000015
2021-07-23 20:03:03,077 epoch 35 - iter 1184/1480 - loss 0.07898887 - samples/sec: 141.79 - lr: 0.000015
2021-07-23 20:03:36,238 epoch 35 - iter 1332/1480 - loss 0.07881050 - samples/sec: 142.85 - lr: 0.000015
2021-07-23 20:04:09,747 epoch 35 - iter 1480/1480 - loss 0.07774086 - samples/sec: 141.37 - lr: 0.000015
2021-07-23 20:04:09,748 ----------------------------------------------------------------------------------------------------
2021-07-23 20:04:09,748 EPOCH 35 done: loss 0.0777 - lr 0.0000150
2021-07-23 20:04:27,039 DEV : loss 0.12164869904518127 - score 0.9706
Epoch    35: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 20:04:27,223 BAD EPOCHS (no improvement): 4
2021-07-23 20:04:27,223 ----------------------------------------------------------------------------------------------------
2021-07-23 20:05:00,560 epoch 36 - iter 148/1480 - loss 0.08784831 - samples/sec: 142.11 - lr: 0.000008
2021-07-23 20:05:34,240 epoch 36 - iter 296/1480 - loss 0.07920899 - samples/sec: 140.65 - lr: 0.000008
2021-07-23 20:06:07,692 epoch 36 - iter 444/1480 - loss 0.07871689 - samples/sec: 141.61 - lr: 0.000008
2021-07-23 20:06:40,592 epoch 36 - iter 592/1480 - loss 0.07673516 - samples/sec: 143.98 - lr: 0.000008
2021-07-23 20:07:13,976 epoch 36 - iter 740/1480 - loss 0.07443196 - samples/sec: 141.89 - lr: 0.000008
2021-07-23 20:07:47,187 epoch 36 - iter 888/1480 - loss 0.07481922 - samples/sec: 142.64 - lr: 0.000008
2021-07-23 20:08:20,930 epoch 36 - iter 1036/1480 - loss 0.07432436 - samples/sec: 140.38 - lr: 0.000008
2021-07-23 20:08:54,718 epoch 36 - iter 1184/1480 - loss 0.07547275 - samples/sec: 140.20 - lr: 0.000008
2021-07-23 20:09:28,024 epoch 36 - iter 1332/1480 - loss 0.07676753 - samples/sec: 142.23 - lr: 0.000008
2021-07-23 20:10:01,588 epoch 36 - iter 1480/1480 - loss 0.07644014 - samples/sec: 141.13 - lr: 0.000008
2021-07-23 20:10:01,590 ----------------------------------------------------------------------------------------------------
2021-07-23 20:10:01,590 EPOCH 36 done: loss 0.0764 - lr 0.0000075
2021-07-23 20:10:18,962 DEV : loss 0.12277550995349884 - score 0.9704
2021-07-23 20:10:19,148 BAD EPOCHS (no improvement): 1
2021-07-23 20:10:19,148 ----------------------------------------------------------------------------------------------------
2021-07-23 20:10:52,239 epoch 37 - iter 148/1480 - loss 0.08205187 - samples/sec: 143.16 - lr: 0.000008
2021-07-23 20:11:25,859 epoch 37 - iter 296/1480 - loss 0.07919447 - samples/sec: 140.90 - lr: 0.000008
2021-07-23 20:11:59,225 epoch 37 - iter 444/1480 - loss 0.08206288 - samples/sec: 141.97 - lr: 0.000008
2021-07-23 20:12:32,738 epoch 37 - iter 592/1480 - loss 0.08057273 - samples/sec: 141.35 - lr: 0.000008
2021-07-23 20:13:06,413 epoch 37 - iter 740/1480 - loss 0.07850375 - samples/sec: 140.67 - lr: 0.000008
2021-07-23 20:13:40,107 epoch 37 - iter 888/1480 - loss 0.07809357 - samples/sec: 140.59 - lr: 0.000008
2021-07-23 20:14:13,667 epoch 37 - iter 1036/1480 - loss 0.07867571 - samples/sec: 141.15 - lr: 0.000008
2021-07-23 20:14:46,963 epoch 37 - iter 1184/1480 - loss 0.07865931 - samples/sec: 142.27 - lr: 0.000008
2021-07-23 20:15:20,088 epoch 37 - iter 1332/1480 - loss 0.07732998 - samples/sec: 143.01 - lr: 0.000008
2021-07-23 20:15:53,327 epoch 37 - iter 1480/1480 - loss 0.07746530 - samples/sec: 142.52 - lr: 0.000008
2021-07-23 20:15:53,328 ----------------------------------------------------------------------------------------------------
2021-07-23 20:15:53,328 EPOCH 37 done: loss 0.0775 - lr 0.0000075
2021-07-23 20:16:10,617 DEV : loss 0.12297270447015762 - score 0.9715
2021-07-23 20:16:10,803 BAD EPOCHS (no improvement): 2
2021-07-23 20:16:10,803 ----------------------------------------------------------------------------------------------------
2021-07-23 20:16:44,268 epoch 38 - iter 148/1480 - loss 0.07514521 - samples/sec: 141.57 - lr: 0.000008
2021-07-23 20:17:17,761 epoch 38 - iter 296/1480 - loss 0.07414537 - samples/sec: 141.44 - lr: 0.000008
2021-07-23 20:17:51,371 epoch 38 - iter 444/1480 - loss 0.07542161 - samples/sec: 140.94 - lr: 0.000008
2021-07-23 20:18:24,981 epoch 38 - iter 592/1480 - loss 0.07656838 - samples/sec: 140.94 - lr: 0.000008
2021-07-23 20:18:57,912 epoch 38 - iter 740/1480 - loss 0.07688923 - samples/sec: 143.85 - lr: 0.000008
2021-07-23 20:19:31,148 epoch 38 - iter 888/1480 - loss 0.07663070 - samples/sec: 142.53 - lr: 0.000008
2021-07-23 20:20:04,565 epoch 38 - iter 1036/1480 - loss 0.07566848 - samples/sec: 141.75 - lr: 0.000008
2021-07-23 20:20:37,756 epoch 38 - iter 1184/1480 - loss 0.07484714 - samples/sec: 142.72 - lr: 0.000008
2021-07-23 20:21:11,399 epoch 38 - iter 1332/1480 - loss 0.07577798 - samples/sec: 140.80 - lr: 0.000008
2021-07-23 20:21:44,668 epoch 38 - iter 1480/1480 - loss 0.07598248 - samples/sec: 142.39 - lr: 0.000008
2021-07-23 20:21:44,670 ----------------------------------------------------------------------------------------------------
2021-07-23 20:21:44,670 EPOCH 38 done: loss 0.0760 - lr 0.0000075
2021-07-23 20:22:01,988 DEV : loss 0.12252403050661087 - score 0.971
2021-07-23 20:22:02,176 BAD EPOCHS (no improvement): 3
2021-07-23 20:22:02,176 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:35,398 epoch 39 - iter 148/1480 - loss 0.07956902 - samples/sec: 142.61 - lr: 0.000008
2021-07-23 20:23:08,575 epoch 39 - iter 296/1480 - loss 0.07486383 - samples/sec: 142.78 - lr: 0.000008
2021-07-23 20:23:42,114 epoch 39 - iter 444/1480 - loss 0.07532072 - samples/sec: 141.24 - lr: 0.000008
2021-07-23 20:24:15,483 epoch 39 - iter 592/1480 - loss 0.07590883 - samples/sec: 141.96 - lr: 0.000008
2021-07-23 20:24:48,951 epoch 39 - iter 740/1480 - loss 0.07620693 - samples/sec: 141.54 - lr: 0.000008
2021-07-23 20:25:22,224 epoch 39 - iter 888/1480 - loss 0.07561760 - samples/sec: 142.37 - lr: 0.000008
2021-07-23 20:25:55,724 epoch 39 - iter 1036/1480 - loss 0.07446388 - samples/sec: 141.41 - lr: 0.000008
2021-07-23 20:26:29,057 epoch 39 - iter 1184/1480 - loss 0.07475022 - samples/sec: 142.11 - lr: 0.000008
2021-07-23 20:27:02,884 epoch 39 - iter 1332/1480 - loss 0.07540118 - samples/sec: 140.04 - lr: 0.000008
2021-07-23 20:27:36,427 epoch 39 - iter 1480/1480 - loss 0.07559517 - samples/sec: 141.22 - lr: 0.000008
2021-07-23 20:27:36,429 ----------------------------------------------------------------------------------------------------
2021-07-23 20:27:36,429 EPOCH 39 done: loss 0.0756 - lr 0.0000075
2021-07-23 20:27:55,098 DEV : loss 0.12282402068376541 - score 0.9712
Epoch    39: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 20:27:55,283 BAD EPOCHS (no improvement): 4
2021-07-23 20:27:55,283 ----------------------------------------------------------------------------------------------------
2021-07-23 20:28:28,774 epoch 40 - iter 148/1480 - loss 0.07125147 - samples/sec: 141.46 - lr: 0.000004
2021-07-23 20:29:02,886 epoch 40 - iter 296/1480 - loss 0.07203195 - samples/sec: 138.87 - lr: 0.000004
2021-07-23 20:29:36,039 epoch 40 - iter 444/1480 - loss 0.07145539 - samples/sec: 142.89 - lr: 0.000004
2021-07-23 20:30:09,064 epoch 40 - iter 592/1480 - loss 0.07177326 - samples/sec: 143.44 - lr: 0.000004
2021-07-23 20:30:42,429 epoch 40 - iter 740/1480 - loss 0.07436934 - samples/sec: 141.98 - lr: 0.000004
2021-07-23 20:31:15,943 epoch 40 - iter 888/1480 - loss 0.07420519 - samples/sec: 141.35 - lr: 0.000004
2021-07-23 20:31:49,291 epoch 40 - iter 1036/1480 - loss 0.07403231 - samples/sec: 142.05 - lr: 0.000004
2021-07-23 20:32:22,773 epoch 40 - iter 1184/1480 - loss 0.07358046 - samples/sec: 141.48 - lr: 0.000004
2021-07-23 20:32:56,351 epoch 40 - iter 1332/1480 - loss 0.07429974 - samples/sec: 141.07 - lr: 0.000004
2021-07-23 20:33:29,303 epoch 40 - iter 1480/1480 - loss 0.07435629 - samples/sec: 143.76 - lr: 0.000004
2021-07-23 20:33:29,304 ----------------------------------------------------------------------------------------------------
2021-07-23 20:33:29,304 EPOCH 40 done: loss 0.0744 - lr 0.0000038
2021-07-23 20:33:46,614 DEV : loss 0.12306615710258484 - score 0.9711
2021-07-23 20:33:46,798 BAD EPOCHS (no improvement): 1
2021-07-23 20:33:47,400 ----------------------------------------------------------------------------------------------------
2021-07-23 20:33:47,400 Testing using best model ...
2021-07-23 20:33:47,401 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/tur.pdtb.tdb/best-model.pt
2021-07-23 20:36:50,533 0.9751	0.9795	0.9773
2021-07-23 20:36:50,533 
Results:
- F1-score (micro) 0.9773
- F1-score (macro) 0.9785

By class:
SENT       tp: 4804 - fp: 237 - fn: 194 - precision: 0.9530 - recall: 0.9612 - f1-score: 0.9571
X          tp: 4460 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 20:36:50,533 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/por.rst.cstn/
2021-07-23 20:36:50,561 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/por.rst.cstn
2021-07-23 20:36:50,562 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/por.rst.cstn/sent_train.txt
2021-07-23 20:36:50,564 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/por.rst.cstn/sent_dev.txt
2021-07-23 20:36:50,566 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/por.rst.cstn/sent_test.txt
Corpus: 5076 train + 859 dev + 1271 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 20:36:58,922 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:58,924 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 20:36:58,924 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:58,924 Corpus: "Corpus: 5076 train + 859 dev + 1271 test sentences"
2021-07-23 20:36:58,924 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:58,924 Parameters:
2021-07-23 20:36:58,924  - learning_rate: "3e-05"
2021-07-23 20:36:58,924  - mini_batch_size: "32"
2021-07-23 20:36:58,924  - patience: "3"
2021-07-23 20:36:58,924  - anneal_factor: "0.5"
2021-07-23 20:36:58,924  - max_epochs: "40"
2021-07-23 20:36:58,924  - shuffle: "True"
2021-07-23 20:36:58,924  - train_with_dev: "False"
2021-07-23 20:36:58,924  - batch_growth_annealing: "False"
2021-07-23 20:36:58,924 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:58,925 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/por.rst.cstn"
2021-07-23 20:36:58,925 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:58,925 Device: cuda:0
2021-07-23 20:36:58,925 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:58,925 Embeddings storage mode: cpu
2021-07-23 20:36:58,927 ----------------------------------------------------------------------------------------------------
2021-07-23 20:37:08,360 epoch 1 - iter 15/159 - loss 17.58417498 - samples/sec: 50.90 - lr: 0.000030
2021-07-23 20:37:17,526 epoch 1 - iter 30/159 - loss 15.06853800 - samples/sec: 52.37 - lr: 0.000030
2021-07-23 20:37:26,850 epoch 1 - iter 45/159 - loss 13.01697144 - samples/sec: 51.48 - lr: 0.000030
2021-07-23 20:37:36,096 epoch 1 - iter 60/159 - loss 11.06378379 - samples/sec: 51.92 - lr: 0.000030
2021-07-23 20:37:45,356 epoch 1 - iter 75/159 - loss 9.46561147 - samples/sec: 51.84 - lr: 0.000030
2021-07-23 20:37:54,701 epoch 1 - iter 90/159 - loss 8.21645724 - samples/sec: 51.37 - lr: 0.000030
2021-07-23 20:38:04,014 epoch 1 - iter 105/159 - loss 7.25265166 - samples/sec: 51.54 - lr: 0.000030
2021-07-23 20:38:13,411 epoch 1 - iter 120/159 - loss 6.49839360 - samples/sec: 51.08 - lr: 0.000030
2021-07-23 20:38:22,634 epoch 1 - iter 135/159 - loss 5.89951490 - samples/sec: 52.05 - lr: 0.000030
2021-07-23 20:38:31,978 epoch 1 - iter 150/159 - loss 5.39738561 - samples/sec: 51.38 - lr: 0.000030
2021-07-23 20:38:37,328 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:37,328 EPOCH 1 done: loss 5.1390 - lr 0.0000300
2021-07-23 20:38:49,161 DEV : loss 0.7075148820877075 - score 0.6968
2021-07-23 20:38:49,187 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:38:50,638 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:54,431 epoch 2 - iter 15/159 - loss 0.78303577 - samples/sec: 126.61 - lr: 0.000030
2021-07-23 20:38:58,237 epoch 2 - iter 30/159 - loss 0.72778298 - samples/sec: 126.17 - lr: 0.000030
2021-07-23 20:39:01,833 epoch 2 - iter 45/159 - loss 0.69429129 - samples/sec: 133.52 - lr: 0.000030
2021-07-23 20:39:05,556 epoch 2 - iter 60/159 - loss 0.68532237 - samples/sec: 128.93 - lr: 0.000030
2021-07-23 20:39:09,313 epoch 2 - iter 75/159 - loss 0.66226524 - samples/sec: 127.81 - lr: 0.000030
2021-07-23 20:39:13,196 epoch 2 - iter 90/159 - loss 0.64594025 - samples/sec: 123.65 - lr: 0.000030
2021-07-23 20:39:16,995 epoch 2 - iter 105/159 - loss 0.62103278 - samples/sec: 126.37 - lr: 0.000030
2021-07-23 20:39:20,599 epoch 2 - iter 120/159 - loss 0.59925122 - samples/sec: 133.23 - lr: 0.000030
2021-07-23 20:39:24,390 epoch 2 - iter 135/159 - loss 0.58149687 - samples/sec: 126.65 - lr: 0.000030
2021-07-23 20:39:28,884 epoch 2 - iter 150/159 - loss 0.56252939 - samples/sec: 127.69 - lr: 0.000030
2021-07-23 20:39:31,079 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:31,079 EPOCH 2 done: loss 0.5534 - lr 0.0000300
2021-07-23 20:39:33,270 DEV : loss 0.27278321981430054 - score 0.918
2021-07-23 20:39:33,296 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:39:37,723 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:41,422 epoch 3 - iter 15/159 - loss 0.32924962 - samples/sec: 129.86 - lr: 0.000030
2021-07-23 20:39:45,347 epoch 3 - iter 30/159 - loss 0.34410936 - samples/sec: 122.33 - lr: 0.000030
2021-07-23 20:39:48,910 epoch 3 - iter 45/159 - loss 0.33635375 - samples/sec: 134.75 - lr: 0.000030
2021-07-23 20:39:52,640 epoch 3 - iter 60/159 - loss 0.32022696 - samples/sec: 128.70 - lr: 0.000030
2021-07-23 20:39:56,418 epoch 3 - iter 75/159 - loss 0.31762906 - samples/sec: 127.08 - lr: 0.000030
2021-07-23 20:40:00,083 epoch 3 - iter 90/159 - loss 0.30964384 - samples/sec: 131.03 - lr: 0.000030
2021-07-23 20:40:03,905 epoch 3 - iter 105/159 - loss 0.29872074 - samples/sec: 125.61 - lr: 0.000030
2021-07-23 20:40:07,953 epoch 3 - iter 120/159 - loss 0.29379771 - samples/sec: 118.61 - lr: 0.000030
2021-07-23 20:40:11,764 epoch 3 - iter 135/159 - loss 0.29066223 - samples/sec: 125.97 - lr: 0.000030
2021-07-23 20:40:15,408 epoch 3 - iter 150/159 - loss 0.28439535 - samples/sec: 131.77 - lr: 0.000030
2021-07-23 20:40:17,541 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:17,541 EPOCH 3 done: loss 0.2802 - lr 0.0000300
2021-07-23 20:40:19,687 DEV : loss 0.12144570797681808 - score 0.9761
2021-07-23 20:40:19,714 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:40:24,864 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:28,608 epoch 4 - iter 15/159 - loss 0.23510684 - samples/sec: 128.32 - lr: 0.000030
2021-07-23 20:40:32,482 epoch 4 - iter 30/159 - loss 0.23317454 - samples/sec: 123.92 - lr: 0.000030
2021-07-23 20:40:36,163 epoch 4 - iter 45/159 - loss 0.23030769 - samples/sec: 130.44 - lr: 0.000030
2021-07-23 20:40:39,873 epoch 4 - iter 60/159 - loss 0.21804293 - samples/sec: 129.41 - lr: 0.000030
2021-07-23 20:40:43,660 epoch 4 - iter 75/159 - loss 0.21240743 - samples/sec: 126.79 - lr: 0.000030
2021-07-23 20:40:47,353 epoch 4 - iter 90/159 - loss 0.21111934 - samples/sec: 130.00 - lr: 0.000030
2021-07-23 20:40:51,177 epoch 4 - iter 105/159 - loss 0.20596928 - samples/sec: 125.57 - lr: 0.000030
2021-07-23 20:40:54,995 epoch 4 - iter 120/159 - loss 0.20403875 - samples/sec: 125.73 - lr: 0.000030
2021-07-23 20:40:58,663 epoch 4 - iter 135/159 - loss 0.19770736 - samples/sec: 130.89 - lr: 0.000030
2021-07-23 20:41:02,417 epoch 4 - iter 150/159 - loss 0.19372629 - samples/sec: 127.92 - lr: 0.000030
2021-07-23 20:41:04,680 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:04,680 EPOCH 4 done: loss 0.1912 - lr 0.0000300
2021-07-23 20:41:06,849 DEV : loss 0.07646659016609192 - score 0.9833
2021-07-23 20:41:06,876 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:41:11,427 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:15,243 epoch 5 - iter 15/159 - loss 0.18356593 - samples/sec: 125.90 - lr: 0.000030
2021-07-23 20:41:18,987 epoch 5 - iter 30/159 - loss 0.18191059 - samples/sec: 128.25 - lr: 0.000030
2021-07-23 20:41:22,708 epoch 5 - iter 45/159 - loss 0.16769826 - samples/sec: 129.03 - lr: 0.000030
2021-07-23 20:41:26,382 epoch 5 - iter 60/159 - loss 0.16653014 - samples/sec: 130.67 - lr: 0.000030
2021-07-23 20:41:30,111 epoch 5 - iter 75/159 - loss 0.16071107 - samples/sec: 128.75 - lr: 0.000030
2021-07-23 20:41:34,012 epoch 5 - iter 90/159 - loss 0.15765312 - samples/sec: 123.10 - lr: 0.000030
2021-07-23 20:41:37,806 epoch 5 - iter 105/159 - loss 0.15520179 - samples/sec: 126.52 - lr: 0.000030
2021-07-23 20:41:41,487 epoch 5 - iter 120/159 - loss 0.15790138 - samples/sec: 130.45 - lr: 0.000030
2021-07-23 20:41:45,380 epoch 5 - iter 135/159 - loss 0.15518772 - samples/sec: 123.34 - lr: 0.000030
2021-07-23 20:41:49,189 epoch 5 - iter 150/159 - loss 0.15432007 - samples/sec: 126.05 - lr: 0.000030
2021-07-23 20:41:51,223 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:51,223 EPOCH 5 done: loss 0.1514 - lr 0.0000300
2021-07-23 20:41:53,377 DEV : loss 0.059368591755628586 - score 0.9878
2021-07-23 20:41:53,404 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:41:57,960 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:01,924 epoch 6 - iter 15/159 - loss 0.13627061 - samples/sec: 121.20 - lr: 0.000030
2021-07-23 20:42:05,779 epoch 6 - iter 30/159 - loss 0.13753636 - samples/sec: 124.54 - lr: 0.000030
2021-07-23 20:42:09,568 epoch 6 - iter 45/159 - loss 0.14004232 - samples/sec: 126.71 - lr: 0.000030
2021-07-23 20:42:13,262 epoch 6 - iter 60/159 - loss 0.13620308 - samples/sec: 130.00 - lr: 0.000030
2021-07-23 20:42:16,947 epoch 6 - iter 75/159 - loss 0.13200578 - samples/sec: 130.28 - lr: 0.000030
2021-07-23 20:42:20,836 epoch 6 - iter 90/159 - loss 0.13268933 - samples/sec: 123.46 - lr: 0.000030
2021-07-23 20:42:24,688 epoch 6 - iter 105/159 - loss 0.13633133 - samples/sec: 124.64 - lr: 0.000030
2021-07-23 20:42:28,524 epoch 6 - iter 120/159 - loss 0.13616616 - samples/sec: 125.16 - lr: 0.000030
2021-07-23 20:42:32,200 epoch 6 - iter 135/159 - loss 0.13566840 - samples/sec: 130.61 - lr: 0.000030
2021-07-23 20:42:35,882 epoch 6 - iter 150/159 - loss 0.13431908 - samples/sec: 130.42 - lr: 0.000030
2021-07-23 20:42:38,015 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:38,015 EPOCH 6 done: loss 0.1351 - lr 0.0000300
2021-07-23 20:42:40,178 DEV : loss 0.04917510226368904 - score 0.9896
2021-07-23 20:42:40,205 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:42:45,235 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:49,112 epoch 7 - iter 15/159 - loss 0.15380109 - samples/sec: 123.90 - lr: 0.000030
2021-07-23 20:42:53,067 epoch 7 - iter 30/159 - loss 0.13869356 - samples/sec: 121.39 - lr: 0.000030
2021-07-23 20:42:56,916 epoch 7 - iter 45/159 - loss 0.13718576 - samples/sec: 124.75 - lr: 0.000030
2021-07-23 20:43:00,624 epoch 7 - iter 60/159 - loss 0.13774183 - samples/sec: 129.47 - lr: 0.000030
2021-07-23 20:43:04,338 epoch 7 - iter 75/159 - loss 0.13470817 - samples/sec: 129.26 - lr: 0.000030
2021-07-23 20:43:08,184 epoch 7 - iter 90/159 - loss 0.13007600 - samples/sec: 124.85 - lr: 0.000030
2021-07-23 20:43:11,883 epoch 7 - iter 105/159 - loss 0.12518066 - samples/sec: 129.80 - lr: 0.000030
2021-07-23 20:43:15,668 epoch 7 - iter 120/159 - loss 0.12328568 - samples/sec: 126.86 - lr: 0.000030
2021-07-23 20:43:19,505 epoch 7 - iter 135/159 - loss 0.12435828 - samples/sec: 125.11 - lr: 0.000030
2021-07-23 20:43:23,248 epoch 7 - iter 150/159 - loss 0.12230031 - samples/sec: 128.29 - lr: 0.000030
2021-07-23 20:43:25,460 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:25,461 EPOCH 7 done: loss 0.1225 - lr 0.0000300
2021-07-23 20:43:27,621 DEV : loss 0.0440550297498703 - score 0.9904
2021-07-23 20:43:27,648 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:43:32,791 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:36,740 epoch 8 - iter 15/159 - loss 0.10220926 - samples/sec: 121.61 - lr: 0.000030
2021-07-23 20:43:40,513 epoch 8 - iter 30/159 - loss 0.09723383 - samples/sec: 127.25 - lr: 0.000030
2021-07-23 20:43:44,174 epoch 8 - iter 45/159 - loss 0.10676435 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 20:43:47,911 epoch 8 - iter 60/159 - loss 0.10421121 - samples/sec: 128.49 - lr: 0.000030
2021-07-23 20:43:51,740 epoch 8 - iter 75/159 - loss 0.10459295 - samples/sec: 125.40 - lr: 0.000030
2021-07-23 20:43:55,632 epoch 8 - iter 90/159 - loss 0.10347918 - samples/sec: 123.35 - lr: 0.000030
2021-07-23 20:43:59,328 epoch 8 - iter 105/159 - loss 0.10723153 - samples/sec: 129.92 - lr: 0.000030
2021-07-23 20:44:03,092 epoch 8 - iter 120/159 - loss 0.10903936 - samples/sec: 127.55 - lr: 0.000030
2021-07-23 20:44:06,908 epoch 8 - iter 135/159 - loss 0.10891386 - samples/sec: 125.80 - lr: 0.000030
2021-07-23 20:44:10,708 epoch 8 - iter 150/159 - loss 0.11085036 - samples/sec: 126.36 - lr: 0.000030
2021-07-23 20:44:12,877 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:12,877 EPOCH 8 done: loss 0.1131 - lr 0.0000300
2021-07-23 20:44:15,023 DEV : loss 0.0389142706990242 - score 0.9904
2021-07-23 20:44:15,050 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:44:19,721 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:23,544 epoch 9 - iter 15/159 - loss 0.10607242 - samples/sec: 125.64 - lr: 0.000030
2021-07-23 20:44:27,381 epoch 9 - iter 30/159 - loss 0.11105243 - samples/sec: 125.15 - lr: 0.000030
2021-07-23 20:44:31,264 epoch 9 - iter 45/159 - loss 0.10473246 - samples/sec: 123.65 - lr: 0.000030
2021-07-23 20:44:34,976 epoch 9 - iter 60/159 - loss 0.09853032 - samples/sec: 129.32 - lr: 0.000030
2021-07-23 20:44:38,535 epoch 9 - iter 75/159 - loss 0.10371050 - samples/sec: 134.91 - lr: 0.000030
2021-07-23 20:44:42,392 epoch 9 - iter 90/159 - loss 0.10153633 - samples/sec: 124.50 - lr: 0.000030
2021-07-23 20:44:46,207 epoch 9 - iter 105/159 - loss 0.10141704 - samples/sec: 125.84 - lr: 0.000030
2021-07-23 20:44:50,032 epoch 9 - iter 120/159 - loss 0.10144053 - samples/sec: 125.52 - lr: 0.000030
2021-07-23 20:44:53,829 epoch 9 - iter 135/159 - loss 0.10161290 - samples/sec: 126.45 - lr: 0.000030
2021-07-23 20:44:57,616 epoch 9 - iter 150/159 - loss 0.10529481 - samples/sec: 126.78 - lr: 0.000030
2021-07-23 20:44:59,787 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:59,787 EPOCH 9 done: loss 0.1046 - lr 0.0000300
2021-07-23 20:45:01,977 DEV : loss 0.040253568440675735 - score 0.9912
2021-07-23 20:45:02,004 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:45:06,771 ----------------------------------------------------------------------------------------------------
2021-07-23 20:45:10,615 epoch 10 - iter 15/159 - loss 0.10574795 - samples/sec: 124.97 - lr: 0.000030
2021-07-23 20:45:14,299 epoch 10 - iter 30/159 - loss 0.10374660 - samples/sec: 130.32 - lr: 0.000030
2021-07-23 20:45:18,204 epoch 10 - iter 45/159 - loss 0.10714885 - samples/sec: 122.96 - lr: 0.000030
2021-07-23 20:45:21,971 epoch 10 - iter 60/159 - loss 0.10714142 - samples/sec: 127.46 - lr: 0.000030
2021-07-23 20:45:25,676 epoch 10 - iter 75/159 - loss 0.10241498 - samples/sec: 129.60 - lr: 0.000030
2021-07-23 20:45:29,501 epoch 10 - iter 90/159 - loss 0.10591141 - samples/sec: 125.51 - lr: 0.000030
2021-07-23 20:45:33,303 epoch 10 - iter 105/159 - loss 0.10427725 - samples/sec: 126.28 - lr: 0.000030
2021-07-23 20:45:37,056 epoch 10 - iter 120/159 - loss 0.10321126 - samples/sec: 127.93 - lr: 0.000030
2021-07-23 20:45:40,812 epoch 10 - iter 135/159 - loss 0.10226044 - samples/sec: 127.82 - lr: 0.000030
2021-07-23 20:45:44,535 epoch 10 - iter 150/159 - loss 0.10237160 - samples/sec: 128.95 - lr: 0.000030
2021-07-23 20:45:46,812 ----------------------------------------------------------------------------------------------------
2021-07-23 20:45:46,813 EPOCH 10 done: loss 0.1026 - lr 0.0000300
2021-07-23 20:45:48,986 DEV : loss 0.035983629524707794 - score 0.9912
2021-07-23 20:45:49,012 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:45:53,751 ----------------------------------------------------------------------------------------------------
2021-07-23 20:45:57,464 epoch 11 - iter 15/159 - loss 0.07796661 - samples/sec: 129.39 - lr: 0.000030
2021-07-23 20:46:01,180 epoch 11 - iter 30/159 - loss 0.08020694 - samples/sec: 129.18 - lr: 0.000030
2021-07-23 20:46:05,024 epoch 11 - iter 45/159 - loss 0.08201893 - samples/sec: 124.92 - lr: 0.000030
2021-07-23 20:46:08,722 epoch 11 - iter 60/159 - loss 0.08080708 - samples/sec: 129.83 - lr: 0.000030
2021-07-23 20:46:12,495 epoch 11 - iter 75/159 - loss 0.08331542 - samples/sec: 127.24 - lr: 0.000030
2021-07-23 20:46:16,383 epoch 11 - iter 90/159 - loss 0.08244081 - samples/sec: 123.49 - lr: 0.000030
2021-07-23 20:46:20,296 epoch 11 - iter 105/159 - loss 0.08193683 - samples/sec: 122.70 - lr: 0.000030
2021-07-23 20:46:23,900 epoch 11 - iter 120/159 - loss 0.08018422 - samples/sec: 133.22 - lr: 0.000030
2021-07-23 20:46:27,607 epoch 11 - iter 135/159 - loss 0.08359218 - samples/sec: 129.52 - lr: 0.000030
2021-07-23 20:46:31,503 epoch 11 - iter 150/159 - loss 0.08404121 - samples/sec: 123.23 - lr: 0.000030
2021-07-23 20:46:33,711 ----------------------------------------------------------------------------------------------------
2021-07-23 20:46:33,711 EPOCH 11 done: loss 0.0853 - lr 0.0000300
2021-07-23 20:46:35,890 DEV : loss 0.033054906874895096 - score 0.9913
2021-07-23 20:46:35,917 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:46:40,501 ----------------------------------------------------------------------------------------------------
2021-07-23 20:46:44,491 epoch 12 - iter 15/159 - loss 0.11236672 - samples/sec: 120.39 - lr: 0.000030
2021-07-23 20:46:48,345 epoch 12 - iter 30/159 - loss 0.10408830 - samples/sec: 124.57 - lr: 0.000030
2021-07-23 20:46:52,148 epoch 12 - iter 45/159 - loss 0.08861662 - samples/sec: 126.25 - lr: 0.000030
2021-07-23 20:46:55,840 epoch 12 - iter 60/159 - loss 0.09215101 - samples/sec: 130.03 - lr: 0.000030
2021-07-23 20:46:59,596 epoch 12 - iter 75/159 - loss 0.09715516 - samples/sec: 127.82 - lr: 0.000030
2021-07-23 20:47:03,358 epoch 12 - iter 90/159 - loss 0.09388686 - samples/sec: 127.62 - lr: 0.000030
2021-07-23 20:47:07,135 epoch 12 - iter 105/159 - loss 0.09055727 - samples/sec: 127.13 - lr: 0.000030
2021-07-23 20:47:10,903 epoch 12 - iter 120/159 - loss 0.08763511 - samples/sec: 127.40 - lr: 0.000030
2021-07-23 20:47:14,592 epoch 12 - iter 135/159 - loss 0.08943699 - samples/sec: 130.17 - lr: 0.000030
2021-07-23 20:47:18,314 epoch 12 - iter 150/159 - loss 0.08785987 - samples/sec: 129.00 - lr: 0.000030
2021-07-23 20:47:20,559 ----------------------------------------------------------------------------------------------------
2021-07-23 20:47:20,559 EPOCH 12 done: loss 0.0889 - lr 0.0000300
2021-07-23 20:47:22,737 DEV : loss 0.03265451639890671 - score 0.9921
2021-07-23 20:47:22,763 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:47:27,317 ----------------------------------------------------------------------------------------------------
2021-07-23 20:47:31,063 epoch 13 - iter 15/159 - loss 0.10593153 - samples/sec: 128.25 - lr: 0.000030
2021-07-23 20:47:34,896 epoch 13 - iter 30/159 - loss 0.10079753 - samples/sec: 125.26 - lr: 0.000030
2021-07-23 20:47:38,663 epoch 13 - iter 45/159 - loss 0.09397282 - samples/sec: 127.47 - lr: 0.000030
2021-07-23 20:47:42,367 epoch 13 - iter 60/159 - loss 0.09791345 - samples/sec: 129.60 - lr: 0.000030
2021-07-23 20:47:46,079 epoch 13 - iter 75/159 - loss 0.09797180 - samples/sec: 129.35 - lr: 0.000030
2021-07-23 20:47:49,755 epoch 13 - iter 90/159 - loss 0.09497242 - samples/sec: 130.62 - lr: 0.000030
2021-07-23 20:47:53,363 epoch 13 - iter 105/159 - loss 0.08882397 - samples/sec: 133.06 - lr: 0.000030
2021-07-23 20:47:57,148 epoch 13 - iter 120/159 - loss 0.08780885 - samples/sec: 126.85 - lr: 0.000030
2021-07-23 20:48:01,003 epoch 13 - iter 135/159 - loss 0.08824291 - samples/sec: 124.55 - lr: 0.000030
2021-07-23 20:48:04,828 epoch 13 - iter 150/159 - loss 0.08676090 - samples/sec: 125.51 - lr: 0.000030
2021-07-23 20:48:07,108 ----------------------------------------------------------------------------------------------------
2021-07-23 20:48:07,108 EPOCH 13 done: loss 0.0860 - lr 0.0000300
2021-07-23 20:48:09,285 DEV : loss 0.032602615654468536 - score 0.9921
2021-07-23 20:48:09,312 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:48:13,709 ----------------------------------------------------------------------------------------------------
2021-07-23 20:48:17,559 epoch 14 - iter 15/159 - loss 0.09401329 - samples/sec: 124.78 - lr: 0.000030
2021-07-23 20:48:21,380 epoch 14 - iter 30/159 - loss 0.09653794 - samples/sec: 125.66 - lr: 0.000030
2021-07-23 20:48:25,147 epoch 14 - iter 45/159 - loss 0.09721345 - samples/sec: 127.44 - lr: 0.000030
2021-07-23 20:48:28,830 epoch 14 - iter 60/159 - loss 0.09944839 - samples/sec: 130.36 - lr: 0.000030
2021-07-23 20:48:32,632 epoch 14 - iter 75/159 - loss 0.10057188 - samples/sec: 126.29 - lr: 0.000030
2021-07-23 20:48:36,355 epoch 14 - iter 90/159 - loss 0.09319059 - samples/sec: 128.95 - lr: 0.000030
2021-07-23 20:48:40,096 epoch 14 - iter 105/159 - loss 0.09079242 - samples/sec: 128.34 - lr: 0.000030
2021-07-23 20:48:43,788 epoch 14 - iter 120/159 - loss 0.08934309 - samples/sec: 130.05 - lr: 0.000030
2021-07-23 20:48:47,612 epoch 14 - iter 135/159 - loss 0.08854941 - samples/sec: 125.56 - lr: 0.000030
2021-07-23 20:48:51,340 epoch 14 - iter 150/159 - loss 0.08913576 - samples/sec: 128.78 - lr: 0.000030
2021-07-23 20:48:53,523 ----------------------------------------------------------------------------------------------------
2021-07-23 20:48:53,523 EPOCH 14 done: loss 0.0906 - lr 0.0000300
2021-07-23 20:48:55,696 DEV : loss 0.033943574875593185 - score 0.993
2021-07-23 20:48:55,723 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:49:00,545 ----------------------------------------------------------------------------------------------------
2021-07-23 20:49:04,373 epoch 15 - iter 15/159 - loss 0.07277553 - samples/sec: 125.49 - lr: 0.000030
2021-07-23 20:49:08,043 epoch 15 - iter 30/159 - loss 0.08150618 - samples/sec: 130.81 - lr: 0.000030
2021-07-23 20:49:11,804 epoch 15 - iter 45/159 - loss 0.08315909 - samples/sec: 127.68 - lr: 0.000030
2021-07-23 20:49:15,700 epoch 15 - iter 60/159 - loss 0.08428287 - samples/sec: 123.21 - lr: 0.000030
2021-07-23 20:49:19,275 epoch 15 - iter 75/159 - loss 0.08015287 - samples/sec: 134.33 - lr: 0.000030
2021-07-23 20:49:22,998 epoch 15 - iter 90/159 - loss 0.08474450 - samples/sec: 128.95 - lr: 0.000030
2021-07-23 20:49:26,717 epoch 15 - iter 105/159 - loss 0.08172820 - samples/sec: 129.11 - lr: 0.000030
2021-07-23 20:49:30,671 epoch 15 - iter 120/159 - loss 0.08377436 - samples/sec: 121.41 - lr: 0.000030
2021-07-23 20:49:34,468 epoch 15 - iter 135/159 - loss 0.08536398 - samples/sec: 126.43 - lr: 0.000030
2021-07-23 20:49:38,261 epoch 15 - iter 150/159 - loss 0.08628792 - samples/sec: 126.60 - lr: 0.000030
2021-07-23 20:49:40,539 ----------------------------------------------------------------------------------------------------
2021-07-23 20:49:40,540 EPOCH 15 done: loss 0.0867 - lr 0.0000300
2021-07-23 20:49:42,715 DEV : loss 0.037573009729385376 - score 0.9921
2021-07-23 20:49:42,742 BAD EPOCHS (no improvement): 1
2021-07-23 20:49:42,742 ----------------------------------------------------------------------------------------------------
2021-07-23 20:49:46,591 epoch 16 - iter 15/159 - loss 0.10277451 - samples/sec: 124.78 - lr: 0.000030
2021-07-23 20:49:50,255 epoch 16 - iter 30/159 - loss 0.08810678 - samples/sec: 131.03 - lr: 0.000030
2021-07-23 20:49:53,908 epoch 16 - iter 45/159 - loss 0.08526969 - samples/sec: 131.42 - lr: 0.000030
2021-07-23 20:49:57,640 epoch 16 - iter 60/159 - loss 0.08113912 - samples/sec: 128.66 - lr: 0.000030
2021-07-23 20:50:01,548 epoch 16 - iter 75/159 - loss 0.08247972 - samples/sec: 122.84 - lr: 0.000030
2021-07-23 20:50:05,285 epoch 16 - iter 90/159 - loss 0.08031192 - samples/sec: 128.49 - lr: 0.000030
2021-07-23 20:50:09,215 epoch 16 - iter 105/159 - loss 0.07818978 - samples/sec: 122.17 - lr: 0.000030
2021-07-23 20:50:12,980 epoch 16 - iter 120/159 - loss 0.08281846 - samples/sec: 127.54 - lr: 0.000030
2021-07-23 20:50:16,795 epoch 16 - iter 135/159 - loss 0.08069891 - samples/sec: 125.83 - lr: 0.000030
2021-07-23 20:50:20,584 epoch 16 - iter 150/159 - loss 0.08265941 - samples/sec: 126.72 - lr: 0.000030
2021-07-23 20:50:22,761 ----------------------------------------------------------------------------------------------------
2021-07-23 20:50:22,761 EPOCH 16 done: loss 0.0848 - lr 0.0000300
2021-07-23 20:50:25,156 DEV : loss 0.034112267196178436 - score 0.9912
2021-07-23 20:50:25,182 BAD EPOCHS (no improvement): 2
2021-07-23 20:50:25,183 ----------------------------------------------------------------------------------------------------
2021-07-23 20:50:29,133 epoch 17 - iter 15/159 - loss 0.07301191 - samples/sec: 121.57 - lr: 0.000030
2021-07-23 20:50:32,939 epoch 17 - iter 30/159 - loss 0.06785540 - samples/sec: 126.14 - lr: 0.000030
2021-07-23 20:50:36,733 epoch 17 - iter 45/159 - loss 0.06991501 - samples/sec: 126.56 - lr: 0.000030
2021-07-23 20:50:40,563 epoch 17 - iter 60/159 - loss 0.06774261 - samples/sec: 125.34 - lr: 0.000030
2021-07-23 20:50:44,344 epoch 17 - iter 75/159 - loss 0.07258952 - samples/sec: 126.97 - lr: 0.000030
2021-07-23 20:50:48,085 epoch 17 - iter 90/159 - loss 0.06925637 - samples/sec: 128.36 - lr: 0.000030
2021-07-23 20:50:51,698 epoch 17 - iter 105/159 - loss 0.06598829 - samples/sec: 132.86 - lr: 0.000030
2021-07-23 20:50:55,453 epoch 17 - iter 120/159 - loss 0.06685137 - samples/sec: 127.87 - lr: 0.000030
2021-07-23 20:50:59,148 epoch 17 - iter 135/159 - loss 0.06972348 - samples/sec: 129.96 - lr: 0.000030
2021-07-23 20:51:02,988 epoch 17 - iter 150/159 - loss 0.06991860 - samples/sec: 125.02 - lr: 0.000030
2021-07-23 20:51:05,120 ----------------------------------------------------------------------------------------------------
2021-07-23 20:51:05,120 EPOCH 17 done: loss 0.0706 - lr 0.0000300
2021-07-23 20:51:07,289 DEV : loss 0.030818337574601173 - score 0.9939
2021-07-23 20:51:07,316 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:51:11,888 ----------------------------------------------------------------------------------------------------
2021-07-23 20:51:15,689 epoch 18 - iter 15/159 - loss 0.09385110 - samples/sec: 126.38 - lr: 0.000030
2021-07-23 20:51:19,502 epoch 18 - iter 30/159 - loss 0.07751422 - samples/sec: 125.91 - lr: 0.000030
2021-07-23 20:51:23,443 epoch 18 - iter 45/159 - loss 0.08011135 - samples/sec: 121.81 - lr: 0.000030
2021-07-23 20:51:27,099 epoch 18 - iter 60/159 - loss 0.07960511 - samples/sec: 131.35 - lr: 0.000030
2021-07-23 20:51:30,904 epoch 18 - iter 75/159 - loss 0.07933825 - samples/sec: 126.18 - lr: 0.000030
2021-07-23 20:51:34,706 epoch 18 - iter 90/159 - loss 0.08204824 - samples/sec: 126.27 - lr: 0.000030
2021-07-23 20:51:38,520 epoch 18 - iter 105/159 - loss 0.07969039 - samples/sec: 125.87 - lr: 0.000030
2021-07-23 20:51:42,156 epoch 18 - iter 120/159 - loss 0.07969416 - samples/sec: 132.06 - lr: 0.000030
2021-07-23 20:51:45,995 epoch 18 - iter 135/159 - loss 0.07780894 - samples/sec: 125.05 - lr: 0.000030
2021-07-23 20:51:49,703 epoch 18 - iter 150/159 - loss 0.07781291 - samples/sec: 129.48 - lr: 0.000030
2021-07-23 20:51:51,897 ----------------------------------------------------------------------------------------------------
2021-07-23 20:51:51,897 EPOCH 18 done: loss 0.0774 - lr 0.0000300
2021-07-23 20:51:54,069 DEV : loss 0.03363502770662308 - score 0.9921
2021-07-23 20:51:54,096 BAD EPOCHS (no improvement): 1
2021-07-23 20:51:54,096 ----------------------------------------------------------------------------------------------------
2021-07-23 20:51:57,873 epoch 19 - iter 15/159 - loss 0.07296199 - samples/sec: 127.18 - lr: 0.000030
2021-07-23 20:52:01,546 epoch 19 - iter 30/159 - loss 0.07415013 - samples/sec: 130.69 - lr: 0.000030
2021-07-23 20:52:05,267 epoch 19 - iter 45/159 - loss 0.07748899 - samples/sec: 129.04 - lr: 0.000030
2021-07-23 20:52:09,140 epoch 19 - iter 60/159 - loss 0.08069984 - samples/sec: 123.99 - lr: 0.000030
2021-07-23 20:52:12,884 epoch 19 - iter 75/159 - loss 0.08148687 - samples/sec: 128.22 - lr: 0.000030
2021-07-23 20:52:16,605 epoch 19 - iter 90/159 - loss 0.07523597 - samples/sec: 129.05 - lr: 0.000030
2021-07-23 20:52:20,448 epoch 19 - iter 105/159 - loss 0.07431120 - samples/sec: 124.92 - lr: 0.000030
2021-07-23 20:52:24,215 epoch 19 - iter 120/159 - loss 0.07217248 - samples/sec: 127.45 - lr: 0.000030
2021-07-23 20:52:28,152 epoch 19 - iter 135/159 - loss 0.07455607 - samples/sec: 121.97 - lr: 0.000030
2021-07-23 20:52:31,845 epoch 19 - iter 150/159 - loss 0.07314474 - samples/sec: 130.01 - lr: 0.000030
2021-07-23 20:52:34,127 ----------------------------------------------------------------------------------------------------
2021-07-23 20:52:34,127 EPOCH 19 done: loss 0.0733 - lr 0.0000300
2021-07-23 20:52:36,299 DEV : loss 0.02903238870203495 - score 0.9948
2021-07-23 20:52:36,326 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:52:40,787 ----------------------------------------------------------------------------------------------------
2021-07-23 20:52:44,640 epoch 20 - iter 15/159 - loss 0.06983992 - samples/sec: 124.66 - lr: 0.000030
2021-07-23 20:52:48,475 epoch 20 - iter 30/159 - loss 0.08070179 - samples/sec: 125.21 - lr: 0.000030
2021-07-23 20:52:52,315 epoch 20 - iter 45/159 - loss 0.07686810 - samples/sec: 125.04 - lr: 0.000030
2021-07-23 20:52:55,887 epoch 20 - iter 60/159 - loss 0.07567278 - samples/sec: 134.39 - lr: 0.000030
2021-07-23 20:52:59,660 epoch 20 - iter 75/159 - loss 0.07183307 - samples/sec: 127.26 - lr: 0.000030
2021-07-23 20:53:03,556 epoch 20 - iter 90/159 - loss 0.07170159 - samples/sec: 123.23 - lr: 0.000030
2021-07-23 20:53:07,283 epoch 20 - iter 105/159 - loss 0.07220344 - samples/sec: 128.81 - lr: 0.000030
2021-07-23 20:53:10,937 epoch 20 - iter 120/159 - loss 0.07086426 - samples/sec: 131.40 - lr: 0.000030
2021-07-23 20:53:14,668 epoch 20 - iter 135/159 - loss 0.07142764 - samples/sec: 128.69 - lr: 0.000030
2021-07-23 20:53:18,435 epoch 20 - iter 150/159 - loss 0.06989700 - samples/sec: 127.47 - lr: 0.000030
2021-07-23 20:53:20,684 ----------------------------------------------------------------------------------------------------
2021-07-23 20:53:20,684 EPOCH 20 done: loss 0.0684 - lr 0.0000300
2021-07-23 20:53:22,850 DEV : loss 0.028939533978700638 - score 0.9948
2021-07-23 20:53:22,877 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:53:27,461 ----------------------------------------------------------------------------------------------------
2021-07-23 20:53:31,261 epoch 21 - iter 15/159 - loss 0.04451327 - samples/sec: 126.41 - lr: 0.000030
2021-07-23 20:53:35,137 epoch 21 - iter 30/159 - loss 0.05272464 - samples/sec: 123.85 - lr: 0.000030
2021-07-23 20:53:38,765 epoch 21 - iter 45/159 - loss 0.06682671 - samples/sec: 132.34 - lr: 0.000030
2021-07-23 20:53:42,600 epoch 21 - iter 60/159 - loss 0.06481759 - samples/sec: 125.19 - lr: 0.000030
2021-07-23 20:53:46,344 epoch 21 - iter 75/159 - loss 0.06719647 - samples/sec: 128.24 - lr: 0.000030
2021-07-23 20:53:50,190 epoch 21 - iter 90/159 - loss 0.06821212 - samples/sec: 124.83 - lr: 0.000030
2021-07-23 20:53:54,043 epoch 21 - iter 105/159 - loss 0.07097557 - samples/sec: 124.61 - lr: 0.000030
2021-07-23 20:53:57,773 epoch 21 - iter 120/159 - loss 0.07267226 - samples/sec: 128.73 - lr: 0.000030
2021-07-23 20:54:01,448 epoch 21 - iter 135/159 - loss 0.07156838 - samples/sec: 130.63 - lr: 0.000030
2021-07-23 20:54:05,268 epoch 21 - iter 150/159 - loss 0.07284616 - samples/sec: 125.70 - lr: 0.000030
2021-07-23 20:54:07,467 ----------------------------------------------------------------------------------------------------
2021-07-23 20:54:07,468 EPOCH 21 done: loss 0.0718 - lr 0.0000300
2021-07-23 20:54:09,641 DEV : loss 0.028356654569506645 - score 0.9948
2021-07-23 20:54:09,668 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:54:14,426 ----------------------------------------------------------------------------------------------------
2021-07-23 20:54:18,426 epoch 22 - iter 15/159 - loss 0.08882570 - samples/sec: 120.07 - lr: 0.000030
2021-07-23 20:54:22,208 epoch 22 - iter 30/159 - loss 0.07258831 - samples/sec: 126.95 - lr: 0.000030
2021-07-23 20:54:25,943 epoch 22 - iter 45/159 - loss 0.07602129 - samples/sec: 128.53 - lr: 0.000030
2021-07-23 20:54:29,799 epoch 22 - iter 60/159 - loss 0.07487701 - samples/sec: 124.54 - lr: 0.000030
2021-07-23 20:54:33,542 epoch 22 - iter 75/159 - loss 0.07386170 - samples/sec: 128.25 - lr: 0.000030
2021-07-23 20:54:37,344 epoch 22 - iter 90/159 - loss 0.07384775 - samples/sec: 126.30 - lr: 0.000030
2021-07-23 20:54:41,013 epoch 22 - iter 105/159 - loss 0.07317481 - samples/sec: 130.85 - lr: 0.000030
2021-07-23 20:54:44,840 epoch 22 - iter 120/159 - loss 0.07260255 - samples/sec: 125.47 - lr: 0.000030
2021-07-23 20:54:48,681 epoch 22 - iter 135/159 - loss 0.07139157 - samples/sec: 125.01 - lr: 0.000030
2021-07-23 20:54:52,378 epoch 22 - iter 150/159 - loss 0.07035523 - samples/sec: 129.84 - lr: 0.000030
2021-07-23 20:54:54,607 ----------------------------------------------------------------------------------------------------
2021-07-23 20:54:54,608 EPOCH 22 done: loss 0.0712 - lr 0.0000300
2021-07-23 20:54:56,778 DEV : loss 0.029269466176629066 - score 0.993
2021-07-23 20:54:56,804 BAD EPOCHS (no improvement): 1
2021-07-23 20:54:56,805 ----------------------------------------------------------------------------------------------------
2021-07-23 20:55:00,621 epoch 23 - iter 15/159 - loss 0.07249783 - samples/sec: 125.85 - lr: 0.000030
2021-07-23 20:55:04,342 epoch 23 - iter 30/159 - loss 0.06327564 - samples/sec: 129.01 - lr: 0.000030
2021-07-23 20:55:08,167 epoch 23 - iter 45/159 - loss 0.05983915 - samples/sec: 125.51 - lr: 0.000030
2021-07-23 20:55:11,918 epoch 23 - iter 60/159 - loss 0.06284901 - samples/sec: 128.03 - lr: 0.000030
2021-07-23 20:55:15,685 epoch 23 - iter 75/159 - loss 0.06509636 - samples/sec: 127.44 - lr: 0.000030
2021-07-23 20:55:19,392 epoch 23 - iter 90/159 - loss 0.06519706 - samples/sec: 129.55 - lr: 0.000030
2021-07-23 20:55:23,240 epoch 23 - iter 105/159 - loss 0.06230938 - samples/sec: 124.75 - lr: 0.000030
2021-07-23 20:55:26,999 epoch 23 - iter 120/159 - loss 0.06332555 - samples/sec: 127.74 - lr: 0.000030
2021-07-23 20:55:30,763 epoch 23 - iter 135/159 - loss 0.06297472 - samples/sec: 127.56 - lr: 0.000030
2021-07-23 20:55:34,353 epoch 23 - iter 150/159 - loss 0.06678078 - samples/sec: 133.75 - lr: 0.000030
2021-07-23 20:55:36,584 ----------------------------------------------------------------------------------------------------
2021-07-23 20:55:36,584 EPOCH 23 done: loss 0.0683 - lr 0.0000300
2021-07-23 20:55:38,758 DEV : loss 0.03579368069767952 - score 0.9912
2021-07-23 20:55:38,784 BAD EPOCHS (no improvement): 2
2021-07-23 20:55:38,784 ----------------------------------------------------------------------------------------------------
2021-07-23 20:55:42,524 epoch 24 - iter 15/159 - loss 0.04111220 - samples/sec: 128.44 - lr: 0.000030
2021-07-23 20:55:46,433 epoch 24 - iter 30/159 - loss 0.04447331 - samples/sec: 122.81 - lr: 0.000030
2021-07-23 20:55:50,195 epoch 24 - iter 45/159 - loss 0.04647914 - samples/sec: 127.64 - lr: 0.000030
2021-07-23 20:55:53,983 epoch 24 - iter 60/159 - loss 0.05059872 - samples/sec: 126.73 - lr: 0.000030
2021-07-23 20:55:57,787 epoch 24 - iter 75/159 - loss 0.05552678 - samples/sec: 126.21 - lr: 0.000030
2021-07-23 20:56:01,447 epoch 24 - iter 90/159 - loss 0.05895224 - samples/sec: 131.21 - lr: 0.000030
2021-07-23 20:56:05,110 epoch 24 - iter 105/159 - loss 0.05928655 - samples/sec: 131.07 - lr: 0.000030
2021-07-23 20:56:08,720 epoch 24 - iter 120/159 - loss 0.05803330 - samples/sec: 133.00 - lr: 0.000030
2021-07-23 20:56:12,518 epoch 24 - iter 135/159 - loss 0.05688712 - samples/sec: 126.40 - lr: 0.000030
2021-07-23 20:56:16,360 epoch 24 - iter 150/159 - loss 0.05680840 - samples/sec: 124.97 - lr: 0.000030
2021-07-23 20:56:18,539 ----------------------------------------------------------------------------------------------------
2021-07-23 20:56:18,539 EPOCH 24 done: loss 0.0586 - lr 0.0000300
2021-07-23 20:56:20,715 DEV : loss 0.03135612607002258 - score 0.9912
2021-07-23 20:56:20,742 BAD EPOCHS (no improvement): 3
2021-07-23 20:56:20,742 ----------------------------------------------------------------------------------------------------
2021-07-23 20:56:24,463 epoch 25 - iter 15/159 - loss 0.05010288 - samples/sec: 129.05 - lr: 0.000030
2021-07-23 20:56:28,136 epoch 25 - iter 30/159 - loss 0.06372684 - samples/sec: 130.72 - lr: 0.000030
2021-07-23 20:56:31,907 epoch 25 - iter 45/159 - loss 0.06563067 - samples/sec: 127.34 - lr: 0.000030
2021-07-23 20:56:35,679 epoch 25 - iter 60/159 - loss 0.06556688 - samples/sec: 127.29 - lr: 0.000030
2021-07-23 20:56:39,441 epoch 25 - iter 75/159 - loss 0.06121759 - samples/sec: 127.60 - lr: 0.000030
2021-07-23 20:56:43,340 epoch 25 - iter 90/159 - loss 0.06273247 - samples/sec: 123.14 - lr: 0.000030
2021-07-23 20:56:47,170 epoch 25 - iter 105/159 - loss 0.06100895 - samples/sec: 125.38 - lr: 0.000030
2021-07-23 20:56:50,912 epoch 25 - iter 120/159 - loss 0.05942080 - samples/sec: 128.29 - lr: 0.000030
2021-07-23 20:56:54,643 epoch 25 - iter 135/159 - loss 0.06088302 - samples/sec: 128.68 - lr: 0.000030
2021-07-23 20:56:58,359 epoch 25 - iter 150/159 - loss 0.06032971 - samples/sec: 129.23 - lr: 0.000030
2021-07-23 20:57:00,501 ----------------------------------------------------------------------------------------------------
2021-07-23 20:57:00,501 EPOCH 25 done: loss 0.0596 - lr 0.0000300
2021-07-23 20:57:02,678 DEV : loss 0.02811032347381115 - score 0.9948
Epoch    25: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 20:57:02,705 BAD EPOCHS (no improvement): 4
2021-07-23 20:57:02,705 ----------------------------------------------------------------------------------------------------
2021-07-23 20:57:06,532 epoch 26 - iter 15/159 - loss 0.06666855 - samples/sec: 125.51 - lr: 0.000015
2021-07-23 20:57:10,249 epoch 26 - iter 30/159 - loss 0.05665491 - samples/sec: 129.18 - lr: 0.000015
2021-07-23 20:57:13,865 epoch 26 - iter 45/159 - loss 0.06087926 - samples/sec: 132.77 - lr: 0.000015
2021-07-23 20:57:17,669 epoch 26 - iter 60/159 - loss 0.06576487 - samples/sec: 126.22 - lr: 0.000015
2021-07-23 20:57:21,463 epoch 26 - iter 75/159 - loss 0.06766495 - samples/sec: 126.55 - lr: 0.000015
2021-07-23 20:57:25,321 epoch 26 - iter 90/159 - loss 0.07241576 - samples/sec: 124.44 - lr: 0.000015
2021-07-23 20:57:29,219 epoch 26 - iter 105/159 - loss 0.07128535 - samples/sec: 123.16 - lr: 0.000015
2021-07-23 20:57:32,864 epoch 26 - iter 120/159 - loss 0.06621946 - samples/sec: 131.73 - lr: 0.000015
2021-07-23 20:57:36,760 epoch 26 - iter 135/159 - loss 0.06414750 - samples/sec: 123.23 - lr: 0.000015
2021-07-23 20:57:40,430 epoch 26 - iter 150/159 - loss 0.06378762 - samples/sec: 130.84 - lr: 0.000015
2021-07-23 20:57:42,498 ----------------------------------------------------------------------------------------------------
2021-07-23 20:57:42,498 EPOCH 26 done: loss 0.0633 - lr 0.0000150
2021-07-23 20:57:44,671 DEV : loss 0.02901727706193924 - score 0.9948
2021-07-23 20:57:44,698 BAD EPOCHS (no improvement): 1
2021-07-23 20:57:44,699 ----------------------------------------------------------------------------------------------------
2021-07-23 20:57:48,546 epoch 27 - iter 15/159 - loss 0.05540321 - samples/sec: 124.82 - lr: 0.000015
2021-07-23 20:57:52,351 epoch 27 - iter 30/159 - loss 0.06082987 - samples/sec: 126.18 - lr: 0.000015
2021-07-23 20:57:56,188 epoch 27 - iter 45/159 - loss 0.05989244 - samples/sec: 125.14 - lr: 0.000015
2021-07-23 20:57:59,852 epoch 27 - iter 60/159 - loss 0.05647348 - samples/sec: 131.04 - lr: 0.000015
2021-07-23 20:58:03,579 epoch 27 - iter 75/159 - loss 0.05395665 - samples/sec: 128.84 - lr: 0.000015
2021-07-23 20:58:07,435 epoch 27 - iter 90/159 - loss 0.05452316 - samples/sec: 124.50 - lr: 0.000015
2021-07-23 20:58:11,120 epoch 27 - iter 105/159 - loss 0.06044217 - samples/sec: 130.29 - lr: 0.000015
2021-07-23 20:58:14,845 epoch 27 - iter 120/159 - loss 0.06394353 - samples/sec: 128.90 - lr: 0.000015
2021-07-23 20:58:18,644 epoch 27 - iter 135/159 - loss 0.06268704 - samples/sec: 126.39 - lr: 0.000015
2021-07-23 20:58:22,564 epoch 27 - iter 150/159 - loss 0.06151059 - samples/sec: 122.46 - lr: 0.000015
2021-07-23 20:58:24,774 ----------------------------------------------------------------------------------------------------
2021-07-23 20:58:24,774 EPOCH 27 done: loss 0.0616 - lr 0.0000150
2021-07-23 20:58:26,948 DEV : loss 0.03535320609807968 - score 0.9921
2021-07-23 20:58:26,975 BAD EPOCHS (no improvement): 2
2021-07-23 20:58:26,975 ----------------------------------------------------------------------------------------------------
2021-07-23 20:58:30,804 epoch 28 - iter 15/159 - loss 0.06698066 - samples/sec: 125.42 - lr: 0.000015
2021-07-23 20:58:34,567 epoch 28 - iter 30/159 - loss 0.05531498 - samples/sec: 127.61 - lr: 0.000015
2021-07-23 20:58:38,419 epoch 28 - iter 45/159 - loss 0.05853761 - samples/sec: 124.62 - lr: 0.000015
2021-07-23 20:58:42,046 epoch 28 - iter 60/159 - loss 0.05478823 - samples/sec: 132.37 - lr: 0.000015
2021-07-23 20:58:45,747 epoch 28 - iter 75/159 - loss 0.05493566 - samples/sec: 129.75 - lr: 0.000015
2021-07-23 20:58:49,525 epoch 28 - iter 90/159 - loss 0.05905415 - samples/sec: 127.08 - lr: 0.000015
2021-07-23 20:58:53,312 epoch 28 - iter 105/159 - loss 0.05533137 - samples/sec: 126.79 - lr: 0.000015
2021-07-23 20:58:57,243 epoch 28 - iter 120/159 - loss 0.05651352 - samples/sec: 122.13 - lr: 0.000015
2021-07-23 20:59:01,123 epoch 28 - iter 135/159 - loss 0.05818114 - samples/sec: 123.74 - lr: 0.000015
2021-07-23 20:59:04,949 epoch 28 - iter 150/159 - loss 0.05872050 - samples/sec: 125.49 - lr: 0.000015
2021-07-23 20:59:07,075 ----------------------------------------------------------------------------------------------------
2021-07-23 20:59:07,076 EPOCH 28 done: loss 0.0587 - lr 0.0000150
2021-07-23 20:59:09,259 DEV : loss 0.028154820203781128 - score 0.9939
2021-07-23 20:59:09,286 BAD EPOCHS (no improvement): 3
2021-07-23 20:59:09,286 ----------------------------------------------------------------------------------------------------
2021-07-23 20:59:13,060 epoch 29 - iter 15/159 - loss 0.05984620 - samples/sec: 127.28 - lr: 0.000015
2021-07-23 20:59:16,808 epoch 29 - iter 30/159 - loss 0.06336064 - samples/sec: 128.09 - lr: 0.000015
2021-07-23 20:59:20,640 epoch 29 - iter 45/159 - loss 0.06789859 - samples/sec: 125.29 - lr: 0.000015
2021-07-23 20:59:24,384 epoch 29 - iter 60/159 - loss 0.06053961 - samples/sec: 128.23 - lr: 0.000015
2021-07-23 20:59:28,390 epoch 29 - iter 75/159 - loss 0.05683607 - samples/sec: 119.85 - lr: 0.000015
2021-07-23 20:59:32,092 epoch 29 - iter 90/159 - loss 0.05594952 - samples/sec: 129.71 - lr: 0.000015
2021-07-23 20:59:35,714 epoch 29 - iter 105/159 - loss 0.05473553 - samples/sec: 132.56 - lr: 0.000015
2021-07-23 20:59:39,500 epoch 29 - iter 120/159 - loss 0.05543813 - samples/sec: 126.81 - lr: 0.000015
2021-07-23 20:59:43,344 epoch 29 - iter 135/159 - loss 0.05602743 - samples/sec: 124.90 - lr: 0.000015
2021-07-23 20:59:47,129 epoch 29 - iter 150/159 - loss 0.05497854 - samples/sec: 126.86 - lr: 0.000015
2021-07-23 20:59:49,315 ----------------------------------------------------------------------------------------------------
2021-07-23 20:59:49,315 EPOCH 29 done: loss 0.0549 - lr 0.0000150
2021-07-23 20:59:51,487 DEV : loss 0.026942919939756393 - score 0.9939
Epoch    29: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 20:59:51,514 BAD EPOCHS (no improvement): 4
2021-07-23 20:59:51,514 ----------------------------------------------------------------------------------------------------
2021-07-23 20:59:55,235 epoch 30 - iter 15/159 - loss 0.05751359 - samples/sec: 129.06 - lr: 0.000008
2021-07-23 20:59:58,849 epoch 30 - iter 30/159 - loss 0.06367971 - samples/sec: 132.86 - lr: 0.000008
2021-07-23 21:00:02,836 epoch 30 - iter 45/159 - loss 0.06174269 - samples/sec: 120.44 - lr: 0.000008
2021-07-23 21:00:06,760 epoch 30 - iter 60/159 - loss 0.06518623 - samples/sec: 122.35 - lr: 0.000008
2021-07-23 21:00:10,616 epoch 30 - iter 75/159 - loss 0.06145755 - samples/sec: 124.52 - lr: 0.000008
2021-07-23 21:00:14,448 epoch 30 - iter 90/159 - loss 0.05950200 - samples/sec: 125.30 - lr: 0.000008
2021-07-23 21:00:18,204 epoch 30 - iter 105/159 - loss 0.05746220 - samples/sec: 127.82 - lr: 0.000008
2021-07-23 21:00:21,981 epoch 30 - iter 120/159 - loss 0.05702754 - samples/sec: 127.13 - lr: 0.000008
2021-07-23 21:00:25,609 epoch 30 - iter 135/159 - loss 0.05612107 - samples/sec: 132.33 - lr: 0.000008
2021-07-23 21:00:29,335 epoch 30 - iter 150/159 - loss 0.05568142 - samples/sec: 128.85 - lr: 0.000008
2021-07-23 21:00:31,517 ----------------------------------------------------------------------------------------------------
2021-07-23 21:00:31,517 EPOCH 30 done: loss 0.0565 - lr 0.0000075
2021-07-23 21:00:33,699 DEV : loss 0.027938222512602806 - score 0.9939
2021-07-23 21:00:33,726 BAD EPOCHS (no improvement): 1
2021-07-23 21:00:33,726 ----------------------------------------------------------------------------------------------------
2021-07-23 21:00:37,617 epoch 31 - iter 15/159 - loss 0.05177635 - samples/sec: 123.43 - lr: 0.000008
2021-07-23 21:00:41,403 epoch 31 - iter 30/159 - loss 0.05592418 - samples/sec: 126.81 - lr: 0.000008
2021-07-23 21:00:45,375 epoch 31 - iter 45/159 - loss 0.05037960 - samples/sec: 120.88 - lr: 0.000008
2021-07-23 21:00:49,185 epoch 31 - iter 60/159 - loss 0.05900145 - samples/sec: 126.04 - lr: 0.000008
2021-07-23 21:00:52,977 epoch 31 - iter 75/159 - loss 0.05525588 - samples/sec: 126.60 - lr: 0.000008
2021-07-23 21:00:56,712 epoch 31 - iter 90/159 - loss 0.05586547 - samples/sec: 128.56 - lr: 0.000008
2021-07-23 21:01:00,483 epoch 31 - iter 105/159 - loss 0.05944639 - samples/sec: 127.30 - lr: 0.000008
2021-07-23 21:01:04,209 epoch 31 - iter 120/159 - loss 0.05762105 - samples/sec: 128.88 - lr: 0.000008
2021-07-23 21:01:07,999 epoch 31 - iter 135/159 - loss 0.05659761 - samples/sec: 126.66 - lr: 0.000008
2021-07-23 21:01:11,704 epoch 31 - iter 150/159 - loss 0.05615422 - samples/sec: 129.61 - lr: 0.000008
2021-07-23 21:01:13,731 ----------------------------------------------------------------------------------------------------
2021-07-23 21:01:13,731 EPOCH 31 done: loss 0.0573 - lr 0.0000075
2021-07-23 21:01:15,902 DEV : loss 0.02818814292550087 - score 0.9939
2021-07-23 21:01:15,928 BAD EPOCHS (no improvement): 2
2021-07-23 21:01:15,929 ----------------------------------------------------------------------------------------------------
2021-07-23 21:01:19,961 epoch 32 - iter 15/159 - loss 0.04506453 - samples/sec: 119.11 - lr: 0.000008
2021-07-23 21:01:23,779 epoch 32 - iter 30/159 - loss 0.04483815 - samples/sec: 125.73 - lr: 0.000008
2021-07-23 21:01:27,545 epoch 32 - iter 45/159 - loss 0.04461408 - samples/sec: 127.50 - lr: 0.000008
2021-07-23 21:01:31,233 epoch 32 - iter 60/159 - loss 0.04317894 - samples/sec: 130.21 - lr: 0.000008
2021-07-23 21:01:35,105 epoch 32 - iter 75/159 - loss 0.04483905 - samples/sec: 123.99 - lr: 0.000008
2021-07-23 21:01:38,783 epoch 32 - iter 90/159 - loss 0.04323526 - samples/sec: 130.53 - lr: 0.000008
2021-07-23 21:01:42,565 epoch 32 - iter 105/159 - loss 0.04732818 - samples/sec: 126.96 - lr: 0.000008
2021-07-23 21:01:46,419 epoch 32 - iter 120/159 - loss 0.04656352 - samples/sec: 124.57 - lr: 0.000008
2021-07-23 21:01:50,251 epoch 32 - iter 135/159 - loss 0.04921020 - samples/sec: 125.30 - lr: 0.000008
2021-07-23 21:01:53,928 epoch 32 - iter 150/159 - loss 0.05451206 - samples/sec: 130.58 - lr: 0.000008
2021-07-23 21:01:56,135 ----------------------------------------------------------------------------------------------------
2021-07-23 21:01:56,136 EPOCH 32 done: loss 0.0568 - lr 0.0000075
2021-07-23 21:01:58,307 DEV : loss 0.03074030391871929 - score 0.993
2021-07-23 21:01:58,334 BAD EPOCHS (no improvement): 3
2021-07-23 21:01:58,334 ----------------------------------------------------------------------------------------------------
2021-07-23 21:02:02,117 epoch 33 - iter 15/159 - loss 0.06876671 - samples/sec: 126.98 - lr: 0.000008
2021-07-23 21:02:05,931 epoch 33 - iter 30/159 - loss 0.06894124 - samples/sec: 125.87 - lr: 0.000008
2021-07-23 21:02:09,719 epoch 33 - iter 45/159 - loss 0.07396118 - samples/sec: 126.74 - lr: 0.000008
2021-07-23 21:02:13,471 epoch 33 - iter 60/159 - loss 0.06919159 - samples/sec: 127.99 - lr: 0.000008
2021-07-23 21:02:17,291 epoch 33 - iter 75/159 - loss 0.06969753 - samples/sec: 125.68 - lr: 0.000008
2021-07-23 21:02:21,124 epoch 33 - iter 90/159 - loss 0.06465319 - samples/sec: 125.24 - lr: 0.000008
2021-07-23 21:02:24,798 epoch 33 - iter 105/159 - loss 0.06276187 - samples/sec: 130.69 - lr: 0.000008
2021-07-23 21:02:28,588 epoch 33 - iter 120/159 - loss 0.06185982 - samples/sec: 126.70 - lr: 0.000008
2021-07-23 21:02:32,392 epoch 33 - iter 135/159 - loss 0.06332445 - samples/sec: 126.20 - lr: 0.000008
2021-07-23 21:02:36,184 epoch 33 - iter 150/159 - loss 0.06241860 - samples/sec: 126.62 - lr: 0.000008
2021-07-23 21:02:38,360 ----------------------------------------------------------------------------------------------------
2021-07-23 21:02:38,360 EPOCH 33 done: loss 0.0607 - lr 0.0000075
2021-07-23 21:02:40,529 DEV : loss 0.031221721321344376 - score 0.993
Epoch    33: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 21:02:40,556 BAD EPOCHS (no improvement): 4
2021-07-23 21:02:40,556 ----------------------------------------------------------------------------------------------------
2021-07-23 21:02:44,256 epoch 34 - iter 15/159 - loss 0.04556888 - samples/sec: 129.82 - lr: 0.000004
2021-07-23 21:02:48,139 epoch 34 - iter 30/159 - loss 0.04086422 - samples/sec: 123.65 - lr: 0.000004
2021-07-23 21:02:51,905 epoch 34 - iter 45/159 - loss 0.04262244 - samples/sec: 127.50 - lr: 0.000004
2021-07-23 21:02:55,748 epoch 34 - iter 60/159 - loss 0.04158154 - samples/sec: 124.91 - lr: 0.000004
2021-07-23 21:02:59,444 epoch 34 - iter 75/159 - loss 0.04940820 - samples/sec: 129.93 - lr: 0.000004
2021-07-23 21:03:03,148 epoch 34 - iter 90/159 - loss 0.04801199 - samples/sec: 129.62 - lr: 0.000004
2021-07-23 21:03:07,075 epoch 34 - iter 105/159 - loss 0.04861784 - samples/sec: 122.26 - lr: 0.000004
2021-07-23 21:03:10,760 epoch 34 - iter 120/159 - loss 0.04940912 - samples/sec: 130.29 - lr: 0.000004
2021-07-23 21:03:14,444 epoch 34 - iter 135/159 - loss 0.04805548 - samples/sec: 130.31 - lr: 0.000004
2021-07-23 21:03:18,280 epoch 34 - iter 150/159 - loss 0.05041562 - samples/sec: 125.17 - lr: 0.000004
2021-07-23 21:03:20,519 ----------------------------------------------------------------------------------------------------
2021-07-23 21:03:20,519 EPOCH 34 done: loss 0.0518 - lr 0.0000038
2021-07-23 21:03:22,700 DEV : loss 0.02921660803258419 - score 0.993
2021-07-23 21:03:22,727 BAD EPOCHS (no improvement): 1
2021-07-23 21:03:22,728 ----------------------------------------------------------------------------------------------------
2021-07-23 21:03:26,623 epoch 35 - iter 15/159 - loss 0.04011477 - samples/sec: 123.29 - lr: 0.000004
2021-07-23 21:03:30,327 epoch 35 - iter 30/159 - loss 0.04535866 - samples/sec: 129.62 - lr: 0.000004
2021-07-23 21:03:34,003 epoch 35 - iter 45/159 - loss 0.04226946 - samples/sec: 130.60 - lr: 0.000004
2021-07-23 21:03:37,831 epoch 35 - iter 60/159 - loss 0.04600779 - samples/sec: 125.42 - lr: 0.000004
2021-07-23 21:03:41,482 epoch 35 - iter 75/159 - loss 0.04367374 - samples/sec: 131.51 - lr: 0.000004
2021-07-23 21:03:45,283 epoch 35 - iter 90/159 - loss 0.04501140 - samples/sec: 126.32 - lr: 0.000004
2021-07-23 21:03:48,984 epoch 35 - iter 105/159 - loss 0.04699127 - samples/sec: 129.73 - lr: 0.000004
2021-07-23 21:03:52,969 epoch 35 - iter 120/159 - loss 0.05164150 - samples/sec: 120.48 - lr: 0.000004
2021-07-23 21:03:56,756 epoch 35 - iter 135/159 - loss 0.05203071 - samples/sec: 126.80 - lr: 0.000004
2021-07-23 21:04:00,568 epoch 35 - iter 150/159 - loss 0.05107153 - samples/sec: 125.94 - lr: 0.000004
2021-07-23 21:04:02,751 ----------------------------------------------------------------------------------------------------
2021-07-23 21:04:02,751 EPOCH 35 done: loss 0.0500 - lr 0.0000038
2021-07-23 21:04:04,926 DEV : loss 0.02833307720720768 - score 0.9939
2021-07-23 21:04:04,952 BAD EPOCHS (no improvement): 2
2021-07-23 21:04:04,953 ----------------------------------------------------------------------------------------------------
2021-07-23 21:04:08,947 epoch 36 - iter 15/159 - loss 0.04281468 - samples/sec: 120.25 - lr: 0.000004
2021-07-23 21:04:12,705 epoch 36 - iter 30/159 - loss 0.04260029 - samples/sec: 127.75 - lr: 0.000004
2021-07-23 21:04:16,412 epoch 36 - iter 45/159 - loss 0.04852555 - samples/sec: 129.50 - lr: 0.000004
2021-07-23 21:04:20,144 epoch 36 - iter 60/159 - loss 0.04918555 - samples/sec: 128.65 - lr: 0.000004
2021-07-23 21:04:23,863 epoch 36 - iter 75/159 - loss 0.04873927 - samples/sec: 129.11 - lr: 0.000004
2021-07-23 21:04:27,563 epoch 36 - iter 90/159 - loss 0.04630890 - samples/sec: 129.76 - lr: 0.000004
2021-07-23 21:04:31,313 epoch 36 - iter 105/159 - loss 0.04813150 - samples/sec: 128.04 - lr: 0.000004
2021-07-23 21:04:35,106 epoch 36 - iter 120/159 - loss 0.04741239 - samples/sec: 126.57 - lr: 0.000004
2021-07-23 21:04:38,819 epoch 36 - iter 135/159 - loss 0.05002048 - samples/sec: 129.30 - lr: 0.000004
2021-07-23 21:04:42,584 epoch 36 - iter 150/159 - loss 0.05089161 - samples/sec: 127.52 - lr: 0.000004
2021-07-23 21:04:44,683 ----------------------------------------------------------------------------------------------------
2021-07-23 21:04:44,684 EPOCH 36 done: loss 0.0512 - lr 0.0000038
2021-07-23 21:04:46,868 DEV : loss 0.028515858575701714 - score 0.9939
2021-07-23 21:04:46,895 BAD EPOCHS (no improvement): 3
2021-07-23 21:04:46,895 ----------------------------------------------------------------------------------------------------
2021-07-23 21:04:50,916 epoch 37 - iter 15/159 - loss 0.06247038 - samples/sec: 119.43 - lr: 0.000004
2021-07-23 21:04:54,873 epoch 37 - iter 30/159 - loss 0.06402434 - samples/sec: 121.34 - lr: 0.000004
2021-07-23 21:04:58,811 epoch 37 - iter 45/159 - loss 0.05852964 - samples/sec: 121.92 - lr: 0.000004
2021-07-23 21:05:02,538 epoch 37 - iter 60/159 - loss 0.05680566 - samples/sec: 128.81 - lr: 0.000004
2021-07-23 21:05:06,368 epoch 37 - iter 75/159 - loss 0.05624142 - samples/sec: 125.38 - lr: 0.000004
2021-07-23 21:05:10,064 epoch 37 - iter 90/159 - loss 0.05597474 - samples/sec: 129.89 - lr: 0.000004
2021-07-23 21:05:13,767 epoch 37 - iter 105/159 - loss 0.05601744 - samples/sec: 129.66 - lr: 0.000004
2021-07-23 21:05:17,460 epoch 37 - iter 120/159 - loss 0.05654306 - samples/sec: 130.02 - lr: 0.000004
2021-07-23 21:05:21,045 epoch 37 - iter 135/159 - loss 0.05501553 - samples/sec: 133.93 - lr: 0.000004
2021-07-23 21:05:24,884 epoch 37 - iter 150/159 - loss 0.05387379 - samples/sec: 125.05 - lr: 0.000004
2021-07-23 21:05:27,076 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:27,076 EPOCH 37 done: loss 0.0537 - lr 0.0000038
2021-07-23 21:05:29,253 DEV : loss 0.028776822611689568 - score 0.9939
Epoch    37: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 21:05:29,280 BAD EPOCHS (no improvement): 4
2021-07-23 21:05:29,280 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:29,280 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:29,280 learning rate too small - quitting training!
2021-07-23 21:05:29,280 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:30,730 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:30,731 Testing using best model ...
2021-07-23 21:05:30,732 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/por.rst.cstn/best-model.pt
2021-07-23 21:05:51,174 0.9847	0.9988	0.9917
2021-07-23 21:05:51,174 
Results:
- F1-score (micro) 0.9917
- F1-score (macro) 0.9903

By class:
SENT       tp: 354 - fp: 13 - fn: 1 - precision: 0.9646 - recall: 0.9972 - f1-score: 0.9806
X          tp: 481 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 21:05:51,174 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/deu.rst.pcc/
2021-07-23 21:05:51,253 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/deu.rst.pcc
2021-07-23 21:05:51,254 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/deu.rst.pcc/sent_train.txt
2021-07-23 21:05:51,255 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/deu.rst.pcc/sent_dev.txt
2021-07-23 21:05:51,257 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/deu.rst.pcc/sent_test.txt
Corpus: 3223 train + 506 dev + 1038 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 21:05:54,619 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:54,621 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 21:05:54,621 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:54,621 Corpus: "Corpus: 3223 train + 506 dev + 1038 test sentences"
2021-07-23 21:05:54,621 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:54,621 Parameters:
2021-07-23 21:05:54,621  - learning_rate: "3e-05"
2021-07-23 21:05:54,621  - mini_batch_size: "32"
2021-07-23 21:05:54,621  - patience: "3"
2021-07-23 21:05:54,621  - anneal_factor: "0.5"
2021-07-23 21:05:54,621  - max_epochs: "40"
2021-07-23 21:05:54,621  - shuffle: "True"
2021-07-23 21:05:54,621  - train_with_dev: "False"
2021-07-23 21:05:54,621  - batch_growth_annealing: "False"
2021-07-23 21:05:54,621 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:54,621 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/deu.rst.pcc"
2021-07-23 21:05:54,621 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:54,622 Device: cuda:0
2021-07-23 21:05:54,622 ----------------------------------------------------------------------------------------------------
2021-07-23 21:05:54,622 Embeddings storage mode: cpu
2021-07-23 21:05:54,624 ----------------------------------------------------------------------------------------------------
2021-07-23 21:06:00,501 epoch 1 - iter 10/101 - loss 10.88505154 - samples/sec: 54.46 - lr: 0.000030
2021-07-23 21:06:06,318 epoch 1 - iter 20/101 - loss 9.89583321 - samples/sec: 55.02 - lr: 0.000030
2021-07-23 21:06:12,149 epoch 1 - iter 30/101 - loss 9.07875595 - samples/sec: 54.88 - lr: 0.000030
2021-07-23 21:06:18,059 epoch 1 - iter 40/101 - loss 8.41736184 - samples/sec: 54.15 - lr: 0.000030
2021-07-23 21:06:23,930 epoch 1 - iter 50/101 - loss 7.77199620 - samples/sec: 54.51 - lr: 0.000030
2021-07-23 21:06:29,712 epoch 1 - iter 60/101 - loss 7.12214925 - samples/sec: 55.35 - lr: 0.000030
2021-07-23 21:06:35,594 epoch 1 - iter 70/101 - loss 6.60275501 - samples/sec: 54.40 - lr: 0.000030
2021-07-23 21:06:41,488 epoch 1 - iter 80/101 - loss 6.12791660 - samples/sec: 54.30 - lr: 0.000030
2021-07-23 21:06:47,353 epoch 1 - iter 90/101 - loss 5.68190953 - samples/sec: 54.57 - lr: 0.000030
2021-07-23 21:06:53,385 epoch 1 - iter 100/101 - loss 5.30442872 - samples/sec: 53.06 - lr: 0.000030
2021-07-23 21:06:53,823 ----------------------------------------------------------------------------------------------------
2021-07-23 21:06:53,823 EPOCH 1 done: loss 5.2671 - lr 0.0000300
2021-07-23 21:07:00,247 DEV : loss 1.3951269388198853 - score 0.0
2021-07-23 21:07:00,260 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:07:00,825 ----------------------------------------------------------------------------------------------------
2021-07-23 21:07:03,147 epoch 2 - iter 10/101 - loss 1.61863950 - samples/sec: 137.92 - lr: 0.000030
2021-07-23 21:07:05,472 epoch 2 - iter 20/101 - loss 1.49465528 - samples/sec: 137.69 - lr: 0.000030
2021-07-23 21:07:07,948 epoch 2 - iter 30/101 - loss 1.39489082 - samples/sec: 139.80 - lr: 0.000030
2021-07-23 21:07:10,149 epoch 2 - iter 40/101 - loss 1.32996022 - samples/sec: 145.50 - lr: 0.000030
2021-07-23 21:07:12,511 epoch 2 - iter 50/101 - loss 1.27369600 - samples/sec: 135.51 - lr: 0.000030
2021-07-23 21:07:14,824 epoch 2 - iter 60/101 - loss 1.22620277 - samples/sec: 138.37 - lr: 0.000030
2021-07-23 21:07:17,168 epoch 2 - iter 70/101 - loss 1.18369495 - samples/sec: 136.58 - lr: 0.000030
2021-07-23 21:07:19,516 epoch 2 - iter 80/101 - loss 1.14855530 - samples/sec: 136.28 - lr: 0.000030
2021-07-23 21:07:21,779 epoch 2 - iter 90/101 - loss 1.10819142 - samples/sec: 141.45 - lr: 0.000030
2021-07-23 21:07:24,056 epoch 2 - iter 100/101 - loss 1.07045376 - samples/sec: 140.60 - lr: 0.000030
2021-07-23 21:07:24,244 ----------------------------------------------------------------------------------------------------
2021-07-23 21:07:24,244 EPOCH 2 done: loss 1.0684 - lr 0.0000300
2021-07-23 21:07:25,405 DEV : loss 0.5991246700286865 - score 0.8452
2021-07-23 21:07:25,417 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:07:27,726 ----------------------------------------------------------------------------------------------------
2021-07-23 21:07:29,992 epoch 3 - iter 10/101 - loss 0.71053311 - samples/sec: 141.38 - lr: 0.000030
2021-07-23 21:07:32,242 epoch 3 - iter 20/101 - loss 0.69324419 - samples/sec: 142.30 - lr: 0.000030
2021-07-23 21:07:34,510 epoch 3 - iter 30/101 - loss 0.67884635 - samples/sec: 141.13 - lr: 0.000030
2021-07-23 21:07:36,867 epoch 3 - iter 40/101 - loss 0.64058733 - samples/sec: 135.79 - lr: 0.000030
2021-07-23 21:07:39,175 epoch 3 - iter 50/101 - loss 0.64243316 - samples/sec: 138.69 - lr: 0.000030
2021-07-23 21:07:41,456 epoch 3 - iter 60/101 - loss 0.63391653 - samples/sec: 140.36 - lr: 0.000030
2021-07-23 21:07:43,698 epoch 3 - iter 70/101 - loss 0.62715818 - samples/sec: 142.78 - lr: 0.000030
2021-07-23 21:07:46,082 epoch 3 - iter 80/101 - loss 0.61671225 - samples/sec: 134.25 - lr: 0.000030
2021-07-23 21:07:48,428 epoch 3 - iter 90/101 - loss 0.60615213 - samples/sec: 136.42 - lr: 0.000030
2021-07-23 21:07:50,728 epoch 3 - iter 100/101 - loss 0.59078407 - samples/sec: 139.22 - lr: 0.000030
2021-07-23 21:07:50,894 ----------------------------------------------------------------------------------------------------
2021-07-23 21:07:50,894 EPOCH 3 done: loss 0.5878 - lr 0.0000300
2021-07-23 21:07:52,053 DEV : loss 0.3436354696750641 - score 0.9312
2021-07-23 21:07:52,065 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:07:54,312 ----------------------------------------------------------------------------------------------------
2021-07-23 21:07:56,571 epoch 4 - iter 10/101 - loss 0.43683962 - samples/sec: 141.80 - lr: 0.000030
2021-07-23 21:07:58,762 epoch 4 - iter 20/101 - loss 0.41449050 - samples/sec: 146.12 - lr: 0.000030
2021-07-23 21:08:01,151 epoch 4 - iter 30/101 - loss 0.42203958 - samples/sec: 133.97 - lr: 0.000030
2021-07-23 21:08:03,535 epoch 4 - iter 40/101 - loss 0.42295244 - samples/sec: 134.27 - lr: 0.000030
2021-07-23 21:08:05,780 epoch 4 - iter 50/101 - loss 0.40782476 - samples/sec: 142.56 - lr: 0.000030
2021-07-23 21:08:08,143 epoch 4 - iter 60/101 - loss 0.40581316 - samples/sec: 135.49 - lr: 0.000030
2021-07-23 21:08:10,459 epoch 4 - iter 70/101 - loss 0.40445740 - samples/sec: 138.19 - lr: 0.000030
2021-07-23 21:08:12,804 epoch 4 - iter 80/101 - loss 0.39894978 - samples/sec: 136.52 - lr: 0.000030
2021-07-23 21:08:15,133 epoch 4 - iter 90/101 - loss 0.39552709 - samples/sec: 137.43 - lr: 0.000030
2021-07-23 21:08:17,430 epoch 4 - iter 100/101 - loss 0.39411013 - samples/sec: 139.33 - lr: 0.000030
2021-07-23 21:08:17,588 ----------------------------------------------------------------------------------------------------
2021-07-23 21:08:17,588 EPOCH 4 done: loss 0.3940 - lr 0.0000300
2021-07-23 21:08:18,744 DEV : loss 0.2193409502506256 - score 0.9566
2021-07-23 21:08:18,756 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:08:21,302 ----------------------------------------------------------------------------------------------------
2021-07-23 21:08:23,640 epoch 5 - iter 10/101 - loss 0.30479993 - samples/sec: 137.05 - lr: 0.000030
2021-07-23 21:08:25,952 epoch 5 - iter 20/101 - loss 0.32069356 - samples/sec: 138.45 - lr: 0.000030
2021-07-23 21:08:28,306 epoch 5 - iter 30/101 - loss 0.31789571 - samples/sec: 135.95 - lr: 0.000030
2021-07-23 21:08:30,573 epoch 5 - iter 40/101 - loss 0.31105150 - samples/sec: 141.24 - lr: 0.000030
2021-07-23 21:08:32,985 epoch 5 - iter 50/101 - loss 0.31057471 - samples/sec: 132.70 - lr: 0.000030
2021-07-23 21:08:35,155 epoch 5 - iter 60/101 - loss 0.30981974 - samples/sec: 147.50 - lr: 0.000030
2021-07-23 21:08:37,550 epoch 5 - iter 70/101 - loss 0.31766263 - samples/sec: 133.62 - lr: 0.000030
2021-07-23 21:08:39,835 epoch 5 - iter 80/101 - loss 0.31190422 - samples/sec: 140.13 - lr: 0.000030
2021-07-23 21:08:42,087 epoch 5 - iter 90/101 - loss 0.30835796 - samples/sec: 142.10 - lr: 0.000030
2021-07-23 21:08:44,415 epoch 5 - iter 100/101 - loss 0.30302769 - samples/sec: 137.52 - lr: 0.000030
2021-07-23 21:08:44,614 ----------------------------------------------------------------------------------------------------
2021-07-23 21:08:44,614 EPOCH 5 done: loss 0.3031 - lr 0.0000300
2021-07-23 21:08:45,774 DEV : loss 0.15894661843776703 - score 0.9638
2021-07-23 21:08:45,786 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:08:48,144 ----------------------------------------------------------------------------------------------------
2021-07-23 21:08:50,382 epoch 6 - iter 10/101 - loss 0.28795517 - samples/sec: 143.13 - lr: 0.000030
2021-07-23 21:08:52,616 epoch 6 - iter 20/101 - loss 0.27696269 - samples/sec: 143.28 - lr: 0.000030
2021-07-23 21:08:55,021 epoch 6 - iter 30/101 - loss 0.26729224 - samples/sec: 133.14 - lr: 0.000030
2021-07-23 21:08:57,416 epoch 6 - iter 40/101 - loss 0.25331322 - samples/sec: 133.64 - lr: 0.000030
2021-07-23 21:08:59,843 epoch 6 - iter 50/101 - loss 0.25282433 - samples/sec: 131.86 - lr: 0.000030
2021-07-23 21:09:02,100 epoch 6 - iter 60/101 - loss 0.24798583 - samples/sec: 141.88 - lr: 0.000030
2021-07-23 21:09:04,335 epoch 6 - iter 70/101 - loss 0.24686208 - samples/sec: 143.21 - lr: 0.000030
2021-07-23 21:09:06,666 epoch 6 - iter 80/101 - loss 0.24885083 - samples/sec: 137.31 - lr: 0.000030
2021-07-23 21:09:08,951 epoch 6 - iter 90/101 - loss 0.24604513 - samples/sec: 140.09 - lr: 0.000030
2021-07-23 21:09:11,327 epoch 6 - iter 100/101 - loss 0.24726937 - samples/sec: 134.69 - lr: 0.000030
2021-07-23 21:09:11,504 ----------------------------------------------------------------------------------------------------
2021-07-23 21:09:11,505 EPOCH 6 done: loss 0.2468 - lr 0.0000300
2021-07-23 21:09:12,663 DEV : loss 0.12737435102462769 - score 0.9723
2021-07-23 21:09:12,675 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:09:15,231 ----------------------------------------------------------------------------------------------------
2021-07-23 21:09:17,488 epoch 7 - iter 10/101 - loss 0.26113640 - samples/sec: 141.95 - lr: 0.000030
2021-07-23 21:09:19,687 epoch 7 - iter 20/101 - loss 0.24490941 - samples/sec: 145.61 - lr: 0.000030
2021-07-23 21:09:21,966 epoch 7 - iter 30/101 - loss 0.25073393 - samples/sec: 140.40 - lr: 0.000030
2021-07-23 21:09:24,338 epoch 7 - iter 40/101 - loss 0.24400538 - samples/sec: 134.94 - lr: 0.000030
2021-07-23 21:09:26,706 epoch 7 - iter 50/101 - loss 0.24521508 - samples/sec: 135.19 - lr: 0.000030
2021-07-23 21:09:29,043 epoch 7 - iter 60/101 - loss 0.24640271 - samples/sec: 136.98 - lr: 0.000030
2021-07-23 21:09:31,423 epoch 7 - iter 70/101 - loss 0.23931946 - samples/sec: 134.52 - lr: 0.000030
2021-07-23 21:09:33,639 epoch 7 - iter 80/101 - loss 0.23174163 - samples/sec: 144.42 - lr: 0.000030
2021-07-23 21:09:36,079 epoch 7 - iter 90/101 - loss 0.22470199 - samples/sec: 131.19 - lr: 0.000030
2021-07-23 21:09:38,376 epoch 7 - iter 100/101 - loss 0.22111010 - samples/sec: 139.35 - lr: 0.000030
2021-07-23 21:09:38,543 ----------------------------------------------------------------------------------------------------
2021-07-23 21:09:38,544 EPOCH 7 done: loss 0.2213 - lr 0.0000300
2021-07-23 21:09:39,705 DEV : loss 0.10603152215480804 - score 0.9752
2021-07-23 21:09:39,717 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:09:42,218 ----------------------------------------------------------------------------------------------------
2021-07-23 21:09:44,580 epoch 8 - iter 10/101 - loss 0.15648394 - samples/sec: 135.59 - lr: 0.000030
2021-07-23 21:09:46,879 epoch 8 - iter 20/101 - loss 0.16695400 - samples/sec: 139.28 - lr: 0.000030
2021-07-23 21:09:49,268 epoch 8 - iter 30/101 - loss 0.16977258 - samples/sec: 133.97 - lr: 0.000030
2021-07-23 21:09:51,471 epoch 8 - iter 40/101 - loss 0.15348323 - samples/sec: 145.33 - lr: 0.000030
2021-07-23 21:09:53,863 epoch 8 - iter 50/101 - loss 0.16210100 - samples/sec: 133.81 - lr: 0.000030
2021-07-23 21:09:56,204 epoch 8 - iter 60/101 - loss 0.16933466 - samples/sec: 136.74 - lr: 0.000030
2021-07-23 21:09:58,500 epoch 8 - iter 70/101 - loss 0.17186970 - samples/sec: 139.42 - lr: 0.000030
2021-07-23 21:10:00,809 epoch 8 - iter 80/101 - loss 0.18196011 - samples/sec: 138.61 - lr: 0.000030
2021-07-23 21:10:03,096 epoch 8 - iter 90/101 - loss 0.18154653 - samples/sec: 139.98 - lr: 0.000030
2021-07-23 21:10:05,348 epoch 8 - iter 100/101 - loss 0.18193448 - samples/sec: 142.11 - lr: 0.000030
2021-07-23 21:10:05,534 ----------------------------------------------------------------------------------------------------
2021-07-23 21:10:05,535 EPOCH 8 done: loss 0.1824 - lr 0.0000300
2021-07-23 21:10:06,696 DEV : loss 0.09270008653402328 - score 0.9766
2021-07-23 21:10:06,709 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:10:09,259 ----------------------------------------------------------------------------------------------------
2021-07-23 21:10:11,543 epoch 9 - iter 10/101 - loss 0.21838200 - samples/sec: 140.30 - lr: 0.000030
2021-07-23 21:10:13,799 epoch 9 - iter 20/101 - loss 0.18911859 - samples/sec: 141.89 - lr: 0.000030
2021-07-23 21:10:16,180 epoch 9 - iter 30/101 - loss 0.18007854 - samples/sec: 134.42 - lr: 0.000030
2021-07-23 21:10:18,471 epoch 9 - iter 40/101 - loss 0.18485470 - samples/sec: 139.69 - lr: 0.000030
2021-07-23 21:10:20,783 epoch 9 - iter 50/101 - loss 0.18191376 - samples/sec: 138.47 - lr: 0.000030
2021-07-23 21:10:22,979 epoch 9 - iter 60/101 - loss 0.17759618 - samples/sec: 145.79 - lr: 0.000030
2021-07-23 21:10:25,391 epoch 9 - iter 70/101 - loss 0.18231256 - samples/sec: 132.67 - lr: 0.000030
2021-07-23 21:10:27,739 epoch 9 - iter 80/101 - loss 0.17973715 - samples/sec: 136.35 - lr: 0.000030
2021-07-23 21:10:30,011 epoch 9 - iter 90/101 - loss 0.17758878 - samples/sec: 140.91 - lr: 0.000030
2021-07-23 21:10:32,282 epoch 9 - iter 100/101 - loss 0.17984177 - samples/sec: 140.92 - lr: 0.000030
2021-07-23 21:10:32,487 ----------------------------------------------------------------------------------------------------
2021-07-23 21:10:32,488 EPOCH 9 done: loss 0.1783 - lr 0.0000300
2021-07-23 21:10:33,647 DEV : loss 0.08317576348781586 - score 0.978
2021-07-23 21:10:33,660 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:10:36,029 ----------------------------------------------------------------------------------------------------
2021-07-23 21:10:38,391 epoch 10 - iter 10/101 - loss 0.12500708 - samples/sec: 135.63 - lr: 0.000030
2021-07-23 21:10:40,760 epoch 10 - iter 20/101 - loss 0.13253983 - samples/sec: 135.09 - lr: 0.000030
2021-07-23 21:10:43,078 epoch 10 - iter 30/101 - loss 0.15496945 - samples/sec: 138.09 - lr: 0.000030
2021-07-23 21:10:45,531 epoch 10 - iter 40/101 - loss 0.16034329 - samples/sec: 130.48 - lr: 0.000030
2021-07-23 21:10:47,840 epoch 10 - iter 50/101 - loss 0.17085286 - samples/sec: 138.65 - lr: 0.000030
2021-07-23 21:10:50,080 epoch 10 - iter 60/101 - loss 0.16558188 - samples/sec: 142.89 - lr: 0.000030
2021-07-23 21:10:52,293 epoch 10 - iter 70/101 - loss 0.16240437 - samples/sec: 144.68 - lr: 0.000030
2021-07-23 21:10:54,627 epoch 10 - iter 80/101 - loss 0.15884722 - samples/sec: 137.14 - lr: 0.000030
2021-07-23 21:10:56,836 epoch 10 - iter 90/101 - loss 0.16024948 - samples/sec: 144.89 - lr: 0.000030
2021-07-23 21:10:59,031 epoch 10 - iter 100/101 - loss 0.16111954 - samples/sec: 145.86 - lr: 0.000030
2021-07-23 21:10:59,231 ----------------------------------------------------------------------------------------------------
2021-07-23 21:10:59,231 EPOCH 10 done: loss 0.1605 - lr 0.0000300
2021-07-23 21:11:00,390 DEV : loss 0.07988086342811584 - score 0.9755
2021-07-23 21:11:00,403 BAD EPOCHS (no improvement): 1
2021-07-23 21:11:00,403 ----------------------------------------------------------------------------------------------------
2021-07-23 21:11:02,723 epoch 11 - iter 10/101 - loss 0.18100020 - samples/sec: 138.02 - lr: 0.000030
2021-07-23 21:11:05,047 epoch 11 - iter 20/101 - loss 0.18504467 - samples/sec: 137.74 - lr: 0.000030
2021-07-23 21:11:07,391 epoch 11 - iter 30/101 - loss 0.15477267 - samples/sec: 136.56 - lr: 0.000030
2021-07-23 21:11:09,652 epoch 11 - iter 40/101 - loss 0.15854071 - samples/sec: 141.59 - lr: 0.000030
2021-07-23 21:11:12,020 epoch 11 - iter 50/101 - loss 0.15093767 - samples/sec: 135.16 - lr: 0.000030
2021-07-23 21:11:14,399 epoch 11 - iter 60/101 - loss 0.14642296 - samples/sec: 134.54 - lr: 0.000030
2021-07-23 21:11:16,705 epoch 11 - iter 70/101 - loss 0.14719007 - samples/sec: 138.82 - lr: 0.000030
2021-07-23 21:11:18,949 epoch 11 - iter 80/101 - loss 0.14821642 - samples/sec: 142.67 - lr: 0.000030
2021-07-23 21:11:21,152 epoch 11 - iter 90/101 - loss 0.14892300 - samples/sec: 145.28 - lr: 0.000030
2021-07-23 21:11:23,456 epoch 11 - iter 100/101 - loss 0.15127752 - samples/sec: 138.93 - lr: 0.000030
2021-07-23 21:11:23,631 ----------------------------------------------------------------------------------------------------
2021-07-23 21:11:23,631 EPOCH 11 done: loss 0.1518 - lr 0.0000300
2021-07-23 21:11:24,790 DEV : loss 0.07078691571950912 - score 0.9808
2021-07-23 21:11:24,803 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:11:27,297 ----------------------------------------------------------------------------------------------------
2021-07-23 21:11:29,684 epoch 12 - iter 10/101 - loss 0.13583254 - samples/sec: 134.22 - lr: 0.000030
2021-07-23 21:11:31,931 epoch 12 - iter 20/101 - loss 0.14798820 - samples/sec: 142.43 - lr: 0.000030
2021-07-23 21:11:34,344 epoch 12 - iter 30/101 - loss 0.15440592 - samples/sec: 132.66 - lr: 0.000030
2021-07-23 21:11:36,797 epoch 12 - iter 40/101 - loss 0.15349726 - samples/sec: 130.50 - lr: 0.000030
2021-07-23 21:11:39,045 epoch 12 - iter 50/101 - loss 0.14622710 - samples/sec: 142.36 - lr: 0.000030
2021-07-23 21:11:41,267 epoch 12 - iter 60/101 - loss 0.14464547 - samples/sec: 144.09 - lr: 0.000030
2021-07-23 21:11:43,564 epoch 12 - iter 70/101 - loss 0.14033248 - samples/sec: 139.36 - lr: 0.000030
2021-07-23 21:11:45,932 epoch 12 - iter 80/101 - loss 0.14546402 - samples/sec: 135.15 - lr: 0.000030
2021-07-23 21:11:48,311 epoch 12 - iter 90/101 - loss 0.14676153 - samples/sec: 134.53 - lr: 0.000030
2021-07-23 21:11:50,544 epoch 12 - iter 100/101 - loss 0.14239286 - samples/sec: 143.38 - lr: 0.000030
2021-07-23 21:11:50,695 ----------------------------------------------------------------------------------------------------
2021-07-23 21:11:50,695 EPOCH 12 done: loss 0.1412 - lr 0.0000300
2021-07-23 21:11:51,856 DEV : loss 0.06877538561820984 - score 0.9784
2021-07-23 21:11:51,868 BAD EPOCHS (no improvement): 1
2021-07-23 21:11:51,869 ----------------------------------------------------------------------------------------------------
2021-07-23 21:11:54,164 epoch 13 - iter 10/101 - loss 0.11144793 - samples/sec: 139.54 - lr: 0.000030
2021-07-23 21:11:56,472 epoch 13 - iter 20/101 - loss 0.12455480 - samples/sec: 138.67 - lr: 0.000030
2021-07-23 21:11:58,704 epoch 13 - iter 30/101 - loss 0.12082347 - samples/sec: 143.42 - lr: 0.000030
2021-07-23 21:12:01,144 epoch 13 - iter 40/101 - loss 0.12691274 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 21:12:03,538 epoch 13 - iter 50/101 - loss 0.13503610 - samples/sec: 133.72 - lr: 0.000030
2021-07-23 21:12:05,749 epoch 13 - iter 60/101 - loss 0.13948216 - samples/sec: 144.82 - lr: 0.000030
2021-07-23 21:12:07,923 epoch 13 - iter 70/101 - loss 0.13885839 - samples/sec: 147.25 - lr: 0.000030
2021-07-23 21:12:10,312 epoch 13 - iter 80/101 - loss 0.14396730 - samples/sec: 134.00 - lr: 0.000030
2021-07-23 21:12:12,615 epoch 13 - iter 90/101 - loss 0.14594003 - samples/sec: 139.00 - lr: 0.000030
2021-07-23 21:12:14,941 epoch 13 - iter 100/101 - loss 0.14386771 - samples/sec: 137.61 - lr: 0.000030
2021-07-23 21:12:15,096 ----------------------------------------------------------------------------------------------------
2021-07-23 21:12:15,096 EPOCH 13 done: loss 0.1428 - lr 0.0000300
2021-07-23 21:12:16,251 DEV : loss 0.06179478019475937 - score 0.985
2021-07-23 21:12:16,264 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:12:18,814 ----------------------------------------------------------------------------------------------------
2021-07-23 21:12:21,257 epoch 14 - iter 10/101 - loss 0.13230538 - samples/sec: 131.13 - lr: 0.000030
2021-07-23 21:12:23,628 epoch 14 - iter 20/101 - loss 0.11929707 - samples/sec: 135.00 - lr: 0.000030
2021-07-23 21:12:25,907 epoch 14 - iter 30/101 - loss 0.12293925 - samples/sec: 140.43 - lr: 0.000030
2021-07-23 21:12:28,168 epoch 14 - iter 40/101 - loss 0.12451676 - samples/sec: 141.60 - lr: 0.000030
2021-07-23 21:12:30,472 epoch 14 - iter 50/101 - loss 0.12264223 - samples/sec: 138.89 - lr: 0.000030
2021-07-23 21:12:32,767 epoch 14 - iter 60/101 - loss 0.12258113 - samples/sec: 139.53 - lr: 0.000030
2021-07-23 21:12:35,061 epoch 14 - iter 70/101 - loss 0.12145255 - samples/sec: 139.54 - lr: 0.000030
2021-07-23 21:12:37,418 epoch 14 - iter 80/101 - loss 0.11838216 - samples/sec: 135.76 - lr: 0.000030
2021-07-23 21:12:39,688 epoch 14 - iter 90/101 - loss 0.11858976 - samples/sec: 141.06 - lr: 0.000030
2021-07-23 21:12:42,026 epoch 14 - iter 100/101 - loss 0.12337319 - samples/sec: 136.92 - lr: 0.000030
2021-07-23 21:12:42,190 ----------------------------------------------------------------------------------------------------
2021-07-23 21:12:42,190 EPOCH 14 done: loss 0.1225 - lr 0.0000300
2021-07-23 21:12:43,347 DEV : loss 0.06466455012559891 - score 0.9811
2021-07-23 21:12:43,359 BAD EPOCHS (no improvement): 1
2021-07-23 21:12:43,360 ----------------------------------------------------------------------------------------------------
2021-07-23 21:12:45,682 epoch 15 - iter 10/101 - loss 0.09203629 - samples/sec: 137.89 - lr: 0.000030
2021-07-23 21:12:48,001 epoch 15 - iter 20/101 - loss 0.11191854 - samples/sec: 138.02 - lr: 0.000030
2021-07-23 21:12:50,278 epoch 15 - iter 30/101 - loss 0.11703961 - samples/sec: 140.60 - lr: 0.000030
2021-07-23 21:12:52,507 epoch 15 - iter 40/101 - loss 0.11867997 - samples/sec: 143.61 - lr: 0.000030
2021-07-23 21:12:54,903 epoch 15 - iter 50/101 - loss 0.12819517 - samples/sec: 133.59 - lr: 0.000030
2021-07-23 21:12:57,219 epoch 15 - iter 60/101 - loss 0.12209872 - samples/sec: 138.23 - lr: 0.000030
2021-07-23 21:12:59,515 epoch 15 - iter 70/101 - loss 0.12112796 - samples/sec: 139.37 - lr: 0.000030
2021-07-23 21:13:01,792 epoch 15 - iter 80/101 - loss 0.12343687 - samples/sec: 140.61 - lr: 0.000030
2021-07-23 21:13:04,075 epoch 15 - iter 90/101 - loss 0.12436282 - samples/sec: 140.18 - lr: 0.000030
2021-07-23 21:13:06,346 epoch 15 - iter 100/101 - loss 0.12387760 - samples/sec: 140.98 - lr: 0.000030
2021-07-23 21:13:06,534 ----------------------------------------------------------------------------------------------------
2021-07-23 21:13:06,535 EPOCH 15 done: loss 0.1246 - lr 0.0000300
2021-07-23 21:13:07,692 DEV : loss 0.05936299264431 - score 0.9836
2021-07-23 21:13:07,705 BAD EPOCHS (no improvement): 2
2021-07-23 21:13:07,705 ----------------------------------------------------------------------------------------------------
2021-07-23 21:13:09,808 epoch 16 - iter 10/101 - loss 0.12089638 - samples/sec: 152.28 - lr: 0.000030
2021-07-23 21:13:12,087 epoch 16 - iter 20/101 - loss 0.11171945 - samples/sec: 140.48 - lr: 0.000030
2021-07-23 21:13:14,358 epoch 16 - iter 30/101 - loss 0.10913254 - samples/sec: 140.90 - lr: 0.000030
2021-07-23 21:13:16,623 epoch 16 - iter 40/101 - loss 0.10898302 - samples/sec: 141.37 - lr: 0.000030
2021-07-23 21:13:18,982 epoch 16 - iter 50/101 - loss 0.11005012 - samples/sec: 135.65 - lr: 0.000030
2021-07-23 21:13:21,404 epoch 16 - iter 60/101 - loss 0.11054283 - samples/sec: 132.17 - lr: 0.000030
2021-07-23 21:13:23,771 epoch 16 - iter 70/101 - loss 0.11349635 - samples/sec: 135.22 - lr: 0.000030
2021-07-23 21:13:26,124 epoch 16 - iter 80/101 - loss 0.11226213 - samples/sec: 136.07 - lr: 0.000030
2021-07-23 21:13:28,414 epoch 16 - iter 90/101 - loss 0.11124004 - samples/sec: 139.76 - lr: 0.000030
2021-07-23 21:13:30,704 epoch 16 - iter 100/101 - loss 0.11257532 - samples/sec: 139.79 - lr: 0.000030
2021-07-23 21:13:30,884 ----------------------------------------------------------------------------------------------------
2021-07-23 21:13:30,884 EPOCH 16 done: loss 0.1150 - lr 0.0000300
2021-07-23 21:13:32,040 DEV : loss 0.06597816199064255 - score 0.9798
2021-07-23 21:13:32,053 BAD EPOCHS (no improvement): 3
2021-07-23 21:13:32,053 ----------------------------------------------------------------------------------------------------
2021-07-23 21:13:34,278 epoch 17 - iter 10/101 - loss 0.08492490 - samples/sec: 143.92 - lr: 0.000030
2021-07-23 21:13:36,670 epoch 17 - iter 20/101 - loss 0.10355396 - samples/sec: 133.82 - lr: 0.000030
2021-07-23 21:13:38,943 epoch 17 - iter 30/101 - loss 0.09181695 - samples/sec: 140.83 - lr: 0.000030
2021-07-23 21:13:41,235 epoch 17 - iter 40/101 - loss 0.09647693 - samples/sec: 139.66 - lr: 0.000030
2021-07-23 21:13:43,691 epoch 17 - iter 50/101 - loss 0.10773391 - samples/sec: 130.32 - lr: 0.000030
2021-07-23 21:13:45,966 epoch 17 - iter 60/101 - loss 0.10965094 - samples/sec: 140.71 - lr: 0.000030
2021-07-23 21:13:48,284 epoch 17 - iter 70/101 - loss 0.11191226 - samples/sec: 138.08 - lr: 0.000030
2021-07-23 21:13:50,547 epoch 17 - iter 80/101 - loss 0.11432157 - samples/sec: 141.45 - lr: 0.000030
2021-07-23 21:13:52,784 epoch 17 - iter 90/101 - loss 0.11702707 - samples/sec: 143.10 - lr: 0.000030
2021-07-23 21:13:55,044 epoch 17 - iter 100/101 - loss 0.12025647 - samples/sec: 141.62 - lr: 0.000030
2021-07-23 21:13:55,232 ----------------------------------------------------------------------------------------------------
2021-07-23 21:13:55,232 EPOCH 17 done: loss 0.1206 - lr 0.0000300
2021-07-23 21:13:56,388 DEV : loss 0.05460144579410553 - score 0.9835
Epoch    17: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 21:13:56,401 BAD EPOCHS (no improvement): 4
2021-07-23 21:13:56,401 ----------------------------------------------------------------------------------------------------
2021-07-23 21:13:58,699 epoch 18 - iter 10/101 - loss 0.10717804 - samples/sec: 139.35 - lr: 0.000015
2021-07-23 21:14:01,087 epoch 18 - iter 20/101 - loss 0.11450801 - samples/sec: 134.06 - lr: 0.000015
2021-07-23 21:14:03,367 epoch 18 - iter 30/101 - loss 0.09907155 - samples/sec: 140.37 - lr: 0.000015
2021-07-23 21:14:05,698 epoch 18 - iter 40/101 - loss 0.10462604 - samples/sec: 137.32 - lr: 0.000015
2021-07-23 21:14:07,974 epoch 18 - iter 50/101 - loss 0.10684260 - samples/sec: 140.68 - lr: 0.000015
2021-07-23 21:14:10,300 epoch 18 - iter 60/101 - loss 0.10841596 - samples/sec: 137.58 - lr: 0.000015
2021-07-23 21:14:12,567 epoch 18 - iter 70/101 - loss 0.10961228 - samples/sec: 141.21 - lr: 0.000015
2021-07-23 21:14:14,911 epoch 18 - iter 80/101 - loss 0.11448745 - samples/sec: 136.59 - lr: 0.000015
2021-07-23 21:14:17,219 epoch 18 - iter 90/101 - loss 0.11524217 - samples/sec: 138.67 - lr: 0.000015
2021-07-23 21:14:19,447 epoch 18 - iter 100/101 - loss 0.11459492 - samples/sec: 143.65 - lr: 0.000015
2021-07-23 21:14:19,637 ----------------------------------------------------------------------------------------------------
2021-07-23 21:14:19,637 EPOCH 18 done: loss 0.1140 - lr 0.0000150
2021-07-23 21:14:20,795 DEV : loss 0.06383787840604782 - score 0.9825
2021-07-23 21:14:20,808 BAD EPOCHS (no improvement): 1
2021-07-23 21:14:20,808 ----------------------------------------------------------------------------------------------------
2021-07-23 21:14:23,204 epoch 19 - iter 10/101 - loss 0.09745045 - samples/sec: 133.63 - lr: 0.000015
2021-07-23 21:14:25,498 epoch 19 - iter 20/101 - loss 0.09081755 - samples/sec: 139.54 - lr: 0.000015
2021-07-23 21:14:27,768 epoch 19 - iter 30/101 - loss 0.08303212 - samples/sec: 141.00 - lr: 0.000015
2021-07-23 21:14:30,092 epoch 19 - iter 40/101 - loss 0.08639376 - samples/sec: 137.76 - lr: 0.000015
2021-07-23 21:14:32,363 epoch 19 - iter 50/101 - loss 0.09265088 - samples/sec: 140.96 - lr: 0.000015
2021-07-23 21:14:34,643 epoch 19 - iter 60/101 - loss 0.09301668 - samples/sec: 140.39 - lr: 0.000015
2021-07-23 21:14:36,863 epoch 19 - iter 70/101 - loss 0.09441692 - samples/sec: 144.16 - lr: 0.000015
2021-07-23 21:14:39,081 epoch 19 - iter 80/101 - loss 0.09829850 - samples/sec: 144.33 - lr: 0.000015
2021-07-23 21:14:41,494 epoch 19 - iter 90/101 - loss 0.09823943 - samples/sec: 132.68 - lr: 0.000015
2021-07-23 21:14:43,795 epoch 19 - iter 100/101 - loss 0.10012119 - samples/sec: 139.11 - lr: 0.000015
2021-07-23 21:14:43,995 ----------------------------------------------------------------------------------------------------
2021-07-23 21:14:43,995 EPOCH 19 done: loss 0.0997 - lr 0.0000150
2021-07-23 21:14:45,150 DEV : loss 0.05082423985004425 - score 0.9864
2021-07-23 21:14:45,163 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:14:47,559 ----------------------------------------------------------------------------------------------------
2021-07-23 21:14:49,835 epoch 20 - iter 10/101 - loss 0.12614479 - samples/sec: 140.77 - lr: 0.000015
2021-07-23 21:14:52,159 epoch 20 - iter 20/101 - loss 0.09798632 - samples/sec: 137.70 - lr: 0.000015
2021-07-23 21:14:54,459 epoch 20 - iter 30/101 - loss 0.10354139 - samples/sec: 139.20 - lr: 0.000015
2021-07-23 21:14:56,598 epoch 20 - iter 40/101 - loss 0.09894782 - samples/sec: 149.63 - lr: 0.000015
2021-07-23 21:14:59,023 epoch 20 - iter 50/101 - loss 0.09980183 - samples/sec: 132.02 - lr: 0.000015
2021-07-23 21:15:01,295 epoch 20 - iter 60/101 - loss 0.10553009 - samples/sec: 140.90 - lr: 0.000015
2021-07-23 21:15:03,551 epoch 20 - iter 70/101 - loss 0.10197379 - samples/sec: 141.89 - lr: 0.000015
2021-07-23 21:15:05,915 epoch 20 - iter 80/101 - loss 0.09927757 - samples/sec: 135.36 - lr: 0.000015
2021-07-23 21:15:08,235 epoch 20 - iter 90/101 - loss 0.09784371 - samples/sec: 138.02 - lr: 0.000015
2021-07-23 21:15:10,580 epoch 20 - iter 100/101 - loss 0.10082713 - samples/sec: 136.46 - lr: 0.000015
2021-07-23 21:15:10,761 ----------------------------------------------------------------------------------------------------
2021-07-23 21:15:10,761 EPOCH 20 done: loss 0.1007 - lr 0.0000150
2021-07-23 21:15:11,918 DEV : loss 0.057761672884225845 - score 0.9838
2021-07-23 21:15:11,931 BAD EPOCHS (no improvement): 1
2021-07-23 21:15:11,931 ----------------------------------------------------------------------------------------------------
2021-07-23 21:15:14,248 epoch 21 - iter 10/101 - loss 0.07626062 - samples/sec: 138.21 - lr: 0.000015
2021-07-23 21:15:16,475 epoch 21 - iter 20/101 - loss 0.09348891 - samples/sec: 143.74 - lr: 0.000015
2021-07-23 21:15:18,732 epoch 21 - iter 30/101 - loss 0.09230605 - samples/sec: 141.85 - lr: 0.000015
2021-07-23 21:15:21,063 epoch 21 - iter 40/101 - loss 0.09849839 - samples/sec: 137.32 - lr: 0.000015
2021-07-23 21:15:23,376 epoch 21 - iter 50/101 - loss 0.10294477 - samples/sec: 138.35 - lr: 0.000015
2021-07-23 21:15:25,648 epoch 21 - iter 60/101 - loss 0.10640260 - samples/sec: 140.92 - lr: 0.000015
2021-07-23 21:15:28,021 epoch 21 - iter 70/101 - loss 0.11214635 - samples/sec: 134.89 - lr: 0.000015
2021-07-23 21:15:30,400 epoch 21 - iter 80/101 - loss 0.11078903 - samples/sec: 134.52 - lr: 0.000015
2021-07-23 21:15:32,702 epoch 21 - iter 90/101 - loss 0.10951062 - samples/sec: 139.06 - lr: 0.000015
2021-07-23 21:15:34,945 epoch 21 - iter 100/101 - loss 0.10801387 - samples/sec: 142.75 - lr: 0.000015
2021-07-23 21:15:35,106 ----------------------------------------------------------------------------------------------------
2021-07-23 21:15:35,106 EPOCH 21 done: loss 0.1084 - lr 0.0000150
2021-07-23 21:15:36,265 DEV : loss 0.05475880578160286 - score 0.9811
2021-07-23 21:15:36,277 BAD EPOCHS (no improvement): 2
2021-07-23 21:15:36,277 ----------------------------------------------------------------------------------------------------
2021-07-23 21:15:38,694 epoch 22 - iter 10/101 - loss 0.08121187 - samples/sec: 132.49 - lr: 0.000015
2021-07-23 21:15:40,982 epoch 22 - iter 20/101 - loss 0.09368802 - samples/sec: 139.94 - lr: 0.000015
2021-07-23 21:15:43,399 epoch 22 - iter 30/101 - loss 0.09527480 - samples/sec: 132.40 - lr: 0.000015
2021-07-23 21:15:45,689 epoch 22 - iter 40/101 - loss 0.09277005 - samples/sec: 139.82 - lr: 0.000015
2021-07-23 21:15:48,010 epoch 22 - iter 50/101 - loss 0.09741867 - samples/sec: 137.87 - lr: 0.000015
2021-07-23 21:15:50,291 epoch 22 - iter 60/101 - loss 0.10469049 - samples/sec: 140.32 - lr: 0.000015
2021-07-23 21:15:52,579 epoch 22 - iter 70/101 - loss 0.10566193 - samples/sec: 139.94 - lr: 0.000015
2021-07-23 21:15:54,851 epoch 22 - iter 80/101 - loss 0.10255266 - samples/sec: 140.86 - lr: 0.000015
2021-07-23 21:15:57,215 epoch 22 - iter 90/101 - loss 0.10086200 - samples/sec: 135.44 - lr: 0.000015
2021-07-23 21:15:59,460 epoch 22 - iter 100/101 - loss 0.10197352 - samples/sec: 142.55 - lr: 0.000015
2021-07-23 21:15:59,643 ----------------------------------------------------------------------------------------------------
2021-07-23 21:15:59,644 EPOCH 22 done: loss 0.1018 - lr 0.0000150
2021-07-23 21:16:00,801 DEV : loss 0.04699503630399704 - score 0.9864
2021-07-23 21:16:00,814 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:16:03,407 ----------------------------------------------------------------------------------------------------
2021-07-23 21:16:05,807 epoch 23 - iter 10/101 - loss 0.08249401 - samples/sec: 133.48 - lr: 0.000015
2021-07-23 21:16:08,079 epoch 23 - iter 20/101 - loss 0.08410023 - samples/sec: 140.89 - lr: 0.000015
2021-07-23 21:16:10,292 epoch 23 - iter 30/101 - loss 0.07720175 - samples/sec: 144.66 - lr: 0.000015
2021-07-23 21:16:12,528 epoch 23 - iter 40/101 - loss 0.07693665 - samples/sec: 143.15 - lr: 0.000015
2021-07-23 21:16:14,706 epoch 23 - iter 50/101 - loss 0.09073534 - samples/sec: 146.94 - lr: 0.000015
2021-07-23 21:16:17,083 epoch 23 - iter 60/101 - loss 0.09608347 - samples/sec: 134.69 - lr: 0.000015
2021-07-23 21:16:19,258 epoch 23 - iter 70/101 - loss 0.09563188 - samples/sec: 147.18 - lr: 0.000015
2021-07-23 21:16:21,552 epoch 23 - iter 80/101 - loss 0.09673051 - samples/sec: 139.51 - lr: 0.000015
2021-07-23 21:16:23,947 epoch 23 - iter 90/101 - loss 0.10024302 - samples/sec: 133.62 - lr: 0.000015
2021-07-23 21:16:26,356 epoch 23 - iter 100/101 - loss 0.09859685 - samples/sec: 132.92 - lr: 0.000015
2021-07-23 21:16:26,552 ----------------------------------------------------------------------------------------------------
2021-07-23 21:16:26,552 EPOCH 23 done: loss 0.0982 - lr 0.0000150
2021-07-23 21:16:27,709 DEV : loss 0.04588615149259567 - score 0.9877
2021-07-23 21:16:27,722 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:16:30,040 ----------------------------------------------------------------------------------------------------
2021-07-23 21:16:32,351 epoch 24 - iter 10/101 - loss 0.12812165 - samples/sec: 138.57 - lr: 0.000015
2021-07-23 21:16:34,666 epoch 24 - iter 20/101 - loss 0.11184072 - samples/sec: 138.28 - lr: 0.000015
2021-07-23 21:16:36,899 epoch 24 - iter 30/101 - loss 0.09815357 - samples/sec: 143.31 - lr: 0.000015
2021-07-23 21:16:39,167 epoch 24 - iter 40/101 - loss 0.10088331 - samples/sec: 141.16 - lr: 0.000015
2021-07-23 21:16:41,628 epoch 24 - iter 50/101 - loss 0.10399642 - samples/sec: 130.08 - lr: 0.000015
2021-07-23 21:16:43,875 epoch 24 - iter 60/101 - loss 0.10969214 - samples/sec: 142.45 - lr: 0.000015
2021-07-23 21:16:46,119 epoch 24 - iter 70/101 - loss 0.10826638 - samples/sec: 142.63 - lr: 0.000015
2021-07-23 21:16:48,408 epoch 24 - iter 80/101 - loss 0.10566962 - samples/sec: 139.85 - lr: 0.000015
2021-07-23 21:16:50,750 epoch 24 - iter 90/101 - loss 0.10236156 - samples/sec: 136.64 - lr: 0.000015
2021-07-23 21:16:53,076 epoch 24 - iter 100/101 - loss 0.10068783 - samples/sec: 137.66 - lr: 0.000015
2021-07-23 21:16:53,263 ----------------------------------------------------------------------------------------------------
2021-07-23 21:16:53,263 EPOCH 24 done: loss 0.0998 - lr 0.0000150
2021-07-23 21:16:54,421 DEV : loss 0.05573347210884094 - score 0.9825
2021-07-23 21:16:54,434 BAD EPOCHS (no improvement): 1
2021-07-23 21:16:54,434 ----------------------------------------------------------------------------------------------------
2021-07-23 21:16:56,734 epoch 25 - iter 10/101 - loss 0.13908674 - samples/sec: 139.21 - lr: 0.000015
2021-07-23 21:16:59,140 epoch 25 - iter 20/101 - loss 0.11967202 - samples/sec: 133.07 - lr: 0.000015
2021-07-23 21:17:01,468 epoch 25 - iter 30/101 - loss 0.10723389 - samples/sec: 137.50 - lr: 0.000015
2021-07-23 21:17:03,651 epoch 25 - iter 40/101 - loss 0.10381090 - samples/sec: 146.62 - lr: 0.000015
2021-07-23 21:17:06,024 epoch 25 - iter 50/101 - loss 0.10398797 - samples/sec: 134.90 - lr: 0.000015
2021-07-23 21:17:08,353 epoch 25 - iter 60/101 - loss 0.10288369 - samples/sec: 137.45 - lr: 0.000015
2021-07-23 21:17:10,544 epoch 25 - iter 70/101 - loss 0.10169348 - samples/sec: 146.10 - lr: 0.000015
2021-07-23 21:17:12,838 epoch 25 - iter 80/101 - loss 0.09966398 - samples/sec: 139.50 - lr: 0.000015
2021-07-23 21:17:15,196 epoch 25 - iter 90/101 - loss 0.09707056 - samples/sec: 135.75 - lr: 0.000015
2021-07-23 21:17:17,484 epoch 25 - iter 100/101 - loss 0.09590787 - samples/sec: 139.94 - lr: 0.000015
2021-07-23 21:17:17,660 ----------------------------------------------------------------------------------------------------
2021-07-23 21:17:17,660 EPOCH 25 done: loss 0.0953 - lr 0.0000150
2021-07-23 21:17:18,817 DEV : loss 0.050568997859954834 - score 0.9852
2021-07-23 21:17:18,830 BAD EPOCHS (no improvement): 2
2021-07-23 21:17:18,830 ----------------------------------------------------------------------------------------------------
2021-07-23 21:17:21,059 epoch 26 - iter 10/101 - loss 0.09643274 - samples/sec: 143.70 - lr: 0.000015
2021-07-23 21:17:23,417 epoch 26 - iter 20/101 - loss 0.11123628 - samples/sec: 135.75 - lr: 0.000015
2021-07-23 21:17:25,702 epoch 26 - iter 30/101 - loss 0.11784723 - samples/sec: 140.11 - lr: 0.000015
2021-07-23 21:17:28,012 epoch 26 - iter 40/101 - loss 0.11220448 - samples/sec: 138.55 - lr: 0.000015
2021-07-23 21:17:30,228 epoch 26 - iter 50/101 - loss 0.11080674 - samples/sec: 144.46 - lr: 0.000015
2021-07-23 21:17:32,570 epoch 26 - iter 60/101 - loss 0.10734968 - samples/sec: 136.67 - lr: 0.000015
2021-07-23 21:17:34,812 epoch 26 - iter 70/101 - loss 0.10034611 - samples/sec: 142.78 - lr: 0.000015
2021-07-23 21:17:37,148 epoch 26 - iter 80/101 - loss 0.10120319 - samples/sec: 137.01 - lr: 0.000015
2021-07-23 21:17:39,453 epoch 26 - iter 90/101 - loss 0.10114149 - samples/sec: 138.90 - lr: 0.000015
2021-07-23 21:17:41,799 epoch 26 - iter 100/101 - loss 0.10493980 - samples/sec: 136.40 - lr: 0.000015
2021-07-23 21:17:41,970 ----------------------------------------------------------------------------------------------------
2021-07-23 21:17:41,971 EPOCH 26 done: loss 0.1046 - lr 0.0000150
2021-07-23 21:17:43,129 DEV : loss 0.05526920408010483 - score 0.9838
2021-07-23 21:17:43,142 BAD EPOCHS (no improvement): 3
2021-07-23 21:17:43,142 ----------------------------------------------------------------------------------------------------
2021-07-23 21:17:45,427 epoch 27 - iter 10/101 - loss 0.08887328 - samples/sec: 140.11 - lr: 0.000015
2021-07-23 21:17:47,827 epoch 27 - iter 20/101 - loss 0.09598202 - samples/sec: 133.39 - lr: 0.000015
2021-07-23 21:17:50,091 epoch 27 - iter 30/101 - loss 0.09718889 - samples/sec: 141.40 - lr: 0.000015
2021-07-23 21:17:52,459 epoch 27 - iter 40/101 - loss 0.09911846 - samples/sec: 135.14 - lr: 0.000015
2021-07-23 21:17:54,736 epoch 27 - iter 50/101 - loss 0.10125480 - samples/sec: 140.63 - lr: 0.000015
2021-07-23 21:17:57,090 epoch 27 - iter 60/101 - loss 0.10919047 - samples/sec: 135.94 - lr: 0.000015
2021-07-23 21:17:59,412 epoch 27 - iter 70/101 - loss 0.10521152 - samples/sec: 137.89 - lr: 0.000015
2021-07-23 21:18:01,666 epoch 27 - iter 80/101 - loss 0.10155738 - samples/sec: 141.97 - lr: 0.000015
2021-07-23 21:18:03,904 epoch 27 - iter 90/101 - loss 0.10120557 - samples/sec: 143.04 - lr: 0.000015
2021-07-23 21:18:06,134 epoch 27 - iter 100/101 - loss 0.09899568 - samples/sec: 143.56 - lr: 0.000015
2021-07-23 21:18:06,314 ----------------------------------------------------------------------------------------------------
2021-07-23 21:18:06,315 EPOCH 27 done: loss 0.0999 - lr 0.0000150
2021-07-23 21:18:07,474 DEV : loss 0.04602641612291336 - score 0.9864
Epoch    27: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 21:18:07,486 BAD EPOCHS (no improvement): 4
2021-07-23 21:18:07,486 ----------------------------------------------------------------------------------------------------
2021-07-23 21:18:09,852 epoch 28 - iter 10/101 - loss 0.09102393 - samples/sec: 135.36 - lr: 0.000008
2021-07-23 21:18:12,176 epoch 28 - iter 20/101 - loss 0.07388472 - samples/sec: 137.70 - lr: 0.000008
2021-07-23 21:18:14,564 epoch 28 - iter 30/101 - loss 0.07450725 - samples/sec: 134.07 - lr: 0.000008
2021-07-23 21:18:16,758 epoch 28 - iter 40/101 - loss 0.08163244 - samples/sec: 145.90 - lr: 0.000008
2021-07-23 21:18:18,970 epoch 28 - iter 50/101 - loss 0.07862794 - samples/sec: 144.71 - lr: 0.000008
2021-07-23 21:18:21,307 epoch 28 - iter 60/101 - loss 0.07813841 - samples/sec: 136.94 - lr: 0.000008
2021-07-23 21:18:23,626 epoch 28 - iter 70/101 - loss 0.08214352 - samples/sec: 138.05 - lr: 0.000008
2021-07-23 21:18:25,895 epoch 28 - iter 80/101 - loss 0.08584835 - samples/sec: 141.08 - lr: 0.000008
2021-07-23 21:18:28,196 epoch 28 - iter 90/101 - loss 0.09093699 - samples/sec: 139.10 - lr: 0.000008
2021-07-23 21:18:30,495 epoch 28 - iter 100/101 - loss 0.09485842 - samples/sec: 139.26 - lr: 0.000008
2021-07-23 21:18:30,648 ----------------------------------------------------------------------------------------------------
2021-07-23 21:18:30,648 EPOCH 28 done: loss 0.0942 - lr 0.0000075
2021-07-23 21:18:31,805 DEV : loss 0.04478133097290993 - score 0.9864
2021-07-23 21:18:31,817 BAD EPOCHS (no improvement): 1
2021-07-23 21:18:31,818 ----------------------------------------------------------------------------------------------------
2021-07-23 21:18:34,331 epoch 29 - iter 10/101 - loss 0.09692899 - samples/sec: 127.39 - lr: 0.000008
2021-07-23 21:18:36,656 epoch 29 - iter 20/101 - loss 0.09487997 - samples/sec: 137.67 - lr: 0.000008
2021-07-23 21:18:38,871 epoch 29 - iter 30/101 - loss 0.10454516 - samples/sec: 144.51 - lr: 0.000008
2021-07-23 21:18:41,150 epoch 29 - iter 40/101 - loss 0.10063312 - samples/sec: 140.47 - lr: 0.000008
2021-07-23 21:18:43,466 epoch 29 - iter 50/101 - loss 0.10114576 - samples/sec: 138.21 - lr: 0.000008
2021-07-23 21:18:45,723 epoch 29 - iter 60/101 - loss 0.09636803 - samples/sec: 141.81 - lr: 0.000008
2021-07-23 21:18:48,106 epoch 29 - iter 70/101 - loss 0.09665563 - samples/sec: 134.31 - lr: 0.000008
2021-07-23 21:18:50,400 epoch 29 - iter 80/101 - loss 0.09780931 - samples/sec: 139.54 - lr: 0.000008
2021-07-23 21:18:52,780 epoch 29 - iter 90/101 - loss 0.10239634 - samples/sec: 134.49 - lr: 0.000008
2021-07-23 21:18:54,979 epoch 29 - iter 100/101 - loss 0.10087420 - samples/sec: 145.57 - lr: 0.000008
2021-07-23 21:18:55,171 ----------------------------------------------------------------------------------------------------
2021-07-23 21:18:55,171 EPOCH 29 done: loss 0.1003 - lr 0.0000075
2021-07-23 21:18:56,328 DEV : loss 0.051177140325307846 - score 0.9838
2021-07-23 21:18:56,340 BAD EPOCHS (no improvement): 2
2021-07-23 21:18:56,340 ----------------------------------------------------------------------------------------------------
2021-07-23 21:18:58,660 epoch 30 - iter 10/101 - loss 0.10923944 - samples/sec: 138.03 - lr: 0.000008
2021-07-23 21:19:00,976 epoch 30 - iter 20/101 - loss 0.09471544 - samples/sec: 138.20 - lr: 0.000008
2021-07-23 21:19:03,337 epoch 30 - iter 30/101 - loss 0.08216678 - samples/sec: 135.62 - lr: 0.000008
2021-07-23 21:19:05,584 epoch 30 - iter 40/101 - loss 0.08542187 - samples/sec: 142.42 - lr: 0.000008
2021-07-23 21:19:07,843 epoch 30 - iter 50/101 - loss 0.09120487 - samples/sec: 141.71 - lr: 0.000008
2021-07-23 21:19:10,278 epoch 30 - iter 60/101 - loss 0.09528941 - samples/sec: 131.44 - lr: 0.000008
2021-07-23 21:19:12,560 epoch 30 - iter 70/101 - loss 0.09364722 - samples/sec: 140.32 - lr: 0.000008
2021-07-23 21:19:14,823 epoch 30 - iter 80/101 - loss 0.09029898 - samples/sec: 141.41 - lr: 0.000008
2021-07-23 21:19:17,023 epoch 30 - iter 90/101 - loss 0.09556405 - samples/sec: 145.54 - lr: 0.000008
2021-07-23 21:19:19,368 epoch 30 - iter 100/101 - loss 0.09496056 - samples/sec: 136.46 - lr: 0.000008
2021-07-23 21:19:19,551 ----------------------------------------------------------------------------------------------------
2021-07-23 21:19:19,551 EPOCH 30 done: loss 0.0941 - lr 0.0000075
2021-07-23 21:19:20,709 DEV : loss 0.04987897723913193 - score 0.9865
2021-07-23 21:19:20,721 BAD EPOCHS (no improvement): 3
2021-07-23 21:19:20,722 ----------------------------------------------------------------------------------------------------
2021-07-23 21:19:22,955 epoch 31 - iter 10/101 - loss 0.10286658 - samples/sec: 143.41 - lr: 0.000008
2021-07-23 21:19:25,303 epoch 31 - iter 20/101 - loss 0.10750739 - samples/sec: 136.33 - lr: 0.000008
2021-07-23 21:19:27,530 epoch 31 - iter 30/101 - loss 0.09912264 - samples/sec: 143.71 - lr: 0.000008
2021-07-23 21:19:29,923 epoch 31 - iter 40/101 - loss 0.09690023 - samples/sec: 133.76 - lr: 0.000008
2021-07-23 21:19:32,283 epoch 31 - iter 50/101 - loss 0.10270162 - samples/sec: 135.61 - lr: 0.000008
2021-07-23 21:19:34,487 epoch 31 - iter 60/101 - loss 0.11207959 - samples/sec: 145.25 - lr: 0.000008
2021-07-23 21:19:36,843 epoch 31 - iter 70/101 - loss 0.10708085 - samples/sec: 135.88 - lr: 0.000008
2021-07-23 21:19:39,227 epoch 31 - iter 80/101 - loss 0.10597568 - samples/sec: 134.22 - lr: 0.000008
2021-07-23 21:19:41,487 epoch 31 - iter 90/101 - loss 0.10143033 - samples/sec: 141.67 - lr: 0.000008
2021-07-23 21:19:43,703 epoch 31 - iter 100/101 - loss 0.10084669 - samples/sec: 144.47 - lr: 0.000008
2021-07-23 21:19:43,895 ----------------------------------------------------------------------------------------------------
2021-07-23 21:19:43,895 EPOCH 31 done: loss 0.1003 - lr 0.0000075
2021-07-23 21:19:45,052 DEV : loss 0.05241413041949272 - score 0.9838
Epoch    31: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 21:19:45,065 BAD EPOCHS (no improvement): 4
2021-07-23 21:19:45,065 ----------------------------------------------------------------------------------------------------
2021-07-23 21:19:47,334 epoch 32 - iter 10/101 - loss 0.16005825 - samples/sec: 141.13 - lr: 0.000004
2021-07-23 21:19:49,659 epoch 32 - iter 20/101 - loss 0.12269316 - samples/sec: 137.72 - lr: 0.000004
2021-07-23 21:19:51,952 epoch 32 - iter 30/101 - loss 0.10658561 - samples/sec: 139.58 - lr: 0.000004
2021-07-23 21:19:54,255 epoch 32 - iter 40/101 - loss 0.09682343 - samples/sec: 138.99 - lr: 0.000004
2021-07-23 21:19:56,559 epoch 32 - iter 50/101 - loss 0.09183784 - samples/sec: 138.93 - lr: 0.000004
2021-07-23 21:19:59,031 epoch 32 - iter 60/101 - loss 0.09091086 - samples/sec: 129.50 - lr: 0.000004
2021-07-23 21:20:01,271 epoch 32 - iter 70/101 - loss 0.09097055 - samples/sec: 142.90 - lr: 0.000004
2021-07-23 21:20:03,538 epoch 32 - iter 80/101 - loss 0.09260544 - samples/sec: 141.20 - lr: 0.000004
2021-07-23 21:20:05,772 epoch 32 - iter 90/101 - loss 0.09504193 - samples/sec: 143.28 - lr: 0.000004
2021-07-23 21:20:08,077 epoch 32 - iter 100/101 - loss 0.09703022 - samples/sec: 138.88 - lr: 0.000004
2021-07-23 21:20:08,271 ----------------------------------------------------------------------------------------------------
2021-07-23 21:20:08,271 EPOCH 32 done: loss 0.0991 - lr 0.0000038
2021-07-23 21:20:09,424 DEV : loss 0.049149464815855026 - score 0.9865
2021-07-23 21:20:09,436 BAD EPOCHS (no improvement): 1
2021-07-23 21:20:09,436 ----------------------------------------------------------------------------------------------------
2021-07-23 21:20:11,735 epoch 33 - iter 10/101 - loss 0.08046050 - samples/sec: 139.31 - lr: 0.000004
2021-07-23 21:20:14,148 epoch 33 - iter 20/101 - loss 0.07755238 - samples/sec: 132.64 - lr: 0.000004
2021-07-23 21:20:16,511 epoch 33 - iter 30/101 - loss 0.07658638 - samples/sec: 135.49 - lr: 0.000004
2021-07-23 21:20:18,824 epoch 33 - iter 40/101 - loss 0.08647300 - samples/sec: 138.38 - lr: 0.000004
2021-07-23 21:20:21,107 epoch 33 - iter 50/101 - loss 0.08179572 - samples/sec: 140.19 - lr: 0.000004
2021-07-23 21:20:23,446 epoch 33 - iter 60/101 - loss 0.07906433 - samples/sec: 136.88 - lr: 0.000004
2021-07-23 21:20:25,806 epoch 33 - iter 70/101 - loss 0.07961799 - samples/sec: 135.61 - lr: 0.000004
2021-07-23 21:20:28,118 epoch 33 - iter 80/101 - loss 0.08405000 - samples/sec: 138.44 - lr: 0.000004
2021-07-23 21:20:30,363 epoch 33 - iter 90/101 - loss 0.08311929 - samples/sec: 142.57 - lr: 0.000004
2021-07-23 21:20:32,620 epoch 33 - iter 100/101 - loss 0.08413970 - samples/sec: 141.82 - lr: 0.000004
2021-07-23 21:20:32,793 ----------------------------------------------------------------------------------------------------
2021-07-23 21:20:32,793 EPOCH 33 done: loss 0.0839 - lr 0.0000038
2021-07-23 21:20:33,949 DEV : loss 0.04607296735048294 - score 0.9878
2021-07-23 21:20:33,961 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:20:36,313 ----------------------------------------------------------------------------------------------------
2021-07-23 21:20:38,684 epoch 34 - iter 10/101 - loss 0.05721540 - samples/sec: 135.10 - lr: 0.000004
2021-07-23 21:20:41,084 epoch 34 - iter 20/101 - loss 0.06137326 - samples/sec: 133.37 - lr: 0.000004
2021-07-23 21:20:43,483 epoch 34 - iter 30/101 - loss 0.06874616 - samples/sec: 133.47 - lr: 0.000004
2021-07-23 21:20:45,723 epoch 34 - iter 40/101 - loss 0.07130019 - samples/sec: 142.87 - lr: 0.000004
2021-07-23 21:20:48,009 epoch 34 - iter 50/101 - loss 0.07321934 - samples/sec: 140.00 - lr: 0.000004
2021-07-23 21:20:50,286 epoch 34 - iter 60/101 - loss 0.07893705 - samples/sec: 140.59 - lr: 0.000004
2021-07-23 21:20:52,618 epoch 34 - iter 70/101 - loss 0.07643773 - samples/sec: 137.25 - lr: 0.000004
2021-07-23 21:20:54,967 epoch 34 - iter 80/101 - loss 0.08077898 - samples/sec: 136.27 - lr: 0.000004
2021-07-23 21:20:57,164 epoch 34 - iter 90/101 - loss 0.08136806 - samples/sec: 145.73 - lr: 0.000004
2021-07-23 21:20:59,511 epoch 34 - iter 100/101 - loss 0.08405973 - samples/sec: 136.36 - lr: 0.000004
2021-07-23 21:20:59,696 ----------------------------------------------------------------------------------------------------
2021-07-23 21:20:59,696 EPOCH 34 done: loss 0.0836 - lr 0.0000038
2021-07-23 21:21:00,854 DEV : loss 0.045542195439338684 - score 0.9878
2021-07-23 21:21:00,867 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:21:03,785 ----------------------------------------------------------------------------------------------------
2021-07-23 21:21:06,075 epoch 35 - iter 10/101 - loss 0.08756497 - samples/sec: 139.88 - lr: 0.000004
2021-07-23 21:21:08,299 epoch 35 - iter 20/101 - loss 0.10305062 - samples/sec: 143.94 - lr: 0.000004
2021-07-23 21:21:10,651 epoch 35 - iter 30/101 - loss 0.10561813 - samples/sec: 136.07 - lr: 0.000004
2021-07-23 21:21:12,903 epoch 35 - iter 40/101 - loss 0.10714938 - samples/sec: 142.15 - lr: 0.000004
2021-07-23 21:21:15,149 epoch 35 - iter 50/101 - loss 0.10248911 - samples/sec: 142.54 - lr: 0.000004
2021-07-23 21:21:17,471 epoch 35 - iter 60/101 - loss 0.09681649 - samples/sec: 137.82 - lr: 0.000004
2021-07-23 21:21:19,819 epoch 35 - iter 70/101 - loss 0.09524410 - samples/sec: 136.31 - lr: 0.000004
2021-07-23 21:21:22,117 epoch 35 - iter 80/101 - loss 0.09943117 - samples/sec: 139.34 - lr: 0.000004
2021-07-23 21:21:24,536 epoch 35 - iter 90/101 - loss 0.09769324 - samples/sec: 132.29 - lr: 0.000004
2021-07-23 21:21:26,773 epoch 35 - iter 100/101 - loss 0.09486629 - samples/sec: 143.13 - lr: 0.000004
2021-07-23 21:21:26,930 ----------------------------------------------------------------------------------------------------
2021-07-23 21:21:26,930 EPOCH 35 done: loss 0.0940 - lr 0.0000038
2021-07-23 21:21:28,085 DEV : loss 0.04649531468749046 - score 0.9878
2021-07-23 21:21:28,097 BAD EPOCHS (no improvement): 1
2021-07-23 21:21:28,097 ----------------------------------------------------------------------------------------------------
2021-07-23 21:21:30,364 epoch 36 - iter 10/101 - loss 0.10080203 - samples/sec: 141.30 - lr: 0.000004
2021-07-23 21:21:32,588 epoch 36 - iter 20/101 - loss 0.09430776 - samples/sec: 143.94 - lr: 0.000004
2021-07-23 21:21:34,796 epoch 36 - iter 30/101 - loss 0.09754766 - samples/sec: 144.98 - lr: 0.000004
2021-07-23 21:21:37,116 epoch 36 - iter 40/101 - loss 0.09729713 - samples/sec: 137.94 - lr: 0.000004
2021-07-23 21:21:39,496 epoch 36 - iter 50/101 - loss 0.10108157 - samples/sec: 134.49 - lr: 0.000004
2021-07-23 21:21:41,911 epoch 36 - iter 60/101 - loss 0.09734493 - samples/sec: 132.54 - lr: 0.000004
2021-07-23 21:21:44,172 epoch 36 - iter 70/101 - loss 0.09648252 - samples/sec: 141.58 - lr: 0.000004
2021-07-23 21:21:46,563 epoch 36 - iter 80/101 - loss 0.09490508 - samples/sec: 133.90 - lr: 0.000004
2021-07-23 21:21:48,938 epoch 36 - iter 90/101 - loss 0.09422810 - samples/sec: 134.74 - lr: 0.000004
2021-07-23 21:21:51,212 epoch 36 - iter 100/101 - loss 0.09690555 - samples/sec: 140.75 - lr: 0.000004
2021-07-23 21:21:51,399 ----------------------------------------------------------------------------------------------------
2021-07-23 21:21:51,400 EPOCH 36 done: loss 0.0965 - lr 0.0000038
2021-07-23 21:21:52,558 DEV : loss 0.04686586931347847 - score 0.9878
2021-07-23 21:21:52,570 BAD EPOCHS (no improvement): 2
2021-07-23 21:21:52,571 ----------------------------------------------------------------------------------------------------
2021-07-23 21:21:54,927 epoch 37 - iter 10/101 - loss 0.07445066 - samples/sec: 135.88 - lr: 0.000004
2021-07-23 21:21:57,124 epoch 37 - iter 20/101 - loss 0.06913666 - samples/sec: 145.71 - lr: 0.000004
2021-07-23 21:21:59,448 epoch 37 - iter 30/101 - loss 0.06657130 - samples/sec: 137.74 - lr: 0.000004
2021-07-23 21:22:01,773 epoch 37 - iter 40/101 - loss 0.07728323 - samples/sec: 137.66 - lr: 0.000004
2021-07-23 21:22:04,077 epoch 37 - iter 50/101 - loss 0.08603398 - samples/sec: 138.97 - lr: 0.000004
2021-07-23 21:22:06,356 epoch 37 - iter 60/101 - loss 0.08427415 - samples/sec: 140.41 - lr: 0.000004
2021-07-23 21:22:08,659 epoch 37 - iter 70/101 - loss 0.08333096 - samples/sec: 139.04 - lr: 0.000004
2021-07-23 21:22:11,004 epoch 37 - iter 80/101 - loss 0.08711224 - samples/sec: 136.50 - lr: 0.000004
2021-07-23 21:22:13,315 epoch 37 - iter 90/101 - loss 0.08558216 - samples/sec: 138.47 - lr: 0.000004
2021-07-23 21:22:15,612 epoch 37 - iter 100/101 - loss 0.08781186 - samples/sec: 139.39 - lr: 0.000004
2021-07-23 21:22:15,799 ----------------------------------------------------------------------------------------------------
2021-07-23 21:22:15,799 EPOCH 37 done: loss 0.0871 - lr 0.0000038
2021-07-23 21:22:16,954 DEV : loss 0.045271798968315125 - score 0.9878
2021-07-23 21:22:16,967 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:22:19,442 ----------------------------------------------------------------------------------------------------
2021-07-23 21:22:21,857 epoch 38 - iter 10/101 - loss 0.09534445 - samples/sec: 132.64 - lr: 0.000004
2021-07-23 21:22:24,164 epoch 38 - iter 20/101 - loss 0.10365199 - samples/sec: 138.75 - lr: 0.000004
2021-07-23 21:22:26,436 epoch 38 - iter 30/101 - loss 0.09630004 - samples/sec: 140.86 - lr: 0.000004
2021-07-23 21:22:28,651 epoch 38 - iter 40/101 - loss 0.09060004 - samples/sec: 144.49 - lr: 0.000004
2021-07-23 21:22:30,971 epoch 38 - iter 50/101 - loss 0.09023871 - samples/sec: 138.03 - lr: 0.000004
2021-07-23 21:22:33,337 epoch 38 - iter 60/101 - loss 0.08813178 - samples/sec: 135.28 - lr: 0.000004
2021-07-23 21:22:35,696 epoch 38 - iter 70/101 - loss 0.08301252 - samples/sec: 135.69 - lr: 0.000004
2021-07-23 21:22:38,008 epoch 38 - iter 80/101 - loss 0.08267663 - samples/sec: 138.43 - lr: 0.000004
2021-07-23 21:22:40,331 epoch 38 - iter 90/101 - loss 0.08021352 - samples/sec: 137.77 - lr: 0.000004
2021-07-23 21:22:42,571 epoch 38 - iter 100/101 - loss 0.08561089 - samples/sec: 142.90 - lr: 0.000004
2021-07-23 21:22:42,752 ----------------------------------------------------------------------------------------------------
2021-07-23 21:22:42,752 EPOCH 38 done: loss 0.0857 - lr 0.0000038
2021-07-23 21:22:43,906 DEV : loss 0.0433785505592823 - score 0.9864
2021-07-23 21:22:43,919 BAD EPOCHS (no improvement): 1
2021-07-23 21:22:43,919 ----------------------------------------------------------------------------------------------------
2021-07-23 21:22:46,164 epoch 39 - iter 10/101 - loss 0.10139296 - samples/sec: 142.69 - lr: 0.000004
2021-07-23 21:22:48,503 epoch 39 - iter 20/101 - loss 0.09388458 - samples/sec: 136.81 - lr: 0.000004
2021-07-23 21:22:50,734 epoch 39 - iter 30/101 - loss 0.08010608 - samples/sec: 143.47 - lr: 0.000004
2021-07-23 21:22:53,036 epoch 39 - iter 40/101 - loss 0.08787814 - samples/sec: 139.08 - lr: 0.000004
2021-07-23 21:22:55,332 epoch 39 - iter 50/101 - loss 0.09280029 - samples/sec: 139.40 - lr: 0.000004
2021-07-23 21:22:57,624 epoch 39 - iter 60/101 - loss 0.09141251 - samples/sec: 139.65 - lr: 0.000004
2021-07-23 21:22:59,959 epoch 39 - iter 70/101 - loss 0.09538810 - samples/sec: 137.12 - lr: 0.000004
2021-07-23 21:23:02,282 epoch 39 - iter 80/101 - loss 0.09531131 - samples/sec: 137.75 - lr: 0.000004
2021-07-23 21:23:04,724 epoch 39 - iter 90/101 - loss 0.09649958 - samples/sec: 131.11 - lr: 0.000004
2021-07-23 21:23:07,040 epoch 39 - iter 100/101 - loss 0.09351147 - samples/sec: 138.17 - lr: 0.000004
2021-07-23 21:23:07,217 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:07,217 EPOCH 39 done: loss 0.0933 - lr 0.0000038
2021-07-23 21:23:08,373 DEV : loss 0.044824909418821335 - score 0.9878
2021-07-23 21:23:08,386 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:23:10,938 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:13,335 epoch 40 - iter 10/101 - loss 0.08827258 - samples/sec: 133.60 - lr: 0.000004
2021-07-23 21:23:15,559 epoch 40 - iter 20/101 - loss 0.07717966 - samples/sec: 143.94 - lr: 0.000004
2021-07-23 21:23:17,831 epoch 40 - iter 30/101 - loss 0.07942974 - samples/sec: 140.89 - lr: 0.000004
2021-07-23 21:23:20,072 epoch 40 - iter 40/101 - loss 0.07901220 - samples/sec: 142.86 - lr: 0.000004
2021-07-23 21:23:22,384 epoch 40 - iter 50/101 - loss 0.08386618 - samples/sec: 138.45 - lr: 0.000004
2021-07-23 21:23:24,748 epoch 40 - iter 60/101 - loss 0.08450721 - samples/sec: 135.40 - lr: 0.000004
2021-07-23 21:23:26,902 epoch 40 - iter 70/101 - loss 0.08551436 - samples/sec: 148.55 - lr: 0.000004
2021-07-23 21:23:29,324 epoch 40 - iter 80/101 - loss 0.08158622 - samples/sec: 132.17 - lr: 0.000004
2021-07-23 21:23:31,751 epoch 40 - iter 90/101 - loss 0.08705245 - samples/sec: 131.91 - lr: 0.000004
2021-07-23 21:23:34,055 epoch 40 - iter 100/101 - loss 0.08750681 - samples/sec: 138.92 - lr: 0.000004
2021-07-23 21:23:34,236 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:34,236 EPOCH 40 done: loss 0.0867 - lr 0.0000038
2021-07-23 21:23:35,391 DEV : loss 0.04582187533378601 - score 0.9878
2021-07-23 21:23:35,404 BAD EPOCHS (no improvement): 1
2021-07-23 21:23:35,968 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:35,969 Testing using best model ...
2021-07-23 21:23:35,970 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/deu.rst.pcc/best-model.pt
2021-07-23 21:23:51,149 0.9881	0.9816	0.9848
2021-07-23 21:23:51,149 
Results:
- F1-score (micro) 0.9848
- F1-score (macro) 0.9864

By class:
SENT       tp: 411 - fp: 9 - fn: 14 - precision: 0.9786 - recall: 0.9671 - f1-score: 0.9728
X          tp: 334 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 21:23:51,149 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/spa.rst.sctb/
2021-07-23 21:23:51,225 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/spa.rst.sctb
2021-07-23 21:23:51,225 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/spa.rst.sctb/sent_train.txt
2021-07-23 21:23:51,227 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/spa.rst.sctb/sent_dev.txt
2021-07-23 21:23:51,228 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/spa.rst.sctb/sent_test.txt
Corpus: 993 train + 302 dev + 290 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 21:23:53,790 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:53,791 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 21:23:53,791 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:53,791 Corpus: "Corpus: 993 train + 302 dev + 290 test sentences"
2021-07-23 21:23:53,791 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:53,791 Parameters:
2021-07-23 21:23:53,791  - learning_rate: "3e-05"
2021-07-23 21:23:53,791  - mini_batch_size: "32"
2021-07-23 21:23:53,792  - patience: "3"
2021-07-23 21:23:53,792  - anneal_factor: "0.5"
2021-07-23 21:23:53,792  - max_epochs: "40"
2021-07-23 21:23:53,792  - shuffle: "True"
2021-07-23 21:23:53,792  - train_with_dev: "False"
2021-07-23 21:23:53,792  - batch_growth_annealing: "False"
2021-07-23 21:23:53,792 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:53,792 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/spa.rst.sctb"
2021-07-23 21:23:53,792 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:53,792 Device: cuda:0
2021-07-23 21:23:53,792 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:53,792 Embeddings storage mode: cpu
2021-07-23 21:23:53,794 ----------------------------------------------------------------------------------------------------
2021-07-23 21:23:55,589 epoch 1 - iter 3/32 - loss 7.94543680 - samples/sec: 53.54 - lr: 0.000030
2021-07-23 21:23:57,361 epoch 1 - iter 6/32 - loss 7.56245542 - samples/sec: 54.18 - lr: 0.000030
2021-07-23 21:23:59,194 epoch 1 - iter 9/32 - loss 7.50702439 - samples/sec: 52.39 - lr: 0.000030
2021-07-23 21:24:01,003 epoch 1 - iter 12/32 - loss 7.29266127 - samples/sec: 53.07 - lr: 0.000030
2021-07-23 21:24:02,858 epoch 1 - iter 15/32 - loss 7.08674679 - samples/sec: 51.77 - lr: 0.000030
2021-07-23 21:24:04,710 epoch 1 - iter 18/32 - loss 6.80031400 - samples/sec: 51.82 - lr: 0.000030
2021-07-23 21:24:06,530 epoch 1 - iter 21/32 - loss 6.61203611 - samples/sec: 52.76 - lr: 0.000030
2021-07-23 21:24:08,293 epoch 1 - iter 24/32 - loss 6.43203278 - samples/sec: 54.48 - lr: 0.000030
2021-07-23 21:24:10,132 epoch 1 - iter 27/32 - loss 6.24882057 - samples/sec: 52.21 - lr: 0.000030
2021-07-23 21:24:11,942 epoch 1 - iter 30/32 - loss 6.09304957 - samples/sec: 53.03 - lr: 0.000030
2021-07-23 21:24:12,591 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:12,591 EPOCH 1 done: loss 5.8733 - lr 0.0000300
2021-07-23 21:24:16,676 DEV : loss 3.202009677886963 - score 0.0
2021-07-23 21:24:16,685 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:24:17,243 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:17,997 epoch 2 - iter 3/32 - loss 3.68795284 - samples/sec: 127.50 - lr: 0.000030
2021-07-23 21:24:18,744 epoch 2 - iter 6/32 - loss 3.62340864 - samples/sec: 128.64 - lr: 0.000030
2021-07-23 21:24:19,479 epoch 2 - iter 9/32 - loss 3.60839452 - samples/sec: 130.70 - lr: 0.000030
2021-07-23 21:24:20,221 epoch 2 - iter 12/32 - loss 3.60364171 - samples/sec: 129.52 - lr: 0.000030
2021-07-23 21:24:20,982 epoch 2 - iter 15/32 - loss 3.60288517 - samples/sec: 126.10 - lr: 0.000030
2021-07-23 21:24:21,738 epoch 2 - iter 18/32 - loss 3.54658873 - samples/sec: 127.17 - lr: 0.000030
2021-07-23 21:24:22,546 epoch 2 - iter 21/32 - loss 3.47564471 - samples/sec: 118.78 - lr: 0.000030
2021-07-23 21:24:23,306 epoch 2 - iter 24/32 - loss 3.42409883 - samples/sec: 126.46 - lr: 0.000030
2021-07-23 21:24:24,081 epoch 2 - iter 27/32 - loss 3.36647594 - samples/sec: 123.98 - lr: 0.000030
2021-07-23 21:24:24,880 epoch 2 - iter 30/32 - loss 3.24709118 - samples/sec: 120.22 - lr: 0.000030
2021-07-23 21:24:25,191 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:25,191 EPOCH 2 done: loss 3.3221 - lr 0.0000300
2021-07-23 21:24:25,984 DEV : loss 2.0404632091522217 - score 0.0
2021-07-23 21:24:25,993 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:24:29,207 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:30,012 epoch 3 - iter 3/32 - loss 2.56337635 - samples/sec: 119.55 - lr: 0.000030
2021-07-23 21:24:30,808 epoch 3 - iter 6/32 - loss 2.50959420 - samples/sec: 120.62 - lr: 0.000030
2021-07-23 21:24:31,563 epoch 3 - iter 9/32 - loss 2.40774413 - samples/sec: 127.31 - lr: 0.000030
2021-07-23 21:24:32,307 epoch 3 - iter 12/32 - loss 2.31910244 - samples/sec: 128.97 - lr: 0.000030
2021-07-23 21:24:33,111 epoch 3 - iter 15/32 - loss 2.33758117 - samples/sec: 119.54 - lr: 0.000030
2021-07-23 21:24:33,786 epoch 3 - iter 18/32 - loss 2.33910041 - samples/sec: 142.37 - lr: 0.000030
2021-07-23 21:24:34,554 epoch 3 - iter 21/32 - loss 2.30698167 - samples/sec: 125.09 - lr: 0.000030
2021-07-23 21:24:35,324 epoch 3 - iter 24/32 - loss 2.24128904 - samples/sec: 124.69 - lr: 0.000030
2021-07-23 21:24:36,181 epoch 3 - iter 27/32 - loss 2.19521962 - samples/sec: 112.03 - lr: 0.000030
2021-07-23 21:24:36,944 epoch 3 - iter 30/32 - loss 2.14958548 - samples/sec: 125.99 - lr: 0.000030
2021-07-23 21:24:37,238 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:37,238 EPOCH 3 done: loss 2.0717 - lr 0.0000300
2021-07-23 21:24:38,029 DEV : loss 1.5977028608322144 - score 0.7595
2021-07-23 21:24:38,039 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:24:40,361 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:41,113 epoch 4 - iter 3/32 - loss 1.39114261 - samples/sec: 127.99 - lr: 0.000030
2021-07-23 21:24:41,846 epoch 4 - iter 6/32 - loss 1.45615270 - samples/sec: 131.12 - lr: 0.000030
2021-07-23 21:24:42,570 epoch 4 - iter 9/32 - loss 1.49728300 - samples/sec: 132.72 - lr: 0.000030
2021-07-23 21:24:43,351 epoch 4 - iter 12/32 - loss 1.60111020 - samples/sec: 122.85 - lr: 0.000030
2021-07-23 21:24:44,172 epoch 4 - iter 15/32 - loss 1.50266003 - samples/sec: 117.10 - lr: 0.000030
2021-07-23 21:24:44,924 epoch 4 - iter 18/32 - loss 1.55011098 - samples/sec: 127.66 - lr: 0.000030
2021-07-23 21:24:45,740 epoch 4 - iter 21/32 - loss 1.59070436 - samples/sec: 117.72 - lr: 0.000030
2021-07-23 21:24:46,496 epoch 4 - iter 24/32 - loss 1.59331208 - samples/sec: 127.09 - lr: 0.000030
2021-07-23 21:24:47,232 epoch 4 - iter 27/32 - loss 1.62263944 - samples/sec: 130.35 - lr: 0.000030
2021-07-23 21:24:47,997 epoch 4 - iter 30/32 - loss 1.58625559 - samples/sec: 125.60 - lr: 0.000030
2021-07-23 21:24:48,299 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:48,299 EPOCH 4 done: loss 1.5416 - lr 0.0000300
2021-07-23 21:24:49,091 DEV : loss 1.26679265499115 - score 0.7547
2021-07-23 21:24:49,100 BAD EPOCHS (no improvement): 1
2021-07-23 21:24:49,100 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:49,863 epoch 5 - iter 3/32 - loss 1.61526489 - samples/sec: 126.08 - lr: 0.000030
2021-07-23 21:24:50,723 epoch 5 - iter 6/32 - loss 1.49155307 - samples/sec: 111.61 - lr: 0.000030
2021-07-23 21:24:51,480 epoch 5 - iter 9/32 - loss 1.42776723 - samples/sec: 126.90 - lr: 0.000030
2021-07-23 21:24:52,257 epoch 5 - iter 12/32 - loss 1.42049013 - samples/sec: 123.73 - lr: 0.000030
2021-07-23 21:24:53,075 epoch 5 - iter 15/32 - loss 1.42594937 - samples/sec: 117.34 - lr: 0.000030
2021-07-23 21:24:53,788 epoch 5 - iter 18/32 - loss 1.35778467 - samples/sec: 134.71 - lr: 0.000030
2021-07-23 21:24:54,532 epoch 5 - iter 21/32 - loss 1.33285578 - samples/sec: 129.21 - lr: 0.000030
2021-07-23 21:24:55,281 epoch 5 - iter 24/32 - loss 1.30141653 - samples/sec: 128.21 - lr: 0.000030
2021-07-23 21:24:56,039 epoch 5 - iter 27/32 - loss 1.27287530 - samples/sec: 126.71 - lr: 0.000030
2021-07-23 21:24:56,772 epoch 5 - iter 30/32 - loss 1.26266140 - samples/sec: 131.08 - lr: 0.000030
2021-07-23 21:24:57,062 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:57,062 EPOCH 5 done: loss 1.3459 - lr 0.0000300
2021-07-23 21:24:57,855 DEV : loss 0.9784523248672485 - score 0.7524
2021-07-23 21:24:57,865 BAD EPOCHS (no improvement): 2
2021-07-23 21:24:57,865 ----------------------------------------------------------------------------------------------------
2021-07-23 21:24:58,556 epoch 6 - iter 3/32 - loss 0.99041679 - samples/sec: 139.06 - lr: 0.000030
2021-07-23 21:24:59,331 epoch 6 - iter 6/32 - loss 1.15585781 - samples/sec: 123.98 - lr: 0.000030
2021-07-23 21:25:00,100 epoch 6 - iter 9/32 - loss 1.21763683 - samples/sec: 124.87 - lr: 0.000030
2021-07-23 21:25:00,855 epoch 6 - iter 12/32 - loss 1.16181471 - samples/sec: 127.31 - lr: 0.000030
2021-07-23 21:25:01,613 epoch 6 - iter 15/32 - loss 1.14473344 - samples/sec: 126.71 - lr: 0.000030
2021-07-23 21:25:02,471 epoch 6 - iter 18/32 - loss 1.13103411 - samples/sec: 111.88 - lr: 0.000030
2021-07-23 21:25:03,222 epoch 6 - iter 21/32 - loss 1.10822095 - samples/sec: 128.04 - lr: 0.000030
2021-07-23 21:25:04,069 epoch 6 - iter 24/32 - loss 1.07779572 - samples/sec: 113.38 - lr: 0.000030
2021-07-23 21:25:04,761 epoch 6 - iter 27/32 - loss 1.04615814 - samples/sec: 138.80 - lr: 0.000030
2021-07-23 21:25:05,527 epoch 6 - iter 30/32 - loss 1.02559336 - samples/sec: 125.34 - lr: 0.000030
2021-07-23 21:25:05,803 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:05,803 EPOCH 6 done: loss 0.9915 - lr 0.0000300
2021-07-23 21:25:06,596 DEV : loss 0.7453805804252625 - score 0.7625
2021-07-23 21:25:06,605 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:25:08,920 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:09,625 epoch 7 - iter 3/32 - loss 0.63097554 - samples/sec: 136.75 - lr: 0.000030
2021-07-23 21:25:10,408 epoch 7 - iter 6/32 - loss 0.84255160 - samples/sec: 122.55 - lr: 0.000030
2021-07-23 21:25:11,159 epoch 7 - iter 9/32 - loss 0.84257152 - samples/sec: 128.00 - lr: 0.000030
2021-07-23 21:25:11,953 epoch 7 - iter 12/32 - loss 0.83859977 - samples/sec: 120.90 - lr: 0.000030
2021-07-23 21:25:12,708 epoch 7 - iter 15/32 - loss 0.85089535 - samples/sec: 127.30 - lr: 0.000030
2021-07-23 21:25:13,432 epoch 7 - iter 18/32 - loss 0.81216122 - samples/sec: 132.57 - lr: 0.000030
2021-07-23 21:25:14,123 epoch 7 - iter 21/32 - loss 0.82339678 - samples/sec: 139.02 - lr: 0.000030
2021-07-23 21:25:14,912 epoch 7 - iter 24/32 - loss 0.83882172 - samples/sec: 121.81 - lr: 0.000030
2021-07-23 21:25:15,732 epoch 7 - iter 27/32 - loss 0.82602597 - samples/sec: 117.10 - lr: 0.000030
2021-07-23 21:25:16,540 epoch 7 - iter 30/32 - loss 0.79774541 - samples/sec: 118.78 - lr: 0.000030
2021-07-23 21:25:16,843 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:16,843 EPOCH 7 done: loss 0.7736 - lr 0.0000300
2021-07-23 21:25:17,634 DEV : loss 0.5575553178787231 - score 0.7664
2021-07-23 21:25:17,643 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:25:20,096 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:20,783 epoch 8 - iter 3/32 - loss 0.74358284 - samples/sec: 140.09 - lr: 0.000030
2021-07-23 21:25:21,500 epoch 8 - iter 6/32 - loss 0.76187263 - samples/sec: 133.98 - lr: 0.000030
2021-07-23 21:25:22,297 epoch 8 - iter 9/32 - loss 0.70038189 - samples/sec: 120.51 - lr: 0.000030
2021-07-23 21:25:23,016 epoch 8 - iter 12/32 - loss 0.72434114 - samples/sec: 133.53 - lr: 0.000030
2021-07-23 21:25:23,812 epoch 8 - iter 15/32 - loss 0.69313189 - samples/sec: 120.66 - lr: 0.000030
2021-07-23 21:25:24,540 epoch 8 - iter 18/32 - loss 0.68210290 - samples/sec: 131.98 - lr: 0.000030
2021-07-23 21:25:25,320 epoch 8 - iter 21/32 - loss 0.65640807 - samples/sec: 123.23 - lr: 0.000030
2021-07-23 21:25:26,045 epoch 8 - iter 24/32 - loss 0.66606212 - samples/sec: 132.42 - lr: 0.000030
2021-07-23 21:25:26,880 epoch 8 - iter 27/32 - loss 0.64993654 - samples/sec: 115.05 - lr: 0.000030
2021-07-23 21:25:27,685 epoch 8 - iter 30/32 - loss 0.63860444 - samples/sec: 119.24 - lr: 0.000030
2021-07-23 21:25:28,041 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:28,041 EPOCH 8 done: loss 0.6255 - lr 0.0000300
2021-07-23 21:25:28,832 DEV : loss 0.42383718490600586 - score 0.8239
2021-07-23 21:25:28,842 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:25:31,416 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:32,171 epoch 9 - iter 3/32 - loss 0.65350900 - samples/sec: 127.53 - lr: 0.000030
2021-07-23 21:25:32,852 epoch 9 - iter 6/32 - loss 0.57720947 - samples/sec: 140.92 - lr: 0.000030
2021-07-23 21:25:33,571 epoch 9 - iter 9/32 - loss 0.56000230 - samples/sec: 133.67 - lr: 0.000030
2021-07-23 21:25:34,377 epoch 9 - iter 12/32 - loss 0.56999344 - samples/sec: 119.21 - lr: 0.000030
2021-07-23 21:25:35,244 epoch 9 - iter 15/32 - loss 0.56947854 - samples/sec: 110.71 - lr: 0.000030
2021-07-23 21:25:36,029 epoch 9 - iter 18/32 - loss 0.55651302 - samples/sec: 122.39 - lr: 0.000030
2021-07-23 21:25:36,765 epoch 9 - iter 21/32 - loss 0.54783088 - samples/sec: 130.46 - lr: 0.000030
2021-07-23 21:25:37,596 epoch 9 - iter 24/32 - loss 0.55573948 - samples/sec: 115.64 - lr: 0.000030
2021-07-23 21:25:38,332 epoch 9 - iter 27/32 - loss 0.54018403 - samples/sec: 130.38 - lr: 0.000030
2021-07-23 21:25:39,088 epoch 9 - iter 30/32 - loss 0.52139436 - samples/sec: 127.14 - lr: 0.000030
2021-07-23 21:25:39,345 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:39,346 EPOCH 9 done: loss 0.5000 - lr 0.0000300
2021-07-23 21:25:40,226 DEV : loss 0.32073575258255005 - score 0.9151
2021-07-23 21:25:40,238 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:25:42,717 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:43,472 epoch 10 - iter 3/32 - loss 0.45304804 - samples/sec: 127.57 - lr: 0.000030
2021-07-23 21:25:44,273 epoch 10 - iter 6/32 - loss 0.50307436 - samples/sec: 119.89 - lr: 0.000030
2021-07-23 21:25:45,028 epoch 10 - iter 9/32 - loss 0.45557322 - samples/sec: 127.28 - lr: 0.000030
2021-07-23 21:25:45,795 epoch 10 - iter 12/32 - loss 0.44704345 - samples/sec: 125.10 - lr: 0.000030
2021-07-23 21:25:46,637 epoch 10 - iter 15/32 - loss 0.43283687 - samples/sec: 114.12 - lr: 0.000030
2021-07-23 21:25:47,356 epoch 10 - iter 18/32 - loss 0.42223768 - samples/sec: 133.52 - lr: 0.000030
2021-07-23 21:25:48,108 epoch 10 - iter 21/32 - loss 0.41602751 - samples/sec: 127.78 - lr: 0.000030
2021-07-23 21:25:48,930 epoch 10 - iter 24/32 - loss 0.42456875 - samples/sec: 116.82 - lr: 0.000030
2021-07-23 21:25:49,652 epoch 10 - iter 27/32 - loss 0.41253429 - samples/sec: 133.03 - lr: 0.000030
2021-07-23 21:25:50,411 epoch 10 - iter 30/32 - loss 0.41511291 - samples/sec: 126.55 - lr: 0.000030
2021-07-23 21:25:50,696 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:50,696 EPOCH 10 done: loss 0.4044 - lr 0.0000300
2021-07-23 21:25:51,487 DEV : loss 0.2518445551395416 - score 0.9465
2021-07-23 21:25:51,500 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:25:53,992 ----------------------------------------------------------------------------------------------------
2021-07-23 21:25:54,795 epoch 11 - iter 3/32 - loss 0.37388803 - samples/sec: 119.83 - lr: 0.000030
2021-07-23 21:25:55,552 epoch 11 - iter 6/32 - loss 0.33789805 - samples/sec: 126.90 - lr: 0.000030
2021-07-23 21:25:56,225 epoch 11 - iter 9/32 - loss 0.33266557 - samples/sec: 142.82 - lr: 0.000030
2021-07-23 21:25:56,976 epoch 11 - iter 12/32 - loss 0.34747234 - samples/sec: 127.91 - lr: 0.000030
2021-07-23 21:25:57,693 epoch 11 - iter 15/32 - loss 0.37881920 - samples/sec: 133.98 - lr: 0.000030
2021-07-23 21:25:58,460 epoch 11 - iter 18/32 - loss 0.36684213 - samples/sec: 125.19 - lr: 0.000030
2021-07-23 21:25:59,224 epoch 11 - iter 21/32 - loss 0.36709274 - samples/sec: 125.79 - lr: 0.000030
2021-07-23 21:26:00,024 epoch 11 - iter 24/32 - loss 0.35905594 - samples/sec: 119.93 - lr: 0.000030
2021-07-23 21:26:00,785 epoch 11 - iter 27/32 - loss 0.35526061 - samples/sec: 126.27 - lr: 0.000030
2021-07-23 21:26:01,626 epoch 11 - iter 30/32 - loss 0.34952131 - samples/sec: 114.21 - lr: 0.000030
2021-07-23 21:26:01,943 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:01,943 EPOCH 11 done: loss 0.3361 - lr 0.0000300
2021-07-23 21:26:02,738 DEV : loss 0.20357084274291992 - score 0.9521
2021-07-23 21:26:02,751 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:26:05,168 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:05,987 epoch 12 - iter 3/32 - loss 0.37623255 - samples/sec: 117.48 - lr: 0.000030
2021-07-23 21:26:06,776 epoch 12 - iter 6/32 - loss 0.35243365 - samples/sec: 121.73 - lr: 0.000030
2021-07-23 21:26:07,539 epoch 12 - iter 9/32 - loss 0.37970283 - samples/sec: 125.96 - lr: 0.000030
2021-07-23 21:26:08,291 epoch 12 - iter 12/32 - loss 0.34702698 - samples/sec: 127.78 - lr: 0.000030
2021-07-23 21:26:09,048 epoch 12 - iter 15/32 - loss 0.34045147 - samples/sec: 126.80 - lr: 0.000030
2021-07-23 21:26:09,808 epoch 12 - iter 18/32 - loss 0.33528911 - samples/sec: 126.46 - lr: 0.000030
2021-07-23 21:26:10,508 epoch 12 - iter 21/32 - loss 0.33736878 - samples/sec: 137.22 - lr: 0.000030
2021-07-23 21:26:11,231 epoch 12 - iter 24/32 - loss 0.32284196 - samples/sec: 132.83 - lr: 0.000030
2021-07-23 21:26:11,997 epoch 12 - iter 27/32 - loss 0.31360639 - samples/sec: 125.34 - lr: 0.000030
2021-07-23 21:26:12,800 epoch 12 - iter 30/32 - loss 0.30801438 - samples/sec: 119.61 - lr: 0.000030
2021-07-23 21:26:13,090 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:13,090 EPOCH 12 done: loss 0.3085 - lr 0.0000300
2021-07-23 21:26:13,884 DEV : loss 0.16399097442626953 - score 0.9635
2021-07-23 21:26:13,893 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:26:16,543 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:17,301 epoch 13 - iter 3/32 - loss 0.24249705 - samples/sec: 127.08 - lr: 0.000030
2021-07-23 21:26:18,086 epoch 13 - iter 6/32 - loss 0.29732376 - samples/sec: 122.34 - lr: 0.000030
2021-07-23 21:26:18,868 epoch 13 - iter 9/32 - loss 0.28026363 - samples/sec: 122.76 - lr: 0.000030
2021-07-23 21:26:19,532 epoch 13 - iter 12/32 - loss 0.25677124 - samples/sec: 144.75 - lr: 0.000030
2021-07-23 21:26:20,270 epoch 13 - iter 15/32 - loss 0.24221213 - samples/sec: 130.06 - lr: 0.000030
2021-07-23 21:26:21,020 epoch 13 - iter 18/32 - loss 0.24529759 - samples/sec: 128.11 - lr: 0.000030
2021-07-23 21:26:21,836 epoch 13 - iter 21/32 - loss 0.24337143 - samples/sec: 117.75 - lr: 0.000030
2021-07-23 21:26:22,607 epoch 13 - iter 24/32 - loss 0.25554562 - samples/sec: 124.49 - lr: 0.000030
2021-07-23 21:26:23,441 epoch 13 - iter 27/32 - loss 0.26380430 - samples/sec: 115.20 - lr: 0.000030
2021-07-23 21:26:24,195 epoch 13 - iter 30/32 - loss 0.26600305 - samples/sec: 127.48 - lr: 0.000030
2021-07-23 21:26:24,476 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:24,476 EPOCH 13 done: loss 0.2557 - lr 0.0000300
2021-07-23 21:26:25,268 DEV : loss 0.1368059366941452 - score 0.9689
2021-07-23 21:26:25,282 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:26:27,810 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:28,600 epoch 14 - iter 3/32 - loss 0.20342434 - samples/sec: 121.91 - lr: 0.000030
2021-07-23 21:26:29,327 epoch 14 - iter 6/32 - loss 0.23416370 - samples/sec: 132.11 - lr: 0.000030
2021-07-23 21:26:30,053 epoch 14 - iter 9/32 - loss 0.23505218 - samples/sec: 132.30 - lr: 0.000030
2021-07-23 21:26:30,873 epoch 14 - iter 12/32 - loss 0.22007186 - samples/sec: 117.14 - lr: 0.000030
2021-07-23 21:26:31,652 epoch 14 - iter 15/32 - loss 0.22506151 - samples/sec: 123.23 - lr: 0.000030
2021-07-23 21:26:32,371 epoch 14 - iter 18/32 - loss 0.23063016 - samples/sec: 133.56 - lr: 0.000030
2021-07-23 21:26:33,179 epoch 14 - iter 21/32 - loss 0.21894965 - samples/sec: 118.84 - lr: 0.000030
2021-07-23 21:26:33,961 epoch 14 - iter 24/32 - loss 0.20985728 - samples/sec: 122.91 - lr: 0.000030
2021-07-23 21:26:34,723 epoch 14 - iter 27/32 - loss 0.20357704 - samples/sec: 125.94 - lr: 0.000030
2021-07-23 21:26:35,496 epoch 14 - iter 30/32 - loss 0.20688884 - samples/sec: 124.36 - lr: 0.000030
2021-07-23 21:26:35,831 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:35,831 EPOCH 14 done: loss 0.2018 - lr 0.0000300
2021-07-23 21:26:36,623 DEV : loss 0.12050195038318634 - score 0.9635
2021-07-23 21:26:36,633 BAD EPOCHS (no improvement): 1
2021-07-23 21:26:36,633 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:37,399 epoch 15 - iter 3/32 - loss 0.18960380 - samples/sec: 125.51 - lr: 0.000030
2021-07-23 21:26:38,202 epoch 15 - iter 6/32 - loss 0.23171610 - samples/sec: 119.62 - lr: 0.000030
2021-07-23 21:26:38,980 epoch 15 - iter 9/32 - loss 0.21824600 - samples/sec: 123.46 - lr: 0.000030
2021-07-23 21:26:39,711 epoch 15 - iter 12/32 - loss 0.19938089 - samples/sec: 131.37 - lr: 0.000030
2021-07-23 21:26:40,452 epoch 15 - iter 15/32 - loss 0.20479725 - samples/sec: 129.61 - lr: 0.000030
2021-07-23 21:26:41,203 epoch 15 - iter 18/32 - loss 0.21718072 - samples/sec: 127.87 - lr: 0.000030
2021-07-23 21:26:42,005 epoch 15 - iter 21/32 - loss 0.22178407 - samples/sec: 119.83 - lr: 0.000030
2021-07-23 21:26:42,785 epoch 15 - iter 24/32 - loss 0.21593118 - samples/sec: 123.12 - lr: 0.000030
2021-07-23 21:26:43,585 epoch 15 - iter 27/32 - loss 0.21321630 - samples/sec: 120.03 - lr: 0.000030
2021-07-23 21:26:44,356 epoch 15 - iter 30/32 - loss 0.21411956 - samples/sec: 124.65 - lr: 0.000030
2021-07-23 21:26:44,621 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:44,621 EPOCH 15 done: loss 0.2230 - lr 0.0000300
2021-07-23 21:26:45,414 DEV : loss 0.10322966426610947 - score 0.9742
2021-07-23 21:26:45,424 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:26:47,907 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:48,672 epoch 16 - iter 3/32 - loss 0.26870416 - samples/sec: 125.81 - lr: 0.000030
2021-07-23 21:26:49,428 epoch 16 - iter 6/32 - loss 0.22308643 - samples/sec: 127.00 - lr: 0.000030
2021-07-23 21:26:50,228 epoch 16 - iter 9/32 - loss 0.23163312 - samples/sec: 120.06 - lr: 0.000030
2021-07-23 21:26:50,945 epoch 16 - iter 12/32 - loss 0.19591807 - samples/sec: 134.05 - lr: 0.000030
2021-07-23 21:26:51,695 epoch 16 - iter 15/32 - loss 0.20790307 - samples/sec: 128.09 - lr: 0.000030
2021-07-23 21:26:52,497 epoch 16 - iter 18/32 - loss 0.21798796 - samples/sec: 119.78 - lr: 0.000030
2021-07-23 21:26:53,248 epoch 16 - iter 21/32 - loss 0.20390489 - samples/sec: 127.78 - lr: 0.000030
2021-07-23 21:26:54,101 epoch 16 - iter 24/32 - loss 0.20078886 - samples/sec: 112.61 - lr: 0.000030
2021-07-23 21:26:54,847 epoch 16 - iter 27/32 - loss 0.21570937 - samples/sec: 128.76 - lr: 0.000030
2021-07-23 21:26:55,657 epoch 16 - iter 30/32 - loss 0.21403144 - samples/sec: 118.64 - lr: 0.000030
2021-07-23 21:26:55,976 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:55,976 EPOCH 16 done: loss 0.2141 - lr 0.0000300
2021-07-23 21:26:56,766 DEV : loss 0.09504079073667526 - score 0.9716
2021-07-23 21:26:56,775 BAD EPOCHS (no improvement): 1
2021-07-23 21:26:56,776 ----------------------------------------------------------------------------------------------------
2021-07-23 21:26:57,516 epoch 17 - iter 3/32 - loss 0.12655763 - samples/sec: 129.84 - lr: 0.000030
2021-07-23 21:26:58,244 epoch 17 - iter 6/32 - loss 0.15195392 - samples/sec: 132.03 - lr: 0.000030
2021-07-23 21:26:59,019 epoch 17 - iter 9/32 - loss 0.13686863 - samples/sec: 123.91 - lr: 0.000030
2021-07-23 21:26:59,741 epoch 17 - iter 12/32 - loss 0.14552826 - samples/sec: 132.97 - lr: 0.000030
2021-07-23 21:27:00,552 epoch 17 - iter 15/32 - loss 0.15383441 - samples/sec: 118.40 - lr: 0.000030
2021-07-23 21:27:01,357 epoch 17 - iter 18/32 - loss 0.17177172 - samples/sec: 119.37 - lr: 0.000030
2021-07-23 21:27:02,131 epoch 17 - iter 21/32 - loss 0.16763859 - samples/sec: 124.05 - lr: 0.000030
2021-07-23 21:27:02,925 epoch 17 - iter 24/32 - loss 0.16655336 - samples/sec: 121.06 - lr: 0.000030
2021-07-23 21:27:03,696 epoch 17 - iter 27/32 - loss 0.16675550 - samples/sec: 124.53 - lr: 0.000030
2021-07-23 21:27:04,424 epoch 17 - iter 30/32 - loss 0.16243829 - samples/sec: 131.92 - lr: 0.000030
2021-07-23 21:27:04,732 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:04,732 EPOCH 17 done: loss 0.1573 - lr 0.0000300
2021-07-23 21:27:05,522 DEV : loss 0.08545147627592087 - score 0.9795
2021-07-23 21:27:05,532 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:27:08,093 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:08,822 epoch 18 - iter 3/32 - loss 0.12060256 - samples/sec: 132.08 - lr: 0.000030
2021-07-23 21:27:09,575 epoch 18 - iter 6/32 - loss 0.12421957 - samples/sec: 127.43 - lr: 0.000030
2021-07-23 21:27:10,331 epoch 18 - iter 9/32 - loss 0.15241788 - samples/sec: 127.12 - lr: 0.000030
2021-07-23 21:27:11,129 epoch 18 - iter 12/32 - loss 0.16017032 - samples/sec: 120.41 - lr: 0.000030
2021-07-23 21:27:11,957 epoch 18 - iter 15/32 - loss 0.15529604 - samples/sec: 115.96 - lr: 0.000030
2021-07-23 21:27:12,683 epoch 18 - iter 18/32 - loss 0.14680590 - samples/sec: 132.26 - lr: 0.000030
2021-07-23 21:27:13,468 epoch 18 - iter 21/32 - loss 0.14692381 - samples/sec: 122.43 - lr: 0.000030
2021-07-23 21:27:14,265 epoch 18 - iter 24/32 - loss 0.14734427 - samples/sec: 120.49 - lr: 0.000030
2021-07-23 21:27:14,992 epoch 18 - iter 27/32 - loss 0.14358479 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 21:27:15,776 epoch 18 - iter 30/32 - loss 0.15167649 - samples/sec: 122.57 - lr: 0.000030
2021-07-23 21:27:16,084 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:16,084 EPOCH 18 done: loss 0.1513 - lr 0.0000300
2021-07-23 21:27:16,878 DEV : loss 0.07909461110830307 - score 0.9821
2021-07-23 21:27:16,887 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:27:19,241 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:20,021 epoch 19 - iter 3/32 - loss 0.20161668 - samples/sec: 123.41 - lr: 0.000030
2021-07-23 21:27:20,800 epoch 19 - iter 6/32 - loss 0.17402323 - samples/sec: 123.32 - lr: 0.000030
2021-07-23 21:27:21,551 epoch 19 - iter 9/32 - loss 0.16668234 - samples/sec: 127.87 - lr: 0.000030
2021-07-23 21:27:22,408 epoch 19 - iter 12/32 - loss 0.15100242 - samples/sec: 112.19 - lr: 0.000030
2021-07-23 21:27:23,156 epoch 19 - iter 15/32 - loss 0.14848879 - samples/sec: 128.35 - lr: 0.000030
2021-07-23 21:27:23,904 epoch 19 - iter 18/32 - loss 0.15890360 - samples/sec: 128.44 - lr: 0.000030
2021-07-23 21:27:24,640 epoch 19 - iter 21/32 - loss 0.15389092 - samples/sec: 130.48 - lr: 0.000030
2021-07-23 21:27:25,421 epoch 19 - iter 24/32 - loss 0.15442426 - samples/sec: 122.93 - lr: 0.000030
2021-07-23 21:27:26,161 epoch 19 - iter 27/32 - loss 0.15192078 - samples/sec: 129.88 - lr: 0.000030
2021-07-23 21:27:26,942 epoch 19 - iter 30/32 - loss 0.15167321 - samples/sec: 122.98 - lr: 0.000030
2021-07-23 21:27:27,266 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:27,266 EPOCH 19 done: loss 0.1490 - lr 0.0000300
2021-07-23 21:27:28,058 DEV : loss 0.07497598230838776 - score 0.9847
2021-07-23 21:27:28,067 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:27:30,510 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:31,232 epoch 20 - iter 3/32 - loss 0.10253738 - samples/sec: 133.41 - lr: 0.000030
2021-07-23 21:27:32,037 epoch 20 - iter 6/32 - loss 0.12117255 - samples/sec: 119.39 - lr: 0.000030
2021-07-23 21:27:32,817 epoch 20 - iter 9/32 - loss 0.11407147 - samples/sec: 123.07 - lr: 0.000030
2021-07-23 21:27:33,614 epoch 20 - iter 12/32 - loss 0.11725084 - samples/sec: 120.57 - lr: 0.000030
2021-07-23 21:27:34,324 epoch 20 - iter 15/32 - loss 0.14359066 - samples/sec: 135.21 - lr: 0.000030
2021-07-23 21:27:35,133 epoch 20 - iter 18/32 - loss 0.14782499 - samples/sec: 118.75 - lr: 0.000030
2021-07-23 21:27:35,833 epoch 20 - iter 21/32 - loss 0.13663678 - samples/sec: 137.28 - lr: 0.000030
2021-07-23 21:27:36,600 epoch 20 - iter 24/32 - loss 0.13310608 - samples/sec: 125.10 - lr: 0.000030
2021-07-23 21:27:37,410 epoch 20 - iter 27/32 - loss 0.12917074 - samples/sec: 118.63 - lr: 0.000030
2021-07-23 21:27:38,187 epoch 20 - iter 30/32 - loss 0.13317490 - samples/sec: 123.64 - lr: 0.000030
2021-07-23 21:27:38,524 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:38,524 EPOCH 20 done: loss 0.1273 - lr 0.0000300
2021-07-23 21:27:39,319 DEV : loss 0.0727548822760582 - score 0.9847
2021-07-23 21:27:39,333 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:27:41,727 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:42,506 epoch 21 - iter 3/32 - loss 0.12225168 - samples/sec: 123.54 - lr: 0.000030
2021-07-23 21:27:43,296 epoch 21 - iter 6/32 - loss 0.11537845 - samples/sec: 121.59 - lr: 0.000030
2021-07-23 21:27:44,047 epoch 21 - iter 9/32 - loss 0.12255815 - samples/sec: 127.86 - lr: 0.000030
2021-07-23 21:27:44,767 epoch 21 - iter 12/32 - loss 0.11678218 - samples/sec: 133.44 - lr: 0.000030
2021-07-23 21:27:45,563 epoch 21 - iter 15/32 - loss 0.13889324 - samples/sec: 120.73 - lr: 0.000030
2021-07-23 21:27:46,316 epoch 21 - iter 18/32 - loss 0.14262762 - samples/sec: 127.52 - lr: 0.000030
2021-07-23 21:27:47,058 epoch 21 - iter 21/32 - loss 0.14850972 - samples/sec: 129.52 - lr: 0.000030
2021-07-23 21:27:47,825 epoch 21 - iter 24/32 - loss 0.14268488 - samples/sec: 125.15 - lr: 0.000030
2021-07-23 21:27:48,623 epoch 21 - iter 27/32 - loss 0.14340099 - samples/sec: 120.33 - lr: 0.000030
2021-07-23 21:27:49,356 epoch 21 - iter 30/32 - loss 0.13951376 - samples/sec: 131.09 - lr: 0.000030
2021-07-23 21:27:49,692 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:49,692 EPOCH 21 done: loss 0.1367 - lr 0.0000300
2021-07-23 21:27:50,483 DEV : loss 0.06909755617380142 - score 0.9847
2021-07-23 21:27:50,493 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:27:53,011 ----------------------------------------------------------------------------------------------------
2021-07-23 21:27:53,836 epoch 22 - iter 3/32 - loss 0.15668055 - samples/sec: 116.72 - lr: 0.000030
2021-07-23 21:27:54,515 epoch 22 - iter 6/32 - loss 0.15660027 - samples/sec: 141.41 - lr: 0.000030
2021-07-23 21:27:55,297 epoch 22 - iter 9/32 - loss 0.13900213 - samples/sec: 122.91 - lr: 0.000030
2021-07-23 21:27:56,019 epoch 22 - iter 12/32 - loss 0.12486429 - samples/sec: 133.04 - lr: 0.000030
2021-07-23 21:27:56,751 epoch 22 - iter 15/32 - loss 0.13609378 - samples/sec: 131.06 - lr: 0.000030
2021-07-23 21:27:57,540 epoch 22 - iter 18/32 - loss 0.13338371 - samples/sec: 121.82 - lr: 0.000030
2021-07-23 21:27:58,336 epoch 22 - iter 21/32 - loss 0.14447509 - samples/sec: 120.67 - lr: 0.000030
2021-07-23 21:27:59,109 epoch 22 - iter 24/32 - loss 0.13921411 - samples/sec: 124.30 - lr: 0.000030
2021-07-23 21:27:59,893 epoch 22 - iter 27/32 - loss 0.13839250 - samples/sec: 122.45 - lr: 0.000030
2021-07-23 21:28:00,719 epoch 22 - iter 30/32 - loss 0.13806469 - samples/sec: 116.24 - lr: 0.000030
2021-07-23 21:28:01,075 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:01,075 EPOCH 22 done: loss 0.1495 - lr 0.0000300
2021-07-23 21:28:01,866 DEV : loss 0.06594987213611603 - score 0.9847
2021-07-23 21:28:01,878 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:28:04,372 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:05,188 epoch 23 - iter 3/32 - loss 0.09021103 - samples/sec: 117.90 - lr: 0.000030
2021-07-23 21:28:05,955 epoch 23 - iter 6/32 - loss 0.12384667 - samples/sec: 125.25 - lr: 0.000030
2021-07-23 21:28:06,713 epoch 23 - iter 9/32 - loss 0.11110471 - samples/sec: 126.81 - lr: 0.000030
2021-07-23 21:28:07,524 epoch 23 - iter 12/32 - loss 0.12239300 - samples/sec: 118.35 - lr: 0.000030
2021-07-23 21:28:08,269 epoch 23 - iter 15/32 - loss 0.10906330 - samples/sec: 129.04 - lr: 0.000030
2021-07-23 21:28:08,967 epoch 23 - iter 18/32 - loss 0.10695074 - samples/sec: 137.54 - lr: 0.000030
2021-07-23 21:28:09,750 epoch 23 - iter 21/32 - loss 0.10757770 - samples/sec: 122.71 - lr: 0.000030
2021-07-23 21:28:10,494 epoch 23 - iter 24/32 - loss 0.10650620 - samples/sec: 128.98 - lr: 0.000030
2021-07-23 21:28:11,240 epoch 23 - iter 27/32 - loss 0.10467854 - samples/sec: 128.84 - lr: 0.000030
2021-07-23 21:28:12,043 epoch 23 - iter 30/32 - loss 0.11252122 - samples/sec: 119.57 - lr: 0.000030
2021-07-23 21:28:12,348 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:12,349 EPOCH 23 done: loss 0.1095 - lr 0.0000300
2021-07-23 21:28:13,139 DEV : loss 0.06568529456853867 - score 0.9847
2021-07-23 21:28:13,149 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:28:15,512 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:16,288 epoch 24 - iter 3/32 - loss 0.10122905 - samples/sec: 124.00 - lr: 0.000030
2021-07-23 21:28:17,063 epoch 24 - iter 6/32 - loss 0.11301123 - samples/sec: 123.92 - lr: 0.000030
2021-07-23 21:28:17,808 epoch 24 - iter 9/32 - loss 0.10062830 - samples/sec: 129.04 - lr: 0.000030
2021-07-23 21:28:18,647 epoch 24 - iter 12/32 - loss 0.10422292 - samples/sec: 114.37 - lr: 0.000030
2021-07-23 21:28:19,428 epoch 24 - iter 15/32 - loss 0.11131233 - samples/sec: 123.08 - lr: 0.000030
2021-07-23 21:28:20,139 epoch 24 - iter 18/32 - loss 0.11257490 - samples/sec: 135.07 - lr: 0.000030
2021-07-23 21:28:20,895 epoch 24 - iter 21/32 - loss 0.10779090 - samples/sec: 127.01 - lr: 0.000030
2021-07-23 21:28:21,656 epoch 24 - iter 24/32 - loss 0.11067421 - samples/sec: 126.31 - lr: 0.000030
2021-07-23 21:28:22,455 epoch 24 - iter 27/32 - loss 0.10801560 - samples/sec: 120.12 - lr: 0.000030
2021-07-23 21:28:23,156 epoch 24 - iter 30/32 - loss 0.10638869 - samples/sec: 136.98 - lr: 0.000030
2021-07-23 21:28:23,483 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:23,483 EPOCH 24 done: loss 0.1873 - lr 0.0000300
2021-07-23 21:28:24,275 DEV : loss 0.06388687342405319 - score 0.9847
2021-07-23 21:28:24,285 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:28:26,699 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:27,389 epoch 25 - iter 3/32 - loss 0.08531603 - samples/sec: 139.46 - lr: 0.000030
2021-07-23 21:28:28,127 epoch 25 - iter 6/32 - loss 0.09375953 - samples/sec: 130.08 - lr: 0.000030
2021-07-23 21:28:28,983 epoch 25 - iter 9/32 - loss 0.10535153 - samples/sec: 112.27 - lr: 0.000030
2021-07-23 21:28:29,723 epoch 25 - iter 12/32 - loss 0.09665945 - samples/sec: 129.75 - lr: 0.000030
2021-07-23 21:28:30,508 epoch 25 - iter 15/32 - loss 0.09895714 - samples/sec: 122.40 - lr: 0.000030
2021-07-23 21:28:31,281 epoch 25 - iter 18/32 - loss 0.09874385 - samples/sec: 124.19 - lr: 0.000030
2021-07-23 21:28:31,986 epoch 25 - iter 21/32 - loss 0.10011980 - samples/sec: 136.37 - lr: 0.000030
2021-07-23 21:28:32,707 epoch 25 - iter 24/32 - loss 0.09663306 - samples/sec: 133.15 - lr: 0.000030
2021-07-23 21:28:33,518 epoch 25 - iter 27/32 - loss 0.09776241 - samples/sec: 118.46 - lr: 0.000030
2021-07-23 21:28:34,325 epoch 25 - iter 30/32 - loss 0.10088040 - samples/sec: 118.92 - lr: 0.000030
2021-07-23 21:28:34,671 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:34,671 EPOCH 25 done: loss 0.0979 - lr 0.0000300
2021-07-23 21:28:35,462 DEV : loss 0.062407027930021286 - score 0.9847
2021-07-23 21:28:35,476 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:28:37,893 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:38,598 epoch 26 - iter 3/32 - loss 0.13859100 - samples/sec: 136.57 - lr: 0.000030
2021-07-23 21:28:39,457 epoch 26 - iter 6/32 - loss 0.14207600 - samples/sec: 111.75 - lr: 0.000030
2021-07-23 21:28:40,228 epoch 26 - iter 9/32 - loss 0.13016845 - samples/sec: 124.60 - lr: 0.000030
2021-07-23 21:28:40,936 epoch 26 - iter 12/32 - loss 0.11756737 - samples/sec: 135.67 - lr: 0.000030
2021-07-23 21:28:41,687 epoch 26 - iter 15/32 - loss 0.11089564 - samples/sec: 127.80 - lr: 0.000030
2021-07-23 21:28:42,449 epoch 26 - iter 18/32 - loss 0.10876970 - samples/sec: 126.17 - lr: 0.000030
2021-07-23 21:28:43,275 epoch 26 - iter 21/32 - loss 0.11152645 - samples/sec: 116.27 - lr: 0.000030
2021-07-23 21:28:43,984 epoch 26 - iter 24/32 - loss 0.11146363 - samples/sec: 135.45 - lr: 0.000030
2021-07-23 21:28:44,759 epoch 26 - iter 27/32 - loss 0.11191753 - samples/sec: 123.91 - lr: 0.000030
2021-07-23 21:28:45,540 epoch 26 - iter 30/32 - loss 0.10707342 - samples/sec: 123.02 - lr: 0.000030
2021-07-23 21:28:45,844 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:45,844 EPOCH 26 done: loss 0.1083 - lr 0.0000300
2021-07-23 21:28:46,635 DEV : loss 0.06056405231356621 - score 0.9847
2021-07-23 21:28:46,645 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:28:49,045 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:49,869 epoch 27 - iter 3/32 - loss 0.12106978 - samples/sec: 116.78 - lr: 0.000030
2021-07-23 21:28:50,643 epoch 27 - iter 6/32 - loss 0.09997982 - samples/sec: 124.06 - lr: 0.000030
2021-07-23 21:28:51,400 epoch 27 - iter 9/32 - loss 0.09082585 - samples/sec: 126.90 - lr: 0.000030
2021-07-23 21:28:52,083 epoch 27 - iter 12/32 - loss 0.08112281 - samples/sec: 140.62 - lr: 0.000030
2021-07-23 21:28:52,829 epoch 27 - iter 15/32 - loss 0.08081069 - samples/sec: 128.75 - lr: 0.000030
2021-07-23 21:28:53,605 epoch 27 - iter 18/32 - loss 0.08621765 - samples/sec: 123.81 - lr: 0.000030
2021-07-23 21:28:54,399 epoch 27 - iter 21/32 - loss 0.08772552 - samples/sec: 120.93 - lr: 0.000030
2021-07-23 21:28:55,196 epoch 27 - iter 24/32 - loss 0.09035061 - samples/sec: 120.59 - lr: 0.000030
2021-07-23 21:28:55,945 epoch 27 - iter 27/32 - loss 0.09255574 - samples/sec: 128.21 - lr: 0.000030
2021-07-23 21:28:56,684 epoch 27 - iter 30/32 - loss 0.09404983 - samples/sec: 129.94 - lr: 0.000030
2021-07-23 21:28:56,996 ----------------------------------------------------------------------------------------------------
2021-07-23 21:28:56,996 EPOCH 27 done: loss 0.0953 - lr 0.0000300
2021-07-23 21:28:57,786 DEV : loss 0.06025099381804466 - score 0.9847
2021-07-23 21:28:57,796 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:29:00,328 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:01,085 epoch 28 - iter 3/32 - loss 0.09257195 - samples/sec: 127.07 - lr: 0.000030
2021-07-23 21:29:01,926 epoch 28 - iter 6/32 - loss 0.08223821 - samples/sec: 114.21 - lr: 0.000030
2021-07-23 21:29:02,674 epoch 28 - iter 9/32 - loss 0.08353123 - samples/sec: 128.33 - lr: 0.000030
2021-07-23 21:29:03,377 epoch 28 - iter 12/32 - loss 0.08961332 - samples/sec: 136.70 - lr: 0.000030
2021-07-23 21:29:04,155 epoch 28 - iter 15/32 - loss 0.08533514 - samples/sec: 123.37 - lr: 0.000030
2021-07-23 21:29:04,893 epoch 28 - iter 18/32 - loss 0.08647098 - samples/sec: 130.20 - lr: 0.000030
2021-07-23 21:29:05,724 epoch 28 - iter 21/32 - loss 0.08231818 - samples/sec: 115.59 - lr: 0.000030
2021-07-23 21:29:06,497 epoch 28 - iter 24/32 - loss 0.08743550 - samples/sec: 124.31 - lr: 0.000030
2021-07-23 21:29:07,255 epoch 28 - iter 27/32 - loss 0.09109940 - samples/sec: 126.68 - lr: 0.000030
2021-07-23 21:29:08,037 epoch 28 - iter 30/32 - loss 0.09123374 - samples/sec: 122.74 - lr: 0.000030
2021-07-23 21:29:08,356 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:08,356 EPOCH 28 done: loss 0.0902 - lr 0.0000300
2021-07-23 21:29:09,146 DEV : loss 0.05888862535357475 - score 0.9847
2021-07-23 21:29:09,155 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:29:11,860 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:12,640 epoch 29 - iter 3/32 - loss 0.09009123 - samples/sec: 123.38 - lr: 0.000030
2021-07-23 21:29:13,367 epoch 29 - iter 6/32 - loss 0.07977355 - samples/sec: 132.08 - lr: 0.000030
2021-07-23 21:29:14,148 epoch 29 - iter 9/32 - loss 0.09311712 - samples/sec: 122.99 - lr: 0.000030
2021-07-23 21:29:14,903 epoch 29 - iter 12/32 - loss 0.08665701 - samples/sec: 127.26 - lr: 0.000030
2021-07-23 21:29:15,604 epoch 29 - iter 15/32 - loss 0.09789531 - samples/sec: 136.91 - lr: 0.000030
2021-07-23 21:29:16,349 epoch 29 - iter 18/32 - loss 0.10087475 - samples/sec: 128.92 - lr: 0.000030
2021-07-23 21:29:17,211 epoch 29 - iter 21/32 - loss 0.09674752 - samples/sec: 111.43 - lr: 0.000030
2021-07-23 21:29:18,057 epoch 29 - iter 24/32 - loss 0.09159140 - samples/sec: 113.54 - lr: 0.000030
2021-07-23 21:29:18,838 epoch 29 - iter 27/32 - loss 0.09407839 - samples/sec: 123.08 - lr: 0.000030
2021-07-23 21:29:19,604 epoch 29 - iter 30/32 - loss 0.09631796 - samples/sec: 125.34 - lr: 0.000030
2021-07-23 21:29:19,861 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:19,861 EPOCH 29 done: loss 0.0937 - lr 0.0000300
2021-07-23 21:29:20,653 DEV : loss 0.05738356336951256 - score 0.9847
2021-07-23 21:29:20,663 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:29:23,288 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:24,074 epoch 30 - iter 3/32 - loss 0.06895348 - samples/sec: 122.45 - lr: 0.000030
2021-07-23 21:29:24,892 epoch 30 - iter 6/32 - loss 0.07619355 - samples/sec: 117.46 - lr: 0.000030
2021-07-23 21:29:25,697 epoch 30 - iter 9/32 - loss 0.06493307 - samples/sec: 119.24 - lr: 0.000030
2021-07-23 21:29:26,354 epoch 30 - iter 12/32 - loss 0.05463208 - samples/sec: 146.23 - lr: 0.000030
2021-07-23 21:29:27,127 epoch 30 - iter 15/32 - loss 0.05276979 - samples/sec: 124.22 - lr: 0.000030
2021-07-23 21:29:27,818 epoch 30 - iter 18/32 - loss 0.05564707 - samples/sec: 138.99 - lr: 0.000030
2021-07-23 21:29:28,604 epoch 30 - iter 21/32 - loss 0.05656360 - samples/sec: 122.19 - lr: 0.000030
2021-07-23 21:29:29,428 epoch 30 - iter 24/32 - loss 0.06931445 - samples/sec: 116.62 - lr: 0.000030
2021-07-23 21:29:30,160 epoch 30 - iter 27/32 - loss 0.06913200 - samples/sec: 131.30 - lr: 0.000030
2021-07-23 21:29:30,977 epoch 30 - iter 30/32 - loss 0.07268381 - samples/sec: 117.53 - lr: 0.000030
2021-07-23 21:29:31,281 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:31,281 EPOCH 30 done: loss 0.0721 - lr 0.0000300
2021-07-23 21:29:32,074 DEV : loss 0.06088092923164368 - score 0.9873
2021-07-23 21:29:32,084 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:29:34,603 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:35,354 epoch 31 - iter 3/32 - loss 0.09700927 - samples/sec: 128.30 - lr: 0.000030
2021-07-23 21:29:36,124 epoch 31 - iter 6/32 - loss 0.09375501 - samples/sec: 124.64 - lr: 0.000030
2021-07-23 21:29:36,856 epoch 31 - iter 9/32 - loss 0.08609620 - samples/sec: 131.26 - lr: 0.000030
2021-07-23 21:29:37,623 epoch 31 - iter 12/32 - loss 0.08101481 - samples/sec: 125.13 - lr: 0.000030
2021-07-23 21:29:38,391 epoch 31 - iter 15/32 - loss 0.08139937 - samples/sec: 125.17 - lr: 0.000030
2021-07-23 21:29:39,188 epoch 31 - iter 18/32 - loss 0.07575863 - samples/sec: 120.45 - lr: 0.000030
2021-07-23 21:29:39,984 epoch 31 - iter 21/32 - loss 0.08384225 - samples/sec: 120.65 - lr: 0.000030
2021-07-23 21:29:40,768 epoch 31 - iter 24/32 - loss 0.08392580 - samples/sec: 122.51 - lr: 0.000030
2021-07-23 21:29:41,582 epoch 31 - iter 27/32 - loss 0.08363717 - samples/sec: 118.10 - lr: 0.000030
2021-07-23 21:29:42,313 epoch 31 - iter 30/32 - loss 0.08980350 - samples/sec: 131.33 - lr: 0.000030
2021-07-23 21:29:42,623 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:42,623 EPOCH 31 done: loss 0.0882 - lr 0.0000300
2021-07-23 21:29:43,418 DEV : loss 0.0624677911400795 - score 0.9848
2021-07-23 21:29:43,428 BAD EPOCHS (no improvement): 1
2021-07-23 21:29:43,428 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:44,163 epoch 32 - iter 3/32 - loss 0.06834227 - samples/sec: 130.86 - lr: 0.000030
2021-07-23 21:29:44,975 epoch 32 - iter 6/32 - loss 0.07431860 - samples/sec: 118.30 - lr: 0.000030
2021-07-23 21:29:45,759 epoch 32 - iter 9/32 - loss 0.08119529 - samples/sec: 122.46 - lr: 0.000030
2021-07-23 21:29:46,499 epoch 32 - iter 12/32 - loss 0.08178544 - samples/sec: 129.75 - lr: 0.000030
2021-07-23 21:29:47,276 epoch 32 - iter 15/32 - loss 0.08394423 - samples/sec: 123.62 - lr: 0.000030
2021-07-23 21:29:48,103 epoch 32 - iter 18/32 - loss 0.07974621 - samples/sec: 116.15 - lr: 0.000030
2021-07-23 21:29:48,867 epoch 32 - iter 21/32 - loss 0.08521447 - samples/sec: 125.80 - lr: 0.000030
2021-07-23 21:29:49,579 epoch 32 - iter 24/32 - loss 0.08270326 - samples/sec: 134.94 - lr: 0.000030
2021-07-23 21:29:50,354 epoch 32 - iter 27/32 - loss 0.08186835 - samples/sec: 123.91 - lr: 0.000030
2021-07-23 21:29:51,094 epoch 32 - iter 30/32 - loss 0.07861279 - samples/sec: 129.70 - lr: 0.000030
2021-07-23 21:29:51,392 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:51,392 EPOCH 32 done: loss 0.0770 - lr 0.0000300
2021-07-23 21:29:52,183 DEV : loss 0.05995391681790352 - score 0.9847
2021-07-23 21:29:52,193 BAD EPOCHS (no improvement): 2
2021-07-23 21:29:52,193 ----------------------------------------------------------------------------------------------------
2021-07-23 21:29:52,975 epoch 33 - iter 3/32 - loss 0.08833404 - samples/sec: 122.90 - lr: 0.000030
2021-07-23 21:29:53,712 epoch 33 - iter 6/32 - loss 0.07270488 - samples/sec: 130.28 - lr: 0.000030
2021-07-23 21:29:54,535 epoch 33 - iter 9/32 - loss 0.06987977 - samples/sec: 116.77 - lr: 0.000030
2021-07-23 21:29:55,264 epoch 33 - iter 12/32 - loss 0.08444464 - samples/sec: 131.81 - lr: 0.000030
2021-07-23 21:29:56,001 epoch 33 - iter 15/32 - loss 0.07594245 - samples/sec: 130.31 - lr: 0.000030
2021-07-23 21:29:56,755 epoch 33 - iter 18/32 - loss 0.07946015 - samples/sec: 127.29 - lr: 0.000030
2021-07-23 21:29:57,532 epoch 33 - iter 21/32 - loss 0.08272209 - samples/sec: 123.70 - lr: 0.000030
2021-07-23 21:29:58,313 epoch 33 - iter 24/32 - loss 0.08204753 - samples/sec: 122.98 - lr: 0.000030
2021-07-23 21:29:59,052 epoch 33 - iter 27/32 - loss 0.08425808 - samples/sec: 129.94 - lr: 0.000030
2021-07-23 21:29:59,869 epoch 33 - iter 30/32 - loss 0.08149493 - samples/sec: 117.54 - lr: 0.000030
2021-07-23 21:30:00,180 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:00,180 EPOCH 33 done: loss 0.0801 - lr 0.0000300
2021-07-23 21:30:00,971 DEV : loss 0.058779921382665634 - score 0.9847
2021-07-23 21:30:00,980 BAD EPOCHS (no improvement): 3
2021-07-23 21:30:00,980 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:01,755 epoch 34 - iter 3/32 - loss 0.10601227 - samples/sec: 124.16 - lr: 0.000030
2021-07-23 21:30:02,528 epoch 34 - iter 6/32 - loss 0.09744330 - samples/sec: 124.18 - lr: 0.000030
2021-07-23 21:30:03,302 epoch 34 - iter 9/32 - loss 0.08293728 - samples/sec: 124.17 - lr: 0.000030
2021-07-23 21:30:04,016 epoch 34 - iter 12/32 - loss 0.07361764 - samples/sec: 134.45 - lr: 0.000030
2021-07-23 21:30:04,759 epoch 34 - iter 15/32 - loss 0.07821500 - samples/sec: 129.33 - lr: 0.000030
2021-07-23 21:30:05,559 epoch 34 - iter 18/32 - loss 0.07769841 - samples/sec: 120.13 - lr: 0.000030
2021-07-23 21:30:06,437 epoch 34 - iter 21/32 - loss 0.07949931 - samples/sec: 109.36 - lr: 0.000030
2021-07-23 21:30:07,159 epoch 34 - iter 24/32 - loss 0.07811730 - samples/sec: 133.00 - lr: 0.000030
2021-07-23 21:30:07,970 epoch 34 - iter 27/32 - loss 0.08337132 - samples/sec: 118.50 - lr: 0.000030
2021-07-23 21:30:08,763 epoch 34 - iter 30/32 - loss 0.08202900 - samples/sec: 121.08 - lr: 0.000030
2021-07-23 21:30:09,051 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:09,051 EPOCH 34 done: loss 0.0782 - lr 0.0000300
2021-07-23 21:30:09,840 DEV : loss 0.060576021671295166 - score 0.9848
Epoch    34: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 21:30:09,849 BAD EPOCHS (no improvement): 4
2021-07-23 21:30:09,850 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:10,694 epoch 35 - iter 3/32 - loss 0.09871049 - samples/sec: 113.88 - lr: 0.000015
2021-07-23 21:30:11,447 epoch 35 - iter 6/32 - loss 0.09876760 - samples/sec: 127.61 - lr: 0.000015
2021-07-23 21:30:12,172 epoch 35 - iter 9/32 - loss 0.08390127 - samples/sec: 132.51 - lr: 0.000015
2021-07-23 21:30:12,980 epoch 35 - iter 12/32 - loss 0.07657265 - samples/sec: 118.78 - lr: 0.000015
2021-07-23 21:30:13,692 epoch 35 - iter 15/32 - loss 0.06883526 - samples/sec: 134.96 - lr: 0.000015
2021-07-23 21:30:14,501 epoch 35 - iter 18/32 - loss 0.07592476 - samples/sec: 118.74 - lr: 0.000015
2021-07-23 21:30:15,312 epoch 35 - iter 21/32 - loss 0.08516799 - samples/sec: 118.42 - lr: 0.000015
2021-07-23 21:30:16,029 epoch 35 - iter 24/32 - loss 0.07766131 - samples/sec: 133.91 - lr: 0.000015
2021-07-23 21:30:16,764 epoch 35 - iter 27/32 - loss 0.07875792 - samples/sec: 130.76 - lr: 0.000015
2021-07-23 21:30:17,511 epoch 35 - iter 30/32 - loss 0.07506174 - samples/sec: 128.59 - lr: 0.000015
2021-07-23 21:30:17,816 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:17,817 EPOCH 35 done: loss 0.0747 - lr 0.0000150
2021-07-23 21:30:18,606 DEV : loss 0.059390999376773834 - score 0.9873
2021-07-23 21:30:18,616 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:30:21,225 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:22,033 epoch 36 - iter 3/32 - loss 0.11522832 - samples/sec: 119.05 - lr: 0.000015
2021-07-23 21:30:22,801 epoch 36 - iter 6/32 - loss 0.08982551 - samples/sec: 125.02 - lr: 0.000015
2021-07-23 21:30:23,561 epoch 36 - iter 9/32 - loss 0.07373214 - samples/sec: 126.48 - lr: 0.000015
2021-07-23 21:30:24,361 epoch 36 - iter 12/32 - loss 0.07409173 - samples/sec: 120.01 - lr: 0.000015
2021-07-23 21:30:25,104 epoch 36 - iter 15/32 - loss 0.07830482 - samples/sec: 129.36 - lr: 0.000015
2021-07-23 21:30:25,820 epoch 36 - iter 18/32 - loss 0.07663333 - samples/sec: 133.98 - lr: 0.000015
2021-07-23 21:30:26,666 epoch 36 - iter 21/32 - loss 0.07353803 - samples/sec: 113.59 - lr: 0.000015
2021-07-23 21:30:27,384 epoch 36 - iter 24/32 - loss 0.07536535 - samples/sec: 133.75 - lr: 0.000015
2021-07-23 21:30:28,080 epoch 36 - iter 27/32 - loss 0.07333928 - samples/sec: 138.00 - lr: 0.000015
2021-07-23 21:30:28,883 epoch 36 - iter 30/32 - loss 0.07364509 - samples/sec: 119.57 - lr: 0.000015
2021-07-23 21:30:29,223 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:29,223 EPOCH 36 done: loss 0.0712 - lr 0.0000150
2021-07-23 21:30:30,014 DEV : loss 0.05869460105895996 - score 0.9847
2021-07-23 21:30:30,024 BAD EPOCHS (no improvement): 1
2021-07-23 21:30:30,024 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:30,812 epoch 37 - iter 3/32 - loss 0.05905466 - samples/sec: 122.00 - lr: 0.000015
2021-07-23 21:30:31,612 epoch 37 - iter 6/32 - loss 0.04739172 - samples/sec: 120.11 - lr: 0.000015
2021-07-23 21:30:32,304 epoch 37 - iter 9/32 - loss 0.06864690 - samples/sec: 138.89 - lr: 0.000015
2021-07-23 21:30:33,117 epoch 37 - iter 12/32 - loss 0.09114899 - samples/sec: 118.07 - lr: 0.000015
2021-07-23 21:30:33,903 epoch 37 - iter 15/32 - loss 0.08859875 - samples/sec: 122.18 - lr: 0.000015
2021-07-23 21:30:34,676 epoch 37 - iter 18/32 - loss 0.08667114 - samples/sec: 124.35 - lr: 0.000015
2021-07-23 21:30:35,448 epoch 37 - iter 21/32 - loss 0.08642129 - samples/sec: 124.37 - lr: 0.000015
2021-07-23 21:30:36,161 epoch 37 - iter 24/32 - loss 0.09499713 - samples/sec: 134.74 - lr: 0.000015
2021-07-23 21:30:36,944 epoch 37 - iter 27/32 - loss 0.08965080 - samples/sec: 122.65 - lr: 0.000015
2021-07-23 21:30:37,740 epoch 37 - iter 30/32 - loss 0.08974307 - samples/sec: 120.65 - lr: 0.000015
2021-07-23 21:30:38,013 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:38,013 EPOCH 37 done: loss 0.0854 - lr 0.0000150
2021-07-23 21:30:38,805 DEV : loss 0.06235583499073982 - score 0.9848
2021-07-23 21:30:38,815 BAD EPOCHS (no improvement): 2
2021-07-23 21:30:38,815 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:39,532 epoch 38 - iter 3/32 - loss 0.07482956 - samples/sec: 134.12 - lr: 0.000015
2021-07-23 21:30:40,325 epoch 38 - iter 6/32 - loss 0.08350130 - samples/sec: 121.18 - lr: 0.000015
2021-07-23 21:30:40,980 epoch 38 - iter 9/32 - loss 0.09184579 - samples/sec: 146.64 - lr: 0.000015
2021-07-23 21:30:41,833 epoch 38 - iter 12/32 - loss 0.07435547 - samples/sec: 112.59 - lr: 0.000015
2021-07-23 21:30:42,633 epoch 38 - iter 15/32 - loss 0.08313562 - samples/sec: 120.07 - lr: 0.000015
2021-07-23 21:30:43,392 epoch 38 - iter 18/32 - loss 0.07881261 - samples/sec: 126.51 - lr: 0.000015
2021-07-23 21:30:44,136 epoch 38 - iter 21/32 - loss 0.07926552 - samples/sec: 129.11 - lr: 0.000015
2021-07-23 21:30:44,908 epoch 38 - iter 24/32 - loss 0.07410385 - samples/sec: 124.38 - lr: 0.000015
2021-07-23 21:30:45,676 epoch 38 - iter 27/32 - loss 0.06865518 - samples/sec: 125.10 - lr: 0.000015
2021-07-23 21:30:46,497 epoch 38 - iter 30/32 - loss 0.06848892 - samples/sec: 116.92 - lr: 0.000015
2021-07-23 21:30:46,792 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:46,793 EPOCH 38 done: loss 0.0691 - lr 0.0000150
2021-07-23 21:30:47,583 DEV : loss 0.06200825795531273 - score 0.9848
2021-07-23 21:30:47,592 BAD EPOCHS (no improvement): 3
2021-07-23 21:30:47,592 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:48,383 epoch 39 - iter 3/32 - loss 0.06550782 - samples/sec: 121.56 - lr: 0.000015
2021-07-23 21:30:49,144 epoch 39 - iter 6/32 - loss 0.05337938 - samples/sec: 126.25 - lr: 0.000015
2021-07-23 21:30:49,945 epoch 39 - iter 9/32 - loss 0.06025258 - samples/sec: 119.95 - lr: 0.000015
2021-07-23 21:30:50,668 epoch 39 - iter 12/32 - loss 0.07030395 - samples/sec: 132.94 - lr: 0.000015
2021-07-23 21:30:51,423 epoch 39 - iter 15/32 - loss 0.07573843 - samples/sec: 127.17 - lr: 0.000015
2021-07-23 21:30:52,191 epoch 39 - iter 18/32 - loss 0.06836104 - samples/sec: 125.07 - lr: 0.000015
2021-07-23 21:30:52,909 epoch 39 - iter 21/32 - loss 0.06425880 - samples/sec: 133.73 - lr: 0.000015
2021-07-23 21:30:53,701 epoch 39 - iter 24/32 - loss 0.06271426 - samples/sec: 121.29 - lr: 0.000015
2021-07-23 21:30:54,509 epoch 39 - iter 27/32 - loss 0.05931482 - samples/sec: 118.87 - lr: 0.000015
2021-07-23 21:30:55,263 epoch 39 - iter 30/32 - loss 0.06222131 - samples/sec: 127.37 - lr: 0.000015
2021-07-23 21:30:55,563 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:55,563 EPOCH 39 done: loss 0.0593 - lr 0.0000150
2021-07-23 21:30:56,355 DEV : loss 0.06087794899940491 - score 0.9823
Epoch    39: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 21:30:56,369 BAD EPOCHS (no improvement): 4
2021-07-23 21:30:56,369 ----------------------------------------------------------------------------------------------------
2021-07-23 21:30:57,117 epoch 40 - iter 3/32 - loss 0.03042386 - samples/sec: 128.62 - lr: 0.000008
2021-07-23 21:30:57,847 epoch 40 - iter 6/32 - loss 0.03658504 - samples/sec: 131.63 - lr: 0.000008
2021-07-23 21:30:58,608 epoch 40 - iter 9/32 - loss 0.06514291 - samples/sec: 126.08 - lr: 0.000008
2021-07-23 21:30:59,362 epoch 40 - iter 12/32 - loss 0.05915723 - samples/sec: 127.53 - lr: 0.000008
2021-07-23 21:31:00,136 epoch 40 - iter 15/32 - loss 0.05131537 - samples/sec: 124.11 - lr: 0.000008
2021-07-23 21:31:00,926 epoch 40 - iter 18/32 - loss 0.05004827 - samples/sec: 121.53 - lr: 0.000008
2021-07-23 21:31:01,731 epoch 40 - iter 21/32 - loss 0.05002748 - samples/sec: 119.28 - lr: 0.000008
2021-07-23 21:31:02,650 epoch 40 - iter 24/32 - loss 0.05636288 - samples/sec: 104.51 - lr: 0.000008
2021-07-23 21:31:03,401 epoch 40 - iter 27/32 - loss 0.05503795 - samples/sec: 128.03 - lr: 0.000008
2021-07-23 21:31:04,126 epoch 40 - iter 30/32 - loss 0.06145208 - samples/sec: 132.52 - lr: 0.000008
2021-07-23 21:31:04,434 ----------------------------------------------------------------------------------------------------
2021-07-23 21:31:04,434 EPOCH 40 done: loss 0.0608 - lr 0.0000075
2021-07-23 21:31:05,223 DEV : loss 0.06243591383099556 - score 0.9848
2021-07-23 21:31:05,232 BAD EPOCHS (no improvement): 1
2021-07-23 21:31:05,796 ----------------------------------------------------------------------------------------------------
2021-07-23 21:31:05,796 Testing using best model ...
2021-07-23 21:31:05,797 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/spa.rst.sctb/best-model.pt
2021-07-23 21:31:11,668 0.9894	0.9842	0.9868
2021-07-23 21:31:11,668 
Results:
- F1-score (micro) 0.9868
- F1-score (macro) 0.9839

By class:
SENT       tp: 75 - fp: 2 - fn: 3 - precision: 0.9740 - recall: 0.9615 - f1-score: 0.9677
X          tp: 112 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 21:31:11,668 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.pdtb.pdtb/
2021-07-23 21:31:11,700 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.pdtb.pdtb
2021-07-23 21:31:11,700 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.pdtb.pdtb/sent_train.txt
2021-07-23 21:31:11,702 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.pdtb.pdtb/sent_dev.txt
2021-07-23 21:31:11,703 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.pdtb.pdtb/sent_test.txt
Corpus: 105434 train + 5406 dev + 38250 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 21:31:33,838 ----------------------------------------------------------------------------------------------------
2021-07-23 21:31:33,840 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 21:31:33,840 ----------------------------------------------------------------------------------------------------
2021-07-23 21:31:33,840 Corpus: "Corpus: 105434 train + 5406 dev + 38250 test sentences"
2021-07-23 21:31:33,840 ----------------------------------------------------------------------------------------------------
2021-07-23 21:31:33,840 Parameters:
2021-07-23 21:31:33,840  - learning_rate: "3e-05"
2021-07-23 21:31:33,840  - mini_batch_size: "32"
2021-07-23 21:31:33,840  - patience: "3"
2021-07-23 21:31:33,840  - anneal_factor: "0.5"
2021-07-23 21:31:33,840  - max_epochs: "40"
2021-07-23 21:31:33,840  - shuffle: "True"
2021-07-23 21:31:33,841  - train_with_dev: "False"
2021-07-23 21:31:33,841  - batch_growth_annealing: "False"
2021-07-23 21:31:33,841 ----------------------------------------------------------------------------------------------------
2021-07-23 21:31:33,841 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.pdtb.pdtb"
2021-07-23 21:31:33,841 ----------------------------------------------------------------------------------------------------
2021-07-23 21:31:33,841 Device: cuda:0
2021-07-23 21:31:33,841 ----------------------------------------------------------------------------------------------------
2021-07-23 21:31:33,841 Embeddings storage mode: cpu
2021-07-23 21:31:33,843 ----------------------------------------------------------------------------------------------------
2021-07-23 21:34:47,911 epoch 1 - iter 329/3295 - loss 4.97732723 - samples/sec: 54.25 - lr: 0.000030
2021-07-23 21:38:07,876 epoch 1 - iter 658/3295 - loss 2.65738098 - samples/sec: 52.65 - lr: 0.000030
2021-07-23 21:41:37,316 epoch 1 - iter 987/3295 - loss 1.85650001 - samples/sec: 50.27 - lr: 0.000030
2021-07-23 21:45:05,378 epoch 1 - iter 1316/3295 - loss 1.45024270 - samples/sec: 50.60 - lr: 0.000030
2021-07-23 21:48:30,065 epoch 1 - iter 1645/3295 - loss 1.20003469 - samples/sec: 51.44 - lr: 0.000030
2021-07-23 21:51:44,109 epoch 1 - iter 1974/3295 - loss 1.03547801 - samples/sec: 54.26 - lr: 0.000030
2021-07-23 21:54:57,845 epoch 1 - iter 2303/3295 - loss 0.91549651 - samples/sec: 54.35 - lr: 0.000030
2021-07-23 21:58:12,399 epoch 1 - iter 2632/3295 - loss 0.82573266 - samples/sec: 54.12 - lr: 0.000030
2021-07-23 22:01:27,312 epoch 1 - iter 2961/3295 - loss 0.75405144 - samples/sec: 54.02 - lr: 0.000030
2021-07-23 22:04:42,220 epoch 1 - iter 3290/3295 - loss 0.69690090 - samples/sec: 54.02 - lr: 0.000030
2021-07-23 22:04:45,122 ----------------------------------------------------------------------------------------------------
2021-07-23 22:04:45,123 EPOCH 1 done: loss 0.6960 - lr 0.0000300
2021-07-23 22:05:55,888 DEV : loss 0.06989629566669464 - score 0.9824
2021-07-23 22:05:56,032 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 22:05:56,588 ----------------------------------------------------------------------------------------------------
2021-07-23 22:07:16,503 epoch 2 - iter 329/3295 - loss 0.17545021 - samples/sec: 131.77 - lr: 0.000030
2021-07-23 22:08:35,976 epoch 2 - iter 658/3295 - loss 0.17340121 - samples/sec: 132.50 - lr: 0.000030
2021-07-23 22:09:56,168 epoch 2 - iter 987/3295 - loss 0.16993346 - samples/sec: 131.31 - lr: 0.000030
2021-07-23 22:11:15,345 epoch 2 - iter 1316/3295 - loss 0.16576380 - samples/sec: 132.99 - lr: 0.000030
2021-07-23 22:12:35,022 epoch 2 - iter 1645/3295 - loss 0.16138794 - samples/sec: 132.16 - lr: 0.000030
2021-07-23 22:13:54,195 epoch 2 - iter 1974/3295 - loss 0.15797888 - samples/sec: 133.00 - lr: 0.000030
2021-07-23 22:15:13,388 epoch 2 - iter 2303/3295 - loss 0.15307348 - samples/sec: 132.97 - lr: 0.000030
2021-07-23 22:16:33,168 epoch 2 - iter 2632/3295 - loss 0.14882730 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 22:17:52,248 epoch 2 - iter 2961/3295 - loss 0.14400411 - samples/sec: 133.16 - lr: 0.000030
2021-07-23 22:19:11,347 epoch 2 - iter 3290/3295 - loss 0.13990585 - samples/sec: 133.13 - lr: 0.000030
2021-07-23 22:19:12,493 ----------------------------------------------------------------------------------------------------
2021-07-23 22:19:12,494 EPOCH 2 done: loss 0.1398 - lr 0.0000300
2021-07-23 22:19:25,526 DEV : loss 0.0544719472527504 - score 0.9855
2021-07-23 22:19:25,670 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 22:19:28,000 ----------------------------------------------------------------------------------------------------
2021-07-23 22:20:47,863 epoch 3 - iter 329/3295 - loss 0.09774767 - samples/sec: 131.87 - lr: 0.000030
2021-07-23 22:22:07,589 epoch 3 - iter 658/3295 - loss 0.09441026 - samples/sec: 132.08 - lr: 0.000030
2021-07-23 22:23:28,164 epoch 3 - iter 987/3295 - loss 0.09559572 - samples/sec: 130.69 - lr: 0.000030
2021-07-23 22:24:48,641 epoch 3 - iter 1316/3295 - loss 0.09327080 - samples/sec: 130.85 - lr: 0.000030
2021-07-23 22:26:09,916 epoch 3 - iter 1645/3295 - loss 0.09307987 - samples/sec: 129.56 - lr: 0.000030
2021-07-23 22:27:29,688 epoch 3 - iter 1974/3295 - loss 0.09152365 - samples/sec: 132.00 - lr: 0.000030
2021-07-23 22:28:49,812 epoch 3 - iter 2303/3295 - loss 0.08993696 - samples/sec: 131.42 - lr: 0.000030
2021-07-23 22:30:09,775 epoch 3 - iter 2632/3295 - loss 0.09015271 - samples/sec: 131.69 - lr: 0.000030
2021-07-23 22:31:29,888 epoch 3 - iter 2961/3295 - loss 0.08934413 - samples/sec: 131.44 - lr: 0.000030
2021-07-23 22:32:49,946 epoch 3 - iter 3290/3295 - loss 0.08822548 - samples/sec: 131.53 - lr: 0.000030
2021-07-23 22:32:51,129 ----------------------------------------------------------------------------------------------------
2021-07-23 22:32:51,129 EPOCH 3 done: loss 0.0882 - lr 0.0000300
2021-07-23 22:33:07,222 DEV : loss 0.04904767498373985 - score 0.9867
2021-07-23 22:33:07,367 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 22:33:09,865 ----------------------------------------------------------------------------------------------------
2021-07-23 22:34:30,109 epoch 4 - iter 329/3295 - loss 0.08076499 - samples/sec: 131.24 - lr: 0.000030
2021-07-23 22:35:50,910 epoch 4 - iter 658/3295 - loss 0.08119136 - samples/sec: 130.32 - lr: 0.000030
2021-07-23 22:37:11,580 epoch 4 - iter 987/3295 - loss 0.07946026 - samples/sec: 130.53 - lr: 0.000030
2021-07-23 22:38:32,310 epoch 4 - iter 1316/3295 - loss 0.07949645 - samples/sec: 130.44 - lr: 0.000030
2021-07-23 22:39:52,471 epoch 4 - iter 1645/3295 - loss 0.07785742 - samples/sec: 131.36 - lr: 0.000030
2021-07-23 22:41:13,223 epoch 4 - iter 1974/3295 - loss 0.07766623 - samples/sec: 130.40 - lr: 0.000030
2021-07-23 22:42:33,641 epoch 4 - iter 2303/3295 - loss 0.07795424 - samples/sec: 130.94 - lr: 0.000030
2021-07-23 22:43:53,563 epoch 4 - iter 2632/3295 - loss 0.07844882 - samples/sec: 131.76 - lr: 0.000030
2021-07-23 22:45:13,699 epoch 4 - iter 2961/3295 - loss 0.07890670 - samples/sec: 131.40 - lr: 0.000030
2021-07-23 22:46:34,164 epoch 4 - iter 3290/3295 - loss 0.07839674 - samples/sec: 130.87 - lr: 0.000030
2021-07-23 22:46:35,389 ----------------------------------------------------------------------------------------------------
2021-07-23 22:46:35,389 EPOCH 4 done: loss 0.0784 - lr 0.0000300
2021-07-23 22:46:48,571 DEV : loss 0.04960467666387558 - score 0.9866
2021-07-23 22:46:48,717 BAD EPOCHS (no improvement): 1
2021-07-23 22:46:48,717 ----------------------------------------------------------------------------------------------------
2021-07-23 22:48:09,039 epoch 5 - iter 329/3295 - loss 0.07307306 - samples/sec: 131.11 - lr: 0.000030
2021-07-23 22:49:29,640 epoch 5 - iter 658/3295 - loss 0.06979328 - samples/sec: 130.65 - lr: 0.000030
2021-07-23 22:50:50,631 epoch 5 - iter 987/3295 - loss 0.07296340 - samples/sec: 130.02 - lr: 0.000030
2021-07-23 22:52:11,310 epoch 5 - iter 1316/3295 - loss 0.07422726 - samples/sec: 130.52 - lr: 0.000030
2021-07-23 22:53:31,303 epoch 5 - iter 1645/3295 - loss 0.07440763 - samples/sec: 131.64 - lr: 0.000030
2021-07-23 22:54:52,343 epoch 5 - iter 1974/3295 - loss 0.07485827 - samples/sec: 129.94 - lr: 0.000030
2021-07-23 22:56:13,450 epoch 5 - iter 2303/3295 - loss 0.07384829 - samples/sec: 129.83 - lr: 0.000030
2021-07-23 22:57:34,672 epoch 5 - iter 2632/3295 - loss 0.07383761 - samples/sec: 129.65 - lr: 0.000030
2021-07-23 22:58:54,980 epoch 5 - iter 2961/3295 - loss 0.07387963 - samples/sec: 131.12 - lr: 0.000030
2021-07-23 23:00:16,460 epoch 5 - iter 3290/3295 - loss 0.07335187 - samples/sec: 129.24 - lr: 0.000030
2021-07-23 23:00:17,735 ----------------------------------------------------------------------------------------------------
2021-07-23 23:00:17,735 EPOCH 5 done: loss 0.0734 - lr 0.0000300
2021-07-23 23:00:30,981 DEV : loss 0.05033644288778305 - score 0.9864
2021-07-23 23:00:31,127 BAD EPOCHS (no improvement): 2
2021-07-23 23:00:31,127 ----------------------------------------------------------------------------------------------------
2021-07-23 23:01:51,951 epoch 6 - iter 329/3295 - loss 0.06546182 - samples/sec: 130.29 - lr: 0.000030
2021-07-23 23:03:13,098 epoch 6 - iter 658/3295 - loss 0.06722200 - samples/sec: 129.77 - lr: 0.000030
2021-07-23 23:04:33,454 epoch 6 - iter 987/3295 - loss 0.06801257 - samples/sec: 131.04 - lr: 0.000030
2021-07-23 23:05:53,904 epoch 6 - iter 1316/3295 - loss 0.06891445 - samples/sec: 130.89 - lr: 0.000030
2021-07-23 23:07:14,156 epoch 6 - iter 1645/3295 - loss 0.06879057 - samples/sec: 131.21 - lr: 0.000030
2021-07-23 23:08:34,280 epoch 6 - iter 1974/3295 - loss 0.06852145 - samples/sec: 131.42 - lr: 0.000030
2021-07-23 23:09:56,097 epoch 6 - iter 2303/3295 - loss 0.06940183 - samples/sec: 128.70 - lr: 0.000030
2021-07-23 23:11:16,945 epoch 6 - iter 2632/3295 - loss 0.06918740 - samples/sec: 130.25 - lr: 0.000030
2021-07-23 23:12:37,591 epoch 6 - iter 2961/3295 - loss 0.06896705 - samples/sec: 130.57 - lr: 0.000030
2021-07-23 23:13:58,748 epoch 6 - iter 3290/3295 - loss 0.06911358 - samples/sec: 129.75 - lr: 0.000030
2021-07-23 23:13:59,968 ----------------------------------------------------------------------------------------------------
2021-07-23 23:13:59,968 EPOCH 6 done: loss 0.0691 - lr 0.0000300
2021-07-23 23:14:13,231 DEV : loss 0.04979709908366203 - score 0.9867
2021-07-23 23:14:13,376 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 23:14:15,652 ----------------------------------------------------------------------------------------------------
2021-07-23 23:15:36,708 epoch 7 - iter 329/3295 - loss 0.06986079 - samples/sec: 129.93 - lr: 0.000030
2021-07-23 23:16:57,671 epoch 7 - iter 658/3295 - loss 0.06941408 - samples/sec: 130.06 - lr: 0.000030
2021-07-23 23:18:18,409 epoch 7 - iter 987/3295 - loss 0.07051411 - samples/sec: 130.42 - lr: 0.000030
2021-07-23 23:19:38,741 epoch 7 - iter 1316/3295 - loss 0.06810692 - samples/sec: 131.08 - lr: 0.000030
2021-07-23 23:20:59,192 epoch 7 - iter 1645/3295 - loss 0.06724265 - samples/sec: 130.89 - lr: 0.000030
2021-07-23 23:22:20,331 epoch 7 - iter 1974/3295 - loss 0.06631070 - samples/sec: 129.78 - lr: 0.000030
2021-07-23 23:23:41,271 epoch 7 - iter 2303/3295 - loss 0.06586386 - samples/sec: 130.10 - lr: 0.000030
2021-07-23 23:25:01,997 epoch 7 - iter 2632/3295 - loss 0.06625359 - samples/sec: 130.44 - lr: 0.000030
2021-07-23 23:26:21,644 epoch 7 - iter 2961/3295 - loss 0.06597251 - samples/sec: 132.21 - lr: 0.000030
2021-07-23 23:27:42,213 epoch 7 - iter 3290/3295 - loss 0.06586611 - samples/sec: 130.70 - lr: 0.000030
2021-07-23 23:27:43,404 ----------------------------------------------------------------------------------------------------
2021-07-23 23:27:43,404 EPOCH 7 done: loss 0.0658 - lr 0.0000300
2021-07-23 23:27:56,638 DEV : loss 0.046160195022821426 - score 0.9879
2021-07-23 23:27:56,785 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 23:27:59,359 ----------------------------------------------------------------------------------------------------
2021-07-23 23:29:20,220 epoch 8 - iter 329/3295 - loss 0.06192912 - samples/sec: 130.24 - lr: 0.000030
2021-07-23 23:30:40,186 epoch 8 - iter 658/3295 - loss 0.06085042 - samples/sec: 131.68 - lr: 0.000030
2021-07-23 23:32:00,916 epoch 8 - iter 987/3295 - loss 0.05948027 - samples/sec: 130.44 - lr: 0.000030
2021-07-23 23:33:20,992 epoch 8 - iter 1316/3295 - loss 0.06091502 - samples/sec: 131.50 - lr: 0.000030
2021-07-23 23:34:41,948 epoch 8 - iter 1645/3295 - loss 0.06125193 - samples/sec: 130.07 - lr: 0.000030
2021-07-23 23:36:02,672 epoch 8 - iter 1974/3295 - loss 0.06119295 - samples/sec: 130.45 - lr: 0.000030
2021-07-23 23:37:23,699 epoch 8 - iter 2303/3295 - loss 0.06152837 - samples/sec: 129.96 - lr: 0.000030
2021-07-23 23:38:45,211 epoch 8 - iter 2632/3295 - loss 0.06182586 - samples/sec: 129.19 - lr: 0.000030
2021-07-23 23:40:05,820 epoch 8 - iter 2961/3295 - loss 0.06176029 - samples/sec: 130.63 - lr: 0.000030
2021-07-23 23:41:27,007 epoch 8 - iter 3290/3295 - loss 0.06267583 - samples/sec: 129.70 - lr: 0.000030
2021-07-23 23:41:28,232 ----------------------------------------------------------------------------------------------------
2021-07-23 23:41:28,232 EPOCH 8 done: loss 0.0627 - lr 0.0000300
2021-07-23 23:41:41,405 DEV : loss 0.04591132327914238 - score 0.987
2021-07-23 23:41:41,553 BAD EPOCHS (no improvement): 1
2021-07-23 23:41:41,553 ----------------------------------------------------------------------------------------------------
2021-07-23 23:43:01,889 epoch 9 - iter 329/3295 - loss 0.06545246 - samples/sec: 131.09 - lr: 0.000030
2021-07-23 23:44:22,718 epoch 9 - iter 658/3295 - loss 0.06484010 - samples/sec: 130.28 - lr: 0.000030
2021-07-23 23:45:43,285 epoch 9 - iter 987/3295 - loss 0.06356532 - samples/sec: 130.70 - lr: 0.000030
2021-07-23 23:47:03,927 epoch 9 - iter 1316/3295 - loss 0.06341452 - samples/sec: 130.58 - lr: 0.000030
2021-07-23 23:48:24,966 epoch 9 - iter 1645/3295 - loss 0.06284221 - samples/sec: 129.94 - lr: 0.000030
2021-07-23 23:49:45,161 epoch 9 - iter 1974/3295 - loss 0.06207406 - samples/sec: 131.31 - lr: 0.000030
2021-07-23 23:51:05,977 epoch 9 - iter 2303/3295 - loss 0.06282026 - samples/sec: 130.30 - lr: 0.000030
2021-07-23 23:52:26,559 epoch 9 - iter 2632/3295 - loss 0.06197243 - samples/sec: 130.68 - lr: 0.000030
2021-07-23 23:53:47,396 epoch 9 - iter 2961/3295 - loss 0.06143644 - samples/sec: 130.26 - lr: 0.000030
2021-07-23 23:55:08,578 epoch 9 - iter 3290/3295 - loss 0.06077253 - samples/sec: 129.71 - lr: 0.000030
2021-07-23 23:55:09,756 ----------------------------------------------------------------------------------------------------
2021-07-23 23:55:09,757 EPOCH 9 done: loss 0.0607 - lr 0.0000300
2021-07-23 23:55:22,942 DEV : loss 0.04378965497016907 - score 0.9881
2021-07-23 23:55:23,090 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 23:55:25,560 ----------------------------------------------------------------------------------------------------
2021-07-23 23:56:46,227 epoch 10 - iter 329/3295 - loss 0.05505858 - samples/sec: 130.55 - lr: 0.000030
2021-07-23 23:58:07,228 epoch 10 - iter 658/3295 - loss 0.05776742 - samples/sec: 130.00 - lr: 0.000030
2021-07-23 23:59:28,051 epoch 10 - iter 987/3295 - loss 0.05872620 - samples/sec: 130.29 - lr: 0.000030
2021-07-24 00:00:49,009 epoch 10 - iter 1316/3295 - loss 0.05824429 - samples/sec: 130.07 - lr: 0.000030
2021-07-24 00:02:09,299 epoch 10 - iter 1645/3295 - loss 0.05713534 - samples/sec: 131.15 - lr: 0.000030
2021-07-24 00:03:29,381 epoch 10 - iter 1974/3295 - loss 0.05692853 - samples/sec: 131.49 - lr: 0.000030
2021-07-24 00:04:49,292 epoch 10 - iter 2303/3295 - loss 0.05785158 - samples/sec: 131.77 - lr: 0.000030
2021-07-24 00:06:10,346 epoch 10 - iter 2632/3295 - loss 0.05836976 - samples/sec: 129.92 - lr: 0.000030
2021-07-24 00:07:31,493 epoch 10 - iter 2961/3295 - loss 0.05875086 - samples/sec: 129.77 - lr: 0.000030
2021-07-24 00:08:51,999 epoch 10 - iter 3290/3295 - loss 0.05880825 - samples/sec: 130.80 - lr: 0.000030
2021-07-24 00:08:53,139 ----------------------------------------------------------------------------------------------------
2021-07-24 00:08:53,139 EPOCH 10 done: loss 0.0588 - lr 0.0000300
2021-07-24 00:09:06,316 DEV : loss 0.04348897188901901 - score 0.9888
2021-07-24 00:09:06,464 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 00:09:09,015 ----------------------------------------------------------------------------------------------------
2021-07-24 00:10:32,984 epoch 11 - iter 329/3295 - loss 0.05997303 - samples/sec: 125.42 - lr: 0.000030
2021-07-24 00:11:53,232 epoch 11 - iter 658/3295 - loss 0.06104177 - samples/sec: 131.22 - lr: 0.000030
2021-07-24 00:13:14,635 epoch 11 - iter 987/3295 - loss 0.05850426 - samples/sec: 129.36 - lr: 0.000030
2021-07-24 00:14:35,028 epoch 11 - iter 1316/3295 - loss 0.05716906 - samples/sec: 130.98 - lr: 0.000030
2021-07-24 00:15:55,597 epoch 11 - iter 1645/3295 - loss 0.05719484 - samples/sec: 130.70 - lr: 0.000030
2021-07-24 00:17:16,375 epoch 11 - iter 1974/3295 - loss 0.05742439 - samples/sec: 130.36 - lr: 0.000030
2021-07-24 00:18:36,961 epoch 11 - iter 2303/3295 - loss 0.05833164 - samples/sec: 130.67 - lr: 0.000030
2021-07-24 00:19:58,327 epoch 11 - iter 2632/3295 - loss 0.05779157 - samples/sec: 129.42 - lr: 0.000030
2021-07-24 00:21:18,738 epoch 11 - iter 2961/3295 - loss 0.05802591 - samples/sec: 130.95 - lr: 0.000030
2021-07-24 00:22:39,859 epoch 11 - iter 3290/3295 - loss 0.05846901 - samples/sec: 129.81 - lr: 0.000030
2021-07-24 00:22:41,016 ----------------------------------------------------------------------------------------------------
2021-07-24 00:22:41,016 EPOCH 11 done: loss 0.0584 - lr 0.0000300
2021-07-24 00:22:54,233 DEV : loss 0.04384896531701088 - score 0.989
2021-07-24 00:22:54,381 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 00:22:56,931 ----------------------------------------------------------------------------------------------------
2021-07-24 00:24:17,708 epoch 12 - iter 329/3295 - loss 0.05514172 - samples/sec: 130.38 - lr: 0.000030
2021-07-24 00:25:38,505 epoch 12 - iter 658/3295 - loss 0.05731510 - samples/sec: 130.33 - lr: 0.000030
2021-07-24 00:26:59,290 epoch 12 - iter 987/3295 - loss 0.05633324 - samples/sec: 130.35 - lr: 0.000030
2021-07-24 00:28:20,282 epoch 12 - iter 1316/3295 - loss 0.05651871 - samples/sec: 130.01 - lr: 0.000030
2021-07-24 00:29:39,833 epoch 12 - iter 1645/3295 - loss 0.05647045 - samples/sec: 132.37 - lr: 0.000030
2021-07-24 00:30:59,759 epoch 12 - iter 1974/3295 - loss 0.05515548 - samples/sec: 131.75 - lr: 0.000030
2021-07-24 00:32:20,868 epoch 12 - iter 2303/3295 - loss 0.05612052 - samples/sec: 129.83 - lr: 0.000030
2021-07-24 00:33:41,609 epoch 12 - iter 2632/3295 - loss 0.05614336 - samples/sec: 130.42 - lr: 0.000030
2021-07-24 00:35:02,337 epoch 12 - iter 2961/3295 - loss 0.05668819 - samples/sec: 130.44 - lr: 0.000030
2021-07-24 00:36:22,624 epoch 12 - iter 3290/3295 - loss 0.05631537 - samples/sec: 131.16 - lr: 0.000030
2021-07-24 00:36:23,769 ----------------------------------------------------------------------------------------------------
2021-07-24 00:36:23,769 EPOCH 12 done: loss 0.0563 - lr 0.0000300
2021-07-24 00:36:37,005 DEV : loss 0.04296387359499931 - score 0.9898
2021-07-24 00:36:37,152 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 00:36:39,661 ----------------------------------------------------------------------------------------------------
2021-07-24 00:38:00,496 epoch 13 - iter 329/3295 - loss 0.05653502 - samples/sec: 130.28 - lr: 0.000030
2021-07-24 00:39:20,418 epoch 13 - iter 658/3295 - loss 0.05506481 - samples/sec: 131.76 - lr: 0.000030
2021-07-24 00:40:41,331 epoch 13 - iter 987/3295 - loss 0.05513294 - samples/sec: 130.14 - lr: 0.000030
2021-07-24 00:42:01,768 epoch 13 - iter 1316/3295 - loss 0.05388474 - samples/sec: 130.91 - lr: 0.000030
2021-07-24 00:43:22,458 epoch 13 - iter 1645/3295 - loss 0.05358353 - samples/sec: 130.50 - lr: 0.000030
2021-07-24 00:44:43,446 epoch 13 - iter 1974/3295 - loss 0.05282343 - samples/sec: 130.02 - lr: 0.000030
2021-07-24 00:46:03,760 epoch 13 - iter 2303/3295 - loss 0.05288709 - samples/sec: 131.11 - lr: 0.000030
2021-07-24 00:47:24,684 epoch 13 - iter 2632/3295 - loss 0.05368069 - samples/sec: 130.12 - lr: 0.000030
2021-07-24 00:48:45,476 epoch 13 - iter 2961/3295 - loss 0.05401673 - samples/sec: 130.34 - lr: 0.000030
2021-07-24 00:50:06,074 epoch 13 - iter 3290/3295 - loss 0.05412184 - samples/sec: 130.65 - lr: 0.000030
2021-07-24 00:50:07,230 ----------------------------------------------------------------------------------------------------
2021-07-24 00:50:07,231 EPOCH 13 done: loss 0.0541 - lr 0.0000300
2021-07-24 00:50:20,448 DEV : loss 0.04367909952998161 - score 0.9893
2021-07-24 00:50:20,597 BAD EPOCHS (no improvement): 1
2021-07-24 00:50:20,597 ----------------------------------------------------------------------------------------------------
2021-07-24 00:51:40,980 epoch 14 - iter 329/3295 - loss 0.05289526 - samples/sec: 131.01 - lr: 0.000030
2021-07-24 00:53:01,907 epoch 14 - iter 658/3295 - loss 0.05062591 - samples/sec: 130.12 - lr: 0.000030
2021-07-24 00:54:22,541 epoch 14 - iter 987/3295 - loss 0.05043328 - samples/sec: 130.59 - lr: 0.000030
2021-07-24 00:55:43,412 epoch 14 - iter 1316/3295 - loss 0.05191810 - samples/sec: 130.21 - lr: 0.000030
2021-07-24 00:57:03,738 epoch 14 - iter 1645/3295 - loss 0.05209127 - samples/sec: 131.09 - lr: 0.000030
2021-07-24 00:58:24,204 epoch 14 - iter 1974/3295 - loss 0.05299852 - samples/sec: 130.86 - lr: 0.000030
2021-07-24 00:59:45,195 epoch 14 - iter 2303/3295 - loss 0.05307502 - samples/sec: 130.02 - lr: 0.000030
2021-07-24 01:01:05,958 epoch 14 - iter 2632/3295 - loss 0.05277318 - samples/sec: 130.38 - lr: 0.000030
2021-07-24 01:02:27,268 epoch 14 - iter 2961/3295 - loss 0.05304593 - samples/sec: 129.51 - lr: 0.000030
2021-07-24 01:03:47,229 epoch 14 - iter 3290/3295 - loss 0.05288896 - samples/sec: 131.69 - lr: 0.000030
2021-07-24 01:03:48,521 ----------------------------------------------------------------------------------------------------
2021-07-24 01:03:48,521 EPOCH 14 done: loss 0.0529 - lr 0.0000300
2021-07-24 01:04:01,742 DEV : loss 0.046008482575416565 - score 0.9881
2021-07-24 01:04:01,890 BAD EPOCHS (no improvement): 2
2021-07-24 01:04:01,890 ----------------------------------------------------------------------------------------------------
2021-07-24 01:05:21,363 epoch 15 - iter 329/3295 - loss 0.05307163 - samples/sec: 132.51 - lr: 0.000030
2021-07-24 01:06:41,880 epoch 15 - iter 658/3295 - loss 0.05188089 - samples/sec: 130.78 - lr: 0.000030
2021-07-24 01:08:02,114 epoch 15 - iter 987/3295 - loss 0.05043746 - samples/sec: 131.24 - lr: 0.000030
2021-07-24 01:09:22,676 epoch 15 - iter 1316/3295 - loss 0.05178029 - samples/sec: 130.71 - lr: 0.000030
2021-07-24 01:10:43,674 epoch 15 - iter 1645/3295 - loss 0.05197339 - samples/sec: 130.00 - lr: 0.000030
2021-07-24 01:12:04,372 epoch 15 - iter 1974/3295 - loss 0.05120619 - samples/sec: 130.49 - lr: 0.000030
2021-07-24 01:13:25,052 epoch 15 - iter 2303/3295 - loss 0.05099657 - samples/sec: 130.52 - lr: 0.000030
2021-07-24 01:14:45,984 epoch 15 - iter 2632/3295 - loss 0.05141626 - samples/sec: 130.11 - lr: 0.000030
2021-07-24 01:16:07,497 epoch 15 - iter 2961/3295 - loss 0.05190862 - samples/sec: 129.18 - lr: 0.000030
2021-07-24 01:17:28,024 epoch 15 - iter 3290/3295 - loss 0.05161080 - samples/sec: 130.76 - lr: 0.000030
2021-07-24 01:17:29,245 ----------------------------------------------------------------------------------------------------
2021-07-24 01:17:29,246 EPOCH 15 done: loss 0.0518 - lr 0.0000300
2021-07-24 01:17:42,495 DEV : loss 0.04279375076293945 - score 0.9891
2021-07-24 01:17:42,643 BAD EPOCHS (no improvement): 3
2021-07-24 01:17:42,644 ----------------------------------------------------------------------------------------------------
2021-07-24 01:19:03,108 epoch 16 - iter 329/3295 - loss 0.05393894 - samples/sec: 130.88 - lr: 0.000030
2021-07-24 01:20:23,845 epoch 16 - iter 658/3295 - loss 0.04959343 - samples/sec: 130.42 - lr: 0.000030
2021-07-24 01:21:44,197 epoch 16 - iter 987/3295 - loss 0.04984682 - samples/sec: 131.05 - lr: 0.000030
2021-07-24 01:23:05,269 epoch 16 - iter 1316/3295 - loss 0.04963381 - samples/sec: 129.89 - lr: 0.000030
2021-07-24 01:24:26,537 epoch 16 - iter 1645/3295 - loss 0.04978395 - samples/sec: 129.57 - lr: 0.000030
2021-07-24 01:25:47,645 epoch 16 - iter 1974/3295 - loss 0.05039682 - samples/sec: 129.83 - lr: 0.000030
2021-07-24 01:27:07,736 epoch 16 - iter 2303/3295 - loss 0.04971548 - samples/sec: 131.48 - lr: 0.000030
2021-07-24 01:28:28,185 epoch 16 - iter 2632/3295 - loss 0.05002158 - samples/sec: 130.89 - lr: 0.000030
2021-07-24 01:29:48,977 epoch 16 - iter 2961/3295 - loss 0.05048697 - samples/sec: 130.34 - lr: 0.000030
2021-07-24 01:31:09,792 epoch 16 - iter 3290/3295 - loss 0.05045617 - samples/sec: 130.30 - lr: 0.000030
2021-07-24 01:31:10,997 ----------------------------------------------------------------------------------------------------
2021-07-24 01:31:10,997 EPOCH 16 done: loss 0.0505 - lr 0.0000300
2021-07-24 01:31:24,283 DEV : loss 0.04310880973935127 - score 0.9893
Epoch    16: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 01:31:24,433 BAD EPOCHS (no improvement): 4
2021-07-24 01:31:24,434 ----------------------------------------------------------------------------------------------------
2021-07-24 01:32:45,107 epoch 17 - iter 329/3295 - loss 0.04604803 - samples/sec: 130.54 - lr: 0.000015
2021-07-24 01:34:05,417 epoch 17 - iter 658/3295 - loss 0.04824768 - samples/sec: 131.12 - lr: 0.000015
2021-07-24 01:35:26,343 epoch 17 - iter 987/3295 - loss 0.04865821 - samples/sec: 130.12 - lr: 0.000015
2021-07-24 01:36:46,836 epoch 17 - iter 1316/3295 - loss 0.04780039 - samples/sec: 130.82 - lr: 0.000015
2021-07-24 01:38:07,609 epoch 17 - iter 1645/3295 - loss 0.04786367 - samples/sec: 130.37 - lr: 0.000015
2021-07-24 01:39:27,707 epoch 17 - iter 1974/3295 - loss 0.04784117 - samples/sec: 131.47 - lr: 0.000015
2021-07-24 01:40:49,039 epoch 17 - iter 2303/3295 - loss 0.04793344 - samples/sec: 129.47 - lr: 0.000015
2021-07-24 01:42:10,145 epoch 17 - iter 2632/3295 - loss 0.04750991 - samples/sec: 129.83 - lr: 0.000015
2021-07-24 01:43:30,860 epoch 17 - iter 2961/3295 - loss 0.04717929 - samples/sec: 130.46 - lr: 0.000015
2021-07-24 01:44:51,104 epoch 17 - iter 3290/3295 - loss 0.04768463 - samples/sec: 131.23 - lr: 0.000015
2021-07-24 01:44:52,290 ----------------------------------------------------------------------------------------------------
2021-07-24 01:44:52,291 EPOCH 17 done: loss 0.0477 - lr 0.0000150
2021-07-24 01:45:05,546 DEV : loss 0.0415787547826767 - score 0.9901
2021-07-24 01:45:05,697 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 01:45:08,100 ----------------------------------------------------------------------------------------------------
2021-07-24 01:46:29,368 epoch 18 - iter 329/3295 - loss 0.04685103 - samples/sec: 129.58 - lr: 0.000015
2021-07-24 01:47:50,620 epoch 18 - iter 658/3295 - loss 0.04764468 - samples/sec: 129.60 - lr: 0.000015
2021-07-24 01:49:13,962 epoch 18 - iter 987/3295 - loss 0.04682215 - samples/sec: 126.35 - lr: 0.000015
2021-07-24 01:50:34,715 epoch 18 - iter 1316/3295 - loss 0.04733699 - samples/sec: 130.40 - lr: 0.000015
2021-07-24 01:51:55,378 epoch 18 - iter 1645/3295 - loss 0.04809601 - samples/sec: 130.55 - lr: 0.000015
2021-07-24 01:53:15,647 epoch 18 - iter 1974/3295 - loss 0.04791078 - samples/sec: 131.19 - lr: 0.000015
2021-07-24 01:54:36,523 epoch 18 - iter 2303/3295 - loss 0.04755373 - samples/sec: 130.20 - lr: 0.000015
2021-07-24 01:55:56,785 epoch 18 - iter 2632/3295 - loss 0.04773400 - samples/sec: 131.20 - lr: 0.000015
2021-07-24 01:57:17,126 epoch 18 - iter 2961/3295 - loss 0.04809869 - samples/sec: 131.07 - lr: 0.000015
2021-07-24 01:58:38,224 epoch 18 - iter 3290/3295 - loss 0.04824122 - samples/sec: 129.84 - lr: 0.000015
2021-07-24 01:58:39,424 ----------------------------------------------------------------------------------------------------
2021-07-24 01:58:39,425 EPOCH 18 done: loss 0.0482 - lr 0.0000150
2021-07-24 01:58:52,727 DEV : loss 0.040776416659355164 - score 0.9898
2021-07-24 01:58:52,874 BAD EPOCHS (no improvement): 1
2021-07-24 01:58:52,875 ----------------------------------------------------------------------------------------------------
2021-07-24 02:00:13,000 epoch 19 - iter 329/3295 - loss 0.04398623 - samples/sec: 131.43 - lr: 0.000015
2021-07-24 02:01:33,746 epoch 19 - iter 658/3295 - loss 0.04590844 - samples/sec: 130.41 - lr: 0.000015
2021-07-24 02:02:55,208 epoch 19 - iter 987/3295 - loss 0.04693171 - samples/sec: 129.27 - lr: 0.000015
2021-07-24 02:04:15,868 epoch 19 - iter 1316/3295 - loss 0.04671108 - samples/sec: 130.55 - lr: 0.000015
2021-07-24 02:05:36,152 epoch 19 - iter 1645/3295 - loss 0.04619192 - samples/sec: 131.16 - lr: 0.000015
2021-07-24 02:06:56,565 epoch 19 - iter 1974/3295 - loss 0.04596040 - samples/sec: 130.95 - lr: 0.000015
2021-07-24 02:08:17,825 epoch 19 - iter 2303/3295 - loss 0.04602442 - samples/sec: 129.59 - lr: 0.000015
2021-07-24 02:09:38,680 epoch 19 - iter 2632/3295 - loss 0.04597140 - samples/sec: 130.24 - lr: 0.000015
2021-07-24 02:10:59,828 epoch 19 - iter 2961/3295 - loss 0.04656243 - samples/sec: 129.76 - lr: 0.000015
2021-07-24 02:12:20,940 epoch 19 - iter 3290/3295 - loss 0.04632079 - samples/sec: 129.82 - lr: 0.000015
2021-07-24 02:12:22,036 ----------------------------------------------------------------------------------------------------
2021-07-24 02:12:22,036 EPOCH 19 done: loss 0.0463 - lr 0.0000150
2021-07-24 02:12:35,265 DEV : loss 0.042018093168735504 - score 0.9905
2021-07-24 02:12:35,412 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 02:12:38,015 ----------------------------------------------------------------------------------------------------
2021-07-24 02:13:59,153 epoch 20 - iter 329/3295 - loss 0.04459147 - samples/sec: 129.79 - lr: 0.000015
2021-07-24 02:15:20,113 epoch 20 - iter 658/3295 - loss 0.04683879 - samples/sec: 130.07 - lr: 0.000015
2021-07-24 02:16:40,751 epoch 20 - iter 987/3295 - loss 0.04553608 - samples/sec: 130.58 - lr: 0.000015
2021-07-24 02:18:01,419 epoch 20 - iter 1316/3295 - loss 0.04583919 - samples/sec: 130.54 - lr: 0.000015
2021-07-24 02:19:21,628 epoch 20 - iter 1645/3295 - loss 0.04596990 - samples/sec: 131.28 - lr: 0.000015
2021-07-24 02:20:42,262 epoch 20 - iter 1974/3295 - loss 0.04567184 - samples/sec: 130.59 - lr: 0.000015
2021-07-24 02:22:02,592 epoch 20 - iter 2303/3295 - loss 0.04543554 - samples/sec: 131.09 - lr: 0.000015
2021-07-24 02:23:23,088 epoch 20 - iter 2632/3295 - loss 0.04548645 - samples/sec: 130.82 - lr: 0.000015
2021-07-24 02:24:43,748 epoch 20 - iter 2961/3295 - loss 0.04532082 - samples/sec: 130.55 - lr: 0.000015
2021-07-24 02:26:04,306 epoch 20 - iter 3290/3295 - loss 0.04573918 - samples/sec: 130.72 - lr: 0.000015
2021-07-24 02:26:05,489 ----------------------------------------------------------------------------------------------------
2021-07-24 02:26:05,489 EPOCH 20 done: loss 0.0458 - lr 0.0000150
2021-07-24 02:26:18,737 DEV : loss 0.04080337658524513 - score 0.9904
2021-07-24 02:26:18,886 BAD EPOCHS (no improvement): 1
2021-07-24 02:26:18,886 ----------------------------------------------------------------------------------------------------
2021-07-24 02:27:39,969 epoch 21 - iter 329/3295 - loss 0.05280806 - samples/sec: 129.88 - lr: 0.000015
2021-07-24 02:29:00,422 epoch 21 - iter 658/3295 - loss 0.04904827 - samples/sec: 130.89 - lr: 0.000015
2021-07-24 02:30:21,160 epoch 21 - iter 987/3295 - loss 0.04857377 - samples/sec: 130.42 - lr: 0.000015
2021-07-24 02:31:42,052 epoch 21 - iter 1316/3295 - loss 0.04680410 - samples/sec: 130.18 - lr: 0.000015
2021-07-24 02:33:02,772 epoch 21 - iter 1645/3295 - loss 0.04551377 - samples/sec: 130.45 - lr: 0.000015
2021-07-24 02:34:23,041 epoch 21 - iter 1974/3295 - loss 0.04572063 - samples/sec: 131.19 - lr: 0.000015
2021-07-24 02:35:43,676 epoch 21 - iter 2303/3295 - loss 0.04604962 - samples/sec: 130.59 - lr: 0.000015
2021-07-24 02:37:04,588 epoch 21 - iter 2632/3295 - loss 0.04543645 - samples/sec: 130.14 - lr: 0.000015
2021-07-24 02:38:25,059 epoch 21 - iter 2961/3295 - loss 0.04511341 - samples/sec: 130.86 - lr: 0.000015
2021-07-24 02:39:45,793 epoch 21 - iter 3290/3295 - loss 0.04506330 - samples/sec: 130.43 - lr: 0.000015
2021-07-24 02:39:46,952 ----------------------------------------------------------------------------------------------------
2021-07-24 02:39:46,952 EPOCH 21 done: loss 0.0451 - lr 0.0000150
2021-07-24 02:40:00,221 DEV : loss 0.040928035974502563 - score 0.9897
2021-07-24 02:40:00,369 BAD EPOCHS (no improvement): 2
2021-07-24 02:40:00,370 ----------------------------------------------------------------------------------------------------
2021-07-24 02:41:21,164 epoch 22 - iter 329/3295 - loss 0.04435927 - samples/sec: 130.34 - lr: 0.000015
2021-07-24 02:42:42,017 epoch 22 - iter 658/3295 - loss 0.04333100 - samples/sec: 130.24 - lr: 0.000015
2021-07-24 02:44:02,481 epoch 22 - iter 987/3295 - loss 0.04356937 - samples/sec: 130.87 - lr: 0.000015
2021-07-24 02:45:22,887 epoch 22 - iter 1316/3295 - loss 0.04436590 - samples/sec: 130.96 - lr: 0.000015
2021-07-24 02:46:44,328 epoch 22 - iter 1645/3295 - loss 0.04487504 - samples/sec: 129.30 - lr: 0.000015
2021-07-24 02:48:04,649 epoch 22 - iter 1974/3295 - loss 0.04474966 - samples/sec: 131.10 - lr: 0.000015
2021-07-24 02:49:26,121 epoch 22 - iter 2303/3295 - loss 0.04413663 - samples/sec: 129.25 - lr: 0.000015
2021-07-24 02:50:47,129 epoch 22 - iter 2632/3295 - loss 0.04427669 - samples/sec: 129.99 - lr: 0.000015
2021-07-24 02:52:07,255 epoch 22 - iter 2961/3295 - loss 0.04444329 - samples/sec: 131.42 - lr: 0.000015
2021-07-24 02:53:27,793 epoch 22 - iter 3290/3295 - loss 0.04471720 - samples/sec: 130.75 - lr: 0.000015
2021-07-24 02:53:28,957 ----------------------------------------------------------------------------------------------------
2021-07-24 02:53:28,957 EPOCH 22 done: loss 0.0447 - lr 0.0000150
2021-07-24 02:53:42,239 DEV : loss 0.0404004342854023 - score 0.9898
2021-07-24 02:53:42,386 BAD EPOCHS (no improvement): 3
2021-07-24 02:53:42,386 ----------------------------------------------------------------------------------------------------
2021-07-24 02:55:03,501 epoch 23 - iter 329/3295 - loss 0.04463686 - samples/sec: 129.83 - lr: 0.000015
2021-07-24 02:56:23,279 epoch 23 - iter 658/3295 - loss 0.04465271 - samples/sec: 131.99 - lr: 0.000015
2021-07-24 02:57:42,880 epoch 23 - iter 987/3295 - loss 0.04568045 - samples/sec: 132.29 - lr: 0.000015
2021-07-24 02:59:03,429 epoch 23 - iter 1316/3295 - loss 0.04579167 - samples/sec: 130.73 - lr: 0.000015
2021-07-24 03:00:24,296 epoch 23 - iter 1645/3295 - loss 0.04514141 - samples/sec: 130.22 - lr: 0.000015
2021-07-24 03:01:45,392 epoch 23 - iter 1974/3295 - loss 0.04449887 - samples/sec: 129.85 - lr: 0.000015
2021-07-24 03:03:06,700 epoch 23 - iter 2303/3295 - loss 0.04457136 - samples/sec: 129.51 - lr: 0.000015
2021-07-24 03:04:27,765 epoch 23 - iter 2632/3295 - loss 0.04433158 - samples/sec: 129.90 - lr: 0.000015
2021-07-24 03:05:48,729 epoch 23 - iter 2961/3295 - loss 0.04452938 - samples/sec: 130.06 - lr: 0.000015
2021-07-24 03:07:09,907 epoch 23 - iter 3290/3295 - loss 0.04463408 - samples/sec: 129.72 - lr: 0.000015
2021-07-24 03:07:11,101 ----------------------------------------------------------------------------------------------------
2021-07-24 03:07:11,101 EPOCH 23 done: loss 0.0447 - lr 0.0000150
2021-07-24 03:07:24,359 DEV : loss 0.03978670760989189 - score 0.9901
Epoch    23: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 03:07:24,508 BAD EPOCHS (no improvement): 4
2021-07-24 03:07:24,509 ----------------------------------------------------------------------------------------------------
2021-07-24 03:08:45,253 epoch 24 - iter 329/3295 - loss 0.03933804 - samples/sec: 130.42 - lr: 0.000008
2021-07-24 03:10:05,508 epoch 24 - iter 658/3295 - loss 0.04260021 - samples/sec: 131.21 - lr: 0.000008
2021-07-24 03:11:26,353 epoch 24 - iter 987/3295 - loss 0.04170325 - samples/sec: 130.25 - lr: 0.000008
2021-07-24 03:12:47,416 epoch 24 - iter 1316/3295 - loss 0.04235659 - samples/sec: 129.90 - lr: 0.000008
2021-07-24 03:14:07,791 epoch 24 - iter 1645/3295 - loss 0.04166028 - samples/sec: 131.01 - lr: 0.000008
2021-07-24 03:15:28,589 epoch 24 - iter 1974/3295 - loss 0.04229529 - samples/sec: 130.33 - lr: 0.000008
2021-07-24 03:16:49,202 epoch 24 - iter 2303/3295 - loss 0.04206214 - samples/sec: 130.63 - lr: 0.000008
2021-07-24 03:18:10,308 epoch 24 - iter 2632/3295 - loss 0.04251863 - samples/sec: 129.83 - lr: 0.000008
2021-07-24 03:19:31,132 epoch 24 - iter 2961/3295 - loss 0.04252944 - samples/sec: 130.29 - lr: 0.000008
2021-07-24 03:20:52,372 epoch 24 - iter 3290/3295 - loss 0.04281456 - samples/sec: 129.62 - lr: 0.000008
2021-07-24 03:20:53,595 ----------------------------------------------------------------------------------------------------
2021-07-24 03:20:53,595 EPOCH 24 done: loss 0.0428 - lr 0.0000075
2021-07-24 03:21:06,842 DEV : loss 0.04110221937298775 - score 0.99
2021-07-24 03:21:06,990 BAD EPOCHS (no improvement): 1
2021-07-24 03:21:06,990 ----------------------------------------------------------------------------------------------------
2021-07-24 03:22:28,088 epoch 25 - iter 329/3295 - loss 0.04201838 - samples/sec: 129.85 - lr: 0.000008
2021-07-24 03:23:48,947 epoch 25 - iter 658/3295 - loss 0.04192247 - samples/sec: 130.23 - lr: 0.000008
2021-07-24 03:25:09,908 epoch 25 - iter 987/3295 - loss 0.04162123 - samples/sec: 130.07 - lr: 0.000008
2021-07-24 03:26:30,772 epoch 25 - iter 1316/3295 - loss 0.04117920 - samples/sec: 130.22 - lr: 0.000008
2021-07-24 03:27:54,599 epoch 25 - iter 1645/3295 - loss 0.04140247 - samples/sec: 125.62 - lr: 0.000008
2021-07-24 03:29:15,124 epoch 25 - iter 1974/3295 - loss 0.04229843 - samples/sec: 130.77 - lr: 0.000008
2021-07-24 03:30:36,176 epoch 25 - iter 2303/3295 - loss 0.04190220 - samples/sec: 129.92 - lr: 0.000008
2021-07-24 03:31:56,912 epoch 25 - iter 2632/3295 - loss 0.04265447 - samples/sec: 130.43 - lr: 0.000008
2021-07-24 03:33:16,784 epoch 25 - iter 2961/3295 - loss 0.04233345 - samples/sec: 131.84 - lr: 0.000008
2021-07-24 03:34:36,821 epoch 25 - iter 3290/3295 - loss 0.04221854 - samples/sec: 131.57 - lr: 0.000008
2021-07-24 03:34:38,052 ----------------------------------------------------------------------------------------------------
2021-07-24 03:34:38,052 EPOCH 25 done: loss 0.0422 - lr 0.0000075
2021-07-24 03:34:51,300 DEV : loss 0.04145123064517975 - score 0.9899
2021-07-24 03:34:51,449 BAD EPOCHS (no improvement): 2
2021-07-24 03:34:51,449 ----------------------------------------------------------------------------------------------------
2021-07-24 03:36:11,957 epoch 26 - iter 329/3295 - loss 0.04399809 - samples/sec: 130.81 - lr: 0.000008
2021-07-24 03:37:32,519 epoch 26 - iter 658/3295 - loss 0.04373703 - samples/sec: 130.71 - lr: 0.000008
2021-07-24 03:38:52,731 epoch 26 - iter 987/3295 - loss 0.04304088 - samples/sec: 131.28 - lr: 0.000008
2021-07-24 03:40:13,072 epoch 26 - iter 1316/3295 - loss 0.04248855 - samples/sec: 131.07 - lr: 0.000008
2021-07-24 03:41:34,237 epoch 26 - iter 1645/3295 - loss 0.04184180 - samples/sec: 129.74 - lr: 0.000008
2021-07-24 03:42:55,391 epoch 26 - iter 1974/3295 - loss 0.04156058 - samples/sec: 129.75 - lr: 0.000008
2021-07-24 03:44:16,008 epoch 26 - iter 2303/3295 - loss 0.04225268 - samples/sec: 130.62 - lr: 0.000008
2021-07-24 03:45:36,560 epoch 26 - iter 2632/3295 - loss 0.04266959 - samples/sec: 130.72 - lr: 0.000008
2021-07-24 03:46:57,343 epoch 26 - iter 2961/3295 - loss 0.04299031 - samples/sec: 130.35 - lr: 0.000008
2021-07-24 03:48:17,916 epoch 26 - iter 3290/3295 - loss 0.04309332 - samples/sec: 130.69 - lr: 0.000008
2021-07-24 03:48:19,192 ----------------------------------------------------------------------------------------------------
2021-07-24 03:48:19,192 EPOCH 26 done: loss 0.0431 - lr 0.0000075
2021-07-24 03:48:32,469 DEV : loss 0.04102513939142227 - score 0.9897
2021-07-24 03:48:32,616 BAD EPOCHS (no improvement): 3
2021-07-24 03:48:32,616 ----------------------------------------------------------------------------------------------------
2021-07-24 03:49:52,894 epoch 27 - iter 329/3295 - loss 0.03957413 - samples/sec: 131.18 - lr: 0.000008
2021-07-24 03:51:13,085 epoch 27 - iter 658/3295 - loss 0.04264969 - samples/sec: 131.31 - lr: 0.000008
2021-07-24 03:52:33,808 epoch 27 - iter 987/3295 - loss 0.04441319 - samples/sec: 130.45 - lr: 0.000008
2021-07-24 03:53:54,717 epoch 27 - iter 1316/3295 - loss 0.04371527 - samples/sec: 130.15 - lr: 0.000008
2021-07-24 03:55:15,808 epoch 27 - iter 1645/3295 - loss 0.04307433 - samples/sec: 129.85 - lr: 0.000008
2021-07-24 03:56:37,083 epoch 27 - iter 1974/3295 - loss 0.04232912 - samples/sec: 129.56 - lr: 0.000008
2021-07-24 03:57:56,962 epoch 27 - iter 2303/3295 - loss 0.04186354 - samples/sec: 131.83 - lr: 0.000008
2021-07-24 03:59:17,638 epoch 27 - iter 2632/3295 - loss 0.04213560 - samples/sec: 130.52 - lr: 0.000008
2021-07-24 04:00:37,936 epoch 27 - iter 2961/3295 - loss 0.04222805 - samples/sec: 131.14 - lr: 0.000008
2021-07-24 04:01:58,981 epoch 27 - iter 3290/3295 - loss 0.04202145 - samples/sec: 129.93 - lr: 0.000008
2021-07-24 04:02:00,180 ----------------------------------------------------------------------------------------------------
2021-07-24 04:02:00,180 EPOCH 27 done: loss 0.0421 - lr 0.0000075
2021-07-24 04:02:13,463 DEV : loss 0.04045925661921501 - score 0.9901
Epoch    27: reducing learning rate of group 0 to 3.7500e-06.
2021-07-24 04:02:13,610 BAD EPOCHS (no improvement): 4
2021-07-24 04:02:13,611 ----------------------------------------------------------------------------------------------------
2021-07-24 04:03:34,020 epoch 28 - iter 329/3295 - loss 0.04315989 - samples/sec: 130.97 - lr: 0.000004
2021-07-24 04:04:54,687 epoch 28 - iter 658/3295 - loss 0.04147806 - samples/sec: 130.54 - lr: 0.000004
2021-07-24 04:06:15,750 epoch 28 - iter 987/3295 - loss 0.04105905 - samples/sec: 129.90 - lr: 0.000004
2021-07-24 04:07:36,796 epoch 28 - iter 1316/3295 - loss 0.04029203 - samples/sec: 129.93 - lr: 0.000004
2021-07-24 04:08:57,432 epoch 28 - iter 1645/3295 - loss 0.03998314 - samples/sec: 130.59 - lr: 0.000004
2021-07-24 04:10:18,335 epoch 28 - iter 1974/3295 - loss 0.04033612 - samples/sec: 130.16 - lr: 0.000004
2021-07-24 04:11:38,367 epoch 28 - iter 2303/3295 - loss 0.04024057 - samples/sec: 131.57 - lr: 0.000004
2021-07-24 04:12:59,518 epoch 28 - iter 2632/3295 - loss 0.04077122 - samples/sec: 129.76 - lr: 0.000004
2021-07-24 04:14:19,392 epoch 28 - iter 2961/3295 - loss 0.04080698 - samples/sec: 131.83 - lr: 0.000004
2021-07-24 04:15:40,207 epoch 28 - iter 3290/3295 - loss 0.04027541 - samples/sec: 130.30 - lr: 0.000004
2021-07-24 04:15:41,404 ----------------------------------------------------------------------------------------------------
2021-07-24 04:15:41,404 EPOCH 28 done: loss 0.0402 - lr 0.0000038
2021-07-24 04:15:54,677 DEV : loss 0.04114634916186333 - score 0.9898
2021-07-24 04:15:54,824 BAD EPOCHS (no improvement): 1
2021-07-24 04:15:54,824 ----------------------------------------------------------------------------------------------------
2021-07-24 04:17:15,901 epoch 29 - iter 329/3295 - loss 0.04269345 - samples/sec: 129.89 - lr: 0.000004
2021-07-24 04:18:36,876 epoch 29 - iter 658/3295 - loss 0.04319742 - samples/sec: 130.04 - lr: 0.000004
2021-07-24 04:19:57,525 epoch 29 - iter 987/3295 - loss 0.04291619 - samples/sec: 130.57 - lr: 0.000004
2021-07-24 04:21:18,536 epoch 29 - iter 1316/3295 - loss 0.04281175 - samples/sec: 129.98 - lr: 0.000004
2021-07-24 04:22:38,897 epoch 29 - iter 1645/3295 - loss 0.04221599 - samples/sec: 131.03 - lr: 0.000004
2021-07-24 04:23:58,340 epoch 29 - iter 1974/3295 - loss 0.04140639 - samples/sec: 132.55 - lr: 0.000004
2021-07-24 04:25:19,232 epoch 29 - iter 2303/3295 - loss 0.04140464 - samples/sec: 130.18 - lr: 0.000004
2021-07-24 04:26:40,040 epoch 29 - iter 2632/3295 - loss 0.04135364 - samples/sec: 130.31 - lr: 0.000004
2021-07-24 04:28:01,286 epoch 29 - iter 2961/3295 - loss 0.04182796 - samples/sec: 129.61 - lr: 0.000004
2021-07-24 04:29:21,408 epoch 29 - iter 3290/3295 - loss 0.04192237 - samples/sec: 131.43 - lr: 0.000004
2021-07-24 04:29:22,552 ----------------------------------------------------------------------------------------------------
2021-07-24 04:29:22,552 EPOCH 29 done: loss 0.0419 - lr 0.0000038
2021-07-24 04:29:35,794 DEV : loss 0.041241422295570374 - score 0.9899
2021-07-24 04:29:35,941 BAD EPOCHS (no improvement): 2
2021-07-24 04:29:35,942 ----------------------------------------------------------------------------------------------------
2021-07-24 04:30:56,644 epoch 30 - iter 329/3295 - loss 0.04345448 - samples/sec: 130.49 - lr: 0.000004
2021-07-24 04:32:17,580 epoch 30 - iter 658/3295 - loss 0.04176484 - samples/sec: 130.10 - lr: 0.000004
2021-07-24 04:33:38,277 epoch 30 - iter 987/3295 - loss 0.04163713 - samples/sec: 130.49 - lr: 0.000004
2021-07-24 04:34:58,624 epoch 30 - iter 1316/3295 - loss 0.04229931 - samples/sec: 131.06 - lr: 0.000004
2021-07-24 04:36:18,517 epoch 30 - iter 1645/3295 - loss 0.04203886 - samples/sec: 131.80 - lr: 0.000004
2021-07-24 04:37:38,568 epoch 30 - iter 1974/3295 - loss 0.04151192 - samples/sec: 131.54 - lr: 0.000004
2021-07-24 04:38:59,335 epoch 30 - iter 2303/3295 - loss 0.04106160 - samples/sec: 130.38 - lr: 0.000004
2021-07-24 04:40:20,700 epoch 30 - iter 2632/3295 - loss 0.04104393 - samples/sec: 129.42 - lr: 0.000004
2021-07-24 04:41:41,128 epoch 30 - iter 2961/3295 - loss 0.04070652 - samples/sec: 130.93 - lr: 0.000004
2021-07-24 04:43:01,632 epoch 30 - iter 3290/3295 - loss 0.04104729 - samples/sec: 130.80 - lr: 0.000004
2021-07-24 04:43:02,880 ----------------------------------------------------------------------------------------------------
2021-07-24 04:43:02,880 EPOCH 30 done: loss 0.0411 - lr 0.0000038
2021-07-24 04:43:16,135 DEV : loss 0.04151950404047966 - score 0.9898
2021-07-24 04:43:16,282 BAD EPOCHS (no improvement): 3
2021-07-24 04:43:16,283 ----------------------------------------------------------------------------------------------------
2021-07-24 04:44:36,652 epoch 31 - iter 329/3295 - loss 0.03927277 - samples/sec: 131.03 - lr: 0.000004
2021-07-24 04:45:57,643 epoch 31 - iter 658/3295 - loss 0.04182446 - samples/sec: 130.02 - lr: 0.000004
2021-07-24 04:47:17,656 epoch 31 - iter 987/3295 - loss 0.04351315 - samples/sec: 131.61 - lr: 0.000004
2021-07-24 04:48:38,570 epoch 31 - iter 1316/3295 - loss 0.04211531 - samples/sec: 130.14 - lr: 0.000004
2021-07-24 04:49:58,691 epoch 31 - iter 1645/3295 - loss 0.04237988 - samples/sec: 131.43 - lr: 0.000004
2021-07-24 04:51:20,397 epoch 31 - iter 1974/3295 - loss 0.04186601 - samples/sec: 128.88 - lr: 0.000004
2021-07-24 04:52:40,423 epoch 31 - iter 2303/3295 - loss 0.04124388 - samples/sec: 131.58 - lr: 0.000004
2021-07-24 04:54:01,220 epoch 31 - iter 2632/3295 - loss 0.04069364 - samples/sec: 130.33 - lr: 0.000004
2021-07-24 04:55:21,967 epoch 31 - iter 2961/3295 - loss 0.04027928 - samples/sec: 130.41 - lr: 0.000004
2021-07-24 04:56:42,483 epoch 31 - iter 3290/3295 - loss 0.04039685 - samples/sec: 130.78 - lr: 0.000004
2021-07-24 04:56:43,664 ----------------------------------------------------------------------------------------------------
2021-07-24 04:56:43,664 EPOCH 31 done: loss 0.0404 - lr 0.0000038
2021-07-24 04:56:56,933 DEV : loss 0.0410667322576046 - score 0.99
Epoch    31: reducing learning rate of group 0 to 1.8750e-06.
2021-07-24 04:56:57,079 BAD EPOCHS (no improvement): 4
2021-07-24 04:56:57,080 ----------------------------------------------------------------------------------------------------
2021-07-24 04:56:57,080 ----------------------------------------------------------------------------------------------------
2021-07-24 04:56:57,080 learning rate too small - quitting training!
2021-07-24 04:56:57,080 ----------------------------------------------------------------------------------------------------
2021-07-24 04:56:57,641 ----------------------------------------------------------------------------------------------------
2021-07-24 04:56:57,641 Testing using best model ...
2021-07-24 04:56:57,642 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.pdtb.pdtb/best-model.pt
2021-07-24 05:05:08,776 0.9909	0.9894	0.9901
2021-07-24 05:05:08,776 
Results:
- F1-score (micro) 0.9901
- F1-score (macro) 0.9894

By class:
SENT       tp: 11646 - fp: 233 - fn: 272 - precision: 0.9804 - recall: 0.9772 - f1-score: 0.9788
X          tp: 13689 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-24 05:05:08,776 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/rus.rst.rrt/
2021-07-24 05:05:08,819 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/rus.rst.rrt
2021-07-24 05:05:08,820 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/rus.rst.rrt/sent_train.txt
2021-07-24 05:05:08,822 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/rus.rst.rrt/sent_dev.txt
2021-07-24 05:05:08,824 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/rus.rst.rrt/sent_test.txt
Corpus: 42562 train + 5825 dev + 12668 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-24 05:05:27,097 ----------------------------------------------------------------------------------------------------
2021-07-24 05:05:27,100 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50021, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-24 05:05:27,100 ----------------------------------------------------------------------------------------------------
2021-07-24 05:05:27,101 Corpus: "Corpus: 42562 train + 5825 dev + 12668 test sentences"
2021-07-24 05:05:27,101 ----------------------------------------------------------------------------------------------------
2021-07-24 05:05:27,101 Parameters:
2021-07-24 05:05:27,101  - learning_rate: "3e-05"
2021-07-24 05:05:27,101  - mini_batch_size: "32"
2021-07-24 05:05:27,101  - patience: "3"
2021-07-24 05:05:27,101  - anneal_factor: "0.5"
2021-07-24 05:05:27,101  - max_epochs: "40"
2021-07-24 05:05:27,101  - shuffle: "True"
2021-07-24 05:05:27,102  - train_with_dev: "False"
2021-07-24 05:05:27,102  - batch_growth_annealing: "False"
2021-07-24 05:05:27,102 ----------------------------------------------------------------------------------------------------
2021-07-24 05:05:27,102 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/rus.rst.rrt"
2021-07-24 05:05:27,102 ----------------------------------------------------------------------------------------------------
2021-07-24 05:05:27,102 Device: cuda:0
2021-07-24 05:05:27,102 ----------------------------------------------------------------------------------------------------
2021-07-24 05:05:27,102 Embeddings storage mode: cpu
2021-07-24 05:05:27,107 ----------------------------------------------------------------------------------------------------
2021-07-24 05:06:43,669 epoch 1 - iter 133/1331 - loss 2.59336070 - samples/sec: 55.59 - lr: 0.000030
2021-07-24 05:08:02,270 epoch 1 - iter 266/1331 - loss 1.44678487 - samples/sec: 54.15 - lr: 0.000030
2021-07-24 05:09:20,695 epoch 1 - iter 399/1331 - loss 1.02748339 - samples/sec: 54.27 - lr: 0.000030
2021-07-24 05:10:41,086 epoch 1 - iter 532/1331 - loss 0.83022298 - samples/sec: 52.94 - lr: 0.000030
2021-07-24 05:12:01,441 epoch 1 - iter 665/1331 - loss 0.70043340 - samples/sec: 52.97 - lr: 0.000030
2021-07-24 05:13:22,299 epoch 1 - iter 798/1331 - loss 0.62537901 - samples/sec: 52.64 - lr: 0.000030
2021-07-24 05:14:42,662 epoch 1 - iter 931/1331 - loss 0.56884051 - samples/sec: 52.96 - lr: 0.000030
2021-07-24 05:16:03,945 epoch 1 - iter 1064/1331 - loss 0.52479014 - samples/sec: 52.36 - lr: 0.000030
2021-07-24 05:17:26,905 epoch 1 - iter 1197/1331 - loss 0.48851929 - samples/sec: 51.31 - lr: 0.000030
2021-07-24 05:18:51,823 epoch 1 - iter 1330/1331 - loss 0.45856772 - samples/sec: 50.12 - lr: 0.000030
2021-07-24 05:18:51,879 ----------------------------------------------------------------------------------------------------
2021-07-24 05:18:51,880 EPOCH 1 done: loss 0.4583 - lr 0.0000300
2021-07-24 05:20:13,086 DEV : loss 0.10765164345502853 - score 0.9721
2021-07-24 05:20:13,239 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:20:13,910 ----------------------------------------------------------------------------------------------------
2021-07-24 05:20:45,565 epoch 2 - iter 133/1331 - loss 0.16652549 - samples/sec: 134.49 - lr: 0.000030
2021-07-24 05:21:17,662 epoch 2 - iter 266/1331 - loss 0.16304462 - samples/sec: 132.63 - lr: 0.000030
2021-07-24 05:21:50,092 epoch 2 - iter 399/1331 - loss 0.15683231 - samples/sec: 131.26 - lr: 0.000030
2021-07-24 05:22:22,620 epoch 2 - iter 532/1331 - loss 0.15835281 - samples/sec: 130.87 - lr: 0.000030
2021-07-24 05:22:56,016 epoch 2 - iter 665/1331 - loss 0.15615486 - samples/sec: 127.46 - lr: 0.000030
2021-07-24 05:23:28,065 epoch 2 - iter 798/1331 - loss 0.15554755 - samples/sec: 132.82 - lr: 0.000030
2021-07-24 05:24:00,507 epoch 2 - iter 931/1331 - loss 0.15580191 - samples/sec: 131.22 - lr: 0.000030
2021-07-24 05:24:32,998 epoch 2 - iter 1064/1331 - loss 0.15526148 - samples/sec: 131.02 - lr: 0.000030
2021-07-24 05:25:05,055 epoch 2 - iter 1197/1331 - loss 0.15369752 - samples/sec: 132.79 - lr: 0.000030
2021-07-24 05:25:37,213 epoch 2 - iter 1330/1331 - loss 0.15268614 - samples/sec: 132.38 - lr: 0.000030
2021-07-24 05:25:37,285 ----------------------------------------------------------------------------------------------------
2021-07-24 05:25:37,285 EPOCH 2 done: loss 0.1527 - lr 0.0000300
2021-07-24 05:25:51,671 DEV : loss 0.08956687152385712 - score 0.9759
2021-07-24 05:25:51,825 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:25:54,766 ----------------------------------------------------------------------------------------------------
2021-07-24 05:26:27,196 epoch 3 - iter 133/1331 - loss 0.14222947 - samples/sec: 131.28 - lr: 0.000030
2021-07-24 05:26:59,905 epoch 3 - iter 266/1331 - loss 0.14908539 - samples/sec: 130.14 - lr: 0.000030
2021-07-24 05:27:31,793 epoch 3 - iter 399/1331 - loss 0.14311204 - samples/sec: 133.50 - lr: 0.000030
2021-07-24 05:28:04,584 epoch 3 - iter 532/1331 - loss 0.14284729 - samples/sec: 129.82 - lr: 0.000030
2021-07-24 05:28:36,991 epoch 3 - iter 665/1331 - loss 0.13958827 - samples/sec: 131.36 - lr: 0.000030
2021-07-24 05:29:09,497 epoch 3 - iter 798/1331 - loss 0.13762869 - samples/sec: 130.96 - lr: 0.000030
2021-07-24 05:29:42,224 epoch 3 - iter 931/1331 - loss 0.13508883 - samples/sec: 130.07 - lr: 0.000030
2021-07-24 05:30:14,460 epoch 3 - iter 1064/1331 - loss 0.13490974 - samples/sec: 132.05 - lr: 0.000030
2021-07-24 05:30:46,619 epoch 3 - iter 1197/1331 - loss 0.13443707 - samples/sec: 132.37 - lr: 0.000030
2021-07-24 05:31:19,240 epoch 3 - iter 1330/1331 - loss 0.13318054 - samples/sec: 130.50 - lr: 0.000030
2021-07-24 05:31:19,313 ----------------------------------------------------------------------------------------------------
2021-07-24 05:31:19,313 EPOCH 3 done: loss 0.1331 - lr 0.0000300
2021-07-24 05:31:33,591 DEV : loss 0.07710572332143784 - score 0.9786
2021-07-24 05:31:33,746 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:31:36,936 ----------------------------------------------------------------------------------------------------
2021-07-24 05:32:09,255 epoch 4 - iter 133/1331 - loss 0.12158371 - samples/sec: 131.73 - lr: 0.000030
2021-07-24 05:32:41,412 epoch 4 - iter 266/1331 - loss 0.12075424 - samples/sec: 132.38 - lr: 0.000030
2021-07-24 05:33:14,099 epoch 4 - iter 399/1331 - loss 0.12176909 - samples/sec: 130.23 - lr: 0.000030
2021-07-24 05:33:45,992 epoch 4 - iter 532/1331 - loss 0.12176288 - samples/sec: 133.47 - lr: 0.000030
2021-07-24 05:34:18,465 epoch 4 - iter 665/1331 - loss 0.12056538 - samples/sec: 131.09 - lr: 0.000030
2021-07-24 05:34:51,074 epoch 4 - iter 798/1331 - loss 0.11910569 - samples/sec: 130.54 - lr: 0.000030
2021-07-24 05:35:23,208 epoch 4 - iter 931/1331 - loss 0.11829666 - samples/sec: 132.47 - lr: 0.000030
2021-07-24 05:35:55,301 epoch 4 - iter 1064/1331 - loss 0.11719898 - samples/sec: 132.64 - lr: 0.000030
2021-07-24 05:36:27,030 epoch 4 - iter 1197/1331 - loss 0.11591180 - samples/sec: 134.16 - lr: 0.000030
2021-07-24 05:36:59,269 epoch 4 - iter 1330/1331 - loss 0.11482563 - samples/sec: 132.04 - lr: 0.000030
2021-07-24 05:36:59,323 ----------------------------------------------------------------------------------------------------
2021-07-24 05:36:59,323 EPOCH 4 done: loss 0.1151 - lr 0.0000300
2021-07-24 05:37:13,605 DEV : loss 0.07496587932109833 - score 0.9797
2021-07-24 05:37:13,758 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:37:16,894 ----------------------------------------------------------------------------------------------------
2021-07-24 05:37:50,121 epoch 5 - iter 133/1331 - loss 0.12067217 - samples/sec: 128.14 - lr: 0.000030
2021-07-24 05:38:22,729 epoch 5 - iter 266/1331 - loss 0.10954335 - samples/sec: 130.55 - lr: 0.000030
2021-07-24 05:38:54,919 epoch 5 - iter 399/1331 - loss 0.10862956 - samples/sec: 132.24 - lr: 0.000030
2021-07-24 05:39:27,548 epoch 5 - iter 532/1331 - loss 0.10675828 - samples/sec: 130.46 - lr: 0.000030
2021-07-24 05:39:59,780 epoch 5 - iter 665/1331 - loss 0.10461372 - samples/sec: 132.07 - lr: 0.000030
2021-07-24 05:40:32,087 epoch 5 - iter 798/1331 - loss 0.10395319 - samples/sec: 131.76 - lr: 0.000030
2021-07-24 05:41:04,700 epoch 5 - iter 931/1331 - loss 0.10283528 - samples/sec: 130.53 - lr: 0.000030
2021-07-24 05:41:37,585 epoch 5 - iter 1064/1331 - loss 0.10143700 - samples/sec: 129.44 - lr: 0.000030
2021-07-24 05:42:10,185 epoch 5 - iter 1197/1331 - loss 0.10230657 - samples/sec: 130.58 - lr: 0.000030
2021-07-24 05:42:42,819 epoch 5 - iter 1330/1331 - loss 0.10269526 - samples/sec: 130.44 - lr: 0.000030
2021-07-24 05:42:42,887 ----------------------------------------------------------------------------------------------------
2021-07-24 05:42:42,887 EPOCH 5 done: loss 0.1027 - lr 0.0000300
2021-07-24 05:42:57,259 DEV : loss 0.07288555800914764 - score 0.9795
2021-07-24 05:42:57,413 BAD EPOCHS (no improvement): 1
2021-07-24 05:42:57,414 ----------------------------------------------------------------------------------------------------
2021-07-24 05:43:29,709 epoch 6 - iter 133/1331 - loss 0.09110748 - samples/sec: 131.82 - lr: 0.000030
2021-07-24 05:44:02,194 epoch 6 - iter 266/1331 - loss 0.09447437 - samples/sec: 131.04 - lr: 0.000030
2021-07-24 05:44:35,172 epoch 6 - iter 399/1331 - loss 0.09467248 - samples/sec: 129.08 - lr: 0.000030
2021-07-24 05:45:07,472 epoch 6 - iter 532/1331 - loss 0.09678464 - samples/sec: 131.79 - lr: 0.000030
2021-07-24 05:45:39,712 epoch 6 - iter 665/1331 - loss 0.09501052 - samples/sec: 132.04 - lr: 0.000030
2021-07-24 05:46:12,145 epoch 6 - iter 798/1331 - loss 0.09701865 - samples/sec: 131.25 - lr: 0.000030
2021-07-24 05:46:44,676 epoch 6 - iter 931/1331 - loss 0.09834666 - samples/sec: 130.86 - lr: 0.000030
2021-07-24 05:47:17,119 epoch 6 - iter 1064/1331 - loss 0.09797639 - samples/sec: 131.21 - lr: 0.000030
2021-07-24 05:47:49,732 epoch 6 - iter 1197/1331 - loss 0.09623956 - samples/sec: 130.53 - lr: 0.000030
2021-07-24 05:48:22,445 epoch 6 - iter 1330/1331 - loss 0.09594259 - samples/sec: 130.13 - lr: 0.000030
2021-07-24 05:48:22,519 ----------------------------------------------------------------------------------------------------
2021-07-24 05:48:22,519 EPOCH 6 done: loss 0.0961 - lr 0.0000300
2021-07-24 05:48:38,382 DEV : loss 0.06850340962409973 - score 0.9808
2021-07-24 05:48:38,536 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:48:41,541 ----------------------------------------------------------------------------------------------------
2021-07-24 05:49:14,077 epoch 7 - iter 133/1331 - loss 0.08787058 - samples/sec: 130.85 - lr: 0.000030
2021-07-24 05:49:46,692 epoch 7 - iter 266/1331 - loss 0.09103829 - samples/sec: 130.52 - lr: 0.000030
2021-07-24 05:50:19,560 epoch 7 - iter 399/1331 - loss 0.08735813 - samples/sec: 129.51 - lr: 0.000030
2021-07-24 05:50:52,032 epoch 7 - iter 532/1331 - loss 0.08896354 - samples/sec: 131.09 - lr: 0.000030
2021-07-24 05:51:24,197 epoch 7 - iter 665/1331 - loss 0.08893858 - samples/sec: 132.34 - lr: 0.000030
2021-07-24 05:51:56,600 epoch 7 - iter 798/1331 - loss 0.08981310 - samples/sec: 131.37 - lr: 0.000030
2021-07-24 05:52:29,305 epoch 7 - iter 931/1331 - loss 0.08860104 - samples/sec: 130.16 - lr: 0.000030
2021-07-24 05:53:01,461 epoch 7 - iter 1064/1331 - loss 0.08764136 - samples/sec: 132.38 - lr: 0.000030
2021-07-24 05:53:33,936 epoch 7 - iter 1197/1331 - loss 0.08884855 - samples/sec: 131.08 - lr: 0.000030
2021-07-24 05:54:06,767 epoch 7 - iter 1330/1331 - loss 0.08930005 - samples/sec: 129.66 - lr: 0.000030
2021-07-24 05:54:06,815 ----------------------------------------------------------------------------------------------------
2021-07-24 05:54:06,815 EPOCH 7 done: loss 0.0892 - lr 0.0000300
2021-07-24 05:54:21,312 DEV : loss 0.07029623538255692 - score 0.9822
2021-07-24 05:54:21,467 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:54:24,604 ----------------------------------------------------------------------------------------------------
2021-07-24 05:54:56,962 epoch 8 - iter 133/1331 - loss 0.08237318 - samples/sec: 131.58 - lr: 0.000030
2021-07-24 05:55:29,387 epoch 8 - iter 266/1331 - loss 0.08750834 - samples/sec: 131.28 - lr: 0.000030
2021-07-24 05:56:01,725 epoch 8 - iter 399/1331 - loss 0.08575241 - samples/sec: 131.64 - lr: 0.000030
2021-07-24 05:56:34,009 epoch 8 - iter 532/1331 - loss 0.08324996 - samples/sec: 131.85 - lr: 0.000030
2021-07-24 05:57:06,913 epoch 8 - iter 665/1331 - loss 0.08382752 - samples/sec: 129.37 - lr: 0.000030
2021-07-24 05:57:38,997 epoch 8 - iter 798/1331 - loss 0.08515041 - samples/sec: 132.68 - lr: 0.000030
2021-07-24 05:58:11,296 epoch 8 - iter 931/1331 - loss 0.08568791 - samples/sec: 131.80 - lr: 0.000030
2021-07-24 05:58:43,756 epoch 8 - iter 1064/1331 - loss 0.08624145 - samples/sec: 131.14 - lr: 0.000030
2021-07-24 05:59:16,980 epoch 8 - iter 1197/1331 - loss 0.08659598 - samples/sec: 128.13 - lr: 0.000030
2021-07-24 05:59:49,772 epoch 8 - iter 1330/1331 - loss 0.08649426 - samples/sec: 129.81 - lr: 0.000030
2021-07-24 05:59:49,827 ----------------------------------------------------------------------------------------------------
2021-07-24 05:59:49,827 EPOCH 8 done: loss 0.0865 - lr 0.0000300
2021-07-24 06:00:04,319 DEV : loss 0.06649814546108246 - score 0.9804
2021-07-24 06:00:04,474 BAD EPOCHS (no improvement): 1
2021-07-24 06:00:04,475 ----------------------------------------------------------------------------------------------------
2021-07-24 06:00:36,835 epoch 9 - iter 133/1331 - loss 0.09016097 - samples/sec: 131.56 - lr: 0.000030
2021-07-24 06:01:09,580 epoch 9 - iter 266/1331 - loss 0.08996037 - samples/sec: 130.00 - lr: 0.000030
2021-07-24 06:01:42,098 epoch 9 - iter 399/1331 - loss 0.08890248 - samples/sec: 130.91 - lr: 0.000030
2021-07-24 06:02:14,940 epoch 9 - iter 532/1331 - loss 0.08857493 - samples/sec: 129.62 - lr: 0.000030
2021-07-24 06:02:47,215 epoch 9 - iter 665/1331 - loss 0.08593637 - samples/sec: 131.89 - lr: 0.000030
2021-07-24 06:03:19,888 epoch 9 - iter 798/1331 - loss 0.08702784 - samples/sec: 130.28 - lr: 0.000030
2021-07-24 06:03:52,348 epoch 9 - iter 931/1331 - loss 0.08633797 - samples/sec: 131.14 - lr: 0.000030
2021-07-24 06:04:25,147 epoch 9 - iter 1064/1331 - loss 0.08572119 - samples/sec: 129.79 - lr: 0.000030
2021-07-24 06:04:57,493 epoch 9 - iter 1197/1331 - loss 0.08514549 - samples/sec: 131.60 - lr: 0.000030
2021-07-24 06:05:30,088 epoch 9 - iter 1330/1331 - loss 0.08375575 - samples/sec: 130.60 - lr: 0.000030
2021-07-24 06:05:30,119 ----------------------------------------------------------------------------------------------------
2021-07-24 06:05:30,119 EPOCH 9 done: loss 0.0837 - lr 0.0000300
2021-07-24 06:05:44,638 DEV : loss 0.0706707164645195 - score 0.9819
2021-07-24 06:05:44,792 BAD EPOCHS (no improvement): 2
2021-07-24 06:05:44,792 ----------------------------------------------------------------------------------------------------
2021-07-24 06:06:17,240 epoch 10 - iter 133/1331 - loss 0.08946772 - samples/sec: 131.20 - lr: 0.000030
2021-07-24 06:06:49,955 epoch 10 - iter 266/1331 - loss 0.08038810 - samples/sec: 130.12 - lr: 0.000030
2021-07-24 06:07:22,205 epoch 10 - iter 399/1331 - loss 0.07822587 - samples/sec: 132.00 - lr: 0.000030
2021-07-24 06:07:54,619 epoch 10 - iter 532/1331 - loss 0.08103528 - samples/sec: 131.33 - lr: 0.000030
2021-07-24 06:08:26,736 epoch 10 - iter 665/1331 - loss 0.08291299 - samples/sec: 132.54 - lr: 0.000030
2021-07-24 06:08:59,438 epoch 10 - iter 798/1331 - loss 0.08155054 - samples/sec: 130.17 - lr: 0.000030
2021-07-24 06:09:32,275 epoch 10 - iter 931/1331 - loss 0.08211609 - samples/sec: 129.63 - lr: 0.000030
2021-07-24 06:10:04,880 epoch 10 - iter 1064/1331 - loss 0.08070322 - samples/sec: 130.56 - lr: 0.000030
2021-07-24 06:10:37,425 epoch 10 - iter 1197/1331 - loss 0.08037886 - samples/sec: 130.80 - lr: 0.000030
2021-07-24 06:11:09,560 epoch 10 - iter 1330/1331 - loss 0.08057518 - samples/sec: 132.47 - lr: 0.000030
2021-07-24 06:11:09,610 ----------------------------------------------------------------------------------------------------
2021-07-24 06:11:09,610 EPOCH 10 done: loss 0.0805 - lr 0.0000300
2021-07-24 06:11:24,103 DEV : loss 0.06741765141487122 - score 0.9826
2021-07-24 06:11:24,259 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:11:27,349 ----------------------------------------------------------------------------------------------------
2021-07-24 06:12:01,271 epoch 11 - iter 133/1331 - loss 0.08108307 - samples/sec: 125.51 - lr: 0.000030
2021-07-24 06:12:33,735 epoch 11 - iter 266/1331 - loss 0.07937155 - samples/sec: 131.12 - lr: 0.000030
2021-07-24 06:13:06,192 epoch 11 - iter 399/1331 - loss 0.07842322 - samples/sec: 131.16 - lr: 0.000030
2021-07-24 06:13:38,188 epoch 11 - iter 532/1331 - loss 0.07624767 - samples/sec: 133.04 - lr: 0.000030
2021-07-24 06:14:10,240 epoch 11 - iter 665/1331 - loss 0.07891901 - samples/sec: 132.81 - lr: 0.000030
2021-07-24 06:14:42,524 epoch 11 - iter 798/1331 - loss 0.07761554 - samples/sec: 131.86 - lr: 0.000030
2021-07-24 06:15:15,056 epoch 11 - iter 931/1331 - loss 0.07723205 - samples/sec: 130.85 - lr: 0.000030
2021-07-24 06:15:47,924 epoch 11 - iter 1064/1331 - loss 0.07769996 - samples/sec: 129.51 - lr: 0.000030
2021-07-24 06:16:20,584 epoch 11 - iter 1197/1331 - loss 0.07782024 - samples/sec: 130.34 - lr: 0.000030
2021-07-24 06:16:53,233 epoch 11 - iter 1330/1331 - loss 0.07669586 - samples/sec: 130.38 - lr: 0.000030
2021-07-24 06:16:53,291 ----------------------------------------------------------------------------------------------------
2021-07-24 06:16:53,291 EPOCH 11 done: loss 0.0767 - lr 0.0000300
2021-07-24 06:17:07,825 DEV : loss 0.06366676092147827 - score 0.9824
2021-07-24 06:17:07,981 BAD EPOCHS (no improvement): 1
2021-07-24 06:17:07,981 ----------------------------------------------------------------------------------------------------
2021-07-24 06:17:40,417 epoch 12 - iter 133/1331 - loss 0.07039005 - samples/sec: 131.25 - lr: 0.000030
2021-07-24 06:18:12,640 epoch 12 - iter 266/1331 - loss 0.07419461 - samples/sec: 132.10 - lr: 0.000030
2021-07-24 06:18:45,339 epoch 12 - iter 399/1331 - loss 0.07429873 - samples/sec: 130.18 - lr: 0.000030
2021-07-24 06:19:17,780 epoch 12 - iter 532/1331 - loss 0.07650474 - samples/sec: 131.22 - lr: 0.000030
2021-07-24 06:19:49,864 epoch 12 - iter 665/1331 - loss 0.07757630 - samples/sec: 132.68 - lr: 0.000030
2021-07-24 06:20:22,436 epoch 12 - iter 798/1331 - loss 0.07816984 - samples/sec: 130.69 - lr: 0.000030
2021-07-24 06:20:54,866 epoch 12 - iter 931/1331 - loss 0.07838776 - samples/sec: 131.27 - lr: 0.000030
2021-07-24 06:21:27,192 epoch 12 - iter 1064/1331 - loss 0.07784667 - samples/sec: 131.69 - lr: 0.000030
2021-07-24 06:22:00,033 epoch 12 - iter 1197/1331 - loss 0.07822786 - samples/sec: 129.62 - lr: 0.000030
2021-07-24 06:22:32,355 epoch 12 - iter 1330/1331 - loss 0.07719986 - samples/sec: 131.70 - lr: 0.000030
2021-07-24 06:22:32,432 ----------------------------------------------------------------------------------------------------
2021-07-24 06:22:32,432 EPOCH 12 done: loss 0.0771 - lr 0.0000300
2021-07-24 06:22:46,904 DEV : loss 0.0625695288181305 - score 0.9821
2021-07-24 06:22:47,058 BAD EPOCHS (no improvement): 2
2021-07-24 06:22:47,059 ----------------------------------------------------------------------------------------------------
2021-07-24 06:23:19,684 epoch 13 - iter 133/1331 - loss 0.07408802 - samples/sec: 130.49 - lr: 0.000030
2021-07-24 06:23:52,248 epoch 13 - iter 266/1331 - loss 0.07395007 - samples/sec: 130.72 - lr: 0.000030
2021-07-24 06:24:25,287 epoch 13 - iter 399/1331 - loss 0.07584469 - samples/sec: 128.84 - lr: 0.000030
2021-07-24 06:24:57,646 epoch 13 - iter 532/1331 - loss 0.07338217 - samples/sec: 131.55 - lr: 0.000030
2021-07-24 06:25:30,432 epoch 13 - iter 665/1331 - loss 0.07275650 - samples/sec: 129.84 - lr: 0.000030
2021-07-24 06:26:03,184 epoch 13 - iter 798/1331 - loss 0.07526022 - samples/sec: 129.97 - lr: 0.000030
2021-07-24 06:26:36,192 epoch 13 - iter 931/1331 - loss 0.07607602 - samples/sec: 128.96 - lr: 0.000030
2021-07-24 06:27:08,621 epoch 13 - iter 1064/1331 - loss 0.07499783 - samples/sec: 131.27 - lr: 0.000030
2021-07-24 06:27:41,020 epoch 13 - iter 1197/1331 - loss 0.07456142 - samples/sec: 131.39 - lr: 0.000030
2021-07-24 06:28:13,312 epoch 13 - iter 1330/1331 - loss 0.07429448 - samples/sec: 131.83 - lr: 0.000030
2021-07-24 06:28:13,379 ----------------------------------------------------------------------------------------------------
2021-07-24 06:28:13,379 EPOCH 13 done: loss 0.0742 - lr 0.0000300
2021-07-24 06:28:27,863 DEV : loss 0.06164713576436043 - score 0.9837
2021-07-24 06:28:28,023 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:28:34,469 ----------------------------------------------------------------------------------------------------
2021-07-24 06:29:07,001 epoch 14 - iter 133/1331 - loss 0.06624362 - samples/sec: 130.87 - lr: 0.000030
2021-07-24 06:29:39,587 epoch 14 - iter 266/1331 - loss 0.07126865 - samples/sec: 130.63 - lr: 0.000030
2021-07-24 06:30:12,455 epoch 14 - iter 399/1331 - loss 0.07353825 - samples/sec: 129.52 - lr: 0.000030
2021-07-24 06:30:44,990 epoch 14 - iter 532/1331 - loss 0.07346270 - samples/sec: 130.84 - lr: 0.000030
2021-07-24 06:31:17,313 epoch 14 - iter 665/1331 - loss 0.07428780 - samples/sec: 131.70 - lr: 0.000030
2021-07-24 06:31:49,808 epoch 14 - iter 798/1331 - loss 0.07337153 - samples/sec: 131.00 - lr: 0.000030
2021-07-24 06:32:21,933 epoch 14 - iter 931/1331 - loss 0.07241547 - samples/sec: 132.51 - lr: 0.000030
2021-07-24 06:32:54,694 epoch 14 - iter 1064/1331 - loss 0.07249842 - samples/sec: 129.94 - lr: 0.000030
2021-07-24 06:33:27,580 epoch 14 - iter 1197/1331 - loss 0.07213316 - samples/sec: 129.44 - lr: 0.000030
2021-07-24 06:34:00,036 epoch 14 - iter 1330/1331 - loss 0.07241625 - samples/sec: 131.16 - lr: 0.000030
2021-07-24 06:34:00,103 ----------------------------------------------------------------------------------------------------
2021-07-24 06:34:00,103 EPOCH 14 done: loss 0.0724 - lr 0.0000300
2021-07-24 06:34:14,567 DEV : loss 0.0652511939406395 - score 0.9813
2021-07-24 06:34:14,722 BAD EPOCHS (no improvement): 1
2021-07-24 06:34:14,723 ----------------------------------------------------------------------------------------------------
2021-07-24 06:34:47,679 epoch 15 - iter 133/1331 - loss 0.07120337 - samples/sec: 129.18 - lr: 0.000030
2021-07-24 06:35:20,933 epoch 15 - iter 266/1331 - loss 0.07167763 - samples/sec: 128.01 - lr: 0.000030
2021-07-24 06:35:53,257 epoch 15 - iter 399/1331 - loss 0.07055774 - samples/sec: 131.69 - lr: 0.000030
2021-07-24 06:36:25,951 epoch 15 - iter 532/1331 - loss 0.07186153 - samples/sec: 130.20 - lr: 0.000030
2021-07-24 06:36:58,179 epoch 15 - iter 665/1331 - loss 0.07237325 - samples/sec: 132.09 - lr: 0.000030
2021-07-24 06:37:30,479 epoch 15 - iter 798/1331 - loss 0.07206477 - samples/sec: 131.79 - lr: 0.000030
2021-07-24 06:38:03,132 epoch 15 - iter 931/1331 - loss 0.07182223 - samples/sec: 130.37 - lr: 0.000030
2021-07-24 06:38:35,139 epoch 15 - iter 1064/1331 - loss 0.07115939 - samples/sec: 133.00 - lr: 0.000030
2021-07-24 06:39:07,528 epoch 15 - iter 1197/1331 - loss 0.07104746 - samples/sec: 131.43 - lr: 0.000030
2021-07-24 06:39:39,556 epoch 15 - iter 1330/1331 - loss 0.07061229 - samples/sec: 132.91 - lr: 0.000030
2021-07-24 06:39:39,625 ----------------------------------------------------------------------------------------------------
2021-07-24 06:39:39,625 EPOCH 15 done: loss 0.0706 - lr 0.0000300
2021-07-24 06:39:55,529 DEV : loss 0.06319597363471985 - score 0.9837
2021-07-24 06:39:55,685 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:39:58,965 ----------------------------------------------------------------------------------------------------
2021-07-24 06:40:30,939 epoch 16 - iter 133/1331 - loss 0.06470949 - samples/sec: 133.15 - lr: 0.000030
2021-07-24 06:41:03,700 epoch 16 - iter 266/1331 - loss 0.06636806 - samples/sec: 129.94 - lr: 0.000030
2021-07-24 06:41:36,169 epoch 16 - iter 399/1331 - loss 0.06637142 - samples/sec: 131.11 - lr: 0.000030
2021-07-24 06:42:08,634 epoch 16 - iter 532/1331 - loss 0.06748875 - samples/sec: 131.12 - lr: 0.000030
2021-07-24 06:42:41,060 epoch 16 - iter 665/1331 - loss 0.06661183 - samples/sec: 131.28 - lr: 0.000030
2021-07-24 06:43:14,223 epoch 16 - iter 798/1331 - loss 0.06808087 - samples/sec: 128.36 - lr: 0.000030
2021-07-24 06:43:46,040 epoch 16 - iter 931/1331 - loss 0.06725823 - samples/sec: 133.79 - lr: 0.000030
2021-07-24 06:44:18,784 epoch 16 - iter 1064/1331 - loss 0.06851024 - samples/sec: 130.00 - lr: 0.000030
2021-07-24 06:44:51,487 epoch 16 - iter 1197/1331 - loss 0.06859968 - samples/sec: 130.17 - lr: 0.000030
2021-07-24 06:45:23,857 epoch 16 - iter 1330/1331 - loss 0.06819607 - samples/sec: 131.51 - lr: 0.000030
2021-07-24 06:45:23,895 ----------------------------------------------------------------------------------------------------
2021-07-24 06:45:23,895 EPOCH 16 done: loss 0.0681 - lr 0.0000300
2021-07-24 06:45:38,384 DEV : loss 0.062138572335243225 - score 0.9818
2021-07-24 06:45:38,540 BAD EPOCHS (no improvement): 1
2021-07-24 06:45:38,540 ----------------------------------------------------------------------------------------------------
2021-07-24 06:46:10,368 epoch 17 - iter 133/1331 - loss 0.07054940 - samples/sec: 133.76 - lr: 0.000030
2021-07-24 06:46:43,004 epoch 17 - iter 266/1331 - loss 0.06588433 - samples/sec: 130.44 - lr: 0.000030
2021-07-24 06:47:15,689 epoch 17 - iter 399/1331 - loss 0.06917867 - samples/sec: 130.24 - lr: 0.000030
2021-07-24 06:47:48,216 epoch 17 - iter 532/1331 - loss 0.06780985 - samples/sec: 130.87 - lr: 0.000030
2021-07-24 06:48:21,140 epoch 17 - iter 665/1331 - loss 0.06821653 - samples/sec: 129.29 - lr: 0.000030
2021-07-24 06:48:53,144 epoch 17 - iter 798/1331 - loss 0.06796860 - samples/sec: 133.01 - lr: 0.000030
2021-07-24 06:49:25,324 epoch 17 - iter 931/1331 - loss 0.06782556 - samples/sec: 132.29 - lr: 0.000030
2021-07-24 06:49:57,738 epoch 17 - iter 1064/1331 - loss 0.06836200 - samples/sec: 131.33 - lr: 0.000030
2021-07-24 06:50:30,477 epoch 17 - iter 1197/1331 - loss 0.06830371 - samples/sec: 130.02 - lr: 0.000030
2021-07-24 06:51:03,337 epoch 17 - iter 1330/1331 - loss 0.06877984 - samples/sec: 129.54 - lr: 0.000030
2021-07-24 06:51:03,382 ----------------------------------------------------------------------------------------------------
2021-07-24 06:51:03,382 EPOCH 17 done: loss 0.0687 - lr 0.0000300
2021-07-24 06:51:17,947 DEV : loss 0.0659569799900055 - score 0.9808
2021-07-24 06:51:18,105 BAD EPOCHS (no improvement): 2
2021-07-24 06:51:18,105 ----------------------------------------------------------------------------------------------------
2021-07-24 06:51:50,119 epoch 18 - iter 133/1331 - loss 0.06161136 - samples/sec: 132.98 - lr: 0.000030
2021-07-24 06:52:22,239 epoch 18 - iter 266/1331 - loss 0.06634461 - samples/sec: 132.53 - lr: 0.000030
2021-07-24 06:52:54,840 epoch 18 - iter 399/1331 - loss 0.06812402 - samples/sec: 130.57 - lr: 0.000030
2021-07-24 06:53:27,412 epoch 18 - iter 532/1331 - loss 0.06787906 - samples/sec: 130.69 - lr: 0.000030
2021-07-24 06:53:59,737 epoch 18 - iter 665/1331 - loss 0.06833287 - samples/sec: 131.69 - lr: 0.000030
2021-07-24 06:54:32,399 epoch 18 - iter 798/1331 - loss 0.06704297 - samples/sec: 130.33 - lr: 0.000030
2021-07-24 06:55:05,104 epoch 18 - iter 931/1331 - loss 0.06738754 - samples/sec: 130.16 - lr: 0.000030
2021-07-24 06:55:37,708 epoch 18 - iter 1064/1331 - loss 0.06833668 - samples/sec: 130.56 - lr: 0.000030
2021-07-24 06:56:10,260 epoch 18 - iter 1197/1331 - loss 0.06787100 - samples/sec: 130.77 - lr: 0.000030
2021-07-24 06:56:42,531 epoch 18 - iter 1330/1331 - loss 0.06753470 - samples/sec: 131.91 - lr: 0.000030
2021-07-24 06:56:42,587 ----------------------------------------------------------------------------------------------------
2021-07-24 06:56:42,587 EPOCH 18 done: loss 0.0675 - lr 0.0000300
2021-07-24 06:56:57,097 DEV : loss 0.06106735020875931 - score 0.9835
2021-07-24 06:56:57,253 BAD EPOCHS (no improvement): 3
2021-07-24 06:56:57,253 ----------------------------------------------------------------------------------------------------
2021-07-24 06:57:29,920 epoch 19 - iter 133/1331 - loss 0.06303040 - samples/sec: 130.32 - lr: 0.000030
2021-07-24 06:58:02,453 epoch 19 - iter 266/1331 - loss 0.06312209 - samples/sec: 130.85 - lr: 0.000030
2021-07-24 06:58:34,828 epoch 19 - iter 399/1331 - loss 0.06602805 - samples/sec: 131.48 - lr: 0.000030
2021-07-24 06:59:07,836 epoch 19 - iter 532/1331 - loss 0.06602160 - samples/sec: 128.96 - lr: 0.000030
2021-07-24 06:59:40,114 epoch 19 - iter 665/1331 - loss 0.06659826 - samples/sec: 131.88 - lr: 0.000030
2021-07-24 07:00:12,635 epoch 19 - iter 798/1331 - loss 0.06532846 - samples/sec: 130.90 - lr: 0.000030
2021-07-24 07:00:45,123 epoch 19 - iter 931/1331 - loss 0.06491273 - samples/sec: 131.03 - lr: 0.000030
2021-07-24 07:01:17,940 epoch 19 - iter 1064/1331 - loss 0.06466302 - samples/sec: 129.71 - lr: 0.000030
2021-07-24 07:01:49,812 epoch 19 - iter 1197/1331 - loss 0.06453321 - samples/sec: 133.56 - lr: 0.000030
2021-07-24 07:02:22,125 epoch 19 - iter 1330/1331 - loss 0.06428076 - samples/sec: 131.74 - lr: 0.000030
2021-07-24 07:02:22,157 ----------------------------------------------------------------------------------------------------
2021-07-24 07:02:22,157 EPOCH 19 done: loss 0.0642 - lr 0.0000300
2021-07-24 07:02:38,076 DEV : loss 0.06115790084004402 - score 0.9838
2021-07-24 07:02:38,229 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:02:40,990 ----------------------------------------------------------------------------------------------------
2021-07-24 07:03:13,435 epoch 20 - iter 133/1331 - loss 0.07286139 - samples/sec: 131.22 - lr: 0.000030
2021-07-24 07:03:45,712 epoch 20 - iter 266/1331 - loss 0.06679404 - samples/sec: 131.88 - lr: 0.000030
2021-07-24 07:04:17,961 epoch 20 - iter 399/1331 - loss 0.06592189 - samples/sec: 132.00 - lr: 0.000030
2021-07-24 07:04:51,015 epoch 20 - iter 532/1331 - loss 0.06362938 - samples/sec: 128.78 - lr: 0.000030
2021-07-24 07:05:23,149 epoch 20 - iter 665/1331 - loss 0.06108310 - samples/sec: 132.47 - lr: 0.000030
2021-07-24 07:05:55,647 epoch 20 - iter 798/1331 - loss 0.06259571 - samples/sec: 130.99 - lr: 0.000030
2021-07-24 07:06:28,671 epoch 20 - iter 931/1331 - loss 0.06433795 - samples/sec: 128.90 - lr: 0.000030
2021-07-24 07:07:01,263 epoch 20 - iter 1064/1331 - loss 0.06434078 - samples/sec: 130.61 - lr: 0.000030
2021-07-24 07:07:33,293 epoch 20 - iter 1197/1331 - loss 0.06515100 - samples/sec: 132.90 - lr: 0.000030
2021-07-24 07:08:06,181 epoch 20 - iter 1330/1331 - loss 0.06495052 - samples/sec: 129.44 - lr: 0.000030
2021-07-24 07:08:06,243 ----------------------------------------------------------------------------------------------------
2021-07-24 07:08:06,243 EPOCH 20 done: loss 0.0649 - lr 0.0000300
2021-07-24 07:08:20,786 DEV : loss 0.06036626547574997 - score 0.9835
2021-07-24 07:08:20,940 BAD EPOCHS (no improvement): 1
2021-07-24 07:08:20,941 ----------------------------------------------------------------------------------------------------
2021-07-24 07:08:53,248 epoch 21 - iter 133/1331 - loss 0.05306390 - samples/sec: 131.77 - lr: 0.000030
2021-07-24 07:09:25,682 epoch 21 - iter 266/1331 - loss 0.05407065 - samples/sec: 131.25 - lr: 0.000030
2021-07-24 07:09:57,992 epoch 21 - iter 399/1331 - loss 0.05772541 - samples/sec: 131.75 - lr: 0.000030
2021-07-24 07:10:30,382 epoch 21 - iter 532/1331 - loss 0.05810970 - samples/sec: 131.43 - lr: 0.000030
2021-07-24 07:11:03,484 epoch 21 - iter 665/1331 - loss 0.05943838 - samples/sec: 128.60 - lr: 0.000030
2021-07-24 07:11:36,160 epoch 21 - iter 798/1331 - loss 0.06080504 - samples/sec: 130.27 - lr: 0.000030
2021-07-24 07:12:08,727 epoch 21 - iter 931/1331 - loss 0.06001756 - samples/sec: 130.71 - lr: 0.000030
2021-07-24 07:12:41,231 epoch 21 - iter 1064/1331 - loss 0.06074409 - samples/sec: 130.96 - lr: 0.000030
2021-07-24 07:13:13,665 epoch 21 - iter 1197/1331 - loss 0.06060356 - samples/sec: 131.25 - lr: 0.000030
2021-07-24 07:13:46,541 epoch 21 - iter 1330/1331 - loss 0.06060088 - samples/sec: 129.48 - lr: 0.000030
2021-07-24 07:13:46,575 ----------------------------------------------------------------------------------------------------
2021-07-24 07:13:46,576 EPOCH 21 done: loss 0.0606 - lr 0.0000300
2021-07-24 07:14:01,151 DEV : loss 0.06414980441331863 - score 0.9805
2021-07-24 07:14:01,305 BAD EPOCHS (no improvement): 2
2021-07-24 07:14:01,305 ----------------------------------------------------------------------------------------------------
2021-07-24 07:14:33,816 epoch 22 - iter 133/1331 - loss 0.05737441 - samples/sec: 130.95 - lr: 0.000030
2021-07-24 07:15:06,064 epoch 22 - iter 266/1331 - loss 0.06118965 - samples/sec: 132.00 - lr: 0.000030
2021-07-24 07:15:38,568 epoch 22 - iter 399/1331 - loss 0.06076401 - samples/sec: 130.96 - lr: 0.000030
2021-07-24 07:16:11,075 epoch 22 - iter 532/1331 - loss 0.06027585 - samples/sec: 130.95 - lr: 0.000030
2021-07-24 07:16:43,208 epoch 22 - iter 665/1331 - loss 0.05952428 - samples/sec: 132.48 - lr: 0.000030
2021-07-24 07:17:15,844 epoch 22 - iter 798/1331 - loss 0.06092642 - samples/sec: 130.44 - lr: 0.000030
2021-07-24 07:17:48,655 epoch 22 - iter 931/1331 - loss 0.06053378 - samples/sec: 129.74 - lr: 0.000030
2021-07-24 07:18:21,181 epoch 22 - iter 1064/1331 - loss 0.06080411 - samples/sec: 130.88 - lr: 0.000030
2021-07-24 07:18:53,771 epoch 22 - iter 1197/1331 - loss 0.05998318 - samples/sec: 130.62 - lr: 0.000030
2021-07-24 07:19:26,051 epoch 22 - iter 1330/1331 - loss 0.06152879 - samples/sec: 131.87 - lr: 0.000030
2021-07-24 07:19:26,082 ----------------------------------------------------------------------------------------------------
2021-07-24 07:19:26,082 EPOCH 22 done: loss 0.0615 - lr 0.0000300
2021-07-24 07:19:40,678 DEV : loss 0.061328332871198654 - score 0.9828
2021-07-24 07:19:40,836 BAD EPOCHS (no improvement): 3
2021-07-24 07:19:40,836 ----------------------------------------------------------------------------------------------------
2021-07-24 07:20:13,409 epoch 23 - iter 133/1331 - loss 0.06229640 - samples/sec: 130.70 - lr: 0.000030
2021-07-24 07:20:45,864 epoch 23 - iter 266/1331 - loss 0.06209469 - samples/sec: 131.16 - lr: 0.000030
2021-07-24 07:21:18,570 epoch 23 - iter 399/1331 - loss 0.06131362 - samples/sec: 130.16 - lr: 0.000030
2021-07-24 07:21:51,180 epoch 23 - iter 532/1331 - loss 0.06329913 - samples/sec: 130.54 - lr: 0.000030
2021-07-24 07:22:23,923 epoch 23 - iter 665/1331 - loss 0.06168013 - samples/sec: 130.01 - lr: 0.000030
2021-07-24 07:22:56,259 epoch 23 - iter 798/1331 - loss 0.06123989 - samples/sec: 131.64 - lr: 0.000030
2021-07-24 07:23:28,592 epoch 23 - iter 931/1331 - loss 0.06138220 - samples/sec: 131.66 - lr: 0.000030
2021-07-24 07:24:01,175 epoch 23 - iter 1064/1331 - loss 0.06018985 - samples/sec: 130.64 - lr: 0.000030
2021-07-24 07:24:33,619 epoch 23 - iter 1197/1331 - loss 0.05886443 - samples/sec: 131.21 - lr: 0.000030
2021-07-24 07:25:06,236 epoch 23 - iter 1330/1331 - loss 0.05860441 - samples/sec: 130.51 - lr: 0.000030
2021-07-24 07:25:06,298 ----------------------------------------------------------------------------------------------------
2021-07-24 07:25:06,298 EPOCH 23 done: loss 0.0595 - lr 0.0000300
2021-07-24 07:25:20,908 DEV : loss 0.0597628578543663 - score 0.9843
2021-07-24 07:25:21,066 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:25:23,858 ----------------------------------------------------------------------------------------------------
2021-07-24 07:25:56,556 epoch 24 - iter 133/1331 - loss 0.05893857 - samples/sec: 130.21 - lr: 0.000030
2021-07-24 07:26:29,045 epoch 24 - iter 266/1331 - loss 0.05709388 - samples/sec: 131.03 - lr: 0.000030
2021-07-24 07:27:01,494 epoch 24 - iter 399/1331 - loss 0.05810991 - samples/sec: 131.19 - lr: 0.000030
2021-07-24 07:27:34,104 epoch 24 - iter 532/1331 - loss 0.05834911 - samples/sec: 130.54 - lr: 0.000030
2021-07-24 07:28:06,799 epoch 24 - iter 665/1331 - loss 0.05898580 - samples/sec: 130.20 - lr: 0.000030
2021-07-24 07:28:39,113 epoch 24 - iter 798/1331 - loss 0.05906019 - samples/sec: 131.73 - lr: 0.000030
2021-07-24 07:29:11,764 epoch 24 - iter 931/1331 - loss 0.05874282 - samples/sec: 130.37 - lr: 0.000030
2021-07-24 07:29:44,513 epoch 24 - iter 1064/1331 - loss 0.05843313 - samples/sec: 129.98 - lr: 0.000030
2021-07-24 07:30:16,936 epoch 24 - iter 1197/1331 - loss 0.05808675 - samples/sec: 131.29 - lr: 0.000030
2021-07-24 07:30:49,640 epoch 24 - iter 1330/1331 - loss 0.05755534 - samples/sec: 130.16 - lr: 0.000030
2021-07-24 07:30:49,694 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:49,694 EPOCH 24 done: loss 0.0575 - lr 0.0000300
2021-07-24 07:31:05,656 DEV : loss 0.06016830727458 - score 0.9846
2021-07-24 07:31:05,811 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:31:08,537 ----------------------------------------------------------------------------------------------------
2021-07-24 07:31:41,209 epoch 25 - iter 133/1331 - loss 0.05464363 - samples/sec: 130.31 - lr: 0.000030
2021-07-24 07:32:13,673 epoch 25 - iter 266/1331 - loss 0.05504155 - samples/sec: 131.12 - lr: 0.000030
2021-07-24 07:32:46,644 epoch 25 - iter 399/1331 - loss 0.05562047 - samples/sec: 129.11 - lr: 0.000030
2021-07-24 07:33:19,037 epoch 25 - iter 532/1331 - loss 0.05744226 - samples/sec: 131.42 - lr: 0.000030
2021-07-24 07:33:51,081 epoch 25 - iter 665/1331 - loss 0.05880896 - samples/sec: 132.85 - lr: 0.000030
2021-07-24 07:34:23,680 epoch 25 - iter 798/1331 - loss 0.05844363 - samples/sec: 130.58 - lr: 0.000030
2021-07-24 07:34:56,020 epoch 25 - iter 931/1331 - loss 0.05810882 - samples/sec: 131.63 - lr: 0.000030
2021-07-24 07:35:28,693 epoch 25 - iter 1064/1331 - loss 0.05740412 - samples/sec: 130.29 - lr: 0.000030
2021-07-24 07:36:01,336 epoch 25 - iter 1197/1331 - loss 0.05818579 - samples/sec: 130.40 - lr: 0.000030
2021-07-24 07:36:33,583 epoch 25 - iter 1330/1331 - loss 0.05826891 - samples/sec: 132.01 - lr: 0.000030
2021-07-24 07:36:33,613 ----------------------------------------------------------------------------------------------------
2021-07-24 07:36:33,613 EPOCH 25 done: loss 0.0582 - lr 0.0000300
2021-07-24 07:36:48,204 DEV : loss 0.05972092226147652 - score 0.985
2021-07-24 07:36:48,360 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:36:51,170 ----------------------------------------------------------------------------------------------------
2021-07-24 07:37:24,031 epoch 26 - iter 133/1331 - loss 0.05370072 - samples/sec: 129.56 - lr: 0.000030
2021-07-24 07:37:56,733 epoch 26 - iter 266/1331 - loss 0.05200573 - samples/sec: 130.17 - lr: 0.000030
2021-07-24 07:38:28,991 epoch 26 - iter 399/1331 - loss 0.05072908 - samples/sec: 131.97 - lr: 0.000030
2021-07-24 07:39:01,356 epoch 26 - iter 532/1331 - loss 0.05165126 - samples/sec: 131.53 - lr: 0.000030
2021-07-24 07:39:34,265 epoch 26 - iter 665/1331 - loss 0.05225049 - samples/sec: 129.35 - lr: 0.000030
2021-07-24 07:40:06,920 epoch 26 - iter 798/1331 - loss 0.05263757 - samples/sec: 130.36 - lr: 0.000030
2021-07-24 07:40:39,459 epoch 26 - iter 931/1331 - loss 0.05422289 - samples/sec: 130.82 - lr: 0.000030
2021-07-24 07:41:11,768 epoch 26 - iter 1064/1331 - loss 0.05404777 - samples/sec: 131.76 - lr: 0.000030
2021-07-24 07:41:43,744 epoch 26 - iter 1197/1331 - loss 0.05407178 - samples/sec: 133.12 - lr: 0.000030
2021-07-24 07:42:16,393 epoch 26 - iter 1330/1331 - loss 0.05422093 - samples/sec: 130.39 - lr: 0.000030
2021-07-24 07:42:16,439 ----------------------------------------------------------------------------------------------------
2021-07-24 07:42:16,439 EPOCH 26 done: loss 0.0542 - lr 0.0000300
2021-07-24 07:42:31,031 DEV : loss 0.06214706227183342 - score 0.984
2021-07-24 07:42:31,188 BAD EPOCHS (no improvement): 1
2021-07-24 07:42:31,188 ----------------------------------------------------------------------------------------------------
2021-07-24 07:43:03,461 epoch 27 - iter 133/1331 - loss 0.05103531 - samples/sec: 131.92 - lr: 0.000030
2021-07-24 07:43:36,253 epoch 27 - iter 266/1331 - loss 0.05317168 - samples/sec: 129.81 - lr: 0.000030
2021-07-24 07:44:09,100 epoch 27 - iter 399/1331 - loss 0.05352410 - samples/sec: 129.59 - lr: 0.000030
2021-07-24 07:44:41,543 epoch 27 - iter 532/1331 - loss 0.05375770 - samples/sec: 131.21 - lr: 0.000030
2021-07-24 07:45:13,655 epoch 27 - iter 665/1331 - loss 0.05426454 - samples/sec: 132.57 - lr: 0.000030
2021-07-24 07:45:46,351 epoch 27 - iter 798/1331 - loss 0.05503570 - samples/sec: 130.19 - lr: 0.000030
2021-07-24 07:46:19,293 epoch 27 - iter 931/1331 - loss 0.05485512 - samples/sec: 129.22 - lr: 0.000030
2021-07-24 07:46:51,647 epoch 27 - iter 1064/1331 - loss 0.05619290 - samples/sec: 131.57 - lr: 0.000030
2021-07-24 07:47:24,232 epoch 27 - iter 1197/1331 - loss 0.05571660 - samples/sec: 130.64 - lr: 0.000030
2021-07-24 07:47:56,797 epoch 27 - iter 1330/1331 - loss 0.05518808 - samples/sec: 130.72 - lr: 0.000030
2021-07-24 07:47:56,832 ----------------------------------------------------------------------------------------------------
2021-07-24 07:47:56,832 EPOCH 27 done: loss 0.0551 - lr 0.0000300
2021-07-24 07:48:11,434 DEV : loss 0.06250502914190292 - score 0.9838
2021-07-24 07:48:11,591 BAD EPOCHS (no improvement): 2
2021-07-24 07:48:11,591 ----------------------------------------------------------------------------------------------------
2021-07-24 07:48:44,156 epoch 28 - iter 133/1331 - loss 0.05697104 - samples/sec: 130.73 - lr: 0.000030
2021-07-24 07:49:17,144 epoch 28 - iter 266/1331 - loss 0.05494909 - samples/sec: 129.04 - lr: 0.000030
2021-07-24 07:49:49,671 epoch 28 - iter 399/1331 - loss 0.05505041 - samples/sec: 130.87 - lr: 0.000030
2021-07-24 07:50:21,531 epoch 28 - iter 532/1331 - loss 0.05348852 - samples/sec: 133.61 - lr: 0.000030
2021-07-24 07:50:54,381 epoch 28 - iter 665/1331 - loss 0.05247630 - samples/sec: 129.58 - lr: 0.000030
2021-07-24 07:51:27,240 epoch 28 - iter 798/1331 - loss 0.05213327 - samples/sec: 129.55 - lr: 0.000030
2021-07-24 07:51:59,619 epoch 28 - iter 931/1331 - loss 0.05169235 - samples/sec: 131.47 - lr: 0.000030
2021-07-24 07:52:32,067 epoch 28 - iter 1064/1331 - loss 0.05243718 - samples/sec: 131.19 - lr: 0.000030
2021-07-24 07:53:04,429 epoch 28 - iter 1197/1331 - loss 0.05250204 - samples/sec: 131.54 - lr: 0.000030
2021-07-24 07:53:37,465 epoch 28 - iter 1330/1331 - loss 0.05252474 - samples/sec: 128.86 - lr: 0.000030
2021-07-24 07:53:37,509 ----------------------------------------------------------------------------------------------------
2021-07-24 07:53:37,509 EPOCH 28 done: loss 0.0525 - lr 0.0000300
2021-07-24 07:53:53,756 DEV : loss 0.06173889338970184 - score 0.9837
2021-07-24 07:53:53,912 BAD EPOCHS (no improvement): 3
2021-07-24 07:53:53,912 ----------------------------------------------------------------------------------------------------
2021-07-24 07:54:26,235 epoch 29 - iter 133/1331 - loss 0.06068887 - samples/sec: 131.72 - lr: 0.000030
2021-07-24 07:54:59,081 epoch 29 - iter 266/1331 - loss 0.05731422 - samples/sec: 129.60 - lr: 0.000030
2021-07-24 07:55:31,169 epoch 29 - iter 399/1331 - loss 0.05427587 - samples/sec: 132.66 - lr: 0.000030
2021-07-24 07:56:03,875 epoch 29 - iter 532/1331 - loss 0.05353308 - samples/sec: 130.16 - lr: 0.000030
2021-07-24 07:56:36,335 epoch 29 - iter 665/1331 - loss 0.05373398 - samples/sec: 131.14 - lr: 0.000030
2021-07-24 07:57:08,950 epoch 29 - iter 798/1331 - loss 0.05268110 - samples/sec: 130.52 - lr: 0.000030
2021-07-24 07:57:41,605 epoch 29 - iter 931/1331 - loss 0.05242633 - samples/sec: 130.36 - lr: 0.000030
2021-07-24 07:58:14,015 epoch 29 - iter 1064/1331 - loss 0.05301441 - samples/sec: 131.34 - lr: 0.000030
2021-07-24 07:58:46,432 epoch 29 - iter 1197/1331 - loss 0.05225749 - samples/sec: 131.32 - lr: 0.000030
2021-07-24 07:59:19,111 epoch 29 - iter 1330/1331 - loss 0.05197108 - samples/sec: 130.26 - lr: 0.000030
2021-07-24 07:59:19,178 ----------------------------------------------------------------------------------------------------
2021-07-24 07:59:19,178 EPOCH 29 done: loss 0.0519 - lr 0.0000300
2021-07-24 07:59:33,785 DEV : loss 0.061489734798669815 - score 0.9854
2021-07-24 07:59:33,941 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:59:36,727 ----------------------------------------------------------------------------------------------------
2021-07-24 08:00:09,431 epoch 30 - iter 133/1331 - loss 0.04865424 - samples/sec: 130.18 - lr: 0.000030
2021-07-24 08:00:42,209 epoch 30 - iter 266/1331 - loss 0.05049069 - samples/sec: 129.87 - lr: 0.000030
2021-07-24 08:01:14,657 epoch 30 - iter 399/1331 - loss 0.05389048 - samples/sec: 131.19 - lr: 0.000030
2021-07-24 08:01:47,029 epoch 30 - iter 532/1331 - loss 0.05060456 - samples/sec: 131.50 - lr: 0.000030
2021-07-24 08:02:19,364 epoch 30 - iter 665/1331 - loss 0.05134946 - samples/sec: 131.65 - lr: 0.000030
2021-07-24 08:02:52,012 epoch 30 - iter 798/1331 - loss 0.05150283 - samples/sec: 130.38 - lr: 0.000030
2021-07-24 08:03:24,088 epoch 30 - iter 931/1331 - loss 0.05152836 - samples/sec: 132.71 - lr: 0.000030
2021-07-24 08:03:56,796 epoch 30 - iter 1064/1331 - loss 0.05148108 - samples/sec: 130.15 - lr: 0.000030
2021-07-24 08:04:29,546 epoch 30 - iter 1197/1331 - loss 0.05065705 - samples/sec: 129.98 - lr: 0.000030
2021-07-24 08:05:02,131 epoch 30 - iter 1330/1331 - loss 0.05116190 - samples/sec: 130.64 - lr: 0.000030
2021-07-24 08:05:02,192 ----------------------------------------------------------------------------------------------------
2021-07-24 08:05:02,192 EPOCH 30 done: loss 0.0511 - lr 0.0000300
2021-07-24 08:05:16,739 DEV : loss 0.06185845658183098 - score 0.9843
2021-07-24 08:05:16,896 BAD EPOCHS (no improvement): 1
2021-07-24 08:05:16,896 ----------------------------------------------------------------------------------------------------
2021-07-24 08:05:49,228 epoch 31 - iter 133/1331 - loss 0.05007854 - samples/sec: 131.68 - lr: 0.000030
2021-07-24 08:06:21,900 epoch 31 - iter 266/1331 - loss 0.05127345 - samples/sec: 130.29 - lr: 0.000030
2021-07-24 08:06:54,364 epoch 31 - iter 399/1331 - loss 0.04945859 - samples/sec: 131.12 - lr: 0.000030
2021-07-24 08:07:26,800 epoch 31 - iter 532/1331 - loss 0.05006221 - samples/sec: 131.24 - lr: 0.000030
2021-07-24 08:07:59,012 epoch 31 - iter 665/1331 - loss 0.05024011 - samples/sec: 132.15 - lr: 0.000030
2021-07-24 08:08:31,525 epoch 31 - iter 798/1331 - loss 0.05009457 - samples/sec: 130.93 - lr: 0.000030
2021-07-24 08:09:04,553 epoch 31 - iter 931/1331 - loss 0.04956002 - samples/sec: 128.89 - lr: 0.000030
2021-07-24 08:09:37,260 epoch 31 - iter 1064/1331 - loss 0.05023496 - samples/sec: 130.15 - lr: 0.000030
2021-07-24 08:10:09,605 epoch 31 - iter 1197/1331 - loss 0.05105024 - samples/sec: 131.61 - lr: 0.000030
2021-07-24 08:10:41,721 epoch 31 - iter 1330/1331 - loss 0.05078375 - samples/sec: 132.55 - lr: 0.000030
2021-07-24 08:10:41,751 ----------------------------------------------------------------------------------------------------
2021-07-24 08:10:41,752 EPOCH 31 done: loss 0.0507 - lr 0.0000300
2021-07-24 08:10:56,280 DEV : loss 0.06433411687612534 - score 0.9844
2021-07-24 08:10:56,436 BAD EPOCHS (no improvement): 2
2021-07-24 08:10:56,437 ----------------------------------------------------------------------------------------------------
2021-07-24 08:11:28,810 epoch 32 - iter 133/1331 - loss 0.05731833 - samples/sec: 131.51 - lr: 0.000030
2021-07-24 08:12:01,744 epoch 32 - iter 266/1331 - loss 0.05540397 - samples/sec: 129.25 - lr: 0.000030
2021-07-24 08:12:34,048 epoch 32 - iter 399/1331 - loss 0.05566925 - samples/sec: 131.77 - lr: 0.000030
2021-07-24 08:13:06,157 epoch 32 - iter 532/1331 - loss 0.05411994 - samples/sec: 132.58 - lr: 0.000030
2021-07-24 08:13:38,739 epoch 32 - iter 665/1331 - loss 0.05310466 - samples/sec: 130.65 - lr: 0.000030
2021-07-24 08:14:11,083 epoch 32 - iter 798/1331 - loss 0.05283294 - samples/sec: 131.61 - lr: 0.000030
2021-07-24 08:14:43,324 epoch 32 - iter 931/1331 - loss 0.05143267 - samples/sec: 132.03 - lr: 0.000030
2021-07-24 08:15:15,868 epoch 32 - iter 1064/1331 - loss 0.05154716 - samples/sec: 130.80 - lr: 0.000030
2021-07-24 08:15:48,206 epoch 32 - iter 1197/1331 - loss 0.05153694 - samples/sec: 131.64 - lr: 0.000030
2021-07-24 08:16:20,743 epoch 32 - iter 1330/1331 - loss 0.05204330 - samples/sec: 130.83 - lr: 0.000030
2021-07-24 08:16:20,799 ----------------------------------------------------------------------------------------------------
2021-07-24 08:16:20,799 EPOCH 32 done: loss 0.0520 - lr 0.0000300
2021-07-24 08:16:35,344 DEV : loss 0.06188659742474556 - score 0.9832
2021-07-24 08:16:35,502 BAD EPOCHS (no improvement): 3
2021-07-24 08:16:35,502 ----------------------------------------------------------------------------------------------------
2021-07-24 08:17:08,367 epoch 33 - iter 133/1331 - loss 0.04840459 - samples/sec: 129.54 - lr: 0.000030
2021-07-24 08:17:41,229 epoch 33 - iter 266/1331 - loss 0.04781411 - samples/sec: 129.54 - lr: 0.000030
2021-07-24 08:18:13,265 epoch 33 - iter 399/1331 - loss 0.04660125 - samples/sec: 132.88 - lr: 0.000030
2021-07-24 08:18:45,563 epoch 33 - iter 532/1331 - loss 0.04747941 - samples/sec: 131.80 - lr: 0.000030
2021-07-24 08:19:18,075 epoch 33 - iter 665/1331 - loss 0.04764170 - samples/sec: 130.93 - lr: 0.000030
2021-07-24 08:19:50,491 epoch 33 - iter 798/1331 - loss 0.04738521 - samples/sec: 131.32 - lr: 0.000030
2021-07-24 08:20:23,007 epoch 33 - iter 931/1331 - loss 0.04791957 - samples/sec: 130.92 - lr: 0.000030
2021-07-24 08:20:55,553 epoch 33 - iter 1064/1331 - loss 0.04794885 - samples/sec: 130.79 - lr: 0.000030
2021-07-24 08:21:28,117 epoch 33 - iter 1197/1331 - loss 0.04881538 - samples/sec: 130.72 - lr: 0.000030
2021-07-24 08:22:00,567 epoch 33 - iter 1330/1331 - loss 0.04864431 - samples/sec: 131.18 - lr: 0.000030
2021-07-24 08:22:00,613 ----------------------------------------------------------------------------------------------------
2021-07-24 08:22:00,613 EPOCH 33 done: loss 0.0486 - lr 0.0000300
2021-07-24 08:22:16,594 DEV : loss 0.06269139796495438 - score 0.9839
Epoch    33: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 08:22:16,751 BAD EPOCHS (no improvement): 4
2021-07-24 08:22:16,752 ----------------------------------------------------------------------------------------------------
2021-07-24 08:22:49,404 epoch 34 - iter 133/1331 - loss 0.04548472 - samples/sec: 130.38 - lr: 0.000015
2021-07-24 08:23:22,036 epoch 34 - iter 266/1331 - loss 0.04438330 - samples/sec: 130.45 - lr: 0.000015
2021-07-24 08:23:54,502 epoch 34 - iter 399/1331 - loss 0.04499932 - samples/sec: 131.12 - lr: 0.000015
2021-07-24 08:24:27,061 epoch 34 - iter 532/1331 - loss 0.04381042 - samples/sec: 130.74 - lr: 0.000015
2021-07-24 08:24:59,448 epoch 34 - iter 665/1331 - loss 0.04394668 - samples/sec: 131.44 - lr: 0.000015
2021-07-24 08:25:31,985 epoch 34 - iter 798/1331 - loss 0.04526240 - samples/sec: 130.83 - lr: 0.000015
2021-07-24 08:26:04,278 epoch 34 - iter 931/1331 - loss 0.04414537 - samples/sec: 131.82 - lr: 0.000015
2021-07-24 08:26:36,739 epoch 34 - iter 1064/1331 - loss 0.04548715 - samples/sec: 131.14 - lr: 0.000015
2021-07-24 08:27:08,945 epoch 34 - iter 1197/1331 - loss 0.04574661 - samples/sec: 132.18 - lr: 0.000015
2021-07-24 08:27:41,728 epoch 34 - iter 1330/1331 - loss 0.04516292 - samples/sec: 129.85 - lr: 0.000015
2021-07-24 08:27:41,759 ----------------------------------------------------------------------------------------------------
2021-07-24 08:27:41,759 EPOCH 34 done: loss 0.0451 - lr 0.0000150
2021-07-24 08:27:56,332 DEV : loss 0.062057919800281525 - score 0.9857
2021-07-24 08:27:56,487 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 08:27:59,389 ----------------------------------------------------------------------------------------------------
2021-07-24 08:28:32,018 epoch 35 - iter 133/1331 - loss 0.04408710 - samples/sec: 130.48 - lr: 0.000015
2021-07-24 08:29:04,829 epoch 35 - iter 266/1331 - loss 0.04202364 - samples/sec: 129.74 - lr: 0.000015
2021-07-24 08:29:37,517 epoch 35 - iter 399/1331 - loss 0.04140970 - samples/sec: 130.23 - lr: 0.000015
2021-07-24 08:30:09,680 epoch 35 - iter 532/1331 - loss 0.04237908 - samples/sec: 132.35 - lr: 0.000015
2021-07-24 08:30:42,120 epoch 35 - iter 665/1331 - loss 0.04451190 - samples/sec: 131.22 - lr: 0.000015
2021-07-24 08:31:15,032 epoch 35 - iter 798/1331 - loss 0.04425302 - samples/sec: 129.34 - lr: 0.000015
2021-07-24 08:31:46,994 epoch 35 - iter 931/1331 - loss 0.04434660 - samples/sec: 133.19 - lr: 0.000015
2021-07-24 08:32:19,306 epoch 35 - iter 1064/1331 - loss 0.04494787 - samples/sec: 131.74 - lr: 0.000015
2021-07-24 08:32:51,622 epoch 35 - iter 1197/1331 - loss 0.04581886 - samples/sec: 131.73 - lr: 0.000015
2021-07-24 08:33:23,932 epoch 35 - iter 1330/1331 - loss 0.04458804 - samples/sec: 131.75 - lr: 0.000015
2021-07-24 08:33:23,995 ----------------------------------------------------------------------------------------------------
2021-07-24 08:33:23,995 EPOCH 35 done: loss 0.0446 - lr 0.0000150
2021-07-24 08:33:38,613 DEV : loss 0.06436637789011002 - score 0.9832
2021-07-24 08:33:38,768 BAD EPOCHS (no improvement): 1
2021-07-24 08:33:38,769 ----------------------------------------------------------------------------------------------------
2021-07-24 08:34:11,616 epoch 36 - iter 133/1331 - loss 0.03711603 - samples/sec: 129.61 - lr: 0.000015
2021-07-24 08:34:44,065 epoch 36 - iter 266/1331 - loss 0.04370162 - samples/sec: 131.19 - lr: 0.000015
2021-07-24 08:35:16,681 epoch 36 - iter 399/1331 - loss 0.04265461 - samples/sec: 130.51 - lr: 0.000015
2021-07-24 08:35:48,769 epoch 36 - iter 532/1331 - loss 0.04390591 - samples/sec: 132.66 - lr: 0.000015
2021-07-24 08:36:21,173 epoch 36 - iter 665/1331 - loss 0.04558528 - samples/sec: 131.37 - lr: 0.000015
2021-07-24 08:36:53,683 epoch 36 - iter 798/1331 - loss 0.04532681 - samples/sec: 130.94 - lr: 0.000015
2021-07-24 08:37:26,324 epoch 36 - iter 931/1331 - loss 0.04669426 - samples/sec: 130.41 - lr: 0.000015
2021-07-24 08:37:58,692 epoch 36 - iter 1064/1331 - loss 0.04647183 - samples/sec: 131.52 - lr: 0.000015
2021-07-24 08:38:31,552 epoch 36 - iter 1197/1331 - loss 0.04654937 - samples/sec: 129.55 - lr: 0.000015
2021-07-24 08:39:04,029 epoch 36 - iter 1330/1331 - loss 0.04594290 - samples/sec: 131.07 - lr: 0.000015
2021-07-24 08:39:04,074 ----------------------------------------------------------------------------------------------------
2021-07-24 08:39:04,074 EPOCH 36 done: loss 0.0459 - lr 0.0000150
2021-07-24 08:39:18,633 DEV : loss 0.0643281415104866 - score 0.985
2021-07-24 08:39:18,788 BAD EPOCHS (no improvement): 2
2021-07-24 08:39:18,788 ----------------------------------------------------------------------------------------------------
2021-07-24 08:39:51,575 epoch 37 - iter 133/1331 - loss 0.04461843 - samples/sec: 129.84 - lr: 0.000015
2021-07-24 08:40:23,464 epoch 37 - iter 266/1331 - loss 0.04405329 - samples/sec: 133.49 - lr: 0.000015
2021-07-24 08:40:56,051 epoch 37 - iter 399/1331 - loss 0.04452560 - samples/sec: 130.63 - lr: 0.000015
2021-07-24 08:41:28,672 epoch 37 - iter 532/1331 - loss 0.04618700 - samples/sec: 130.50 - lr: 0.000015
2021-07-24 08:42:01,129 epoch 37 - iter 665/1331 - loss 0.04705780 - samples/sec: 131.15 - lr: 0.000015
2021-07-24 08:42:33,568 epoch 37 - iter 798/1331 - loss 0.04534518 - samples/sec: 131.23 - lr: 0.000015
2021-07-24 08:43:06,444 epoch 37 - iter 931/1331 - loss 0.04492972 - samples/sec: 129.48 - lr: 0.000015
2021-07-24 08:43:38,951 epoch 37 - iter 1064/1331 - loss 0.04530479 - samples/sec: 130.95 - lr: 0.000015
2021-07-24 08:44:11,712 epoch 37 - iter 1197/1331 - loss 0.04495463 - samples/sec: 129.93 - lr: 0.000015
2021-07-24 08:44:44,185 epoch 37 - iter 1330/1331 - loss 0.04481706 - samples/sec: 131.09 - lr: 0.000015
2021-07-24 08:44:44,240 ----------------------------------------------------------------------------------------------------
2021-07-24 08:44:44,240 EPOCH 37 done: loss 0.0448 - lr 0.0000150
2021-07-24 08:45:00,204 DEV : loss 0.0638740286231041 - score 0.9848
2021-07-24 08:45:00,358 BAD EPOCHS (no improvement): 3
2021-07-24 08:45:00,359 ----------------------------------------------------------------------------------------------------
2021-07-24 08:45:33,055 epoch 38 - iter 133/1331 - loss 0.04162052 - samples/sec: 130.20 - lr: 0.000015
2021-07-24 08:46:05,437 epoch 38 - iter 266/1331 - loss 0.04307147 - samples/sec: 131.46 - lr: 0.000015
2021-07-24 08:46:37,723 epoch 38 - iter 399/1331 - loss 0.04249065 - samples/sec: 131.85 - lr: 0.000015
2021-07-24 08:47:10,347 epoch 38 - iter 532/1331 - loss 0.04412512 - samples/sec: 130.48 - lr: 0.000015
2021-07-24 08:47:42,771 epoch 38 - iter 665/1331 - loss 0.04179357 - samples/sec: 131.29 - lr: 0.000015
2021-07-24 08:48:15,930 epoch 38 - iter 798/1331 - loss 0.04201038 - samples/sec: 128.38 - lr: 0.000015
2021-07-24 08:48:48,401 epoch 38 - iter 931/1331 - loss 0.04209995 - samples/sec: 131.10 - lr: 0.000015
2021-07-24 08:49:20,717 epoch 38 - iter 1064/1331 - loss 0.04286558 - samples/sec: 131.73 - lr: 0.000015
2021-07-24 08:49:52,930 epoch 38 - iter 1197/1331 - loss 0.04268795 - samples/sec: 132.15 - lr: 0.000015
2021-07-24 08:50:25,249 epoch 38 - iter 1330/1331 - loss 0.04255762 - samples/sec: 131.71 - lr: 0.000015
2021-07-24 08:50:25,288 ----------------------------------------------------------------------------------------------------
2021-07-24 08:50:25,288 EPOCH 38 done: loss 0.0425 - lr 0.0000150
2021-07-24 08:50:39,874 DEV : loss 0.06515195965766907 - score 0.9838
Epoch    38: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 08:50:40,031 BAD EPOCHS (no improvement): 4
2021-07-24 08:50:40,031 ----------------------------------------------------------------------------------------------------
2021-07-24 08:51:12,568 epoch 39 - iter 133/1331 - loss 0.03848050 - samples/sec: 130.84 - lr: 0.000008
2021-07-24 08:51:45,613 epoch 39 - iter 266/1331 - loss 0.04099430 - samples/sec: 128.82 - lr: 0.000008
2021-07-24 08:52:18,067 epoch 39 - iter 399/1331 - loss 0.03883005 - samples/sec: 131.16 - lr: 0.000008
2021-07-24 08:52:50,388 epoch 39 - iter 532/1331 - loss 0.04186249 - samples/sec: 131.71 - lr: 0.000008
2021-07-24 08:53:22,652 epoch 39 - iter 665/1331 - loss 0.04236241 - samples/sec: 131.94 - lr: 0.000008
2021-07-24 08:53:55,362 epoch 39 - iter 798/1331 - loss 0.04236521 - samples/sec: 130.14 - lr: 0.000008
2021-07-24 08:54:27,852 epoch 39 - iter 931/1331 - loss 0.04189619 - samples/sec: 131.02 - lr: 0.000008
2021-07-24 08:55:00,517 epoch 39 - iter 1064/1331 - loss 0.04074994 - samples/sec: 130.32 - lr: 0.000008
2021-07-24 08:55:32,861 epoch 39 - iter 1197/1331 - loss 0.04097574 - samples/sec: 131.61 - lr: 0.000008
2021-07-24 08:56:04,976 epoch 39 - iter 1330/1331 - loss 0.04110976 - samples/sec: 132.55 - lr: 0.000008
2021-07-24 08:56:05,055 ----------------------------------------------------------------------------------------------------
2021-07-24 08:56:05,055 EPOCH 39 done: loss 0.0411 - lr 0.0000075
2021-07-24 08:56:19,625 DEV : loss 0.06684926897287369 - score 0.9834
2021-07-24 08:56:19,778 BAD EPOCHS (no improvement): 1
2021-07-24 08:56:19,778 ----------------------------------------------------------------------------------------------------
2021-07-24 08:56:52,451 epoch 40 - iter 133/1331 - loss 0.04051411 - samples/sec: 130.30 - lr: 0.000008
2021-07-24 08:57:24,761 epoch 40 - iter 266/1331 - loss 0.04111163 - samples/sec: 131.75 - lr: 0.000008
2021-07-24 08:57:57,684 epoch 40 - iter 399/1331 - loss 0.04043891 - samples/sec: 129.30 - lr: 0.000008
2021-07-24 08:58:29,596 epoch 40 - iter 532/1331 - loss 0.04135795 - samples/sec: 133.39 - lr: 0.000008
2021-07-24 08:59:02,375 epoch 40 - iter 665/1331 - loss 0.04179128 - samples/sec: 129.87 - lr: 0.000008
2021-07-24 08:59:34,597 epoch 40 - iter 798/1331 - loss 0.04093721 - samples/sec: 132.11 - lr: 0.000008
2021-07-24 09:00:07,100 epoch 40 - iter 931/1331 - loss 0.04052674 - samples/sec: 130.97 - lr: 0.000008
2021-07-24 09:00:39,299 epoch 40 - iter 1064/1331 - loss 0.04087240 - samples/sec: 132.20 - lr: 0.000008
2021-07-24 09:01:11,949 epoch 40 - iter 1197/1331 - loss 0.04051221 - samples/sec: 130.38 - lr: 0.000008
2021-07-24 09:01:44,828 epoch 40 - iter 1330/1331 - loss 0.04063814 - samples/sec: 129.47 - lr: 0.000008
2021-07-24 09:01:44,892 ----------------------------------------------------------------------------------------------------
2021-07-24 09:01:44,893 EPOCH 40 done: loss 0.0407 - lr 0.0000075
2021-07-24 09:01:59,467 DEV : loss 0.06649444997310638 - score 0.983
2021-07-24 09:01:59,618 BAD EPOCHS (no improvement): 2
2021-07-24 09:02:00,297 ----------------------------------------------------------------------------------------------------
2021-07-24 09:02:00,297 Testing using best model ...
2021-07-24 09:02:00,298 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/rus.rst.rrt/best-model.pt
2021-07-24 09:05:03,342 0.9771	0.9890	0.9830
2021-07-24 09:05:03,343 
Results:
- F1-score (micro) 0.9830
- F1-score (macro) 0.9815

By class:
SENT       tp: 3729 - fp: 194 - fn: 92 - precision: 0.9505 - recall: 0.9759 - f1-score: 0.9631
X          tp: 4551 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-24 09:05:03,343 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.gum/
2021-07-24 09:05:03,392 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.gum
2021-07-24 09:05:03,392 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.gum/sent_train.txt
2021-07-24 09:05:03,395 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.gum/sent_dev.txt
2021-07-24 09:05:03,396 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.gum/sent_test.txt
Corpus: 13230 train + 2617 dev + 3777 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-24 09:05:07,202 ----------------------------------------------------------------------------------------------------
2021-07-24 09:05:07,204 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-24 09:05:07,204 ----------------------------------------------------------------------------------------------------
2021-07-24 09:05:07,204 Corpus: "Corpus: 13230 train + 2617 dev + 3777 test sentences"
2021-07-24 09:05:07,204 ----------------------------------------------------------------------------------------------------
2021-07-24 09:05:07,204 Parameters:
2021-07-24 09:05:07,204  - learning_rate: "3e-05"
2021-07-24 09:05:07,204  - mini_batch_size: "32"
2021-07-24 09:05:07,204  - patience: "3"
2021-07-24 09:05:07,204  - anneal_factor: "0.5"
2021-07-24 09:05:07,204  - max_epochs: "40"
2021-07-24 09:05:07,204  - shuffle: "True"
2021-07-24 09:05:07,204  - train_with_dev: "False"
2021-07-24 09:05:07,204  - batch_growth_annealing: "False"
2021-07-24 09:05:07,205 ----------------------------------------------------------------------------------------------------
2021-07-24 09:05:07,205 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.gum"
2021-07-24 09:05:07,205 ----------------------------------------------------------------------------------------------------
2021-07-24 09:05:07,205 Device: cuda:0
2021-07-24 09:05:07,205 ----------------------------------------------------------------------------------------------------
2021-07-24 09:05:07,205 Embeddings storage mode: cpu
2021-07-24 09:05:07,207 ----------------------------------------------------------------------------------------------------
2021-07-24 09:05:31,162 epoch 1 - iter 41/414 - loss 6.36522854 - samples/sec: 54.77 - lr: 0.000030
2021-07-24 09:05:55,565 epoch 1 - iter 82/414 - loss 5.08873091 - samples/sec: 53.77 - lr: 0.000030
2021-07-24 09:06:21,606 epoch 1 - iter 123/414 - loss 4.13637906 - samples/sec: 50.39 - lr: 0.000030
2021-07-24 09:06:47,455 epoch 1 - iter 164/414 - loss 3.48873208 - samples/sec: 50.76 - lr: 0.000030
2021-07-24 09:07:11,351 epoch 1 - iter 205/414 - loss 3.06805997 - samples/sec: 54.91 - lr: 0.000030
2021-07-24 09:07:36,138 epoch 1 - iter 246/414 - loss 2.70367316 - samples/sec: 52.94 - lr: 0.000030
2021-07-24 09:08:04,764 epoch 1 - iter 287/414 - loss 2.40917956 - samples/sec: 45.83 - lr: 0.000030
2021-07-24 09:08:28,499 epoch 1 - iter 328/414 - loss 2.17837644 - samples/sec: 55.28 - lr: 0.000030
2021-07-24 09:08:51,763 epoch 1 - iter 369/414 - loss 1.98993921 - samples/sec: 56.40 - lr: 0.000030
2021-07-24 09:09:14,982 epoch 1 - iter 410/414 - loss 1.83195835 - samples/sec: 56.51 - lr: 0.000030
2021-07-24 09:09:16,927 ----------------------------------------------------------------------------------------------------
2021-07-24 09:09:16,927 EPOCH 1 done: loss 1.8175 - lr 0.0000300
2021-07-24 09:09:50,869 DEV : loss 0.1490117758512497 - score 0.978
2021-07-24 09:09:50,939 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:09:51,492 ----------------------------------------------------------------------------------------------------
2021-07-24 09:10:00,877 epoch 2 - iter 41/414 - loss 0.37806479 - samples/sec: 139.85 - lr: 0.000030
2021-07-24 09:10:10,711 epoch 2 - iter 82/414 - loss 0.34777770 - samples/sec: 133.45 - lr: 0.000030
2021-07-24 09:10:20,372 epoch 2 - iter 123/414 - loss 0.33011886 - samples/sec: 135.83 - lr: 0.000030
2021-07-24 09:10:29,978 epoch 2 - iter 164/414 - loss 0.32298813 - samples/sec: 136.62 - lr: 0.000030
2021-07-24 09:10:39,443 epoch 2 - iter 205/414 - loss 0.31503697 - samples/sec: 138.65 - lr: 0.000030
2021-07-24 09:10:49,076 epoch 2 - iter 246/414 - loss 0.31056657 - samples/sec: 136.23 - lr: 0.000030
2021-07-24 09:10:58,670 epoch 2 - iter 287/414 - loss 0.29976354 - samples/sec: 136.78 - lr: 0.000030
2021-07-24 09:11:08,204 epoch 2 - iter 328/414 - loss 0.29022343 - samples/sec: 137.64 - lr: 0.000030
2021-07-24 09:11:17,792 epoch 2 - iter 369/414 - loss 0.28724440 - samples/sec: 136.88 - lr: 0.000030
2021-07-24 09:11:27,348 epoch 2 - iter 410/414 - loss 0.28325586 - samples/sec: 137.32 - lr: 0.000030
2021-07-24 09:11:28,152 ----------------------------------------------------------------------------------------------------
2021-07-24 09:11:28,152 EPOCH 2 done: loss 0.2832 - lr 0.0000300
2021-07-24 09:11:34,390 DEV : loss 0.08770081400871277 - score 0.9824
2021-07-24 09:11:34,461 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:11:36,757 ----------------------------------------------------------------------------------------------------
2021-07-24 09:11:46,576 epoch 3 - iter 41/414 - loss 0.24656221 - samples/sec: 133.67 - lr: 0.000030
2021-07-24 09:11:56,361 epoch 3 - iter 82/414 - loss 0.23611818 - samples/sec: 134.12 - lr: 0.000030
2021-07-24 09:12:05,994 epoch 3 - iter 123/414 - loss 0.22698056 - samples/sec: 136.22 - lr: 0.000030
2021-07-24 09:12:15,388 epoch 3 - iter 164/414 - loss 0.22726563 - samples/sec: 139.69 - lr: 0.000030
2021-07-24 09:12:25,184 epoch 3 - iter 205/414 - loss 0.22422876 - samples/sec: 133.97 - lr: 0.000030
2021-07-24 09:12:34,881 epoch 3 - iter 246/414 - loss 0.22013502 - samples/sec: 135.34 - lr: 0.000030
2021-07-24 09:12:44,545 epoch 3 - iter 287/414 - loss 0.22043666 - samples/sec: 135.79 - lr: 0.000030
2021-07-24 09:12:54,216 epoch 3 - iter 328/414 - loss 0.22110701 - samples/sec: 135.69 - lr: 0.000030
2021-07-24 09:13:03,733 epoch 3 - iter 369/414 - loss 0.22081116 - samples/sec: 137.89 - lr: 0.000030
2021-07-24 09:13:13,412 epoch 3 - iter 410/414 - loss 0.21680207 - samples/sec: 135.58 - lr: 0.000030
2021-07-24 09:13:14,268 ----------------------------------------------------------------------------------------------------
2021-07-24 09:13:14,268 EPOCH 3 done: loss 0.2172 - lr 0.0000300
2021-07-24 09:13:20,482 DEV : loss 0.07671903818845749 - score 0.9843
2021-07-24 09:13:20,553 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:13:22,849 ----------------------------------------------------------------------------------------------------
2021-07-24 09:13:32,400 epoch 4 - iter 41/414 - loss 0.22928800 - samples/sec: 137.43 - lr: 0.000030
2021-07-24 09:13:42,165 epoch 4 - iter 82/414 - loss 0.22479066 - samples/sec: 134.38 - lr: 0.000030
2021-07-24 09:13:51,687 epoch 4 - iter 123/414 - loss 0.21856728 - samples/sec: 137.82 - lr: 0.000030
2021-07-24 09:14:01,139 epoch 4 - iter 164/414 - loss 0.21349079 - samples/sec: 138.84 - lr: 0.000030
2021-07-24 09:14:10,725 epoch 4 - iter 205/414 - loss 0.20822026 - samples/sec: 136.90 - lr: 0.000030
2021-07-24 09:14:20,284 epoch 4 - iter 246/414 - loss 0.20557835 - samples/sec: 137.29 - lr: 0.000030
2021-07-24 09:14:29,635 epoch 4 - iter 287/414 - loss 0.20738186 - samples/sec: 140.33 - lr: 0.000030
2021-07-24 09:14:39,337 epoch 4 - iter 328/414 - loss 0.20550987 - samples/sec: 135.26 - lr: 0.000030
2021-07-24 09:14:48,953 epoch 4 - iter 369/414 - loss 0.20548620 - samples/sec: 136.47 - lr: 0.000030
2021-07-24 09:14:58,602 epoch 4 - iter 410/414 - loss 0.20275703 - samples/sec: 136.01 - lr: 0.000030
2021-07-24 09:14:59,458 ----------------------------------------------------------------------------------------------------
2021-07-24 09:14:59,458 EPOCH 4 done: loss 0.2026 - lr 0.0000300
2021-07-24 09:15:05,681 DEV : loss 0.07249603420495987 - score 0.9851
2021-07-24 09:15:05,752 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:15:08,144 ----------------------------------------------------------------------------------------------------
2021-07-24 09:15:17,615 epoch 5 - iter 41/414 - loss 0.20641525 - samples/sec: 138.60 - lr: 0.000030
2021-07-24 09:15:27,207 epoch 5 - iter 82/414 - loss 0.19253591 - samples/sec: 136.81 - lr: 0.000030
2021-07-24 09:15:36,937 epoch 5 - iter 123/414 - loss 0.18835710 - samples/sec: 134.88 - lr: 0.000030
2021-07-24 09:15:46,500 epoch 5 - iter 164/414 - loss 0.18825149 - samples/sec: 137.22 - lr: 0.000030
2021-07-24 09:15:55,992 epoch 5 - iter 205/414 - loss 0.19377364 - samples/sec: 138.26 - lr: 0.000030
2021-07-24 09:16:05,664 epoch 5 - iter 246/414 - loss 0.19875022 - samples/sec: 135.67 - lr: 0.000030
2021-07-24 09:16:15,305 epoch 5 - iter 287/414 - loss 0.19969408 - samples/sec: 136.12 - lr: 0.000030
2021-07-24 09:16:25,085 epoch 5 - iter 328/414 - loss 0.19818861 - samples/sec: 134.18 - lr: 0.000030
2021-07-24 09:16:34,863 epoch 5 - iter 369/414 - loss 0.19793775 - samples/sec: 134.20 - lr: 0.000030
2021-07-24 09:16:44,608 epoch 5 - iter 410/414 - loss 0.19446315 - samples/sec: 134.67 - lr: 0.000030
2021-07-24 09:16:45,430 ----------------------------------------------------------------------------------------------------
2021-07-24 09:16:45,431 EPOCH 5 done: loss 0.1943 - lr 0.0000300
2021-07-24 09:16:51,659 DEV : loss 0.06927172839641571 - score 0.9857
2021-07-24 09:16:51,730 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:16:53,909 ----------------------------------------------------------------------------------------------------
2021-07-24 09:17:03,497 epoch 6 - iter 41/414 - loss 0.18797022 - samples/sec: 136.90 - lr: 0.000030
2021-07-24 09:17:13,215 epoch 6 - iter 82/414 - loss 0.19940854 - samples/sec: 135.04 - lr: 0.000030
2021-07-24 09:17:22,928 epoch 6 - iter 123/414 - loss 0.18412252 - samples/sec: 135.10 - lr: 0.000030
2021-07-24 09:17:32,563 epoch 6 - iter 164/414 - loss 0.18496650 - samples/sec: 136.20 - lr: 0.000030
2021-07-24 09:17:42,112 epoch 6 - iter 205/414 - loss 0.18028352 - samples/sec: 137.44 - lr: 0.000030
2021-07-24 09:17:51,717 epoch 6 - iter 246/414 - loss 0.17764611 - samples/sec: 136.62 - lr: 0.000030
2021-07-24 09:18:01,368 epoch 6 - iter 287/414 - loss 0.17583287 - samples/sec: 135.97 - lr: 0.000030
2021-07-24 09:18:11,169 epoch 6 - iter 328/414 - loss 0.17263318 - samples/sec: 133.89 - lr: 0.000030
2021-07-24 09:18:20,736 epoch 6 - iter 369/414 - loss 0.17479964 - samples/sec: 137.18 - lr: 0.000030
2021-07-24 09:18:30,376 epoch 6 - iter 410/414 - loss 0.17623694 - samples/sec: 136.13 - lr: 0.000030
2021-07-24 09:18:31,188 ----------------------------------------------------------------------------------------------------
2021-07-24 09:18:31,188 EPOCH 6 done: loss 0.1754 - lr 0.0000300
2021-07-24 09:18:37,886 DEV : loss 0.06680531054735184 - score 0.9857
2021-07-24 09:18:37,957 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:18:40,202 ----------------------------------------------------------------------------------------------------
2021-07-24 09:18:49,780 epoch 7 - iter 41/414 - loss 0.15037737 - samples/sec: 137.05 - lr: 0.000030
2021-07-24 09:18:59,255 epoch 7 - iter 82/414 - loss 0.16387757 - samples/sec: 138.50 - lr: 0.000030
2021-07-24 09:19:08,892 epoch 7 - iter 123/414 - loss 0.17536163 - samples/sec: 136.18 - lr: 0.000030
2021-07-24 09:19:18,626 epoch 7 - iter 164/414 - loss 0.17029874 - samples/sec: 134.82 - lr: 0.000030
2021-07-24 09:19:28,371 epoch 7 - iter 205/414 - loss 0.17065760 - samples/sec: 134.65 - lr: 0.000030
2021-07-24 09:19:38,061 epoch 7 - iter 246/414 - loss 0.17305139 - samples/sec: 135.44 - lr: 0.000030
2021-07-24 09:19:47,935 epoch 7 - iter 287/414 - loss 0.16999791 - samples/sec: 132.89 - lr: 0.000030
2021-07-24 09:19:57,550 epoch 7 - iter 328/414 - loss 0.17345774 - samples/sec: 136.49 - lr: 0.000030
2021-07-24 09:20:07,137 epoch 7 - iter 369/414 - loss 0.17335758 - samples/sec: 136.89 - lr: 0.000030
2021-07-24 09:20:16,528 epoch 7 - iter 410/414 - loss 0.17541786 - samples/sec: 139.74 - lr: 0.000030
2021-07-24 09:20:17,432 ----------------------------------------------------------------------------------------------------
2021-07-24 09:20:17,433 EPOCH 7 done: loss 0.1745 - lr 0.0000300
2021-07-24 09:20:23,645 DEV : loss 0.06520606577396393 - score 0.986
2021-07-24 09:20:23,716 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:20:26,063 ----------------------------------------------------------------------------------------------------
2021-07-24 09:20:35,696 epoch 8 - iter 41/414 - loss 0.18274228 - samples/sec: 136.27 - lr: 0.000030
2021-07-24 09:20:45,447 epoch 8 - iter 82/414 - loss 0.18061842 - samples/sec: 134.57 - lr: 0.000030
2021-07-24 09:20:54,939 epoch 8 - iter 123/414 - loss 0.18043987 - samples/sec: 138.26 - lr: 0.000030
2021-07-24 09:21:04,793 epoch 8 - iter 164/414 - loss 0.18109479 - samples/sec: 133.17 - lr: 0.000030
2021-07-24 09:21:14,345 epoch 8 - iter 205/414 - loss 0.17518343 - samples/sec: 137.39 - lr: 0.000030
2021-07-24 09:21:24,069 epoch 8 - iter 246/414 - loss 0.17048791 - samples/sec: 134.95 - lr: 0.000030
2021-07-24 09:21:33,860 epoch 8 - iter 287/414 - loss 0.17184643 - samples/sec: 134.03 - lr: 0.000030
2021-07-24 09:21:43,537 epoch 8 - iter 328/414 - loss 0.17310133 - samples/sec: 135.61 - lr: 0.000030
2021-07-24 09:21:53,047 epoch 8 - iter 369/414 - loss 0.17344457 - samples/sec: 137.99 - lr: 0.000030
2021-07-24 09:22:02,475 epoch 8 - iter 410/414 - loss 0.17452208 - samples/sec: 139.19 - lr: 0.000030
2021-07-24 09:22:03,395 ----------------------------------------------------------------------------------------------------
2021-07-24 09:22:03,395 EPOCH 8 done: loss 0.1739 - lr 0.0000300
2021-07-24 09:22:09,614 DEV : loss 0.0648159608244896 - score 0.986
2021-07-24 09:22:09,685 BAD EPOCHS (no improvement): 1
2021-07-24 09:22:09,685 ----------------------------------------------------------------------------------------------------
2021-07-24 09:22:19,344 epoch 9 - iter 41/414 - loss 0.19625072 - samples/sec: 135.88 - lr: 0.000030
2021-07-24 09:22:29,125 epoch 9 - iter 82/414 - loss 0.18156858 - samples/sec: 134.18 - lr: 0.000030
2021-07-24 09:22:38,671 epoch 9 - iter 123/414 - loss 0.17518064 - samples/sec: 137.47 - lr: 0.000030
2021-07-24 09:22:48,480 epoch 9 - iter 164/414 - loss 0.16904057 - samples/sec: 133.78 - lr: 0.000030
2021-07-24 09:22:58,063 epoch 9 - iter 205/414 - loss 0.17324134 - samples/sec: 136.94 - lr: 0.000030
2021-07-24 09:23:07,668 epoch 9 - iter 246/414 - loss 0.17061043 - samples/sec: 136.64 - lr: 0.000030
2021-07-24 09:23:17,203 epoch 9 - iter 287/414 - loss 0.16773570 - samples/sec: 137.62 - lr: 0.000030
2021-07-24 09:23:26,878 epoch 9 - iter 328/414 - loss 0.16752456 - samples/sec: 135.65 - lr: 0.000030
2021-07-24 09:23:36,477 epoch 9 - iter 369/414 - loss 0.16563912 - samples/sec: 136.71 - lr: 0.000030
2021-07-24 09:23:46,024 epoch 9 - iter 410/414 - loss 0.16391014 - samples/sec: 137.45 - lr: 0.000030
2021-07-24 09:23:46,762 ----------------------------------------------------------------------------------------------------
2021-07-24 09:23:46,762 EPOCH 9 done: loss 0.1641 - lr 0.0000300
2021-07-24 09:23:52,987 DEV : loss 0.06475773453712463 - score 0.987
2021-07-24 09:23:53,058 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:23:55,356 ----------------------------------------------------------------------------------------------------
2021-07-24 09:24:04,888 epoch 10 - iter 41/414 - loss 0.14675224 - samples/sec: 137.72 - lr: 0.000030
2021-07-24 09:24:14,246 epoch 10 - iter 82/414 - loss 0.15503215 - samples/sec: 140.23 - lr: 0.000030
2021-07-24 09:24:23,695 epoch 10 - iter 123/414 - loss 0.15361908 - samples/sec: 138.89 - lr: 0.000030
2021-07-24 09:24:33,292 epoch 10 - iter 164/414 - loss 0.15478841 - samples/sec: 136.73 - lr: 0.000030
2021-07-24 09:24:43,267 epoch 10 - iter 205/414 - loss 0.15941767 - samples/sec: 131.56 - lr: 0.000030
2021-07-24 09:24:52,941 epoch 10 - iter 246/414 - loss 0.15905416 - samples/sec: 135.65 - lr: 0.000030
2021-07-24 09:25:02,681 epoch 10 - iter 287/414 - loss 0.15954097 - samples/sec: 134.73 - lr: 0.000030
2021-07-24 09:25:12,368 epoch 10 - iter 328/414 - loss 0.15888517 - samples/sec: 135.47 - lr: 0.000030
2021-07-24 09:25:22,174 epoch 10 - iter 369/414 - loss 0.16046829 - samples/sec: 133.84 - lr: 0.000030
2021-07-24 09:25:31,805 epoch 10 - iter 410/414 - loss 0.16078422 - samples/sec: 136.25 - lr: 0.000030
2021-07-24 09:25:32,667 ----------------------------------------------------------------------------------------------------
2021-07-24 09:25:32,667 EPOCH 10 done: loss 0.1609 - lr 0.0000300
2021-07-24 09:25:38,888 DEV : loss 0.06222772225737572 - score 0.9873
2021-07-24 09:25:38,959 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:25:41,283 ----------------------------------------------------------------------------------------------------
2021-07-24 09:25:51,156 epoch 11 - iter 41/414 - loss 0.13938190 - samples/sec: 132.95 - lr: 0.000030
2021-07-24 09:26:00,980 epoch 11 - iter 82/414 - loss 0.14408493 - samples/sec: 133.59 - lr: 0.000030
2021-07-24 09:26:10,456 epoch 11 - iter 123/414 - loss 0.14541985 - samples/sec: 138.49 - lr: 0.000030
2021-07-24 09:26:20,156 epoch 11 - iter 164/414 - loss 0.14177988 - samples/sec: 135.29 - lr: 0.000030
2021-07-24 09:26:30,013 epoch 11 - iter 205/414 - loss 0.14171561 - samples/sec: 133.13 - lr: 0.000030
2021-07-24 09:26:39,567 epoch 11 - iter 246/414 - loss 0.14186291 - samples/sec: 137.36 - lr: 0.000030
2021-07-24 09:26:49,330 epoch 11 - iter 287/414 - loss 0.14171088 - samples/sec: 134.41 - lr: 0.000030
2021-07-24 09:26:58,941 epoch 11 - iter 328/414 - loss 0.14102949 - samples/sec: 136.55 - lr: 0.000030
2021-07-24 09:27:08,755 epoch 11 - iter 369/414 - loss 0.14280353 - samples/sec: 133.71 - lr: 0.000030
2021-07-24 09:27:18,331 epoch 11 - iter 410/414 - loss 0.14309976 - samples/sec: 137.04 - lr: 0.000030
2021-07-24 09:27:19,095 ----------------------------------------------------------------------------------------------------
2021-07-24 09:27:19,095 EPOCH 11 done: loss 0.1432 - lr 0.0000300
2021-07-24 09:27:25,314 DEV : loss 0.06134822592139244 - score 0.9879
2021-07-24 09:27:25,385 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:27:27,601 ----------------------------------------------------------------------------------------------------
2021-07-24 09:27:37,527 epoch 12 - iter 41/414 - loss 0.14202060 - samples/sec: 132.24 - lr: 0.000030
2021-07-24 09:27:47,228 epoch 12 - iter 82/414 - loss 0.14813129 - samples/sec: 135.28 - lr: 0.000030
2021-07-24 09:27:56,587 epoch 12 - iter 123/414 - loss 0.14195666 - samples/sec: 140.21 - lr: 0.000030
2021-07-24 09:28:05,865 epoch 12 - iter 164/414 - loss 0.14569973 - samples/sec: 141.45 - lr: 0.000030
2021-07-24 09:28:15,648 epoch 12 - iter 205/414 - loss 0.15034118 - samples/sec: 134.13 - lr: 0.000030
2021-07-24 09:28:25,340 epoch 12 - iter 246/414 - loss 0.14914918 - samples/sec: 135.40 - lr: 0.000030
2021-07-24 09:28:34,997 epoch 12 - iter 287/414 - loss 0.14562807 - samples/sec: 135.90 - lr: 0.000030
2021-07-24 09:28:44,781 epoch 12 - iter 328/414 - loss 0.14233563 - samples/sec: 134.13 - lr: 0.000030
2021-07-24 09:28:54,328 epoch 12 - iter 369/414 - loss 0.14227671 - samples/sec: 137.45 - lr: 0.000030
2021-07-24 09:29:03,818 epoch 12 - iter 410/414 - loss 0.13985952 - samples/sec: 138.29 - lr: 0.000030
2021-07-24 09:29:04,656 ----------------------------------------------------------------------------------------------------
2021-07-24 09:29:04,656 EPOCH 12 done: loss 0.1404 - lr 0.0000300
2021-07-24 09:29:10,865 DEV : loss 0.06206061691045761 - score 0.9873
2021-07-24 09:29:10,936 BAD EPOCHS (no improvement): 1
2021-07-24 09:29:10,936 ----------------------------------------------------------------------------------------------------
2021-07-24 09:29:20,376 epoch 13 - iter 41/414 - loss 0.10998766 - samples/sec: 139.04 - lr: 0.000030
2021-07-24 09:29:29,979 epoch 13 - iter 82/414 - loss 0.11082129 - samples/sec: 136.66 - lr: 0.000030
2021-07-24 09:29:39,563 epoch 13 - iter 123/414 - loss 0.12555534 - samples/sec: 136.92 - lr: 0.000030
2021-07-24 09:29:49,304 epoch 13 - iter 164/414 - loss 0.12425553 - samples/sec: 134.73 - lr: 0.000030
2021-07-24 09:29:58,840 epoch 13 - iter 205/414 - loss 0.12441062 - samples/sec: 137.62 - lr: 0.000030
2021-07-24 09:30:08,465 epoch 13 - iter 246/414 - loss 0.12709307 - samples/sec: 136.33 - lr: 0.000030
2021-07-24 09:30:18,029 epoch 13 - iter 287/414 - loss 0.12296704 - samples/sec: 137.22 - lr: 0.000030
2021-07-24 09:30:27,552 epoch 13 - iter 328/414 - loss 0.12215718 - samples/sec: 137.80 - lr: 0.000030
2021-07-24 09:30:37,092 epoch 13 - iter 369/414 - loss 0.12123319 - samples/sec: 137.56 - lr: 0.000030
2021-07-24 09:30:46,776 epoch 13 - iter 410/414 - loss 0.12229298 - samples/sec: 135.51 - lr: 0.000030
2021-07-24 09:30:47,688 ----------------------------------------------------------------------------------------------------
2021-07-24 09:30:47,688 EPOCH 13 done: loss 0.1220 - lr 0.0000300
2021-07-24 09:30:53,887 DEV : loss 0.060987528413534164 - score 0.9879
2021-07-24 09:30:53,957 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:30:56,210 ----------------------------------------------------------------------------------------------------
2021-07-24 09:31:05,939 epoch 14 - iter 41/414 - loss 0.11464681 - samples/sec: 134.93 - lr: 0.000030
2021-07-24 09:31:15,537 epoch 14 - iter 82/414 - loss 0.10776093 - samples/sec: 136.73 - lr: 0.000030
2021-07-24 09:31:25,124 epoch 14 - iter 123/414 - loss 0.12010583 - samples/sec: 136.88 - lr: 0.000030
2021-07-24 09:31:34,802 epoch 14 - iter 164/414 - loss 0.12228739 - samples/sec: 135.59 - lr: 0.000030
2021-07-24 09:31:44,411 epoch 14 - iter 205/414 - loss 0.11928334 - samples/sec: 136.57 - lr: 0.000030
2021-07-24 09:31:54,007 epoch 14 - iter 246/414 - loss 0.11717118 - samples/sec: 136.75 - lr: 0.000030
2021-07-24 09:32:03,616 epoch 14 - iter 287/414 - loss 0.11491342 - samples/sec: 136.57 - lr: 0.000030
2021-07-24 09:32:13,354 epoch 14 - iter 328/414 - loss 0.11684515 - samples/sec: 134.76 - lr: 0.000030
2021-07-24 09:32:23,009 epoch 14 - iter 369/414 - loss 0.11563706 - samples/sec: 135.92 - lr: 0.000030
2021-07-24 09:32:32,664 epoch 14 - iter 410/414 - loss 0.11447926 - samples/sec: 135.93 - lr: 0.000030
2021-07-24 09:32:33,543 ----------------------------------------------------------------------------------------------------
2021-07-24 09:32:33,543 EPOCH 14 done: loss 0.1138 - lr 0.0000300
2021-07-24 09:32:39,721 DEV : loss 0.05851483717560768 - score 0.9887
2021-07-24 09:32:39,792 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:32:42,007 ----------------------------------------------------------------------------------------------------
2021-07-24 09:32:52,129 epoch 15 - iter 41/414 - loss 0.08145658 - samples/sec: 129.68 - lr: 0.000030
2021-07-24 09:33:01,886 epoch 15 - iter 82/414 - loss 0.09282688 - samples/sec: 134.50 - lr: 0.000030
2021-07-24 09:33:11,676 epoch 15 - iter 123/414 - loss 0.09372698 - samples/sec: 134.04 - lr: 0.000030
2021-07-24 09:33:21,159 epoch 15 - iter 164/414 - loss 0.09584402 - samples/sec: 138.38 - lr: 0.000030
2021-07-24 09:33:30,764 epoch 15 - iter 205/414 - loss 0.09614781 - samples/sec: 136.63 - lr: 0.000030
2021-07-24 09:33:40,288 epoch 15 - iter 246/414 - loss 0.09511143 - samples/sec: 137.79 - lr: 0.000030
2021-07-24 09:33:50,212 epoch 15 - iter 287/414 - loss 0.09928866 - samples/sec: 132.23 - lr: 0.000030
2021-07-24 09:33:59,844 epoch 15 - iter 328/414 - loss 0.10174396 - samples/sec: 136.25 - lr: 0.000030
2021-07-24 09:34:09,345 epoch 15 - iter 369/414 - loss 0.10392115 - samples/sec: 138.12 - lr: 0.000030
2021-07-24 09:34:19,057 epoch 15 - iter 410/414 - loss 0.10379047 - samples/sec: 135.11 - lr: 0.000030
2021-07-24 09:34:19,868 ----------------------------------------------------------------------------------------------------
2021-07-24 09:34:19,868 EPOCH 15 done: loss 0.1033 - lr 0.0000300
2021-07-24 09:34:26,060 DEV : loss 0.057331863790750504 - score 0.9884
2021-07-24 09:34:26,131 BAD EPOCHS (no improvement): 1
2021-07-24 09:34:26,131 ----------------------------------------------------------------------------------------------------
2021-07-24 09:34:35,632 epoch 16 - iter 41/414 - loss 0.06961117 - samples/sec: 138.14 - lr: 0.000030
2021-07-24 09:34:45,165 epoch 16 - iter 82/414 - loss 0.09187644 - samples/sec: 137.67 - lr: 0.000030
2021-07-24 09:34:54,904 epoch 16 - iter 123/414 - loss 0.09470401 - samples/sec: 134.74 - lr: 0.000030
2021-07-24 09:35:04,572 epoch 16 - iter 164/414 - loss 0.09396686 - samples/sec: 135.74 - lr: 0.000030
2021-07-24 09:35:14,032 epoch 16 - iter 205/414 - loss 0.09521648 - samples/sec: 138.72 - lr: 0.000030
2021-07-24 09:35:23,781 epoch 16 - iter 246/414 - loss 0.09589370 - samples/sec: 134.60 - lr: 0.000030
2021-07-24 09:35:33,669 epoch 16 - iter 287/414 - loss 0.09626273 - samples/sec: 132.71 - lr: 0.000030
2021-07-24 09:35:43,252 epoch 16 - iter 328/414 - loss 0.09583714 - samples/sec: 136.95 - lr: 0.000030
2021-07-24 09:35:52,828 epoch 16 - iter 369/414 - loss 0.09684600 - samples/sec: 137.03 - lr: 0.000030
2021-07-24 09:36:02,508 epoch 16 - iter 410/414 - loss 0.09742081 - samples/sec: 135.57 - lr: 0.000030
2021-07-24 09:36:03,343 ----------------------------------------------------------------------------------------------------
2021-07-24 09:36:03,344 EPOCH 16 done: loss 0.0974 - lr 0.0000300
2021-07-24 09:36:09,514 DEV : loss 0.061547912657260895 - score 0.9862
2021-07-24 09:36:09,584 BAD EPOCHS (no improvement): 2
2021-07-24 09:36:09,584 ----------------------------------------------------------------------------------------------------
2021-07-24 09:36:19,240 epoch 17 - iter 41/414 - loss 0.07196780 - samples/sec: 135.93 - lr: 0.000030
2021-07-24 09:36:29,120 epoch 17 - iter 82/414 - loss 0.08271391 - samples/sec: 132.83 - lr: 0.000030
2021-07-24 09:36:38,804 epoch 17 - iter 123/414 - loss 0.07846258 - samples/sec: 135.51 - lr: 0.000030
2021-07-24 09:36:48,328 epoch 17 - iter 164/414 - loss 0.08547004 - samples/sec: 137.80 - lr: 0.000030
2021-07-24 09:36:58,212 epoch 17 - iter 205/414 - loss 0.08626211 - samples/sec: 132.76 - lr: 0.000030
2021-07-24 09:37:07,816 epoch 17 - iter 246/414 - loss 0.08685583 - samples/sec: 136.65 - lr: 0.000030
2021-07-24 09:37:17,234 epoch 17 - iter 287/414 - loss 0.08737485 - samples/sec: 139.33 - lr: 0.000030
2021-07-24 09:37:26,704 epoch 17 - iter 328/414 - loss 0.08612055 - samples/sec: 138.58 - lr: 0.000030
2021-07-24 09:37:36,134 epoch 17 - iter 369/414 - loss 0.08691478 - samples/sec: 139.17 - lr: 0.000030
2021-07-24 09:37:45,749 epoch 17 - iter 410/414 - loss 0.08785376 - samples/sec: 136.48 - lr: 0.000030
2021-07-24 09:37:46,562 ----------------------------------------------------------------------------------------------------
2021-07-24 09:37:46,562 EPOCH 17 done: loss 0.0877 - lr 0.0000300
2021-07-24 09:37:52,729 DEV : loss 0.05817339941859245 - score 0.9879
2021-07-24 09:37:52,799 BAD EPOCHS (no improvement): 3
2021-07-24 09:37:52,800 ----------------------------------------------------------------------------------------------------
2021-07-24 09:38:02,367 epoch 18 - iter 41/414 - loss 0.08161954 - samples/sec: 137.19 - lr: 0.000030
2021-07-24 09:38:12,057 epoch 18 - iter 82/414 - loss 0.07279926 - samples/sec: 135.42 - lr: 0.000030
2021-07-24 09:38:21,748 epoch 18 - iter 123/414 - loss 0.07683760 - samples/sec: 135.41 - lr: 0.000030
2021-07-24 09:38:31,431 epoch 18 - iter 164/414 - loss 0.07908355 - samples/sec: 135.53 - lr: 0.000030
2021-07-24 09:38:41,033 epoch 18 - iter 205/414 - loss 0.07850999 - samples/sec: 136.66 - lr: 0.000030
2021-07-24 09:38:50,668 epoch 18 - iter 246/414 - loss 0.08205111 - samples/sec: 136.20 - lr: 0.000030
2021-07-24 09:39:00,110 epoch 18 - iter 287/414 - loss 0.08241309 - samples/sec: 139.00 - lr: 0.000030
2021-07-24 09:39:09,508 epoch 18 - iter 328/414 - loss 0.08365451 - samples/sec: 139.63 - lr: 0.000030
2021-07-24 09:39:19,341 epoch 18 - iter 369/414 - loss 0.08479622 - samples/sec: 133.45 - lr: 0.000030
2021-07-24 09:39:28,868 epoch 18 - iter 410/414 - loss 0.08340937 - samples/sec: 137.75 - lr: 0.000030
2021-07-24 09:39:29,706 ----------------------------------------------------------------------------------------------------
2021-07-24 09:39:29,707 EPOCH 18 done: loss 0.0831 - lr 0.0000300
2021-07-24 09:39:35,877 DEV : loss 0.060936953872442245 - score 0.9873
Epoch    18: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 09:39:35,947 BAD EPOCHS (no improvement): 4
2021-07-24 09:39:35,947 ----------------------------------------------------------------------------------------------------
2021-07-24 09:39:45,881 epoch 19 - iter 41/414 - loss 0.09858487 - samples/sec: 132.13 - lr: 0.000015
2021-07-24 09:39:55,357 epoch 19 - iter 82/414 - loss 0.09149799 - samples/sec: 138.49 - lr: 0.000015
2021-07-24 09:40:04,950 epoch 19 - iter 123/414 - loss 0.09196222 - samples/sec: 136.79 - lr: 0.000015
2021-07-24 09:40:14,587 epoch 19 - iter 164/414 - loss 0.09016233 - samples/sec: 136.17 - lr: 0.000015
2021-07-24 09:40:24,264 epoch 19 - iter 205/414 - loss 0.08965081 - samples/sec: 135.61 - lr: 0.000015
2021-07-24 09:40:33,804 epoch 19 - iter 246/414 - loss 0.08755401 - samples/sec: 137.55 - lr: 0.000015
2021-07-24 09:40:43,307 epoch 19 - iter 287/414 - loss 0.08298708 - samples/sec: 138.10 - lr: 0.000015
2021-07-24 09:40:52,967 epoch 19 - iter 328/414 - loss 0.08225193 - samples/sec: 135.85 - lr: 0.000015
2021-07-24 09:41:02,767 epoch 19 - iter 369/414 - loss 0.08167960 - samples/sec: 133.91 - lr: 0.000015
2021-07-24 09:41:12,557 epoch 19 - iter 410/414 - loss 0.08356223 - samples/sec: 134.05 - lr: 0.000015
2021-07-24 09:41:13,369 ----------------------------------------------------------------------------------------------------
2021-07-24 09:41:13,370 EPOCH 19 done: loss 0.0835 - lr 0.0000150
2021-07-24 09:41:19,555 DEV : loss 0.0585617870092392 - score 0.9881
2021-07-24 09:41:19,626 BAD EPOCHS (no improvement): 1
2021-07-24 09:41:19,626 ----------------------------------------------------------------------------------------------------
2021-07-24 09:41:29,280 epoch 20 - iter 41/414 - loss 0.05973832 - samples/sec: 135.96 - lr: 0.000015
2021-07-24 09:41:38,969 epoch 20 - iter 82/414 - loss 0.06789935 - samples/sec: 135.43 - lr: 0.000015
2021-07-24 09:41:48,456 epoch 20 - iter 123/414 - loss 0.07356396 - samples/sec: 138.34 - lr: 0.000015
2021-07-24 09:41:58,225 epoch 20 - iter 164/414 - loss 0.07691660 - samples/sec: 134.33 - lr: 0.000015
2021-07-24 09:42:07,841 epoch 20 - iter 205/414 - loss 0.07602234 - samples/sec: 136.47 - lr: 0.000015
2021-07-24 09:42:17,256 epoch 20 - iter 246/414 - loss 0.07738916 - samples/sec: 139.37 - lr: 0.000015
2021-07-24 09:42:26,875 epoch 20 - iter 287/414 - loss 0.07804335 - samples/sec: 136.44 - lr: 0.000015
2021-07-24 09:42:36,472 epoch 20 - iter 328/414 - loss 0.08072882 - samples/sec: 136.74 - lr: 0.000015
2021-07-24 09:42:46,259 epoch 20 - iter 369/414 - loss 0.08011087 - samples/sec: 134.08 - lr: 0.000015
2021-07-24 09:42:56,050 epoch 20 - iter 410/414 - loss 0.07927954 - samples/sec: 134.04 - lr: 0.000015
2021-07-24 09:42:56,886 ----------------------------------------------------------------------------------------------------
2021-07-24 09:42:56,886 EPOCH 20 done: loss 0.0794 - lr 0.0000150
2021-07-24 09:43:03,062 DEV : loss 0.05805085599422455 - score 0.9879
2021-07-24 09:43:03,133 BAD EPOCHS (no improvement): 2
2021-07-24 09:43:03,134 ----------------------------------------------------------------------------------------------------
2021-07-24 09:43:12,848 epoch 21 - iter 41/414 - loss 0.09364637 - samples/sec: 135.10 - lr: 0.000015
2021-07-24 09:43:22,680 epoch 21 - iter 82/414 - loss 0.08534850 - samples/sec: 133.48 - lr: 0.000015
2021-07-24 09:43:32,023 epoch 21 - iter 123/414 - loss 0.08466448 - samples/sec: 140.45 - lr: 0.000015
2021-07-24 09:43:41,733 epoch 21 - iter 164/414 - loss 0.08411125 - samples/sec: 135.16 - lr: 0.000015
2021-07-24 09:43:51,329 epoch 21 - iter 205/414 - loss 0.08244895 - samples/sec: 136.75 - lr: 0.000015
2021-07-24 09:44:01,108 epoch 21 - iter 246/414 - loss 0.08035719 - samples/sec: 134.20 - lr: 0.000015
2021-07-24 09:44:10,628 epoch 21 - iter 287/414 - loss 0.08059258 - samples/sec: 137.84 - lr: 0.000015
2021-07-24 09:44:20,197 epoch 21 - iter 328/414 - loss 0.07843688 - samples/sec: 137.15 - lr: 0.000015
2021-07-24 09:44:29,969 epoch 21 - iter 369/414 - loss 0.07921083 - samples/sec: 134.28 - lr: 0.000015
2021-07-24 09:44:39,548 epoch 21 - iter 410/414 - loss 0.07868044 - samples/sec: 137.00 - lr: 0.000015
2021-07-24 09:44:40,358 ----------------------------------------------------------------------------------------------------
2021-07-24 09:44:40,358 EPOCH 21 done: loss 0.0780 - lr 0.0000150
2021-07-24 09:44:46,521 DEV : loss 0.058977141976356506 - score 0.9884
2021-07-24 09:44:46,592 BAD EPOCHS (no improvement): 3
2021-07-24 09:44:46,592 ----------------------------------------------------------------------------------------------------
2021-07-24 09:44:56,175 epoch 22 - iter 41/414 - loss 0.06366357 - samples/sec: 136.97 - lr: 0.000015
2021-07-24 09:45:05,678 epoch 22 - iter 82/414 - loss 0.06799790 - samples/sec: 138.10 - lr: 0.000015
2021-07-24 09:45:15,201 epoch 22 - iter 123/414 - loss 0.07593496 - samples/sec: 137.80 - lr: 0.000015
2021-07-24 09:45:24,833 epoch 22 - iter 164/414 - loss 0.07815468 - samples/sec: 136.23 - lr: 0.000015
2021-07-24 09:45:34,263 epoch 22 - iter 205/414 - loss 0.07785694 - samples/sec: 139.17 - lr: 0.000015
2021-07-24 09:45:43,996 epoch 22 - iter 246/414 - loss 0.07843234 - samples/sec: 134.82 - lr: 0.000015
2021-07-24 09:45:53,884 epoch 22 - iter 287/414 - loss 0.07756966 - samples/sec: 132.72 - lr: 0.000015
2021-07-24 09:46:03,647 epoch 22 - iter 328/414 - loss 0.07779034 - samples/sec: 134.41 - lr: 0.000015
2021-07-24 09:46:13,312 epoch 22 - iter 369/414 - loss 0.07528025 - samples/sec: 135.78 - lr: 0.000015
2021-07-24 09:46:22,912 epoch 22 - iter 410/414 - loss 0.07557412 - samples/sec: 136.69 - lr: 0.000015
2021-07-24 09:46:23,766 ----------------------------------------------------------------------------------------------------
2021-07-24 09:46:23,766 EPOCH 22 done: loss 0.0755 - lr 0.0000150
2021-07-24 09:46:29,938 DEV : loss 0.05812440812587738 - score 0.9884
Epoch    22: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 09:46:30,009 BAD EPOCHS (no improvement): 4
2021-07-24 09:46:30,009 ----------------------------------------------------------------------------------------------------
2021-07-24 09:46:39,981 epoch 23 - iter 41/414 - loss 0.07647750 - samples/sec: 131.63 - lr: 0.000008
2021-07-24 09:46:49,571 epoch 23 - iter 82/414 - loss 0.07443528 - samples/sec: 136.84 - lr: 0.000008
2021-07-24 09:46:59,278 epoch 23 - iter 123/414 - loss 0.07684099 - samples/sec: 135.19 - lr: 0.000008
2021-07-24 09:47:08,816 epoch 23 - iter 164/414 - loss 0.07830916 - samples/sec: 137.58 - lr: 0.000008
2021-07-24 09:47:18,483 epoch 23 - iter 205/414 - loss 0.07334857 - samples/sec: 135.75 - lr: 0.000008
2021-07-24 09:47:28,137 epoch 23 - iter 246/414 - loss 0.07345927 - samples/sec: 135.93 - lr: 0.000008
2021-07-24 09:47:37,855 epoch 23 - iter 287/414 - loss 0.07235184 - samples/sec: 135.04 - lr: 0.000008
2021-07-24 09:47:47,484 epoch 23 - iter 328/414 - loss 0.07230702 - samples/sec: 136.28 - lr: 0.000008
2021-07-24 09:47:57,040 epoch 23 - iter 369/414 - loss 0.07272891 - samples/sec: 137.33 - lr: 0.000008
2021-07-24 09:48:06,869 epoch 23 - iter 410/414 - loss 0.07142414 - samples/sec: 133.52 - lr: 0.000008
2021-07-24 09:48:07,723 ----------------------------------------------------------------------------------------------------
2021-07-24 09:48:07,724 EPOCH 23 done: loss 0.0721 - lr 0.0000075
2021-07-24 09:48:13,896 DEV : loss 0.05819213390350342 - score 0.9879
2021-07-24 09:48:13,967 BAD EPOCHS (no improvement): 1
2021-07-24 09:48:13,967 ----------------------------------------------------------------------------------------------------
2021-07-24 09:48:23,392 epoch 24 - iter 41/414 - loss 0.09136212 - samples/sec: 139.26 - lr: 0.000008
2021-07-24 09:48:33,077 epoch 24 - iter 82/414 - loss 0.08113832 - samples/sec: 135.50 - lr: 0.000008
2021-07-24 09:48:42,764 epoch 24 - iter 123/414 - loss 0.08140766 - samples/sec: 135.47 - lr: 0.000008
2021-07-24 09:48:52,297 epoch 24 - iter 164/414 - loss 0.07959407 - samples/sec: 137.67 - lr: 0.000008
2021-07-24 09:49:01,820 epoch 24 - iter 205/414 - loss 0.07934446 - samples/sec: 137.79 - lr: 0.000008
2021-07-24 09:49:11,715 epoch 24 - iter 246/414 - loss 0.07790973 - samples/sec: 132.62 - lr: 0.000008
2021-07-24 09:49:21,409 epoch 24 - iter 287/414 - loss 0.07555297 - samples/sec: 135.38 - lr: 0.000008
2021-07-24 09:49:31,192 epoch 24 - iter 328/414 - loss 0.07157319 - samples/sec: 134.13 - lr: 0.000008
2021-07-24 09:49:40,785 epoch 24 - iter 369/414 - loss 0.07138143 - samples/sec: 136.80 - lr: 0.000008
2021-07-24 09:49:50,350 epoch 24 - iter 410/414 - loss 0.07011198 - samples/sec: 137.20 - lr: 0.000008
2021-07-24 09:49:51,217 ----------------------------------------------------------------------------------------------------
2021-07-24 09:49:51,217 EPOCH 24 done: loss 0.0704 - lr 0.0000075
2021-07-24 09:49:57,386 DEV : loss 0.057619430124759674 - score 0.989
2021-07-24 09:49:57,458 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:49:59,713 ----------------------------------------------------------------------------------------------------
2021-07-24 09:50:09,348 epoch 25 - iter 41/414 - loss 0.07312135 - samples/sec: 136.24 - lr: 0.000008
2021-07-24 09:50:19,143 epoch 25 - iter 82/414 - loss 0.06762130 - samples/sec: 133.98 - lr: 0.000008
2021-07-24 09:50:29,080 epoch 25 - iter 123/414 - loss 0.07800328 - samples/sec: 132.06 - lr: 0.000008
2021-07-24 09:50:38,651 epoch 25 - iter 164/414 - loss 0.07593476 - samples/sec: 137.12 - lr: 0.000008
2021-07-24 09:50:48,260 epoch 25 - iter 205/414 - loss 0.07435954 - samples/sec: 136.57 - lr: 0.000008
2021-07-24 09:50:57,875 epoch 25 - iter 246/414 - loss 0.07486263 - samples/sec: 136.49 - lr: 0.000008
2021-07-24 09:51:07,357 epoch 25 - iter 287/414 - loss 0.07697139 - samples/sec: 138.40 - lr: 0.000008
2021-07-24 09:51:16,955 epoch 25 - iter 328/414 - loss 0.07508505 - samples/sec: 136.73 - lr: 0.000008
2021-07-24 09:51:26,569 epoch 25 - iter 369/414 - loss 0.07555485 - samples/sec: 136.49 - lr: 0.000008
2021-07-24 09:51:36,014 epoch 25 - iter 410/414 - loss 0.07823162 - samples/sec: 138.95 - lr: 0.000008
2021-07-24 09:51:36,867 ----------------------------------------------------------------------------------------------------
2021-07-24 09:51:36,867 EPOCH 25 done: loss 0.0779 - lr 0.0000075
2021-07-24 09:51:43,032 DEV : loss 0.05728434771299362 - score 0.9884
2021-07-24 09:51:43,103 BAD EPOCHS (no improvement): 1
2021-07-24 09:51:43,103 ----------------------------------------------------------------------------------------------------
2021-07-24 09:51:52,548 epoch 26 - iter 41/414 - loss 0.05981037 - samples/sec: 138.98 - lr: 0.000008
2021-07-24 09:52:02,101 epoch 26 - iter 82/414 - loss 0.06231924 - samples/sec: 137.37 - lr: 0.000008
2021-07-24 09:52:11,873 epoch 26 - iter 123/414 - loss 0.06699213 - samples/sec: 134.30 - lr: 0.000008
2021-07-24 09:52:21,699 epoch 26 - iter 164/414 - loss 0.06935499 - samples/sec: 133.55 - lr: 0.000008
2021-07-24 09:52:31,297 epoch 26 - iter 205/414 - loss 0.07183368 - samples/sec: 136.72 - lr: 0.000008
2021-07-24 09:52:41,004 epoch 26 - iter 246/414 - loss 0.07340026 - samples/sec: 135.19 - lr: 0.000008
2021-07-24 09:52:50,597 epoch 26 - iter 287/414 - loss 0.07285257 - samples/sec: 136.80 - lr: 0.000008
2021-07-24 09:53:00,220 epoch 26 - iter 328/414 - loss 0.07222120 - samples/sec: 136.38 - lr: 0.000008
2021-07-24 09:53:09,837 epoch 26 - iter 369/414 - loss 0.07140364 - samples/sec: 136.46 - lr: 0.000008
2021-07-24 09:53:19,463 epoch 26 - iter 410/414 - loss 0.07224962 - samples/sec: 136.32 - lr: 0.000008
2021-07-24 09:53:20,314 ----------------------------------------------------------------------------------------------------
2021-07-24 09:53:20,314 EPOCH 26 done: loss 0.0719 - lr 0.0000075
2021-07-24 09:53:26,498 DEV : loss 0.05668018385767937 - score 0.9887
2021-07-24 09:53:26,569 BAD EPOCHS (no improvement): 2
2021-07-24 09:53:26,570 ----------------------------------------------------------------------------------------------------
2021-07-24 09:53:36,831 epoch 27 - iter 41/414 - loss 0.08616945 - samples/sec: 127.91 - lr: 0.000008
2021-07-24 09:53:46,341 epoch 27 - iter 82/414 - loss 0.07250768 - samples/sec: 137.99 - lr: 0.000008
2021-07-24 09:53:55,900 epoch 27 - iter 123/414 - loss 0.07586699 - samples/sec: 137.28 - lr: 0.000008
2021-07-24 09:54:05,680 epoch 27 - iter 164/414 - loss 0.07357942 - samples/sec: 134.19 - lr: 0.000008
2021-07-24 09:54:15,167 epoch 27 - iter 205/414 - loss 0.07601148 - samples/sec: 138.33 - lr: 0.000008
2021-07-24 09:54:24,825 epoch 27 - iter 246/414 - loss 0.07668946 - samples/sec: 135.88 - lr: 0.000008
2021-07-24 09:54:34,586 epoch 27 - iter 287/414 - loss 0.07801592 - samples/sec: 134.44 - lr: 0.000008
2021-07-24 09:54:44,057 epoch 27 - iter 328/414 - loss 0.07803449 - samples/sec: 138.55 - lr: 0.000008
2021-07-24 09:54:54,011 epoch 27 - iter 369/414 - loss 0.07448434 - samples/sec: 131.84 - lr: 0.000008
2021-07-24 09:55:03,563 epoch 27 - iter 410/414 - loss 0.07446269 - samples/sec: 137.39 - lr: 0.000008
2021-07-24 09:55:04,338 ----------------------------------------------------------------------------------------------------
2021-07-24 09:55:04,338 EPOCH 27 done: loss 0.0740 - lr 0.0000075
2021-07-24 09:55:10,509 DEV : loss 0.057446252554655075 - score 0.9887
2021-07-24 09:55:10,579 BAD EPOCHS (no improvement): 3
2021-07-24 09:55:10,579 ----------------------------------------------------------------------------------------------------
2021-07-24 09:55:20,249 epoch 28 - iter 41/414 - loss 0.07137657 - samples/sec: 135.74 - lr: 0.000008
2021-07-24 09:55:30,044 epoch 28 - iter 82/414 - loss 0.07388930 - samples/sec: 133.97 - lr: 0.000008
2021-07-24 09:55:39,884 epoch 28 - iter 123/414 - loss 0.07819247 - samples/sec: 133.35 - lr: 0.000008
2021-07-24 09:55:49,377 epoch 28 - iter 164/414 - loss 0.07292122 - samples/sec: 138.25 - lr: 0.000008
2021-07-24 09:55:58,951 epoch 28 - iter 205/414 - loss 0.07229380 - samples/sec: 137.07 - lr: 0.000008
2021-07-24 09:56:08,617 epoch 28 - iter 246/414 - loss 0.07392703 - samples/sec: 135.76 - lr: 0.000008
2021-07-24 09:56:18,278 epoch 28 - iter 287/414 - loss 0.07470762 - samples/sec: 135.84 - lr: 0.000008
2021-07-24 09:56:27,741 epoch 28 - iter 328/414 - loss 0.07455473 - samples/sec: 138.67 - lr: 0.000008
2021-07-24 09:56:37,496 epoch 28 - iter 369/414 - loss 0.07546640 - samples/sec: 134.53 - lr: 0.000008
2021-07-24 09:56:47,036 epoch 28 - iter 410/414 - loss 0.07469764 - samples/sec: 137.56 - lr: 0.000008
2021-07-24 09:56:47,855 ----------------------------------------------------------------------------------------------------
2021-07-24 09:56:47,855 EPOCH 28 done: loss 0.0744 - lr 0.0000075
2021-07-24 09:56:54,032 DEV : loss 0.05704165995121002 - score 0.9892
2021-07-24 09:56:54,101 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 09:56:56,414 ----------------------------------------------------------------------------------------------------
2021-07-24 09:57:06,134 epoch 29 - iter 41/414 - loss 0.07315432 - samples/sec: 135.04 - lr: 0.000008
2021-07-24 09:57:15,533 epoch 29 - iter 82/414 - loss 0.06670404 - samples/sec: 139.64 - lr: 0.000008
2021-07-24 09:57:25,256 epoch 29 - iter 123/414 - loss 0.06869495 - samples/sec: 134.96 - lr: 0.000008
2021-07-24 09:57:35,204 epoch 29 - iter 164/414 - loss 0.06663521 - samples/sec: 131.92 - lr: 0.000008
2021-07-24 09:57:44,667 epoch 29 - iter 205/414 - loss 0.06684478 - samples/sec: 138.67 - lr: 0.000008
2021-07-24 09:57:54,329 epoch 29 - iter 246/414 - loss 0.06952232 - samples/sec: 135.83 - lr: 0.000008
2021-07-24 09:58:04,049 epoch 29 - iter 287/414 - loss 0.07080730 - samples/sec: 135.01 - lr: 0.000008
2021-07-24 09:58:13,655 epoch 29 - iter 328/414 - loss 0.07021656 - samples/sec: 136.61 - lr: 0.000008
2021-07-24 09:58:23,251 epoch 29 - iter 369/414 - loss 0.06888040 - samples/sec: 136.75 - lr: 0.000008
2021-07-24 09:58:32,857 epoch 29 - iter 410/414 - loss 0.06833994 - samples/sec: 136.61 - lr: 0.000008
2021-07-24 09:58:33,698 ----------------------------------------------------------------------------------------------------
2021-07-24 09:58:33,698 EPOCH 29 done: loss 0.0680 - lr 0.0000075
2021-07-24 09:58:39,873 DEV : loss 0.0574471689760685 - score 0.9887
2021-07-24 09:58:39,944 BAD EPOCHS (no improvement): 1
2021-07-24 09:58:39,944 ----------------------------------------------------------------------------------------------------
2021-07-24 09:58:49,617 epoch 30 - iter 41/414 - loss 0.06609140 - samples/sec: 135.69 - lr: 0.000008
2021-07-24 09:58:59,073 epoch 30 - iter 82/414 - loss 0.06438234 - samples/sec: 138.78 - lr: 0.000008
2021-07-24 09:59:08,740 epoch 30 - iter 123/414 - loss 0.06860112 - samples/sec: 135.75 - lr: 0.000008
2021-07-24 09:59:18,269 epoch 30 - iter 164/414 - loss 0.06890994 - samples/sec: 137.71 - lr: 0.000008
2021-07-24 09:59:27,891 epoch 30 - iter 205/414 - loss 0.07255309 - samples/sec: 136.39 - lr: 0.000008
2021-07-24 09:59:37,519 epoch 30 - iter 246/414 - loss 0.07273412 - samples/sec: 136.30 - lr: 0.000008
2021-07-24 09:59:47,332 epoch 30 - iter 287/414 - loss 0.07044598 - samples/sec: 133.74 - lr: 0.000008
2021-07-24 09:59:56,973 epoch 30 - iter 328/414 - loss 0.06924330 - samples/sec: 136.12 - lr: 0.000008
2021-07-24 10:00:06,648 epoch 30 - iter 369/414 - loss 0.07089928 - samples/sec: 135.64 - lr: 0.000008
2021-07-24 10:00:16,320 epoch 30 - iter 410/414 - loss 0.07155381 - samples/sec: 135.67 - lr: 0.000008
2021-07-24 10:00:17,187 ----------------------------------------------------------------------------------------------------
2021-07-24 10:00:17,187 EPOCH 30 done: loss 0.0712 - lr 0.0000075
2021-07-24 10:00:23,357 DEV : loss 0.05668739974498749 - score 0.9884
2021-07-24 10:00:23,428 BAD EPOCHS (no improvement): 2
2021-07-24 10:00:23,428 ----------------------------------------------------------------------------------------------------
2021-07-24 10:00:33,406 epoch 31 - iter 41/414 - loss 0.07726956 - samples/sec: 131.54 - lr: 0.000008
2021-07-24 10:00:42,992 epoch 31 - iter 82/414 - loss 0.07576176 - samples/sec: 136.90 - lr: 0.000008
2021-07-24 10:00:52,568 epoch 31 - iter 123/414 - loss 0.07384348 - samples/sec: 137.04 - lr: 0.000008
2021-07-24 10:01:02,051 epoch 31 - iter 164/414 - loss 0.07255987 - samples/sec: 138.39 - lr: 0.000008
2021-07-24 10:01:11,844 epoch 31 - iter 205/414 - loss 0.07122544 - samples/sec: 133.99 - lr: 0.000008
2021-07-24 10:01:21,437 epoch 31 - iter 246/414 - loss 0.07151764 - samples/sec: 136.80 - lr: 0.000008
2021-07-24 10:01:31,213 epoch 31 - iter 287/414 - loss 0.07200973 - samples/sec: 134.23 - lr: 0.000008
2021-07-24 10:01:40,822 epoch 31 - iter 328/414 - loss 0.07158217 - samples/sec: 136.58 - lr: 0.000008
2021-07-24 10:01:50,600 epoch 31 - iter 369/414 - loss 0.07004160 - samples/sec: 134.20 - lr: 0.000008
2021-07-24 10:02:00,273 epoch 31 - iter 410/414 - loss 0.07045490 - samples/sec: 135.67 - lr: 0.000008
2021-07-24 10:02:01,122 ----------------------------------------------------------------------------------------------------
2021-07-24 10:02:01,122 EPOCH 31 done: loss 0.0702 - lr 0.0000075
2021-07-24 10:02:07,289 DEV : loss 0.05676542595028877 - score 0.9884
2021-07-24 10:02:07,360 BAD EPOCHS (no improvement): 3
2021-07-24 10:02:07,360 ----------------------------------------------------------------------------------------------------
2021-07-24 10:02:16,907 epoch 32 - iter 41/414 - loss 0.06002094 - samples/sec: 137.49 - lr: 0.000008
2021-07-24 10:02:26,367 epoch 32 - iter 82/414 - loss 0.05892633 - samples/sec: 138.71 - lr: 0.000008
2021-07-24 10:02:36,009 epoch 32 - iter 123/414 - loss 0.06143920 - samples/sec: 136.11 - lr: 0.000008
2021-07-24 10:02:45,757 epoch 32 - iter 164/414 - loss 0.06224701 - samples/sec: 134.63 - lr: 0.000008
2021-07-24 10:02:55,409 epoch 32 - iter 205/414 - loss 0.06272308 - samples/sec: 135.96 - lr: 0.000008
2021-07-24 10:03:05,036 epoch 32 - iter 246/414 - loss 0.06319596 - samples/sec: 136.31 - lr: 0.000008
2021-07-24 10:03:14,956 epoch 32 - iter 287/414 - loss 0.06676301 - samples/sec: 132.29 - lr: 0.000008
2021-07-24 10:03:24,649 epoch 32 - iter 328/414 - loss 0.06785980 - samples/sec: 135.39 - lr: 0.000008
2021-07-24 10:03:34,434 epoch 32 - iter 369/414 - loss 0.06865322 - samples/sec: 134.12 - lr: 0.000008
2021-07-24 10:03:44,157 epoch 32 - iter 410/414 - loss 0.06959524 - samples/sec: 134.96 - lr: 0.000008
2021-07-24 10:03:44,967 ----------------------------------------------------------------------------------------------------
2021-07-24 10:03:44,968 EPOCH 32 done: loss 0.0692 - lr 0.0000075
2021-07-24 10:03:51,160 DEV : loss 0.05642673745751381 - score 0.9887
Epoch    32: reducing learning rate of group 0 to 3.7500e-06.
2021-07-24 10:03:51,233 BAD EPOCHS (no improvement): 4
2021-07-24 10:03:51,233 ----------------------------------------------------------------------------------------------------
2021-07-24 10:04:00,816 epoch 33 - iter 41/414 - loss 0.06704758 - samples/sec: 136.96 - lr: 0.000004
2021-07-24 10:04:10,359 epoch 33 - iter 82/414 - loss 0.07503871 - samples/sec: 137.51 - lr: 0.000004
2021-07-24 10:04:20,002 epoch 33 - iter 123/414 - loss 0.07344485 - samples/sec: 136.08 - lr: 0.000004
2021-07-24 10:04:29,644 epoch 33 - iter 164/414 - loss 0.07387054 - samples/sec: 136.10 - lr: 0.000004
2021-07-24 10:04:39,399 epoch 33 - iter 205/414 - loss 0.07296530 - samples/sec: 134.53 - lr: 0.000004
2021-07-24 10:04:49,003 epoch 33 - iter 246/414 - loss 0.07467911 - samples/sec: 136.64 - lr: 0.000004
2021-07-24 10:04:58,826 epoch 33 - iter 287/414 - loss 0.07016613 - samples/sec: 133.60 - lr: 0.000004
2021-07-24 10:05:08,313 epoch 33 - iter 328/414 - loss 0.06846137 - samples/sec: 138.32 - lr: 0.000004
2021-07-24 10:05:18,065 epoch 33 - iter 369/414 - loss 0.06873673 - samples/sec: 134.57 - lr: 0.000004
2021-07-24 10:05:27,646 epoch 33 - iter 410/414 - loss 0.06668059 - samples/sec: 136.97 - lr: 0.000004
2021-07-24 10:05:28,490 ----------------------------------------------------------------------------------------------------
2021-07-24 10:05:28,491 EPOCH 33 done: loss 0.0678 - lr 0.0000038
2021-07-24 10:05:34,669 DEV : loss 0.056819356977939606 - score 0.989
2021-07-24 10:05:34,740 BAD EPOCHS (no improvement): 1
2021-07-24 10:05:34,741 ----------------------------------------------------------------------------------------------------
2021-07-24 10:05:44,503 epoch 34 - iter 41/414 - loss 0.06839596 - samples/sec: 134.45 - lr: 0.000004
2021-07-24 10:05:53,839 epoch 34 - iter 82/414 - loss 0.07095544 - samples/sec: 140.57 - lr: 0.000004
2021-07-24 10:06:03,700 epoch 34 - iter 123/414 - loss 0.07005037 - samples/sec: 133.07 - lr: 0.000004
2021-07-24 10:06:13,301 epoch 34 - iter 164/414 - loss 0.07035288 - samples/sec: 136.69 - lr: 0.000004
2021-07-24 10:06:23,012 epoch 34 - iter 205/414 - loss 0.06947350 - samples/sec: 135.13 - lr: 0.000004
2021-07-24 10:06:32,364 epoch 34 - iter 246/414 - loss 0.07052640 - samples/sec: 140.32 - lr: 0.000004
2021-07-24 10:06:41,876 epoch 34 - iter 287/414 - loss 0.06859442 - samples/sec: 137.97 - lr: 0.000004
2021-07-24 10:06:51,446 epoch 34 - iter 328/414 - loss 0.06751262 - samples/sec: 137.13 - lr: 0.000004
2021-07-24 10:07:01,210 epoch 34 - iter 369/414 - loss 0.07122034 - samples/sec: 134.40 - lr: 0.000004
2021-07-24 10:07:11,105 epoch 34 - iter 410/414 - loss 0.07140789 - samples/sec: 132.62 - lr: 0.000004
2021-07-24 10:07:11,919 ----------------------------------------------------------------------------------------------------
2021-07-24 10:07:11,919 EPOCH 34 done: loss 0.0726 - lr 0.0000038
2021-07-24 10:07:18,088 DEV : loss 0.05643237754702568 - score 0.9887
2021-07-24 10:07:18,159 BAD EPOCHS (no improvement): 2
2021-07-24 10:07:18,159 ----------------------------------------------------------------------------------------------------
2021-07-24 10:07:28,056 epoch 35 - iter 41/414 - loss 0.06853770 - samples/sec: 132.62 - lr: 0.000004
2021-07-24 10:07:37,593 epoch 35 - iter 82/414 - loss 0.07935373 - samples/sec: 137.60 - lr: 0.000004
2021-07-24 10:07:47,261 epoch 35 - iter 123/414 - loss 0.07828067 - samples/sec: 135.75 - lr: 0.000004
2021-07-24 10:07:57,088 epoch 35 - iter 164/414 - loss 0.07583039 - samples/sec: 133.54 - lr: 0.000004
2021-07-24 10:08:06,684 epoch 35 - iter 205/414 - loss 0.07117208 - samples/sec: 136.75 - lr: 0.000004
2021-07-24 10:08:16,259 epoch 35 - iter 246/414 - loss 0.07043622 - samples/sec: 137.06 - lr: 0.000004
2021-07-24 10:08:25,888 epoch 35 - iter 287/414 - loss 0.06814006 - samples/sec: 136.28 - lr: 0.000004
2021-07-24 10:08:35,404 epoch 35 - iter 328/414 - loss 0.06703314 - samples/sec: 137.90 - lr: 0.000004
2021-07-24 10:08:45,037 epoch 35 - iter 369/414 - loss 0.06749091 - samples/sec: 136.24 - lr: 0.000004
2021-07-24 10:08:54,937 epoch 35 - iter 410/414 - loss 0.06820443 - samples/sec: 132.56 - lr: 0.000004
2021-07-24 10:08:55,772 ----------------------------------------------------------------------------------------------------
2021-07-24 10:08:55,772 EPOCH 35 done: loss 0.0686 - lr 0.0000038
2021-07-24 10:09:01,956 DEV : loss 0.05601060017943382 - score 0.989
2021-07-24 10:09:02,027 BAD EPOCHS (no improvement): 3
2021-07-24 10:09:02,027 ----------------------------------------------------------------------------------------------------
2021-07-24 10:09:11,805 epoch 36 - iter 41/414 - loss 0.06825303 - samples/sec: 134.23 - lr: 0.000004
2021-07-24 10:09:21,320 epoch 36 - iter 82/414 - loss 0.07080740 - samples/sec: 137.92 - lr: 0.000004
2021-07-24 10:09:30,909 epoch 36 - iter 123/414 - loss 0.07279484 - samples/sec: 136.85 - lr: 0.000004
2021-07-24 10:09:40,569 epoch 36 - iter 164/414 - loss 0.07261651 - samples/sec: 135.86 - lr: 0.000004
2021-07-24 10:09:50,116 epoch 36 - iter 205/414 - loss 0.07146849 - samples/sec: 137.45 - lr: 0.000004
2021-07-24 10:09:59,817 epoch 36 - iter 246/414 - loss 0.07019709 - samples/sec: 135.27 - lr: 0.000004
2021-07-24 10:10:09,589 epoch 36 - iter 287/414 - loss 0.06898344 - samples/sec: 134.30 - lr: 0.000004
2021-07-24 10:10:19,356 epoch 36 - iter 328/414 - loss 0.06797140 - samples/sec: 134.36 - lr: 0.000004
2021-07-24 10:10:28,796 epoch 36 - iter 369/414 - loss 0.06951481 - samples/sec: 139.02 - lr: 0.000004
2021-07-24 10:10:38,523 epoch 36 - iter 410/414 - loss 0.06870154 - samples/sec: 134.91 - lr: 0.000004
2021-07-24 10:10:39,267 ----------------------------------------------------------------------------------------------------
2021-07-24 10:10:39,268 EPOCH 36 done: loss 0.0689 - lr 0.0000038
2021-07-24 10:10:45,435 DEV : loss 0.0560016892850399 - score 0.989
Epoch    36: reducing learning rate of group 0 to 1.8750e-06.
2021-07-24 10:10:45,505 BAD EPOCHS (no improvement): 4
2021-07-24 10:10:45,506 ----------------------------------------------------------------------------------------------------
2021-07-24 10:10:45,506 ----------------------------------------------------------------------------------------------------
2021-07-24 10:10:45,506 learning rate too small - quitting training!
2021-07-24 10:10:45,506 ----------------------------------------------------------------------------------------------------
2021-07-24 10:10:46,056 ----------------------------------------------------------------------------------------------------
2021-07-24 10:10:46,056 Testing using best model ...
2021-07-24 10:10:46,057 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.rst.gum/best-model.pt
2021-07-24 10:11:35,613 0.9847	0.9843	0.9845
2021-07-24 10:11:35,613 
Results:
- F1-score (micro) 0.9845
- F1-score (macro) 0.9851

By class:
SENT       tp: 1327 - fp: 38 - fn: 41 - precision: 0.9722 - recall: 0.9700 - f1-score: 0.9711
X          tp: 1251 - fp: 2 - fn: 0 - precision: 0.9984 - recall: 1.0000 - f1-score: 0.9992
2021-07-24 10:11:35,613 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/nld.rst.nldt/
2021-07-24 10:11:35,668 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/nld.rst.nldt
2021-07-24 10:11:35,671 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/nld.rst.nldt/sent_train.txt
2021-07-24 10:11:35,673 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/nld.rst.nldt/sent_dev.txt
2021-07-24 10:11:35,675 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/nld.rst.nldt/sent_test.txt
Corpus: 2059 train + 599 dev + 738 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-24 10:11:39,475 ----------------------------------------------------------------------------------------------------
2021-07-24 10:11:39,476 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30073, 768, padding_idx=3)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-24 10:11:39,477 ----------------------------------------------------------------------------------------------------
2021-07-24 10:11:39,477 Corpus: "Corpus: 2059 train + 599 dev + 738 test sentences"
2021-07-24 10:11:39,477 ----------------------------------------------------------------------------------------------------
2021-07-24 10:11:39,477 Parameters:
2021-07-24 10:11:39,477  - learning_rate: "3e-05"
2021-07-24 10:11:39,477  - mini_batch_size: "32"
2021-07-24 10:11:39,477  - patience: "3"
2021-07-24 10:11:39,477  - anneal_factor: "0.5"
2021-07-24 10:11:39,477  - max_epochs: "40"
2021-07-24 10:11:39,477  - shuffle: "True"
2021-07-24 10:11:39,477  - train_with_dev: "False"
2021-07-24 10:11:39,477  - batch_growth_annealing: "False"
2021-07-24 10:11:39,477 ----------------------------------------------------------------------------------------------------
2021-07-24 10:11:39,477 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/nld.rst.nldt"
2021-07-24 10:11:39,477 ----------------------------------------------------------------------------------------------------
2021-07-24 10:11:39,477 Device: cuda:0
2021-07-24 10:11:39,477 ----------------------------------------------------------------------------------------------------
2021-07-24 10:11:39,477 Embeddings storage mode: cpu
2021-07-24 10:11:39,480 ----------------------------------------------------------------------------------------------------
2021-07-24 10:11:42,837 epoch 1 - iter 6/65 - loss 6.66826463 - samples/sec: 57.21 - lr: 0.000030
2021-07-24 10:11:46,176 epoch 1 - iter 12/65 - loss 6.28120752 - samples/sec: 57.50 - lr: 0.000030
2021-07-24 10:11:49,577 epoch 1 - iter 18/65 - loss 6.05414772 - samples/sec: 56.47 - lr: 0.000030
2021-07-24 10:11:53,029 epoch 1 - iter 24/65 - loss 5.95901853 - samples/sec: 55.62 - lr: 0.000030
2021-07-24 10:11:56,514 epoch 1 - iter 30/65 - loss 5.77544208 - samples/sec: 55.11 - lr: 0.000030
2021-07-24 10:12:00,001 epoch 1 - iter 36/65 - loss 5.64546210 - samples/sec: 55.06 - lr: 0.000030
2021-07-24 10:12:03,456 epoch 1 - iter 42/65 - loss 5.46315786 - samples/sec: 55.58 - lr: 0.000030
2021-07-24 10:12:06,871 epoch 1 - iter 48/65 - loss 5.30890744 - samples/sec: 56.24 - lr: 0.000030
2021-07-24 10:12:10,277 epoch 1 - iter 54/65 - loss 5.14933388 - samples/sec: 56.38 - lr: 0.000030
2021-07-24 10:12:13,711 epoch 1 - iter 60/65 - loss 4.99935609 - samples/sec: 55.91 - lr: 0.000030
2021-07-24 10:12:16,224 ----------------------------------------------------------------------------------------------------
2021-07-24 10:12:16,224 EPOCH 1 done: loss 4.8605 - lr 0.0000300
2021-07-24 10:12:23,856 DEV : loss 2.640296697616577 - score 0.0
2021-07-24 10:12:23,871 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:12:24,434 ----------------------------------------------------------------------------------------------------
2021-07-24 10:12:25,824 epoch 2 - iter 6/65 - loss 3.06956295 - samples/sec: 138.34 - lr: 0.000030
2021-07-24 10:12:27,190 epoch 2 - iter 12/65 - loss 3.11122843 - samples/sec: 140.53 - lr: 0.000030
2021-07-24 10:12:28,568 epoch 2 - iter 18/65 - loss 3.00235518 - samples/sec: 139.40 - lr: 0.000030
2021-07-24 10:12:29,940 epoch 2 - iter 24/65 - loss 2.89741266 - samples/sec: 139.99 - lr: 0.000030
2021-07-24 10:12:31,345 epoch 2 - iter 30/65 - loss 2.80475831 - samples/sec: 136.75 - lr: 0.000030
2021-07-24 10:12:32,716 epoch 2 - iter 36/65 - loss 2.71919840 - samples/sec: 140.02 - lr: 0.000030
2021-07-24 10:12:34,140 epoch 2 - iter 42/65 - loss 2.65194629 - samples/sec: 134.91 - lr: 0.000030
2021-07-24 10:12:35,542 epoch 2 - iter 48/65 - loss 2.57965264 - samples/sec: 136.97 - lr: 0.000030
2021-07-24 10:12:36,936 epoch 2 - iter 54/65 - loss 2.50422258 - samples/sec: 137.84 - lr: 0.000030
2021-07-24 10:12:38,340 epoch 2 - iter 60/65 - loss 2.42606768 - samples/sec: 136.75 - lr: 0.000030
2021-07-24 10:12:39,350 ----------------------------------------------------------------------------------------------------
2021-07-24 10:12:39,350 EPOCH 2 done: loss 2.3622 - lr 0.0000300
2021-07-24 10:12:40,857 DEV : loss 1.437916874885559 - score 0.5933
2021-07-24 10:12:40,872 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:12:43,208 ----------------------------------------------------------------------------------------------------
2021-07-24 10:12:44,607 epoch 3 - iter 6/65 - loss 1.58129869 - samples/sec: 137.44 - lr: 0.000030
2021-07-24 10:12:46,011 epoch 3 - iter 12/65 - loss 1.58982101 - samples/sec: 136.83 - lr: 0.000030
2021-07-24 10:12:47,456 epoch 3 - iter 18/65 - loss 1.53167945 - samples/sec: 132.90 - lr: 0.000030
2021-07-24 10:12:48,807 epoch 3 - iter 24/65 - loss 1.49400419 - samples/sec: 142.21 - lr: 0.000030
2021-07-24 10:12:50,176 epoch 3 - iter 30/65 - loss 1.46153286 - samples/sec: 140.27 - lr: 0.000030
2021-07-24 10:12:51,571 epoch 3 - iter 36/65 - loss 1.41936256 - samples/sec: 137.68 - lr: 0.000030
2021-07-24 10:12:53,011 epoch 3 - iter 42/65 - loss 1.38174152 - samples/sec: 133.34 - lr: 0.000030
2021-07-24 10:12:54,408 epoch 3 - iter 48/65 - loss 1.36079065 - samples/sec: 137.51 - lr: 0.000030
2021-07-24 10:12:55,819 epoch 3 - iter 54/65 - loss 1.33269709 - samples/sec: 136.14 - lr: 0.000030
2021-07-24 10:12:57,139 epoch 3 - iter 60/65 - loss 1.29821848 - samples/sec: 145.47 - lr: 0.000030
2021-07-24 10:12:58,138 ----------------------------------------------------------------------------------------------------
2021-07-24 10:12:58,138 EPOCH 3 done: loss 1.2727 - lr 0.0000300
2021-07-24 10:12:59,510 DEV : loss 0.74444979429245 - score 0.606
2021-07-24 10:12:59,525 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:13:01,959 ----------------------------------------------------------------------------------------------------
2021-07-24 10:13:03,340 epoch 4 - iter 6/65 - loss 0.92472877 - samples/sec: 139.23 - lr: 0.000030
2021-07-24 10:13:04,765 epoch 4 - iter 12/65 - loss 0.88565158 - samples/sec: 134.86 - lr: 0.000030
2021-07-24 10:13:06,088 epoch 4 - iter 18/65 - loss 0.89003342 - samples/sec: 145.09 - lr: 0.000030
2021-07-24 10:13:07,465 epoch 4 - iter 24/65 - loss 0.86918304 - samples/sec: 139.56 - lr: 0.000030
2021-07-24 10:13:08,857 epoch 4 - iter 30/65 - loss 0.84421114 - samples/sec: 137.95 - lr: 0.000030
2021-07-24 10:13:10,228 epoch 4 - iter 36/65 - loss 0.82340340 - samples/sec: 140.07 - lr: 0.000030
2021-07-24 10:13:11,683 epoch 4 - iter 42/65 - loss 0.79984518 - samples/sec: 132.00 - lr: 0.000030
2021-07-24 10:13:13,080 epoch 4 - iter 48/65 - loss 0.80225670 - samples/sec: 137.54 - lr: 0.000030
2021-07-24 10:13:14,482 epoch 4 - iter 54/65 - loss 0.78150360 - samples/sec: 136.94 - lr: 0.000030
2021-07-24 10:13:15,921 epoch 4 - iter 60/65 - loss 0.76645838 - samples/sec: 133.55 - lr: 0.000030
2021-07-24 10:13:16,919 ----------------------------------------------------------------------------------------------------
2021-07-24 10:13:16,919 EPOCH 4 done: loss 0.7559 - lr 0.0000300
2021-07-24 10:13:18,298 DEV : loss 0.3927057683467865 - score 0.9064
2021-07-24 10:13:18,313 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:13:20,622 ----------------------------------------------------------------------------------------------------
2021-07-24 10:13:21,992 epoch 5 - iter 6/65 - loss 0.60374978 - samples/sec: 140.37 - lr: 0.000030
2021-07-24 10:13:23,379 epoch 5 - iter 12/65 - loss 0.61194163 - samples/sec: 138.52 - lr: 0.000030
2021-07-24 10:13:24,796 epoch 5 - iter 18/65 - loss 0.60617429 - samples/sec: 135.55 - lr: 0.000030
2021-07-24 10:13:26,205 epoch 5 - iter 24/65 - loss 0.58136747 - samples/sec: 136.29 - lr: 0.000030
2021-07-24 10:13:27,605 epoch 5 - iter 30/65 - loss 0.57290478 - samples/sec: 137.27 - lr: 0.000030
2021-07-24 10:13:28,988 epoch 5 - iter 36/65 - loss 0.56524102 - samples/sec: 138.83 - lr: 0.000030
2021-07-24 10:13:30,356 epoch 5 - iter 42/65 - loss 0.55347365 - samples/sec: 140.45 - lr: 0.000030
2021-07-24 10:13:31,729 epoch 5 - iter 48/65 - loss 0.54285401 - samples/sec: 139.85 - lr: 0.000030
2021-07-24 10:13:33,196 epoch 5 - iter 54/65 - loss 0.53167147 - samples/sec: 130.96 - lr: 0.000030
2021-07-24 10:13:34,567 epoch 5 - iter 60/65 - loss 0.52415917 - samples/sec: 140.04 - lr: 0.000030
2021-07-24 10:13:35,579 ----------------------------------------------------------------------------------------------------
2021-07-24 10:13:35,579 EPOCH 5 done: loss 0.5216 - lr 0.0000300
2021-07-24 10:13:36,960 DEV : loss 0.2396077662706375 - score 0.9571
2021-07-24 10:13:36,978 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:13:39,309 ----------------------------------------------------------------------------------------------------
2021-07-24 10:13:40,765 epoch 6 - iter 6/65 - loss 0.39298449 - samples/sec: 132.07 - lr: 0.000030
2021-07-24 10:13:42,204 epoch 6 - iter 12/65 - loss 0.41522261 - samples/sec: 133.44 - lr: 0.000030
2021-07-24 10:13:43,579 epoch 6 - iter 18/65 - loss 0.40936608 - samples/sec: 139.71 - lr: 0.000030
2021-07-24 10:13:44,991 epoch 6 - iter 24/65 - loss 0.40703730 - samples/sec: 136.02 - lr: 0.000030
2021-07-24 10:13:46,394 epoch 6 - iter 30/65 - loss 0.39351270 - samples/sec: 136.97 - lr: 0.000030
2021-07-24 10:13:47,800 epoch 6 - iter 36/65 - loss 0.39737058 - samples/sec: 136.57 - lr: 0.000030
2021-07-24 10:13:49,197 epoch 6 - iter 42/65 - loss 0.39490876 - samples/sec: 137.50 - lr: 0.000030
2021-07-24 10:13:50,508 epoch 6 - iter 48/65 - loss 0.39103540 - samples/sec: 146.52 - lr: 0.000030
2021-07-24 10:13:51,859 epoch 6 - iter 54/65 - loss 0.38768494 - samples/sec: 142.12 - lr: 0.000030
2021-07-24 10:13:53,268 epoch 6 - iter 60/65 - loss 0.38523195 - samples/sec: 136.33 - lr: 0.000030
2021-07-24 10:13:54,276 ----------------------------------------------------------------------------------------------------
2021-07-24 10:13:54,276 EPOCH 6 done: loss 0.3824 - lr 0.0000300
2021-07-24 10:13:55,656 DEV : loss 0.1682499200105667 - score 0.9678
2021-07-24 10:13:55,671 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:13:57,950 ----------------------------------------------------------------------------------------------------
2021-07-24 10:13:59,320 epoch 7 - iter 6/65 - loss 0.30807092 - samples/sec: 140.33 - lr: 0.000030
2021-07-24 10:14:00,728 epoch 7 - iter 12/65 - loss 0.33247310 - samples/sec: 136.47 - lr: 0.000030
2021-07-24 10:14:02,063 epoch 7 - iter 18/65 - loss 0.35047622 - samples/sec: 143.84 - lr: 0.000030
2021-07-24 10:14:03,471 epoch 7 - iter 24/65 - loss 0.35717845 - samples/sec: 136.39 - lr: 0.000030
2021-07-24 10:14:04,897 epoch 7 - iter 30/65 - loss 0.35220166 - samples/sec: 134.69 - lr: 0.000030
2021-07-24 10:14:06,280 epoch 7 - iter 36/65 - loss 0.33207479 - samples/sec: 138.90 - lr: 0.000030
2021-07-24 10:14:07,715 epoch 7 - iter 42/65 - loss 0.32756912 - samples/sec: 133.86 - lr: 0.000030
2021-07-24 10:14:09,120 epoch 7 - iter 48/65 - loss 0.31823107 - samples/sec: 136.66 - lr: 0.000030
2021-07-24 10:14:10,495 epoch 7 - iter 54/65 - loss 0.31378268 - samples/sec: 139.70 - lr: 0.000030
2021-07-24 10:14:11,860 epoch 7 - iter 60/65 - loss 0.30720047 - samples/sec: 140.73 - lr: 0.000030
2021-07-24 10:14:12,910 ----------------------------------------------------------------------------------------------------
2021-07-24 10:14:12,910 EPOCH 7 done: loss 0.3033 - lr 0.0000300
2021-07-24 10:14:14,289 DEV : loss 0.1342349648475647 - score 0.975
2021-07-24 10:14:14,305 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:14:16,551 ----------------------------------------------------------------------------------------------------
2021-07-24 10:14:17,883 epoch 8 - iter 6/65 - loss 0.26200620 - samples/sec: 144.43 - lr: 0.000030
2021-07-24 10:14:19,248 epoch 8 - iter 12/65 - loss 0.28065686 - samples/sec: 140.72 - lr: 0.000030
2021-07-24 10:14:20,627 epoch 8 - iter 18/65 - loss 0.28257623 - samples/sec: 139.25 - lr: 0.000030
2021-07-24 10:14:22,136 epoch 8 - iter 24/65 - loss 0.27351267 - samples/sec: 127.30 - lr: 0.000030
2021-07-24 10:14:23,504 epoch 8 - iter 30/65 - loss 0.26813621 - samples/sec: 140.40 - lr: 0.000030
2021-07-24 10:14:24,945 epoch 8 - iter 36/65 - loss 0.28386709 - samples/sec: 133.31 - lr: 0.000030
2021-07-24 10:14:26,384 epoch 8 - iter 42/65 - loss 0.28340081 - samples/sec: 133.50 - lr: 0.000030
2021-07-24 10:14:27,775 epoch 8 - iter 48/65 - loss 0.28632353 - samples/sec: 138.10 - lr: 0.000030
2021-07-24 10:14:29,197 epoch 8 - iter 54/65 - loss 0.28460971 - samples/sec: 135.07 - lr: 0.000030
2021-07-24 10:14:30,593 epoch 8 - iter 60/65 - loss 0.27640376 - samples/sec: 137.54 - lr: 0.000030
2021-07-24 10:14:31,627 ----------------------------------------------------------------------------------------------------
2021-07-24 10:14:31,627 EPOCH 8 done: loss 0.2742 - lr 0.0000300
2021-07-24 10:14:33,009 DEV : loss 0.11585552990436554 - score 0.9795
2021-07-24 10:14:33,028 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:14:35,469 ----------------------------------------------------------------------------------------------------
2021-07-24 10:14:36,836 epoch 9 - iter 6/65 - loss 0.21856346 - samples/sec: 140.70 - lr: 0.000030
2021-07-24 10:14:38,147 epoch 9 - iter 12/65 - loss 0.26689876 - samples/sec: 146.48 - lr: 0.000030
2021-07-24 10:14:39,622 epoch 9 - iter 18/65 - loss 0.27591622 - samples/sec: 130.25 - lr: 0.000030
2021-07-24 10:14:41,011 epoch 9 - iter 24/65 - loss 0.28158493 - samples/sec: 138.27 - lr: 0.000030
2021-07-24 10:14:42,444 epoch 9 - iter 30/65 - loss 0.27835116 - samples/sec: 133.99 - lr: 0.000030
2021-07-24 10:14:43,867 epoch 9 - iter 36/65 - loss 0.26871171 - samples/sec: 135.04 - lr: 0.000030
2021-07-24 10:14:45,252 epoch 9 - iter 42/65 - loss 0.26539292 - samples/sec: 138.66 - lr: 0.000030
2021-07-24 10:14:46,592 epoch 9 - iter 48/65 - loss 0.26354003 - samples/sec: 143.34 - lr: 0.000030
2021-07-24 10:14:48,033 epoch 9 - iter 54/65 - loss 0.26664805 - samples/sec: 133.32 - lr: 0.000030
2021-07-24 10:14:49,372 epoch 9 - iter 60/65 - loss 0.26863464 - samples/sec: 143.42 - lr: 0.000030
2021-07-24 10:14:50,406 ----------------------------------------------------------------------------------------------------
2021-07-24 10:14:50,407 EPOCH 9 done: loss 0.2669 - lr 0.0000300
2021-07-24 10:14:51,783 DEV : loss 0.10727089643478394 - score 0.9806
2021-07-24 10:14:51,799 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:14:54,150 ----------------------------------------------------------------------------------------------------
2021-07-24 10:14:55,609 epoch 10 - iter 6/65 - loss 0.30341452 - samples/sec: 131.80 - lr: 0.000030
2021-07-24 10:14:57,012 epoch 10 - iter 12/65 - loss 0.23735203 - samples/sec: 136.88 - lr: 0.000030
2021-07-24 10:14:58,376 epoch 10 - iter 18/65 - loss 0.25301656 - samples/sec: 140.82 - lr: 0.000030
2021-07-24 10:14:59,783 epoch 10 - iter 24/65 - loss 0.25340725 - samples/sec: 136.51 - lr: 0.000030
2021-07-24 10:15:01,157 epoch 10 - iter 30/65 - loss 0.24527927 - samples/sec: 139.82 - lr: 0.000030
2021-07-24 10:15:02,589 epoch 10 - iter 36/65 - loss 0.23645816 - samples/sec: 134.10 - lr: 0.000030
2021-07-24 10:15:03,936 epoch 10 - iter 42/65 - loss 0.24336692 - samples/sec: 142.62 - lr: 0.000030
2021-07-24 10:15:05,331 epoch 10 - iter 48/65 - loss 0.24151969 - samples/sec: 137.65 - lr: 0.000030
2021-07-24 10:15:06,715 epoch 10 - iter 54/65 - loss 0.24196511 - samples/sec: 138.83 - lr: 0.000030
2021-07-24 10:15:08,084 epoch 10 - iter 60/65 - loss 0.24483471 - samples/sec: 140.27 - lr: 0.000030
2021-07-24 10:15:09,098 ----------------------------------------------------------------------------------------------------
2021-07-24 10:15:09,098 EPOCH 10 done: loss 0.2461 - lr 0.0000300
2021-07-24 10:15:10,475 DEV : loss 0.09820177406072617 - score 0.9818
2021-07-24 10:15:10,491 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:15:12,901 ----------------------------------------------------------------------------------------------------
2021-07-24 10:15:14,321 epoch 11 - iter 6/65 - loss 0.27088664 - samples/sec: 135.40 - lr: 0.000030
2021-07-24 10:15:15,661 epoch 11 - iter 12/65 - loss 0.24385521 - samples/sec: 143.40 - lr: 0.000030
2021-07-24 10:15:17,036 epoch 11 - iter 18/65 - loss 0.25490311 - samples/sec: 139.70 - lr: 0.000030
2021-07-24 10:15:18,372 epoch 11 - iter 24/65 - loss 0.24903264 - samples/sec: 143.77 - lr: 0.000030
2021-07-24 10:15:19,808 epoch 11 - iter 30/65 - loss 0.23460302 - samples/sec: 133.77 - lr: 0.000030
2021-07-24 10:15:21,212 epoch 11 - iter 36/65 - loss 0.23759474 - samples/sec: 136.77 - lr: 0.000030
2021-07-24 10:15:22,613 epoch 11 - iter 42/65 - loss 0.23914483 - samples/sec: 137.05 - lr: 0.000030
2021-07-24 10:15:24,025 epoch 11 - iter 48/65 - loss 0.23552351 - samples/sec: 136.11 - lr: 0.000030
2021-07-24 10:15:25,513 epoch 11 - iter 54/65 - loss 0.22511378 - samples/sec: 129.03 - lr: 0.000030
2021-07-24 10:15:26,867 epoch 11 - iter 60/65 - loss 0.22382502 - samples/sec: 141.84 - lr: 0.000030
2021-07-24 10:15:27,858 ----------------------------------------------------------------------------------------------------
2021-07-24 10:15:27,858 EPOCH 11 done: loss 0.2209 - lr 0.0000300
2021-07-24 10:15:29,236 DEV : loss 0.09034095704555511 - score 0.9841
2021-07-24 10:15:29,252 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:15:31,707 ----------------------------------------------------------------------------------------------------
2021-07-24 10:15:33,139 epoch 12 - iter 6/65 - loss 0.19566931 - samples/sec: 134.32 - lr: 0.000030
2021-07-24 10:15:34,556 epoch 12 - iter 12/65 - loss 0.19864255 - samples/sec: 135.57 - lr: 0.000030
2021-07-24 10:15:35,942 epoch 12 - iter 18/65 - loss 0.21518047 - samples/sec: 138.60 - lr: 0.000030
2021-07-24 10:15:37,337 epoch 12 - iter 24/65 - loss 0.20243414 - samples/sec: 137.66 - lr: 0.000030
2021-07-24 10:15:38,703 epoch 12 - iter 30/65 - loss 0.19680399 - samples/sec: 140.60 - lr: 0.000030
2021-07-24 10:15:40,069 epoch 12 - iter 36/65 - loss 0.19586137 - samples/sec: 140.62 - lr: 0.000030
2021-07-24 10:15:41,521 epoch 12 - iter 42/65 - loss 0.19494884 - samples/sec: 132.31 - lr: 0.000030
2021-07-24 10:15:42,932 epoch 12 - iter 48/65 - loss 0.19739228 - samples/sec: 136.14 - lr: 0.000030
2021-07-24 10:15:44,250 epoch 12 - iter 54/65 - loss 0.20140378 - samples/sec: 145.64 - lr: 0.000030
2021-07-24 10:15:45,653 epoch 12 - iter 60/65 - loss 0.19783976 - samples/sec: 136.97 - lr: 0.000030
2021-07-24 10:15:46,674 ----------------------------------------------------------------------------------------------------
2021-07-24 10:15:46,674 EPOCH 12 done: loss 0.1951 - lr 0.0000300
2021-07-24 10:15:48,051 DEV : loss 0.0851837620139122 - score 0.9852
2021-07-24 10:15:48,066 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:15:50,628 ----------------------------------------------------------------------------------------------------
2021-07-24 10:15:52,020 epoch 13 - iter 6/65 - loss 0.29428156 - samples/sec: 138.19 - lr: 0.000030
2021-07-24 10:15:53,415 epoch 13 - iter 12/65 - loss 0.22478577 - samples/sec: 137.69 - lr: 0.000030
2021-07-24 10:15:54,796 epoch 13 - iter 18/65 - loss 0.21403429 - samples/sec: 139.10 - lr: 0.000030
2021-07-24 10:15:56,092 epoch 13 - iter 24/65 - loss 0.23549885 - samples/sec: 148.21 - lr: 0.000030
2021-07-24 10:15:57,440 epoch 13 - iter 30/65 - loss 0.22659671 - samples/sec: 142.41 - lr: 0.000030
2021-07-24 10:15:58,819 epoch 13 - iter 36/65 - loss 0.22204180 - samples/sec: 139.28 - lr: 0.000030
2021-07-24 10:16:00,247 epoch 13 - iter 42/65 - loss 0.22512807 - samples/sec: 134.50 - lr: 0.000030
2021-07-24 10:16:01,707 epoch 13 - iter 48/65 - loss 0.22004214 - samples/sec: 131.61 - lr: 0.000030
2021-07-24 10:16:03,188 epoch 13 - iter 54/65 - loss 0.21882793 - samples/sec: 129.66 - lr: 0.000030
2021-07-24 10:16:04,551 epoch 13 - iter 60/65 - loss 0.21750873 - samples/sec: 140.98 - lr: 0.000030
2021-07-24 10:16:05,551 ----------------------------------------------------------------------------------------------------
2021-07-24 10:16:05,551 EPOCH 13 done: loss 0.2201 - lr 0.0000300
2021-07-24 10:16:07,046 DEV : loss 0.08333764970302582 - score 0.9852
2021-07-24 10:16:07,066 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:16:09,509 ----------------------------------------------------------------------------------------------------
2021-07-24 10:16:10,987 epoch 14 - iter 6/65 - loss 0.19802785 - samples/sec: 130.07 - lr: 0.000030
2021-07-24 10:16:12,451 epoch 14 - iter 12/65 - loss 0.19508772 - samples/sec: 131.20 - lr: 0.000030
2021-07-24 10:16:13,823 epoch 14 - iter 18/65 - loss 0.21054625 - samples/sec: 140.04 - lr: 0.000030
2021-07-24 10:16:15,135 epoch 14 - iter 24/65 - loss 0.20768590 - samples/sec: 146.42 - lr: 0.000030
2021-07-24 10:16:16,541 epoch 14 - iter 30/65 - loss 0.19758540 - samples/sec: 136.60 - lr: 0.000030
2021-07-24 10:16:17,936 epoch 14 - iter 36/65 - loss 0.19779784 - samples/sec: 137.68 - lr: 0.000030
2021-07-24 10:16:19,259 epoch 14 - iter 42/65 - loss 0.20543528 - samples/sec: 145.18 - lr: 0.000030
2021-07-24 10:16:20,657 epoch 14 - iter 48/65 - loss 0.19968075 - samples/sec: 137.44 - lr: 0.000030
2021-07-24 10:16:22,024 epoch 14 - iter 54/65 - loss 0.19918046 - samples/sec: 140.50 - lr: 0.000030
2021-07-24 10:16:23,424 epoch 14 - iter 60/65 - loss 0.19276326 - samples/sec: 137.10 - lr: 0.000030
2021-07-24 10:16:24,444 ----------------------------------------------------------------------------------------------------
2021-07-24 10:16:24,444 EPOCH 14 done: loss 0.1891 - lr 0.0000300
2021-07-24 10:16:25,821 DEV : loss 0.0805436298251152 - score 0.9852
2021-07-24 10:16:25,837 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:16:28,234 ----------------------------------------------------------------------------------------------------
2021-07-24 10:16:29,700 epoch 15 - iter 6/65 - loss 0.20130740 - samples/sec: 131.16 - lr: 0.000030
2021-07-24 10:16:31,052 epoch 15 - iter 12/65 - loss 0.18795631 - samples/sec: 142.07 - lr: 0.000030
2021-07-24 10:16:32,495 epoch 15 - iter 18/65 - loss 0.18920430 - samples/sec: 133.10 - lr: 0.000030
2021-07-24 10:16:33,848 epoch 15 - iter 24/65 - loss 0.18451344 - samples/sec: 142.02 - lr: 0.000030
2021-07-24 10:16:35,233 epoch 15 - iter 30/65 - loss 0.18217469 - samples/sec: 138.67 - lr: 0.000030
2021-07-24 10:16:36,632 epoch 15 - iter 36/65 - loss 0.18368158 - samples/sec: 137.30 - lr: 0.000030
2021-07-24 10:16:37,910 epoch 15 - iter 42/65 - loss 0.18820290 - samples/sec: 150.29 - lr: 0.000030
2021-07-24 10:16:39,287 epoch 15 - iter 48/65 - loss 0.17874710 - samples/sec: 139.51 - lr: 0.000030
2021-07-24 10:16:40,696 epoch 15 - iter 54/65 - loss 0.18350227 - samples/sec: 136.33 - lr: 0.000030
2021-07-24 10:16:42,192 epoch 15 - iter 60/65 - loss 0.18451306 - samples/sec: 128.37 - lr: 0.000030
2021-07-24 10:16:43,226 ----------------------------------------------------------------------------------------------------
2021-07-24 10:16:43,226 EPOCH 15 done: loss 0.1800 - lr 0.0000300
2021-07-24 10:16:44,603 DEV : loss 0.07645224779844284 - score 0.9841
2021-07-24 10:16:44,618 BAD EPOCHS (no improvement): 1
2021-07-24 10:16:44,619 ----------------------------------------------------------------------------------------------------
2021-07-24 10:16:45,979 epoch 16 - iter 6/65 - loss 0.20093577 - samples/sec: 141.25 - lr: 0.000030
2021-07-24 10:16:47,372 epoch 16 - iter 12/65 - loss 0.17888271 - samples/sec: 137.90 - lr: 0.000030
2021-07-24 10:16:48,848 epoch 16 - iter 18/65 - loss 0.16550844 - samples/sec: 130.17 - lr: 0.000030
2021-07-24 10:16:50,235 epoch 16 - iter 24/65 - loss 0.15773373 - samples/sec: 138.46 - lr: 0.000030
2021-07-24 10:16:51,615 epoch 16 - iter 30/65 - loss 0.14658802 - samples/sec: 139.16 - lr: 0.000030
2021-07-24 10:16:53,036 epoch 16 - iter 36/65 - loss 0.15513089 - samples/sec: 135.16 - lr: 0.000030
2021-07-24 10:16:54,456 epoch 16 - iter 42/65 - loss 0.16072387 - samples/sec: 135.26 - lr: 0.000030
2021-07-24 10:16:55,793 epoch 16 - iter 48/65 - loss 0.16666845 - samples/sec: 143.71 - lr: 0.000030
2021-07-24 10:16:57,132 epoch 16 - iter 54/65 - loss 0.16619184 - samples/sec: 143.49 - lr: 0.000030
2021-07-24 10:16:58,549 epoch 16 - iter 60/65 - loss 0.17569062 - samples/sec: 135.51 - lr: 0.000030
2021-07-24 10:16:59,572 ----------------------------------------------------------------------------------------------------
2021-07-24 10:16:59,572 EPOCH 16 done: loss 0.1766 - lr 0.0000300
2021-07-24 10:17:00,947 DEV : loss 0.07464312016963959 - score 0.9841
2021-07-24 10:17:00,963 BAD EPOCHS (no improvement): 2
2021-07-24 10:17:00,963 ----------------------------------------------------------------------------------------------------
2021-07-24 10:17:02,387 epoch 17 - iter 6/65 - loss 0.13214062 - samples/sec: 134.93 - lr: 0.000030
2021-07-24 10:17:03,708 epoch 17 - iter 12/65 - loss 0.13710930 - samples/sec: 145.41 - lr: 0.000030
2021-07-24 10:17:05,010 epoch 17 - iter 18/65 - loss 0.15746782 - samples/sec: 147.54 - lr: 0.000030
2021-07-24 10:17:06,407 epoch 17 - iter 24/65 - loss 0.16860888 - samples/sec: 137.51 - lr: 0.000030
2021-07-24 10:17:07,792 epoch 17 - iter 30/65 - loss 0.17322928 - samples/sec: 138.65 - lr: 0.000030
2021-07-24 10:17:09,204 epoch 17 - iter 36/65 - loss 0.17928939 - samples/sec: 136.10 - lr: 0.000030
2021-07-24 10:17:10,649 epoch 17 - iter 42/65 - loss 0.18312547 - samples/sec: 132.89 - lr: 0.000030
2021-07-24 10:17:12,008 epoch 17 - iter 48/65 - loss 0.17804962 - samples/sec: 141.30 - lr: 0.000030
2021-07-24 10:17:13,424 epoch 17 - iter 54/65 - loss 0.18035066 - samples/sec: 135.66 - lr: 0.000030
2021-07-24 10:17:14,882 epoch 17 - iter 60/65 - loss 0.18332347 - samples/sec: 131.72 - lr: 0.000030
2021-07-24 10:17:15,922 ----------------------------------------------------------------------------------------------------
2021-07-24 10:17:15,923 EPOCH 17 done: loss 0.1799 - lr 0.0000300
2021-07-24 10:17:17,298 DEV : loss 0.07284924387931824 - score 0.9842
2021-07-24 10:17:17,313 BAD EPOCHS (no improvement): 3
2021-07-24 10:17:17,314 ----------------------------------------------------------------------------------------------------
2021-07-24 10:17:18,741 epoch 18 - iter 6/65 - loss 0.18703486 - samples/sec: 134.68 - lr: 0.000030
2021-07-24 10:17:20,172 epoch 18 - iter 12/65 - loss 0.16567292 - samples/sec: 134.18 - lr: 0.000030
2021-07-24 10:17:21,567 epoch 18 - iter 18/65 - loss 0.16860855 - samples/sec: 137.70 - lr: 0.000030
2021-07-24 10:17:22,980 epoch 18 - iter 24/65 - loss 0.17249863 - samples/sec: 135.89 - lr: 0.000030
2021-07-24 10:17:24,284 epoch 18 - iter 30/65 - loss 0.16341443 - samples/sec: 147.31 - lr: 0.000030
2021-07-24 10:17:25,719 epoch 18 - iter 36/65 - loss 0.16506175 - samples/sec: 133.86 - lr: 0.000030
2021-07-24 10:17:27,145 epoch 18 - iter 42/65 - loss 0.16854108 - samples/sec: 134.75 - lr: 0.000030
2021-07-24 10:17:28,507 epoch 18 - iter 48/65 - loss 0.16452773 - samples/sec: 140.94 - lr: 0.000030
2021-07-24 10:17:29,884 epoch 18 - iter 54/65 - loss 0.16177873 - samples/sec: 139.49 - lr: 0.000030
2021-07-24 10:17:31,231 epoch 18 - iter 60/65 - loss 0.16065861 - samples/sec: 142.62 - lr: 0.000030
2021-07-24 10:17:32,234 ----------------------------------------------------------------------------------------------------
2021-07-24 10:17:32,234 EPOCH 18 done: loss 0.1628 - lr 0.0000300
2021-07-24 10:17:33,609 DEV : loss 0.07356474548578262 - score 0.9841
Epoch    18: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 10:17:33,625 BAD EPOCHS (no improvement): 4
2021-07-24 10:17:33,625 ----------------------------------------------------------------------------------------------------
2021-07-24 10:17:34,983 epoch 19 - iter 6/65 - loss 0.11618013 - samples/sec: 141.48 - lr: 0.000015
2021-07-24 10:17:36,388 epoch 19 - iter 12/65 - loss 0.16507919 - samples/sec: 136.77 - lr: 0.000015
2021-07-24 10:17:37,816 epoch 19 - iter 18/65 - loss 0.15475340 - samples/sec: 134.49 - lr: 0.000015
2021-07-24 10:17:39,194 epoch 19 - iter 24/65 - loss 0.14380132 - samples/sec: 139.34 - lr: 0.000015
2021-07-24 10:17:40,539 epoch 19 - iter 30/65 - loss 0.14999172 - samples/sec: 142.83 - lr: 0.000015
2021-07-24 10:17:41,953 epoch 19 - iter 36/65 - loss 0.14612232 - samples/sec: 135.88 - lr: 0.000015
2021-07-24 10:17:43,409 epoch 19 - iter 42/65 - loss 0.14961652 - samples/sec: 131.88 - lr: 0.000015
2021-07-24 10:17:44,740 epoch 19 - iter 48/65 - loss 0.14695452 - samples/sec: 144.31 - lr: 0.000015
2021-07-24 10:17:46,115 epoch 19 - iter 54/65 - loss 0.14321105 - samples/sec: 139.68 - lr: 0.000015
2021-07-24 10:17:47,512 epoch 19 - iter 60/65 - loss 0.14386541 - samples/sec: 137.47 - lr: 0.000015
2021-07-24 10:17:48,495 ----------------------------------------------------------------------------------------------------
2021-07-24 10:17:48,495 EPOCH 19 done: loss 0.1427 - lr 0.0000150
2021-07-24 10:17:49,991 DEV : loss 0.07161146402359009 - score 0.9842
2021-07-24 10:17:50,006 BAD EPOCHS (no improvement): 1
2021-07-24 10:17:50,006 ----------------------------------------------------------------------------------------------------
2021-07-24 10:17:51,364 epoch 20 - iter 6/65 - loss 0.18589625 - samples/sec: 141.53 - lr: 0.000015
2021-07-24 10:17:52,764 epoch 20 - iter 12/65 - loss 0.18880266 - samples/sec: 137.24 - lr: 0.000015
2021-07-24 10:17:54,075 epoch 20 - iter 18/65 - loss 0.18128570 - samples/sec: 146.44 - lr: 0.000015
2021-07-24 10:17:55,525 epoch 20 - iter 24/65 - loss 0.17513065 - samples/sec: 132.47 - lr: 0.000015
2021-07-24 10:17:56,877 epoch 20 - iter 30/65 - loss 0.17242742 - samples/sec: 142.09 - lr: 0.000015
2021-07-24 10:17:58,213 epoch 20 - iter 36/65 - loss 0.16814418 - samples/sec: 143.74 - lr: 0.000015
2021-07-24 10:17:59,633 epoch 20 - iter 42/65 - loss 0.15921846 - samples/sec: 135.32 - lr: 0.000015
2021-07-24 10:18:01,068 epoch 20 - iter 48/65 - loss 0.15954233 - samples/sec: 133.84 - lr: 0.000015
2021-07-24 10:18:02,487 epoch 20 - iter 54/65 - loss 0.17320668 - samples/sec: 135.35 - lr: 0.000015
2021-07-24 10:18:03,852 epoch 20 - iter 60/65 - loss 0.16930756 - samples/sec: 140.68 - lr: 0.000015
2021-07-24 10:18:04,867 ----------------------------------------------------------------------------------------------------
2021-07-24 10:18:04,868 EPOCH 20 done: loss 0.1655 - lr 0.0000150
2021-07-24 10:18:06,243 DEV : loss 0.06991289556026459 - score 0.9842
2021-07-24 10:18:06,259 BAD EPOCHS (no improvement): 2
2021-07-24 10:18:06,259 ----------------------------------------------------------------------------------------------------
2021-07-24 10:18:07,702 epoch 21 - iter 6/65 - loss 0.17732631 - samples/sec: 133.21 - lr: 0.000015
2021-07-24 10:18:09,137 epoch 21 - iter 12/65 - loss 0.17811160 - samples/sec: 133.80 - lr: 0.000015
2021-07-24 10:18:10,502 epoch 21 - iter 18/65 - loss 0.16842086 - samples/sec: 140.74 - lr: 0.000015
2021-07-24 10:18:11,932 epoch 21 - iter 24/65 - loss 0.17136583 - samples/sec: 134.31 - lr: 0.000015
2021-07-24 10:18:13,226 epoch 21 - iter 30/65 - loss 0.16352824 - samples/sec: 148.50 - lr: 0.000015
2021-07-24 10:18:14,575 epoch 21 - iter 36/65 - loss 0.16319847 - samples/sec: 142.38 - lr: 0.000015
2021-07-24 10:18:15,901 epoch 21 - iter 42/65 - loss 0.16584199 - samples/sec: 144.87 - lr: 0.000015
2021-07-24 10:18:17,280 epoch 21 - iter 48/65 - loss 0.16283910 - samples/sec: 139.27 - lr: 0.000015
2021-07-24 10:18:18,705 epoch 21 - iter 54/65 - loss 0.15590628 - samples/sec: 134.71 - lr: 0.000015
2021-07-24 10:18:20,069 epoch 21 - iter 60/65 - loss 0.15513059 - samples/sec: 140.90 - lr: 0.000015
2021-07-24 10:18:21,086 ----------------------------------------------------------------------------------------------------
2021-07-24 10:18:21,086 EPOCH 21 done: loss 0.1541 - lr 0.0000150
2021-07-24 10:18:22,458 DEV : loss 0.06925068795681 - score 0.9853
2021-07-24 10:18:22,477 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:18:24,864 ----------------------------------------------------------------------------------------------------
2021-07-24 10:18:26,304 epoch 22 - iter 6/65 - loss 0.17483387 - samples/sec: 133.57 - lr: 0.000015
2021-07-24 10:18:27,675 epoch 22 - iter 12/65 - loss 0.12698062 - samples/sec: 140.04 - lr: 0.000015
2021-07-24 10:18:29,079 epoch 22 - iter 18/65 - loss 0.15215251 - samples/sec: 136.84 - lr: 0.000015
2021-07-24 10:18:30,485 epoch 22 - iter 24/65 - loss 0.15030972 - samples/sec: 136.63 - lr: 0.000015
2021-07-24 10:18:31,856 epoch 22 - iter 30/65 - loss 0.15462725 - samples/sec: 140.09 - lr: 0.000015
2021-07-24 10:18:33,165 epoch 22 - iter 36/65 - loss 0.15312665 - samples/sec: 146.76 - lr: 0.000015
2021-07-24 10:18:34,548 epoch 22 - iter 42/65 - loss 0.15250854 - samples/sec: 138.83 - lr: 0.000015
2021-07-24 10:18:35,984 epoch 22 - iter 48/65 - loss 0.14642692 - samples/sec: 133.82 - lr: 0.000015
2021-07-24 10:18:37,407 epoch 22 - iter 54/65 - loss 0.15532875 - samples/sec: 134.90 - lr: 0.000015
2021-07-24 10:18:38,800 epoch 22 - iter 60/65 - loss 0.15548660 - samples/sec: 137.90 - lr: 0.000015
2021-07-24 10:18:39,754 ----------------------------------------------------------------------------------------------------
2021-07-24 10:18:39,754 EPOCH 22 done: loss 0.1508 - lr 0.0000150
2021-07-24 10:18:41,129 DEV : loss 0.068712018430233 - score 0.9841
2021-07-24 10:18:41,144 BAD EPOCHS (no improvement): 1
2021-07-24 10:18:41,145 ----------------------------------------------------------------------------------------------------
2021-07-24 10:18:42,583 epoch 23 - iter 6/65 - loss 0.14153750 - samples/sec: 133.59 - lr: 0.000015
2021-07-24 10:18:43,937 epoch 23 - iter 12/65 - loss 0.15664826 - samples/sec: 141.94 - lr: 0.000015
2021-07-24 10:18:45,348 epoch 23 - iter 18/65 - loss 0.16512556 - samples/sec: 136.12 - lr: 0.000015
2021-07-24 10:18:46,707 epoch 23 - iter 24/65 - loss 0.15877449 - samples/sec: 141.32 - lr: 0.000015
2021-07-24 10:18:48,061 epoch 23 - iter 30/65 - loss 0.16204652 - samples/sec: 141.89 - lr: 0.000015
2021-07-24 10:18:49,431 epoch 23 - iter 36/65 - loss 0.16789717 - samples/sec: 140.11 - lr: 0.000015
2021-07-24 10:18:50,854 epoch 23 - iter 42/65 - loss 0.16112581 - samples/sec: 135.04 - lr: 0.000015
2021-07-24 10:18:52,154 epoch 23 - iter 48/65 - loss 0.16133478 - samples/sec: 147.73 - lr: 0.000015
2021-07-24 10:18:53,601 epoch 23 - iter 54/65 - loss 0.15427469 - samples/sec: 132.76 - lr: 0.000015
2021-07-24 10:18:54,961 epoch 23 - iter 60/65 - loss 0.14922176 - samples/sec: 141.26 - lr: 0.000015
2021-07-24 10:18:56,037 ----------------------------------------------------------------------------------------------------
2021-07-24 10:18:56,037 EPOCH 23 done: loss 0.1473 - lr 0.0000150
2021-07-24 10:18:57,413 DEV : loss 0.06809617578983307 - score 0.9842
2021-07-24 10:18:57,429 BAD EPOCHS (no improvement): 2
2021-07-24 10:18:57,429 ----------------------------------------------------------------------------------------------------
2021-07-24 10:18:58,780 epoch 24 - iter 6/65 - loss 0.14020266 - samples/sec: 142.29 - lr: 0.000015
2021-07-24 10:19:00,171 epoch 24 - iter 12/65 - loss 0.19390288 - samples/sec: 138.00 - lr: 0.000015
2021-07-24 10:19:01,640 epoch 24 - iter 18/65 - loss 0.16342830 - samples/sec: 130.77 - lr: 0.000015
2021-07-24 10:19:03,032 epoch 24 - iter 24/65 - loss 0.15441216 - samples/sec: 138.05 - lr: 0.000015
2021-07-24 10:19:04,455 epoch 24 - iter 30/65 - loss 0.15596576 - samples/sec: 134.91 - lr: 0.000015
2021-07-24 10:19:05,833 epoch 24 - iter 36/65 - loss 0.15839312 - samples/sec: 139.45 - lr: 0.000015
2021-07-24 10:19:07,217 epoch 24 - iter 42/65 - loss 0.15659375 - samples/sec: 138.76 - lr: 0.000015
2021-07-24 10:19:08,535 epoch 24 - iter 48/65 - loss 0.15161486 - samples/sec: 145.68 - lr: 0.000015
2021-07-24 10:19:09,837 epoch 24 - iter 54/65 - loss 0.14762200 - samples/sec: 147.63 - lr: 0.000015
2021-07-24 10:19:11,235 epoch 24 - iter 60/65 - loss 0.14582392 - samples/sec: 137.36 - lr: 0.000015
2021-07-24 10:19:12,271 ----------------------------------------------------------------------------------------------------
2021-07-24 10:19:12,271 EPOCH 24 done: loss 0.1434 - lr 0.0000150
2021-07-24 10:19:13,644 DEV : loss 0.06735493987798691 - score 0.9842
2021-07-24 10:19:13,660 BAD EPOCHS (no improvement): 3
2021-07-24 10:19:13,660 ----------------------------------------------------------------------------------------------------
2021-07-24 10:19:15,140 epoch 25 - iter 6/65 - loss 0.14442791 - samples/sec: 129.89 - lr: 0.000015
2021-07-24 10:19:16,556 epoch 25 - iter 12/65 - loss 0.15591547 - samples/sec: 135.58 - lr: 0.000015
2021-07-24 10:19:17,936 epoch 25 - iter 18/65 - loss 0.14036953 - samples/sec: 139.21 - lr: 0.000015
2021-07-24 10:19:19,271 epoch 25 - iter 24/65 - loss 0.14410382 - samples/sec: 143.91 - lr: 0.000015
2021-07-24 10:19:20,704 epoch 25 - iter 30/65 - loss 0.15078947 - samples/sec: 133.98 - lr: 0.000015
2021-07-24 10:19:22,092 epoch 25 - iter 36/65 - loss 0.13995523 - samples/sec: 138.38 - lr: 0.000015
2021-07-24 10:19:23,451 epoch 25 - iter 42/65 - loss 0.14951249 - samples/sec: 141.33 - lr: 0.000015
2021-07-24 10:19:24,811 epoch 25 - iter 48/65 - loss 0.15163923 - samples/sec: 141.23 - lr: 0.000015
2021-07-24 10:19:26,184 epoch 25 - iter 54/65 - loss 0.14951744 - samples/sec: 139.96 - lr: 0.000015
2021-07-24 10:19:27,596 epoch 25 - iter 60/65 - loss 0.15593117 - samples/sec: 135.96 - lr: 0.000015
2021-07-24 10:19:28,634 ----------------------------------------------------------------------------------------------------
2021-07-24 10:19:28,635 EPOCH 25 done: loss 0.1592 - lr 0.0000150
2021-07-24 10:19:30,008 DEV : loss 0.06655335426330566 - score 0.9842
Epoch    25: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 10:19:30,024 BAD EPOCHS (no improvement): 4
2021-07-24 10:19:30,024 ----------------------------------------------------------------------------------------------------
2021-07-24 10:19:31,393 epoch 26 - iter 6/65 - loss 0.12540431 - samples/sec: 140.45 - lr: 0.000008
2021-07-24 10:19:32,785 epoch 26 - iter 12/65 - loss 0.11834571 - samples/sec: 137.97 - lr: 0.000008
2021-07-24 10:19:34,148 epoch 26 - iter 18/65 - loss 0.13044818 - samples/sec: 140.87 - lr: 0.000008
2021-07-24 10:19:35,431 epoch 26 - iter 24/65 - loss 0.15738432 - samples/sec: 149.75 - lr: 0.000008
2021-07-24 10:19:36,899 epoch 26 - iter 30/65 - loss 0.17216199 - samples/sec: 130.81 - lr: 0.000008
2021-07-24 10:19:38,348 epoch 26 - iter 36/65 - loss 0.17558757 - samples/sec: 132.60 - lr: 0.000008
2021-07-24 10:19:39,751 epoch 26 - iter 42/65 - loss 0.17291129 - samples/sec: 136.90 - lr: 0.000008
2021-07-24 10:19:41,107 epoch 26 - iter 48/65 - loss 0.16854209 - samples/sec: 141.62 - lr: 0.000008
2021-07-24 10:19:42,409 epoch 26 - iter 54/65 - loss 0.16062583 - samples/sec: 147.57 - lr: 0.000008
2021-07-24 10:19:43,816 epoch 26 - iter 60/65 - loss 0.15474300 - samples/sec: 136.50 - lr: 0.000008
2021-07-24 10:19:44,855 ----------------------------------------------------------------------------------------------------
2021-07-24 10:19:44,855 EPOCH 26 done: loss 0.1541 - lr 0.0000075
2021-07-24 10:19:46,228 DEV : loss 0.06629596650600433 - score 0.9853
2021-07-24 10:19:46,244 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:19:48,333 ----------------------------------------------------------------------------------------------------
2021-07-24 10:19:49,708 epoch 27 - iter 6/65 - loss 0.23206174 - samples/sec: 139.88 - lr: 0.000008
2021-07-24 10:19:51,033 epoch 27 - iter 12/65 - loss 0.19667377 - samples/sec: 144.99 - lr: 0.000008
2021-07-24 10:19:52,391 epoch 27 - iter 18/65 - loss 0.18143071 - samples/sec: 141.38 - lr: 0.000008
2021-07-24 10:19:53,888 epoch 27 - iter 24/65 - loss 0.17464293 - samples/sec: 128.30 - lr: 0.000008
2021-07-24 10:19:55,251 epoch 27 - iter 30/65 - loss 0.16485876 - samples/sec: 140.95 - lr: 0.000008
2021-07-24 10:19:56,648 epoch 27 - iter 36/65 - loss 0.16086963 - samples/sec: 137.47 - lr: 0.000008
2021-07-24 10:19:57,974 epoch 27 - iter 42/65 - loss 0.14920618 - samples/sec: 144.91 - lr: 0.000008
2021-07-24 10:19:59,445 epoch 27 - iter 48/65 - loss 0.15147270 - samples/sec: 130.53 - lr: 0.000008
2021-07-24 10:20:00,849 epoch 27 - iter 54/65 - loss 0.14615591 - samples/sec: 136.85 - lr: 0.000008
2021-07-24 10:20:02,233 epoch 27 - iter 60/65 - loss 0.14145376 - samples/sec: 138.80 - lr: 0.000008
2021-07-24 10:20:03,185 ----------------------------------------------------------------------------------------------------
2021-07-24 10:20:03,185 EPOCH 27 done: loss 0.1467 - lr 0.0000075
2021-07-24 10:20:04,557 DEV : loss 0.06587570905685425 - score 0.9842
2021-07-24 10:20:04,576 BAD EPOCHS (no improvement): 1
2021-07-24 10:20:04,576 ----------------------------------------------------------------------------------------------------
2021-07-24 10:20:05,957 epoch 28 - iter 6/65 - loss 0.19545871 - samples/sec: 139.18 - lr: 0.000008
2021-07-24 10:20:07,327 epoch 28 - iter 12/65 - loss 0.15070429 - samples/sec: 140.23 - lr: 0.000008
2021-07-24 10:20:08,721 epoch 28 - iter 18/65 - loss 0.14583102 - samples/sec: 137.76 - lr: 0.000008
2021-07-24 10:20:10,071 epoch 28 - iter 24/65 - loss 0.14222190 - samples/sec: 142.29 - lr: 0.000008
2021-07-24 10:20:11,473 epoch 28 - iter 30/65 - loss 0.13656240 - samples/sec: 137.03 - lr: 0.000008
2021-07-24 10:20:12,823 epoch 28 - iter 36/65 - loss 0.13533157 - samples/sec: 142.23 - lr: 0.000008
2021-07-24 10:20:14,208 epoch 28 - iter 42/65 - loss 0.14159996 - samples/sec: 138.70 - lr: 0.000008
2021-07-24 10:20:15,592 epoch 28 - iter 48/65 - loss 0.13932339 - samples/sec: 138.81 - lr: 0.000008
2021-07-24 10:20:17,004 epoch 28 - iter 54/65 - loss 0.13815198 - samples/sec: 135.99 - lr: 0.000008
2021-07-24 10:20:18,384 epoch 28 - iter 60/65 - loss 0.13537557 - samples/sec: 139.21 - lr: 0.000008
2021-07-24 10:20:19,434 ----------------------------------------------------------------------------------------------------
2021-07-24 10:20:19,435 EPOCH 28 done: loss 0.1373 - lr 0.0000075
2021-07-24 10:20:20,807 DEV : loss 0.06597825139760971 - score 0.9842
2021-07-24 10:20:20,822 BAD EPOCHS (no improvement): 2
2021-07-24 10:20:20,822 ----------------------------------------------------------------------------------------------------
2021-07-24 10:20:22,170 epoch 29 - iter 6/65 - loss 0.08729067 - samples/sec: 142.58 - lr: 0.000008
2021-07-24 10:20:23,519 epoch 29 - iter 12/65 - loss 0.09079975 - samples/sec: 142.47 - lr: 0.000008
2021-07-24 10:20:24,890 epoch 29 - iter 18/65 - loss 0.09591410 - samples/sec: 140.08 - lr: 0.000008
2021-07-24 10:20:26,239 epoch 29 - iter 24/65 - loss 0.10684447 - samples/sec: 142.34 - lr: 0.000008
2021-07-24 10:20:27,629 epoch 29 - iter 30/65 - loss 0.10797067 - samples/sec: 138.19 - lr: 0.000008
2021-07-24 10:20:29,037 epoch 29 - iter 36/65 - loss 0.10741232 - samples/sec: 136.44 - lr: 0.000008
2021-07-24 10:20:30,396 epoch 29 - iter 42/65 - loss 0.11390844 - samples/sec: 141.33 - lr: 0.000008
2021-07-24 10:20:31,756 epoch 29 - iter 48/65 - loss 0.12162279 - samples/sec: 141.25 - lr: 0.000008
2021-07-24 10:20:33,160 epoch 29 - iter 54/65 - loss 0.12557893 - samples/sec: 136.75 - lr: 0.000008
2021-07-24 10:20:34,561 epoch 29 - iter 60/65 - loss 0.12862878 - samples/sec: 137.15 - lr: 0.000008
2021-07-24 10:20:35,660 ----------------------------------------------------------------------------------------------------
2021-07-24 10:20:35,660 EPOCH 29 done: loss 0.1277 - lr 0.0000075
2021-07-24 10:20:37,033 DEV : loss 0.06545427441596985 - score 0.9842
2021-07-24 10:20:37,048 BAD EPOCHS (no improvement): 3
2021-07-24 10:20:37,048 ----------------------------------------------------------------------------------------------------
2021-07-24 10:20:38,440 epoch 30 - iter 6/65 - loss 0.13915764 - samples/sec: 138.06 - lr: 0.000008
2021-07-24 10:20:39,816 epoch 30 - iter 12/65 - loss 0.15155710 - samples/sec: 139.62 - lr: 0.000008
2021-07-24 10:20:41,141 epoch 30 - iter 18/65 - loss 0.14654541 - samples/sec: 145.05 - lr: 0.000008
2021-07-24 10:20:42,611 epoch 30 - iter 24/65 - loss 0.14299049 - samples/sec: 130.58 - lr: 0.000008
2021-07-24 10:20:44,078 epoch 30 - iter 30/65 - loss 0.14278123 - samples/sec: 130.99 - lr: 0.000008
2021-07-24 10:20:45,485 epoch 30 - iter 36/65 - loss 0.13434625 - samples/sec: 136.50 - lr: 0.000008
2021-07-24 10:20:46,840 epoch 30 - iter 42/65 - loss 0.13270109 - samples/sec: 141.76 - lr: 0.000008
2021-07-24 10:20:48,219 epoch 30 - iter 48/65 - loss 0.13372559 - samples/sec: 139.25 - lr: 0.000008
2021-07-24 10:20:49,586 epoch 30 - iter 54/65 - loss 0.13505380 - samples/sec: 140.49 - lr: 0.000008
2021-07-24 10:20:50,960 epoch 30 - iter 60/65 - loss 0.13559492 - samples/sec: 139.81 - lr: 0.000008
2021-07-24 10:20:51,943 ----------------------------------------------------------------------------------------------------
2021-07-24 10:20:51,943 EPOCH 30 done: loss 0.1349 - lr 0.0000075
2021-07-24 10:20:53,311 DEV : loss 0.06548282504081726 - score 0.9853
2021-07-24 10:20:53,326 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:20:55,703 ----------------------------------------------------------------------------------------------------
2021-07-24 10:20:57,102 epoch 31 - iter 6/65 - loss 0.13608915 - samples/sec: 137.51 - lr: 0.000008
2021-07-24 10:20:58,607 epoch 31 - iter 12/65 - loss 0.15845940 - samples/sec: 127.56 - lr: 0.000008
2021-07-24 10:21:00,001 epoch 31 - iter 18/65 - loss 0.14021950 - samples/sec: 137.85 - lr: 0.000008
2021-07-24 10:21:01,464 epoch 31 - iter 24/65 - loss 0.13925784 - samples/sec: 131.30 - lr: 0.000008
2021-07-24 10:21:02,832 epoch 31 - iter 30/65 - loss 0.13078450 - samples/sec: 140.34 - lr: 0.000008
2021-07-24 10:21:04,175 epoch 31 - iter 36/65 - loss 0.12263555 - samples/sec: 143.00 - lr: 0.000008
2021-07-24 10:21:05,571 epoch 31 - iter 42/65 - loss 0.12669521 - samples/sec: 137.60 - lr: 0.000008
2021-07-24 10:21:06,955 epoch 31 - iter 48/65 - loss 0.12966390 - samples/sec: 138.80 - lr: 0.000008
2021-07-24 10:21:08,424 epoch 31 - iter 54/65 - loss 0.13054452 - samples/sec: 130.75 - lr: 0.000008
2021-07-24 10:21:09,747 epoch 31 - iter 60/65 - loss 0.13089161 - samples/sec: 145.17 - lr: 0.000008
2021-07-24 10:21:10,743 ----------------------------------------------------------------------------------------------------
2021-07-24 10:21:10,743 EPOCH 31 done: loss 0.1334 - lr 0.0000075
2021-07-24 10:21:12,110 DEV : loss 0.06559143215417862 - score 0.9853
2021-07-24 10:21:12,126 BAD EPOCHS (no improvement): 1
2021-07-24 10:21:12,126 ----------------------------------------------------------------------------------------------------
2021-07-24 10:21:13,503 epoch 32 - iter 6/65 - loss 0.15224450 - samples/sec: 139.61 - lr: 0.000008
2021-07-24 10:21:14,911 epoch 32 - iter 12/65 - loss 0.13854225 - samples/sec: 136.38 - lr: 0.000008
2021-07-24 10:21:16,265 epoch 32 - iter 18/65 - loss 0.15429910 - samples/sec: 141.91 - lr: 0.000008
2021-07-24 10:21:17,692 epoch 32 - iter 24/65 - loss 0.16129249 - samples/sec: 134.58 - lr: 0.000008
2021-07-24 10:21:19,081 epoch 32 - iter 30/65 - loss 0.15401265 - samples/sec: 138.30 - lr: 0.000008
2021-07-24 10:21:20,527 epoch 32 - iter 36/65 - loss 0.14450292 - samples/sec: 132.84 - lr: 0.000008
2021-07-24 10:21:21,924 epoch 32 - iter 42/65 - loss 0.14415081 - samples/sec: 137.51 - lr: 0.000008
2021-07-24 10:21:23,299 epoch 32 - iter 48/65 - loss 0.13934102 - samples/sec: 139.67 - lr: 0.000008
2021-07-24 10:21:24,656 epoch 32 - iter 54/65 - loss 0.14264288 - samples/sec: 141.56 - lr: 0.000008
2021-07-24 10:21:25,992 epoch 32 - iter 60/65 - loss 0.13878825 - samples/sec: 143.69 - lr: 0.000008
2021-07-24 10:21:27,067 ----------------------------------------------------------------------------------------------------
2021-07-24 10:21:27,068 EPOCH 32 done: loss 0.1379 - lr 0.0000075
2021-07-24 10:21:28,438 DEV : loss 0.06474500149488449 - score 0.9842
2021-07-24 10:21:28,454 BAD EPOCHS (no improvement): 2
2021-07-24 10:21:28,454 ----------------------------------------------------------------------------------------------------
2021-07-24 10:21:29,881 epoch 33 - iter 6/65 - loss 0.12822446 - samples/sec: 134.72 - lr: 0.000008
2021-07-24 10:21:31,267 epoch 33 - iter 12/65 - loss 0.16163287 - samples/sec: 138.52 - lr: 0.000008
2021-07-24 10:21:32,616 epoch 33 - iter 18/65 - loss 0.16358931 - samples/sec: 142.43 - lr: 0.000008
2021-07-24 10:21:34,029 epoch 33 - iter 24/65 - loss 0.15801603 - samples/sec: 135.85 - lr: 0.000008
2021-07-24 10:21:35,481 epoch 33 - iter 30/65 - loss 0.16069497 - samples/sec: 132.30 - lr: 0.000008
2021-07-24 10:21:36,912 epoch 33 - iter 36/65 - loss 0.15210676 - samples/sec: 134.28 - lr: 0.000008
2021-07-24 10:21:38,291 epoch 33 - iter 42/65 - loss 0.15042138 - samples/sec: 139.23 - lr: 0.000008
2021-07-24 10:21:39,655 epoch 33 - iter 48/65 - loss 0.14587704 - samples/sec: 140.80 - lr: 0.000008
2021-07-24 10:21:41,007 epoch 33 - iter 54/65 - loss 0.14658466 - samples/sec: 142.11 - lr: 0.000008
2021-07-24 10:21:42,344 epoch 33 - iter 60/65 - loss 0.14341334 - samples/sec: 143.65 - lr: 0.000008
2021-07-24 10:21:43,392 ----------------------------------------------------------------------------------------------------
2021-07-24 10:21:43,392 EPOCH 33 done: loss 0.1441 - lr 0.0000075
2021-07-24 10:21:44,761 DEV : loss 0.06509044766426086 - score 0.9853
2021-07-24 10:21:44,776 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:21:47,229 ----------------------------------------------------------------------------------------------------
2021-07-24 10:21:48,693 epoch 34 - iter 6/65 - loss 0.11832022 - samples/sec: 131.42 - lr: 0.000008
2021-07-24 10:21:50,063 epoch 34 - iter 12/65 - loss 0.14787905 - samples/sec: 140.11 - lr: 0.000008
2021-07-24 10:21:51,444 epoch 34 - iter 18/65 - loss 0.12817576 - samples/sec: 139.16 - lr: 0.000008
2021-07-24 10:21:52,835 epoch 34 - iter 24/65 - loss 0.12940344 - samples/sec: 138.05 - lr: 0.000008
2021-07-24 10:21:54,191 epoch 34 - iter 30/65 - loss 0.12967254 - samples/sec: 141.67 - lr: 0.000008
2021-07-24 10:21:55,652 epoch 34 - iter 36/65 - loss 0.12678277 - samples/sec: 131.42 - lr: 0.000008
2021-07-24 10:21:57,061 epoch 34 - iter 42/65 - loss 0.13181518 - samples/sec: 136.34 - lr: 0.000008
2021-07-24 10:21:58,465 epoch 34 - iter 48/65 - loss 0.13254179 - samples/sec: 136.78 - lr: 0.000008
2021-07-24 10:21:59,825 epoch 34 - iter 54/65 - loss 0.13575149 - samples/sec: 141.25 - lr: 0.000008
2021-07-24 10:22:01,226 epoch 34 - iter 60/65 - loss 0.13390986 - samples/sec: 137.14 - lr: 0.000008
2021-07-24 10:22:02,191 ----------------------------------------------------------------------------------------------------
2021-07-24 10:22:02,191 EPOCH 34 done: loss 0.1351 - lr 0.0000075
2021-07-24 10:22:03,562 DEV : loss 0.06475645303726196 - score 0.9853
2021-07-24 10:22:03,578 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:22:06,086 ----------------------------------------------------------------------------------------------------
2021-07-24 10:22:07,476 epoch 35 - iter 6/65 - loss 0.10214477 - samples/sec: 138.29 - lr: 0.000008
2021-07-24 10:22:08,888 epoch 35 - iter 12/65 - loss 0.11499272 - samples/sec: 136.05 - lr: 0.000008
2021-07-24 10:22:10,273 epoch 35 - iter 18/65 - loss 0.11844326 - samples/sec: 138.71 - lr: 0.000008
2021-07-24 10:22:11,616 epoch 35 - iter 24/65 - loss 0.11662716 - samples/sec: 142.93 - lr: 0.000008
2021-07-24 10:22:13,020 epoch 35 - iter 30/65 - loss 0.10761104 - samples/sec: 136.89 - lr: 0.000008
2021-07-24 10:22:14,462 epoch 35 - iter 36/65 - loss 0.11485488 - samples/sec: 133.12 - lr: 0.000008
2021-07-24 10:22:15,890 epoch 35 - iter 42/65 - loss 0.12415651 - samples/sec: 134.54 - lr: 0.000008
2021-07-24 10:22:17,288 epoch 35 - iter 48/65 - loss 0.12328687 - samples/sec: 137.37 - lr: 0.000008
2021-07-24 10:22:18,607 epoch 35 - iter 54/65 - loss 0.12312611 - samples/sec: 145.69 - lr: 0.000008
2021-07-24 10:22:19,994 epoch 35 - iter 60/65 - loss 0.11780786 - samples/sec: 138.50 - lr: 0.000008
2021-07-24 10:22:21,046 ----------------------------------------------------------------------------------------------------
2021-07-24 10:22:21,047 EPOCH 35 done: loss 0.1187 - lr 0.0000075
2021-07-24 10:22:22,416 DEV : loss 0.06455554813146591 - score 0.9853
2021-07-24 10:22:22,432 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:22:24,800 ----------------------------------------------------------------------------------------------------
2021-07-24 10:22:26,260 epoch 36 - iter 6/65 - loss 0.15007834 - samples/sec: 131.71 - lr: 0.000008
2021-07-24 10:22:27,663 epoch 36 - iter 12/65 - loss 0.13137340 - samples/sec: 136.81 - lr: 0.000008
2021-07-24 10:22:29,104 epoch 36 - iter 18/65 - loss 0.12702819 - samples/sec: 133.37 - lr: 0.000008
2021-07-24 10:22:30,463 epoch 36 - iter 24/65 - loss 0.14228239 - samples/sec: 141.27 - lr: 0.000008
2021-07-24 10:22:31,897 epoch 36 - iter 30/65 - loss 0.14298816 - samples/sec: 133.98 - lr: 0.000008
2021-07-24 10:22:33,276 epoch 36 - iter 36/65 - loss 0.14326623 - samples/sec: 139.24 - lr: 0.000008
2021-07-24 10:22:34,691 epoch 36 - iter 42/65 - loss 0.14148903 - samples/sec: 135.73 - lr: 0.000008
2021-07-24 10:22:36,000 epoch 36 - iter 48/65 - loss 0.14427880 - samples/sec: 146.75 - lr: 0.000008
2021-07-24 10:22:37,319 epoch 36 - iter 54/65 - loss 0.15392793 - samples/sec: 145.64 - lr: 0.000008
2021-07-24 10:22:38,655 epoch 36 - iter 60/65 - loss 0.15822725 - samples/sec: 143.72 - lr: 0.000008
2021-07-24 10:22:39,707 ----------------------------------------------------------------------------------------------------
2021-07-24 10:22:39,708 EPOCH 36 done: loss 0.1558 - lr 0.0000075
2021-07-24 10:22:41,077 DEV : loss 0.06471298635005951 - score 0.9853
2021-07-24 10:22:41,093 BAD EPOCHS (no improvement): 1
2021-07-24 10:22:41,093 ----------------------------------------------------------------------------------------------------
2021-07-24 10:22:42,464 epoch 37 - iter 6/65 - loss 0.23066755 - samples/sec: 140.21 - lr: 0.000008
2021-07-24 10:22:43,951 epoch 37 - iter 12/65 - loss 0.19513994 - samples/sec: 129.15 - lr: 0.000008
2021-07-24 10:22:45,296 epoch 37 - iter 18/65 - loss 0.17547338 - samples/sec: 142.83 - lr: 0.000008
2021-07-24 10:22:46,685 epoch 37 - iter 24/65 - loss 0.17043103 - samples/sec: 138.26 - lr: 0.000008
2021-07-24 10:22:48,079 epoch 37 - iter 30/65 - loss 0.16093736 - samples/sec: 137.76 - lr: 0.000008
2021-07-24 10:22:49,461 epoch 37 - iter 36/65 - loss 0.15387820 - samples/sec: 139.01 - lr: 0.000008
2021-07-24 10:22:50,891 epoch 37 - iter 42/65 - loss 0.15204704 - samples/sec: 134.29 - lr: 0.000008
2021-07-24 10:22:52,276 epoch 37 - iter 48/65 - loss 0.14928864 - samples/sec: 138.71 - lr: 0.000008
2021-07-24 10:22:53,683 epoch 37 - iter 54/65 - loss 0.14277678 - samples/sec: 136.49 - lr: 0.000008
2021-07-24 10:22:55,084 epoch 37 - iter 60/65 - loss 0.14040893 - samples/sec: 137.10 - lr: 0.000008
2021-07-24 10:22:56,138 ----------------------------------------------------------------------------------------------------
2021-07-24 10:22:56,138 EPOCH 37 done: loss 0.1427 - lr 0.0000075
2021-07-24 10:22:57,507 DEV : loss 0.06419026851654053 - score 0.9853
2021-07-24 10:22:57,522 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:22:59,882 ----------------------------------------------------------------------------------------------------
2021-07-24 10:23:01,287 epoch 38 - iter 6/65 - loss 0.09154169 - samples/sec: 136.95 - lr: 0.000008
2021-07-24 10:23:02,647 epoch 38 - iter 12/65 - loss 0.10536267 - samples/sec: 141.19 - lr: 0.000008
2021-07-24 10:23:04,139 epoch 38 - iter 18/65 - loss 0.11296778 - samples/sec: 128.75 - lr: 0.000008
2021-07-24 10:23:05,563 epoch 38 - iter 24/65 - loss 0.11856818 - samples/sec: 134.82 - lr: 0.000008
2021-07-24 10:23:06,933 epoch 38 - iter 30/65 - loss 0.13373834 - samples/sec: 140.27 - lr: 0.000008
2021-07-24 10:23:08,271 epoch 38 - iter 36/65 - loss 0.12866845 - samples/sec: 143.54 - lr: 0.000008
2021-07-24 10:23:09,643 epoch 38 - iter 42/65 - loss 0.12513044 - samples/sec: 140.01 - lr: 0.000008
2021-07-24 10:23:10,936 epoch 38 - iter 48/65 - loss 0.12177450 - samples/sec: 148.48 - lr: 0.000008
2021-07-24 10:23:12,352 epoch 38 - iter 54/65 - loss 0.11834797 - samples/sec: 135.72 - lr: 0.000008
2021-07-24 10:23:13,713 epoch 38 - iter 60/65 - loss 0.12339457 - samples/sec: 141.11 - lr: 0.000008
2021-07-24 10:23:14,746 ----------------------------------------------------------------------------------------------------
2021-07-24 10:23:14,746 EPOCH 38 done: loss 0.1253 - lr 0.0000075
2021-07-24 10:23:16,124 DEV : loss 0.06439203768968582 - score 0.9875
2021-07-24 10:23:16,139 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:23:18,576 ----------------------------------------------------------------------------------------------------
2021-07-24 10:23:19,985 epoch 39 - iter 6/65 - loss 0.14979081 - samples/sec: 136.56 - lr: 0.000008
2021-07-24 10:23:21,320 epoch 39 - iter 12/65 - loss 0.12684983 - samples/sec: 143.83 - lr: 0.000008
2021-07-24 10:23:22,733 epoch 39 - iter 18/65 - loss 0.12256297 - samples/sec: 135.99 - lr: 0.000008
2021-07-24 10:23:24,179 epoch 39 - iter 24/65 - loss 0.12682509 - samples/sec: 132.79 - lr: 0.000008
2021-07-24 10:23:25,516 epoch 39 - iter 30/65 - loss 0.12474691 - samples/sec: 143.63 - lr: 0.000008
2021-07-24 10:23:26,911 epoch 39 - iter 36/65 - loss 0.12429960 - samples/sec: 137.76 - lr: 0.000008
2021-07-24 10:23:28,328 epoch 39 - iter 42/65 - loss 0.12513791 - samples/sec: 135.48 - lr: 0.000008
2021-07-24 10:23:29,721 epoch 39 - iter 48/65 - loss 0.13478136 - samples/sec: 137.89 - lr: 0.000008
2021-07-24 10:23:31,113 epoch 39 - iter 54/65 - loss 0.13442146 - samples/sec: 138.00 - lr: 0.000008
2021-07-24 10:23:32,445 epoch 39 - iter 60/65 - loss 0.13467951 - samples/sec: 144.20 - lr: 0.000008
2021-07-24 10:23:33,519 ----------------------------------------------------------------------------------------------------
2021-07-24 10:23:33,519 EPOCH 39 done: loss 0.1334 - lr 0.0000075
2021-07-24 10:23:34,890 DEV : loss 0.06424189358949661 - score 0.9864
2021-07-24 10:23:34,905 BAD EPOCHS (no improvement): 1
2021-07-24 10:23:34,905 ----------------------------------------------------------------------------------------------------
2021-07-24 10:23:36,312 epoch 40 - iter 6/65 - loss 0.13879455 - samples/sec: 136.65 - lr: 0.000008
2021-07-24 10:23:37,779 epoch 40 - iter 12/65 - loss 0.13074698 - samples/sec: 130.89 - lr: 0.000008
2021-07-24 10:23:39,116 epoch 40 - iter 18/65 - loss 0.11132086 - samples/sec: 143.65 - lr: 0.000008
2021-07-24 10:23:40,541 epoch 40 - iter 24/65 - loss 0.12752716 - samples/sec: 134.85 - lr: 0.000008
2021-07-24 10:23:41,921 epoch 40 - iter 30/65 - loss 0.13642370 - samples/sec: 139.17 - lr: 0.000008
2021-07-24 10:23:43,296 epoch 40 - iter 36/65 - loss 0.14024646 - samples/sec: 139.69 - lr: 0.000008
2021-07-24 10:23:44,609 epoch 40 - iter 42/65 - loss 0.13459579 - samples/sec: 146.31 - lr: 0.000008
2021-07-24 10:23:46,005 epoch 40 - iter 48/65 - loss 0.13395487 - samples/sec: 137.56 - lr: 0.000008
2021-07-24 10:23:47,338 epoch 40 - iter 54/65 - loss 0.13488617 - samples/sec: 144.11 - lr: 0.000008
2021-07-24 10:23:48,752 epoch 40 - iter 60/65 - loss 0.13471111 - samples/sec: 135.81 - lr: 0.000008
2021-07-24 10:23:49,826 ----------------------------------------------------------------------------------------------------
2021-07-24 10:23:49,826 EPOCH 40 done: loss 0.1304 - lr 0.0000075
2021-07-24 10:23:51,203 DEV : loss 0.06370299309492111 - score 0.9864
2021-07-24 10:23:51,218 BAD EPOCHS (no improvement): 2
2021-07-24 10:23:51,786 ----------------------------------------------------------------------------------------------------
2021-07-24 10:23:51,786 Testing using best model ...
2021-07-24 10:23:51,787 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/nld.rst.nldt/best-model.pt
2021-07-24 10:24:03,027 0.9854	0.9890	0.9872
2021-07-24 10:24:03,027 
Results:
- F1-score (micro) 0.9872
- F1-score (macro) 0.9894

By class:
SENT       tp: 323 - fp: 8 - fn: 6 - precision: 0.9758 - recall: 0.9818 - f1-score: 0.9788
X          tp: 216 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-24 10:24:03,028 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.sdrt.stac/
2021-07-24 10:24:03,065 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.sdrt.stac
2021-07-24 10:24:03,067 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.sdrt.stac/sent_train.txt
2021-07-24 10:24:03,069 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.sdrt.stac/sent_dev.txt
2021-07-24 10:24:03,070 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.sdrt.stac/sent_test.txt
Corpus: 9290 train + 1406 dev + 2942 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-24 10:24:06,565 ----------------------------------------------------------------------------------------------------
2021-07-24 10:24:06,566 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-24 10:24:06,566 ----------------------------------------------------------------------------------------------------
2021-07-24 10:24:06,566 Corpus: "Corpus: 9290 train + 1406 dev + 2942 test sentences"
2021-07-24 10:24:06,566 ----------------------------------------------------------------------------------------------------
2021-07-24 10:24:06,567 Parameters:
2021-07-24 10:24:06,567  - learning_rate: "3e-05"
2021-07-24 10:24:06,567  - mini_batch_size: "32"
2021-07-24 10:24:06,567  - patience: "3"
2021-07-24 10:24:06,567  - anneal_factor: "0.5"
2021-07-24 10:24:06,567  - max_epochs: "40"
2021-07-24 10:24:06,567  - shuffle: "True"
2021-07-24 10:24:06,567  - train_with_dev: "False"
2021-07-24 10:24:06,567  - batch_growth_annealing: "False"
2021-07-24 10:24:06,567 ----------------------------------------------------------------------------------------------------
2021-07-24 10:24:06,567 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.sdrt.stac"
2021-07-24 10:24:06,567 ----------------------------------------------------------------------------------------------------
2021-07-24 10:24:06,567 Device: cuda:0
2021-07-24 10:24:06,567 ----------------------------------------------------------------------------------------------------
2021-07-24 10:24:06,567 Embeddings storage mode: cpu
2021-07-24 10:24:06,570 ----------------------------------------------------------------------------------------------------
2021-07-24 10:24:21,049 epoch 1 - iter 29/291 - loss 7.15799305 - samples/sec: 64.10 - lr: 0.000030
2021-07-24 10:24:34,726 epoch 1 - iter 58/291 - loss 5.28455054 - samples/sec: 67.86 - lr: 0.000030
2021-07-24 10:24:48,526 epoch 1 - iter 87/291 - loss 4.40827747 - samples/sec: 67.25 - lr: 0.000030
2021-07-24 10:25:02,217 epoch 1 - iter 116/291 - loss 3.75555726 - samples/sec: 67.79 - lr: 0.000030
2021-07-24 10:25:16,050 epoch 1 - iter 145/291 - loss 3.27809338 - samples/sec: 67.09 - lr: 0.000030
2021-07-24 10:25:29,800 epoch 1 - iter 174/291 - loss 2.90878556 - samples/sec: 67.50 - lr: 0.000030
2021-07-24 10:25:43,396 epoch 1 - iter 203/291 - loss 2.60789983 - samples/sec: 68.27 - lr: 0.000030
2021-07-24 10:25:57,191 epoch 1 - iter 232/291 - loss 2.36463069 - samples/sec: 67.27 - lr: 0.000030
2021-07-24 10:26:11,109 epoch 1 - iter 261/291 - loss 2.16525245 - samples/sec: 66.68 - lr: 0.000030
2021-07-24 10:26:25,130 epoch 1 - iter 290/291 - loss 2.00190320 - samples/sec: 66.20 - lr: 0.000030
2021-07-24 10:26:25,298 ----------------------------------------------------------------------------------------------------
2021-07-24 10:26:25,298 EPOCH 1 done: loss 1.9966 - lr 0.0000300
2021-07-24 10:26:41,256 DEV : loss 0.38147056102752686 - score 0.9313
2021-07-24 10:26:41,276 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:26:41,835 ----------------------------------------------------------------------------------------------------
2021-07-24 10:26:46,524 epoch 2 - iter 29/291 - loss 0.45823851 - samples/sec: 198.01 - lr: 0.000030
2021-07-24 10:26:51,219 epoch 2 - iter 58/291 - loss 0.45390279 - samples/sec: 197.71 - lr: 0.000030
2021-07-24 10:26:55,971 epoch 2 - iter 87/291 - loss 0.44751897 - samples/sec: 195.37 - lr: 0.000030
2021-07-24 10:27:00,760 epoch 2 - iter 116/291 - loss 0.45031069 - samples/sec: 193.84 - lr: 0.000030
2021-07-24 10:27:05,395 epoch 2 - iter 145/291 - loss 0.44007389 - samples/sec: 200.30 - lr: 0.000030
2021-07-24 10:27:10,066 epoch 2 - iter 174/291 - loss 0.43672468 - samples/sec: 198.72 - lr: 0.000030
2021-07-24 10:27:14,717 epoch 2 - iter 203/291 - loss 0.43396305 - samples/sec: 199.61 - lr: 0.000030
2021-07-24 10:27:19,330 epoch 2 - iter 232/291 - loss 0.43208108 - samples/sec: 201.24 - lr: 0.000030
2021-07-24 10:27:23,951 epoch 2 - iter 261/291 - loss 0.42649580 - samples/sec: 200.90 - lr: 0.000030
2021-07-24 10:27:28,662 epoch 2 - iter 290/291 - loss 0.42764363 - samples/sec: 197.06 - lr: 0.000030
2021-07-24 10:27:28,731 ----------------------------------------------------------------------------------------------------
2021-07-24 10:27:28,731 EPOCH 2 done: loss 0.4267 - lr 0.0000300
2021-07-24 10:27:31,001 DEV : loss 0.2846124470233917 - score 0.9315
2021-07-24 10:27:31,021 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:27:33,453 ----------------------------------------------------------------------------------------------------
2021-07-24 10:27:38,113 epoch 3 - iter 29/291 - loss 0.40523347 - samples/sec: 199.29 - lr: 0.000030
2021-07-24 10:27:42,797 epoch 3 - iter 58/291 - loss 0.38304703 - samples/sec: 198.18 - lr: 0.000030
2021-07-24 10:27:47,411 epoch 3 - iter 87/291 - loss 0.38722209 - samples/sec: 201.23 - lr: 0.000030
2021-07-24 10:27:52,075 epoch 3 - iter 116/291 - loss 0.37834105 - samples/sec: 199.03 - lr: 0.000030
2021-07-24 10:27:56,718 epoch 3 - iter 145/291 - loss 0.37792416 - samples/sec: 199.90 - lr: 0.000030
2021-07-24 10:28:01,491 epoch 3 - iter 174/291 - loss 0.38515838 - samples/sec: 194.52 - lr: 0.000030
2021-07-24 10:28:06,111 epoch 3 - iter 203/291 - loss 0.37667030 - samples/sec: 200.91 - lr: 0.000030
2021-07-24 10:28:10,783 epoch 3 - iter 232/291 - loss 0.37786533 - samples/sec: 198.74 - lr: 0.000030
2021-07-24 10:28:15,426 epoch 3 - iter 261/291 - loss 0.37601576 - samples/sec: 199.93 - lr: 0.000030
2021-07-24 10:28:20,119 epoch 3 - iter 290/291 - loss 0.37578272 - samples/sec: 197.79 - lr: 0.000030
2021-07-24 10:28:20,206 ----------------------------------------------------------------------------------------------------
2021-07-24 10:28:20,206 EPOCH 3 done: loss 0.3753 - lr 0.0000300
2021-07-24 10:28:22,470 DEV : loss 0.25574129819869995 - score 0.9391
2021-07-24 10:28:22,490 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:28:24,934 ----------------------------------------------------------------------------------------------------
2021-07-24 10:28:29,609 epoch 4 - iter 29/291 - loss 0.36484396 - samples/sec: 198.69 - lr: 0.000030
2021-07-24 10:28:34,190 epoch 4 - iter 58/291 - loss 0.34069874 - samples/sec: 202.65 - lr: 0.000030
2021-07-24 10:28:38,938 epoch 4 - iter 87/291 - loss 0.34012473 - samples/sec: 195.53 - lr: 0.000030
2021-07-24 10:28:43,572 epoch 4 - iter 116/291 - loss 0.34202519 - samples/sec: 200.33 - lr: 0.000030
2021-07-24 10:28:48,271 epoch 4 - iter 145/291 - loss 0.33867792 - samples/sec: 197.56 - lr: 0.000030
2021-07-24 10:28:52,934 epoch 4 - iter 174/291 - loss 0.33592752 - samples/sec: 199.08 - lr: 0.000030
2021-07-24 10:28:57,676 epoch 4 - iter 203/291 - loss 0.33911248 - samples/sec: 195.76 - lr: 0.000030
2021-07-24 10:29:02,250 epoch 4 - iter 232/291 - loss 0.34032891 - samples/sec: 202.96 - lr: 0.000030
2021-07-24 10:29:07,043 epoch 4 - iter 261/291 - loss 0.33869922 - samples/sec: 193.65 - lr: 0.000030
2021-07-24 10:29:11,803 epoch 4 - iter 290/291 - loss 0.33778651 - samples/sec: 195.04 - lr: 0.000030
2021-07-24 10:29:11,874 ----------------------------------------------------------------------------------------------------
2021-07-24 10:29:11,875 EPOCH 4 done: loss 0.3385 - lr 0.0000300
2021-07-24 10:29:14,141 DEV : loss 0.24978512525558472 - score 0.9406
2021-07-24 10:29:14,162 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:29:16,673 ----------------------------------------------------------------------------------------------------
2021-07-24 10:29:21,371 epoch 5 - iter 29/291 - loss 0.33011510 - samples/sec: 197.68 - lr: 0.000030
2021-07-24 10:29:26,031 epoch 5 - iter 58/291 - loss 0.32280031 - samples/sec: 199.23 - lr: 0.000030
2021-07-24 10:29:30,694 epoch 5 - iter 87/291 - loss 0.32430969 - samples/sec: 199.07 - lr: 0.000030
2021-07-24 10:29:35,307 epoch 5 - iter 116/291 - loss 0.33336299 - samples/sec: 201.26 - lr: 0.000030
2021-07-24 10:29:39,943 epoch 5 - iter 145/291 - loss 0.33727586 - samples/sec: 200.21 - lr: 0.000030
2021-07-24 10:29:44,650 epoch 5 - iter 174/291 - loss 0.33343196 - samples/sec: 197.21 - lr: 0.000030
2021-07-24 10:29:49,464 epoch 5 - iter 203/291 - loss 0.33287134 - samples/sec: 192.85 - lr: 0.000030
2021-07-24 10:29:54,079 epoch 5 - iter 232/291 - loss 0.33143286 - samples/sec: 201.14 - lr: 0.000030
2021-07-24 10:29:58,826 epoch 5 - iter 261/291 - loss 0.33249902 - samples/sec: 195.56 - lr: 0.000030
2021-07-24 10:30:03,495 epoch 5 - iter 290/291 - loss 0.33272276 - samples/sec: 198.81 - lr: 0.000030
2021-07-24 10:30:03,562 ----------------------------------------------------------------------------------------------------
2021-07-24 10:30:03,562 EPOCH 5 done: loss 0.3318 - lr 0.0000300
2021-07-24 10:30:05,824 DEV : loss 0.24352458119392395 - score 0.942
2021-07-24 10:30:05,845 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:30:08,319 ----------------------------------------------------------------------------------------------------
2021-07-24 10:30:13,027 epoch 6 - iter 29/291 - loss 0.31533514 - samples/sec: 197.25 - lr: 0.000030
2021-07-24 10:30:17,774 epoch 6 - iter 58/291 - loss 0.32497103 - samples/sec: 195.58 - lr: 0.000030
2021-07-24 10:30:22,491 epoch 6 - iter 87/291 - loss 0.33927855 - samples/sec: 196.79 - lr: 0.000030
2021-07-24 10:30:27,217 epoch 6 - iter 116/291 - loss 0.34380276 - samples/sec: 196.44 - lr: 0.000030
2021-07-24 10:30:31,840 epoch 6 - iter 145/291 - loss 0.34242568 - samples/sec: 200.82 - lr: 0.000030
2021-07-24 10:30:36,516 epoch 6 - iter 174/291 - loss 0.34511459 - samples/sec: 198.54 - lr: 0.000030
2021-07-24 10:30:41,273 epoch 6 - iter 203/291 - loss 0.34489566 - samples/sec: 195.15 - lr: 0.000030
2021-07-24 10:30:45,947 epoch 6 - iter 232/291 - loss 0.34337136 - samples/sec: 198.60 - lr: 0.000030
2021-07-24 10:30:50,551 epoch 6 - iter 261/291 - loss 0.34150032 - samples/sec: 201.65 - lr: 0.000030
2021-07-24 10:30:55,102 epoch 6 - iter 290/291 - loss 0.34130968 - samples/sec: 203.98 - lr: 0.000030
2021-07-24 10:30:55,186 ----------------------------------------------------------------------------------------------------
2021-07-24 10:30:55,186 EPOCH 6 done: loss 0.3423 - lr 0.0000300
2021-07-24 10:30:57,441 DEV : loss 0.23434770107269287 - score 0.9485
2021-07-24 10:30:57,462 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 10:30:59,939 ----------------------------------------------------------------------------------------------------
2021-07-24 10:31:04,543 epoch 7 - iter 29/291 - loss 0.36723054 - samples/sec: 201.74 - lr: 0.000030
2021-07-24 10:31:09,147 epoch 7 - iter 58/291 - loss 0.35410264 - samples/sec: 201.63 - lr: 0.000030
2021-07-24 10:31:13,767 epoch 7 - iter 87/291 - loss 0.34469866 - samples/sec: 200.92 - lr: 0.000030
2021-07-24 10:31:18,414 epoch 7 - iter 116/291 - loss 0.33929979 - samples/sec: 199.77 - lr: 0.000030
2021-07-24 10:31:23,135 epoch 7 - iter 145/291 - loss 0.34738607 - samples/sec: 196.63 - lr: 0.000030
2021-07-24 10:31:27,943 epoch 7 - iter 174/291 - loss 0.33478785 - samples/sec: 193.06 - lr: 0.000030
2021-07-24 10:31:32,654 epoch 7 - iter 203/291 - loss 0.33583186 - samples/sec: 197.05 - lr: 0.000030
2021-07-24 10:31:37,347 epoch 7 - iter 232/291 - loss 0.33974562 - samples/sec: 197.83 - lr: 0.000030
2021-07-24 10:31:41,969 epoch 7 - iter 261/291 - loss 0.34360264 - samples/sec: 200.84 - lr: 0.000030
2021-07-24 10:31:46,647 epoch 7 - iter 290/291 - loss 0.34338242 - samples/sec: 198.45 - lr: 0.000030
2021-07-24 10:31:46,726 ----------------------------------------------------------------------------------------------------
2021-07-24 10:31:46,726 EPOCH 7 done: loss 0.3443 - lr 0.0000300
2021-07-24 10:31:48,987 DEV : loss 0.23572972416877747 - score 0.9444
2021-07-24 10:31:49,008 BAD EPOCHS (no improvement): 1
2021-07-24 10:31:49,008 ----------------------------------------------------------------------------------------------------
2021-07-24 10:31:53,683 epoch 8 - iter 29/291 - loss 0.33294522 - samples/sec: 198.61 - lr: 0.000030
2021-07-24 10:31:58,330 epoch 8 - iter 58/291 - loss 0.32755426 - samples/sec: 199.79 - lr: 0.000030
2021-07-24 10:32:03,032 epoch 8 - iter 87/291 - loss 0.33371308 - samples/sec: 197.42 - lr: 0.000030
2021-07-24 10:32:07,792 epoch 8 - iter 116/291 - loss 0.33561898 - samples/sec: 195.04 - lr: 0.000030
2021-07-24 10:32:12,520 epoch 8 - iter 145/291 - loss 0.33399159 - samples/sec: 196.34 - lr: 0.000030
2021-07-24 10:32:17,116 epoch 8 - iter 174/291 - loss 0.34219780 - samples/sec: 201.98 - lr: 0.000030
2021-07-24 10:32:21,800 epoch 8 - iter 203/291 - loss 0.33735369 - samples/sec: 198.19 - lr: 0.000030
2021-07-24 10:32:26,458 epoch 8 - iter 232/291 - loss 0.34193139 - samples/sec: 199.30 - lr: 0.000030
2021-07-24 10:32:31,123 epoch 8 - iter 261/291 - loss 0.34299517 - samples/sec: 198.97 - lr: 0.000030
2021-07-24 10:32:35,815 epoch 8 - iter 290/291 - loss 0.34289353 - samples/sec: 197.88 - lr: 0.000030
2021-07-24 10:32:35,899 ----------------------------------------------------------------------------------------------------
2021-07-24 10:32:35,899 EPOCH 8 done: loss 0.3422 - lr 0.0000300
2021-07-24 10:32:38,162 DEV : loss 0.23421190679073334 - score 0.9444
2021-07-24 10:32:38,183 BAD EPOCHS (no improvement): 2
2021-07-24 10:32:38,183 ----------------------------------------------------------------------------------------------------
2021-07-24 10:32:42,828 epoch 9 - iter 29/291 - loss 0.29771284 - samples/sec: 199.90 - lr: 0.000030
2021-07-24 10:32:47,486 epoch 9 - iter 58/291 - loss 0.31688220 - samples/sec: 199.30 - lr: 0.000030
2021-07-24 10:32:52,108 epoch 9 - iter 87/291 - loss 0.31881619 - samples/sec: 200.87 - lr: 0.000030
2021-07-24 10:32:56,772 epoch 9 - iter 116/291 - loss 0.31312212 - samples/sec: 199.04 - lr: 0.000030
2021-07-24 10:33:01,476 epoch 9 - iter 145/291 - loss 0.31800296 - samples/sec: 197.33 - lr: 0.000030
2021-07-24 10:33:06,234 epoch 9 - iter 174/291 - loss 0.31622896 - samples/sec: 195.10 - lr: 0.000030
2021-07-24 10:33:10,871 epoch 9 - iter 203/291 - loss 0.31509418 - samples/sec: 200.17 - lr: 0.000030
2021-07-24 10:33:15,581 epoch 9 - iter 232/291 - loss 0.32068276 - samples/sec: 197.10 - lr: 0.000030
2021-07-24 10:33:20,216 epoch 9 - iter 261/291 - loss 0.32612651 - samples/sec: 200.31 - lr: 0.000030
2021-07-24 10:33:24,906 epoch 9 - iter 290/291 - loss 0.32143388 - samples/sec: 197.93 - lr: 0.000030
2021-07-24 10:33:24,986 ----------------------------------------------------------------------------------------------------
2021-07-24 10:33:24,986 EPOCH 9 done: loss 0.3211 - lr 0.0000300
2021-07-24 10:33:27,243 DEV : loss 0.230348140001297 - score 0.9465
2021-07-24 10:33:27,263 BAD EPOCHS (no improvement): 3
2021-07-24 10:33:27,264 ----------------------------------------------------------------------------------------------------
2021-07-24 10:33:31,942 epoch 10 - iter 29/291 - loss 0.27269826 - samples/sec: 198.49 - lr: 0.000030
2021-07-24 10:33:36,639 epoch 10 - iter 58/291 - loss 0.29127280 - samples/sec: 197.65 - lr: 0.000030
2021-07-24 10:33:41,415 epoch 10 - iter 87/291 - loss 0.30261389 - samples/sec: 194.37 - lr: 0.000030
2021-07-24 10:33:46,072 epoch 10 - iter 116/291 - loss 0.30057029 - samples/sec: 199.34 - lr: 0.000030
2021-07-24 10:33:50,762 epoch 10 - iter 145/291 - loss 0.30256460 - samples/sec: 197.92 - lr: 0.000030
2021-07-24 10:33:55,400 epoch 10 - iter 174/291 - loss 0.30617676 - samples/sec: 200.16 - lr: 0.000030
2021-07-24 10:34:00,058 epoch 10 - iter 203/291 - loss 0.31399355 - samples/sec: 199.27 - lr: 0.000030
2021-07-24 10:34:04,646 epoch 10 - iter 232/291 - loss 0.31245411 - samples/sec: 202.34 - lr: 0.000030
2021-07-24 10:34:09,335 epoch 10 - iter 261/291 - loss 0.32152240 - samples/sec: 198.00 - lr: 0.000030
2021-07-24 10:34:14,051 epoch 10 - iter 290/291 - loss 0.32092586 - samples/sec: 196.84 - lr: 0.000030
2021-07-24 10:34:14,122 ----------------------------------------------------------------------------------------------------
2021-07-24 10:34:14,122 EPOCH 10 done: loss 0.3204 - lr 0.0000300
2021-07-24 10:34:16,379 DEV : loss 0.23700179159641266 - score 0.9451
Epoch    10: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 10:34:16,399 BAD EPOCHS (no improvement): 4
2021-07-24 10:34:16,399 ----------------------------------------------------------------------------------------------------
2021-07-24 10:34:21,086 epoch 11 - iter 29/291 - loss 0.27405509 - samples/sec: 198.12 - lr: 0.000015
2021-07-24 10:34:25,733 epoch 11 - iter 58/291 - loss 0.28405594 - samples/sec: 199.80 - lr: 0.000015
2021-07-24 10:34:30,418 epoch 11 - iter 87/291 - loss 0.28153624 - samples/sec: 198.13 - lr: 0.000015
2021-07-24 10:34:35,212 epoch 11 - iter 116/291 - loss 0.28580708 - samples/sec: 193.68 - lr: 0.000015
2021-07-24 10:34:39,887 epoch 11 - iter 145/291 - loss 0.29287263 - samples/sec: 198.57 - lr: 0.000015
2021-07-24 10:34:44,542 epoch 11 - iter 174/291 - loss 0.30198516 - samples/sec: 199.39 - lr: 0.000015
2021-07-24 10:34:49,209 epoch 11 - iter 203/291 - loss 0.30308475 - samples/sec: 198.90 - lr: 0.000015
2021-07-24 10:34:53,787 epoch 11 - iter 232/291 - loss 0.30762846 - samples/sec: 202.81 - lr: 0.000015
2021-07-24 10:34:58,373 epoch 11 - iter 261/291 - loss 0.31084494 - samples/sec: 202.40 - lr: 0.000015
2021-07-24 10:35:03,056 epoch 11 - iter 290/291 - loss 0.30768031 - samples/sec: 198.26 - lr: 0.000015
2021-07-24 10:35:03,131 ----------------------------------------------------------------------------------------------------
2021-07-24 10:35:03,131 EPOCH 11 done: loss 0.3071 - lr 0.0000150
2021-07-24 10:35:05,388 DEV : loss 0.23080167174339294 - score 0.9446
2021-07-24 10:35:05,408 BAD EPOCHS (no improvement): 1
2021-07-24 10:35:05,408 ----------------------------------------------------------------------------------------------------
2021-07-24 10:35:10,126 epoch 12 - iter 29/291 - loss 0.35148919 - samples/sec: 196.82 - lr: 0.000015
2021-07-24 10:35:14,838 epoch 12 - iter 58/291 - loss 0.33213337 - samples/sec: 196.99 - lr: 0.000015
2021-07-24 10:35:19,451 epoch 12 - iter 87/291 - loss 0.33084212 - samples/sec: 201.27 - lr: 0.000015
2021-07-24 10:35:24,029 epoch 12 - iter 116/291 - loss 0.32701643 - samples/sec: 202.76 - lr: 0.000015
2021-07-24 10:35:28,755 epoch 12 - iter 145/291 - loss 0.31965120 - samples/sec: 196.43 - lr: 0.000015
2021-07-24 10:35:33,378 epoch 12 - iter 174/291 - loss 0.32760878 - samples/sec: 200.81 - lr: 0.000015
2021-07-24 10:35:38,229 epoch 12 - iter 203/291 - loss 0.33117926 - samples/sec: 191.35 - lr: 0.000015
2021-07-24 10:35:42,947 epoch 12 - iter 232/291 - loss 0.32652870 - samples/sec: 196.76 - lr: 0.000015
2021-07-24 10:35:47,556 epoch 12 - iter 261/291 - loss 0.32523482 - samples/sec: 201.45 - lr: 0.000015
2021-07-24 10:35:52,207 epoch 12 - iter 290/291 - loss 0.31943476 - samples/sec: 199.58 - lr: 0.000015
2021-07-24 10:35:52,280 ----------------------------------------------------------------------------------------------------
2021-07-24 10:35:52,280 EPOCH 12 done: loss 0.3225 - lr 0.0000150
2021-07-24 10:35:54,541 DEV : loss 0.23293828964233398 - score 0.9453
2021-07-24 10:35:54,561 BAD EPOCHS (no improvement): 2
2021-07-24 10:35:54,562 ----------------------------------------------------------------------------------------------------
2021-07-24 10:35:59,222 epoch 13 - iter 29/291 - loss 0.32073041 - samples/sec: 199.26 - lr: 0.000015
2021-07-24 10:36:03,898 epoch 13 - iter 58/291 - loss 0.32473387 - samples/sec: 198.49 - lr: 0.000015
2021-07-24 10:36:08,579 epoch 13 - iter 87/291 - loss 0.32933769 - samples/sec: 198.33 - lr: 0.000015
2021-07-24 10:36:13,371 epoch 13 - iter 116/291 - loss 0.32652430 - samples/sec: 193.71 - lr: 0.000015
2021-07-24 10:36:18,026 epoch 13 - iter 145/291 - loss 0.31754575 - samples/sec: 199.44 - lr: 0.000015
2021-07-24 10:36:22,603 epoch 13 - iter 174/291 - loss 0.32270020 - samples/sec: 202.83 - lr: 0.000015
2021-07-24 10:36:27,236 epoch 13 - iter 203/291 - loss 0.32430873 - samples/sec: 200.38 - lr: 0.000015
2021-07-24 10:36:31,958 epoch 13 - iter 232/291 - loss 0.32242321 - samples/sec: 196.56 - lr: 0.000015
2021-07-24 10:36:36,635 epoch 13 - iter 261/291 - loss 0.31957624 - samples/sec: 198.49 - lr: 0.000015
2021-07-24 10:36:41,312 epoch 13 - iter 290/291 - loss 0.31977229 - samples/sec: 198.51 - lr: 0.000015
2021-07-24 10:36:41,389 ----------------------------------------------------------------------------------------------------
2021-07-24 10:36:41,389 EPOCH 13 done: loss 0.3190 - lr 0.0000150
2021-07-24 10:36:43,647 DEV : loss 0.22921861708164215 - score 0.945
2021-07-24 10:36:43,667 BAD EPOCHS (no improvement): 3
2021-07-24 10:36:43,667 ----------------------------------------------------------------------------------------------------
2021-07-24 10:36:48,298 epoch 14 - iter 29/291 - loss 0.32007330 - samples/sec: 200.53 - lr: 0.000015
2021-07-24 10:36:53,047 epoch 14 - iter 58/291 - loss 0.32879506 - samples/sec: 195.46 - lr: 0.000015
2021-07-24 10:36:57,763 epoch 14 - iter 87/291 - loss 0.31560471 - samples/sec: 196.87 - lr: 0.000015
2021-07-24 10:37:02,531 epoch 14 - iter 116/291 - loss 0.31504551 - samples/sec: 194.67 - lr: 0.000015
2021-07-24 10:37:07,192 epoch 14 - iter 145/291 - loss 0.31125990 - samples/sec: 199.20 - lr: 0.000015
2021-07-24 10:37:11,876 epoch 14 - iter 174/291 - loss 0.31082632 - samples/sec: 198.20 - lr: 0.000015
2021-07-24 10:37:16,479 epoch 14 - iter 203/291 - loss 0.31376818 - samples/sec: 201.66 - lr: 0.000015
2021-07-24 10:37:21,166 epoch 14 - iter 232/291 - loss 0.31305037 - samples/sec: 198.08 - lr: 0.000015
2021-07-24 10:37:25,868 epoch 14 - iter 261/291 - loss 0.31263707 - samples/sec: 197.42 - lr: 0.000015
2021-07-24 10:37:30,461 epoch 14 - iter 290/291 - loss 0.30991840 - samples/sec: 202.10 - lr: 0.000015
2021-07-24 10:37:30,542 ----------------------------------------------------------------------------------------------------
2021-07-24 10:37:30,542 EPOCH 14 done: loss 0.3101 - lr 0.0000150
2021-07-24 10:37:32,800 DEV : loss 0.2307155430316925 - score 0.9439
Epoch    14: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 10:37:32,820 BAD EPOCHS (no improvement): 4
2021-07-24 10:37:32,821 ----------------------------------------------------------------------------------------------------
2021-07-24 10:37:37,403 epoch 15 - iter 29/291 - loss 0.26974475 - samples/sec: 202.65 - lr: 0.000008
2021-07-24 10:37:42,031 epoch 15 - iter 58/291 - loss 0.30148662 - samples/sec: 200.58 - lr: 0.000008
2021-07-24 10:37:46,618 epoch 15 - iter 87/291 - loss 0.30816025 - samples/sec: 202.37 - lr: 0.000008
2021-07-24 10:37:51,318 epoch 15 - iter 116/291 - loss 0.32085068 - samples/sec: 197.50 - lr: 0.000008
2021-07-24 10:37:55,954 epoch 15 - iter 145/291 - loss 0.32514276 - samples/sec: 200.26 - lr: 0.000008
2021-07-24 10:38:00,659 epoch 15 - iter 174/291 - loss 0.32045114 - samples/sec: 197.30 - lr: 0.000008
2021-07-24 10:38:05,331 epoch 15 - iter 203/291 - loss 0.32330796 - samples/sec: 198.70 - lr: 0.000008
2021-07-24 10:38:10,144 epoch 15 - iter 232/291 - loss 0.32746374 - samples/sec: 192.88 - lr: 0.000008
2021-07-24 10:38:14,827 epoch 15 - iter 261/291 - loss 0.32372469 - samples/sec: 198.22 - lr: 0.000008
2021-07-24 10:38:19,462 epoch 15 - iter 290/291 - loss 0.31902342 - samples/sec: 200.27 - lr: 0.000008
2021-07-24 10:38:19,537 ----------------------------------------------------------------------------------------------------
2021-07-24 10:38:19,537 EPOCH 15 done: loss 0.3181 - lr 0.0000075
2021-07-24 10:38:21,793 DEV : loss 0.23123383522033691 - score 0.944
2021-07-24 10:38:21,813 BAD EPOCHS (no improvement): 1
2021-07-24 10:38:21,814 ----------------------------------------------------------------------------------------------------
2021-07-24 10:38:26,468 epoch 16 - iter 29/291 - loss 0.26103672 - samples/sec: 199.51 - lr: 0.000008
2021-07-24 10:38:31,091 epoch 16 - iter 58/291 - loss 0.29613655 - samples/sec: 200.82 - lr: 0.000008
2021-07-24 10:38:35,747 epoch 16 - iter 87/291 - loss 0.29629815 - samples/sec: 199.37 - lr: 0.000008
2021-07-24 10:38:40,387 epoch 16 - iter 116/291 - loss 0.29795005 - samples/sec: 200.06 - lr: 0.000008
2021-07-24 10:38:45,039 epoch 16 - iter 145/291 - loss 0.30076787 - samples/sec: 199.55 - lr: 0.000008
2021-07-24 10:38:49,679 epoch 16 - iter 174/291 - loss 0.30545516 - samples/sec: 200.05 - lr: 0.000008
2021-07-24 10:38:54,390 epoch 16 - iter 203/291 - loss 0.30723137 - samples/sec: 197.08 - lr: 0.000008
2021-07-24 10:38:59,146 epoch 16 - iter 232/291 - loss 0.30827972 - samples/sec: 195.20 - lr: 0.000008
2021-07-24 10:39:03,886 epoch 16 - iter 261/291 - loss 0.30684519 - samples/sec: 195.82 - lr: 0.000008
2021-07-24 10:39:08,618 epoch 16 - iter 290/291 - loss 0.30150592 - samples/sec: 196.19 - lr: 0.000008
2021-07-24 10:39:08,691 ----------------------------------------------------------------------------------------------------
2021-07-24 10:39:08,691 EPOCH 16 done: loss 0.3025 - lr 0.0000075
2021-07-24 10:39:10,955 DEV : loss 0.23153838515281677 - score 0.9445
2021-07-24 10:39:10,975 BAD EPOCHS (no improvement): 2
2021-07-24 10:39:10,975 ----------------------------------------------------------------------------------------------------
2021-07-24 10:39:15,611 epoch 17 - iter 29/291 - loss 0.28010959 - samples/sec: 200.33 - lr: 0.000008
2021-07-24 10:39:20,151 epoch 17 - iter 58/291 - loss 0.29871610 - samples/sec: 204.45 - lr: 0.000008
2021-07-24 10:39:24,926 epoch 17 - iter 87/291 - loss 0.29035087 - samples/sec: 194.41 - lr: 0.000008
2021-07-24 10:39:29,654 epoch 17 - iter 116/291 - loss 0.30397830 - samples/sec: 196.37 - lr: 0.000008
2021-07-24 10:39:34,318 epoch 17 - iter 145/291 - loss 0.30615501 - samples/sec: 199.01 - lr: 0.000008
2021-07-24 10:39:38,998 epoch 17 - iter 174/291 - loss 0.30741262 - samples/sec: 198.35 - lr: 0.000008
2021-07-24 10:39:43,618 epoch 17 - iter 203/291 - loss 0.30480968 - samples/sec: 200.93 - lr: 0.000008
2021-07-24 10:39:48,314 epoch 17 - iter 232/291 - loss 0.30986304 - samples/sec: 197.72 - lr: 0.000008
2021-07-24 10:39:52,915 epoch 17 - iter 261/291 - loss 0.31095130 - samples/sec: 201.75 - lr: 0.000008
2021-07-24 10:39:57,663 epoch 17 - iter 290/291 - loss 0.30886312 - samples/sec: 195.54 - lr: 0.000008
2021-07-24 10:39:57,735 ----------------------------------------------------------------------------------------------------
2021-07-24 10:39:57,736 EPOCH 17 done: loss 0.3082 - lr 0.0000075
2021-07-24 10:39:59,991 DEV : loss 0.22829245030879974 - score 0.9426
2021-07-24 10:40:00,012 BAD EPOCHS (no improvement): 3
2021-07-24 10:40:00,012 ----------------------------------------------------------------------------------------------------
2021-07-24 10:40:04,722 epoch 18 - iter 29/291 - loss 0.28365657 - samples/sec: 197.12 - lr: 0.000008
2021-07-24 10:40:09,423 epoch 18 - iter 58/291 - loss 0.29624077 - samples/sec: 197.49 - lr: 0.000008
2021-07-24 10:40:13,975 epoch 18 - iter 87/291 - loss 0.30718230 - samples/sec: 203.96 - lr: 0.000008
2021-07-24 10:40:18,619 epoch 18 - iter 116/291 - loss 0.31202823 - samples/sec: 199.90 - lr: 0.000008
2021-07-24 10:40:23,324 epoch 18 - iter 145/291 - loss 0.31409231 - samples/sec: 197.30 - lr: 0.000008
2021-07-24 10:40:28,003 epoch 18 - iter 174/291 - loss 0.31507347 - samples/sec: 198.37 - lr: 0.000008
2021-07-24 10:40:32,655 epoch 18 - iter 203/291 - loss 0.31366274 - samples/sec: 199.56 - lr: 0.000008
2021-07-24 10:40:37,374 epoch 18 - iter 232/291 - loss 0.31438114 - samples/sec: 196.73 - lr: 0.000008
2021-07-24 10:40:42,072 epoch 18 - iter 261/291 - loss 0.31160806 - samples/sec: 197.59 - lr: 0.000008
2021-07-24 10:40:46,771 epoch 18 - iter 290/291 - loss 0.31183847 - samples/sec: 197.56 - lr: 0.000008
2021-07-24 10:40:46,851 ----------------------------------------------------------------------------------------------------
2021-07-24 10:40:46,851 EPOCH 18 done: loss 0.3114 - lr 0.0000075
2021-07-24 10:40:49,104 DEV : loss 0.2308991700410843 - score 0.9445
Epoch    18: reducing learning rate of group 0 to 3.7500e-06.
2021-07-24 10:40:49,125 BAD EPOCHS (no improvement): 4
2021-07-24 10:40:49,125 ----------------------------------------------------------------------------------------------------
2021-07-24 10:40:53,727 epoch 19 - iter 29/291 - loss 0.36498892 - samples/sec: 201.76 - lr: 0.000004
2021-07-24 10:40:58,452 epoch 19 - iter 58/291 - loss 0.34058021 - samples/sec: 196.49 - lr: 0.000004
2021-07-24 10:41:03,116 epoch 19 - iter 87/291 - loss 0.33004334 - samples/sec: 199.04 - lr: 0.000004
2021-07-24 10:41:07,770 epoch 19 - iter 116/291 - loss 0.33164985 - samples/sec: 199.46 - lr: 0.000004
2021-07-24 10:41:12,396 epoch 19 - iter 145/291 - loss 0.32293563 - samples/sec: 200.68 - lr: 0.000004
2021-07-24 10:41:17,067 epoch 19 - iter 174/291 - loss 0.31380417 - samples/sec: 198.73 - lr: 0.000004
2021-07-24 10:41:21,831 epoch 19 - iter 203/291 - loss 0.30397114 - samples/sec: 194.85 - lr: 0.000004
2021-07-24 10:41:26,424 epoch 19 - iter 232/291 - loss 0.30707582 - samples/sec: 202.13 - lr: 0.000004
2021-07-24 10:41:31,043 epoch 19 - iter 261/291 - loss 0.30865464 - samples/sec: 200.98 - lr: 0.000004
2021-07-24 10:41:35,782 epoch 19 - iter 290/291 - loss 0.30452920 - samples/sec: 195.88 - lr: 0.000004
2021-07-24 10:41:35,855 ----------------------------------------------------------------------------------------------------
2021-07-24 10:41:35,855 EPOCH 19 done: loss 0.3047 - lr 0.0000038
2021-07-24 10:41:38,310 DEV : loss 0.2278125137090683 - score 0.9438
2021-07-24 10:41:38,330 BAD EPOCHS (no improvement): 1
2021-07-24 10:41:38,331 ----------------------------------------------------------------------------------------------------
2021-07-24 10:41:43,048 epoch 20 - iter 29/291 - loss 0.28839898 - samples/sec: 196.86 - lr: 0.000004
2021-07-24 10:41:47,722 epoch 20 - iter 58/291 - loss 0.32396805 - samples/sec: 198.57 - lr: 0.000004
2021-07-24 10:41:52,351 epoch 20 - iter 87/291 - loss 0.31263845 - samples/sec: 200.55 - lr: 0.000004
2021-07-24 10:41:57,101 epoch 20 - iter 116/291 - loss 0.31740786 - samples/sec: 195.44 - lr: 0.000004
2021-07-24 10:42:01,764 epoch 20 - iter 145/291 - loss 0.31431725 - samples/sec: 199.10 - lr: 0.000004
2021-07-24 10:42:06,426 epoch 20 - iter 174/291 - loss 0.31054462 - samples/sec: 199.14 - lr: 0.000004
2021-07-24 10:42:11,094 epoch 20 - iter 203/291 - loss 0.30851648 - samples/sec: 198.85 - lr: 0.000004
2021-07-24 10:42:15,714 epoch 20 - iter 232/291 - loss 0.30926563 - samples/sec: 200.93 - lr: 0.000004
2021-07-24 10:42:20,402 epoch 20 - iter 261/291 - loss 0.30629889 - samples/sec: 198.01 - lr: 0.000004
2021-07-24 10:42:25,095 epoch 20 - iter 290/291 - loss 0.30703691 - samples/sec: 197.82 - lr: 0.000004
2021-07-24 10:42:25,165 ----------------------------------------------------------------------------------------------------
2021-07-24 10:42:25,166 EPOCH 20 done: loss 0.3064 - lr 0.0000038
2021-07-24 10:42:27,421 DEV : loss 0.22685769200325012 - score 0.9455
2021-07-24 10:42:27,442 BAD EPOCHS (no improvement): 2
2021-07-24 10:42:27,442 ----------------------------------------------------------------------------------------------------
2021-07-24 10:42:32,027 epoch 21 - iter 29/291 - loss 0.29160883 - samples/sec: 202.52 - lr: 0.000004
2021-07-24 10:42:36,646 epoch 21 - iter 58/291 - loss 0.29387376 - samples/sec: 200.99 - lr: 0.000004
2021-07-24 10:42:41,430 epoch 21 - iter 87/291 - loss 0.29014976 - samples/sec: 194.04 - lr: 0.000004
2021-07-24 10:42:46,165 epoch 21 - iter 116/291 - loss 0.29117304 - samples/sec: 196.05 - lr: 0.000004
2021-07-24 10:42:50,846 epoch 21 - iter 145/291 - loss 0.29364953 - samples/sec: 198.32 - lr: 0.000004
2021-07-24 10:42:55,626 epoch 21 - iter 174/291 - loss 0.29373172 - samples/sec: 194.23 - lr: 0.000004
2021-07-24 10:43:00,215 epoch 21 - iter 203/291 - loss 0.29441798 - samples/sec: 202.28 - lr: 0.000004
2021-07-24 10:43:04,761 epoch 21 - iter 232/291 - loss 0.29460864 - samples/sec: 204.19 - lr: 0.000004
2021-07-24 10:43:09,359 epoch 21 - iter 261/291 - loss 0.29512149 - samples/sec: 201.94 - lr: 0.000004
2021-07-24 10:43:14,006 epoch 21 - iter 290/291 - loss 0.29688945 - samples/sec: 199.75 - lr: 0.000004
2021-07-24 10:43:14,089 ----------------------------------------------------------------------------------------------------
2021-07-24 10:43:14,090 EPOCH 21 done: loss 0.2987 - lr 0.0000038
2021-07-24 10:43:16,345 DEV : loss 0.2290739268064499 - score 0.9431
2021-07-24 10:43:16,366 BAD EPOCHS (no improvement): 3
2021-07-24 10:43:16,366 ----------------------------------------------------------------------------------------------------
2021-07-24 10:43:21,040 epoch 22 - iter 29/291 - loss 0.30829996 - samples/sec: 198.67 - lr: 0.000004
2021-07-24 10:43:25,835 epoch 22 - iter 58/291 - loss 0.31918443 - samples/sec: 193.60 - lr: 0.000004
2021-07-24 10:43:30,536 epoch 22 - iter 87/291 - loss 0.30464959 - samples/sec: 197.47 - lr: 0.000004
2021-07-24 10:43:35,223 epoch 22 - iter 116/291 - loss 0.29833107 - samples/sec: 198.07 - lr: 0.000004
2021-07-24 10:43:39,928 epoch 22 - iter 145/291 - loss 0.29623909 - samples/sec: 197.28 - lr: 0.000004
2021-07-24 10:43:44,510 epoch 22 - iter 174/291 - loss 0.29073283 - samples/sec: 202.61 - lr: 0.000004
2021-07-24 10:43:49,095 epoch 22 - iter 203/291 - loss 0.29490198 - samples/sec: 202.46 - lr: 0.000004
2021-07-24 10:43:53,779 epoch 22 - iter 232/291 - loss 0.30095790 - samples/sec: 198.22 - lr: 0.000004
2021-07-24 10:43:58,479 epoch 22 - iter 261/291 - loss 0.30010011 - samples/sec: 197.51 - lr: 0.000004
2021-07-24 10:44:03,166 epoch 22 - iter 290/291 - loss 0.30196018 - samples/sec: 198.04 - lr: 0.000004
2021-07-24 10:44:03,227 ----------------------------------------------------------------------------------------------------
2021-07-24 10:44:03,228 EPOCH 22 done: loss 0.3019 - lr 0.0000038
2021-07-24 10:44:05,484 DEV : loss 0.22843150794506073 - score 0.9435
Epoch    22: reducing learning rate of group 0 to 1.8750e-06.
2021-07-24 10:44:05,504 BAD EPOCHS (no improvement): 4
2021-07-24 10:44:05,504 ----------------------------------------------------------------------------------------------------
2021-07-24 10:44:05,504 ----------------------------------------------------------------------------------------------------
2021-07-24 10:44:05,504 learning rate too small - quitting training!
2021-07-24 10:44:05,504 ----------------------------------------------------------------------------------------------------
2021-07-24 10:44:06,065 ----------------------------------------------------------------------------------------------------
2021-07-24 10:44:06,065 Testing using best model ...
2021-07-24 10:44:06,066 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-2/eng.sdrt.stac/best-model.pt
2021-07-24 10:44:40,373 0.9392	0.9655	0.9521
2021-07-24 10:44:40,373 
Results:
- F1-score (micro) 0.9521
- F1-score (macro) 0.9707

By class:
SENT       tp: 2065 - fp: 162 - fn: 90 - precision: 0.9273 - recall: 0.9582 - f1-score: 0.9425
X          tp: 451 - fp: 1 - fn: 0 - precision: 0.9978 - recall: 1.0000 - f1-score: 0.9989
2021-07-24 10:44:40,373 ----------------------------------------------------------------------------------------------------
