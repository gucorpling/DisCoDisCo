/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.rstdt/
2021-07-23 14:58:35,772 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.rstdt
2021-07-23 14:58:35,772 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.rstdt/sent_train.txt
2021-07-23 14:58:35,773 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.rstdt/sent_dev.txt
2021-07-23 14:58:35,773 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.rstdt/sent_test.txt
Corpus: 16207 train + 2332 dev + 6068 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 14:58:42,825 ----------------------------------------------------------------------------------------------------
2021-07-23 14:58:42,826 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 14:58:42,826 ----------------------------------------------------------------------------------------------------
2021-07-23 14:58:42,826 Corpus: "Corpus: 16207 train + 2332 dev + 6068 test sentences"
2021-07-23 14:58:42,826 ----------------------------------------------------------------------------------------------------
2021-07-23 14:58:42,826 Parameters:
2021-07-23 14:58:42,827  - learning_rate: "3e-05"
2021-07-23 14:58:42,827  - mini_batch_size: "32"
2021-07-23 14:58:42,827  - patience: "3"
2021-07-23 14:58:42,827  - anneal_factor: "0.5"
2021-07-23 14:58:42,827  - max_epochs: "40"
2021-07-23 14:58:42,827  - shuffle: "True"
2021-07-23 14:58:42,827  - train_with_dev: "False"
2021-07-23 14:58:42,827  - batch_growth_annealing: "False"
2021-07-23 14:58:42,827 ----------------------------------------------------------------------------------------------------
2021-07-23 14:58:42,827 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.rstdt"
2021-07-23 14:58:42,827 ----------------------------------------------------------------------------------------------------
2021-07-23 14:58:42,827 Device: cuda:0
2021-07-23 14:58:42,827 ----------------------------------------------------------------------------------------------------
2021-07-23 14:58:42,827 Embeddings storage mode: cpu
2021-07-23 14:58:42,830 ----------------------------------------------------------------------------------------------------
2021-07-23 14:59:10,932 epoch 1 - iter 50/507 - loss 7.84589069 - samples/sec: 56.94 - lr: 0.000030
2021-07-23 14:59:39,738 epoch 1 - iter 100/507 - loss 5.43199682 - samples/sec: 55.55 - lr: 0.000030
2021-07-23 15:00:08,376 epoch 1 - iter 150/507 - loss 4.02545611 - samples/sec: 55.87 - lr: 0.000030
2021-07-23 15:00:36,897 epoch 1 - iter 200/507 - loss 3.20530585 - samples/sec: 56.10 - lr: 0.000030
2021-07-23 15:01:05,734 epoch 1 - iter 250/507 - loss 2.67463067 - samples/sec: 55.49 - lr: 0.000030
2021-07-23 15:01:34,544 epoch 1 - iter 300/507 - loss 2.30458913 - samples/sec: 55.54 - lr: 0.000030
2021-07-23 15:02:03,294 epoch 1 - iter 350/507 - loss 2.02766557 - samples/sec: 55.66 - lr: 0.000030
2021-07-23 15:02:32,060 epoch 1 - iter 400/507 - loss 1.81259604 - samples/sec: 55.63 - lr: 0.000030
2021-07-23 15:03:00,804 epoch 1 - iter 450/507 - loss 1.64088868 - samples/sec: 55.67 - lr: 0.000030
2021-07-23 15:03:29,568 epoch 1 - iter 500/507 - loss 1.50329659 - samples/sec: 55.63 - lr: 0.000030
2021-07-23 15:03:33,317 ----------------------------------------------------------------------------------------------------
2021-07-23 15:03:33,318 EPOCH 1 done: loss 1.4873 - lr 0.0000300
2021-07-23 15:04:04,231 DEV : loss 0.13343994319438934 - score 0.9653
2021-07-23 15:04:04,296 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:04:04,946 ----------------------------------------------------------------------------------------------------
2021-07-23 15:04:16,392 epoch 2 - iter 50/507 - loss 0.23423261 - samples/sec: 139.84 - lr: 0.000030
2021-07-23 15:04:28,135 epoch 2 - iter 100/507 - loss 0.22012131 - samples/sec: 136.27 - lr: 0.000030
2021-07-23 15:04:39,722 epoch 2 - iter 150/507 - loss 0.21875466 - samples/sec: 138.12 - lr: 0.000030
2021-07-23 15:04:51,584 epoch 2 - iter 200/507 - loss 0.21463899 - samples/sec: 134.92 - lr: 0.000030
2021-07-23 15:05:03,039 epoch 2 - iter 250/507 - loss 0.21005814 - samples/sec: 139.71 - lr: 0.000030
2021-07-23 15:05:14,794 epoch 2 - iter 300/507 - loss 0.20763622 - samples/sec: 136.13 - lr: 0.000030
2021-07-23 15:05:26,615 epoch 2 - iter 350/507 - loss 0.20169066 - samples/sec: 135.39 - lr: 0.000030
2021-07-23 15:05:38,682 epoch 2 - iter 400/507 - loss 0.19809089 - samples/sec: 132.62 - lr: 0.000030
2021-07-23 15:05:50,491 epoch 2 - iter 450/507 - loss 0.19496714 - samples/sec: 135.51 - lr: 0.000030
2021-07-23 15:06:01,986 epoch 2 - iter 500/507 - loss 0.19265227 - samples/sec: 139.22 - lr: 0.000030
2021-07-23 15:06:03,559 ----------------------------------------------------------------------------------------------------
2021-07-23 15:06:03,559 EPOCH 2 done: loss 0.1928 - lr 0.0000300
2021-07-23 15:06:09,137 DEV : loss 0.08653632551431656 - score 0.976
2021-07-23 15:06:09,201 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:06:11,465 ----------------------------------------------------------------------------------------------------
2021-07-23 15:06:23,438 epoch 3 - iter 50/507 - loss 0.16808080 - samples/sec: 133.69 - lr: 0.000030
2021-07-23 15:06:35,512 epoch 3 - iter 100/507 - loss 0.17521155 - samples/sec: 132.55 - lr: 0.000030
2021-07-23 15:06:47,431 epoch 3 - iter 150/507 - loss 0.17267755 - samples/sec: 134.26 - lr: 0.000030
2021-07-23 15:06:59,054 epoch 3 - iter 200/507 - loss 0.17360856 - samples/sec: 137.70 - lr: 0.000030
2021-07-23 15:07:10,613 epoch 3 - iter 250/507 - loss 0.17131935 - samples/sec: 138.45 - lr: 0.000030
2021-07-23 15:07:22,542 epoch 3 - iter 300/507 - loss 0.17035084 - samples/sec: 134.15 - lr: 0.000030
2021-07-23 15:07:34,379 epoch 3 - iter 350/507 - loss 0.16778288 - samples/sec: 135.20 - lr: 0.000030
2021-07-23 15:07:46,126 epoch 3 - iter 400/507 - loss 0.16569551 - samples/sec: 136.24 - lr: 0.000030
2021-07-23 15:07:58,058 epoch 3 - iter 450/507 - loss 0.16350882 - samples/sec: 134.11 - lr: 0.000030
2021-07-23 15:08:09,423 epoch 3 - iter 500/507 - loss 0.16153935 - samples/sec: 140.82 - lr: 0.000030
2021-07-23 15:08:10,867 ----------------------------------------------------------------------------------------------------
2021-07-23 15:08:10,867 EPOCH 3 done: loss 0.1609 - lr 0.0000300
2021-07-23 15:08:16,441 DEV : loss 0.0770677775144577 - score 0.9775
2021-07-23 15:08:16,508 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:08:18,838 ----------------------------------------------------------------------------------------------------
2021-07-23 15:08:30,572 epoch 4 - iter 50/507 - loss 0.15317595 - samples/sec: 136.42 - lr: 0.000030
2021-07-23 15:08:42,091 epoch 4 - iter 100/507 - loss 0.14407164 - samples/sec: 138.93 - lr: 0.000030
2021-07-23 15:08:53,962 epoch 4 - iter 150/507 - loss 0.14195311 - samples/sec: 134.81 - lr: 0.000030
2021-07-23 15:09:05,909 epoch 4 - iter 200/507 - loss 0.14071168 - samples/sec: 133.96 - lr: 0.000030
2021-07-23 15:09:17,787 epoch 4 - iter 250/507 - loss 0.14261217 - samples/sec: 134.72 - lr: 0.000030
2021-07-23 15:09:29,591 epoch 4 - iter 300/507 - loss 0.14230189 - samples/sec: 135.58 - lr: 0.000030
2021-07-23 15:09:41,527 epoch 4 - iter 350/507 - loss 0.14471175 - samples/sec: 134.08 - lr: 0.000030
2021-07-23 15:09:53,254 epoch 4 - iter 400/507 - loss 0.14433719 - samples/sec: 136.47 - lr: 0.000030
2021-07-23 15:10:04,987 epoch 4 - iter 450/507 - loss 0.14202507 - samples/sec: 136.40 - lr: 0.000030
2021-07-23 15:10:17,011 epoch 4 - iter 500/507 - loss 0.14040253 - samples/sec: 133.10 - lr: 0.000030
2021-07-23 15:10:18,530 ----------------------------------------------------------------------------------------------------
2021-07-23 15:10:18,530 EPOCH 4 done: loss 0.1401 - lr 0.0000300
2021-07-23 15:10:24,133 DEV : loss 0.07434766739606857 - score 0.9807
2021-07-23 15:10:24,198 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:10:26,449 ----------------------------------------------------------------------------------------------------
2021-07-23 15:10:38,108 epoch 5 - iter 50/507 - loss 0.13596234 - samples/sec: 137.30 - lr: 0.000030
2021-07-23 15:10:49,951 epoch 5 - iter 100/507 - loss 0.12987273 - samples/sec: 135.13 - lr: 0.000030
2021-07-23 15:11:01,631 epoch 5 - iter 150/507 - loss 0.13245074 - samples/sec: 137.01 - lr: 0.000030
2021-07-23 15:11:13,467 epoch 5 - iter 200/507 - loss 0.13484573 - samples/sec: 135.21 - lr: 0.000030
2021-07-23 15:11:25,500 epoch 5 - iter 250/507 - loss 0.13450733 - samples/sec: 132.99 - lr: 0.000030
2021-07-23 15:11:37,644 epoch 5 - iter 300/507 - loss 0.13507969 - samples/sec: 131.78 - lr: 0.000030
2021-07-23 15:11:49,436 epoch 5 - iter 350/507 - loss 0.13489191 - samples/sec: 135.72 - lr: 0.000030
2021-07-23 15:12:01,307 epoch 5 - iter 400/507 - loss 0.13444652 - samples/sec: 134.82 - lr: 0.000030
2021-07-23 15:12:13,311 epoch 5 - iter 450/507 - loss 0.13298263 - samples/sec: 133.31 - lr: 0.000030
2021-07-23 15:12:25,284 epoch 5 - iter 500/507 - loss 0.13383800 - samples/sec: 133.67 - lr: 0.000030
2021-07-23 15:12:26,894 ----------------------------------------------------------------------------------------------------
2021-07-23 15:12:26,895 EPOCH 5 done: loss 0.1341 - lr 0.0000300
2021-07-23 15:12:32,472 DEV : loss 0.06505315005779266 - score 0.9819
2021-07-23 15:12:32,538 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:12:34,801 ----------------------------------------------------------------------------------------------------
2021-07-23 15:12:46,442 epoch 6 - iter 50/507 - loss 0.12270409 - samples/sec: 137.51 - lr: 0.000030
2021-07-23 15:12:58,371 epoch 6 - iter 100/507 - loss 0.14257050 - samples/sec: 134.15 - lr: 0.000030
2021-07-23 15:13:10,217 epoch 6 - iter 150/507 - loss 0.13956951 - samples/sec: 135.10 - lr: 0.000030
2021-07-23 15:13:22,163 epoch 6 - iter 200/507 - loss 0.13493059 - samples/sec: 133.96 - lr: 0.000030
2021-07-23 15:13:33,979 epoch 6 - iter 250/507 - loss 0.12838639 - samples/sec: 135.44 - lr: 0.000030
2021-07-23 15:13:46,027 epoch 6 - iter 300/507 - loss 0.12745273 - samples/sec: 132.84 - lr: 0.000030
2021-07-23 15:13:57,862 epoch 6 - iter 350/507 - loss 0.12622691 - samples/sec: 135.22 - lr: 0.000030
2021-07-23 15:14:09,748 epoch 6 - iter 400/507 - loss 0.12719454 - samples/sec: 134.64 - lr: 0.000030
2021-07-23 15:14:21,823 epoch 6 - iter 450/507 - loss 0.12706601 - samples/sec: 132.54 - lr: 0.000030
2021-07-23 15:14:33,614 epoch 6 - iter 500/507 - loss 0.12806072 - samples/sec: 135.72 - lr: 0.000030
2021-07-23 15:14:35,126 ----------------------------------------------------------------------------------------------------
2021-07-23 15:14:35,127 EPOCH 6 done: loss 0.1280 - lr 0.0000300
2021-07-23 15:14:41,271 DEV : loss 0.0650426521897316 - score 0.9813
2021-07-23 15:14:41,335 BAD EPOCHS (no improvement): 1
2021-07-23 15:14:41,335 ----------------------------------------------------------------------------------------------------
2021-07-23 15:14:53,203 epoch 7 - iter 50/507 - loss 0.12437799 - samples/sec: 134.86 - lr: 0.000030
2021-07-23 15:15:04,907 epoch 7 - iter 100/507 - loss 0.12964311 - samples/sec: 136.74 - lr: 0.000030
2021-07-23 15:15:16,871 epoch 7 - iter 150/507 - loss 0.12275154 - samples/sec: 133.77 - lr: 0.000030
2021-07-23 15:15:28,766 epoch 7 - iter 200/507 - loss 0.12152465 - samples/sec: 134.53 - lr: 0.000030
2021-07-23 15:15:40,899 epoch 7 - iter 250/507 - loss 0.12084976 - samples/sec: 131.90 - lr: 0.000030
2021-07-23 15:15:52,727 epoch 7 - iter 300/507 - loss 0.12352348 - samples/sec: 135.30 - lr: 0.000030
2021-07-23 15:16:04,522 epoch 7 - iter 350/507 - loss 0.12293165 - samples/sec: 135.67 - lr: 0.000030
2021-07-23 15:16:16,514 epoch 7 - iter 400/507 - loss 0.12273909 - samples/sec: 133.46 - lr: 0.000030
2021-07-23 15:16:28,227 epoch 7 - iter 450/507 - loss 0.12029453 - samples/sec: 136.63 - lr: 0.000030
2021-07-23 15:16:40,040 epoch 7 - iter 500/507 - loss 0.12057474 - samples/sec: 135.47 - lr: 0.000030
2021-07-23 15:16:41,634 ----------------------------------------------------------------------------------------------------
2021-07-23 15:16:41,634 EPOCH 7 done: loss 0.1208 - lr 0.0000300
2021-07-23 15:16:47,252 DEV : loss 0.06078682839870453 - score 0.9825
2021-07-23 15:16:47,318 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:16:49,686 ----------------------------------------------------------------------------------------------------
2021-07-23 15:17:01,144 epoch 8 - iter 50/507 - loss 0.11737397 - samples/sec: 139.70 - lr: 0.000030
2021-07-23 15:17:12,977 epoch 8 - iter 100/507 - loss 0.11867456 - samples/sec: 135.24 - lr: 0.000030
2021-07-23 15:17:24,615 epoch 8 - iter 150/507 - loss 0.11819655 - samples/sec: 137.51 - lr: 0.000030
2021-07-23 15:17:36,396 epoch 8 - iter 200/507 - loss 0.12071202 - samples/sec: 135.84 - lr: 0.000030
2021-07-23 15:17:48,559 epoch 8 - iter 250/507 - loss 0.12086751 - samples/sec: 131.57 - lr: 0.000030
2021-07-23 15:18:00,452 epoch 8 - iter 300/507 - loss 0.11981213 - samples/sec: 134.56 - lr: 0.000030
2021-07-23 15:18:12,255 epoch 8 - iter 350/507 - loss 0.12112604 - samples/sec: 135.59 - lr: 0.000030
2021-07-23 15:18:24,151 epoch 8 - iter 400/507 - loss 0.11910657 - samples/sec: 134.52 - lr: 0.000030
2021-07-23 15:18:35,888 epoch 8 - iter 450/507 - loss 0.11977909 - samples/sec: 136.36 - lr: 0.000030
2021-07-23 15:18:47,911 epoch 8 - iter 500/507 - loss 0.11904540 - samples/sec: 133.11 - lr: 0.000030
2021-07-23 15:18:49,420 ----------------------------------------------------------------------------------------------------
2021-07-23 15:18:49,420 EPOCH 8 done: loss 0.1191 - lr 0.0000300
2021-07-23 15:18:55,025 DEV : loss 0.06798465549945831 - score 0.9827
2021-07-23 15:18:55,091 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:18:57,383 ----------------------------------------------------------------------------------------------------
2021-07-23 15:19:09,260 epoch 9 - iter 50/507 - loss 0.10006598 - samples/sec: 134.78 - lr: 0.000030
2021-07-23 15:19:21,028 epoch 9 - iter 100/507 - loss 0.10020482 - samples/sec: 135.99 - lr: 0.000030
2021-07-23 15:19:32,819 epoch 9 - iter 150/507 - loss 0.10221403 - samples/sec: 135.72 - lr: 0.000030
2021-07-23 15:19:44,639 epoch 9 - iter 200/507 - loss 0.10490102 - samples/sec: 135.39 - lr: 0.000030
2021-07-23 15:19:56,703 epoch 9 - iter 250/507 - loss 0.10738158 - samples/sec: 132.65 - lr: 0.000030
2021-07-23 15:20:08,476 epoch 9 - iter 300/507 - loss 0.10562749 - samples/sec: 135.94 - lr: 0.000030
2021-07-23 15:20:20,406 epoch 9 - iter 350/507 - loss 0.10692001 - samples/sec: 134.15 - lr: 0.000030
2021-07-23 15:20:32,459 epoch 9 - iter 400/507 - loss 0.11015750 - samples/sec: 132.78 - lr: 0.000030
2021-07-23 15:20:44,039 epoch 9 - iter 450/507 - loss 0.10967405 - samples/sec: 138.21 - lr: 0.000030
2021-07-23 15:20:55,675 epoch 9 - iter 500/507 - loss 0.10862334 - samples/sec: 137.54 - lr: 0.000030
2021-07-23 15:20:57,242 ----------------------------------------------------------------------------------------------------
2021-07-23 15:20:57,243 EPOCH 9 done: loss 0.1087 - lr 0.0000300
2021-07-23 15:21:02,891 DEV : loss 0.0566316694021225 - score 0.9841
2021-07-23 15:21:02,956 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:21:05,205 ----------------------------------------------------------------------------------------------------
2021-07-23 15:21:17,136 epoch 10 - iter 50/507 - loss 0.10775304 - samples/sec: 134.16 - lr: 0.000030
2021-07-23 15:21:28,905 epoch 10 - iter 100/507 - loss 0.09938621 - samples/sec: 135.98 - lr: 0.000030
2021-07-23 15:21:40,815 epoch 10 - iter 150/507 - loss 0.09628377 - samples/sec: 134.36 - lr: 0.000030
2021-07-23 15:21:52,820 epoch 10 - iter 200/507 - loss 0.10171584 - samples/sec: 133.31 - lr: 0.000030
2021-07-23 15:22:04,705 epoch 10 - iter 250/507 - loss 0.10067307 - samples/sec: 134.65 - lr: 0.000030
2021-07-23 15:22:16,453 epoch 10 - iter 300/507 - loss 0.10187560 - samples/sec: 136.23 - lr: 0.000030
2021-07-23 15:22:28,215 epoch 10 - iter 350/507 - loss 0.10062987 - samples/sec: 136.06 - lr: 0.000030
2021-07-23 15:22:40,087 epoch 10 - iter 400/507 - loss 0.09920225 - samples/sec: 134.80 - lr: 0.000030
2021-07-23 15:22:51,908 epoch 10 - iter 450/507 - loss 0.09846129 - samples/sec: 135.38 - lr: 0.000030
2021-07-23 15:23:03,702 epoch 10 - iter 500/507 - loss 0.09748885 - samples/sec: 135.69 - lr: 0.000030
2021-07-23 15:23:05,231 ----------------------------------------------------------------------------------------------------
2021-07-23 15:23:05,231 EPOCH 10 done: loss 0.0976 - lr 0.0000300
2021-07-23 15:23:10,837 DEV : loss 0.058507002890110016 - score 0.9829
2021-07-23 15:23:10,903 BAD EPOCHS (no improvement): 1
2021-07-23 15:23:10,903 ----------------------------------------------------------------------------------------------------
2021-07-23 15:23:22,747 epoch 11 - iter 50/507 - loss 0.09883255 - samples/sec: 135.13 - lr: 0.000030
2021-07-23 15:23:34,509 epoch 11 - iter 100/507 - loss 0.09423666 - samples/sec: 136.06 - lr: 0.000030
2021-07-23 15:23:47,051 epoch 11 - iter 150/507 - loss 0.09544988 - samples/sec: 127.60 - lr: 0.000030
2021-07-23 15:23:58,824 epoch 11 - iter 200/507 - loss 0.09029221 - samples/sec: 135.93 - lr: 0.000030
2021-07-23 15:24:10,655 epoch 11 - iter 250/507 - loss 0.08879667 - samples/sec: 135.27 - lr: 0.000030
2021-07-23 15:24:22,498 epoch 11 - iter 300/507 - loss 0.09112696 - samples/sec: 135.13 - lr: 0.000030
2021-07-23 15:24:34,250 epoch 11 - iter 350/507 - loss 0.08849412 - samples/sec: 136.17 - lr: 0.000030
2021-07-23 15:24:46,223 epoch 11 - iter 400/507 - loss 0.09011432 - samples/sec: 133.67 - lr: 0.000030
2021-07-23 15:24:58,068 epoch 11 - iter 450/507 - loss 0.08989085 - samples/sec: 135.11 - lr: 0.000030
2021-07-23 15:25:10,008 epoch 11 - iter 500/507 - loss 0.09051031 - samples/sec: 134.04 - lr: 0.000030
2021-07-23 15:25:11,646 ----------------------------------------------------------------------------------------------------
2021-07-23 15:25:11,646 EPOCH 11 done: loss 0.0903 - lr 0.0000300
2021-07-23 15:25:17,250 DEV : loss 0.05723566561937332 - score 0.9842
2021-07-23 15:25:17,315 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:25:19,333 ----------------------------------------------------------------------------------------------------
2021-07-23 15:25:31,399 epoch 12 - iter 50/507 - loss 0.08698216 - samples/sec: 132.66 - lr: 0.000030
2021-07-23 15:25:43,324 epoch 12 - iter 100/507 - loss 0.08700951 - samples/sec: 134.20 - lr: 0.000030
2021-07-23 15:25:54,904 epoch 12 - iter 150/507 - loss 0.08577477 - samples/sec: 138.19 - lr: 0.000030
2021-07-23 15:26:06,685 epoch 12 - iter 200/507 - loss 0.08495332 - samples/sec: 135.85 - lr: 0.000030
2021-07-23 15:26:18,794 epoch 12 - iter 250/507 - loss 0.08284057 - samples/sec: 132.15 - lr: 0.000030
2021-07-23 15:26:30,496 epoch 12 - iter 300/507 - loss 0.08175260 - samples/sec: 136.77 - lr: 0.000030
2021-07-23 15:26:42,419 epoch 12 - iter 350/507 - loss 0.08135048 - samples/sec: 134.22 - lr: 0.000030
2021-07-23 15:26:54,342 epoch 12 - iter 400/507 - loss 0.08153373 - samples/sec: 134.22 - lr: 0.000030
2021-07-23 15:27:06,252 epoch 12 - iter 450/507 - loss 0.08149181 - samples/sec: 134.37 - lr: 0.000030
2021-07-23 15:27:18,260 epoch 12 - iter 500/507 - loss 0.08287216 - samples/sec: 133.28 - lr: 0.000030
2021-07-23 15:27:19,783 ----------------------------------------------------------------------------------------------------
2021-07-23 15:27:19,783 EPOCH 12 done: loss 0.0831 - lr 0.0000300
2021-07-23 15:27:25,406 DEV : loss 0.050594255328178406 - score 0.9854
2021-07-23 15:27:25,471 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:27:27,766 ----------------------------------------------------------------------------------------------------
2021-07-23 15:27:39,728 epoch 13 - iter 50/507 - loss 0.08340084 - samples/sec: 133.81 - lr: 0.000030
2021-07-23 15:27:51,713 epoch 13 - iter 100/507 - loss 0.07629443 - samples/sec: 133.53 - lr: 0.000030
2021-07-23 15:28:03,315 epoch 13 - iter 150/507 - loss 0.07765456 - samples/sec: 137.94 - lr: 0.000030
2021-07-23 15:28:15,120 epoch 13 - iter 200/507 - loss 0.07563719 - samples/sec: 135.57 - lr: 0.000030
2021-07-23 15:28:27,097 epoch 13 - iter 250/507 - loss 0.07628683 - samples/sec: 133.62 - lr: 0.000030
2021-07-23 15:28:39,060 epoch 13 - iter 300/507 - loss 0.07755411 - samples/sec: 133.77 - lr: 0.000030
2021-07-23 15:28:50,953 epoch 13 - iter 350/507 - loss 0.07599860 - samples/sec: 134.56 - lr: 0.000030
2021-07-23 15:29:02,788 epoch 13 - iter 400/507 - loss 0.07535865 - samples/sec: 135.23 - lr: 0.000030
2021-07-23 15:29:14,570 epoch 13 - iter 450/507 - loss 0.07376095 - samples/sec: 135.82 - lr: 0.000030
2021-07-23 15:29:26,388 epoch 13 - iter 500/507 - loss 0.07474637 - samples/sec: 135.42 - lr: 0.000030
2021-07-23 15:29:27,851 ----------------------------------------------------------------------------------------------------
2021-07-23 15:29:27,851 EPOCH 13 done: loss 0.0752 - lr 0.0000300
2021-07-23 15:29:33,489 DEV : loss 0.05628146231174469 - score 0.9838
2021-07-23 15:29:33,554 BAD EPOCHS (no improvement): 1
2021-07-23 15:29:33,555 ----------------------------------------------------------------------------------------------------
2021-07-23 15:29:45,441 epoch 14 - iter 50/507 - loss 0.07297802 - samples/sec: 134.66 - lr: 0.000030
2021-07-23 15:29:57,052 epoch 14 - iter 100/507 - loss 0.06812843 - samples/sec: 137.83 - lr: 0.000030
2021-07-23 15:30:08,976 epoch 14 - iter 150/507 - loss 0.06848327 - samples/sec: 134.21 - lr: 0.000030
2021-07-23 15:30:21,019 epoch 14 - iter 200/507 - loss 0.06948589 - samples/sec: 132.88 - lr: 0.000030
2021-07-23 15:30:32,703 epoch 14 - iter 250/507 - loss 0.06825712 - samples/sec: 136.98 - lr: 0.000030
2021-07-23 15:30:44,386 epoch 14 - iter 300/507 - loss 0.06884770 - samples/sec: 136.98 - lr: 0.000030
2021-07-23 15:30:56,304 epoch 14 - iter 350/507 - loss 0.06982704 - samples/sec: 134.28 - lr: 0.000030
2021-07-23 15:31:08,487 epoch 14 - iter 400/507 - loss 0.07075448 - samples/sec: 131.35 - lr: 0.000030
2021-07-23 15:31:20,424 epoch 14 - iter 450/507 - loss 0.07121935 - samples/sec: 134.07 - lr: 0.000030
2021-07-23 15:31:32,445 epoch 14 - iter 500/507 - loss 0.07185930 - samples/sec: 133.13 - lr: 0.000030
2021-07-23 15:31:34,068 ----------------------------------------------------------------------------------------------------
2021-07-23 15:31:34,068 EPOCH 14 done: loss 0.0716 - lr 0.0000300
2021-07-23 15:31:39,678 DEV : loss 0.05021405965089798 - score 0.987
2021-07-23 15:31:39,745 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:31:42,035 ----------------------------------------------------------------------------------------------------
2021-07-23 15:31:53,950 epoch 15 - iter 50/507 - loss 0.06648087 - samples/sec: 134.33 - lr: 0.000030
2021-07-23 15:32:05,584 epoch 15 - iter 100/507 - loss 0.05836424 - samples/sec: 137.57 - lr: 0.000030
2021-07-23 15:32:17,588 epoch 15 - iter 150/507 - loss 0.06042835 - samples/sec: 133.32 - lr: 0.000030
2021-07-23 15:32:29,304 epoch 15 - iter 200/507 - loss 0.06221667 - samples/sec: 136.59 - lr: 0.000030
2021-07-23 15:32:41,233 epoch 15 - iter 250/507 - loss 0.06379062 - samples/sec: 134.16 - lr: 0.000030
2021-07-23 15:32:53,275 epoch 15 - iter 300/507 - loss 0.06341032 - samples/sec: 132.90 - lr: 0.000030
2021-07-23 15:33:05,365 epoch 15 - iter 350/507 - loss 0.06361937 - samples/sec: 132.37 - lr: 0.000030
2021-07-23 15:33:17,317 epoch 15 - iter 400/507 - loss 0.06283045 - samples/sec: 133.89 - lr: 0.000030
2021-07-23 15:33:29,248 epoch 15 - iter 450/507 - loss 0.06330961 - samples/sec: 134.13 - lr: 0.000030
2021-07-23 15:33:41,039 epoch 15 - iter 500/507 - loss 0.06370600 - samples/sec: 135.72 - lr: 0.000030
2021-07-23 15:33:42,620 ----------------------------------------------------------------------------------------------------
2021-07-23 15:33:42,620 EPOCH 15 done: loss 0.0637 - lr 0.0000300
2021-07-23 15:33:48,807 DEV : loss 0.05007562041282654 - score 0.9866
2021-07-23 15:33:48,872 BAD EPOCHS (no improvement): 1
2021-07-23 15:33:48,872 ----------------------------------------------------------------------------------------------------
2021-07-23 15:34:00,841 epoch 16 - iter 50/507 - loss 0.05887735 - samples/sec: 133.73 - lr: 0.000030
2021-07-23 15:34:12,928 epoch 16 - iter 100/507 - loss 0.06685085 - samples/sec: 132.40 - lr: 0.000030
2021-07-23 15:34:24,826 epoch 16 - iter 150/507 - loss 0.06196949 - samples/sec: 134.50 - lr: 0.000030
2021-07-23 15:34:36,676 epoch 16 - iter 200/507 - loss 0.06591834 - samples/sec: 135.05 - lr: 0.000030
2021-07-23 15:34:48,459 epoch 16 - iter 250/507 - loss 0.06532534 - samples/sec: 135.82 - lr: 0.000030
2021-07-23 15:35:00,290 epoch 16 - iter 300/507 - loss 0.06390292 - samples/sec: 135.26 - lr: 0.000030
2021-07-23 15:35:12,110 epoch 16 - iter 350/507 - loss 0.06676146 - samples/sec: 135.40 - lr: 0.000030
2021-07-23 15:35:24,084 epoch 16 - iter 400/507 - loss 0.06757727 - samples/sec: 133.66 - lr: 0.000030
2021-07-23 15:35:35,799 epoch 16 - iter 450/507 - loss 0.06751978 - samples/sec: 136.60 - lr: 0.000030
2021-07-23 15:35:47,685 epoch 16 - iter 500/507 - loss 0.06711251 - samples/sec: 134.64 - lr: 0.000030
2021-07-23 15:35:49,302 ----------------------------------------------------------------------------------------------------
2021-07-23 15:35:49,303 EPOCH 16 done: loss 0.0676 - lr 0.0000300
2021-07-23 15:35:54,907 DEV : loss 0.04871668294072151 - score 0.9869
2021-07-23 15:35:54,973 BAD EPOCHS (no improvement): 2
2021-07-23 15:35:54,973 ----------------------------------------------------------------------------------------------------
2021-07-23 15:36:06,792 epoch 17 - iter 50/507 - loss 0.05309478 - samples/sec: 135.42 - lr: 0.000030
2021-07-23 15:36:18,799 epoch 17 - iter 100/507 - loss 0.06620433 - samples/sec: 133.29 - lr: 0.000030
2021-07-23 15:36:30,785 epoch 17 - iter 150/507 - loss 0.06537460 - samples/sec: 133.52 - lr: 0.000030
2021-07-23 15:36:42,616 epoch 17 - iter 200/507 - loss 0.06582443 - samples/sec: 135.26 - lr: 0.000030
2021-07-23 15:36:54,739 epoch 17 - iter 250/507 - loss 0.06670674 - samples/sec: 132.02 - lr: 0.000030
2021-07-23 15:37:06,644 epoch 17 - iter 300/507 - loss 0.06708667 - samples/sec: 134.42 - lr: 0.000030
2021-07-23 15:37:18,433 epoch 17 - iter 350/507 - loss 0.06509655 - samples/sec: 135.75 - lr: 0.000030
2021-07-23 15:37:30,177 epoch 17 - iter 400/507 - loss 0.06393422 - samples/sec: 136.28 - lr: 0.000030
2021-07-23 15:37:41,951 epoch 17 - iter 450/507 - loss 0.06511996 - samples/sec: 135.92 - lr: 0.000030
2021-07-23 15:37:53,648 epoch 17 - iter 500/507 - loss 0.06532567 - samples/sec: 136.82 - lr: 0.000030
2021-07-23 15:37:55,235 ----------------------------------------------------------------------------------------------------
2021-07-23 15:37:55,236 EPOCH 17 done: loss 0.0652 - lr 0.0000300
2021-07-23 15:38:00,877 DEV : loss 0.04535520821809769 - score 0.9866
2021-07-23 15:38:00,942 BAD EPOCHS (no improvement): 3
2021-07-23 15:38:00,942 ----------------------------------------------------------------------------------------------------
2021-07-23 15:38:12,480 epoch 18 - iter 50/507 - loss 0.04475926 - samples/sec: 138.72 - lr: 0.000030
2021-07-23 15:38:24,416 epoch 18 - iter 100/507 - loss 0.05328910 - samples/sec: 134.07 - lr: 0.000030
2021-07-23 15:38:36,483 epoch 18 - iter 150/507 - loss 0.05893096 - samples/sec: 132.62 - lr: 0.000030
2021-07-23 15:38:48,316 epoch 18 - iter 200/507 - loss 0.05782472 - samples/sec: 135.25 - lr: 0.000030
2021-07-23 15:39:00,380 epoch 18 - iter 250/507 - loss 0.05509985 - samples/sec: 132.65 - lr: 0.000030
2021-07-23 15:39:12,265 epoch 18 - iter 300/507 - loss 0.05555197 - samples/sec: 134.65 - lr: 0.000030
2021-07-23 15:39:23,908 epoch 18 - iter 350/507 - loss 0.05747703 - samples/sec: 137.45 - lr: 0.000030
2021-07-23 15:39:36,083 epoch 18 - iter 400/507 - loss 0.05691085 - samples/sec: 131.44 - lr: 0.000030
2021-07-23 15:39:47,752 epoch 18 - iter 450/507 - loss 0.05715805 - samples/sec: 137.14 - lr: 0.000030
2021-07-23 15:39:59,699 epoch 18 - iter 500/507 - loss 0.05863443 - samples/sec: 133.95 - lr: 0.000030
2021-07-23 15:40:01,284 ----------------------------------------------------------------------------------------------------
2021-07-23 15:40:01,284 EPOCH 18 done: loss 0.0586 - lr 0.0000300
2021-07-23 15:40:06,952 DEV : loss 0.050865817815065384 - score 0.9857
Epoch    18: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 15:40:07,018 BAD EPOCHS (no improvement): 4
2021-07-23 15:40:07,018 ----------------------------------------------------------------------------------------------------
2021-07-23 15:40:18,820 epoch 19 - iter 50/507 - loss 0.05780268 - samples/sec: 135.61 - lr: 0.000015
2021-07-23 15:40:30,844 epoch 19 - iter 100/507 - loss 0.05990634 - samples/sec: 133.10 - lr: 0.000015
2021-07-23 15:40:42,691 epoch 19 - iter 150/507 - loss 0.06077995 - samples/sec: 135.08 - lr: 0.000015
2021-07-23 15:40:54,434 epoch 19 - iter 200/507 - loss 0.05851549 - samples/sec: 136.28 - lr: 0.000015
2021-07-23 15:41:06,206 epoch 19 - iter 250/507 - loss 0.05767193 - samples/sec: 135.95 - lr: 0.000015
2021-07-23 15:41:17,939 epoch 19 - iter 300/507 - loss 0.05736431 - samples/sec: 136.41 - lr: 0.000015
2021-07-23 15:41:29,948 epoch 19 - iter 350/507 - loss 0.05651685 - samples/sec: 133.26 - lr: 0.000015
2021-07-23 15:41:41,940 epoch 19 - iter 400/507 - loss 0.05589042 - samples/sec: 133.45 - lr: 0.000015
2021-07-23 15:41:54,039 epoch 19 - iter 450/507 - loss 0.05543351 - samples/sec: 132.27 - lr: 0.000015
2021-07-23 15:42:05,820 epoch 19 - iter 500/507 - loss 0.05493267 - samples/sec: 135.85 - lr: 0.000015
2021-07-23 15:42:07,346 ----------------------------------------------------------------------------------------------------
2021-07-23 15:42:07,347 EPOCH 19 done: loss 0.0547 - lr 0.0000150
2021-07-23 15:42:12,962 DEV : loss 0.048066701740026474 - score 0.9873
2021-07-23 15:42:13,027 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:42:15,399 ----------------------------------------------------------------------------------------------------
2021-07-23 15:42:27,094 epoch 20 - iter 50/507 - loss 0.05998727 - samples/sec: 136.87 - lr: 0.000015
2021-07-23 15:42:38,934 epoch 20 - iter 100/507 - loss 0.05459382 - samples/sec: 135.17 - lr: 0.000015
2021-07-23 15:42:50,816 epoch 20 - iter 150/507 - loss 0.05862785 - samples/sec: 134.68 - lr: 0.000015
2021-07-23 15:43:02,504 epoch 20 - iter 200/507 - loss 0.05882400 - samples/sec: 136.92 - lr: 0.000015
2021-07-23 15:43:14,608 epoch 20 - iter 250/507 - loss 0.05649203 - samples/sec: 132.22 - lr: 0.000015
2021-07-23 15:43:26,411 epoch 20 - iter 300/507 - loss 0.05595208 - samples/sec: 135.58 - lr: 0.000015
2021-07-23 15:43:38,165 epoch 20 - iter 350/507 - loss 0.05488772 - samples/sec: 136.15 - lr: 0.000015
2021-07-23 15:43:50,109 epoch 20 - iter 400/507 - loss 0.05498177 - samples/sec: 133.99 - lr: 0.000015
2021-07-23 15:44:02,612 epoch 20 - iter 450/507 - loss 0.05396466 - samples/sec: 128.00 - lr: 0.000015
2021-07-23 15:44:14,676 epoch 20 - iter 500/507 - loss 0.05383300 - samples/sec: 132.65 - lr: 0.000015
2021-07-23 15:44:16,260 ----------------------------------------------------------------------------------------------------
2021-07-23 15:44:16,260 EPOCH 20 done: loss 0.0542 - lr 0.0000150
2021-07-23 15:44:21,870 DEV : loss 0.045517005026340485 - score 0.9876
2021-07-23 15:44:21,936 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:44:24,268 ----------------------------------------------------------------------------------------------------
2021-07-23 15:44:36,243 epoch 21 - iter 50/507 - loss 0.04835783 - samples/sec: 133.66 - lr: 0.000015
2021-07-23 15:44:48,071 epoch 21 - iter 100/507 - loss 0.05346402 - samples/sec: 135.31 - lr: 0.000015
2021-07-23 15:45:00,061 epoch 21 - iter 150/507 - loss 0.05111365 - samples/sec: 133.47 - lr: 0.000015
2021-07-23 15:45:12,107 epoch 21 - iter 200/507 - loss 0.05066614 - samples/sec: 132.86 - lr: 0.000015
2021-07-23 15:45:23,871 epoch 21 - iter 250/507 - loss 0.05390409 - samples/sec: 136.03 - lr: 0.000015
2021-07-23 15:45:36,103 epoch 21 - iter 300/507 - loss 0.05353271 - samples/sec: 130.84 - lr: 0.000015
2021-07-23 15:45:47,835 epoch 21 - iter 350/507 - loss 0.05458687 - samples/sec: 136.40 - lr: 0.000015
2021-07-23 15:45:59,719 epoch 21 - iter 400/507 - loss 0.05342939 - samples/sec: 134.67 - lr: 0.000015
2021-07-23 15:46:11,554 epoch 21 - iter 450/507 - loss 0.05328399 - samples/sec: 135.23 - lr: 0.000015
2021-07-23 15:46:23,431 epoch 21 - iter 500/507 - loss 0.05302309 - samples/sec: 134.73 - lr: 0.000015
2021-07-23 15:46:24,972 ----------------------------------------------------------------------------------------------------
2021-07-23 15:46:24,972 EPOCH 21 done: loss 0.0528 - lr 0.0000150
2021-07-23 15:46:30,636 DEV : loss 0.04567364975810051 - score 0.9863
2021-07-23 15:46:30,702 BAD EPOCHS (no improvement): 1
2021-07-23 15:46:30,702 ----------------------------------------------------------------------------------------------------
2021-07-23 15:46:42,707 epoch 22 - iter 50/507 - loss 0.05804226 - samples/sec: 133.32 - lr: 0.000015
2021-07-23 15:46:54,560 epoch 22 - iter 100/507 - loss 0.05840029 - samples/sec: 135.02 - lr: 0.000015
2021-07-23 15:47:06,667 epoch 22 - iter 150/507 - loss 0.05630118 - samples/sec: 132.18 - lr: 0.000015
2021-07-23 15:47:18,407 epoch 22 - iter 200/507 - loss 0.05607695 - samples/sec: 136.31 - lr: 0.000015
2021-07-23 15:47:30,407 epoch 22 - iter 250/507 - loss 0.05411640 - samples/sec: 133.36 - lr: 0.000015
2021-07-23 15:47:42,434 epoch 22 - iter 300/507 - loss 0.05431590 - samples/sec: 133.06 - lr: 0.000015
2021-07-23 15:47:54,011 epoch 22 - iter 350/507 - loss 0.05393085 - samples/sec: 138.24 - lr: 0.000015
2021-07-23 15:48:05,845 epoch 22 - iter 400/507 - loss 0.05410279 - samples/sec: 135.24 - lr: 0.000015
2021-07-23 15:48:17,451 epoch 22 - iter 450/507 - loss 0.05364445 - samples/sec: 137.89 - lr: 0.000015
2021-07-23 15:48:29,392 epoch 22 - iter 500/507 - loss 0.05373176 - samples/sec: 134.02 - lr: 0.000015
2021-07-23 15:48:30,896 ----------------------------------------------------------------------------------------------------
2021-07-23 15:48:30,896 EPOCH 22 done: loss 0.0535 - lr 0.0000150
2021-07-23 15:48:36,541 DEV : loss 0.04678598791360855 - score 0.9869
2021-07-23 15:48:36,607 BAD EPOCHS (no improvement): 2
2021-07-23 15:48:36,607 ----------------------------------------------------------------------------------------------------
2021-07-23 15:48:48,207 epoch 23 - iter 50/507 - loss 0.05661372 - samples/sec: 137.98 - lr: 0.000015
2021-07-23 15:49:00,358 epoch 23 - iter 100/507 - loss 0.05481095 - samples/sec: 131.70 - lr: 0.000015
2021-07-23 15:49:12,142 epoch 23 - iter 150/507 - loss 0.05392840 - samples/sec: 135.82 - lr: 0.000015
2021-07-23 15:49:24,042 epoch 23 - iter 200/507 - loss 0.05295582 - samples/sec: 134.48 - lr: 0.000015
2021-07-23 15:49:35,647 epoch 23 - iter 250/507 - loss 0.05359390 - samples/sec: 137.90 - lr: 0.000015
2021-07-23 15:49:47,458 epoch 23 - iter 300/507 - loss 0.05514182 - samples/sec: 135.49 - lr: 0.000015
2021-07-23 15:49:59,473 epoch 23 - iter 350/507 - loss 0.05488485 - samples/sec: 133.20 - lr: 0.000015
2021-07-23 15:50:11,385 epoch 23 - iter 400/507 - loss 0.05313736 - samples/sec: 134.34 - lr: 0.000015
2021-07-23 15:50:23,175 epoch 23 - iter 450/507 - loss 0.05263252 - samples/sec: 135.74 - lr: 0.000015
2021-07-23 15:50:35,248 epoch 23 - iter 500/507 - loss 0.05264198 - samples/sec: 132.56 - lr: 0.000015
2021-07-23 15:50:36,867 ----------------------------------------------------------------------------------------------------
2021-07-23 15:50:36,867 EPOCH 23 done: loss 0.0526 - lr 0.0000150
2021-07-23 15:50:42,514 DEV : loss 0.04555700719356537 - score 0.9872
2021-07-23 15:50:42,579 BAD EPOCHS (no improvement): 3
2021-07-23 15:50:42,580 ----------------------------------------------------------------------------------------------------
2021-07-23 15:50:54,415 epoch 24 - iter 50/507 - loss 0.06041333 - samples/sec: 135.23 - lr: 0.000015
2021-07-23 15:51:06,158 epoch 24 - iter 100/507 - loss 0.04935035 - samples/sec: 136.29 - lr: 0.000015
2021-07-23 15:51:18,135 epoch 24 - iter 150/507 - loss 0.05173631 - samples/sec: 133.61 - lr: 0.000015
2021-07-23 15:51:29,995 epoch 24 - iter 200/507 - loss 0.05095338 - samples/sec: 134.94 - lr: 0.000015
2021-07-23 15:51:42,028 epoch 24 - iter 250/507 - loss 0.05206539 - samples/sec: 133.00 - lr: 0.000015
2021-07-23 15:51:53,844 epoch 24 - iter 300/507 - loss 0.05344105 - samples/sec: 135.44 - lr: 0.000015
2021-07-23 15:52:05,727 epoch 24 - iter 350/507 - loss 0.05110709 - samples/sec: 134.67 - lr: 0.000015
2021-07-23 15:52:17,760 epoch 24 - iter 400/507 - loss 0.05263901 - samples/sec: 132.99 - lr: 0.000015
2021-07-23 15:52:29,720 epoch 24 - iter 450/507 - loss 0.05208388 - samples/sec: 133.81 - lr: 0.000015
2021-07-23 15:52:41,261 epoch 24 - iter 500/507 - loss 0.05311781 - samples/sec: 138.68 - lr: 0.000015
2021-07-23 15:52:42,790 ----------------------------------------------------------------------------------------------------
2021-07-23 15:52:42,791 EPOCH 24 done: loss 0.0531 - lr 0.0000150
2021-07-23 15:52:48,435 DEV : loss 0.044707801192998886 - score 0.9869
Epoch    24: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 15:52:48,500 BAD EPOCHS (no improvement): 4
2021-07-23 15:52:48,501 ----------------------------------------------------------------------------------------------------
2021-07-23 15:53:00,952 epoch 25 - iter 50/507 - loss 0.06654047 - samples/sec: 128.54 - lr: 0.000008
2021-07-23 15:53:12,887 epoch 25 - iter 100/507 - loss 0.05594054 - samples/sec: 134.09 - lr: 0.000008
2021-07-23 15:53:24,623 epoch 25 - iter 150/507 - loss 0.05077562 - samples/sec: 136.37 - lr: 0.000008
2021-07-23 15:53:36,467 epoch 25 - iter 200/507 - loss 0.04756110 - samples/sec: 135.11 - lr: 0.000008
2021-07-23 15:53:48,056 epoch 25 - iter 250/507 - loss 0.04819382 - samples/sec: 138.10 - lr: 0.000008
2021-07-23 15:54:00,103 epoch 25 - iter 300/507 - loss 0.04813079 - samples/sec: 132.83 - lr: 0.000008
2021-07-23 15:54:12,160 epoch 25 - iter 350/507 - loss 0.04734929 - samples/sec: 132.74 - lr: 0.000008
2021-07-23 15:54:24,055 epoch 25 - iter 400/507 - loss 0.04894582 - samples/sec: 134.53 - lr: 0.000008
2021-07-23 15:54:35,888 epoch 25 - iter 450/507 - loss 0.04884652 - samples/sec: 135.24 - lr: 0.000008
2021-07-23 15:54:47,607 epoch 25 - iter 500/507 - loss 0.04980080 - samples/sec: 136.56 - lr: 0.000008
2021-07-23 15:54:49,179 ----------------------------------------------------------------------------------------------------
2021-07-23 15:54:49,179 EPOCH 25 done: loss 0.0500 - lr 0.0000075
2021-07-23 15:54:54,824 DEV : loss 0.04411423206329346 - score 0.9876
2021-07-23 15:54:54,889 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:54:57,162 ----------------------------------------------------------------------------------------------------
2021-07-23 15:55:09,183 epoch 26 - iter 50/507 - loss 0.05200478 - samples/sec: 133.15 - lr: 0.000008
2021-07-23 15:55:21,184 epoch 26 - iter 100/507 - loss 0.04945490 - samples/sec: 133.35 - lr: 0.000008
2021-07-23 15:55:32,991 epoch 26 - iter 150/507 - loss 0.04925604 - samples/sec: 135.54 - lr: 0.000008
2021-07-23 15:55:44,632 epoch 26 - iter 200/507 - loss 0.04772173 - samples/sec: 137.48 - lr: 0.000008
2021-07-23 15:55:56,485 epoch 26 - iter 250/507 - loss 0.05098664 - samples/sec: 135.01 - lr: 0.000008
2021-07-23 15:56:08,184 epoch 26 - iter 300/507 - loss 0.04980230 - samples/sec: 136.79 - lr: 0.000008
2021-07-23 15:56:20,224 epoch 26 - iter 350/507 - loss 0.04885713 - samples/sec: 132.92 - lr: 0.000008
2021-07-23 15:56:31,980 epoch 26 - iter 400/507 - loss 0.04898784 - samples/sec: 136.13 - lr: 0.000008
2021-07-23 15:56:43,993 epoch 26 - iter 450/507 - loss 0.04871515 - samples/sec: 133.22 - lr: 0.000008
2021-07-23 15:56:56,089 epoch 26 - iter 500/507 - loss 0.04879668 - samples/sec: 132.30 - lr: 0.000008
2021-07-23 15:56:57,670 ----------------------------------------------------------------------------------------------------
2021-07-23 15:56:57,670 EPOCH 26 done: loss 0.0491 - lr 0.0000075
2021-07-23 15:57:03,306 DEV : loss 0.04499819874763489 - score 0.9882
2021-07-23 15:57:03,372 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 15:57:05,557 ----------------------------------------------------------------------------------------------------
2021-07-23 15:57:17,556 epoch 27 - iter 50/507 - loss 0.05004809 - samples/sec: 133.40 - lr: 0.000008
2021-07-23 15:57:29,568 epoch 27 - iter 100/507 - loss 0.05180307 - samples/sec: 133.23 - lr: 0.000008
2021-07-23 15:57:41,165 epoch 27 - iter 150/507 - loss 0.05467000 - samples/sec: 138.00 - lr: 0.000008
2021-07-23 15:57:53,028 epoch 27 - iter 200/507 - loss 0.05545389 - samples/sec: 134.89 - lr: 0.000008
2021-07-23 15:58:04,521 epoch 27 - iter 250/507 - loss 0.05363187 - samples/sec: 139.24 - lr: 0.000008
2021-07-23 15:58:16,220 epoch 27 - iter 300/507 - loss 0.05162276 - samples/sec: 136.79 - lr: 0.000008
2021-07-23 15:58:28,144 epoch 27 - iter 350/507 - loss 0.05171674 - samples/sec: 134.22 - lr: 0.000008
2021-07-23 15:58:39,892 epoch 27 - iter 400/507 - loss 0.05019956 - samples/sec: 136.22 - lr: 0.000008
2021-07-23 15:58:51,939 epoch 27 - iter 450/507 - loss 0.04901573 - samples/sec: 132.84 - lr: 0.000008
2021-07-23 15:59:04,193 epoch 27 - iter 500/507 - loss 0.05028224 - samples/sec: 130.59 - lr: 0.000008
2021-07-23 15:59:05,784 ----------------------------------------------------------------------------------------------------
2021-07-23 15:59:05,784 EPOCH 27 done: loss 0.0506 - lr 0.0000075
2021-07-23 15:59:11,451 DEV : loss 0.04515458270907402 - score 0.9875
2021-07-23 15:59:11,517 BAD EPOCHS (no improvement): 1
2021-07-23 15:59:11,517 ----------------------------------------------------------------------------------------------------
2021-07-23 15:59:23,475 epoch 28 - iter 50/507 - loss 0.04758176 - samples/sec: 133.84 - lr: 0.000008
2021-07-23 15:59:35,508 epoch 28 - iter 100/507 - loss 0.04011785 - samples/sec: 133.00 - lr: 0.000008
2021-07-23 15:59:47,364 epoch 28 - iter 150/507 - loss 0.04405656 - samples/sec: 134.97 - lr: 0.000008
2021-07-23 15:59:59,259 epoch 28 - iter 200/507 - loss 0.04467894 - samples/sec: 134.54 - lr: 0.000008
2021-07-23 16:00:11,044 epoch 28 - iter 250/507 - loss 0.04594228 - samples/sec: 135.80 - lr: 0.000008
2021-07-23 16:00:23,088 epoch 28 - iter 300/507 - loss 0.04649924 - samples/sec: 132.87 - lr: 0.000008
2021-07-23 16:00:34,992 epoch 28 - iter 350/507 - loss 0.04820502 - samples/sec: 134.44 - lr: 0.000008
2021-07-23 16:00:46,727 epoch 28 - iter 400/507 - loss 0.04978332 - samples/sec: 136.38 - lr: 0.000008
2021-07-23 16:00:58,647 epoch 28 - iter 450/507 - loss 0.05037965 - samples/sec: 134.25 - lr: 0.000008
2021-07-23 16:01:10,364 epoch 28 - iter 500/507 - loss 0.04931212 - samples/sec: 136.59 - lr: 0.000008
2021-07-23 16:01:11,912 ----------------------------------------------------------------------------------------------------
2021-07-23 16:01:11,912 EPOCH 28 done: loss 0.0489 - lr 0.0000075
2021-07-23 16:01:17,581 DEV : loss 0.045139163732528687 - score 0.9866
2021-07-23 16:01:17,649 BAD EPOCHS (no improvement): 2
2021-07-23 16:01:17,649 ----------------------------------------------------------------------------------------------------
2021-07-23 16:01:29,440 epoch 29 - iter 50/507 - loss 0.05515494 - samples/sec: 135.74 - lr: 0.000008
2021-07-23 16:01:41,377 epoch 29 - iter 100/507 - loss 0.05975970 - samples/sec: 134.07 - lr: 0.000008
2021-07-23 16:01:53,607 epoch 29 - iter 150/507 - loss 0.05813418 - samples/sec: 130.85 - lr: 0.000008
2021-07-23 16:02:05,583 epoch 29 - iter 200/507 - loss 0.05706614 - samples/sec: 133.63 - lr: 0.000008
2021-07-23 16:02:17,367 epoch 29 - iter 250/507 - loss 0.05631719 - samples/sec: 135.81 - lr: 0.000008
2021-07-23 16:02:29,354 epoch 29 - iter 300/507 - loss 0.05618403 - samples/sec: 133.50 - lr: 0.000008
2021-07-23 16:02:41,344 epoch 29 - iter 350/507 - loss 0.05393116 - samples/sec: 133.47 - lr: 0.000008
2021-07-23 16:02:53,155 epoch 29 - iter 400/507 - loss 0.05184227 - samples/sec: 135.50 - lr: 0.000008
2021-07-23 16:03:04,970 epoch 29 - iter 450/507 - loss 0.05098256 - samples/sec: 135.45 - lr: 0.000008
2021-07-23 16:03:16,522 epoch 29 - iter 500/507 - loss 0.05102369 - samples/sec: 138.53 - lr: 0.000008
2021-07-23 16:03:18,032 ----------------------------------------------------------------------------------------------------
2021-07-23 16:03:18,032 EPOCH 29 done: loss 0.0506 - lr 0.0000075
2021-07-23 16:03:24,241 DEV : loss 0.04369257390499115 - score 0.9878
2021-07-23 16:03:24,307 BAD EPOCHS (no improvement): 3
2021-07-23 16:03:24,307 ----------------------------------------------------------------------------------------------------
2021-07-23 16:03:35,843 epoch 30 - iter 50/507 - loss 0.04109829 - samples/sec: 138.75 - lr: 0.000008
2021-07-23 16:03:47,776 epoch 30 - iter 100/507 - loss 0.05128567 - samples/sec: 134.11 - lr: 0.000008
2021-07-23 16:03:59,828 epoch 30 - iter 150/507 - loss 0.05144121 - samples/sec: 132.79 - lr: 0.000008
2021-07-23 16:04:11,724 epoch 30 - iter 200/507 - loss 0.05174311 - samples/sec: 134.53 - lr: 0.000008
2021-07-23 16:04:23,536 epoch 30 - iter 250/507 - loss 0.05004097 - samples/sec: 135.48 - lr: 0.000008
2021-07-23 16:04:35,486 epoch 30 - iter 300/507 - loss 0.04923417 - samples/sec: 133.92 - lr: 0.000008
2021-07-23 16:04:47,139 epoch 30 - iter 350/507 - loss 0.04771215 - samples/sec: 137.33 - lr: 0.000008
2021-07-23 16:04:59,029 epoch 30 - iter 400/507 - loss 0.04664530 - samples/sec: 134.59 - lr: 0.000008
2021-07-23 16:05:10,787 epoch 30 - iter 450/507 - loss 0.04634247 - samples/sec: 136.11 - lr: 0.000008
2021-07-23 16:05:22,732 epoch 30 - iter 500/507 - loss 0.04802543 - samples/sec: 133.97 - lr: 0.000008
2021-07-23 16:05:24,287 ----------------------------------------------------------------------------------------------------
2021-07-23 16:05:24,287 EPOCH 30 done: loss 0.0484 - lr 0.0000075
2021-07-23 16:05:29,947 DEV : loss 0.04633454233407974 - score 0.9869
Epoch    30: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 16:05:30,012 BAD EPOCHS (no improvement): 4
2021-07-23 16:05:30,013 ----------------------------------------------------------------------------------------------------
2021-07-23 16:05:41,843 epoch 31 - iter 50/507 - loss 0.04096586 - samples/sec: 135.29 - lr: 0.000004
2021-07-23 16:05:53,692 epoch 31 - iter 100/507 - loss 0.04589422 - samples/sec: 135.06 - lr: 0.000004
2021-07-23 16:06:05,415 epoch 31 - iter 150/507 - loss 0.04593006 - samples/sec: 136.51 - lr: 0.000004
2021-07-23 16:06:17,192 epoch 31 - iter 200/507 - loss 0.04681221 - samples/sec: 135.89 - lr: 0.000004
2021-07-23 16:06:29,207 epoch 31 - iter 250/507 - loss 0.04903661 - samples/sec: 133.19 - lr: 0.000004
2021-07-23 16:06:41,152 epoch 31 - iter 300/507 - loss 0.04947211 - samples/sec: 133.98 - lr: 0.000004
2021-07-23 16:06:52,895 epoch 31 - iter 350/507 - loss 0.05007700 - samples/sec: 136.28 - lr: 0.000004
2021-07-23 16:07:04,951 epoch 31 - iter 400/507 - loss 0.04990608 - samples/sec: 132.74 - lr: 0.000004
2021-07-23 16:07:16,800 epoch 31 - iter 450/507 - loss 0.05027950 - samples/sec: 135.06 - lr: 0.000004
2021-07-23 16:07:28,640 epoch 31 - iter 500/507 - loss 0.05032432 - samples/sec: 135.17 - lr: 0.000004
2021-07-23 16:07:30,132 ----------------------------------------------------------------------------------------------------
2021-07-23 16:07:30,132 EPOCH 31 done: loss 0.0504 - lr 0.0000038
2021-07-23 16:07:35,784 DEV : loss 0.04462503269314766 - score 0.9879
2021-07-23 16:07:35,850 BAD EPOCHS (no improvement): 1
2021-07-23 16:07:35,850 ----------------------------------------------------------------------------------------------------
2021-07-23 16:07:47,728 epoch 32 - iter 50/507 - loss 0.03769020 - samples/sec: 134.75 - lr: 0.000004
2021-07-23 16:07:59,816 epoch 32 - iter 100/507 - loss 0.04437094 - samples/sec: 132.39 - lr: 0.000004
2021-07-23 16:08:11,707 epoch 32 - iter 150/507 - loss 0.04808145 - samples/sec: 134.59 - lr: 0.000004
2021-07-23 16:08:23,593 epoch 32 - iter 200/507 - loss 0.04588058 - samples/sec: 134.64 - lr: 0.000004
2021-07-23 16:08:35,312 epoch 32 - iter 250/507 - loss 0.04645059 - samples/sec: 136.56 - lr: 0.000004
2021-07-23 16:08:47,113 epoch 32 - iter 300/507 - loss 0.04706511 - samples/sec: 135.61 - lr: 0.000004
2021-07-23 16:08:58,832 epoch 32 - iter 350/507 - loss 0.04782643 - samples/sec: 136.55 - lr: 0.000004
2021-07-23 16:09:10,872 epoch 32 - iter 400/507 - loss 0.04704476 - samples/sec: 132.93 - lr: 0.000004
2021-07-23 16:09:22,852 epoch 32 - iter 450/507 - loss 0.04729626 - samples/sec: 133.58 - lr: 0.000004
2021-07-23 16:09:34,794 epoch 32 - iter 500/507 - loss 0.04726917 - samples/sec: 134.00 - lr: 0.000004
2021-07-23 16:09:36,246 ----------------------------------------------------------------------------------------------------
2021-07-23 16:09:36,246 EPOCH 32 done: loss 0.0473 - lr 0.0000038
2021-07-23 16:09:41,863 DEV : loss 0.044433239847421646 - score 0.9866
2021-07-23 16:09:41,929 BAD EPOCHS (no improvement): 2
2021-07-23 16:09:41,930 ----------------------------------------------------------------------------------------------------
2021-07-23 16:09:53,432 epoch 33 - iter 50/507 - loss 0.04590147 - samples/sec: 139.15 - lr: 0.000004
2021-07-23 16:10:05,100 epoch 33 - iter 100/507 - loss 0.04466983 - samples/sec: 137.16 - lr: 0.000004
2021-07-23 16:10:17,123 epoch 33 - iter 150/507 - loss 0.04387713 - samples/sec: 133.11 - lr: 0.000004
2021-07-23 16:10:28,796 epoch 33 - iter 200/507 - loss 0.04841324 - samples/sec: 137.11 - lr: 0.000004
2021-07-23 16:10:40,703 epoch 33 - iter 250/507 - loss 0.04621597 - samples/sec: 134.40 - lr: 0.000004
2021-07-23 16:10:52,456 epoch 33 - iter 300/507 - loss 0.04620477 - samples/sec: 136.16 - lr: 0.000004
2021-07-23 16:11:04,456 epoch 33 - iter 350/507 - loss 0.04599966 - samples/sec: 133.36 - lr: 0.000004
2021-07-23 16:11:16,298 epoch 33 - iter 400/507 - loss 0.04633727 - samples/sec: 135.14 - lr: 0.000004
2021-07-23 16:11:28,037 epoch 33 - iter 450/507 - loss 0.04591463 - samples/sec: 136.33 - lr: 0.000004
2021-07-23 16:11:39,969 epoch 33 - iter 500/507 - loss 0.04569671 - samples/sec: 134.12 - lr: 0.000004
2021-07-23 16:11:41,450 ----------------------------------------------------------------------------------------------------
2021-07-23 16:11:41,450 EPOCH 33 done: loss 0.0454 - lr 0.0000038
2021-07-23 16:11:47,109 DEV : loss 0.0447731614112854 - score 0.9872
2021-07-23 16:11:47,175 BAD EPOCHS (no improvement): 3
2021-07-23 16:11:47,175 ----------------------------------------------------------------------------------------------------
2021-07-23 16:11:59,039 epoch 34 - iter 50/507 - loss 0.05125089 - samples/sec: 134.91 - lr: 0.000004
2021-07-23 16:12:11,004 epoch 34 - iter 100/507 - loss 0.04391822 - samples/sec: 133.75 - lr: 0.000004
2021-07-23 16:12:22,896 epoch 34 - iter 150/507 - loss 0.04370626 - samples/sec: 134.57 - lr: 0.000004
2021-07-23 16:12:35,086 epoch 34 - iter 200/507 - loss 0.04607994 - samples/sec: 131.28 - lr: 0.000004
2021-07-23 16:12:46,968 epoch 34 - iter 250/507 - loss 0.04623816 - samples/sec: 134.68 - lr: 0.000004
2021-07-23 16:12:58,637 epoch 34 - iter 300/507 - loss 0.04944023 - samples/sec: 137.15 - lr: 0.000004
2021-07-23 16:13:10,431 epoch 34 - iter 350/507 - loss 0.04939727 - samples/sec: 135.69 - lr: 0.000004
2021-07-23 16:13:22,372 epoch 34 - iter 400/507 - loss 0.04894926 - samples/sec: 134.01 - lr: 0.000004
2021-07-23 16:13:34,137 epoch 34 - iter 450/507 - loss 0.04974860 - samples/sec: 136.03 - lr: 0.000004
2021-07-23 16:13:45,896 epoch 34 - iter 500/507 - loss 0.04965495 - samples/sec: 136.10 - lr: 0.000004
2021-07-23 16:13:47,391 ----------------------------------------------------------------------------------------------------
2021-07-23 16:13:47,391 EPOCH 34 done: loss 0.0498 - lr 0.0000038
2021-07-23 16:13:53,613 DEV : loss 0.044245924800634384 - score 0.9879
Epoch    34: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 16:13:53,678 BAD EPOCHS (no improvement): 4
2021-07-23 16:13:53,678 ----------------------------------------------------------------------------------------------------
2021-07-23 16:13:53,678 ----------------------------------------------------------------------------------------------------
2021-07-23 16:13:53,678 learning rate too small - quitting training!
2021-07-23 16:13:53,678 ----------------------------------------------------------------------------------------------------
2021-07-23 16:13:54,333 ----------------------------------------------------------------------------------------------------
2021-07-23 16:13:54,333 Testing using best model ...
2021-07-23 16:13:54,334 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.rstdt/best-model.pt
2021-07-23 16:15:12,263 0.9816	0.9940	0.9878
2021-07-23 16:15:12,263 
Results:
- F1-score (micro) 0.9878
- F1-score (macro) 0.9865

By class:
SENT       tp: 1788 - fp: 75 - fn: 24 - precision: 0.9597 - recall: 0.9868 - f1-score: 0.9731
X          tp: 2210 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 16:15:12,263 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/tur.pdtb.tdb/
2021-07-23 16:15:12,287 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/tur.pdtb.tdb
2021-07-23 16:15:12,289 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/tur.pdtb.tdb/sent_train.txt
2021-07-23 16:15:12,290 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/tur.pdtb.tdb/sent_dev.txt
2021-07-23 16:15:12,291 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/tur.pdtb.tdb/sent_test.txt
Corpus: 45427 train + 7479 dev + 15547 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 16:15:24,426 ----------------------------------------------------------------------------------------------------
2021-07-23 16:15:24,427 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(32000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 16:15:24,428 ----------------------------------------------------------------------------------------------------
2021-07-23 16:15:24,428 Corpus: "Corpus: 45427 train + 7479 dev + 15547 test sentences"
2021-07-23 16:15:24,428 ----------------------------------------------------------------------------------------------------
2021-07-23 16:15:24,428 Parameters:
2021-07-23 16:15:24,428  - learning_rate: "3e-05"
2021-07-23 16:15:24,428  - mini_batch_size: "32"
2021-07-23 16:15:24,428  - patience: "3"
2021-07-23 16:15:24,428  - anneal_factor: "0.5"
2021-07-23 16:15:24,428  - max_epochs: "40"
2021-07-23 16:15:24,428  - shuffle: "True"
2021-07-23 16:15:24,428  - train_with_dev: "False"
2021-07-23 16:15:24,428  - batch_growth_annealing: "False"
2021-07-23 16:15:24,428 ----------------------------------------------------------------------------------------------------
2021-07-23 16:15:24,428 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/tur.pdtb.tdb"
2021-07-23 16:15:24,428 ----------------------------------------------------------------------------------------------------
2021-07-23 16:15:24,428 Device: cuda:0
2021-07-23 16:15:24,428 ----------------------------------------------------------------------------------------------------
2021-07-23 16:15:24,428 Embeddings storage mode: cpu
2021-07-23 16:15:24,431 ----------------------------------------------------------------------------------------------------
2021-07-23 16:16:42,328 epoch 1 - iter 142/1420 - loss 7.48219486 - samples/sec: 58.34 - lr: 0.000030
2021-07-23 16:18:02,240 epoch 1 - iter 284/1420 - loss 4.12372055 - samples/sec: 56.87 - lr: 0.000030
2021-07-23 16:19:25,476 epoch 1 - iter 426/1420 - loss 2.90183686 - samples/sec: 54.60 - lr: 0.000030
2021-07-23 16:20:47,810 epoch 1 - iter 568/1420 - loss 2.24957410 - samples/sec: 55.19 - lr: 0.000030
2021-07-23 16:22:12,600 epoch 1 - iter 710/1420 - loss 1.84461117 - samples/sec: 53.59 - lr: 0.000030
2021-07-23 16:23:32,650 epoch 1 - iter 852/1420 - loss 1.56615288 - samples/sec: 56.77 - lr: 0.000030
2021-07-23 16:24:52,615 epoch 1 - iter 994/1420 - loss 1.36959199 - samples/sec: 56.83 - lr: 0.000030
2021-07-23 16:26:15,574 epoch 1 - iter 1136/1420 - loss 1.22464692 - samples/sec: 54.78 - lr: 0.000030
2021-07-23 16:27:37,397 epoch 1 - iter 1278/1420 - loss 1.11495538 - samples/sec: 55.54 - lr: 0.000030
2021-07-23 16:28:58,141 epoch 1 - iter 1420/1420 - loss 1.02495373 - samples/sec: 56.28 - lr: 0.000030
2021-07-23 16:28:58,142 ----------------------------------------------------------------------------------------------------
2021-07-23 16:28:58,142 EPOCH 1 done: loss 1.0250 - lr 0.0000300
2021-07-23 16:30:33,397 DEV : loss 0.1741722971200943 - score 0.9594
2021-07-23 16:30:33,578 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:30:34,194 ----------------------------------------------------------------------------------------------------
2021-07-23 16:31:05,506 epoch 2 - iter 142/1420 - loss 0.17842956 - samples/sec: 145.17 - lr: 0.000030
2021-07-23 16:31:36,895 epoch 2 - iter 284/1420 - loss 0.17705124 - samples/sec: 144.80 - lr: 0.000030
2021-07-23 16:32:08,419 epoch 2 - iter 426/1420 - loss 0.17244510 - samples/sec: 144.17 - lr: 0.000030
2021-07-23 16:32:40,432 epoch 2 - iter 568/1420 - loss 0.17270345 - samples/sec: 141.97 - lr: 0.000030
2021-07-23 16:33:12,183 epoch 2 - iter 710/1420 - loss 0.17279045 - samples/sec: 143.15 - lr: 0.000030
2021-07-23 16:33:43,964 epoch 2 - iter 852/1420 - loss 0.17212598 - samples/sec: 143.01 - lr: 0.000030
2021-07-23 16:34:15,770 epoch 2 - iter 994/1420 - loss 0.17127213 - samples/sec: 142.90 - lr: 0.000030
2021-07-23 16:34:47,695 epoch 2 - iter 1136/1420 - loss 0.17118428 - samples/sec: 142.36 - lr: 0.000030
2021-07-23 16:35:19,230 epoch 2 - iter 1278/1420 - loss 0.17034364 - samples/sec: 144.12 - lr: 0.000030
2021-07-23 16:35:50,667 epoch 2 - iter 1420/1420 - loss 0.17023725 - samples/sec: 144.58 - lr: 0.000030
2021-07-23 16:35:50,668 ----------------------------------------------------------------------------------------------------
2021-07-23 16:35:50,668 EPOCH 2 done: loss 0.1702 - lr 0.0000300
2021-07-23 16:36:07,885 DEV : loss 0.1688290536403656 - score 0.9604
2021-07-23 16:36:08,067 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:36:10,319 ----------------------------------------------------------------------------------------------------
2021-07-23 16:36:41,929 epoch 3 - iter 142/1420 - loss 0.15765694 - samples/sec: 143.81 - lr: 0.000030
2021-07-23 16:37:14,083 epoch 3 - iter 284/1420 - loss 0.16475080 - samples/sec: 141.35 - lr: 0.000030
2021-07-23 16:37:45,830 epoch 3 - iter 426/1420 - loss 0.16896202 - samples/sec: 143.16 - lr: 0.000030
2021-07-23 16:38:17,675 epoch 3 - iter 568/1420 - loss 0.16637065 - samples/sec: 142.72 - lr: 0.000030
2021-07-23 16:38:49,680 epoch 3 - iter 710/1420 - loss 0.16485165 - samples/sec: 142.01 - lr: 0.000030
2021-07-23 16:39:21,638 epoch 3 - iter 852/1420 - loss 0.16421084 - samples/sec: 142.22 - lr: 0.000030
2021-07-23 16:39:53,299 epoch 3 - iter 994/1420 - loss 0.16329251 - samples/sec: 143.55 - lr: 0.000030
2021-07-23 16:40:24,900 epoch 3 - iter 1136/1420 - loss 0.16251685 - samples/sec: 143.82 - lr: 0.000030
2021-07-23 16:40:56,787 epoch 3 - iter 1278/1420 - loss 0.16242193 - samples/sec: 142.54 - lr: 0.000030
2021-07-23 16:41:28,639 epoch 3 - iter 1420/1420 - loss 0.16084314 - samples/sec: 142.69 - lr: 0.000030
2021-07-23 16:41:28,640 ----------------------------------------------------------------------------------------------------
2021-07-23 16:41:28,640 EPOCH 3 done: loss 0.1608 - lr 0.0000300
2021-07-23 16:41:47,231 DEV : loss 0.15861445665359497 - score 0.9617
2021-07-23 16:41:47,416 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:41:49,662 ----------------------------------------------------------------------------------------------------
2021-07-23 16:42:21,695 epoch 4 - iter 142/1420 - loss 0.14542020 - samples/sec: 141.91 - lr: 0.000030
2021-07-23 16:42:53,746 epoch 4 - iter 284/1420 - loss 0.14951106 - samples/sec: 141.81 - lr: 0.000030
2021-07-23 16:43:25,811 epoch 4 - iter 426/1420 - loss 0.14972789 - samples/sec: 141.75 - lr: 0.000030
2021-07-23 16:43:57,848 epoch 4 - iter 568/1420 - loss 0.15101881 - samples/sec: 141.87 - lr: 0.000030
2021-07-23 16:44:29,588 epoch 4 - iter 710/1420 - loss 0.14846216 - samples/sec: 143.20 - lr: 0.000030
2021-07-23 16:45:01,499 epoch 4 - iter 852/1420 - loss 0.14828100 - samples/sec: 142.43 - lr: 0.000030
2021-07-23 16:45:33,683 epoch 4 - iter 994/1420 - loss 0.14802529 - samples/sec: 141.22 - lr: 0.000030
2021-07-23 16:46:05,459 epoch 4 - iter 1136/1420 - loss 0.14685175 - samples/sec: 143.03 - lr: 0.000030
2021-07-23 16:46:37,528 epoch 4 - iter 1278/1420 - loss 0.14686297 - samples/sec: 141.73 - lr: 0.000030
2021-07-23 16:47:09,656 epoch 4 - iter 1420/1420 - loss 0.14687512 - samples/sec: 141.47 - lr: 0.000030
2021-07-23 16:47:09,657 ----------------------------------------------------------------------------------------------------
2021-07-23 16:47:09,657 EPOCH 4 done: loss 0.1469 - lr 0.0000300
2021-07-23 16:47:26,969 DEV : loss 0.1535497009754181 - score 0.9627
2021-07-23 16:47:27,155 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:47:29,458 ----------------------------------------------------------------------------------------------------
2021-07-23 16:48:01,534 epoch 5 - iter 142/1420 - loss 0.14590424 - samples/sec: 141.72 - lr: 0.000030
2021-07-23 16:48:33,971 epoch 5 - iter 284/1420 - loss 0.14089352 - samples/sec: 140.12 - lr: 0.000030
2021-07-23 16:49:06,187 epoch 5 - iter 426/1420 - loss 0.13839329 - samples/sec: 141.08 - lr: 0.000030
2021-07-23 16:49:38,328 epoch 5 - iter 568/1420 - loss 0.13809136 - samples/sec: 141.41 - lr: 0.000030
2021-07-23 16:50:10,608 epoch 5 - iter 710/1420 - loss 0.13873578 - samples/sec: 140.80 - lr: 0.000030
2021-07-23 16:50:42,747 epoch 5 - iter 852/1420 - loss 0.14060337 - samples/sec: 141.42 - lr: 0.000030
2021-07-23 16:51:14,964 epoch 5 - iter 994/1420 - loss 0.13913450 - samples/sec: 141.07 - lr: 0.000030
2021-07-23 16:51:47,158 epoch 5 - iter 1136/1420 - loss 0.13934478 - samples/sec: 141.18 - lr: 0.000030
2021-07-23 16:52:19,364 epoch 5 - iter 1278/1420 - loss 0.13847154 - samples/sec: 141.12 - lr: 0.000030
2021-07-23 16:52:51,283 epoch 5 - iter 1420/1420 - loss 0.13815701 - samples/sec: 142.40 - lr: 0.000030
2021-07-23 16:52:51,284 ----------------------------------------------------------------------------------------------------
2021-07-23 16:52:51,284 EPOCH 5 done: loss 0.1382 - lr 0.0000300
2021-07-23 16:53:08,683 DEV : loss 0.14868488907814026 - score 0.9629
2021-07-23 16:53:08,869 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:53:11,185 ----------------------------------------------------------------------------------------------------
2021-07-23 16:53:43,775 epoch 6 - iter 142/1420 - loss 0.12768481 - samples/sec: 139.48 - lr: 0.000030
2021-07-23 16:54:15,567 epoch 6 - iter 284/1420 - loss 0.12610975 - samples/sec: 142.96 - lr: 0.000030
2021-07-23 16:54:47,756 epoch 6 - iter 426/1420 - loss 0.12545343 - samples/sec: 141.20 - lr: 0.000030
2021-07-23 16:55:19,976 epoch 6 - iter 568/1420 - loss 0.12510899 - samples/sec: 141.06 - lr: 0.000030
2021-07-23 16:55:52,249 epoch 6 - iter 710/1420 - loss 0.12618646 - samples/sec: 140.83 - lr: 0.000030
2021-07-23 16:56:24,139 epoch 6 - iter 852/1420 - loss 0.12764830 - samples/sec: 142.52 - lr: 0.000030
2021-07-23 16:56:56,375 epoch 6 - iter 994/1420 - loss 0.12799663 - samples/sec: 140.99 - lr: 0.000030
2021-07-23 16:57:28,663 epoch 6 - iter 1136/1420 - loss 0.12759843 - samples/sec: 140.76 - lr: 0.000030
2021-07-23 16:58:00,984 epoch 6 - iter 1278/1420 - loss 0.12910263 - samples/sec: 140.62 - lr: 0.000030
2021-07-23 16:58:32,886 epoch 6 - iter 1420/1420 - loss 0.12950107 - samples/sec: 142.47 - lr: 0.000030
2021-07-23 16:58:32,887 ----------------------------------------------------------------------------------------------------
2021-07-23 16:58:32,887 EPOCH 6 done: loss 0.1295 - lr 0.0000300
2021-07-23 16:58:50,318 DEV : loss 0.14531147480010986 - score 0.9641
2021-07-23 16:58:50,504 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 16:58:52,804 ----------------------------------------------------------------------------------------------------
2021-07-23 16:59:24,895 epoch 7 - iter 142/1420 - loss 0.13457315 - samples/sec: 141.65 - lr: 0.000030
2021-07-23 16:59:57,132 epoch 7 - iter 284/1420 - loss 0.13412571 - samples/sec: 140.99 - lr: 0.000030
2021-07-23 17:00:29,094 epoch 7 - iter 426/1420 - loss 0.13028557 - samples/sec: 142.20 - lr: 0.000030
2021-07-23 17:01:01,207 epoch 7 - iter 568/1420 - loss 0.12705459 - samples/sec: 141.54 - lr: 0.000030
2021-07-23 17:01:33,507 epoch 7 - iter 710/1420 - loss 0.12667888 - samples/sec: 140.71 - lr: 0.000030
2021-07-23 17:02:05,471 epoch 7 - iter 852/1420 - loss 0.12578507 - samples/sec: 142.19 - lr: 0.000030
2021-07-23 17:02:37,981 epoch 7 - iter 994/1420 - loss 0.12715627 - samples/sec: 139.80 - lr: 0.000030
2021-07-23 17:03:09,980 epoch 7 - iter 1136/1420 - loss 0.12676303 - samples/sec: 142.04 - lr: 0.000030
2021-07-23 17:03:42,404 epoch 7 - iter 1278/1420 - loss 0.12675175 - samples/sec: 140.17 - lr: 0.000030
2021-07-23 17:04:14,431 epoch 7 - iter 1420/1420 - loss 0.12739773 - samples/sec: 141.91 - lr: 0.000030
2021-07-23 17:04:14,432 ----------------------------------------------------------------------------------------------------
2021-07-23 17:04:14,432 EPOCH 7 done: loss 0.1274 - lr 0.0000300
2021-07-23 17:04:33,238 DEV : loss 0.14441707730293274 - score 0.9645
2021-07-23 17:04:33,425 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:04:35,770 ----------------------------------------------------------------------------------------------------
2021-07-23 17:05:08,119 epoch 8 - iter 142/1420 - loss 0.12191239 - samples/sec: 140.52 - lr: 0.000030
2021-07-23 17:05:40,283 epoch 8 - iter 284/1420 - loss 0.12051214 - samples/sec: 141.31 - lr: 0.000030
2021-07-23 17:06:12,371 epoch 8 - iter 426/1420 - loss 0.12084320 - samples/sec: 141.64 - lr: 0.000030
2021-07-23 17:06:44,263 epoch 8 - iter 568/1420 - loss 0.12151816 - samples/sec: 142.51 - lr: 0.000030
2021-07-23 17:07:16,396 epoch 8 - iter 710/1420 - loss 0.12354789 - samples/sec: 141.45 - lr: 0.000030
2021-07-23 17:07:48,497 epoch 8 - iter 852/1420 - loss 0.12484718 - samples/sec: 141.58 - lr: 0.000030
2021-07-23 17:08:20,479 epoch 8 - iter 994/1420 - loss 0.12417135 - samples/sec: 142.11 - lr: 0.000030
2021-07-23 17:08:52,782 epoch 8 - iter 1136/1420 - loss 0.12391387 - samples/sec: 140.70 - lr: 0.000030
2021-07-23 17:09:25,031 epoch 8 - iter 1278/1420 - loss 0.12329668 - samples/sec: 140.94 - lr: 0.000030
2021-07-23 17:09:57,243 epoch 8 - iter 1420/1420 - loss 0.12247631 - samples/sec: 141.10 - lr: 0.000030
2021-07-23 17:09:57,244 ----------------------------------------------------------------------------------------------------
2021-07-23 17:09:57,244 EPOCH 8 done: loss 0.1225 - lr 0.0000300
2021-07-23 17:10:14,594 DEV : loss 0.1419142335653305 - score 0.9655
2021-07-23 17:10:14,782 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:10:17,057 ----------------------------------------------------------------------------------------------------
2021-07-23 17:10:49,759 epoch 9 - iter 142/1420 - loss 0.11595281 - samples/sec: 139.00 - lr: 0.000030
2021-07-23 17:11:22,183 epoch 9 - iter 284/1420 - loss 0.11636532 - samples/sec: 140.17 - lr: 0.000030
2021-07-23 17:11:54,581 epoch 9 - iter 426/1420 - loss 0.11829354 - samples/sec: 140.29 - lr: 0.000030
2021-07-23 17:12:26,492 epoch 9 - iter 568/1420 - loss 0.11845051 - samples/sec: 142.43 - lr: 0.000030
2021-07-23 17:12:58,797 epoch 9 - iter 710/1420 - loss 0.11956935 - samples/sec: 140.69 - lr: 0.000030
2021-07-23 17:13:30,636 epoch 9 - iter 852/1420 - loss 0.11976983 - samples/sec: 142.75 - lr: 0.000030
2021-07-23 17:14:02,635 epoch 9 - iter 994/1420 - loss 0.11877254 - samples/sec: 142.03 - lr: 0.000030
2021-07-23 17:14:34,213 epoch 9 - iter 1136/1420 - loss 0.11884474 - samples/sec: 143.93 - lr: 0.000030
2021-07-23 17:15:05,974 epoch 9 - iter 1278/1420 - loss 0.11861446 - samples/sec: 143.10 - lr: 0.000030
2021-07-23 17:15:37,953 epoch 9 - iter 1420/1420 - loss 0.11787395 - samples/sec: 142.12 - lr: 0.000030
2021-07-23 17:15:37,954 ----------------------------------------------------------------------------------------------------
2021-07-23 17:15:37,954 EPOCH 9 done: loss 0.1179 - lr 0.0000300
2021-07-23 17:15:55,316 DEV : loss 0.1430506855249405 - score 0.966
2021-07-23 17:15:55,502 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:15:57,747 ----------------------------------------------------------------------------------------------------
2021-07-23 17:16:30,496 epoch 10 - iter 142/1420 - loss 0.11280156 - samples/sec: 138.80 - lr: 0.000030
2021-07-23 17:17:02,706 epoch 10 - iter 284/1420 - loss 0.12157330 - samples/sec: 141.11 - lr: 0.000030
2021-07-23 17:17:34,539 epoch 10 - iter 426/1420 - loss 0.11887100 - samples/sec: 142.78 - lr: 0.000030
2021-07-23 17:18:06,416 epoch 10 - iter 568/1420 - loss 0.11515053 - samples/sec: 142.58 - lr: 0.000030
2021-07-23 17:18:38,388 epoch 10 - iter 710/1420 - loss 0.11527765 - samples/sec: 142.16 - lr: 0.000030
2021-07-23 17:19:10,152 epoch 10 - iter 852/1420 - loss 0.11571611 - samples/sec: 143.09 - lr: 0.000030
2021-07-23 17:19:41,862 epoch 10 - iter 994/1420 - loss 0.11533189 - samples/sec: 143.33 - lr: 0.000030
2021-07-23 17:20:13,574 epoch 10 - iter 1136/1420 - loss 0.11486184 - samples/sec: 143.32 - lr: 0.000030
2021-07-23 17:20:45,896 epoch 10 - iter 1278/1420 - loss 0.11348330 - samples/sec: 140.62 - lr: 0.000030
2021-07-23 17:21:17,917 epoch 10 - iter 1420/1420 - loss 0.11340046 - samples/sec: 141.94 - lr: 0.000030
2021-07-23 17:21:17,919 ----------------------------------------------------------------------------------------------------
2021-07-23 17:21:17,919 EPOCH 10 done: loss 0.1134 - lr 0.0000300
2021-07-23 17:21:35,274 DEV : loss 0.1483338475227356 - score 0.9654
2021-07-23 17:21:35,460 BAD EPOCHS (no improvement): 1
2021-07-23 17:21:35,460 ----------------------------------------------------------------------------------------------------
2021-07-23 17:22:07,696 epoch 11 - iter 142/1420 - loss 0.10220018 - samples/sec: 141.00 - lr: 0.000030
2021-07-23 17:22:39,967 epoch 11 - iter 284/1420 - loss 0.10874630 - samples/sec: 140.84 - lr: 0.000030
2021-07-23 17:23:11,387 epoch 11 - iter 426/1420 - loss 0.11159911 - samples/sec: 144.65 - lr: 0.000030
2021-07-23 17:23:43,202 epoch 11 - iter 568/1420 - loss 0.11111084 - samples/sec: 142.86 - lr: 0.000030
2021-07-23 17:24:15,243 epoch 11 - iter 710/1420 - loss 0.11124045 - samples/sec: 141.85 - lr: 0.000030
2021-07-23 17:24:47,579 epoch 11 - iter 852/1420 - loss 0.11258754 - samples/sec: 140.55 - lr: 0.000030
2021-07-23 17:25:19,883 epoch 11 - iter 994/1420 - loss 0.11296138 - samples/sec: 140.69 - lr: 0.000030
2021-07-23 17:25:52,207 epoch 11 - iter 1136/1420 - loss 0.11250932 - samples/sec: 140.61 - lr: 0.000030
2021-07-23 17:26:24,615 epoch 11 - iter 1278/1420 - loss 0.11354515 - samples/sec: 140.24 - lr: 0.000030
2021-07-23 17:26:56,533 epoch 11 - iter 1420/1420 - loss 0.11157239 - samples/sec: 142.40 - lr: 0.000030
2021-07-23 17:26:56,534 ----------------------------------------------------------------------------------------------------
2021-07-23 17:26:56,534 EPOCH 11 done: loss 0.1116 - lr 0.0000300
2021-07-23 17:27:13,839 DEV : loss 0.13671882450580597 - score 0.9662
2021-07-23 17:27:14,027 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:27:16,381 ----------------------------------------------------------------------------------------------------
2021-07-23 17:27:49,792 epoch 12 - iter 142/1420 - loss 0.10288641 - samples/sec: 136.05 - lr: 0.000030
2021-07-23 17:28:22,337 epoch 12 - iter 284/1420 - loss 0.10470318 - samples/sec: 139.66 - lr: 0.000030
2021-07-23 17:28:54,175 epoch 12 - iter 426/1420 - loss 0.10481566 - samples/sec: 142.75 - lr: 0.000030
2021-07-23 17:29:25,761 epoch 12 - iter 568/1420 - loss 0.10788801 - samples/sec: 143.89 - lr: 0.000030
2021-07-23 17:29:57,962 epoch 12 - iter 710/1420 - loss 0.10952101 - samples/sec: 141.14 - lr: 0.000030
2021-07-23 17:30:30,290 epoch 12 - iter 852/1420 - loss 0.10935051 - samples/sec: 140.59 - lr: 0.000030
2021-07-23 17:31:02,543 epoch 12 - iter 994/1420 - loss 0.10883763 - samples/sec: 140.92 - lr: 0.000030
2021-07-23 17:31:34,306 epoch 12 - iter 1136/1420 - loss 0.10894730 - samples/sec: 143.09 - lr: 0.000030
2021-07-23 17:32:06,259 epoch 12 - iter 1278/1420 - loss 0.10855075 - samples/sec: 142.24 - lr: 0.000030
2021-07-23 17:32:38,073 epoch 12 - iter 1420/1420 - loss 0.11044519 - samples/sec: 142.87 - lr: 0.000030
2021-07-23 17:32:38,074 ----------------------------------------------------------------------------------------------------
2021-07-23 17:32:38,074 EPOCH 12 done: loss 0.1104 - lr 0.0000300
2021-07-23 17:32:55,349 DEV : loss 0.12798525393009186 - score 0.9676
2021-07-23 17:32:55,534 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:32:57,771 ----------------------------------------------------------------------------------------------------
2021-07-23 17:33:29,472 epoch 13 - iter 142/1420 - loss 0.10134149 - samples/sec: 143.40 - lr: 0.000030
2021-07-23 17:34:01,256 epoch 13 - iter 284/1420 - loss 0.10299371 - samples/sec: 143.00 - lr: 0.000030
2021-07-23 17:34:32,836 epoch 13 - iter 426/1420 - loss 0.10547736 - samples/sec: 143.92 - lr: 0.000030
2021-07-23 17:35:04,876 epoch 13 - iter 568/1420 - loss 0.10654744 - samples/sec: 141.86 - lr: 0.000030
2021-07-23 17:35:37,216 epoch 13 - iter 710/1420 - loss 0.10621877 - samples/sec: 140.54 - lr: 0.000030
2021-07-23 17:36:09,308 epoch 13 - iter 852/1420 - loss 0.10671886 - samples/sec: 141.63 - lr: 0.000030
2021-07-23 17:36:41,670 epoch 13 - iter 994/1420 - loss 0.10643875 - samples/sec: 140.44 - lr: 0.000030
2021-07-23 17:37:13,618 epoch 13 - iter 1136/1420 - loss 0.10694149 - samples/sec: 142.27 - lr: 0.000030
2021-07-23 17:37:45,565 epoch 13 - iter 1278/1420 - loss 0.10713080 - samples/sec: 142.27 - lr: 0.000030
2021-07-23 17:38:17,790 epoch 13 - iter 1420/1420 - loss 0.10621675 - samples/sec: 141.04 - lr: 0.000030
2021-07-23 17:38:17,791 ----------------------------------------------------------------------------------------------------
2021-07-23 17:38:17,791 EPOCH 13 done: loss 0.1062 - lr 0.0000300
2021-07-23 17:38:35,085 DEV : loss 0.13576579093933105 - score 0.9671
2021-07-23 17:38:35,272 BAD EPOCHS (no improvement): 1
2021-07-23 17:38:35,273 ----------------------------------------------------------------------------------------------------
2021-07-23 17:39:07,004 epoch 14 - iter 142/1420 - loss 0.09991486 - samples/sec: 143.25 - lr: 0.000030
2021-07-23 17:39:38,828 epoch 14 - iter 284/1420 - loss 0.09926249 - samples/sec: 142.82 - lr: 0.000030
2021-07-23 17:40:10,797 epoch 14 - iter 426/1420 - loss 0.10424652 - samples/sec: 142.17 - lr: 0.000030
2021-07-23 17:40:43,111 epoch 14 - iter 568/1420 - loss 0.10413664 - samples/sec: 140.65 - lr: 0.000030
2021-07-23 17:41:15,253 epoch 14 - iter 710/1420 - loss 0.10421609 - samples/sec: 141.41 - lr: 0.000030
2021-07-23 17:41:47,340 epoch 14 - iter 852/1420 - loss 0.10314633 - samples/sec: 141.64 - lr: 0.000030
2021-07-23 17:42:19,138 epoch 14 - iter 994/1420 - loss 0.10213209 - samples/sec: 142.93 - lr: 0.000030
2021-07-23 17:42:51,464 epoch 14 - iter 1136/1420 - loss 0.10337472 - samples/sec: 140.60 - lr: 0.000030
2021-07-23 17:43:23,650 epoch 14 - iter 1278/1420 - loss 0.10401477 - samples/sec: 141.21 - lr: 0.000030
2021-07-23 17:43:55,670 epoch 14 - iter 1420/1420 - loss 0.10413018 - samples/sec: 141.94 - lr: 0.000030
2021-07-23 17:43:55,671 ----------------------------------------------------------------------------------------------------
2021-07-23 17:43:55,671 EPOCH 14 done: loss 0.1041 - lr 0.0000300
2021-07-23 17:44:12,969 DEV : loss 0.12935777008533478 - score 0.9682
2021-07-23 17:44:13,158 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:44:15,360 ----------------------------------------------------------------------------------------------------
2021-07-23 17:44:47,580 epoch 15 - iter 142/1420 - loss 0.10801938 - samples/sec: 141.09 - lr: 0.000030
2021-07-23 17:45:19,619 epoch 15 - iter 284/1420 - loss 0.10441798 - samples/sec: 141.86 - lr: 0.000030
2021-07-23 17:45:51,684 epoch 15 - iter 426/1420 - loss 0.10595066 - samples/sec: 141.74 - lr: 0.000030
2021-07-23 17:46:24,134 epoch 15 - iter 568/1420 - loss 0.10689025 - samples/sec: 140.06 - lr: 0.000030
2021-07-23 17:46:56,416 epoch 15 - iter 710/1420 - loss 0.10695121 - samples/sec: 140.79 - lr: 0.000030
2021-07-23 17:47:28,597 epoch 15 - iter 852/1420 - loss 0.10607688 - samples/sec: 141.23 - lr: 0.000030
2021-07-23 17:48:00,659 epoch 15 - iter 994/1420 - loss 0.10536453 - samples/sec: 141.76 - lr: 0.000030
2021-07-23 17:48:32,544 epoch 15 - iter 1136/1420 - loss 0.10686044 - samples/sec: 142.54 - lr: 0.000030
2021-07-23 17:49:04,603 epoch 15 - iter 1278/1420 - loss 0.10631325 - samples/sec: 141.77 - lr: 0.000030
2021-07-23 17:49:36,607 epoch 15 - iter 1420/1420 - loss 0.10601680 - samples/sec: 142.02 - lr: 0.000030
2021-07-23 17:49:36,608 ----------------------------------------------------------------------------------------------------
2021-07-23 17:49:36,608 EPOCH 15 done: loss 0.1060 - lr 0.0000300
2021-07-23 17:49:54,012 DEV : loss 0.13299599289894104 - score 0.9674
2021-07-23 17:49:54,195 BAD EPOCHS (no improvement): 1
2021-07-23 17:49:54,195 ----------------------------------------------------------------------------------------------------
2021-07-23 17:50:26,026 epoch 16 - iter 142/1420 - loss 0.11558563 - samples/sec: 142.80 - lr: 0.000030
2021-07-23 17:50:57,623 epoch 16 - iter 284/1420 - loss 0.10298798 - samples/sec: 143.84 - lr: 0.000030
2021-07-23 17:51:29,422 epoch 16 - iter 426/1420 - loss 0.09880886 - samples/sec: 142.93 - lr: 0.000030
2021-07-23 17:52:01,472 epoch 16 - iter 568/1420 - loss 0.09984769 - samples/sec: 141.81 - lr: 0.000030
2021-07-23 17:52:33,647 epoch 16 - iter 710/1420 - loss 0.10092296 - samples/sec: 141.26 - lr: 0.000030
2021-07-23 17:53:05,695 epoch 16 - iter 852/1420 - loss 0.10108959 - samples/sec: 141.82 - lr: 0.000030
2021-07-23 17:53:37,983 epoch 16 - iter 994/1420 - loss 0.10057464 - samples/sec: 140.76 - lr: 0.000030
2021-07-23 17:54:10,180 epoch 16 - iter 1136/1420 - loss 0.10117934 - samples/sec: 141.16 - lr: 0.000030
2021-07-23 17:54:42,466 epoch 16 - iter 1278/1420 - loss 0.10262461 - samples/sec: 140.77 - lr: 0.000030
2021-07-23 17:55:14,699 epoch 16 - iter 1420/1420 - loss 0.10291942 - samples/sec: 141.01 - lr: 0.000030
2021-07-23 17:55:14,700 ----------------------------------------------------------------------------------------------------
2021-07-23 17:55:14,700 EPOCH 16 done: loss 0.1029 - lr 0.0000300
2021-07-23 17:55:33,428 DEV : loss 0.12997666001319885 - score 0.9689
2021-07-23 17:55:33,617 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 17:55:35,860 ----------------------------------------------------------------------------------------------------
2021-07-23 17:56:08,076 epoch 17 - iter 142/1420 - loss 0.10341827 - samples/sec: 141.10 - lr: 0.000030
2021-07-23 17:56:39,983 epoch 17 - iter 284/1420 - loss 0.09895634 - samples/sec: 142.45 - lr: 0.000030
2021-07-23 17:57:12,104 epoch 17 - iter 426/1420 - loss 0.09664751 - samples/sec: 141.50 - lr: 0.000030
2021-07-23 17:57:44,645 epoch 17 - iter 568/1420 - loss 0.09980272 - samples/sec: 139.67 - lr: 0.000030
2021-07-23 17:58:16,156 epoch 17 - iter 710/1420 - loss 0.10081106 - samples/sec: 144.24 - lr: 0.000030
2021-07-23 17:58:47,756 epoch 17 - iter 852/1420 - loss 0.10140218 - samples/sec: 143.83 - lr: 0.000030
2021-07-23 17:59:19,544 epoch 17 - iter 994/1420 - loss 0.10104227 - samples/sec: 142.98 - lr: 0.000030
2021-07-23 17:59:51,522 epoch 17 - iter 1136/1420 - loss 0.09976604 - samples/sec: 142.13 - lr: 0.000030
2021-07-23 18:00:23,475 epoch 17 - iter 1278/1420 - loss 0.09918411 - samples/sec: 142.24 - lr: 0.000030
2021-07-23 18:00:55,375 epoch 17 - iter 1420/1420 - loss 0.09923639 - samples/sec: 142.48 - lr: 0.000030
2021-07-23 18:00:55,376 ----------------------------------------------------------------------------------------------------
2021-07-23 18:00:55,376 EPOCH 17 done: loss 0.0992 - lr 0.0000300
2021-07-23 18:01:12,660 DEV : loss 0.12886902689933777 - score 0.9696
2021-07-23 18:01:12,848 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:01:15,138 ----------------------------------------------------------------------------------------------------
2021-07-23 18:01:47,010 epoch 18 - iter 142/1420 - loss 0.09662865 - samples/sec: 142.62 - lr: 0.000030
2021-07-23 18:02:19,383 epoch 18 - iter 284/1420 - loss 0.09749495 - samples/sec: 140.40 - lr: 0.000030
2021-07-23 18:02:51,471 epoch 18 - iter 426/1420 - loss 0.09973353 - samples/sec: 141.64 - lr: 0.000030
2021-07-23 18:03:23,570 epoch 18 - iter 568/1420 - loss 0.09903894 - samples/sec: 141.59 - lr: 0.000030
2021-07-23 18:03:55,468 epoch 18 - iter 710/1420 - loss 0.10035760 - samples/sec: 142.48 - lr: 0.000030
2021-07-23 18:04:27,119 epoch 18 - iter 852/1420 - loss 0.09863643 - samples/sec: 143.60 - lr: 0.000030
2021-07-23 18:04:58,544 epoch 18 - iter 994/1420 - loss 0.09765422 - samples/sec: 144.63 - lr: 0.000030
2021-07-23 18:05:30,750 epoch 18 - iter 1136/1420 - loss 0.09641150 - samples/sec: 141.12 - lr: 0.000030
2021-07-23 18:06:03,135 epoch 18 - iter 1278/1420 - loss 0.09609488 - samples/sec: 140.34 - lr: 0.000030
2021-07-23 18:06:34,818 epoch 18 - iter 1420/1420 - loss 0.09629395 - samples/sec: 143.46 - lr: 0.000030
2021-07-23 18:06:34,819 ----------------------------------------------------------------------------------------------------
2021-07-23 18:06:34,819 EPOCH 18 done: loss 0.0963 - lr 0.0000300
2021-07-23 18:06:52,122 DEV : loss 0.12930068373680115 - score 0.9701
2021-07-23 18:06:52,310 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:06:54,635 ----------------------------------------------------------------------------------------------------
2021-07-23 18:07:26,605 epoch 19 - iter 142/1420 - loss 0.09389336 - samples/sec: 142.19 - lr: 0.000030
2021-07-23 18:07:58,460 epoch 19 - iter 284/1420 - loss 0.09131608 - samples/sec: 142.68 - lr: 0.000030
2021-07-23 18:08:29,979 epoch 19 - iter 426/1420 - loss 0.09333711 - samples/sec: 144.20 - lr: 0.000030
2021-07-23 18:09:01,769 epoch 19 - iter 568/1420 - loss 0.09388111 - samples/sec: 142.97 - lr: 0.000030
2021-07-23 18:09:33,783 epoch 19 - iter 710/1420 - loss 0.09275369 - samples/sec: 141.97 - lr: 0.000030
2021-07-23 18:10:05,787 epoch 19 - iter 852/1420 - loss 0.09386787 - samples/sec: 142.01 - lr: 0.000030
2021-07-23 18:10:37,835 epoch 19 - iter 994/1420 - loss 0.09458598 - samples/sec: 141.82 - lr: 0.000030
2021-07-23 18:11:09,774 epoch 19 - iter 1136/1420 - loss 0.09472324 - samples/sec: 142.30 - lr: 0.000030
2021-07-23 18:11:41,544 epoch 19 - iter 1278/1420 - loss 0.09397380 - samples/sec: 143.06 - lr: 0.000030
2021-07-23 18:12:13,683 epoch 19 - iter 1420/1420 - loss 0.09405033 - samples/sec: 141.42 - lr: 0.000030
2021-07-23 18:12:13,684 ----------------------------------------------------------------------------------------------------
2021-07-23 18:12:13,684 EPOCH 19 done: loss 0.0941 - lr 0.0000300
2021-07-23 18:12:31,141 DEV : loss 0.1277441382408142 - score 0.9709
2021-07-23 18:12:31,328 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:12:33,621 ----------------------------------------------------------------------------------------------------
2021-07-23 18:13:05,356 epoch 20 - iter 142/1420 - loss 0.10002873 - samples/sec: 143.24 - lr: 0.000030
2021-07-23 18:13:37,761 epoch 20 - iter 284/1420 - loss 0.10239379 - samples/sec: 140.26 - lr: 0.000030
2021-07-23 18:14:09,832 epoch 20 - iter 426/1420 - loss 0.09981130 - samples/sec: 141.72 - lr: 0.000030
2021-07-23 18:14:42,046 epoch 20 - iter 568/1420 - loss 0.10145510 - samples/sec: 141.08 - lr: 0.000030
2021-07-23 18:15:13,751 epoch 20 - iter 710/1420 - loss 0.09967771 - samples/sec: 143.35 - lr: 0.000030
2021-07-23 18:15:45,985 epoch 20 - iter 852/1420 - loss 0.09800184 - samples/sec: 141.00 - lr: 0.000030
2021-07-23 18:16:18,128 epoch 20 - iter 994/1420 - loss 0.09815894 - samples/sec: 141.40 - lr: 0.000030
2021-07-23 18:16:50,496 epoch 20 - iter 1136/1420 - loss 0.09741242 - samples/sec: 140.41 - lr: 0.000030
2021-07-23 18:17:22,270 epoch 20 - iter 1278/1420 - loss 0.09671903 - samples/sec: 143.04 - lr: 0.000030
2021-07-23 18:17:53,882 epoch 20 - iter 1420/1420 - loss 0.09700045 - samples/sec: 143.78 - lr: 0.000030
2021-07-23 18:17:53,883 ----------------------------------------------------------------------------------------------------
2021-07-23 18:17:53,883 EPOCH 20 done: loss 0.0970 - lr 0.0000300
2021-07-23 18:18:12,629 DEV : loss 0.12912386655807495 - score 0.9698
2021-07-23 18:18:12,818 BAD EPOCHS (no improvement): 1
2021-07-23 18:18:12,818 ----------------------------------------------------------------------------------------------------
2021-07-23 18:18:44,941 epoch 21 - iter 142/1420 - loss 0.09015579 - samples/sec: 141.50 - lr: 0.000030
2021-07-23 18:19:17,276 epoch 21 - iter 284/1420 - loss 0.08943754 - samples/sec: 140.56 - lr: 0.000030
2021-07-23 18:19:48,967 epoch 21 - iter 426/1420 - loss 0.09301370 - samples/sec: 143.41 - lr: 0.000030
2021-07-23 18:20:20,887 epoch 21 - iter 568/1420 - loss 0.09256067 - samples/sec: 142.39 - lr: 0.000030
2021-07-23 18:20:53,131 epoch 21 - iter 710/1420 - loss 0.09423415 - samples/sec: 140.96 - lr: 0.000030
2021-07-23 18:21:25,104 epoch 21 - iter 852/1420 - loss 0.09391189 - samples/sec: 142.15 - lr: 0.000030
2021-07-23 18:21:57,287 epoch 21 - iter 994/1420 - loss 0.09410042 - samples/sec: 141.22 - lr: 0.000030
2021-07-23 18:22:29,360 epoch 21 - iter 1136/1420 - loss 0.09387743 - samples/sec: 141.70 - lr: 0.000030
2021-07-23 18:23:01,176 epoch 21 - iter 1278/1420 - loss 0.09375169 - samples/sec: 142.85 - lr: 0.000030
2021-07-23 18:23:33,527 epoch 21 - iter 1420/1420 - loss 0.09313123 - samples/sec: 140.49 - lr: 0.000030
2021-07-23 18:23:33,528 ----------------------------------------------------------------------------------------------------
2021-07-23 18:23:33,528 EPOCH 21 done: loss 0.0931 - lr 0.0000300
2021-07-23 18:23:50,957 DEV : loss 0.1291586011648178 - score 0.9694
2021-07-23 18:23:51,143 BAD EPOCHS (no improvement): 2
2021-07-23 18:23:51,144 ----------------------------------------------------------------------------------------------------
2021-07-23 18:24:23,448 epoch 22 - iter 142/1420 - loss 0.09052618 - samples/sec: 140.70 - lr: 0.000030
2021-07-23 18:24:55,380 epoch 22 - iter 284/1420 - loss 0.08966916 - samples/sec: 142.34 - lr: 0.000030
2021-07-23 18:25:27,059 epoch 22 - iter 426/1420 - loss 0.08802734 - samples/sec: 143.47 - lr: 0.000030
2021-07-23 18:25:58,850 epoch 22 - iter 568/1420 - loss 0.09002050 - samples/sec: 142.97 - lr: 0.000030
2021-07-23 18:26:30,670 epoch 22 - iter 710/1420 - loss 0.09042695 - samples/sec: 142.83 - lr: 0.000030
2021-07-23 18:27:02,471 epoch 22 - iter 852/1420 - loss 0.09005913 - samples/sec: 142.92 - lr: 0.000030
2021-07-23 18:27:34,844 epoch 22 - iter 994/1420 - loss 0.09036446 - samples/sec: 140.40 - lr: 0.000030
2021-07-23 18:28:07,179 epoch 22 - iter 1136/1420 - loss 0.09120605 - samples/sec: 140.56 - lr: 0.000030
2021-07-23 18:28:39,471 epoch 22 - iter 1278/1420 - loss 0.09123803 - samples/sec: 140.75 - lr: 0.000030
2021-07-23 18:29:11,115 epoch 22 - iter 1420/1420 - loss 0.09119914 - samples/sec: 143.63 - lr: 0.000030
2021-07-23 18:29:11,116 ----------------------------------------------------------------------------------------------------
2021-07-23 18:29:11,116 EPOCH 22 done: loss 0.0912 - lr 0.0000300
2021-07-23 18:29:28,414 DEV : loss 0.12438912689685822 - score 0.97
2021-07-23 18:29:28,602 BAD EPOCHS (no improvement): 3
2021-07-23 18:29:28,602 ----------------------------------------------------------------------------------------------------
2021-07-23 18:30:00,956 epoch 23 - iter 142/1420 - loss 0.09129382 - samples/sec: 140.49 - lr: 0.000030
2021-07-23 18:30:32,667 epoch 23 - iter 284/1420 - loss 0.09005211 - samples/sec: 143.33 - lr: 0.000030
2021-07-23 18:31:04,859 epoch 23 - iter 426/1420 - loss 0.09158023 - samples/sec: 141.18 - lr: 0.000030
2021-07-23 18:31:36,811 epoch 23 - iter 568/1420 - loss 0.09548903 - samples/sec: 142.25 - lr: 0.000030
2021-07-23 18:32:08,736 epoch 23 - iter 710/1420 - loss 0.09323898 - samples/sec: 142.36 - lr: 0.000030
2021-07-23 18:32:41,032 epoch 23 - iter 852/1420 - loss 0.09241485 - samples/sec: 140.73 - lr: 0.000030
2021-07-23 18:33:12,926 epoch 23 - iter 994/1420 - loss 0.09199109 - samples/sec: 142.50 - lr: 0.000030
2021-07-23 18:33:45,203 epoch 23 - iter 1136/1420 - loss 0.09218691 - samples/sec: 140.81 - lr: 0.000030
2021-07-23 18:34:17,080 epoch 23 - iter 1278/1420 - loss 0.09069926 - samples/sec: 142.58 - lr: 0.000030
2021-07-23 18:34:48,687 epoch 23 - iter 1420/1420 - loss 0.09171764 - samples/sec: 143.80 - lr: 0.000030
2021-07-23 18:34:48,688 ----------------------------------------------------------------------------------------------------
2021-07-23 18:34:48,688 EPOCH 23 done: loss 0.0917 - lr 0.0000300
2021-07-23 18:35:06,008 DEV : loss 0.12296855449676514 - score 0.9698
Epoch    23: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 18:35:06,198 BAD EPOCHS (no improvement): 4
2021-07-23 18:35:06,198 ----------------------------------------------------------------------------------------------------
2021-07-23 18:35:37,995 epoch 24 - iter 142/1420 - loss 0.08504776 - samples/sec: 142.95 - lr: 0.000015
2021-07-23 18:36:10,369 epoch 24 - iter 284/1420 - loss 0.08807230 - samples/sec: 140.39 - lr: 0.000015
2021-07-23 18:36:43,013 epoch 24 - iter 426/1420 - loss 0.08980536 - samples/sec: 139.23 - lr: 0.000015
2021-07-23 18:37:14,498 epoch 24 - iter 568/1420 - loss 0.08886329 - samples/sec: 144.36 - lr: 0.000015
2021-07-23 18:37:46,531 epoch 24 - iter 710/1420 - loss 0.08912369 - samples/sec: 141.89 - lr: 0.000015
2021-07-23 18:38:18,360 epoch 24 - iter 852/1420 - loss 0.08910412 - samples/sec: 142.79 - lr: 0.000015
2021-07-23 18:38:49,987 epoch 24 - iter 994/1420 - loss 0.08899108 - samples/sec: 143.71 - lr: 0.000015
2021-07-23 18:39:22,320 epoch 24 - iter 1136/1420 - loss 0.08933845 - samples/sec: 140.57 - lr: 0.000015
2021-07-23 18:39:54,059 epoch 24 - iter 1278/1420 - loss 0.08872803 - samples/sec: 143.20 - lr: 0.000015
2021-07-23 18:40:25,635 epoch 24 - iter 1420/1420 - loss 0.08942334 - samples/sec: 143.94 - lr: 0.000015
2021-07-23 18:40:25,636 ----------------------------------------------------------------------------------------------------
2021-07-23 18:40:25,636 EPOCH 24 done: loss 0.0894 - lr 0.0000150
2021-07-23 18:40:44,373 DEV : loss 0.12833480536937714 - score 0.97
2021-07-23 18:40:44,560 BAD EPOCHS (no improvement): 1
2021-07-23 18:40:44,560 ----------------------------------------------------------------------------------------------------
2021-07-23 18:41:16,393 epoch 25 - iter 142/1420 - loss 0.08791511 - samples/sec: 142.79 - lr: 0.000015
2021-07-23 18:41:48,508 epoch 25 - iter 284/1420 - loss 0.08706988 - samples/sec: 141.52 - lr: 0.000015
2021-07-23 18:42:20,653 epoch 25 - iter 426/1420 - loss 0.08605534 - samples/sec: 141.39 - lr: 0.000015
2021-07-23 18:42:52,548 epoch 25 - iter 568/1420 - loss 0.08467408 - samples/sec: 142.50 - lr: 0.000015
2021-07-23 18:43:24,743 epoch 25 - iter 710/1420 - loss 0.08596548 - samples/sec: 141.17 - lr: 0.000015
2021-07-23 18:43:56,837 epoch 25 - iter 852/1420 - loss 0.08768693 - samples/sec: 141.61 - lr: 0.000015
2021-07-23 18:44:28,819 epoch 25 - iter 994/1420 - loss 0.08726354 - samples/sec: 142.11 - lr: 0.000015
2021-07-23 18:45:00,991 epoch 25 - iter 1136/1420 - loss 0.08682398 - samples/sec: 141.27 - lr: 0.000015
2021-07-23 18:45:33,324 epoch 25 - iter 1278/1420 - loss 0.08734165 - samples/sec: 140.57 - lr: 0.000015
2021-07-23 18:46:05,474 epoch 25 - iter 1420/1420 - loss 0.08671711 - samples/sec: 141.37 - lr: 0.000015
2021-07-23 18:46:05,475 ----------------------------------------------------------------------------------------------------
2021-07-23 18:46:05,475 EPOCH 25 done: loss 0.0867 - lr 0.0000150
2021-07-23 18:46:22,816 DEV : loss 0.12560588121414185 - score 0.9707
2021-07-23 18:46:23,006 BAD EPOCHS (no improvement): 2
2021-07-23 18:46:23,006 ----------------------------------------------------------------------------------------------------
2021-07-23 18:46:54,711 epoch 26 - iter 142/1420 - loss 0.08341532 - samples/sec: 143.37 - lr: 0.000015
2021-07-23 18:47:26,847 epoch 26 - iter 284/1420 - loss 0.08524022 - samples/sec: 141.43 - lr: 0.000015
2021-07-23 18:47:59,015 epoch 26 - iter 426/1420 - loss 0.08752735 - samples/sec: 141.29 - lr: 0.000015
2021-07-23 18:48:30,575 epoch 26 - iter 568/1420 - loss 0.08709860 - samples/sec: 144.01 - lr: 0.000015
2021-07-23 18:49:01,944 epoch 26 - iter 710/1420 - loss 0.08760287 - samples/sec: 144.89 - lr: 0.000015
2021-07-23 18:49:34,043 epoch 26 - iter 852/1420 - loss 0.08635883 - samples/sec: 141.59 - lr: 0.000015
2021-07-23 18:50:05,808 epoch 26 - iter 994/1420 - loss 0.08568479 - samples/sec: 143.08 - lr: 0.000015
2021-07-23 18:50:37,760 epoch 26 - iter 1136/1420 - loss 0.08592555 - samples/sec: 142.24 - lr: 0.000015
2021-07-23 18:51:10,109 epoch 26 - iter 1278/1420 - loss 0.08612023 - samples/sec: 140.50 - lr: 0.000015
2021-07-23 18:51:42,307 epoch 26 - iter 1420/1420 - loss 0.08660964 - samples/sec: 141.16 - lr: 0.000015
2021-07-23 18:51:42,308 ----------------------------------------------------------------------------------------------------
2021-07-23 18:51:42,308 EPOCH 26 done: loss 0.0866 - lr 0.0000150
2021-07-23 18:51:59,625 DEV : loss 0.12465479224920273 - score 0.9709
2021-07-23 18:51:59,813 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 18:52:02,200 ----------------------------------------------------------------------------------------------------
2021-07-23 18:52:34,335 epoch 27 - iter 142/1420 - loss 0.09115117 - samples/sec: 141.46 - lr: 0.000015
2021-07-23 18:53:06,429 epoch 27 - iter 284/1420 - loss 0.08232860 - samples/sec: 141.61 - lr: 0.000015
2021-07-23 18:53:38,883 epoch 27 - iter 426/1420 - loss 0.08168843 - samples/sec: 140.04 - lr: 0.000015
2021-07-23 18:54:10,954 epoch 27 - iter 568/1420 - loss 0.08366959 - samples/sec: 141.72 - lr: 0.000015
2021-07-23 18:54:42,788 epoch 27 - iter 710/1420 - loss 0.08533590 - samples/sec: 142.77 - lr: 0.000015
2021-07-23 18:55:14,684 epoch 27 - iter 852/1420 - loss 0.08544384 - samples/sec: 142.49 - lr: 0.000015
2021-07-23 18:55:46,636 epoch 27 - iter 994/1420 - loss 0.08505482 - samples/sec: 142.25 - lr: 0.000015
2021-07-23 18:56:19,157 epoch 27 - iter 1136/1420 - loss 0.08482240 - samples/sec: 139.76 - lr: 0.000015
2021-07-23 18:56:50,933 epoch 27 - iter 1278/1420 - loss 0.08492499 - samples/sec: 143.03 - lr: 0.000015
2021-07-23 18:57:23,306 epoch 27 - iter 1420/1420 - loss 0.08473377 - samples/sec: 140.40 - lr: 0.000015
2021-07-23 18:57:23,307 ----------------------------------------------------------------------------------------------------
2021-07-23 18:57:23,307 EPOCH 27 done: loss 0.0847 - lr 0.0000150
2021-07-23 18:57:40,649 DEV : loss 0.12786094844341278 - score 0.9696
2021-07-23 18:57:40,839 BAD EPOCHS (no improvement): 1
2021-07-23 18:57:40,839 ----------------------------------------------------------------------------------------------------
2021-07-23 18:58:12,698 epoch 28 - iter 142/1420 - loss 0.08534961 - samples/sec: 142.68 - lr: 0.000015
2021-07-23 18:58:44,604 epoch 28 - iter 284/1420 - loss 0.08555557 - samples/sec: 142.45 - lr: 0.000015
2021-07-23 18:59:16,677 epoch 28 - iter 426/1420 - loss 0.08475582 - samples/sec: 141.71 - lr: 0.000015
2021-07-23 18:59:48,504 epoch 28 - iter 568/1420 - loss 0.08685175 - samples/sec: 142.80 - lr: 0.000015
2021-07-23 19:00:20,487 epoch 28 - iter 710/1420 - loss 0.08850243 - samples/sec: 142.11 - lr: 0.000015
2021-07-23 19:00:52,557 epoch 28 - iter 852/1420 - loss 0.08675498 - samples/sec: 141.73 - lr: 0.000015
2021-07-23 19:01:25,205 epoch 28 - iter 994/1420 - loss 0.08767674 - samples/sec: 139.21 - lr: 0.000015
2021-07-23 19:01:57,336 epoch 28 - iter 1136/1420 - loss 0.08634404 - samples/sec: 141.45 - lr: 0.000015
2021-07-23 19:02:29,286 epoch 28 - iter 1278/1420 - loss 0.08587730 - samples/sec: 142.25 - lr: 0.000015
2021-07-23 19:03:00,974 epoch 28 - iter 1420/1420 - loss 0.08481637 - samples/sec: 143.43 - lr: 0.000015
2021-07-23 19:03:00,975 ----------------------------------------------------------------------------------------------------
2021-07-23 19:03:00,975 EPOCH 28 done: loss 0.0848 - lr 0.0000150
2021-07-23 19:03:18,302 DEV : loss 0.12681341171264648 - score 0.9702
2021-07-23 19:03:18,491 BAD EPOCHS (no improvement): 2
2021-07-23 19:03:18,491 ----------------------------------------------------------------------------------------------------
2021-07-23 19:03:52,172 epoch 29 - iter 142/1420 - loss 0.08685820 - samples/sec: 134.95 - lr: 0.000015
2021-07-23 19:04:23,494 epoch 29 - iter 284/1420 - loss 0.08274840 - samples/sec: 145.11 - lr: 0.000015
2021-07-23 19:04:56,112 epoch 29 - iter 426/1420 - loss 0.08322782 - samples/sec: 139.34 - lr: 0.000015
2021-07-23 19:05:28,110 epoch 29 - iter 568/1420 - loss 0.07929003 - samples/sec: 142.04 - lr: 0.000015
2021-07-23 19:05:59,888 epoch 29 - iter 710/1420 - loss 0.08088594 - samples/sec: 143.02 - lr: 0.000015
2021-07-23 19:06:32,084 epoch 29 - iter 852/1420 - loss 0.08347736 - samples/sec: 141.17 - lr: 0.000015
2021-07-23 19:07:04,619 epoch 29 - iter 994/1420 - loss 0.08304277 - samples/sec: 139.69 - lr: 0.000015
2021-07-23 19:07:35,991 epoch 29 - iter 1136/1420 - loss 0.08326469 - samples/sec: 144.88 - lr: 0.000015
2021-07-23 19:08:07,918 epoch 29 - iter 1278/1420 - loss 0.08363698 - samples/sec: 142.36 - lr: 0.000015
2021-07-23 19:08:39,685 epoch 29 - iter 1420/1420 - loss 0.08333918 - samples/sec: 143.08 - lr: 0.000015
2021-07-23 19:08:39,686 ----------------------------------------------------------------------------------------------------
2021-07-23 19:08:39,686 EPOCH 29 done: loss 0.0833 - lr 0.0000150
2021-07-23 19:08:57,103 DEV : loss 0.12656286358833313 - score 0.9694
2021-07-23 19:08:57,292 BAD EPOCHS (no improvement): 3
2021-07-23 19:08:57,292 ----------------------------------------------------------------------------------------------------
2021-07-23 19:09:28,908 epoch 30 - iter 142/1420 - loss 0.08257159 - samples/sec: 143.77 - lr: 0.000015
2021-07-23 19:10:01,068 epoch 30 - iter 284/1420 - loss 0.08281867 - samples/sec: 141.32 - lr: 0.000015
2021-07-23 19:10:32,935 epoch 30 - iter 426/1420 - loss 0.08159731 - samples/sec: 142.63 - lr: 0.000015
2021-07-23 19:11:05,204 epoch 30 - iter 568/1420 - loss 0.08284250 - samples/sec: 140.85 - lr: 0.000015
2021-07-23 19:11:37,019 epoch 30 - iter 710/1420 - loss 0.08328850 - samples/sec: 142.85 - lr: 0.000015
2021-07-23 19:12:09,075 epoch 30 - iter 852/1420 - loss 0.08305529 - samples/sec: 141.78 - lr: 0.000015
2021-07-23 19:12:41,303 epoch 30 - iter 994/1420 - loss 0.08268990 - samples/sec: 141.03 - lr: 0.000015
2021-07-23 19:13:13,197 epoch 30 - iter 1136/1420 - loss 0.08375402 - samples/sec: 142.51 - lr: 0.000015
2021-07-23 19:13:45,394 epoch 30 - iter 1278/1420 - loss 0.08496811 - samples/sec: 141.16 - lr: 0.000015
2021-07-23 19:14:17,554 epoch 30 - iter 1420/1420 - loss 0.08400195 - samples/sec: 141.33 - lr: 0.000015
2021-07-23 19:14:17,555 ----------------------------------------------------------------------------------------------------
2021-07-23 19:14:17,555 EPOCH 30 done: loss 0.0840 - lr 0.0000150
2021-07-23 19:14:34,999 DEV : loss 0.1288597285747528 - score 0.9691
Epoch    30: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 19:14:35,187 BAD EPOCHS (no improvement): 4
2021-07-23 19:14:35,187 ----------------------------------------------------------------------------------------------------
2021-07-23 19:15:07,327 epoch 31 - iter 142/1420 - loss 0.07844234 - samples/sec: 141.43 - lr: 0.000008
2021-07-23 19:15:39,164 epoch 31 - iter 284/1420 - loss 0.07978181 - samples/sec: 142.76 - lr: 0.000008
2021-07-23 19:16:11,133 epoch 31 - iter 426/1420 - loss 0.08226397 - samples/sec: 142.17 - lr: 0.000008
2021-07-23 19:16:43,215 epoch 31 - iter 568/1420 - loss 0.07978071 - samples/sec: 141.67 - lr: 0.000008
2021-07-23 19:17:14,860 epoch 31 - iter 710/1420 - loss 0.08113611 - samples/sec: 143.63 - lr: 0.000008
2021-07-23 19:17:46,859 epoch 31 - iter 852/1420 - loss 0.08196635 - samples/sec: 142.04 - lr: 0.000008
2021-07-23 19:18:18,191 epoch 31 - iter 994/1420 - loss 0.08161399 - samples/sec: 145.06 - lr: 0.000008
2021-07-23 19:18:50,366 epoch 31 - iter 1136/1420 - loss 0.08176578 - samples/sec: 141.26 - lr: 0.000008
2021-07-23 19:19:22,164 epoch 31 - iter 1278/1420 - loss 0.08138412 - samples/sec: 142.93 - lr: 0.000008
2021-07-23 19:19:53,810 epoch 31 - iter 1420/1420 - loss 0.08146346 - samples/sec: 143.62 - lr: 0.000008
2021-07-23 19:19:53,811 ----------------------------------------------------------------------------------------------------
2021-07-23 19:19:53,811 EPOCH 31 done: loss 0.0815 - lr 0.0000075
2021-07-23 19:20:11,119 DEV : loss 0.1279432326555252 - score 0.9692
2021-07-23 19:20:11,308 BAD EPOCHS (no improvement): 1
2021-07-23 19:20:11,308 ----------------------------------------------------------------------------------------------------
2021-07-23 19:20:42,942 epoch 32 - iter 142/1420 - loss 0.07836745 - samples/sec: 143.69 - lr: 0.000008
2021-07-23 19:21:14,867 epoch 32 - iter 284/1420 - loss 0.07719769 - samples/sec: 142.37 - lr: 0.000008
2021-07-23 19:21:46,721 epoch 32 - iter 426/1420 - loss 0.07821401 - samples/sec: 142.68 - lr: 0.000008
2021-07-23 19:22:18,515 epoch 32 - iter 568/1420 - loss 0.07955058 - samples/sec: 142.95 - lr: 0.000008
2021-07-23 19:22:50,902 epoch 32 - iter 710/1420 - loss 0.08068325 - samples/sec: 140.33 - lr: 0.000008
2021-07-23 19:23:22,920 epoch 32 - iter 852/1420 - loss 0.08181026 - samples/sec: 141.95 - lr: 0.000008
2021-07-23 19:23:54,923 epoch 32 - iter 994/1420 - loss 0.08106910 - samples/sec: 142.02 - lr: 0.000008
2021-07-23 19:24:26,883 epoch 32 - iter 1136/1420 - loss 0.07995499 - samples/sec: 142.21 - lr: 0.000008
2021-07-23 19:24:59,055 epoch 32 - iter 1278/1420 - loss 0.07973029 - samples/sec: 141.27 - lr: 0.000008
2021-07-23 19:25:31,375 epoch 32 - iter 1420/1420 - loss 0.08057062 - samples/sec: 140.62 - lr: 0.000008
2021-07-23 19:25:31,376 ----------------------------------------------------------------------------------------------------
2021-07-23 19:25:31,376 EPOCH 32 done: loss 0.0806 - lr 0.0000075
2021-07-23 19:25:48,706 DEV : loss 0.12769681215286255 - score 0.9692
2021-07-23 19:25:48,895 BAD EPOCHS (no improvement): 2
2021-07-23 19:25:48,896 ----------------------------------------------------------------------------------------------------
2021-07-23 19:26:21,215 epoch 33 - iter 142/1420 - loss 0.08826254 - samples/sec: 140.64 - lr: 0.000008
2021-07-23 19:26:53,300 epoch 33 - iter 284/1420 - loss 0.08340822 - samples/sec: 141.65 - lr: 0.000008
2021-07-23 19:27:25,343 epoch 33 - iter 426/1420 - loss 0.08374378 - samples/sec: 141.84 - lr: 0.000008
2021-07-23 19:27:57,287 epoch 33 - iter 568/1420 - loss 0.08398773 - samples/sec: 142.28 - lr: 0.000008
2021-07-23 19:28:29,507 epoch 33 - iter 710/1420 - loss 0.08340407 - samples/sec: 141.06 - lr: 0.000008
2021-07-23 19:29:01,315 epoch 33 - iter 852/1420 - loss 0.08356015 - samples/sec: 142.89 - lr: 0.000008
2021-07-23 19:29:33,685 epoch 33 - iter 994/1420 - loss 0.08280423 - samples/sec: 140.41 - lr: 0.000008
2021-07-23 19:30:05,639 epoch 33 - iter 1136/1420 - loss 0.08304793 - samples/sec: 142.24 - lr: 0.000008
2021-07-23 19:30:37,836 epoch 33 - iter 1278/1420 - loss 0.08241150 - samples/sec: 141.16 - lr: 0.000008
2021-07-23 19:31:09,791 epoch 33 - iter 1420/1420 - loss 0.08198741 - samples/sec: 142.23 - lr: 0.000008
2021-07-23 19:31:09,792 ----------------------------------------------------------------------------------------------------
2021-07-23 19:31:09,792 EPOCH 33 done: loss 0.0820 - lr 0.0000075
2021-07-23 19:31:28,621 DEV : loss 0.12766268849372864 - score 0.9695
2021-07-23 19:31:28,810 BAD EPOCHS (no improvement): 3
2021-07-23 19:31:28,810 ----------------------------------------------------------------------------------------------------
2021-07-23 19:32:00,704 epoch 34 - iter 142/1420 - loss 0.08517076 - samples/sec: 142.52 - lr: 0.000008
2021-07-23 19:32:32,882 epoch 34 - iter 284/1420 - loss 0.08267783 - samples/sec: 141.25 - lr: 0.000008
2021-07-23 19:33:04,358 epoch 34 - iter 426/1420 - loss 0.08081929 - samples/sec: 144.40 - lr: 0.000008
2021-07-23 19:33:36,855 epoch 34 - iter 568/1420 - loss 0.08114122 - samples/sec: 139.86 - lr: 0.000008
2021-07-23 19:34:08,635 epoch 34 - iter 710/1420 - loss 0.08126349 - samples/sec: 143.02 - lr: 0.000008
2021-07-23 19:34:40,803 epoch 34 - iter 852/1420 - loss 0.07966590 - samples/sec: 141.29 - lr: 0.000008
2021-07-23 19:35:12,947 epoch 34 - iter 994/1420 - loss 0.08032813 - samples/sec: 141.40 - lr: 0.000008
2021-07-23 19:35:45,152 epoch 34 - iter 1136/1420 - loss 0.07904613 - samples/sec: 141.12 - lr: 0.000008
2021-07-23 19:36:17,511 epoch 34 - iter 1278/1420 - loss 0.07984616 - samples/sec: 140.46 - lr: 0.000008
2021-07-23 19:36:49,611 epoch 34 - iter 1420/1420 - loss 0.07975147 - samples/sec: 141.59 - lr: 0.000008
2021-07-23 19:36:49,612 ----------------------------------------------------------------------------------------------------
2021-07-23 19:36:49,612 EPOCH 34 done: loss 0.0798 - lr 0.0000075
2021-07-23 19:37:07,048 DEV : loss 0.12386041134595871 - score 0.9704
Epoch    34: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 19:37:07,234 BAD EPOCHS (no improvement): 4
2021-07-23 19:37:07,235 ----------------------------------------------------------------------------------------------------
2021-07-23 19:37:39,412 epoch 35 - iter 142/1420 - loss 0.08119535 - samples/sec: 141.26 - lr: 0.000004
2021-07-23 19:38:10,967 epoch 35 - iter 284/1420 - loss 0.07838144 - samples/sec: 144.04 - lr: 0.000004
2021-07-23 19:38:42,891 epoch 35 - iter 426/1420 - loss 0.08035476 - samples/sec: 142.37 - lr: 0.000004
2021-07-23 19:39:14,596 epoch 35 - iter 568/1420 - loss 0.08018293 - samples/sec: 143.35 - lr: 0.000004
2021-07-23 19:39:46,395 epoch 35 - iter 710/1420 - loss 0.07950139 - samples/sec: 142.93 - lr: 0.000004
2021-07-23 19:40:18,302 epoch 35 - iter 852/1420 - loss 0.07840213 - samples/sec: 142.45 - lr: 0.000004
2021-07-23 19:40:49,980 epoch 35 - iter 994/1420 - loss 0.07809543 - samples/sec: 143.48 - lr: 0.000004
2021-07-23 19:41:22,215 epoch 35 - iter 1136/1420 - loss 0.07870885 - samples/sec: 140.99 - lr: 0.000004
2021-07-23 19:41:54,611 epoch 35 - iter 1278/1420 - loss 0.07940745 - samples/sec: 140.30 - lr: 0.000004
2021-07-23 19:42:26,927 epoch 35 - iter 1420/1420 - loss 0.07972508 - samples/sec: 140.64 - lr: 0.000004
2021-07-23 19:42:26,928 ----------------------------------------------------------------------------------------------------
2021-07-23 19:42:26,928 EPOCH 35 done: loss 0.0797 - lr 0.0000038
2021-07-23 19:42:44,386 DEV : loss 0.12457127869129181 - score 0.9708
2021-07-23 19:42:44,573 BAD EPOCHS (no improvement): 1
2021-07-23 19:42:44,573 ----------------------------------------------------------------------------------------------------
2021-07-23 19:43:17,272 epoch 36 - iter 142/1420 - loss 0.08401844 - samples/sec: 139.00 - lr: 0.000004
2021-07-23 19:43:49,312 epoch 36 - iter 284/1420 - loss 0.08174772 - samples/sec: 141.85 - lr: 0.000004
2021-07-23 19:44:21,415 epoch 36 - iter 426/1420 - loss 0.08133707 - samples/sec: 141.57 - lr: 0.000004
2021-07-23 19:44:53,591 epoch 36 - iter 568/1420 - loss 0.07991856 - samples/sec: 141.25 - lr: 0.000004
2021-07-23 19:45:25,764 epoch 36 - iter 710/1420 - loss 0.08104749 - samples/sec: 141.27 - lr: 0.000004
2021-07-23 19:45:57,364 epoch 36 - iter 852/1420 - loss 0.08068443 - samples/sec: 143.83 - lr: 0.000004
2021-07-23 19:46:29,171 epoch 36 - iter 994/1420 - loss 0.08117250 - samples/sec: 142.89 - lr: 0.000004
2021-07-23 19:47:00,684 epoch 36 - iter 1136/1420 - loss 0.08231329 - samples/sec: 144.23 - lr: 0.000004
2021-07-23 19:47:32,583 epoch 36 - iter 1278/1420 - loss 0.08305151 - samples/sec: 142.48 - lr: 0.000004
2021-07-23 19:48:04,375 epoch 36 - iter 1420/1420 - loss 0.08284135 - samples/sec: 142.96 - lr: 0.000004
2021-07-23 19:48:04,376 ----------------------------------------------------------------------------------------------------
2021-07-23 19:48:04,376 EPOCH 36 done: loss 0.0828 - lr 0.0000038
2021-07-23 19:48:21,693 DEV : loss 0.12555919587612152 - score 0.9699
2021-07-23 19:48:21,882 BAD EPOCHS (no improvement): 2
2021-07-23 19:48:21,883 ----------------------------------------------------------------------------------------------------
2021-07-23 19:48:53,674 epoch 37 - iter 142/1420 - loss 0.07518826 - samples/sec: 142.98 - lr: 0.000004
2021-07-23 19:49:25,487 epoch 37 - iter 284/1420 - loss 0.08060233 - samples/sec: 142.87 - lr: 0.000004
2021-07-23 19:49:57,505 epoch 37 - iter 426/1420 - loss 0.08039302 - samples/sec: 141.95 - lr: 0.000004
2021-07-23 19:50:29,202 epoch 37 - iter 568/1420 - loss 0.08302174 - samples/sec: 143.39 - lr: 0.000004
2021-07-23 19:51:01,376 epoch 37 - iter 710/1420 - loss 0.08228750 - samples/sec: 141.26 - lr: 0.000004
2021-07-23 19:51:33,512 epoch 37 - iter 852/1420 - loss 0.08094131 - samples/sec: 141.43 - lr: 0.000004
2021-07-23 19:52:05,686 epoch 37 - iter 994/1420 - loss 0.08025614 - samples/sec: 141.26 - lr: 0.000004
2021-07-23 19:52:37,160 epoch 37 - iter 1136/1420 - loss 0.07992074 - samples/sec: 144.41 - lr: 0.000004
2021-07-23 19:53:08,772 epoch 37 - iter 1278/1420 - loss 0.07938670 - samples/sec: 143.77 - lr: 0.000004
2021-07-23 19:53:41,205 epoch 37 - iter 1420/1420 - loss 0.07950579 - samples/sec: 140.14 - lr: 0.000004
2021-07-23 19:53:41,206 ----------------------------------------------------------------------------------------------------
2021-07-23 19:53:41,206 EPOCH 37 done: loss 0.0795 - lr 0.0000038
2021-07-23 19:54:00,008 DEV : loss 0.1254405677318573 - score 0.9703
2021-07-23 19:54:00,196 BAD EPOCHS (no improvement): 3
2021-07-23 19:54:00,196 ----------------------------------------------------------------------------------------------------
2021-07-23 19:54:32,527 epoch 38 - iter 142/1420 - loss 0.07841350 - samples/sec: 140.59 - lr: 0.000004
2021-07-23 19:55:04,599 epoch 38 - iter 284/1420 - loss 0.08064815 - samples/sec: 141.71 - lr: 0.000004
2021-07-23 19:55:36,911 epoch 38 - iter 426/1420 - loss 0.07995157 - samples/sec: 140.66 - lr: 0.000004
2021-07-23 19:56:08,714 epoch 38 - iter 568/1420 - loss 0.07835453 - samples/sec: 142.91 - lr: 0.000004
2021-07-23 19:56:40,781 epoch 38 - iter 710/1420 - loss 0.07974285 - samples/sec: 141.73 - lr: 0.000004
2021-07-23 19:57:12,692 epoch 38 - iter 852/1420 - loss 0.08016344 - samples/sec: 142.43 - lr: 0.000004
2021-07-23 19:57:44,848 epoch 38 - iter 994/1420 - loss 0.07914199 - samples/sec: 141.34 - lr: 0.000004
2021-07-23 19:58:16,992 epoch 38 - iter 1136/1420 - loss 0.07954321 - samples/sec: 141.40 - lr: 0.000004
2021-07-23 19:58:49,384 epoch 38 - iter 1278/1420 - loss 0.07979079 - samples/sec: 140.31 - lr: 0.000004
2021-07-23 19:59:21,607 epoch 38 - iter 1420/1420 - loss 0.07897998 - samples/sec: 141.05 - lr: 0.000004
2021-07-23 19:59:21,608 ----------------------------------------------------------------------------------------------------
2021-07-23 19:59:21,608 EPOCH 38 done: loss 0.0790 - lr 0.0000038
2021-07-23 19:59:38,940 DEV : loss 0.12494126707315445 - score 0.9706
Epoch    38: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 19:59:39,128 BAD EPOCHS (no improvement): 4
2021-07-23 19:59:39,128 ----------------------------------------------------------------------------------------------------
2021-07-23 19:59:39,128 ----------------------------------------------------------------------------------------------------
2021-07-23 19:59:39,128 learning rate too small - quitting training!
2021-07-23 19:59:39,128 ----------------------------------------------------------------------------------------------------
2021-07-23 19:59:39,761 ----------------------------------------------------------------------------------------------------
2021-07-23 19:59:39,761 Testing using best model ...
2021-07-23 19:59:39,762 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/tur.pdtb.tdb/best-model.pt
2021-07-23 20:03:04,639 0.9668	0.9803	0.9735
2021-07-23 20:03:04,639 
Results:
- F1-score (micro) 0.9735
- F1-score (macro) 0.9763

By class:
SENT       tp: 5898 - fp: 370 - fn: 217 - precision: 0.9410 - recall: 0.9645 - f1-score: 0.9526
X          tp: 4887 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 20:03:04,639 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/por.rst.cstn/
2021-07-23 20:03:04,664 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/por.rst.cstn
2021-07-23 20:03:04,667 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/por.rst.cstn/sent_train.txt
2021-07-23 20:03:04,667 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/por.rst.cstn/sent_dev.txt
2021-07-23 20:03:04,668 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/por.rst.cstn/sent_test.txt
Corpus: 4714 train + 859 dev + 1633 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 20:03:12,978 ----------------------------------------------------------------------------------------------------
2021-07-23 20:03:12,979 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 20:03:12,979 ----------------------------------------------------------------------------------------------------
2021-07-23 20:03:12,979 Corpus: "Corpus: 4714 train + 859 dev + 1633 test sentences"
2021-07-23 20:03:12,980 ----------------------------------------------------------------------------------------------------
2021-07-23 20:03:12,980 Parameters:
2021-07-23 20:03:12,980  - learning_rate: "3e-05"
2021-07-23 20:03:12,980  - mini_batch_size: "32"
2021-07-23 20:03:12,980  - patience: "3"
2021-07-23 20:03:12,980  - anneal_factor: "0.5"
2021-07-23 20:03:12,980  - max_epochs: "40"
2021-07-23 20:03:12,980  - shuffle: "True"
2021-07-23 20:03:12,980  - train_with_dev: "False"
2021-07-23 20:03:12,980  - batch_growth_annealing: "False"
2021-07-23 20:03:12,980 ----------------------------------------------------------------------------------------------------
2021-07-23 20:03:12,980 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/por.rst.cstn"
2021-07-23 20:03:12,980 ----------------------------------------------------------------------------------------------------
2021-07-23 20:03:12,980 Device: cuda:0
2021-07-23 20:03:12,980 ----------------------------------------------------------------------------------------------------
2021-07-23 20:03:12,980 Embeddings storage mode: cpu
2021-07-23 20:03:12,983 ----------------------------------------------------------------------------------------------------
2021-07-23 20:03:21,224 epoch 1 - iter 14/148 - loss 16.62879794 - samples/sec: 54.37 - lr: 0.000030
2021-07-23 20:03:29,329 epoch 1 - iter 28/148 - loss 14.99391638 - samples/sec: 55.28 - lr: 0.000030
2021-07-23 20:03:37,606 epoch 1 - iter 42/148 - loss 13.67730011 - samples/sec: 54.13 - lr: 0.000030
2021-07-23 20:03:45,984 epoch 1 - iter 56/148 - loss 12.16617397 - samples/sec: 53.48 - lr: 0.000030
2021-07-23 20:03:54,207 epoch 1 - iter 70/148 - loss 10.82955590 - samples/sec: 54.48 - lr: 0.000030
2021-07-23 20:04:02,504 epoch 1 - iter 84/148 - loss 9.59160473 - samples/sec: 54.00 - lr: 0.000030
2021-07-23 20:04:10,692 epoch 1 - iter 98/148 - loss 8.55110278 - samples/sec: 54.72 - lr: 0.000030
2021-07-23 20:04:19,017 epoch 1 - iter 112/148 - loss 7.69255309 - samples/sec: 53.82 - lr: 0.000030
2021-07-23 20:04:27,425 epoch 1 - iter 126/148 - loss 6.98436940 - samples/sec: 53.29 - lr: 0.000030
2021-07-23 20:04:35,896 epoch 1 - iter 140/148 - loss 6.39448150 - samples/sec: 52.89 - lr: 0.000030
2021-07-23 20:04:40,322 ----------------------------------------------------------------------------------------------------
2021-07-23 20:04:40,322 EPOCH 1 done: loss 6.1024 - lr 0.0000300
2021-07-23 20:04:52,554 DEV : loss 0.7852599024772644 - score 0.7109
2021-07-23 20:04:52,581 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:04:53,762 ----------------------------------------------------------------------------------------------------
2021-07-23 20:04:57,196 epoch 2 - iter 14/148 - loss 0.86317644 - samples/sec: 130.56 - lr: 0.000030
2021-07-23 20:05:00,590 epoch 2 - iter 28/148 - loss 0.79693394 - samples/sec: 132.01 - lr: 0.000030
2021-07-23 20:05:03,940 epoch 2 - iter 42/148 - loss 0.74134870 - samples/sec: 133.77 - lr: 0.000030
2021-07-23 20:05:07,388 epoch 2 - iter 56/148 - loss 0.71765485 - samples/sec: 129.97 - lr: 0.000030
2021-07-23 20:05:10,800 epoch 2 - iter 70/148 - loss 0.67994745 - samples/sec: 131.37 - lr: 0.000030
2021-07-23 20:05:14,255 epoch 2 - iter 84/148 - loss 0.65694204 - samples/sec: 129.67 - lr: 0.000030
2021-07-23 20:05:17,691 epoch 2 - iter 98/148 - loss 0.62830514 - samples/sec: 130.42 - lr: 0.000030
2021-07-23 20:05:21,155 epoch 2 - iter 112/148 - loss 0.60462769 - samples/sec: 129.39 - lr: 0.000030
2021-07-23 20:05:24,717 epoch 2 - iter 126/148 - loss 0.58532663 - samples/sec: 125.81 - lr: 0.000030
2021-07-23 20:05:28,082 epoch 2 - iter 140/148 - loss 0.56155546 - samples/sec: 133.14 - lr: 0.000030
2021-07-23 20:05:29,874 ----------------------------------------------------------------------------------------------------
2021-07-23 20:05:29,874 EPOCH 2 done: loss 0.5515 - lr 0.0000300
2021-07-23 20:05:32,040 DEV : loss 0.21143224835395813 - score 0.9677
2021-07-23 20:05:32,067 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:05:36,422 ----------------------------------------------------------------------------------------------------
2021-07-23 20:05:40,072 epoch 3 - iter 14/148 - loss 0.31419237 - samples/sec: 122.83 - lr: 0.000030
2021-07-23 20:05:43,588 epoch 3 - iter 28/148 - loss 0.30702465 - samples/sec: 127.45 - lr: 0.000030
2021-07-23 20:05:47,091 epoch 3 - iter 42/148 - loss 0.30556133 - samples/sec: 127.92 - lr: 0.000030
2021-07-23 20:05:50,614 epoch 3 - iter 56/148 - loss 0.30562822 - samples/sec: 127.19 - lr: 0.000030
2021-07-23 20:05:53,786 epoch 3 - iter 70/148 - loss 0.28931667 - samples/sec: 141.27 - lr: 0.000030
2021-07-23 20:05:57,309 epoch 3 - iter 84/148 - loss 0.28625740 - samples/sec: 127.23 - lr: 0.000030
2021-07-23 20:06:00,792 epoch 3 - iter 98/148 - loss 0.27770583 - samples/sec: 128.65 - lr: 0.000030
2021-07-23 20:06:04,181 epoch 3 - iter 112/148 - loss 0.27366342 - samples/sec: 132.24 - lr: 0.000030
2021-07-23 20:06:07,563 epoch 3 - iter 126/148 - loss 0.26466152 - samples/sec: 132.49 - lr: 0.000030
2021-07-23 20:06:10,904 epoch 3 - iter 140/148 - loss 0.25802254 - samples/sec: 134.13 - lr: 0.000030
2021-07-23 20:06:12,812 ----------------------------------------------------------------------------------------------------
2021-07-23 20:06:12,812 EPOCH 3 done: loss 0.2539 - lr 0.0000300
2021-07-23 20:06:14,997 DEV : loss 0.10392788052558899 - score 0.9832
2021-07-23 20:06:15,025 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:06:19,549 ----------------------------------------------------------------------------------------------------
2021-07-23 20:06:22,874 epoch 4 - iter 14/148 - loss 0.21443568 - samples/sec: 134.84 - lr: 0.000030
2021-07-23 20:06:26,300 epoch 4 - iter 28/148 - loss 0.21080271 - samples/sec: 130.79 - lr: 0.000030
2021-07-23 20:06:29,547 epoch 4 - iter 42/148 - loss 0.20250897 - samples/sec: 138.04 - lr: 0.000030
2021-07-23 20:06:32,892 epoch 4 - iter 56/148 - loss 0.19629292 - samples/sec: 133.97 - lr: 0.000030
2021-07-23 20:06:36,524 epoch 4 - iter 70/148 - loss 0.19060141 - samples/sec: 123.38 - lr: 0.000030
2021-07-23 20:06:39,931 epoch 4 - iter 84/148 - loss 0.19180331 - samples/sec: 131.50 - lr: 0.000030
2021-07-23 20:06:43,385 epoch 4 - iter 98/148 - loss 0.18663378 - samples/sec: 129.74 - lr: 0.000030
2021-07-23 20:06:46,771 epoch 4 - iter 112/148 - loss 0.18337339 - samples/sec: 132.35 - lr: 0.000030
2021-07-23 20:06:50,172 epoch 4 - iter 126/148 - loss 0.18555973 - samples/sec: 131.77 - lr: 0.000030
2021-07-23 20:06:53,812 epoch 4 - iter 140/148 - loss 0.18007904 - samples/sec: 123.10 - lr: 0.000030
2021-07-23 20:06:55,694 ----------------------------------------------------------------------------------------------------
2021-07-23 20:06:55,694 EPOCH 4 done: loss 0.1793 - lr 0.0000300
2021-07-23 20:06:57,858 DEV : loss 0.0696139857172966 - score 0.985
2021-07-23 20:06:57,885 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:07:02,295 ----------------------------------------------------------------------------------------------------
2021-07-23 20:07:05,684 epoch 5 - iter 14/148 - loss 0.16061221 - samples/sec: 132.33 - lr: 0.000030
2021-07-23 20:07:09,192 epoch 5 - iter 28/148 - loss 0.14274086 - samples/sec: 127.72 - lr: 0.000030
2021-07-23 20:07:12,612 epoch 5 - iter 42/148 - loss 0.14277628 - samples/sec: 131.03 - lr: 0.000030
2021-07-23 20:07:16,160 epoch 5 - iter 56/148 - loss 0.14578677 - samples/sec: 126.30 - lr: 0.000030
2021-07-23 20:07:19,737 epoch 5 - iter 70/148 - loss 0.14169619 - samples/sec: 125.30 - lr: 0.000030
2021-07-23 20:07:23,117 epoch 5 - iter 84/148 - loss 0.13630842 - samples/sec: 132.59 - lr: 0.000030
2021-07-23 20:07:26,533 epoch 5 - iter 98/148 - loss 0.13693565 - samples/sec: 131.18 - lr: 0.000030
2021-07-23 20:07:29,871 epoch 5 - iter 112/148 - loss 0.13663248 - samples/sec: 134.25 - lr: 0.000030
2021-07-23 20:07:33,207 epoch 5 - iter 126/148 - loss 0.13602228 - samples/sec: 134.30 - lr: 0.000030
2021-07-23 20:07:36,630 epoch 5 - iter 140/148 - loss 0.13937746 - samples/sec: 130.92 - lr: 0.000030
2021-07-23 20:07:38,503 ----------------------------------------------------------------------------------------------------
2021-07-23 20:07:38,503 EPOCH 5 done: loss 0.1370 - lr 0.0000300
2021-07-23 20:07:40,701 DEV : loss 0.0546187087893486 - score 0.9886
2021-07-23 20:07:40,729 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:07:45,506 ----------------------------------------------------------------------------------------------------
2021-07-23 20:07:49,168 epoch 6 - iter 14/148 - loss 0.12869917 - samples/sec: 122.43 - lr: 0.000030
2021-07-23 20:07:52,688 epoch 6 - iter 28/148 - loss 0.14773115 - samples/sec: 127.31 - lr: 0.000030
2021-07-23 20:07:56,035 epoch 6 - iter 42/148 - loss 0.15117087 - samples/sec: 133.90 - lr: 0.000030
2021-07-23 20:07:59,407 epoch 6 - iter 56/148 - loss 0.14536852 - samples/sec: 132.88 - lr: 0.000030
2021-07-23 20:08:02,864 epoch 6 - iter 70/148 - loss 0.14066838 - samples/sec: 129.63 - lr: 0.000030
2021-07-23 20:08:06,227 epoch 6 - iter 84/148 - loss 0.13841412 - samples/sec: 133.26 - lr: 0.000030
2021-07-23 20:08:09,688 epoch 6 - iter 98/148 - loss 0.13938400 - samples/sec: 129.46 - lr: 0.000030
2021-07-23 20:08:13,148 epoch 6 - iter 112/148 - loss 0.13851845 - samples/sec: 129.55 - lr: 0.000030
2021-07-23 20:08:16,539 epoch 6 - iter 126/148 - loss 0.13725476 - samples/sec: 132.14 - lr: 0.000030
2021-07-23 20:08:20,025 epoch 6 - iter 140/148 - loss 0.13679538 - samples/sec: 128.55 - lr: 0.000030
2021-07-23 20:08:21,761 ----------------------------------------------------------------------------------------------------
2021-07-23 20:08:21,761 EPOCH 6 done: loss 0.1364 - lr 0.0000300
2021-07-23 20:08:23,935 DEV : loss 0.04806440323591232 - score 0.9895
2021-07-23 20:08:23,963 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:08:28,798 ----------------------------------------------------------------------------------------------------
2021-07-23 20:08:32,235 epoch 7 - iter 14/148 - loss 0.14761015 - samples/sec: 130.45 - lr: 0.000030
2021-07-23 20:08:35,640 epoch 7 - iter 28/148 - loss 0.12962416 - samples/sec: 131.61 - lr: 0.000030
2021-07-23 20:08:39,132 epoch 7 - iter 42/148 - loss 0.13245602 - samples/sec: 128.35 - lr: 0.000030
2021-07-23 20:08:42,673 epoch 7 - iter 56/148 - loss 0.12660446 - samples/sec: 126.52 - lr: 0.000030
2021-07-23 20:08:46,115 epoch 7 - iter 70/148 - loss 0.12870472 - samples/sec: 130.21 - lr: 0.000030
2021-07-23 20:08:49,584 epoch 7 - iter 84/148 - loss 0.12626754 - samples/sec: 129.16 - lr: 0.000030
2021-07-23 20:08:52,854 epoch 7 - iter 98/148 - loss 0.12416850 - samples/sec: 137.04 - lr: 0.000030
2021-07-23 20:08:56,392 epoch 7 - iter 112/148 - loss 0.12787259 - samples/sec: 126.67 - lr: 0.000030
2021-07-23 20:08:59,668 epoch 7 - iter 126/148 - loss 0.12796896 - samples/sec: 136.81 - lr: 0.000030
2021-07-23 20:09:03,123 epoch 7 - iter 140/148 - loss 0.12634343 - samples/sec: 129.68 - lr: 0.000030
2021-07-23 20:09:05,081 ----------------------------------------------------------------------------------------------------
2021-07-23 20:09:05,081 EPOCH 7 done: loss 0.1247 - lr 0.0000300
2021-07-23 20:09:07,496 DEV : loss 0.04393706098198891 - score 0.9921
2021-07-23 20:09:07,524 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:09:11,661 ----------------------------------------------------------------------------------------------------
2021-07-23 20:09:15,176 epoch 8 - iter 14/148 - loss 0.10812060 - samples/sec: 127.56 - lr: 0.000030
2021-07-23 20:09:18,709 epoch 8 - iter 28/148 - loss 0.10956779 - samples/sec: 126.84 - lr: 0.000030
2021-07-23 20:09:22,187 epoch 8 - iter 42/148 - loss 0.10054904 - samples/sec: 128.84 - lr: 0.000030
2021-07-23 20:09:25,558 epoch 8 - iter 56/148 - loss 0.10725140 - samples/sec: 132.93 - lr: 0.000030
2021-07-23 20:09:28,943 epoch 8 - iter 70/148 - loss 0.11142616 - samples/sec: 132.40 - lr: 0.000030
2021-07-23 20:09:32,419 epoch 8 - iter 84/148 - loss 0.10982664 - samples/sec: 128.92 - lr: 0.000030
2021-07-23 20:09:35,981 epoch 8 - iter 98/148 - loss 0.11026445 - samples/sec: 125.81 - lr: 0.000030
2021-07-23 20:09:39,353 epoch 8 - iter 112/148 - loss 0.10922949 - samples/sec: 132.89 - lr: 0.000030
2021-07-23 20:09:42,695 epoch 8 - iter 126/148 - loss 0.11113222 - samples/sec: 134.08 - lr: 0.000030
2021-07-23 20:09:46,044 epoch 8 - iter 140/148 - loss 0.11078903 - samples/sec: 133.79 - lr: 0.000030
2021-07-23 20:09:47,896 ----------------------------------------------------------------------------------------------------
2021-07-23 20:09:47,896 EPOCH 8 done: loss 0.1124 - lr 0.0000300
2021-07-23 20:09:50,069 DEV : loss 0.03570025786757469 - score 0.9921
2021-07-23 20:09:50,096 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:09:54,650 ----------------------------------------------------------------------------------------------------
2021-07-23 20:09:58,203 epoch 9 - iter 14/148 - loss 0.09039385 - samples/sec: 126.18 - lr: 0.000030
2021-07-23 20:10:01,654 epoch 9 - iter 28/148 - loss 0.09530653 - samples/sec: 129.85 - lr: 0.000030
2021-07-23 20:10:05,144 epoch 9 - iter 42/148 - loss 0.10742791 - samples/sec: 128.41 - lr: 0.000030
2021-07-23 20:10:08,483 epoch 9 - iter 56/148 - loss 0.10412228 - samples/sec: 134.24 - lr: 0.000030
2021-07-23 20:10:11,988 epoch 9 - iter 70/148 - loss 0.10060443 - samples/sec: 127.85 - lr: 0.000030
2021-07-23 20:10:15,447 epoch 9 - iter 84/148 - loss 0.10077695 - samples/sec: 129.54 - lr: 0.000030
2021-07-23 20:10:18,784 epoch 9 - iter 98/148 - loss 0.10014734 - samples/sec: 134.29 - lr: 0.000030
2021-07-23 20:10:22,291 epoch 9 - iter 112/148 - loss 0.10449138 - samples/sec: 127.78 - lr: 0.000030
2021-07-23 20:10:25,621 epoch 9 - iter 126/148 - loss 0.10869297 - samples/sec: 134.58 - lr: 0.000030
2021-07-23 20:10:29,169 epoch 9 - iter 140/148 - loss 0.11156733 - samples/sec: 126.30 - lr: 0.000030
2021-07-23 20:10:31,011 ----------------------------------------------------------------------------------------------------
2021-07-23 20:10:31,011 EPOCH 9 done: loss 0.1102 - lr 0.0000300
2021-07-23 20:10:33,187 DEV : loss 0.041073258966207504 - score 0.9921
2021-07-23 20:10:33,215 BAD EPOCHS (no improvement): 1
2021-07-23 20:10:33,215 ----------------------------------------------------------------------------------------------------
2021-07-23 20:10:36,707 epoch 10 - iter 14/148 - loss 0.10609369 - samples/sec: 128.36 - lr: 0.000030
2021-07-23 20:10:40,109 epoch 10 - iter 28/148 - loss 0.11460795 - samples/sec: 131.74 - lr: 0.000030
2021-07-23 20:10:43,544 epoch 10 - iter 42/148 - loss 0.10308577 - samples/sec: 130.44 - lr: 0.000030
2021-07-23 20:10:47,060 epoch 10 - iter 56/148 - loss 0.10233022 - samples/sec: 127.44 - lr: 0.000030
2021-07-23 20:10:50,391 epoch 10 - iter 70/148 - loss 0.10191087 - samples/sec: 134.55 - lr: 0.000030
2021-07-23 20:10:53,939 epoch 10 - iter 84/148 - loss 0.10298472 - samples/sec: 126.29 - lr: 0.000030
2021-07-23 20:10:57,383 epoch 10 - iter 98/148 - loss 0.10630518 - samples/sec: 130.12 - lr: 0.000030
2021-07-23 20:11:00,792 epoch 10 - iter 112/148 - loss 0.10211072 - samples/sec: 131.45 - lr: 0.000030
2021-07-23 20:11:04,250 epoch 10 - iter 126/148 - loss 0.10133131 - samples/sec: 129.58 - lr: 0.000030
2021-07-23 20:11:07,703 epoch 10 - iter 140/148 - loss 0.10317285 - samples/sec: 129.78 - lr: 0.000030
2021-07-23 20:11:09,515 ----------------------------------------------------------------------------------------------------
2021-07-23 20:11:09,515 EPOCH 10 done: loss 0.1026 - lr 0.0000300
2021-07-23 20:11:11,691 DEV : loss 0.03604467213153839 - score 0.9912
2021-07-23 20:11:11,719 BAD EPOCHS (no improvement): 2
2021-07-23 20:11:11,719 ----------------------------------------------------------------------------------------------------
2021-07-23 20:11:15,252 epoch 11 - iter 14/148 - loss 0.09034450 - samples/sec: 126.87 - lr: 0.000030
2021-07-23 20:11:18,732 epoch 11 - iter 28/148 - loss 0.10252006 - samples/sec: 128.79 - lr: 0.000030
2021-07-23 20:11:22,141 epoch 11 - iter 42/148 - loss 0.10204740 - samples/sec: 131.45 - lr: 0.000030
2021-07-23 20:11:25,568 epoch 11 - iter 56/148 - loss 0.09549414 - samples/sec: 130.74 - lr: 0.000030
2021-07-23 20:11:28,976 epoch 11 - iter 70/148 - loss 0.09874135 - samples/sec: 131.51 - lr: 0.000030
2021-07-23 20:11:32,478 epoch 11 - iter 84/148 - loss 0.09678113 - samples/sec: 127.94 - lr: 0.000030
2021-07-23 20:11:35,888 epoch 11 - iter 98/148 - loss 0.09993327 - samples/sec: 131.42 - lr: 0.000030
2021-07-23 20:11:39,380 epoch 11 - iter 112/148 - loss 0.09986809 - samples/sec: 128.35 - lr: 0.000030
2021-07-23 20:11:42,819 epoch 11 - iter 126/148 - loss 0.09791172 - samples/sec: 130.28 - lr: 0.000030
2021-07-23 20:11:46,349 epoch 11 - iter 140/148 - loss 0.09610068 - samples/sec: 126.96 - lr: 0.000030
2021-07-23 20:11:48,018 ----------------------------------------------------------------------------------------------------
2021-07-23 20:11:48,018 EPOCH 11 done: loss 0.0955 - lr 0.0000300
2021-07-23 20:11:50,192 DEV : loss 0.030102141201496124 - score 0.9939
2021-07-23 20:11:50,220 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:11:54,122 ----------------------------------------------------------------------------------------------------
2021-07-23 20:11:57,655 epoch 12 - iter 14/148 - loss 0.09788184 - samples/sec: 126.91 - lr: 0.000030
2021-07-23 20:12:01,084 epoch 12 - iter 28/148 - loss 0.08330304 - samples/sec: 130.69 - lr: 0.000030
2021-07-23 20:12:04,536 epoch 12 - iter 42/148 - loss 0.07983994 - samples/sec: 129.83 - lr: 0.000030
2021-07-23 20:12:08,062 epoch 12 - iter 56/148 - loss 0.08449478 - samples/sec: 127.06 - lr: 0.000030
2021-07-23 20:12:11,492 epoch 12 - iter 70/148 - loss 0.08894512 - samples/sec: 130.68 - lr: 0.000030
2021-07-23 20:12:14,917 epoch 12 - iter 84/148 - loss 0.08746163 - samples/sec: 130.84 - lr: 0.000030
2021-07-23 20:12:18,231 epoch 12 - iter 98/148 - loss 0.09258873 - samples/sec: 135.20 - lr: 0.000030
2021-07-23 20:12:21,666 epoch 12 - iter 112/148 - loss 0.09168372 - samples/sec: 130.45 - lr: 0.000030
2021-07-23 20:12:25,091 epoch 12 - iter 126/148 - loss 0.09212557 - samples/sec: 130.84 - lr: 0.000030
2021-07-23 20:12:28,621 epoch 12 - iter 140/148 - loss 0.09047738 - samples/sec: 126.95 - lr: 0.000030
2021-07-23 20:12:30,482 ----------------------------------------------------------------------------------------------------
2021-07-23 20:12:30,482 EPOCH 12 done: loss 0.0892 - lr 0.0000300
2021-07-23 20:12:32,669 DEV : loss 0.03354023024439812 - score 0.9921
2021-07-23 20:12:32,696 BAD EPOCHS (no improvement): 1
2021-07-23 20:12:32,696 ----------------------------------------------------------------------------------------------------
2021-07-23 20:12:36,448 epoch 13 - iter 14/148 - loss 0.10338933 - samples/sec: 119.49 - lr: 0.000030
2021-07-23 20:12:39,895 epoch 13 - iter 28/148 - loss 0.09902061 - samples/sec: 130.00 - lr: 0.000030
2021-07-23 20:12:43,167 epoch 13 - iter 42/148 - loss 0.10296722 - samples/sec: 136.94 - lr: 0.000030
2021-07-23 20:12:46,568 epoch 13 - iter 56/148 - loss 0.10622210 - samples/sec: 131.78 - lr: 0.000030
2021-07-23 20:12:49,908 epoch 13 - iter 70/148 - loss 0.10646832 - samples/sec: 134.18 - lr: 0.000030
2021-07-23 20:12:53,353 epoch 13 - iter 84/148 - loss 0.11010915 - samples/sec: 130.06 - lr: 0.000030
2021-07-23 20:12:56,845 epoch 13 - iter 98/148 - loss 0.10471049 - samples/sec: 128.34 - lr: 0.000030
2021-07-23 20:13:00,392 epoch 13 - iter 112/148 - loss 0.10194855 - samples/sec: 126.34 - lr: 0.000030
2021-07-23 20:13:03,836 epoch 13 - iter 126/148 - loss 0.10066441 - samples/sec: 130.11 - lr: 0.000030
2021-07-23 20:13:07,324 epoch 13 - iter 140/148 - loss 0.10050962 - samples/sec: 128.47 - lr: 0.000030
2021-07-23 20:13:09,236 ----------------------------------------------------------------------------------------------------
2021-07-23 20:13:09,236 EPOCH 13 done: loss 0.0995 - lr 0.0000300
2021-07-23 20:13:11,418 DEV : loss 0.033340174704790115 - score 0.9912
2021-07-23 20:13:11,445 BAD EPOCHS (no improvement): 2
2021-07-23 20:13:11,446 ----------------------------------------------------------------------------------------------------
2021-07-23 20:13:14,952 epoch 14 - iter 14/148 - loss 0.07991668 - samples/sec: 127.86 - lr: 0.000030
2021-07-23 20:13:18,424 epoch 14 - iter 28/148 - loss 0.08461195 - samples/sec: 129.05 - lr: 0.000030
2021-07-23 20:13:21,853 epoch 14 - iter 42/148 - loss 0.08537736 - samples/sec: 130.71 - lr: 0.000030
2021-07-23 20:13:25,343 epoch 14 - iter 56/148 - loss 0.08493879 - samples/sec: 128.39 - lr: 0.000030
2021-07-23 20:13:28,843 epoch 14 - iter 70/148 - loss 0.08632166 - samples/sec: 128.04 - lr: 0.000030
2021-07-23 20:13:32,200 epoch 14 - iter 84/148 - loss 0.08320875 - samples/sec: 133.47 - lr: 0.000030
2021-07-23 20:13:35,699 epoch 14 - iter 98/148 - loss 0.08202833 - samples/sec: 128.09 - lr: 0.000030
2021-07-23 20:13:39,228 epoch 14 - iter 112/148 - loss 0.08137158 - samples/sec: 126.97 - lr: 0.000030
2021-07-23 20:13:42,535 epoch 14 - iter 126/148 - loss 0.07946891 - samples/sec: 135.49 - lr: 0.000030
2021-07-23 20:13:46,100 epoch 14 - iter 140/148 - loss 0.08212991 - samples/sec: 125.71 - lr: 0.000030
2021-07-23 20:13:47,836 ----------------------------------------------------------------------------------------------------
2021-07-23 20:13:47,836 EPOCH 14 done: loss 0.0821 - lr 0.0000300
2021-07-23 20:13:50,028 DEV : loss 0.028105422854423523 - score 0.993
2021-07-23 20:13:50,055 BAD EPOCHS (no improvement): 3
2021-07-23 20:13:50,055 ----------------------------------------------------------------------------------------------------
2021-07-23 20:13:53,532 epoch 15 - iter 14/148 - loss 0.08373605 - samples/sec: 128.93 - lr: 0.000030
2021-07-23 20:13:56,965 epoch 15 - iter 28/148 - loss 0.08860851 - samples/sec: 130.55 - lr: 0.000030
2021-07-23 20:14:00,147 epoch 15 - iter 42/148 - loss 0.08824373 - samples/sec: 140.84 - lr: 0.000030
2021-07-23 20:14:03,667 epoch 15 - iter 56/148 - loss 0.08598271 - samples/sec: 127.28 - lr: 0.000030
2021-07-23 20:14:07,099 epoch 15 - iter 70/148 - loss 0.08273783 - samples/sec: 130.60 - lr: 0.000030
2021-07-23 20:14:10,583 epoch 15 - iter 84/148 - loss 0.08192293 - samples/sec: 128.61 - lr: 0.000030
2021-07-23 20:14:14,147 epoch 15 - iter 98/148 - loss 0.08254284 - samples/sec: 125.72 - lr: 0.000030
2021-07-23 20:14:17,526 epoch 15 - iter 112/148 - loss 0.08279102 - samples/sec: 132.64 - lr: 0.000030
2021-07-23 20:14:20,992 epoch 15 - iter 126/148 - loss 0.08092374 - samples/sec: 129.29 - lr: 0.000030
2021-07-23 20:14:24,456 epoch 15 - iter 140/148 - loss 0.08201756 - samples/sec: 129.35 - lr: 0.000030
2021-07-23 20:14:26,342 ----------------------------------------------------------------------------------------------------
2021-07-23 20:14:26,342 EPOCH 15 done: loss 0.0805 - lr 0.0000300
2021-07-23 20:14:28,518 DEV : loss 0.03416110575199127 - score 0.9912
Epoch    15: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 20:14:28,546 BAD EPOCHS (no improvement): 4
2021-07-23 20:14:28,546 ----------------------------------------------------------------------------------------------------
2021-07-23 20:14:31,978 epoch 16 - iter 14/148 - loss 0.07440572 - samples/sec: 130.59 - lr: 0.000015
2021-07-23 20:14:35,311 epoch 16 - iter 28/148 - loss 0.07192218 - samples/sec: 134.47 - lr: 0.000015
2021-07-23 20:14:38,723 epoch 16 - iter 42/148 - loss 0.06483005 - samples/sec: 131.35 - lr: 0.000015
2021-07-23 20:14:42,124 epoch 16 - iter 56/148 - loss 0.06731804 - samples/sec: 131.75 - lr: 0.000015
2021-07-23 20:14:45,486 epoch 16 - iter 70/148 - loss 0.07198459 - samples/sec: 133.29 - lr: 0.000015
2021-07-23 20:14:49,008 epoch 16 - iter 84/148 - loss 0.07269219 - samples/sec: 127.24 - lr: 0.000015
2021-07-23 20:14:52,323 epoch 16 - iter 98/148 - loss 0.07257386 - samples/sec: 135.18 - lr: 0.000015
2021-07-23 20:14:55,774 epoch 16 - iter 112/148 - loss 0.07116741 - samples/sec: 129.83 - lr: 0.000015
2021-07-23 20:14:59,167 epoch 16 - iter 126/148 - loss 0.07016520 - samples/sec: 132.09 - lr: 0.000015
2021-07-23 20:15:02,612 epoch 16 - iter 140/148 - loss 0.07614054 - samples/sec: 130.08 - lr: 0.000015
2021-07-23 20:15:04,518 ----------------------------------------------------------------------------------------------------
2021-07-23 20:15:04,518 EPOCH 16 done: loss 0.0769 - lr 0.0000150
2021-07-23 20:15:06,706 DEV : loss 0.033043913543224335 - score 0.9903
2021-07-23 20:15:06,733 BAD EPOCHS (no improvement): 1
2021-07-23 20:15:06,733 ----------------------------------------------------------------------------------------------------
2021-07-23 20:15:10,248 epoch 17 - iter 14/148 - loss 0.06538574 - samples/sec: 127.55 - lr: 0.000015
2021-07-23 20:15:13,568 epoch 17 - iter 28/148 - loss 0.07076804 - samples/sec: 134.97 - lr: 0.000015
2021-07-23 20:15:16,934 epoch 17 - iter 42/148 - loss 0.07707849 - samples/sec: 133.12 - lr: 0.000015
2021-07-23 20:15:20,432 epoch 17 - iter 56/148 - loss 0.07824992 - samples/sec: 128.11 - lr: 0.000015
2021-07-23 20:15:23,826 epoch 17 - iter 70/148 - loss 0.07578904 - samples/sec: 132.02 - lr: 0.000015
2021-07-23 20:15:27,295 epoch 17 - iter 84/148 - loss 0.07929744 - samples/sec: 129.18 - lr: 0.000015
2021-07-23 20:15:30,856 epoch 17 - iter 98/148 - loss 0.08813036 - samples/sec: 125.86 - lr: 0.000015
2021-07-23 20:15:34,403 epoch 17 - iter 112/148 - loss 0.08857195 - samples/sec: 126.31 - lr: 0.000015
2021-07-23 20:15:37,844 epoch 17 - iter 126/148 - loss 0.08734193 - samples/sec: 130.25 - lr: 0.000015
2021-07-23 20:15:41,248 epoch 17 - iter 140/148 - loss 0.08487636 - samples/sec: 131.65 - lr: 0.000015
2021-07-23 20:15:43,103 ----------------------------------------------------------------------------------------------------
2021-07-23 20:15:43,103 EPOCH 17 done: loss 0.0884 - lr 0.0000150
2021-07-23 20:15:45,284 DEV : loss 0.031300559639930725 - score 0.9912
2021-07-23 20:15:45,311 BAD EPOCHS (no improvement): 2
2021-07-23 20:15:45,312 ----------------------------------------------------------------------------------------------------
2021-07-23 20:15:49,058 epoch 18 - iter 14/148 - loss 0.06554351 - samples/sec: 119.65 - lr: 0.000015
2021-07-23 20:15:52,423 epoch 18 - iter 28/148 - loss 0.07492341 - samples/sec: 133.17 - lr: 0.000015
2021-07-23 20:15:55,743 epoch 18 - iter 42/148 - loss 0.07693497 - samples/sec: 134.97 - lr: 0.000015
2021-07-23 20:15:59,100 epoch 18 - iter 56/148 - loss 0.07677247 - samples/sec: 133.50 - lr: 0.000015
2021-07-23 20:16:02,645 epoch 18 - iter 70/148 - loss 0.07851052 - samples/sec: 126.40 - lr: 0.000015
2021-07-23 20:16:06,116 epoch 18 - iter 84/148 - loss 0.07686324 - samples/sec: 129.11 - lr: 0.000015
2021-07-23 20:16:09,526 epoch 18 - iter 98/148 - loss 0.07668177 - samples/sec: 131.40 - lr: 0.000015
2021-07-23 20:16:12,967 epoch 18 - iter 112/148 - loss 0.07808230 - samples/sec: 130.25 - lr: 0.000015
2021-07-23 20:16:16,464 epoch 18 - iter 126/148 - loss 0.07679194 - samples/sec: 128.15 - lr: 0.000015
2021-07-23 20:16:19,871 epoch 18 - iter 140/148 - loss 0.07668996 - samples/sec: 131.51 - lr: 0.000015
2021-07-23 20:16:21,789 ----------------------------------------------------------------------------------------------------
2021-07-23 20:16:21,790 EPOCH 18 done: loss 0.0772 - lr 0.0000150
2021-07-23 20:16:23,982 DEV : loss 0.03344423696398735 - score 0.9903
2021-07-23 20:16:24,009 BAD EPOCHS (no improvement): 3
2021-07-23 20:16:24,009 ----------------------------------------------------------------------------------------------------
2021-07-23 20:16:27,374 epoch 19 - iter 14/148 - loss 0.09620557 - samples/sec: 133.23 - lr: 0.000015
2021-07-23 20:16:30,781 epoch 19 - iter 28/148 - loss 0.08744424 - samples/sec: 131.53 - lr: 0.000015
2021-07-23 20:16:34,312 epoch 19 - iter 42/148 - loss 0.09084260 - samples/sec: 126.90 - lr: 0.000015
2021-07-23 20:16:37,745 epoch 19 - iter 56/148 - loss 0.08953975 - samples/sec: 130.56 - lr: 0.000015
2021-07-23 20:16:41,135 epoch 19 - iter 70/148 - loss 0.08561294 - samples/sec: 132.19 - lr: 0.000015
2021-07-23 20:16:44,613 epoch 19 - iter 84/148 - loss 0.08134585 - samples/sec: 128.85 - lr: 0.000015
2021-07-23 20:16:47,937 epoch 19 - iter 98/148 - loss 0.07600823 - samples/sec: 134.80 - lr: 0.000015
2021-07-23 20:16:51,354 epoch 19 - iter 112/148 - loss 0.07476129 - samples/sec: 131.14 - lr: 0.000015
2021-07-23 20:16:54,763 epoch 19 - iter 126/148 - loss 0.07671165 - samples/sec: 131.44 - lr: 0.000015
2021-07-23 20:16:58,295 epoch 19 - iter 140/148 - loss 0.07730628 - samples/sec: 126.87 - lr: 0.000015
2021-07-23 20:17:00,155 ----------------------------------------------------------------------------------------------------
2021-07-23 20:17:00,155 EPOCH 19 done: loss 0.0788 - lr 0.0000150
2021-07-23 20:17:02,354 DEV : loss 0.03659326583147049 - score 0.9903
Epoch    19: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 20:17:02,382 BAD EPOCHS (no improvement): 4
2021-07-23 20:17:02,382 ----------------------------------------------------------------------------------------------------
2021-07-23 20:17:05,788 epoch 20 - iter 14/148 - loss 0.08651781 - samples/sec: 131.61 - lr: 0.000008
2021-07-23 20:17:09,327 epoch 20 - iter 28/148 - loss 0.07432057 - samples/sec: 126.60 - lr: 0.000008
2021-07-23 20:17:12,775 epoch 20 - iter 42/148 - loss 0.07184057 - samples/sec: 129.98 - lr: 0.000008
2021-07-23 20:17:16,106 epoch 20 - iter 56/148 - loss 0.07400842 - samples/sec: 134.52 - lr: 0.000008
2021-07-23 20:17:19,506 epoch 20 - iter 70/148 - loss 0.07553934 - samples/sec: 131.81 - lr: 0.000008
2021-07-23 20:17:22,998 epoch 20 - iter 84/148 - loss 0.07334599 - samples/sec: 128.31 - lr: 0.000008
2021-07-23 20:17:26,491 epoch 20 - iter 98/148 - loss 0.06885899 - samples/sec: 128.33 - lr: 0.000008
2021-07-23 20:17:29,932 epoch 20 - iter 112/148 - loss 0.07106990 - samples/sec: 130.20 - lr: 0.000008
2021-07-23 20:17:33,452 epoch 20 - iter 126/148 - loss 0.07539656 - samples/sec: 127.34 - lr: 0.000008
2021-07-23 20:17:36,877 epoch 20 - iter 140/148 - loss 0.07655160 - samples/sec: 130.84 - lr: 0.000008
2021-07-23 20:17:38,673 ----------------------------------------------------------------------------------------------------
2021-07-23 20:17:38,674 EPOCH 20 done: loss 0.0758 - lr 0.0000075
2021-07-23 20:17:40,857 DEV : loss 0.030211713165044785 - score 0.993
2021-07-23 20:17:40,884 BAD EPOCHS (no improvement): 1
2021-07-23 20:17:40,885 ----------------------------------------------------------------------------------------------------
2021-07-23 20:17:44,307 epoch 21 - iter 14/148 - loss 0.06759816 - samples/sec: 130.97 - lr: 0.000008
2021-07-23 20:17:47,832 epoch 21 - iter 28/148 - loss 0.07934627 - samples/sec: 127.15 - lr: 0.000008
2021-07-23 20:17:51,109 epoch 21 - iter 42/148 - loss 0.07375157 - samples/sec: 136.75 - lr: 0.000008
2021-07-23 20:17:54,563 epoch 21 - iter 56/148 - loss 0.07413923 - samples/sec: 129.73 - lr: 0.000008
2021-07-23 20:17:57,949 epoch 21 - iter 70/148 - loss 0.07616037 - samples/sec: 132.36 - lr: 0.000008
2021-07-23 20:18:01,491 epoch 21 - iter 84/148 - loss 0.07584384 - samples/sec: 126.48 - lr: 0.000008
2021-07-23 20:18:04,935 epoch 21 - iter 98/148 - loss 0.07418956 - samples/sec: 130.13 - lr: 0.000008
2021-07-23 20:18:08,432 epoch 21 - iter 112/148 - loss 0.07433607 - samples/sec: 128.16 - lr: 0.000008
2021-07-23 20:18:11,940 epoch 21 - iter 126/148 - loss 0.07697225 - samples/sec: 127.73 - lr: 0.000008
2021-07-23 20:18:15,375 epoch 21 - iter 140/148 - loss 0.07766406 - samples/sec: 130.44 - lr: 0.000008
2021-07-23 20:18:17,220 ----------------------------------------------------------------------------------------------------
2021-07-23 20:18:17,220 EPOCH 21 done: loss 0.0796 - lr 0.0000075
2021-07-23 20:18:19,416 DEV : loss 0.03188906982541084 - score 0.9903
2021-07-23 20:18:19,444 BAD EPOCHS (no improvement): 2
2021-07-23 20:18:19,444 ----------------------------------------------------------------------------------------------------
2021-07-23 20:18:22,928 epoch 22 - iter 14/148 - loss 0.08304543 - samples/sec: 128.66 - lr: 0.000008
2021-07-23 20:18:26,225 epoch 22 - iter 28/148 - loss 0.06959708 - samples/sec: 135.91 - lr: 0.000008
2021-07-23 20:18:29,531 epoch 22 - iter 42/148 - loss 0.07036574 - samples/sec: 135.57 - lr: 0.000008
2021-07-23 20:18:32,976 epoch 22 - iter 56/148 - loss 0.07435877 - samples/sec: 130.07 - lr: 0.000008
2021-07-23 20:18:36,427 epoch 22 - iter 70/148 - loss 0.07411339 - samples/sec: 129.86 - lr: 0.000008
2021-07-23 20:18:39,959 epoch 22 - iter 84/148 - loss 0.07614268 - samples/sec: 126.87 - lr: 0.000008
2021-07-23 20:18:43,292 epoch 22 - iter 98/148 - loss 0.07384057 - samples/sec: 134.45 - lr: 0.000008
2021-07-23 20:18:46,725 epoch 22 - iter 112/148 - loss 0.07340920 - samples/sec: 130.55 - lr: 0.000008
2021-07-23 20:18:50,235 epoch 22 - iter 126/148 - loss 0.07553768 - samples/sec: 127.64 - lr: 0.000008
2021-07-23 20:18:53,796 epoch 22 - iter 140/148 - loss 0.07531867 - samples/sec: 125.85 - lr: 0.000008
2021-07-23 20:18:55,634 ----------------------------------------------------------------------------------------------------
2021-07-23 20:18:55,634 EPOCH 22 done: loss 0.0756 - lr 0.0000075
2021-07-23 20:18:57,842 DEV : loss 0.02957732602953911 - score 0.9921
2021-07-23 20:18:57,869 BAD EPOCHS (no improvement): 3
2021-07-23 20:18:57,870 ----------------------------------------------------------------------------------------------------
2021-07-23 20:19:01,424 epoch 23 - iter 14/148 - loss 0.06332544 - samples/sec: 126.12 - lr: 0.000008
2021-07-23 20:19:04,773 epoch 23 - iter 28/148 - loss 0.06475806 - samples/sec: 133.82 - lr: 0.000008
2021-07-23 20:19:08,352 epoch 23 - iter 42/148 - loss 0.07640347 - samples/sec: 125.18 - lr: 0.000008
2021-07-23 20:19:11,808 epoch 23 - iter 56/148 - loss 0.07675360 - samples/sec: 129.69 - lr: 0.000008
2021-07-23 20:19:15,218 epoch 23 - iter 70/148 - loss 0.07797754 - samples/sec: 131.40 - lr: 0.000008
2021-07-23 20:19:18,558 epoch 23 - iter 84/148 - loss 0.07950743 - samples/sec: 134.18 - lr: 0.000008
2021-07-23 20:19:21,972 epoch 23 - iter 98/148 - loss 0.07774852 - samples/sec: 131.28 - lr: 0.000008
2021-07-23 20:19:25,523 epoch 23 - iter 112/148 - loss 0.07825052 - samples/sec: 126.18 - lr: 0.000008
2021-07-23 20:19:29,024 epoch 23 - iter 126/148 - loss 0.08183429 - samples/sec: 127.98 - lr: 0.000008
2021-07-23 20:19:32,570 epoch 23 - iter 140/148 - loss 0.08204693 - samples/sec: 126.38 - lr: 0.000008
2021-07-23 20:19:34,342 ----------------------------------------------------------------------------------------------------
2021-07-23 20:19:34,342 EPOCH 23 done: loss 0.0837 - lr 0.0000075
2021-07-23 20:19:36,535 DEV : loss 0.03067571297287941 - score 0.9921
Epoch    23: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 20:19:36,563 BAD EPOCHS (no improvement): 4
2021-07-23 20:19:36,563 ----------------------------------------------------------------------------------------------------
2021-07-23 20:19:40,087 epoch 24 - iter 14/148 - loss 0.07185551 - samples/sec: 127.20 - lr: 0.000004
2021-07-23 20:19:43,716 epoch 24 - iter 28/148 - loss 0.07302116 - samples/sec: 123.49 - lr: 0.000004
2021-07-23 20:19:47,126 epoch 24 - iter 42/148 - loss 0.07337230 - samples/sec: 131.44 - lr: 0.000004
2021-07-23 20:19:50,512 epoch 24 - iter 56/148 - loss 0.07115812 - samples/sec: 132.32 - lr: 0.000004
2021-07-23 20:19:53,871 epoch 24 - iter 70/148 - loss 0.07232266 - samples/sec: 133.43 - lr: 0.000004
2021-07-23 20:19:57,152 epoch 24 - iter 84/148 - loss 0.07254781 - samples/sec: 136.56 - lr: 0.000004
2021-07-23 20:20:00,583 epoch 24 - iter 98/148 - loss 0.07138143 - samples/sec: 130.62 - lr: 0.000004
2021-07-23 20:20:04,065 epoch 24 - iter 112/148 - loss 0.07194577 - samples/sec: 128.71 - lr: 0.000004
2021-07-23 20:20:07,546 epoch 24 - iter 126/148 - loss 0.07308537 - samples/sec: 128.73 - lr: 0.000004
2021-07-23 20:20:10,945 epoch 24 - iter 140/148 - loss 0.07128084 - samples/sec: 131.85 - lr: 0.000004
2021-07-23 20:20:12,717 ----------------------------------------------------------------------------------------------------
2021-07-23 20:20:12,718 EPOCH 24 done: loss 0.0704 - lr 0.0000038
2021-07-23 20:20:14,909 DEV : loss 0.028467077761888504 - score 0.993
2021-07-23 20:20:14,937 BAD EPOCHS (no improvement): 1
2021-07-23 20:20:14,937 ----------------------------------------------------------------------------------------------------
2021-07-23 20:20:18,327 epoch 25 - iter 14/148 - loss 0.08791863 - samples/sec: 132.26 - lr: 0.000004
2021-07-23 20:20:21,825 epoch 25 - iter 28/148 - loss 0.07149638 - samples/sec: 128.08 - lr: 0.000004
2021-07-23 20:20:25,192 epoch 25 - iter 42/148 - loss 0.07172870 - samples/sec: 133.12 - lr: 0.000004
2021-07-23 20:20:28,700 epoch 25 - iter 56/148 - loss 0.07977116 - samples/sec: 127.74 - lr: 0.000004
2021-07-23 20:20:32,027 epoch 25 - iter 70/148 - loss 0.08538677 - samples/sec: 134.70 - lr: 0.000004
2021-07-23 20:20:35,413 epoch 25 - iter 84/148 - loss 0.08346191 - samples/sec: 132.35 - lr: 0.000004
2021-07-23 20:20:38,811 epoch 25 - iter 98/148 - loss 0.08344765 - samples/sec: 131.84 - lr: 0.000004
2021-07-23 20:20:42,191 epoch 25 - iter 112/148 - loss 0.08136521 - samples/sec: 132.58 - lr: 0.000004
2021-07-23 20:20:45,616 epoch 25 - iter 126/148 - loss 0.08351496 - samples/sec: 130.86 - lr: 0.000004
2021-07-23 20:20:49,050 epoch 25 - iter 140/148 - loss 0.08224727 - samples/sec: 130.48 - lr: 0.000004
2021-07-23 20:20:50,942 ----------------------------------------------------------------------------------------------------
2021-07-23 20:20:50,942 EPOCH 25 done: loss 0.0814 - lr 0.0000038
2021-07-23 20:20:53,125 DEV : loss 0.03141406178474426 - score 0.9921
2021-07-23 20:20:53,152 BAD EPOCHS (no improvement): 2
2021-07-23 20:20:53,152 ----------------------------------------------------------------------------------------------------
2021-07-23 20:20:56,643 epoch 26 - iter 14/148 - loss 0.09420018 - samples/sec: 128.41 - lr: 0.000004
2021-07-23 20:21:00,038 epoch 26 - iter 28/148 - loss 0.09025337 - samples/sec: 132.00 - lr: 0.000004
2021-07-23 20:21:03,464 epoch 26 - iter 42/148 - loss 0.08992936 - samples/sec: 130.80 - lr: 0.000004
2021-07-23 20:21:06,851 epoch 26 - iter 56/148 - loss 0.08496354 - samples/sec: 132.34 - lr: 0.000004
2021-07-23 20:21:10,422 epoch 26 - iter 70/148 - loss 0.08362091 - samples/sec: 125.46 - lr: 0.000004
2021-07-23 20:21:13,700 epoch 26 - iter 84/148 - loss 0.07847245 - samples/sec: 136.71 - lr: 0.000004
2021-07-23 20:21:17,096 epoch 26 - iter 98/148 - loss 0.07949448 - samples/sec: 131.97 - lr: 0.000004
2021-07-23 20:21:20,539 epoch 26 - iter 112/148 - loss 0.07824118 - samples/sec: 130.15 - lr: 0.000004
2021-07-23 20:21:23,935 epoch 26 - iter 126/148 - loss 0.07877221 - samples/sec: 131.96 - lr: 0.000004
2021-07-23 20:21:27,568 epoch 26 - iter 140/148 - loss 0.07916112 - samples/sec: 123.34 - lr: 0.000004
2021-07-23 20:21:29,383 ----------------------------------------------------------------------------------------------------
2021-07-23 20:21:29,383 EPOCH 26 done: loss 0.0783 - lr 0.0000038
2021-07-23 20:21:31,575 DEV : loss 0.028789443895220757 - score 0.993
2021-07-23 20:21:31,602 BAD EPOCHS (no improvement): 3
2021-07-23 20:21:31,603 ----------------------------------------------------------------------------------------------------
2021-07-23 20:21:35,179 epoch 27 - iter 14/148 - loss 0.06024906 - samples/sec: 125.33 - lr: 0.000004
2021-07-23 20:21:38,608 epoch 27 - iter 28/148 - loss 0.07083777 - samples/sec: 130.71 - lr: 0.000004
2021-07-23 20:21:42,121 epoch 27 - iter 42/148 - loss 0.07398008 - samples/sec: 127.54 - lr: 0.000004
2021-07-23 20:21:45,422 epoch 27 - iter 56/148 - loss 0.07922435 - samples/sec: 135.74 - lr: 0.000004
2021-07-23 20:21:49,059 epoch 27 - iter 70/148 - loss 0.08069685 - samples/sec: 123.23 - lr: 0.000004
2021-07-23 20:21:52,433 epoch 27 - iter 84/148 - loss 0.07609322 - samples/sec: 132.79 - lr: 0.000004
2021-07-23 20:21:55,912 epoch 27 - iter 98/148 - loss 0.07693241 - samples/sec: 128.83 - lr: 0.000004
2021-07-23 20:21:59,358 epoch 27 - iter 112/148 - loss 0.07802324 - samples/sec: 130.01 - lr: 0.000004
2021-07-23 20:22:02,751 epoch 27 - iter 126/148 - loss 0.08036205 - samples/sec: 132.08 - lr: 0.000004
2021-07-23 20:22:06,266 epoch 27 - iter 140/148 - loss 0.07916084 - samples/sec: 127.50 - lr: 0.000004
2021-07-23 20:22:08,074 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:08,074 EPOCH 27 done: loss 0.0793 - lr 0.0000038
2021-07-23 20:22:10,267 DEV : loss 0.029160333797335625 - score 0.9921
Epoch    27: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 20:22:10,295 BAD EPOCHS (no improvement): 4
2021-07-23 20:22:10,295 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:10,295 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:10,295 learning rate too small - quitting training!
2021-07-23 20:22:10,295 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:11,472 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:11,472 Testing using best model ...
2021-07-23 20:22:11,473 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/por.rst.cstn/best-model.pt
2021-07-23 20:22:36,458 0.9862	0.9944	0.9903
2021-07-23 20:22:36,458 
Results:
- F1-score (micro) 0.9903
- F1-score (macro) 0.9892

By class:
SENT       tp: 460 - fp: 12 - fn: 6 - precision: 0.9746 - recall: 0.9871 - f1-score: 0.9808
X          tp: 613 - fp: 3 - fn: 0 - precision: 0.9951 - recall: 1.0000 - f1-score: 0.9976
2021-07-23 20:22:36,458 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/deu.rst.pcc/
2021-07-23 20:22:36,527 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/deu.rst.pcc
2021-07-23 20:22:36,529 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/deu.rst.pcc/sent_train.txt
2021-07-23 20:22:36,530 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/deu.rst.pcc/sent_dev.txt
2021-07-23 20:22:36,532 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/deu.rst.pcc/sent_test.txt
Corpus: 3160 train + 506 dev + 1101 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 20:22:39,980 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:39,981 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 20:22:39,981 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:39,982 Corpus: "Corpus: 3160 train + 506 dev + 1101 test sentences"
2021-07-23 20:22:39,982 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:39,982 Parameters:
2021-07-23 20:22:39,982  - learning_rate: "3e-05"
2021-07-23 20:22:39,982  - mini_batch_size: "32"
2021-07-23 20:22:39,982  - patience: "3"
2021-07-23 20:22:39,982  - anneal_factor: "0.5"
2021-07-23 20:22:39,982  - max_epochs: "40"
2021-07-23 20:22:39,982  - shuffle: "True"
2021-07-23 20:22:39,982  - train_with_dev: "False"
2021-07-23 20:22:39,982  - batch_growth_annealing: "False"
2021-07-23 20:22:39,982 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:39,982 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/deu.rst.pcc"
2021-07-23 20:22:39,982 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:39,982 Device: cuda:0
2021-07-23 20:22:39,982 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:39,982 Embeddings storage mode: cpu
2021-07-23 20:22:39,985 ----------------------------------------------------------------------------------------------------
2021-07-23 20:22:45,075 epoch 1 - iter 9/99 - loss 20.51086617 - samples/sec: 56.60 - lr: 0.000030
2021-07-23 20:22:50,079 epoch 1 - iter 18/99 - loss 19.04408640 - samples/sec: 57.56 - lr: 0.000030
2021-07-23 20:22:55,130 epoch 1 - iter 27/99 - loss 17.94369260 - samples/sec: 57.02 - lr: 0.000030
2021-07-23 20:23:00,239 epoch 1 - iter 36/99 - loss 16.96923725 - samples/sec: 56.38 - lr: 0.000030
2021-07-23 20:23:05,370 epoch 1 - iter 45/99 - loss 16.10523898 - samples/sec: 56.13 - lr: 0.000030
2021-07-23 20:23:10,459 epoch 1 - iter 54/99 - loss 14.96993887 - samples/sec: 56.60 - lr: 0.000030
2021-07-23 20:23:15,476 epoch 1 - iter 63/99 - loss 13.88983447 - samples/sec: 57.42 - lr: 0.000030
2021-07-23 20:23:20,585 epoch 1 - iter 72/99 - loss 12.85246611 - samples/sec: 56.37 - lr: 0.000030
2021-07-23 20:23:25,756 epoch 1 - iter 81/99 - loss 11.88338198 - samples/sec: 55.70 - lr: 0.000030
2021-07-23 20:23:30,996 epoch 1 - iter 90/99 - loss 11.00590003 - samples/sec: 54.98 - lr: 0.000030
2021-07-23 20:23:36,128 epoch 1 - iter 99/99 - loss 10.23407121 - samples/sec: 56.12 - lr: 0.000030
2021-07-23 20:23:36,129 ----------------------------------------------------------------------------------------------------
2021-07-23 20:23:36,129 EPOCH 1 done: loss 10.2341 - lr 0.0000300
2021-07-23 20:23:42,846 DEV : loss 1.8106257915496826 - score 0.0
2021-07-23 20:23:42,858 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:23:43,455 ----------------------------------------------------------------------------------------------------
2021-07-23 20:23:45,558 epoch 2 - iter 9/99 - loss 1.99128862 - samples/sec: 137.06 - lr: 0.000030
2021-07-23 20:23:47,663 epoch 2 - iter 18/99 - loss 1.90214408 - samples/sec: 136.85 - lr: 0.000030
2021-07-23 20:23:49,735 epoch 2 - iter 27/99 - loss 1.77421286 - samples/sec: 139.03 - lr: 0.000030
2021-07-23 20:23:51,865 epoch 2 - iter 36/99 - loss 1.67334476 - samples/sec: 135.28 - lr: 0.000030
2021-07-23 20:23:53,915 epoch 2 - iter 45/99 - loss 1.58004260 - samples/sec: 140.57 - lr: 0.000030
2021-07-23 20:23:55,946 epoch 2 - iter 54/99 - loss 1.50528780 - samples/sec: 141.80 - lr: 0.000030
2021-07-23 20:23:57,996 epoch 2 - iter 63/99 - loss 1.44109680 - samples/sec: 140.54 - lr: 0.000030
2021-07-23 20:23:59,954 epoch 2 - iter 72/99 - loss 1.37378956 - samples/sec: 147.12 - lr: 0.000030
2021-07-23 20:24:02,070 epoch 2 - iter 81/99 - loss 1.31818598 - samples/sec: 136.14 - lr: 0.000030
2021-07-23 20:24:04,090 epoch 2 - iter 90/99 - loss 1.26274760 - samples/sec: 142.68 - lr: 0.000030
2021-07-23 20:24:06,099 epoch 2 - iter 99/99 - loss 1.21715277 - samples/sec: 143.40 - lr: 0.000030
2021-07-23 20:24:06,100 ----------------------------------------------------------------------------------------------------
2021-07-23 20:24:06,100 EPOCH 2 done: loss 1.2172 - lr 0.0000300
2021-07-23 20:24:07,269 DEV : loss 0.5180627703666687 - score 0.8439
2021-07-23 20:24:07,282 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:24:09,647 ----------------------------------------------------------------------------------------------------
2021-07-23 20:24:11,788 epoch 3 - iter 9/99 - loss 0.68993384 - samples/sec: 134.69 - lr: 0.000030
2021-07-23 20:24:13,834 epoch 3 - iter 18/99 - loss 0.63562645 - samples/sec: 140.84 - lr: 0.000030
2021-07-23 20:24:15,883 epoch 3 - iter 27/99 - loss 0.63735674 - samples/sec: 140.57 - lr: 0.000030
2021-07-23 20:24:17,963 epoch 3 - iter 36/99 - loss 0.62178770 - samples/sec: 138.53 - lr: 0.000030
2021-07-23 20:24:19,975 epoch 3 - iter 45/99 - loss 0.59601511 - samples/sec: 143.21 - lr: 0.000030
2021-07-23 20:24:22,032 epoch 3 - iter 54/99 - loss 0.58296983 - samples/sec: 140.05 - lr: 0.000030
2021-07-23 20:24:24,095 epoch 3 - iter 63/99 - loss 0.57051582 - samples/sec: 139.63 - lr: 0.000030
2021-07-23 20:24:26,254 epoch 3 - iter 72/99 - loss 0.55743501 - samples/sec: 133.40 - lr: 0.000030
2021-07-23 20:24:28,268 epoch 3 - iter 81/99 - loss 0.53917598 - samples/sec: 143.10 - lr: 0.000030
2021-07-23 20:24:30,355 epoch 3 - iter 90/99 - loss 0.53207203 - samples/sec: 138.02 - lr: 0.000030
2021-07-23 20:24:32,272 epoch 3 - iter 99/99 - loss 0.51952966 - samples/sec: 150.30 - lr: 0.000030
2021-07-23 20:24:32,273 ----------------------------------------------------------------------------------------------------
2021-07-23 20:24:32,273 EPOCH 3 done: loss 0.5195 - lr 0.0000300
2021-07-23 20:24:33,448 DEV : loss 0.253716379404068 - score 0.9532
2021-07-23 20:24:33,460 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:24:35,696 ----------------------------------------------------------------------------------------------------
2021-07-23 20:24:37,772 epoch 4 - iter 9/99 - loss 0.35767987 - samples/sec: 138.88 - lr: 0.000030
2021-07-23 20:24:39,930 epoch 4 - iter 18/99 - loss 0.36559493 - samples/sec: 133.53 - lr: 0.000030
2021-07-23 20:24:41,995 epoch 4 - iter 27/99 - loss 0.36037625 - samples/sec: 139.52 - lr: 0.000030
2021-07-23 20:24:44,076 epoch 4 - iter 36/99 - loss 0.36801551 - samples/sec: 138.41 - lr: 0.000030
2021-07-23 20:24:46,131 epoch 4 - iter 45/99 - loss 0.36332375 - samples/sec: 140.18 - lr: 0.000030
2021-07-23 20:24:48,180 epoch 4 - iter 54/99 - loss 0.35335049 - samples/sec: 140.66 - lr: 0.000030
2021-07-23 20:24:50,131 epoch 4 - iter 63/99 - loss 0.34631169 - samples/sec: 147.62 - lr: 0.000030
2021-07-23 20:24:52,136 epoch 4 - iter 72/99 - loss 0.33892614 - samples/sec: 143.71 - lr: 0.000030
2021-07-23 20:24:54,186 epoch 4 - iter 81/99 - loss 0.33144013 - samples/sec: 140.53 - lr: 0.000030
2021-07-23 20:24:56,253 epoch 4 - iter 90/99 - loss 0.32791780 - samples/sec: 139.40 - lr: 0.000030
2021-07-23 20:24:58,343 epoch 4 - iter 99/99 - loss 0.32379755 - samples/sec: 137.84 - lr: 0.000030
2021-07-23 20:24:58,343 ----------------------------------------------------------------------------------------------------
2021-07-23 20:24:58,344 EPOCH 4 done: loss 0.3238 - lr 0.0000300
2021-07-23 20:24:59,518 DEV : loss 0.1588590294122696 - score 0.9722
2021-07-23 20:24:59,531 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:25:01,708 ----------------------------------------------------------------------------------------------------
2021-07-23 20:25:03,720 epoch 5 - iter 9/99 - loss 0.26918902 - samples/sec: 143.32 - lr: 0.000030
2021-07-23 20:25:05,798 epoch 5 - iter 18/99 - loss 0.28118483 - samples/sec: 138.62 - lr: 0.000030
2021-07-23 20:25:07,838 epoch 5 - iter 27/99 - loss 0.27889049 - samples/sec: 141.22 - lr: 0.000030
2021-07-23 20:25:09,999 epoch 5 - iter 36/99 - loss 0.27047168 - samples/sec: 133.32 - lr: 0.000030
2021-07-23 20:25:12,104 epoch 5 - iter 45/99 - loss 0.26872486 - samples/sec: 136.89 - lr: 0.000030
2021-07-23 20:25:14,196 epoch 5 - iter 54/99 - loss 0.26180013 - samples/sec: 137.71 - lr: 0.000030
2021-07-23 20:25:16,212 epoch 5 - iter 63/99 - loss 0.25635961 - samples/sec: 142.93 - lr: 0.000030
2021-07-23 20:25:18,272 epoch 5 - iter 72/99 - loss 0.24881903 - samples/sec: 139.80 - lr: 0.000030
2021-07-23 20:25:20,392 epoch 5 - iter 81/99 - loss 0.24496360 - samples/sec: 135.92 - lr: 0.000030
2021-07-23 20:25:22,452 epoch 5 - iter 90/99 - loss 0.24497602 - samples/sec: 139.85 - lr: 0.000030
2021-07-23 20:25:24,402 epoch 5 - iter 99/99 - loss 0.23963173 - samples/sec: 147.72 - lr: 0.000030
2021-07-23 20:25:24,403 ----------------------------------------------------------------------------------------------------
2021-07-23 20:25:24,403 EPOCH 5 done: loss 0.2396 - lr 0.0000300
2021-07-23 20:25:25,575 DEV : loss 0.11746498942375183 - score 0.9779
2021-07-23 20:25:25,587 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:25:27,886 ----------------------------------------------------------------------------------------------------
2021-07-23 20:25:30,060 epoch 6 - iter 9/99 - loss 0.21147295 - samples/sec: 132.62 - lr: 0.000030
2021-07-23 20:25:32,120 epoch 6 - iter 18/99 - loss 0.21725327 - samples/sec: 139.88 - lr: 0.000030
2021-07-23 20:25:34,175 epoch 6 - iter 27/99 - loss 0.22225157 - samples/sec: 140.21 - lr: 0.000030
2021-07-23 20:25:36,194 epoch 6 - iter 36/99 - loss 0.21639326 - samples/sec: 142.66 - lr: 0.000030
2021-07-23 20:25:38,231 epoch 6 - iter 45/99 - loss 0.22793128 - samples/sec: 141.43 - lr: 0.000030
2021-07-23 20:25:40,316 epoch 6 - iter 54/99 - loss 0.21501518 - samples/sec: 138.21 - lr: 0.000030
2021-07-23 20:25:42,340 epoch 6 - iter 63/99 - loss 0.21129569 - samples/sec: 142.31 - lr: 0.000030
2021-07-23 20:25:44,393 epoch 6 - iter 72/99 - loss 0.21474570 - samples/sec: 140.33 - lr: 0.000030
2021-07-23 20:25:46,447 epoch 6 - iter 81/99 - loss 0.20892901 - samples/sec: 140.23 - lr: 0.000030
2021-07-23 20:25:48,555 epoch 6 - iter 90/99 - loss 0.20794649 - samples/sec: 136.71 - lr: 0.000030
2021-07-23 20:25:50,495 epoch 6 - iter 99/99 - loss 0.21021232 - samples/sec: 148.50 - lr: 0.000030
2021-07-23 20:25:50,496 ----------------------------------------------------------------------------------------------------
2021-07-23 20:25:50,496 EPOCH 6 done: loss 0.2102 - lr 0.0000300
2021-07-23 20:25:51,670 DEV : loss 0.09681730717420578 - score 0.9779
2021-07-23 20:25:51,683 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:25:53,745 ----------------------------------------------------------------------------------------------------
2021-07-23 20:25:55,764 epoch 7 - iter 9/99 - loss 0.15292939 - samples/sec: 142.87 - lr: 0.000030
2021-07-23 20:25:57,754 epoch 7 - iter 18/99 - loss 0.19292034 - samples/sec: 144.77 - lr: 0.000030
2021-07-23 20:25:59,803 epoch 7 - iter 27/99 - loss 0.18519301 - samples/sec: 140.57 - lr: 0.000030
2021-07-23 20:26:01,836 epoch 7 - iter 36/99 - loss 0.17937470 - samples/sec: 141.68 - lr: 0.000030
2021-07-23 20:26:03,931 epoch 7 - iter 45/99 - loss 0.17919023 - samples/sec: 137.57 - lr: 0.000030
2021-07-23 20:26:06,096 epoch 7 - iter 54/99 - loss 0.17921974 - samples/sec: 133.08 - lr: 0.000030
2021-07-23 20:26:08,147 epoch 7 - iter 63/99 - loss 0.17416859 - samples/sec: 140.42 - lr: 0.000030
2021-07-23 20:26:10,208 epoch 7 - iter 72/99 - loss 0.17400861 - samples/sec: 139.81 - lr: 0.000030
2021-07-23 20:26:12,358 epoch 7 - iter 81/99 - loss 0.17798594 - samples/sec: 133.96 - lr: 0.000030
2021-07-23 20:26:14,372 epoch 7 - iter 90/99 - loss 0.17825709 - samples/sec: 143.05 - lr: 0.000030
2021-07-23 20:26:16,487 epoch 7 - iter 99/99 - loss 0.17706707 - samples/sec: 136.25 - lr: 0.000030
2021-07-23 20:26:16,488 ----------------------------------------------------------------------------------------------------
2021-07-23 20:26:16,488 EPOCH 7 done: loss 0.1771 - lr 0.0000300
2021-07-23 20:26:17,654 DEV : loss 0.08244490623474121 - score 0.9766
2021-07-23 20:26:17,667 BAD EPOCHS (no improvement): 1
2021-07-23 20:26:17,667 ----------------------------------------------------------------------------------------------------
2021-07-23 20:26:19,735 epoch 8 - iter 9/99 - loss 0.14318133 - samples/sec: 139.39 - lr: 0.000030
2021-07-23 20:26:21,875 epoch 8 - iter 18/99 - loss 0.15465977 - samples/sec: 134.60 - lr: 0.000030
2021-07-23 20:26:23,937 epoch 8 - iter 27/99 - loss 0.16126971 - samples/sec: 139.71 - lr: 0.000030
2021-07-23 20:26:25,975 epoch 8 - iter 36/99 - loss 0.15995482 - samples/sec: 141.39 - lr: 0.000030
2021-07-23 20:26:27,988 epoch 8 - iter 45/99 - loss 0.16594892 - samples/sec: 143.12 - lr: 0.000030
2021-07-23 20:26:29,944 epoch 8 - iter 54/99 - loss 0.17355096 - samples/sec: 147.24 - lr: 0.000030
2021-07-23 20:26:32,095 epoch 8 - iter 63/99 - loss 0.17006066 - samples/sec: 133.93 - lr: 0.000030
2021-07-23 20:26:34,192 epoch 8 - iter 72/99 - loss 0.16852123 - samples/sec: 137.43 - lr: 0.000030
2021-07-23 20:26:36,292 epoch 8 - iter 81/99 - loss 0.16654891 - samples/sec: 137.18 - lr: 0.000030
2021-07-23 20:26:38,364 epoch 8 - iter 90/99 - loss 0.16352116 - samples/sec: 139.05 - lr: 0.000030
2021-07-23 20:26:40,348 epoch 8 - iter 99/99 - loss 0.16214359 - samples/sec: 145.18 - lr: 0.000030
2021-07-23 20:26:40,349 ----------------------------------------------------------------------------------------------------
2021-07-23 20:26:40,349 EPOCH 8 done: loss 0.1621 - lr 0.0000300
2021-07-23 20:26:41,514 DEV : loss 0.0754651352763176 - score 0.9794
2021-07-23 20:26:41,530 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:26:43,782 ----------------------------------------------------------------------------------------------------
2021-07-23 20:26:45,901 epoch 9 - iter 9/99 - loss 0.13349179 - samples/sec: 136.06 - lr: 0.000030
2021-07-23 20:26:47,975 epoch 9 - iter 18/99 - loss 0.15361090 - samples/sec: 138.89 - lr: 0.000030
2021-07-23 20:26:49,987 epoch 9 - iter 27/99 - loss 0.15752215 - samples/sec: 143.16 - lr: 0.000030
2021-07-23 20:26:52,083 epoch 9 - iter 36/99 - loss 0.16076191 - samples/sec: 137.49 - lr: 0.000030
2021-07-23 20:26:54,103 epoch 9 - iter 45/99 - loss 0.15734529 - samples/sec: 142.60 - lr: 0.000030
2021-07-23 20:26:56,241 epoch 9 - iter 54/99 - loss 0.15772996 - samples/sec: 134.78 - lr: 0.000030
2021-07-23 20:26:58,252 epoch 9 - iter 63/99 - loss 0.15173636 - samples/sec: 143.22 - lr: 0.000030
2021-07-23 20:27:00,379 epoch 9 - iter 72/99 - loss 0.15554931 - samples/sec: 135.47 - lr: 0.000030
2021-07-23 20:27:02,491 epoch 9 - iter 81/99 - loss 0.15560127 - samples/sec: 136.38 - lr: 0.000030
2021-07-23 20:27:04,503 epoch 9 - iter 90/99 - loss 0.15591545 - samples/sec: 143.18 - lr: 0.000030
2021-07-23 20:27:06,476 epoch 9 - iter 99/99 - loss 0.15791401 - samples/sec: 146.05 - lr: 0.000030
2021-07-23 20:27:06,477 ----------------------------------------------------------------------------------------------------
2021-07-23 20:27:06,477 EPOCH 9 done: loss 0.1579 - lr 0.0000300
2021-07-23 20:27:07,642 DEV : loss 0.07022637128829956 - score 0.9822
2021-07-23 20:27:07,655 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:27:09,934 ----------------------------------------------------------------------------------------------------
2021-07-23 20:27:12,112 epoch 10 - iter 9/99 - loss 0.15888258 - samples/sec: 132.44 - lr: 0.000030
2021-07-23 20:27:14,062 epoch 10 - iter 18/99 - loss 0.13270663 - samples/sec: 147.69 - lr: 0.000030
2021-07-23 20:27:16,248 epoch 10 - iter 27/99 - loss 0.13325080 - samples/sec: 131.83 - lr: 0.000030
2021-07-23 20:27:18,379 epoch 10 - iter 36/99 - loss 0.13710044 - samples/sec: 135.20 - lr: 0.000030
2021-07-23 20:27:20,492 epoch 10 - iter 45/99 - loss 0.14337718 - samples/sec: 136.34 - lr: 0.000030
2021-07-23 20:27:22,508 epoch 10 - iter 54/99 - loss 0.13894382 - samples/sec: 142.85 - lr: 0.000030
2021-07-23 20:27:24,574 epoch 10 - iter 63/99 - loss 0.13519919 - samples/sec: 139.46 - lr: 0.000030
2021-07-23 20:27:26,593 epoch 10 - iter 72/99 - loss 0.14064224 - samples/sec: 142.71 - lr: 0.000030
2021-07-23 20:27:28,615 epoch 10 - iter 81/99 - loss 0.14348188 - samples/sec: 142.46 - lr: 0.000030
2021-07-23 20:27:30,667 epoch 10 - iter 90/99 - loss 0.14456722 - samples/sec: 140.41 - lr: 0.000030
2021-07-23 20:27:32,667 epoch 10 - iter 99/99 - loss 0.14523275 - samples/sec: 144.06 - lr: 0.000030
2021-07-23 20:27:32,668 ----------------------------------------------------------------------------------------------------
2021-07-23 20:27:32,668 EPOCH 10 done: loss 0.1452 - lr 0.0000300
2021-07-23 20:27:33,834 DEV : loss 0.06499764323234558 - score 0.9878
2021-07-23 20:27:33,847 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:27:36,090 ----------------------------------------------------------------------------------------------------
2021-07-23 20:27:38,179 epoch 11 - iter 9/99 - loss 0.13017703 - samples/sec: 138.07 - lr: 0.000030
2021-07-23 20:27:40,272 epoch 11 - iter 18/99 - loss 0.12213036 - samples/sec: 137.60 - lr: 0.000030
2021-07-23 20:27:42,234 epoch 11 - iter 27/99 - loss 0.12589621 - samples/sec: 146.86 - lr: 0.000030
2021-07-23 20:27:44,219 epoch 11 - iter 36/99 - loss 0.12999167 - samples/sec: 145.16 - lr: 0.000030
2021-07-23 20:27:46,235 epoch 11 - iter 45/99 - loss 0.13293978 - samples/sec: 142.91 - lr: 0.000030
2021-07-23 20:27:48,328 epoch 11 - iter 54/99 - loss 0.13391059 - samples/sec: 137.60 - lr: 0.000030
2021-07-23 20:27:50,455 epoch 11 - iter 63/99 - loss 0.13697723 - samples/sec: 135.43 - lr: 0.000030
2021-07-23 20:27:52,449 epoch 11 - iter 72/99 - loss 0.13684692 - samples/sec: 144.54 - lr: 0.000030
2021-07-23 20:27:54,481 epoch 11 - iter 81/99 - loss 0.13256077 - samples/sec: 141.78 - lr: 0.000030
2021-07-23 20:27:56,432 epoch 11 - iter 90/99 - loss 0.13698943 - samples/sec: 147.66 - lr: 0.000030
2021-07-23 20:27:58,514 epoch 11 - iter 99/99 - loss 0.13696776 - samples/sec: 138.35 - lr: 0.000030
2021-07-23 20:27:58,515 ----------------------------------------------------------------------------------------------------
2021-07-23 20:27:58,515 EPOCH 11 done: loss 0.1370 - lr 0.0000300
2021-07-23 20:27:59,684 DEV : loss 0.07003776729106903 - score 0.9798
2021-07-23 20:27:59,697 BAD EPOCHS (no improvement): 1
2021-07-23 20:27:59,697 ----------------------------------------------------------------------------------------------------
2021-07-23 20:28:01,656 epoch 12 - iter 9/99 - loss 0.11103276 - samples/sec: 147.14 - lr: 0.000030
2021-07-23 20:28:03,763 epoch 12 - iter 18/99 - loss 0.11241142 - samples/sec: 136.76 - lr: 0.000030
2021-07-23 20:28:05,872 epoch 12 - iter 27/99 - loss 0.10673466 - samples/sec: 136.57 - lr: 0.000030
2021-07-23 20:28:07,944 epoch 12 - iter 36/99 - loss 0.12351098 - samples/sec: 139.04 - lr: 0.000030
2021-07-23 20:28:09,915 epoch 12 - iter 45/99 - loss 0.12855413 - samples/sec: 146.18 - lr: 0.000030
2021-07-23 20:28:11,959 epoch 12 - iter 54/99 - loss 0.13464297 - samples/sec: 140.98 - lr: 0.000030
2021-07-23 20:28:14,071 epoch 12 - iter 63/99 - loss 0.13823260 - samples/sec: 136.39 - lr: 0.000030
2021-07-23 20:28:16,268 epoch 12 - iter 72/99 - loss 0.13272768 - samples/sec: 131.11 - lr: 0.000030
2021-07-23 20:28:18,227 epoch 12 - iter 81/99 - loss 0.12824440 - samples/sec: 147.08 - lr: 0.000030
2021-07-23 20:28:20,335 epoch 12 - iter 90/99 - loss 0.13246663 - samples/sec: 136.67 - lr: 0.000030
2021-07-23 20:28:22,314 epoch 12 - iter 99/99 - loss 0.13295518 - samples/sec: 145.56 - lr: 0.000030
2021-07-23 20:28:22,315 ----------------------------------------------------------------------------------------------------
2021-07-23 20:28:22,315 EPOCH 12 done: loss 0.1330 - lr 0.0000300
2021-07-23 20:28:23,490 DEV : loss 0.058124247938394547 - score 0.9863
2021-07-23 20:28:23,506 BAD EPOCHS (no improvement): 2
2021-07-23 20:28:23,506 ----------------------------------------------------------------------------------------------------
2021-07-23 20:28:25,607 epoch 13 - iter 9/99 - loss 0.11696513 - samples/sec: 137.17 - lr: 0.000030
2021-07-23 20:28:27,763 epoch 13 - iter 18/99 - loss 0.11760184 - samples/sec: 133.64 - lr: 0.000030
2021-07-23 20:28:29,864 epoch 13 - iter 27/99 - loss 0.12146871 - samples/sec: 137.13 - lr: 0.000030
2021-07-23 20:28:31,973 epoch 13 - iter 36/99 - loss 0.12015216 - samples/sec: 136.63 - lr: 0.000030
2021-07-23 20:28:33,979 epoch 13 - iter 45/99 - loss 0.11662847 - samples/sec: 143.57 - lr: 0.000030
2021-07-23 20:28:36,095 epoch 13 - iter 54/99 - loss 0.11923853 - samples/sec: 136.19 - lr: 0.000030
2021-07-23 20:28:38,076 epoch 13 - iter 63/99 - loss 0.12158938 - samples/sec: 145.36 - lr: 0.000030
2021-07-23 20:28:40,099 epoch 13 - iter 72/99 - loss 0.12548064 - samples/sec: 142.43 - lr: 0.000030
2021-07-23 20:28:42,164 epoch 13 - iter 81/99 - loss 0.12600809 - samples/sec: 139.50 - lr: 0.000030
2021-07-23 20:28:44,176 epoch 13 - iter 90/99 - loss 0.12494384 - samples/sec: 143.22 - lr: 0.000030
2021-07-23 20:28:46,264 epoch 13 - iter 99/99 - loss 0.12685885 - samples/sec: 137.97 - lr: 0.000030
2021-07-23 20:28:46,265 ----------------------------------------------------------------------------------------------------
2021-07-23 20:28:46,265 EPOCH 13 done: loss 0.1269 - lr 0.0000300
2021-07-23 20:28:47,437 DEV : loss 0.05717867612838745 - score 0.9864
2021-07-23 20:28:47,454 BAD EPOCHS (no improvement): 3
2021-07-23 20:28:47,454 ----------------------------------------------------------------------------------------------------
2021-07-23 20:28:49,560 epoch 14 - iter 9/99 - loss 0.14580598 - samples/sec: 136.85 - lr: 0.000030
2021-07-23 20:28:51,624 epoch 14 - iter 18/99 - loss 0.13165402 - samples/sec: 139.58 - lr: 0.000030
2021-07-23 20:28:53,783 epoch 14 - iter 27/99 - loss 0.13496145 - samples/sec: 133.48 - lr: 0.000030
2021-07-23 20:28:55,876 epoch 14 - iter 36/99 - loss 0.12470893 - samples/sec: 137.63 - lr: 0.000030
2021-07-23 20:28:57,993 epoch 14 - iter 45/99 - loss 0.11541470 - samples/sec: 136.08 - lr: 0.000030
2021-07-23 20:29:00,016 epoch 14 - iter 54/99 - loss 0.11596710 - samples/sec: 142.37 - lr: 0.000030
2021-07-23 20:29:02,156 epoch 14 - iter 63/99 - loss 0.11410007 - samples/sec: 134.68 - lr: 0.000030
2021-07-23 20:29:04,100 epoch 14 - iter 72/99 - loss 0.11545461 - samples/sec: 148.17 - lr: 0.000030
2021-07-23 20:29:06,030 epoch 14 - iter 81/99 - loss 0.11765985 - samples/sec: 149.26 - lr: 0.000030
2021-07-23 20:29:08,174 epoch 14 - iter 90/99 - loss 0.11848473 - samples/sec: 134.35 - lr: 0.000030
2021-07-23 20:29:10,160 epoch 14 - iter 99/99 - loss 0.11697583 - samples/sec: 145.09 - lr: 0.000030
2021-07-23 20:29:10,161 ----------------------------------------------------------------------------------------------------
2021-07-23 20:29:10,161 EPOCH 14 done: loss 0.1170 - lr 0.0000300
2021-07-23 20:29:11,327 DEV : loss 0.05957559123635292 - score 0.9825
Epoch    14: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 20:29:11,342 BAD EPOCHS (no improvement): 4
2021-07-23 20:29:11,342 ----------------------------------------------------------------------------------------------------
2021-07-23 20:29:13,388 epoch 15 - iter 9/99 - loss 0.15383255 - samples/sec: 140.91 - lr: 0.000015
2021-07-23 20:29:15,371 epoch 15 - iter 18/99 - loss 0.13662271 - samples/sec: 145.32 - lr: 0.000015
2021-07-23 20:29:17,432 epoch 15 - iter 27/99 - loss 0.12379075 - samples/sec: 139.78 - lr: 0.000015
2021-07-23 20:29:19,603 epoch 15 - iter 36/99 - loss 0.12609569 - samples/sec: 132.66 - lr: 0.000015
2021-07-23 20:29:21,724 epoch 15 - iter 45/99 - loss 0.12191176 - samples/sec: 135.83 - lr: 0.000015
2021-07-23 20:29:23,739 epoch 15 - iter 54/99 - loss 0.11852208 - samples/sec: 143.00 - lr: 0.000015
2021-07-23 20:29:25,884 epoch 15 - iter 63/99 - loss 0.11953430 - samples/sec: 134.27 - lr: 0.000015
2021-07-23 20:29:27,927 epoch 15 - iter 72/99 - loss 0.12486199 - samples/sec: 141.05 - lr: 0.000015
2021-07-23 20:29:29,931 epoch 15 - iter 81/99 - loss 0.12080976 - samples/sec: 143.73 - lr: 0.000015
2021-07-23 20:29:32,016 epoch 15 - iter 90/99 - loss 0.11836400 - samples/sec: 138.20 - lr: 0.000015
2021-07-23 20:29:34,051 epoch 15 - iter 99/99 - loss 0.11783935 - samples/sec: 141.58 - lr: 0.000015
2021-07-23 20:29:34,052 ----------------------------------------------------------------------------------------------------
2021-07-23 20:29:34,052 EPOCH 15 done: loss 0.1178 - lr 0.0000150
2021-07-23 20:29:35,219 DEV : loss 0.058636851608753204 - score 0.9838
2021-07-23 20:29:35,232 BAD EPOCHS (no improvement): 1
2021-07-23 20:29:35,232 ----------------------------------------------------------------------------------------------------
2021-07-23 20:29:37,306 epoch 16 - iter 9/99 - loss 0.11750537 - samples/sec: 138.99 - lr: 0.000015
2021-07-23 20:29:39,405 epoch 16 - iter 18/99 - loss 0.11788820 - samples/sec: 137.29 - lr: 0.000015
2021-07-23 20:29:41,440 epoch 16 - iter 27/99 - loss 0.11613055 - samples/sec: 141.52 - lr: 0.000015
2021-07-23 20:29:43,555 epoch 16 - iter 36/99 - loss 0.10727154 - samples/sec: 136.23 - lr: 0.000015
2021-07-23 20:29:45,576 epoch 16 - iter 45/99 - loss 0.11004408 - samples/sec: 142.53 - lr: 0.000015
2021-07-23 20:29:47,664 epoch 16 - iter 54/99 - loss 0.11319904 - samples/sec: 138.00 - lr: 0.000015
2021-07-23 20:29:49,741 epoch 16 - iter 63/99 - loss 0.10995223 - samples/sec: 138.75 - lr: 0.000015
2021-07-23 20:29:51,724 epoch 16 - iter 72/99 - loss 0.10878749 - samples/sec: 145.26 - lr: 0.000015
2021-07-23 20:29:53,783 epoch 16 - iter 81/99 - loss 0.10956173 - samples/sec: 139.91 - lr: 0.000015
2021-07-23 20:29:55,948 epoch 16 - iter 90/99 - loss 0.10888210 - samples/sec: 133.08 - lr: 0.000015
2021-07-23 20:29:57,935 epoch 16 - iter 99/99 - loss 0.11119030 - samples/sec: 144.97 - lr: 0.000015
2021-07-23 20:29:57,936 ----------------------------------------------------------------------------------------------------
2021-07-23 20:29:57,936 EPOCH 16 done: loss 0.1112 - lr 0.0000150
2021-07-23 20:29:59,102 DEV : loss 0.055449988692998886 - score 0.9851
2021-07-23 20:29:59,115 BAD EPOCHS (no improvement): 2
2021-07-23 20:29:59,115 ----------------------------------------------------------------------------------------------------
2021-07-23 20:30:01,254 epoch 17 - iter 9/99 - loss 0.10802863 - samples/sec: 134.72 - lr: 0.000015
2021-07-23 20:30:03,439 epoch 17 - iter 18/99 - loss 0.10232523 - samples/sec: 131.89 - lr: 0.000015
2021-07-23 20:30:05,403 epoch 17 - iter 27/99 - loss 0.10518681 - samples/sec: 146.64 - lr: 0.000015
2021-07-23 20:30:07,551 epoch 17 - iter 36/99 - loss 0.10460240 - samples/sec: 134.14 - lr: 0.000015
2021-07-23 20:30:09,567 epoch 17 - iter 45/99 - loss 0.10771064 - samples/sec: 142.91 - lr: 0.000015
2021-07-23 20:30:11,554 epoch 17 - iter 54/99 - loss 0.10878932 - samples/sec: 144.96 - lr: 0.000015
2021-07-23 20:30:13,580 epoch 17 - iter 63/99 - loss 0.10755431 - samples/sec: 142.25 - lr: 0.000015
2021-07-23 20:30:15,681 epoch 17 - iter 72/99 - loss 0.11317072 - samples/sec: 137.11 - lr: 0.000015
2021-07-23 20:30:17,684 epoch 17 - iter 81/99 - loss 0.11287871 - samples/sec: 143.78 - lr: 0.000015
2021-07-23 20:30:19,914 epoch 17 - iter 90/99 - loss 0.11240406 - samples/sec: 129.19 - lr: 0.000015
2021-07-23 20:30:22,007 epoch 17 - iter 99/99 - loss 0.11495923 - samples/sec: 137.69 - lr: 0.000015
2021-07-23 20:30:22,008 ----------------------------------------------------------------------------------------------------
2021-07-23 20:30:22,008 EPOCH 17 done: loss 0.1150 - lr 0.0000150
2021-07-23 20:30:23,172 DEV : loss 0.05418140068650246 - score 0.9878
2021-07-23 20:30:23,185 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:30:25,443 ----------------------------------------------------------------------------------------------------
2021-07-23 20:30:27,644 epoch 18 - iter 9/99 - loss 0.13988212 - samples/sec: 131.03 - lr: 0.000015
2021-07-23 20:30:29,704 epoch 18 - iter 18/99 - loss 0.12646104 - samples/sec: 139.82 - lr: 0.000015
2021-07-23 20:30:31,723 epoch 18 - iter 27/99 - loss 0.11942735 - samples/sec: 142.71 - lr: 0.000015
2021-07-23 20:30:33,703 epoch 18 - iter 36/99 - loss 0.11755384 - samples/sec: 145.49 - lr: 0.000015
2021-07-23 20:30:35,732 epoch 18 - iter 45/99 - loss 0.11559045 - samples/sec: 141.98 - lr: 0.000015
2021-07-23 20:30:37,815 epoch 18 - iter 54/99 - loss 0.11376494 - samples/sec: 138.29 - lr: 0.000015
2021-07-23 20:30:39,940 epoch 18 - iter 63/99 - loss 0.11112315 - samples/sec: 135.61 - lr: 0.000015
2021-07-23 20:30:42,040 epoch 18 - iter 72/99 - loss 0.10922559 - samples/sec: 137.17 - lr: 0.000015
2021-07-23 20:30:44,139 epoch 18 - iter 81/99 - loss 0.10934203 - samples/sec: 137.24 - lr: 0.000015
2021-07-23 20:30:46,150 epoch 18 - iter 90/99 - loss 0.11198287 - samples/sec: 143.24 - lr: 0.000015
2021-07-23 20:30:48,216 epoch 18 - iter 99/99 - loss 0.11515910 - samples/sec: 139.49 - lr: 0.000015
2021-07-23 20:30:48,217 ----------------------------------------------------------------------------------------------------
2021-07-23 20:30:48,217 EPOCH 18 done: loss 0.1152 - lr 0.0000150
2021-07-23 20:30:49,383 DEV : loss 0.05604436621069908 - score 0.9851
2021-07-23 20:30:49,395 BAD EPOCHS (no improvement): 1
2021-07-23 20:30:49,396 ----------------------------------------------------------------------------------------------------
2021-07-23 20:30:51,504 epoch 19 - iter 9/99 - loss 0.13135554 - samples/sec: 136.71 - lr: 0.000015
2021-07-23 20:30:53,486 epoch 19 - iter 18/99 - loss 0.11099463 - samples/sec: 145.38 - lr: 0.000015
2021-07-23 20:30:55,488 epoch 19 - iter 27/99 - loss 0.11744782 - samples/sec: 143.85 - lr: 0.000015
2021-07-23 20:30:57,526 epoch 19 - iter 36/99 - loss 0.11509391 - samples/sec: 141.41 - lr: 0.000015
2021-07-23 20:30:59,553 epoch 19 - iter 45/99 - loss 0.11168069 - samples/sec: 142.15 - lr: 0.000015
2021-07-23 20:31:01,534 epoch 19 - iter 54/99 - loss 0.10897027 - samples/sec: 145.40 - lr: 0.000015
2021-07-23 20:31:03,636 epoch 19 - iter 63/99 - loss 0.10575299 - samples/sec: 137.08 - lr: 0.000015
2021-07-23 20:31:05,676 epoch 19 - iter 72/99 - loss 0.10800890 - samples/sec: 141.23 - lr: 0.000015
2021-07-23 20:31:07,787 epoch 19 - iter 81/99 - loss 0.10630780 - samples/sec: 136.46 - lr: 0.000015
2021-07-23 20:31:09,963 epoch 19 - iter 90/99 - loss 0.10480227 - samples/sec: 132.35 - lr: 0.000015
2021-07-23 20:31:11,988 epoch 19 - iter 99/99 - loss 0.10506173 - samples/sec: 142.31 - lr: 0.000015
2021-07-23 20:31:11,989 ----------------------------------------------------------------------------------------------------
2021-07-23 20:31:11,989 EPOCH 19 done: loss 0.1051 - lr 0.0000150
2021-07-23 20:31:13,162 DEV : loss 0.056709907948970795 - score 0.9837
2021-07-23 20:31:13,175 BAD EPOCHS (no improvement): 2
2021-07-23 20:31:13,175 ----------------------------------------------------------------------------------------------------
2021-07-23 20:31:15,344 epoch 20 - iter 9/99 - loss 0.16824888 - samples/sec: 132.87 - lr: 0.000015
2021-07-23 20:31:17,248 epoch 20 - iter 18/99 - loss 0.12964534 - samples/sec: 151.33 - lr: 0.000015
2021-07-23 20:31:19,382 epoch 20 - iter 27/99 - loss 0.11512300 - samples/sec: 134.96 - lr: 0.000015
2021-07-23 20:31:21,456 epoch 20 - iter 36/99 - loss 0.11997646 - samples/sec: 138.95 - lr: 0.000015
2021-07-23 20:31:23,512 epoch 20 - iter 45/99 - loss 0.11831957 - samples/sec: 140.09 - lr: 0.000015
2021-07-23 20:31:25,587 epoch 20 - iter 54/99 - loss 0.11225646 - samples/sec: 138.87 - lr: 0.000015
2021-07-23 20:31:27,669 epoch 20 - iter 63/99 - loss 0.11570849 - samples/sec: 138.37 - lr: 0.000015
2021-07-23 20:31:29,720 epoch 20 - iter 72/99 - loss 0.11222561 - samples/sec: 140.46 - lr: 0.000015
2021-07-23 20:31:31,727 epoch 20 - iter 81/99 - loss 0.11121834 - samples/sec: 143.51 - lr: 0.000015
2021-07-23 20:31:33,815 epoch 20 - iter 90/99 - loss 0.10913306 - samples/sec: 137.97 - lr: 0.000015
2021-07-23 20:31:35,854 epoch 20 - iter 99/99 - loss 0.10705637 - samples/sec: 141.30 - lr: 0.000015
2021-07-23 20:31:35,855 ----------------------------------------------------------------------------------------------------
2021-07-23 20:31:35,855 EPOCH 20 done: loss 0.1071 - lr 0.0000150
2021-07-23 20:31:37,032 DEV : loss 0.054149385541677475 - score 0.9864
2021-07-23 20:31:37,044 BAD EPOCHS (no improvement): 3
2021-07-23 20:31:37,045 ----------------------------------------------------------------------------------------------------
2021-07-23 20:31:39,209 epoch 21 - iter 9/99 - loss 0.09814466 - samples/sec: 133.18 - lr: 0.000015
2021-07-23 20:31:41,266 epoch 21 - iter 18/99 - loss 0.10974396 - samples/sec: 140.02 - lr: 0.000015
2021-07-23 20:31:43,346 epoch 21 - iter 27/99 - loss 0.10555239 - samples/sec: 138.49 - lr: 0.000015
2021-07-23 20:31:45,433 epoch 21 - iter 36/99 - loss 0.10298367 - samples/sec: 138.10 - lr: 0.000015
2021-07-23 20:31:47,442 epoch 21 - iter 45/99 - loss 0.10135752 - samples/sec: 143.39 - lr: 0.000015
2021-07-23 20:31:49,544 epoch 21 - iter 54/99 - loss 0.09839298 - samples/sec: 137.05 - lr: 0.000015
2021-07-23 20:31:51,591 epoch 21 - iter 63/99 - loss 0.10130517 - samples/sec: 140.74 - lr: 0.000015
2021-07-23 20:31:53,636 epoch 21 - iter 72/99 - loss 0.10111706 - samples/sec: 140.88 - lr: 0.000015
2021-07-23 20:31:55,668 epoch 21 - iter 81/99 - loss 0.09931604 - samples/sec: 141.78 - lr: 0.000015
2021-07-23 20:31:57,743 epoch 21 - iter 90/99 - loss 0.09790291 - samples/sec: 138.83 - lr: 0.000015
2021-07-23 20:31:59,742 epoch 21 - iter 99/99 - loss 0.09959803 - samples/sec: 144.08 - lr: 0.000015
2021-07-23 20:31:59,743 ----------------------------------------------------------------------------------------------------
2021-07-23 20:31:59,743 EPOCH 21 done: loss 0.0996 - lr 0.0000150
2021-07-23 20:32:00,920 DEV : loss 0.052824072539806366 - score 0.9878
2021-07-23 20:32:00,937 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:32:03,210 ----------------------------------------------------------------------------------------------------
2021-07-23 20:32:05,373 epoch 22 - iter 9/99 - loss 0.07693619 - samples/sec: 133.31 - lr: 0.000015
2021-07-23 20:32:07,431 epoch 22 - iter 18/99 - loss 0.07459722 - samples/sec: 139.96 - lr: 0.000015
2021-07-23 20:32:09,391 epoch 22 - iter 27/99 - loss 0.07671407 - samples/sec: 147.01 - lr: 0.000015
2021-07-23 20:32:11,471 epoch 22 - iter 36/99 - loss 0.08049018 - samples/sec: 138.49 - lr: 0.000015
2021-07-23 20:32:13,559 epoch 22 - iter 45/99 - loss 0.09834750 - samples/sec: 137.97 - lr: 0.000015
2021-07-23 20:32:15,681 epoch 22 - iter 54/99 - loss 0.10073135 - samples/sec: 135.80 - lr: 0.000015
2021-07-23 20:32:17,726 epoch 22 - iter 63/99 - loss 0.09977992 - samples/sec: 140.83 - lr: 0.000015
2021-07-23 20:32:19,736 epoch 22 - iter 72/99 - loss 0.09938288 - samples/sec: 143.34 - lr: 0.000015
2021-07-23 20:32:21,835 epoch 22 - iter 81/99 - loss 0.10063500 - samples/sec: 137.28 - lr: 0.000015
2021-07-23 20:32:23,852 epoch 22 - iter 90/99 - loss 0.10082721 - samples/sec: 142.84 - lr: 0.000015
2021-07-23 20:32:25,779 epoch 22 - iter 99/99 - loss 0.10050247 - samples/sec: 149.49 - lr: 0.000015
2021-07-23 20:32:25,780 ----------------------------------------------------------------------------------------------------
2021-07-23 20:32:25,780 EPOCH 22 done: loss 0.1005 - lr 0.0000150
2021-07-23 20:32:26,945 DEV : loss 0.052564989775419235 - score 0.9878
2021-07-23 20:32:26,958 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:32:29,247 ----------------------------------------------------------------------------------------------------
2021-07-23 20:32:31,311 epoch 23 - iter 9/99 - loss 0.08368536 - samples/sec: 139.72 - lr: 0.000015
2021-07-23 20:32:33,358 epoch 23 - iter 18/99 - loss 0.11955932 - samples/sec: 140.70 - lr: 0.000015
2021-07-23 20:32:35,340 epoch 23 - iter 27/99 - loss 0.10573586 - samples/sec: 145.38 - lr: 0.000015
2021-07-23 20:32:37,310 epoch 23 - iter 36/99 - loss 0.10294354 - samples/sec: 146.23 - lr: 0.000015
2021-07-23 20:32:39,352 epoch 23 - iter 45/99 - loss 0.10932855 - samples/sec: 141.11 - lr: 0.000015
2021-07-23 20:32:41,415 epoch 23 - iter 54/99 - loss 0.10093199 - samples/sec: 139.66 - lr: 0.000015
2021-07-23 20:32:43,423 epoch 23 - iter 63/99 - loss 0.10058334 - samples/sec: 143.45 - lr: 0.000015
2021-07-23 20:32:45,488 epoch 23 - iter 72/99 - loss 0.09953345 - samples/sec: 139.53 - lr: 0.000015
2021-07-23 20:32:47,601 epoch 23 - iter 81/99 - loss 0.09891769 - samples/sec: 136.33 - lr: 0.000015
2021-07-23 20:32:49,644 epoch 23 - iter 90/99 - loss 0.09990462 - samples/sec: 141.02 - lr: 0.000015
2021-07-23 20:32:51,659 epoch 23 - iter 99/99 - loss 0.09628631 - samples/sec: 142.95 - lr: 0.000015
2021-07-23 20:32:51,660 ----------------------------------------------------------------------------------------------------
2021-07-23 20:32:51,660 EPOCH 23 done: loss 0.0963 - lr 0.0000150
2021-07-23 20:32:52,825 DEV : loss 0.05447603762149811 - score 0.985
2021-07-23 20:32:52,837 BAD EPOCHS (no improvement): 1
2021-07-23 20:32:52,838 ----------------------------------------------------------------------------------------------------
2021-07-23 20:32:54,831 epoch 24 - iter 9/99 - loss 0.10128272 - samples/sec: 144.58 - lr: 0.000015
2021-07-23 20:32:57,048 epoch 24 - iter 18/99 - loss 0.11319318 - samples/sec: 129.95 - lr: 0.000015
2021-07-23 20:32:59,038 epoch 24 - iter 27/99 - loss 0.09992077 - samples/sec: 144.79 - lr: 0.000015
2021-07-23 20:33:01,076 epoch 24 - iter 36/99 - loss 0.10354454 - samples/sec: 141.37 - lr: 0.000015
2021-07-23 20:33:03,061 epoch 24 - iter 45/99 - loss 0.09458998 - samples/sec: 145.15 - lr: 0.000015
2021-07-23 20:33:05,154 epoch 24 - iter 54/99 - loss 0.09997167 - samples/sec: 137.65 - lr: 0.000015
2021-07-23 20:33:07,103 epoch 24 - iter 63/99 - loss 0.10039243 - samples/sec: 147.81 - lr: 0.000015
2021-07-23 20:33:09,074 epoch 24 - iter 72/99 - loss 0.09559321 - samples/sec: 146.19 - lr: 0.000015
2021-07-23 20:33:11,099 epoch 24 - iter 81/99 - loss 0.09517366 - samples/sec: 142.29 - lr: 0.000015
2021-07-23 20:33:13,240 epoch 24 - iter 90/99 - loss 0.09390341 - samples/sec: 134.55 - lr: 0.000015
2021-07-23 20:33:15,255 epoch 24 - iter 99/99 - loss 0.09973944 - samples/sec: 142.94 - lr: 0.000015
2021-07-23 20:33:15,256 ----------------------------------------------------------------------------------------------------
2021-07-23 20:33:15,256 EPOCH 24 done: loss 0.0997 - lr 0.0000150
2021-07-23 20:33:16,430 DEV : loss 0.052932873368263245 - score 0.9891
2021-07-23 20:33:16,443 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:33:18,877 ----------------------------------------------------------------------------------------------------
2021-07-23 20:33:20,939 epoch 25 - iter 9/99 - loss 0.09998212 - samples/sec: 139.78 - lr: 0.000015
2021-07-23 20:33:23,103 epoch 25 - iter 18/99 - loss 0.09889582 - samples/sec: 133.14 - lr: 0.000015
2021-07-23 20:33:25,115 epoch 25 - iter 27/99 - loss 0.10149617 - samples/sec: 143.22 - lr: 0.000015
2021-07-23 20:33:27,115 epoch 25 - iter 36/99 - loss 0.09925889 - samples/sec: 143.99 - lr: 0.000015
2021-07-23 20:33:29,220 epoch 25 - iter 45/99 - loss 0.09889965 - samples/sec: 136.90 - lr: 0.000015
2021-07-23 20:33:31,277 epoch 25 - iter 54/99 - loss 0.10007069 - samples/sec: 140.04 - lr: 0.000015
2021-07-23 20:33:33,393 epoch 25 - iter 63/99 - loss 0.10212668 - samples/sec: 136.18 - lr: 0.000015
2021-07-23 20:33:35,459 epoch 25 - iter 72/99 - loss 0.10111171 - samples/sec: 139.44 - lr: 0.000015
2021-07-23 20:33:37,479 epoch 25 - iter 81/99 - loss 0.10230075 - samples/sec: 142.60 - lr: 0.000015
2021-07-23 20:33:39,495 epoch 25 - iter 90/99 - loss 0.10882413 - samples/sec: 142.88 - lr: 0.000015
2021-07-23 20:33:41,518 epoch 25 - iter 99/99 - loss 0.10542099 - samples/sec: 142.40 - lr: 0.000015
2021-07-23 20:33:41,519 ----------------------------------------------------------------------------------------------------
2021-07-23 20:33:41,519 EPOCH 25 done: loss 0.1054 - lr 0.0000150
2021-07-23 20:33:42,694 DEV : loss 0.05467567592859268 - score 0.9878
2021-07-23 20:33:42,710 BAD EPOCHS (no improvement): 1
2021-07-23 20:33:42,711 ----------------------------------------------------------------------------------------------------
2021-07-23 20:33:44,809 epoch 26 - iter 9/99 - loss 0.09501869 - samples/sec: 137.37 - lr: 0.000015
2021-07-23 20:33:46,908 epoch 26 - iter 18/99 - loss 0.09468411 - samples/sec: 137.28 - lr: 0.000015
2021-07-23 20:33:49,009 epoch 26 - iter 27/99 - loss 0.09962988 - samples/sec: 137.06 - lr: 0.000015
2021-07-23 20:33:51,071 epoch 26 - iter 36/99 - loss 0.10731566 - samples/sec: 139.74 - lr: 0.000015
2021-07-23 20:33:53,040 epoch 26 - iter 45/99 - loss 0.10991525 - samples/sec: 146.31 - lr: 0.000015
2021-07-23 20:33:55,018 epoch 26 - iter 54/99 - loss 0.10852167 - samples/sec: 145.65 - lr: 0.000015
2021-07-23 20:33:57,200 epoch 26 - iter 63/99 - loss 0.10759878 - samples/sec: 132.06 - lr: 0.000015
2021-07-23 20:33:59,264 epoch 26 - iter 72/99 - loss 0.10867372 - samples/sec: 139.54 - lr: 0.000015
2021-07-23 20:34:01,259 epoch 26 - iter 81/99 - loss 0.10978420 - samples/sec: 144.42 - lr: 0.000015
2021-07-23 20:34:03,324 epoch 26 - iter 90/99 - loss 0.10675780 - samples/sec: 139.50 - lr: 0.000015
2021-07-23 20:34:05,323 epoch 26 - iter 99/99 - loss 0.10677667 - samples/sec: 144.19 - lr: 0.000015
2021-07-23 20:34:05,324 ----------------------------------------------------------------------------------------------------
2021-07-23 20:34:05,324 EPOCH 26 done: loss 0.1068 - lr 0.0000150
2021-07-23 20:34:06,498 DEV : loss 0.053961824625730515 - score 0.985
2021-07-23 20:34:06,511 BAD EPOCHS (no improvement): 2
2021-07-23 20:34:06,511 ----------------------------------------------------------------------------------------------------
2021-07-23 20:34:08,566 epoch 27 - iter 9/99 - loss 0.11133333 - samples/sec: 140.31 - lr: 0.000015
2021-07-23 20:34:10,670 epoch 27 - iter 18/99 - loss 0.09850933 - samples/sec: 136.88 - lr: 0.000015
2021-07-23 20:34:12,728 epoch 27 - iter 27/99 - loss 0.09209938 - samples/sec: 140.03 - lr: 0.000015
2021-07-23 20:34:14,767 epoch 27 - iter 36/99 - loss 0.08724059 - samples/sec: 141.25 - lr: 0.000015
2021-07-23 20:34:16,695 epoch 27 - iter 45/99 - loss 0.08561337 - samples/sec: 149.44 - lr: 0.000015
2021-07-23 20:34:18,828 epoch 27 - iter 54/99 - loss 0.08761113 - samples/sec: 135.09 - lr: 0.000015
2021-07-23 20:34:20,844 epoch 27 - iter 63/99 - loss 0.09655980 - samples/sec: 142.91 - lr: 0.000015
2021-07-23 20:34:22,934 epoch 27 - iter 72/99 - loss 0.09723474 - samples/sec: 137.82 - lr: 0.000015
2021-07-23 20:34:25,084 epoch 27 - iter 81/99 - loss 0.09613688 - samples/sec: 133.97 - lr: 0.000015
2021-07-23 20:34:27,104 epoch 27 - iter 90/99 - loss 0.09374973 - samples/sec: 142.63 - lr: 0.000015
2021-07-23 20:34:29,206 epoch 27 - iter 99/99 - loss 0.09387668 - samples/sec: 137.09 - lr: 0.000015
2021-07-23 20:34:29,207 ----------------------------------------------------------------------------------------------------
2021-07-23 20:34:29,207 EPOCH 27 done: loss 0.0939 - lr 0.0000150
2021-07-23 20:34:30,373 DEV : loss 0.05451521277427673 - score 0.985
2021-07-23 20:34:30,385 BAD EPOCHS (no improvement): 3
2021-07-23 20:34:30,386 ----------------------------------------------------------------------------------------------------
2021-07-23 20:34:32,448 epoch 28 - iter 9/99 - loss 0.09110664 - samples/sec: 139.79 - lr: 0.000015
2021-07-23 20:34:34,435 epoch 28 - iter 18/99 - loss 0.12612905 - samples/sec: 144.94 - lr: 0.000015
2021-07-23 20:34:36,447 epoch 28 - iter 27/99 - loss 0.10565717 - samples/sec: 143.22 - lr: 0.000015
2021-07-23 20:34:38,539 epoch 28 - iter 36/99 - loss 0.10399251 - samples/sec: 137.67 - lr: 0.000015
2021-07-23 20:34:40,568 epoch 28 - iter 45/99 - loss 0.10119041 - samples/sec: 142.00 - lr: 0.000015
2021-07-23 20:34:42,615 epoch 28 - iter 54/99 - loss 0.09650813 - samples/sec: 140.74 - lr: 0.000015
2021-07-23 20:34:44,743 epoch 28 - iter 63/99 - loss 0.09281898 - samples/sec: 135.37 - lr: 0.000015
2021-07-23 20:34:46,898 epoch 28 - iter 72/99 - loss 0.09645829 - samples/sec: 133.67 - lr: 0.000015
2021-07-23 20:34:48,936 epoch 28 - iter 81/99 - loss 0.09697810 - samples/sec: 141.36 - lr: 0.000015
2021-07-23 20:34:51,003 epoch 28 - iter 90/99 - loss 0.09644118 - samples/sec: 139.39 - lr: 0.000015
2021-07-23 20:34:53,042 epoch 28 - iter 99/99 - loss 0.09533128 - samples/sec: 141.29 - lr: 0.000015
2021-07-23 20:34:53,043 ----------------------------------------------------------------------------------------------------
2021-07-23 20:34:53,043 EPOCH 28 done: loss 0.0953 - lr 0.0000150
2021-07-23 20:34:54,206 DEV : loss 0.052117716521024704 - score 0.9863
Epoch    28: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 20:34:54,219 BAD EPOCHS (no improvement): 4
2021-07-23 20:34:54,219 ----------------------------------------------------------------------------------------------------
2021-07-23 20:34:56,283 epoch 29 - iter 9/99 - loss 0.11736681 - samples/sec: 139.69 - lr: 0.000008
2021-07-23 20:34:58,291 epoch 29 - iter 18/99 - loss 0.12479198 - samples/sec: 143.44 - lr: 0.000008
2021-07-23 20:35:00,344 epoch 29 - iter 27/99 - loss 0.10040815 - samples/sec: 140.35 - lr: 0.000008
2021-07-23 20:35:02,371 epoch 29 - iter 36/99 - loss 0.10254987 - samples/sec: 142.14 - lr: 0.000008
2021-07-23 20:35:04,427 epoch 29 - iter 45/99 - loss 0.10683979 - samples/sec: 140.11 - lr: 0.000008
2021-07-23 20:35:06,488 epoch 29 - iter 54/99 - loss 0.10806372 - samples/sec: 139.77 - lr: 0.000008
2021-07-23 20:35:08,502 epoch 29 - iter 63/99 - loss 0.10353889 - samples/sec: 143.02 - lr: 0.000008
2021-07-23 20:35:10,532 epoch 29 - iter 72/99 - loss 0.10249411 - samples/sec: 141.93 - lr: 0.000008
2021-07-23 20:35:12,584 epoch 29 - iter 81/99 - loss 0.09860375 - samples/sec: 140.38 - lr: 0.000008
2021-07-23 20:35:14,654 epoch 29 - iter 90/99 - loss 0.09793136 - samples/sec: 139.19 - lr: 0.000008
2021-07-23 20:35:16,647 epoch 29 - iter 99/99 - loss 0.09794268 - samples/sec: 144.61 - lr: 0.000008
2021-07-23 20:35:16,647 ----------------------------------------------------------------------------------------------------
2021-07-23 20:35:16,648 EPOCH 29 done: loss 0.0979 - lr 0.0000075
2021-07-23 20:35:17,811 DEV : loss 0.05440578982234001 - score 0.9878
2021-07-23 20:35:17,828 BAD EPOCHS (no improvement): 1
2021-07-23 20:35:17,828 ----------------------------------------------------------------------------------------------------
2021-07-23 20:35:19,942 epoch 30 - iter 9/99 - loss 0.09304284 - samples/sec: 136.31 - lr: 0.000008
2021-07-23 20:35:21,988 epoch 30 - iter 18/99 - loss 0.09046450 - samples/sec: 140.87 - lr: 0.000008
2021-07-23 20:35:24,035 epoch 30 - iter 27/99 - loss 0.11533465 - samples/sec: 140.71 - lr: 0.000008
2021-07-23 20:35:26,107 epoch 30 - iter 36/99 - loss 0.11220468 - samples/sec: 139.02 - lr: 0.000008
2021-07-23 20:35:28,129 epoch 30 - iter 45/99 - loss 0.10683533 - samples/sec: 142.52 - lr: 0.000008
2021-07-23 20:35:30,155 epoch 30 - iter 54/99 - loss 0.09981221 - samples/sec: 142.14 - lr: 0.000008
2021-07-23 20:35:32,252 epoch 30 - iter 63/99 - loss 0.09817265 - samples/sec: 137.44 - lr: 0.000008
2021-07-23 20:35:34,231 epoch 30 - iter 72/99 - loss 0.09612971 - samples/sec: 145.54 - lr: 0.000008
2021-07-23 20:35:36,440 epoch 30 - iter 81/99 - loss 0.09782845 - samples/sec: 130.41 - lr: 0.000008
2021-07-23 20:35:38,463 epoch 30 - iter 90/99 - loss 0.09526259 - samples/sec: 142.43 - lr: 0.000008
2021-07-23 20:35:40,307 epoch 30 - iter 99/99 - loss 0.09537634 - samples/sec: 156.22 - lr: 0.000008
2021-07-23 20:35:40,308 ----------------------------------------------------------------------------------------------------
2021-07-23 20:35:40,308 EPOCH 30 done: loss 0.0954 - lr 0.0000075
2021-07-23 20:35:41,475 DEV : loss 0.05114925652742386 - score 0.985
2021-07-23 20:35:41,492 BAD EPOCHS (no improvement): 2
2021-07-23 20:35:41,492 ----------------------------------------------------------------------------------------------------
2021-07-23 20:35:43,532 epoch 31 - iter 9/99 - loss 0.09303406 - samples/sec: 141.31 - lr: 0.000008
2021-07-23 20:35:45,532 epoch 31 - iter 18/99 - loss 0.07741038 - samples/sec: 144.03 - lr: 0.000008
2021-07-23 20:35:47,576 epoch 31 - iter 27/99 - loss 0.08283950 - samples/sec: 140.96 - lr: 0.000008
2021-07-23 20:35:49,579 epoch 31 - iter 36/99 - loss 0.08679341 - samples/sec: 143.84 - lr: 0.000008
2021-07-23 20:35:51,668 epoch 31 - iter 45/99 - loss 0.08580478 - samples/sec: 137.89 - lr: 0.000008
2021-07-23 20:35:53,783 epoch 31 - iter 54/99 - loss 0.08081034 - samples/sec: 136.22 - lr: 0.000008
2021-07-23 20:35:55,746 epoch 31 - iter 63/99 - loss 0.08296593 - samples/sec: 146.77 - lr: 0.000008
2021-07-23 20:35:57,703 epoch 31 - iter 72/99 - loss 0.08262357 - samples/sec: 147.21 - lr: 0.000008
2021-07-23 20:35:59,765 epoch 31 - iter 81/99 - loss 0.08079454 - samples/sec: 139.67 - lr: 0.000008
2021-07-23 20:36:01,855 epoch 31 - iter 90/99 - loss 0.08426006 - samples/sec: 137.88 - lr: 0.000008
2021-07-23 20:36:03,907 epoch 31 - iter 99/99 - loss 0.08535171 - samples/sec: 140.42 - lr: 0.000008
2021-07-23 20:36:03,908 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:03,908 EPOCH 31 done: loss 0.0854 - lr 0.0000075
2021-07-23 20:36:05,073 DEV : loss 0.05149709805846214 - score 0.985
2021-07-23 20:36:05,089 BAD EPOCHS (no improvement): 3
2021-07-23 20:36:05,089 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:07,086 epoch 32 - iter 9/99 - loss 0.10796519 - samples/sec: 144.33 - lr: 0.000008
2021-07-23 20:36:09,251 epoch 32 - iter 18/99 - loss 0.10525282 - samples/sec: 133.09 - lr: 0.000008
2021-07-23 20:36:11,311 epoch 32 - iter 27/99 - loss 0.09973990 - samples/sec: 139.81 - lr: 0.000008
2021-07-23 20:36:13,254 epoch 32 - iter 36/99 - loss 0.08950969 - samples/sec: 148.29 - lr: 0.000008
2021-07-23 20:36:15,302 epoch 32 - iter 45/99 - loss 0.09017418 - samples/sec: 140.70 - lr: 0.000008
2021-07-23 20:36:17,448 epoch 32 - iter 54/99 - loss 0.09125754 - samples/sec: 134.21 - lr: 0.000008
2021-07-23 20:36:19,432 epoch 32 - iter 63/99 - loss 0.09325367 - samples/sec: 145.26 - lr: 0.000008
2021-07-23 20:36:21,424 epoch 32 - iter 72/99 - loss 0.09409848 - samples/sec: 144.61 - lr: 0.000008
2021-07-23 20:36:23,511 epoch 32 - iter 81/99 - loss 0.09144066 - samples/sec: 138.01 - lr: 0.000008
2021-07-23 20:36:25,538 epoch 32 - iter 90/99 - loss 0.09027653 - samples/sec: 142.16 - lr: 0.000008
2021-07-23 20:36:27,523 epoch 32 - iter 99/99 - loss 0.09270298 - samples/sec: 145.13 - lr: 0.000008
2021-07-23 20:36:27,524 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:27,524 EPOCH 32 done: loss 0.0927 - lr 0.0000075
2021-07-23 20:36:28,688 DEV : loss 0.05255249887704849 - score 0.9851
Epoch    32: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 20:36:28,701 BAD EPOCHS (no improvement): 4
2021-07-23 20:36:28,701 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:30,952 epoch 33 - iter 9/99 - loss 0.09329944 - samples/sec: 128.02 - lr: 0.000004
2021-07-23 20:36:33,020 epoch 33 - iter 18/99 - loss 0.10644742 - samples/sec: 139.36 - lr: 0.000004
2021-07-23 20:36:35,081 epoch 33 - iter 27/99 - loss 0.08731431 - samples/sec: 139.79 - lr: 0.000004
2021-07-23 20:36:37,152 epoch 33 - iter 36/99 - loss 0.08619320 - samples/sec: 139.10 - lr: 0.000004
2021-07-23 20:36:39,190 epoch 33 - iter 45/99 - loss 0.08977178 - samples/sec: 141.34 - lr: 0.000004
2021-07-23 20:36:41,160 epoch 33 - iter 54/99 - loss 0.09970781 - samples/sec: 146.23 - lr: 0.000004
2021-07-23 20:36:43,210 epoch 33 - iter 63/99 - loss 0.10147788 - samples/sec: 140.51 - lr: 0.000004
2021-07-23 20:36:45,216 epoch 33 - iter 72/99 - loss 0.09706285 - samples/sec: 143.63 - lr: 0.000004
2021-07-23 20:36:47,219 epoch 33 - iter 81/99 - loss 0.09535699 - samples/sec: 143.80 - lr: 0.000004
2021-07-23 20:36:49,227 epoch 33 - iter 90/99 - loss 0.09483593 - samples/sec: 143.49 - lr: 0.000004
2021-07-23 20:36:51,307 epoch 33 - iter 99/99 - loss 0.09519981 - samples/sec: 138.51 - lr: 0.000004
2021-07-23 20:36:51,308 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:51,308 EPOCH 33 done: loss 0.0952 - lr 0.0000038
2021-07-23 20:36:52,477 DEV : loss 0.050863925367593765 - score 0.9864
2021-07-23 20:36:52,489 BAD EPOCHS (no improvement): 1
2021-07-23 20:36:52,490 ----------------------------------------------------------------------------------------------------
2021-07-23 20:36:54,424 epoch 34 - iter 9/99 - loss 0.07995031 - samples/sec: 148.98 - lr: 0.000004
2021-07-23 20:36:56,573 epoch 34 - iter 18/99 - loss 0.08549181 - samples/sec: 134.10 - lr: 0.000004
2021-07-23 20:36:58,708 epoch 34 - iter 27/99 - loss 0.10165396 - samples/sec: 134.91 - lr: 0.000004
2021-07-23 20:37:00,784 epoch 34 - iter 36/99 - loss 0.09856556 - samples/sec: 138.77 - lr: 0.000004
2021-07-23 20:37:02,844 epoch 34 - iter 45/99 - loss 0.09062259 - samples/sec: 139.88 - lr: 0.000004
2021-07-23 20:37:04,784 epoch 34 - iter 54/99 - loss 0.08688271 - samples/sec: 148.49 - lr: 0.000004
2021-07-23 20:37:06,871 epoch 34 - iter 63/99 - loss 0.08948352 - samples/sec: 138.02 - lr: 0.000004
2021-07-23 20:37:08,953 epoch 34 - iter 72/99 - loss 0.09369508 - samples/sec: 138.42 - lr: 0.000004
2021-07-23 20:37:10,997 epoch 34 - iter 81/99 - loss 0.09454341 - samples/sec: 140.90 - lr: 0.000004
2021-07-23 20:37:13,100 epoch 34 - iter 90/99 - loss 0.09479915 - samples/sec: 137.01 - lr: 0.000004
2021-07-23 20:37:15,160 epoch 34 - iter 99/99 - loss 0.09346488 - samples/sec: 139.83 - lr: 0.000004
2021-07-23 20:37:15,161 ----------------------------------------------------------------------------------------------------
2021-07-23 20:37:15,161 EPOCH 34 done: loss 0.0935 - lr 0.0000038
2021-07-23 20:37:16,336 DEV : loss 0.049994997680187225 - score 0.9877
2021-07-23 20:37:16,348 BAD EPOCHS (no improvement): 2
2021-07-23 20:37:16,348 ----------------------------------------------------------------------------------------------------
2021-07-23 20:37:18,472 epoch 35 - iter 9/99 - loss 0.10061913 - samples/sec: 135.72 - lr: 0.000004
2021-07-23 20:37:20,547 epoch 35 - iter 18/99 - loss 0.10516431 - samples/sec: 138.86 - lr: 0.000004
2021-07-23 20:37:22,680 epoch 35 - iter 27/99 - loss 0.09002797 - samples/sec: 135.06 - lr: 0.000004
2021-07-23 20:37:24,750 epoch 35 - iter 36/99 - loss 0.08951115 - samples/sec: 139.15 - lr: 0.000004
2021-07-23 20:37:26,784 epoch 35 - iter 45/99 - loss 0.08923307 - samples/sec: 141.67 - lr: 0.000004
2021-07-23 20:37:28,784 epoch 35 - iter 54/99 - loss 0.09335557 - samples/sec: 144.00 - lr: 0.000004
2021-07-23 20:37:30,868 epoch 35 - iter 63/99 - loss 0.09307763 - samples/sec: 138.24 - lr: 0.000004
2021-07-23 20:37:32,932 epoch 35 - iter 72/99 - loss 0.09249882 - samples/sec: 139.61 - lr: 0.000004
2021-07-23 20:37:34,980 epoch 35 - iter 81/99 - loss 0.09466018 - samples/sec: 140.64 - lr: 0.000004
2021-07-23 20:37:36,962 epoch 35 - iter 90/99 - loss 0.09163405 - samples/sec: 145.34 - lr: 0.000004
2021-07-23 20:37:39,019 epoch 35 - iter 99/99 - loss 0.09133069 - samples/sec: 140.12 - lr: 0.000004
2021-07-23 20:37:39,019 ----------------------------------------------------------------------------------------------------
2021-07-23 20:37:39,020 EPOCH 35 done: loss 0.0913 - lr 0.0000038
2021-07-23 20:37:40,192 DEV : loss 0.05061601847410202 - score 0.9877
2021-07-23 20:37:40,205 BAD EPOCHS (no improvement): 3
2021-07-23 20:37:40,205 ----------------------------------------------------------------------------------------------------
2021-07-23 20:37:42,251 epoch 36 - iter 9/99 - loss 0.05839492 - samples/sec: 140.87 - lr: 0.000004
2021-07-23 20:37:44,323 epoch 36 - iter 18/99 - loss 0.06899925 - samples/sec: 139.05 - lr: 0.000004
2021-07-23 20:37:46,403 epoch 36 - iter 27/99 - loss 0.07265441 - samples/sec: 138.52 - lr: 0.000004
2021-07-23 20:37:48,464 epoch 36 - iter 36/99 - loss 0.07248666 - samples/sec: 139.81 - lr: 0.000004
2021-07-23 20:37:50,608 epoch 36 - iter 45/99 - loss 0.08191536 - samples/sec: 134.34 - lr: 0.000004
2021-07-23 20:37:52,831 epoch 36 - iter 54/99 - loss 0.08938464 - samples/sec: 129.60 - lr: 0.000004
2021-07-23 20:37:54,965 epoch 36 - iter 63/99 - loss 0.09022504 - samples/sec: 135.02 - lr: 0.000004
2021-07-23 20:37:56,991 epoch 36 - iter 72/99 - loss 0.08528296 - samples/sec: 142.14 - lr: 0.000004
2021-07-23 20:37:58,951 epoch 36 - iter 81/99 - loss 0.08946409 - samples/sec: 147.03 - lr: 0.000004
2021-07-23 20:38:00,915 epoch 36 - iter 90/99 - loss 0.08863640 - samples/sec: 146.71 - lr: 0.000004
2021-07-23 20:38:02,870 epoch 36 - iter 99/99 - loss 0.08981686 - samples/sec: 147.35 - lr: 0.000004
2021-07-23 20:38:02,871 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:02,871 EPOCH 36 done: loss 0.0898 - lr 0.0000038
2021-07-23 20:38:04,043 DEV : loss 0.05176978558301926 - score 0.985
Epoch    36: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 20:38:04,055 BAD EPOCHS (no improvement): 4
2021-07-23 20:38:04,056 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:04,056 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:04,056 learning rate too small - quitting training!
2021-07-23 20:38:04,056 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:04,621 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:04,621 Testing using best model ...
2021-07-23 20:38:04,622 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/deu.rst.pcc/best-model.pt
2021-07-23 20:38:20,375 0.9913	0.9852	0.9882
2021-07-23 20:38:20,375 
Results:
- F1-score (micro) 0.9882
- F1-score (macro) 0.9895

By class:
SENT       tp: 443 - fp: 7 - fn: 12 - precision: 0.9844 - recall: 0.9736 - f1-score: 0.9790
X          tp: 355 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 20:38:20,375 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/spa.rst.sctb/
2021-07-23 20:38:20,448 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/spa.rst.sctb
2021-07-23 20:38:20,448 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/spa.rst.sctb/sent_train.txt
2021-07-23 20:38:20,450 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/spa.rst.sctb/sent_dev.txt
2021-07-23 20:38:20,451 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/spa.rst.sctb/sent_test.txt
Corpus: 743 train + 302 dev + 540 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 20:38:23,036 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:23,037 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 20:38:23,037 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:23,038 Corpus: "Corpus: 743 train + 302 dev + 540 test sentences"
2021-07-23 20:38:23,038 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:23,038 Parameters:
2021-07-23 20:38:23,038  - learning_rate: "3e-05"
2021-07-23 20:38:23,038  - mini_batch_size: "32"
2021-07-23 20:38:23,038  - patience: "3"
2021-07-23 20:38:23,038  - anneal_factor: "0.5"
2021-07-23 20:38:23,038  - max_epochs: "40"
2021-07-23 20:38:23,038  - shuffle: "True"
2021-07-23 20:38:23,038  - train_with_dev: "False"
2021-07-23 20:38:23,038  - batch_growth_annealing: "False"
2021-07-23 20:38:23,038 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:23,038 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/spa.rst.sctb"
2021-07-23 20:38:23,038 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:23,038 Device: cuda:0
2021-07-23 20:38:23,038 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:23,038 Embeddings storage mode: cpu
2021-07-23 20:38:23,041 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:24,224 epoch 1 - iter 2/24 - loss 8.92522287 - samples/sec: 54.11 - lr: 0.000030
2021-07-23 20:38:25,396 epoch 1 - iter 4/24 - loss 8.35884285 - samples/sec: 54.64 - lr: 0.000030
2021-07-23 20:38:26,585 epoch 1 - iter 6/24 - loss 8.26370454 - samples/sec: 53.86 - lr: 0.000030
2021-07-23 20:38:27,794 epoch 1 - iter 8/24 - loss 8.13529927 - samples/sec: 52.92 - lr: 0.000030
2021-07-23 20:38:29,004 epoch 1 - iter 10/24 - loss 7.94553008 - samples/sec: 52.90 - lr: 0.000030
2021-07-23 20:38:30,199 epoch 1 - iter 12/24 - loss 7.71813532 - samples/sec: 53.59 - lr: 0.000030
2021-07-23 20:38:31,412 epoch 1 - iter 14/24 - loss 7.55141415 - samples/sec: 52.78 - lr: 0.000030
2021-07-23 20:38:32,581 epoch 1 - iter 16/24 - loss 7.29485705 - samples/sec: 54.75 - lr: 0.000030
2021-07-23 20:38:33,774 epoch 1 - iter 18/24 - loss 7.07861866 - samples/sec: 53.65 - lr: 0.000030
2021-07-23 20:38:34,979 epoch 1 - iter 20/24 - loss 6.89356411 - samples/sec: 53.12 - lr: 0.000030
2021-07-23 20:38:36,210 epoch 1 - iter 22/24 - loss 6.76098483 - samples/sec: 52.00 - lr: 0.000030
2021-07-23 20:38:36,967 epoch 1 - iter 24/24 - loss 6.62916442 - samples/sec: 84.61 - lr: 0.000030
2021-07-23 20:38:36,968 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:36,968 EPOCH 1 done: loss 6.6292 - lr 0.0000300
2021-07-23 20:38:41,013 DEV : loss 3.3914620876312256 - score 0.0
2021-07-23 20:38:41,022 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:38:41,587 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:42,101 epoch 2 - iter 2/24 - loss 4.96476173 - samples/sec: 125.06 - lr: 0.000030
2021-07-23 20:38:42,649 epoch 2 - iter 4/24 - loss 4.77946669 - samples/sec: 116.83 - lr: 0.000030
2021-07-23 20:38:43,146 epoch 2 - iter 6/24 - loss 4.53967667 - samples/sec: 128.72 - lr: 0.000030
2021-07-23 20:38:43,686 epoch 2 - iter 8/24 - loss 4.57665253 - samples/sec: 118.66 - lr: 0.000030
2021-07-23 20:38:44,204 epoch 2 - iter 10/24 - loss 4.43979216 - samples/sec: 123.60 - lr: 0.000030
2021-07-23 20:38:44,703 epoch 2 - iter 12/24 - loss 4.37048602 - samples/sec: 128.49 - lr: 0.000030
2021-07-23 20:38:45,176 epoch 2 - iter 14/24 - loss 4.21140335 - samples/sec: 135.29 - lr: 0.000030
2021-07-23 20:38:45,628 epoch 2 - iter 16/24 - loss 4.06004855 - samples/sec: 141.72 - lr: 0.000030
2021-07-23 20:38:46,109 epoch 2 - iter 18/24 - loss 3.93551546 - samples/sec: 133.19 - lr: 0.000030
2021-07-23 20:38:46,628 epoch 2 - iter 20/24 - loss 3.90179527 - samples/sec: 123.33 - lr: 0.000030
2021-07-23 20:38:47,113 epoch 2 - iter 22/24 - loss 3.79818100 - samples/sec: 132.25 - lr: 0.000030
2021-07-23 20:38:47,479 epoch 2 - iter 24/24 - loss 3.80207341 - samples/sec: 174.63 - lr: 0.000030
2021-07-23 20:38:47,480 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:47,480 EPOCH 2 done: loss 3.8021 - lr 0.0000300
2021-07-23 20:38:48,275 DEV : loss 2.0741825103759766 - score 0.0
2021-07-23 20:38:48,285 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:38:50,580 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:51,129 epoch 3 - iter 2/24 - loss 2.57706654 - samples/sec: 117.05 - lr: 0.000030
2021-07-23 20:38:51,634 epoch 3 - iter 4/24 - loss 2.54607183 - samples/sec: 126.73 - lr: 0.000030
2021-07-23 20:38:52,192 epoch 3 - iter 6/24 - loss 2.77921760 - samples/sec: 114.80 - lr: 0.000030
2021-07-23 20:38:52,688 epoch 3 - iter 8/24 - loss 2.67162248 - samples/sec: 129.04 - lr: 0.000030
2021-07-23 20:38:53,209 epoch 3 - iter 10/24 - loss 2.66197977 - samples/sec: 123.06 - lr: 0.000030
2021-07-23 20:38:53,758 epoch 3 - iter 12/24 - loss 2.68093208 - samples/sec: 116.51 - lr: 0.000030
2021-07-23 20:38:54,212 epoch 3 - iter 14/24 - loss 2.59090451 - samples/sec: 141.27 - lr: 0.000030
2021-07-23 20:38:54,659 epoch 3 - iter 16/24 - loss 2.58315063 - samples/sec: 143.20 - lr: 0.000030
2021-07-23 20:38:55,217 epoch 3 - iter 18/24 - loss 2.50418233 - samples/sec: 114.77 - lr: 0.000030
2021-07-23 20:38:55,660 epoch 3 - iter 20/24 - loss 2.43497410 - samples/sec: 144.67 - lr: 0.000030
2021-07-23 20:38:56,175 epoch 3 - iter 22/24 - loss 2.37246076 - samples/sec: 124.28 - lr: 0.000030
2021-07-23 20:38:56,532 epoch 3 - iter 24/24 - loss 2.33443423 - samples/sec: 179.26 - lr: 0.000030
2021-07-23 20:38:56,534 ----------------------------------------------------------------------------------------------------
2021-07-23 20:38:56,534 EPOCH 3 done: loss 2.3344 - lr 0.0000300
2021-07-23 20:38:57,327 DEV : loss 1.7369216680526733 - score 0.7595
2021-07-23 20:38:57,336 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:38:59,588 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:00,109 epoch 4 - iter 2/24 - loss 1.67090261 - samples/sec: 123.22 - lr: 0.000030
2021-07-23 20:39:00,599 epoch 4 - iter 4/24 - loss 1.66859496 - samples/sec: 130.71 - lr: 0.000030
2021-07-23 20:39:01,108 epoch 4 - iter 6/24 - loss 1.75469730 - samples/sec: 125.89 - lr: 0.000030
2021-07-23 20:39:01,634 epoch 4 - iter 8/24 - loss 1.78508498 - samples/sec: 121.78 - lr: 0.000030
2021-07-23 20:39:02,181 epoch 4 - iter 10/24 - loss 1.84060125 - samples/sec: 116.94 - lr: 0.000030
2021-07-23 20:39:02,686 epoch 4 - iter 12/24 - loss 1.86410478 - samples/sec: 127.00 - lr: 0.000030
2021-07-23 20:39:03,155 epoch 4 - iter 14/24 - loss 1.80311719 - samples/sec: 136.42 - lr: 0.000030
2021-07-23 20:39:03,614 epoch 4 - iter 16/24 - loss 1.80119803 - samples/sec: 139.60 - lr: 0.000030
2021-07-23 20:39:04,113 epoch 4 - iter 18/24 - loss 1.80167221 - samples/sec: 128.39 - lr: 0.000030
2021-07-23 20:39:04,645 epoch 4 - iter 20/24 - loss 1.82482396 - samples/sec: 120.34 - lr: 0.000030
2021-07-23 20:39:05,172 epoch 4 - iter 22/24 - loss 1.83560656 - samples/sec: 121.68 - lr: 0.000030
2021-07-23 20:39:05,509 epoch 4 - iter 24/24 - loss 1.80884401 - samples/sec: 189.76 - lr: 0.000030
2021-07-23 20:39:05,510 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:05,510 EPOCH 4 done: loss 1.8088 - lr 0.0000300
2021-07-23 20:39:06,298 DEV : loss 1.4983080625534058 - score 0.7595
2021-07-23 20:39:06,308 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:39:08,623 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:09,171 epoch 5 - iter 2/24 - loss 1.54492450 - samples/sec: 117.20 - lr: 0.000030
2021-07-23 20:39:09,767 epoch 5 - iter 4/24 - loss 1.59325600 - samples/sec: 107.51 - lr: 0.000030
2021-07-23 20:39:10,303 epoch 5 - iter 6/24 - loss 1.55855248 - samples/sec: 119.42 - lr: 0.000030
2021-07-23 20:39:10,720 epoch 5 - iter 8/24 - loss 1.61499062 - samples/sec: 153.68 - lr: 0.000030
2021-07-23 20:39:11,203 epoch 5 - iter 10/24 - loss 1.59452291 - samples/sec: 132.44 - lr: 0.000030
2021-07-23 20:39:11,684 epoch 5 - iter 12/24 - loss 1.55945272 - samples/sec: 133.14 - lr: 0.000030
2021-07-23 20:39:12,248 epoch 5 - iter 14/24 - loss 1.60868978 - samples/sec: 113.53 - lr: 0.000030
2021-07-23 20:39:12,763 epoch 5 - iter 16/24 - loss 1.60225181 - samples/sec: 124.35 - lr: 0.000030
2021-07-23 20:39:13,296 epoch 5 - iter 18/24 - loss 1.59619512 - samples/sec: 120.30 - lr: 0.000030
2021-07-23 20:39:13,763 epoch 5 - iter 20/24 - loss 1.58563810 - samples/sec: 137.11 - lr: 0.000030
2021-07-23 20:39:14,220 epoch 5 - iter 22/24 - loss 1.54840076 - samples/sec: 139.91 - lr: 0.000030
2021-07-23 20:39:14,594 epoch 5 - iter 24/24 - loss 1.53242753 - samples/sec: 171.56 - lr: 0.000030
2021-07-23 20:39:14,595 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:14,595 EPOCH 5 done: loss 1.5324 - lr 0.0000300
2021-07-23 20:39:15,383 DEV : loss 1.3031619787216187 - score 0.7547
2021-07-23 20:39:15,393 BAD EPOCHS (no improvement): 1
2021-07-23 20:39:15,393 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:15,909 epoch 6 - iter 2/24 - loss 0.97981840 - samples/sec: 124.38 - lr: 0.000030
2021-07-23 20:39:16,363 epoch 6 - iter 4/24 - loss 1.32915866 - samples/sec: 140.94 - lr: 0.000030
2021-07-23 20:39:16,909 epoch 6 - iter 6/24 - loss 1.43986807 - samples/sec: 117.37 - lr: 0.000030
2021-07-23 20:39:17,371 epoch 6 - iter 8/24 - loss 1.47821222 - samples/sec: 138.52 - lr: 0.000030
2021-07-23 20:39:17,879 epoch 6 - iter 10/24 - loss 1.37267337 - samples/sec: 126.01 - lr: 0.000030
2021-07-23 20:39:18,400 epoch 6 - iter 12/24 - loss 1.40181125 - samples/sec: 122.99 - lr: 0.000030
2021-07-23 20:39:18,893 epoch 6 - iter 14/24 - loss 1.38145823 - samples/sec: 130.00 - lr: 0.000030
2021-07-23 20:39:19,448 epoch 6 - iter 16/24 - loss 1.38652387 - samples/sec: 115.30 - lr: 0.000030
2021-07-23 20:39:19,899 epoch 6 - iter 18/24 - loss 1.33478990 - samples/sec: 142.16 - lr: 0.000030
2021-07-23 20:39:20,363 epoch 6 - iter 20/24 - loss 1.32230804 - samples/sec: 137.90 - lr: 0.000030
2021-07-23 20:39:20,900 epoch 6 - iter 22/24 - loss 1.35086498 - samples/sec: 119.41 - lr: 0.000030
2021-07-23 20:39:21,253 epoch 6 - iter 24/24 - loss 1.38104395 - samples/sec: 181.42 - lr: 0.000030
2021-07-23 20:39:21,254 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:21,254 EPOCH 6 done: loss 1.3810 - lr 0.0000300
2021-07-23 20:39:22,043 DEV : loss 1.1308459043502808 - score 0.7524
2021-07-23 20:39:22,053 BAD EPOCHS (no improvement): 2
2021-07-23 20:39:22,053 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:22,498 epoch 7 - iter 2/24 - loss 1.35856706 - samples/sec: 144.05 - lr: 0.000030
2021-07-23 20:39:23,029 epoch 7 - iter 4/24 - loss 1.40239057 - samples/sec: 120.56 - lr: 0.000030
2021-07-23 20:39:23,533 epoch 7 - iter 6/24 - loss 1.30001080 - samples/sec: 127.29 - lr: 0.000030
2021-07-23 20:39:24,048 epoch 7 - iter 8/24 - loss 1.27430674 - samples/sec: 124.30 - lr: 0.000030
2021-07-23 20:39:24,565 epoch 7 - iter 10/24 - loss 1.28270173 - samples/sec: 123.84 - lr: 0.000030
2021-07-23 20:39:25,643 epoch 7 - iter 12/24 - loss 1.27452609 - samples/sec: 123.47 - lr: 0.000030
2021-07-23 20:39:26,169 epoch 7 - iter 14/24 - loss 1.25279800 - samples/sec: 121.72 - lr: 0.000030
2021-07-23 20:39:26,693 epoch 7 - iter 16/24 - loss 1.24792128 - samples/sec: 122.40 - lr: 0.000030
2021-07-23 20:39:27,253 epoch 7 - iter 18/24 - loss 1.22225227 - samples/sec: 114.28 - lr: 0.000030
2021-07-23 20:39:27,753 epoch 7 - iter 20/24 - loss 1.22215247 - samples/sec: 128.04 - lr: 0.000030
2021-07-23 20:39:28,184 epoch 7 - iter 22/24 - loss 1.23251442 - samples/sec: 148.79 - lr: 0.000030
2021-07-23 20:39:28,494 epoch 7 - iter 24/24 - loss 1.20686998 - samples/sec: 206.43 - lr: 0.000030
2021-07-23 20:39:28,495 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:28,495 EPOCH 7 done: loss 1.2069 - lr 0.0000300
2021-07-23 20:39:29,284 DEV : loss 0.9761635065078735 - score 0.7524
2021-07-23 20:39:29,293 BAD EPOCHS (no improvement): 3
2021-07-23 20:39:29,294 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:29,781 epoch 8 - iter 2/24 - loss 0.93561420 - samples/sec: 131.75 - lr: 0.000030
2021-07-23 20:39:30,293 epoch 8 - iter 4/24 - loss 1.07895212 - samples/sec: 124.93 - lr: 0.000030
2021-07-23 20:39:30,776 epoch 8 - iter 6/24 - loss 1.10848108 - samples/sec: 132.69 - lr: 0.000030
2021-07-23 20:39:31,295 epoch 8 - iter 8/24 - loss 1.10828855 - samples/sec: 123.41 - lr: 0.000030
2021-07-23 20:39:31,783 epoch 8 - iter 10/24 - loss 1.08479188 - samples/sec: 131.10 - lr: 0.000030
2021-07-23 20:39:32,336 epoch 8 - iter 12/24 - loss 1.11019505 - samples/sec: 115.83 - lr: 0.000030
2021-07-23 20:39:32,807 epoch 8 - iter 14/24 - loss 1.11876895 - samples/sec: 135.98 - lr: 0.000030
2021-07-23 20:39:33,311 epoch 8 - iter 16/24 - loss 1.09976850 - samples/sec: 127.05 - lr: 0.000030
2021-07-23 20:39:33,788 epoch 8 - iter 18/24 - loss 1.07876963 - samples/sec: 134.34 - lr: 0.000030
2021-07-23 20:39:34,287 epoch 8 - iter 20/24 - loss 1.07742626 - samples/sec: 128.38 - lr: 0.000030
2021-07-23 20:39:34,825 epoch 8 - iter 22/24 - loss 1.06521915 - samples/sec: 118.93 - lr: 0.000030
2021-07-23 20:39:35,163 epoch 8 - iter 24/24 - loss 1.08513497 - samples/sec: 189.98 - lr: 0.000030
2021-07-23 20:39:35,164 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:35,164 EPOCH 8 done: loss 1.0851 - lr 0.0000300
2021-07-23 20:39:36,211 DEV : loss 0.8232585191726685 - score 0.7524
Epoch     8: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 20:39:36,225 BAD EPOCHS (no improvement): 4
2021-07-23 20:39:36,225 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:36,730 epoch 9 - iter 2/24 - loss 1.01478171 - samples/sec: 127.11 - lr: 0.000015
2021-07-23 20:39:37,309 epoch 9 - iter 4/24 - loss 1.05442128 - samples/sec: 110.56 - lr: 0.000015
2021-07-23 20:39:37,798 epoch 9 - iter 6/24 - loss 1.00728375 - samples/sec: 131.05 - lr: 0.000015
2021-07-23 20:39:38,289 epoch 9 - iter 8/24 - loss 0.98470338 - samples/sec: 130.43 - lr: 0.000015
2021-07-23 20:39:38,793 epoch 9 - iter 10/24 - loss 0.98616207 - samples/sec: 127.15 - lr: 0.000015
2021-07-23 20:39:39,348 epoch 9 - iter 12/24 - loss 0.99332285 - samples/sec: 115.39 - lr: 0.000015
2021-07-23 20:39:39,846 epoch 9 - iter 14/24 - loss 0.98920631 - samples/sec: 128.56 - lr: 0.000015
2021-07-23 20:39:40,363 epoch 9 - iter 16/24 - loss 0.98532966 - samples/sec: 123.88 - lr: 0.000015
2021-07-23 20:39:40,821 epoch 9 - iter 18/24 - loss 0.96808874 - samples/sec: 139.90 - lr: 0.000015
2021-07-23 20:39:41,368 epoch 9 - iter 20/24 - loss 0.94925221 - samples/sec: 116.90 - lr: 0.000015
2021-07-23 20:39:41,869 epoch 9 - iter 22/24 - loss 0.96777699 - samples/sec: 127.99 - lr: 0.000015
2021-07-23 20:39:42,158 epoch 9 - iter 24/24 - loss 0.94673454 - samples/sec: 221.29 - lr: 0.000015
2021-07-23 20:39:42,159 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:42,159 EPOCH 9 done: loss 0.9467 - lr 0.0000150
2021-07-23 20:39:42,953 DEV : loss 0.7488767504692078 - score 0.7524
2021-07-23 20:39:42,963 BAD EPOCHS (no improvement): 1
2021-07-23 20:39:42,963 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:43,484 epoch 10 - iter 2/24 - loss 0.99982840 - samples/sec: 123.06 - lr: 0.000015
2021-07-23 20:39:44,061 epoch 10 - iter 4/24 - loss 0.95092981 - samples/sec: 111.08 - lr: 0.000015
2021-07-23 20:39:44,591 epoch 10 - iter 6/24 - loss 0.97283190 - samples/sec: 120.82 - lr: 0.000015
2021-07-23 20:39:45,043 epoch 10 - iter 8/24 - loss 0.97301613 - samples/sec: 141.62 - lr: 0.000015
2021-07-23 20:39:45,567 epoch 10 - iter 10/24 - loss 0.94333568 - samples/sec: 122.30 - lr: 0.000015
2021-07-23 20:39:46,051 epoch 10 - iter 12/24 - loss 0.93186853 - samples/sec: 132.20 - lr: 0.000015
2021-07-23 20:39:46,587 epoch 10 - iter 14/24 - loss 0.95534070 - samples/sec: 119.60 - lr: 0.000015
2021-07-23 20:39:47,120 epoch 10 - iter 16/24 - loss 0.95477872 - samples/sec: 120.23 - lr: 0.000015
2021-07-23 20:39:47,597 epoch 10 - iter 18/24 - loss 0.93470031 - samples/sec: 134.04 - lr: 0.000015
2021-07-23 20:39:48,069 epoch 10 - iter 20/24 - loss 0.94104110 - samples/sec: 135.75 - lr: 0.000015
2021-07-23 20:39:48,566 epoch 10 - iter 22/24 - loss 0.91517191 - samples/sec: 128.83 - lr: 0.000015
2021-07-23 20:39:48,882 epoch 10 - iter 24/24 - loss 0.91564155 - samples/sec: 202.92 - lr: 0.000015
2021-07-23 20:39:48,883 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:48,883 EPOCH 10 done: loss 0.9156 - lr 0.0000150
2021-07-23 20:39:49,677 DEV : loss 0.6781803965568542 - score 0.7547
2021-07-23 20:39:49,687 BAD EPOCHS (no improvement): 2
2021-07-23 20:39:49,687 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:50,196 epoch 11 - iter 2/24 - loss 0.73783246 - samples/sec: 125.98 - lr: 0.000015
2021-07-23 20:39:50,659 epoch 11 - iter 4/24 - loss 0.84820579 - samples/sec: 138.41 - lr: 0.000015
2021-07-23 20:39:51,214 epoch 11 - iter 6/24 - loss 0.91075264 - samples/sec: 115.44 - lr: 0.000015
2021-07-23 20:39:51,679 epoch 11 - iter 8/24 - loss 0.93300179 - samples/sec: 137.76 - lr: 0.000015
2021-07-23 20:39:52,169 epoch 11 - iter 10/24 - loss 0.85915939 - samples/sec: 130.74 - lr: 0.000015
2021-07-23 20:39:52,713 epoch 11 - iter 12/24 - loss 0.83061923 - samples/sec: 117.68 - lr: 0.000015
2021-07-23 20:39:53,179 epoch 11 - iter 14/24 - loss 0.82449332 - samples/sec: 137.45 - lr: 0.000015
2021-07-23 20:39:53,756 epoch 11 - iter 16/24 - loss 0.81342802 - samples/sec: 110.85 - lr: 0.000015
2021-07-23 20:39:54,209 epoch 11 - iter 18/24 - loss 0.82207410 - samples/sec: 141.64 - lr: 0.000015
2021-07-23 20:39:54,753 epoch 11 - iter 20/24 - loss 0.81354159 - samples/sec: 117.59 - lr: 0.000015
2021-07-23 20:39:55,285 epoch 11 - iter 22/24 - loss 0.81839095 - samples/sec: 120.48 - lr: 0.000015
2021-07-23 20:39:55,618 epoch 11 - iter 24/24 - loss 0.81745559 - samples/sec: 192.11 - lr: 0.000015
2021-07-23 20:39:55,619 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:55,619 EPOCH 11 done: loss 0.8175 - lr 0.0000150
2021-07-23 20:39:56,412 DEV : loss 0.6075756549835205 - score 0.7547
2021-07-23 20:39:56,421 BAD EPOCHS (no improvement): 3
2021-07-23 20:39:56,421 ----------------------------------------------------------------------------------------------------
2021-07-23 20:39:56,911 epoch 12 - iter 2/24 - loss 0.87128019 - samples/sec: 130.94 - lr: 0.000015
2021-07-23 20:39:57,424 epoch 12 - iter 4/24 - loss 0.85378501 - samples/sec: 125.01 - lr: 0.000015
2021-07-23 20:39:57,942 epoch 12 - iter 6/24 - loss 0.81355667 - samples/sec: 123.45 - lr: 0.000015
2021-07-23 20:39:58,581 epoch 12 - iter 8/24 - loss 0.79968844 - samples/sec: 100.33 - lr: 0.000015
2021-07-23 20:39:59,088 epoch 12 - iter 10/24 - loss 0.78703572 - samples/sec: 126.39 - lr: 0.000015
2021-07-23 20:39:59,548 epoch 12 - iter 12/24 - loss 0.78951088 - samples/sec: 139.11 - lr: 0.000015
2021-07-23 20:40:00,048 epoch 12 - iter 14/24 - loss 0.78548884 - samples/sec: 128.14 - lr: 0.000015
2021-07-23 20:40:00,584 epoch 12 - iter 16/24 - loss 0.76310147 - samples/sec: 119.48 - lr: 0.000015
2021-07-23 20:40:01,097 epoch 12 - iter 18/24 - loss 0.78505197 - samples/sec: 124.64 - lr: 0.000015
2021-07-23 20:40:01,576 epoch 12 - iter 20/24 - loss 0.77911598 - samples/sec: 133.84 - lr: 0.000015
2021-07-23 20:40:02,066 epoch 12 - iter 22/24 - loss 0.77462204 - samples/sec: 130.65 - lr: 0.000015
2021-07-23 20:40:02,447 epoch 12 - iter 24/24 - loss 0.78494223 - samples/sec: 168.20 - lr: 0.000015
2021-07-23 20:40:02,448 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:02,449 EPOCH 12 done: loss 0.7849 - lr 0.0000150
2021-07-23 20:40:03,242 DEV : loss 0.5432572364807129 - score 0.7547
Epoch    12: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 20:40:03,251 BAD EPOCHS (no improvement): 4
2021-07-23 20:40:03,251 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:03,792 epoch 13 - iter 2/24 - loss 0.85042888 - samples/sec: 118.56 - lr: 0.000008
2021-07-23 20:40:04,285 epoch 13 - iter 4/24 - loss 0.75520717 - samples/sec: 130.09 - lr: 0.000008
2021-07-23 20:40:04,793 epoch 13 - iter 6/24 - loss 0.80533236 - samples/sec: 125.91 - lr: 0.000008
2021-07-23 20:40:05,279 epoch 13 - iter 8/24 - loss 0.82638461 - samples/sec: 131.90 - lr: 0.000008
2021-07-23 20:40:05,775 epoch 13 - iter 10/24 - loss 0.80350245 - samples/sec: 129.11 - lr: 0.000008
2021-07-23 20:40:06,306 epoch 13 - iter 12/24 - loss 0.78251889 - samples/sec: 120.51 - lr: 0.000008
2021-07-23 20:40:06,841 epoch 13 - iter 14/24 - loss 0.74378308 - samples/sec: 119.86 - lr: 0.000008
2021-07-23 20:40:07,323 epoch 13 - iter 16/24 - loss 0.73894425 - samples/sec: 132.84 - lr: 0.000008
2021-07-23 20:40:07,775 epoch 13 - iter 18/24 - loss 0.72278892 - samples/sec: 141.48 - lr: 0.000008
2021-07-23 20:40:08,288 epoch 13 - iter 20/24 - loss 0.70620771 - samples/sec: 125.03 - lr: 0.000008
2021-07-23 20:40:08,800 epoch 13 - iter 22/24 - loss 0.71105752 - samples/sec: 124.98 - lr: 0.000008
2021-07-23 20:40:09,189 epoch 13 - iter 24/24 - loss 0.70707492 - samples/sec: 164.72 - lr: 0.000008
2021-07-23 20:40:09,190 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:09,190 EPOCH 13 done: loss 0.7071 - lr 0.0000075
2021-07-23 20:40:09,983 DEV : loss 0.5078548789024353 - score 0.7547
2021-07-23 20:40:09,993 BAD EPOCHS (no improvement): 1
2021-07-23 20:40:09,993 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:10,529 epoch 14 - iter 2/24 - loss 0.59597483 - samples/sec: 119.72 - lr: 0.000008
2021-07-23 20:40:11,065 epoch 14 - iter 4/24 - loss 0.77627060 - samples/sec: 119.42 - lr: 0.000008
2021-07-23 20:40:11,597 epoch 14 - iter 6/24 - loss 0.78278746 - samples/sec: 120.35 - lr: 0.000008
2021-07-23 20:40:12,030 epoch 14 - iter 8/24 - loss 0.76600029 - samples/sec: 147.98 - lr: 0.000008
2021-07-23 20:40:12,539 epoch 14 - iter 10/24 - loss 0.76464757 - samples/sec: 125.73 - lr: 0.000008
2021-07-23 20:40:13,064 epoch 14 - iter 12/24 - loss 0.75742284 - samples/sec: 122.10 - lr: 0.000008
2021-07-23 20:40:13,616 epoch 14 - iter 14/24 - loss 0.77865722 - samples/sec: 115.96 - lr: 0.000008
2021-07-23 20:40:14,107 epoch 14 - iter 16/24 - loss 0.72945910 - samples/sec: 130.40 - lr: 0.000008
2021-07-23 20:40:14,641 epoch 14 - iter 18/24 - loss 0.73162677 - samples/sec: 119.98 - lr: 0.000008
2021-07-23 20:40:15,140 epoch 14 - iter 20/24 - loss 0.73801474 - samples/sec: 128.47 - lr: 0.000008
2021-07-23 20:40:15,600 epoch 14 - iter 22/24 - loss 0.72072574 - samples/sec: 139.17 - lr: 0.000008
2021-07-23 20:40:15,914 epoch 14 - iter 24/24 - loss 0.68557008 - samples/sec: 203.94 - lr: 0.000008
2021-07-23 20:40:15,915 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:15,915 EPOCH 14 done: loss 0.6856 - lr 0.0000075
2021-07-23 20:40:16,708 DEV : loss 0.4758903682231903 - score 0.7586
2021-07-23 20:40:16,718 BAD EPOCHS (no improvement): 2
2021-07-23 20:40:16,718 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:17,219 epoch 15 - iter 2/24 - loss 0.50610925 - samples/sec: 128.08 - lr: 0.000008
2021-07-23 20:40:17,747 epoch 15 - iter 4/24 - loss 0.59609001 - samples/sec: 121.23 - lr: 0.000008
2021-07-23 20:40:18,257 epoch 15 - iter 6/24 - loss 0.66652313 - samples/sec: 125.72 - lr: 0.000008
2021-07-23 20:40:18,808 epoch 15 - iter 8/24 - loss 0.66397617 - samples/sec: 116.17 - lr: 0.000008
2021-07-23 20:40:19,296 epoch 15 - iter 10/24 - loss 0.67998871 - samples/sec: 131.13 - lr: 0.000008
2021-07-23 20:40:19,796 epoch 15 - iter 12/24 - loss 0.67414492 - samples/sec: 128.01 - lr: 0.000008
2021-07-23 20:40:20,352 epoch 15 - iter 14/24 - loss 0.66008585 - samples/sec: 115.25 - lr: 0.000008
2021-07-23 20:40:20,809 epoch 15 - iter 16/24 - loss 0.64787095 - samples/sec: 140.33 - lr: 0.000008
2021-07-23 20:40:21,338 epoch 15 - iter 18/24 - loss 0.62410343 - samples/sec: 121.01 - lr: 0.000008
2021-07-23 20:40:21,891 epoch 15 - iter 20/24 - loss 0.64433966 - samples/sec: 115.86 - lr: 0.000008
2021-07-23 20:40:22,332 epoch 15 - iter 22/24 - loss 0.64418384 - samples/sec: 145.08 - lr: 0.000008
2021-07-23 20:40:22,665 epoch 15 - iter 24/24 - loss 0.63502844 - samples/sec: 192.27 - lr: 0.000008
2021-07-23 20:40:22,666 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:22,666 EPOCH 15 done: loss 0.6350 - lr 0.0000075
2021-07-23 20:40:23,766 DEV : loss 0.4474470317363739 - score 0.7778
2021-07-23 20:40:23,781 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:40:27,393 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:27,891 epoch 16 - iter 2/24 - loss 0.46286593 - samples/sec: 128.84 - lr: 0.000008
2021-07-23 20:40:28,377 epoch 16 - iter 4/24 - loss 0.58386008 - samples/sec: 131.80 - lr: 0.000008
2021-07-23 20:40:28,919 epoch 16 - iter 6/24 - loss 0.70706669 - samples/sec: 118.24 - lr: 0.000008
2021-07-23 20:40:29,387 epoch 16 - iter 8/24 - loss 0.67453493 - samples/sec: 136.93 - lr: 0.000008
2021-07-23 20:40:29,893 epoch 16 - iter 10/24 - loss 0.62315534 - samples/sec: 126.58 - lr: 0.000008
2021-07-23 20:40:30,357 epoch 16 - iter 12/24 - loss 0.62703278 - samples/sec: 138.02 - lr: 0.000008
2021-07-23 20:40:30,833 epoch 16 - iter 14/24 - loss 0.62649645 - samples/sec: 134.47 - lr: 0.000008
2021-07-23 20:40:31,335 epoch 16 - iter 16/24 - loss 0.64339940 - samples/sec: 127.45 - lr: 0.000008
2021-07-23 20:40:31,876 epoch 16 - iter 18/24 - loss 0.62811800 - samples/sec: 118.38 - lr: 0.000008
2021-07-23 20:40:32,371 epoch 16 - iter 20/24 - loss 0.61387608 - samples/sec: 129.40 - lr: 0.000008
2021-07-23 20:40:32,891 epoch 16 - iter 22/24 - loss 0.61526527 - samples/sec: 123.22 - lr: 0.000008
2021-07-23 20:40:33,293 epoch 16 - iter 24/24 - loss 0.64367105 - samples/sec: 159.34 - lr: 0.000008
2021-07-23 20:40:33,294 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:33,294 EPOCH 16 done: loss 0.6437 - lr 0.0000075
2021-07-23 20:40:34,084 DEV : loss 0.4186423420906067 - score 0.8108
2021-07-23 20:40:34,094 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:40:36,372 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:36,864 epoch 17 - iter 2/24 - loss 0.48120338 - samples/sec: 130.79 - lr: 0.000008
2021-07-23 20:40:37,341 epoch 17 - iter 4/24 - loss 0.50565366 - samples/sec: 134.24 - lr: 0.000008
2021-07-23 20:40:37,852 epoch 17 - iter 6/24 - loss 0.56912306 - samples/sec: 125.14 - lr: 0.000008
2021-07-23 20:40:38,357 epoch 17 - iter 8/24 - loss 0.57623466 - samples/sec: 126.91 - lr: 0.000008
2021-07-23 20:40:38,833 epoch 17 - iter 10/24 - loss 0.63386521 - samples/sec: 134.50 - lr: 0.000008
2021-07-23 20:40:39,404 epoch 17 - iter 12/24 - loss 0.61844428 - samples/sec: 112.12 - lr: 0.000008
2021-07-23 20:40:39,968 epoch 17 - iter 14/24 - loss 0.60934947 - samples/sec: 113.70 - lr: 0.000008
2021-07-23 20:40:40,440 epoch 17 - iter 16/24 - loss 0.58687663 - samples/sec: 135.46 - lr: 0.000008
2021-07-23 20:40:40,912 epoch 17 - iter 18/24 - loss 0.58519489 - samples/sec: 135.92 - lr: 0.000008
2021-07-23 20:40:41,411 epoch 17 - iter 20/24 - loss 0.57998504 - samples/sec: 128.18 - lr: 0.000008
2021-07-23 20:40:41,883 epoch 17 - iter 22/24 - loss 0.59214070 - samples/sec: 135.88 - lr: 0.000008
2021-07-23 20:40:42,268 epoch 17 - iter 24/24 - loss 0.59249712 - samples/sec: 166.06 - lr: 0.000008
2021-07-23 20:40:42,270 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:42,270 EPOCH 17 done: loss 0.5925 - lr 0.0000075
2021-07-23 20:40:43,061 DEV : loss 0.3931290805339813 - score 0.8319
2021-07-23 20:40:43,074 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:40:45,328 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:45,821 epoch 18 - iter 2/24 - loss 0.55949423 - samples/sec: 130.50 - lr: 0.000008
2021-07-23 20:40:46,381 epoch 18 - iter 4/24 - loss 0.63779376 - samples/sec: 114.40 - lr: 0.000008
2021-07-23 20:40:46,847 epoch 18 - iter 6/24 - loss 0.67259334 - samples/sec: 137.43 - lr: 0.000008
2021-07-23 20:40:47,343 epoch 18 - iter 8/24 - loss 0.67330590 - samples/sec: 129.05 - lr: 0.000008
2021-07-23 20:40:47,909 epoch 18 - iter 10/24 - loss 0.64259363 - samples/sec: 113.07 - lr: 0.000008
2021-07-23 20:40:48,354 epoch 18 - iter 12/24 - loss 0.61807915 - samples/sec: 144.04 - lr: 0.000008
2021-07-23 20:40:48,837 epoch 18 - iter 14/24 - loss 0.59490316 - samples/sec: 132.60 - lr: 0.000008
2021-07-23 20:40:49,328 epoch 18 - iter 16/24 - loss 0.58936900 - samples/sec: 130.40 - lr: 0.000008
2021-07-23 20:40:49,828 epoch 18 - iter 18/24 - loss 0.57619051 - samples/sec: 128.25 - lr: 0.000008
2021-07-23 20:40:50,337 epoch 18 - iter 20/24 - loss 0.59684826 - samples/sec: 125.83 - lr: 0.000008
2021-07-23 20:40:50,876 epoch 18 - iter 22/24 - loss 0.59323682 - samples/sec: 118.73 - lr: 0.000008
2021-07-23 20:40:51,236 epoch 18 - iter 24/24 - loss 0.59366272 - samples/sec: 178.15 - lr: 0.000008
2021-07-23 20:40:51,237 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:51,237 EPOCH 18 done: loss 0.5937 - lr 0.0000075
2021-07-23 20:40:52,025 DEV : loss 0.3662109375 - score 0.8588
2021-07-23 20:40:52,035 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:40:54,242 ----------------------------------------------------------------------------------------------------
2021-07-23 20:40:54,795 epoch 19 - iter 2/24 - loss 0.52309895 - samples/sec: 116.07 - lr: 0.000008
2021-07-23 20:40:55,313 epoch 19 - iter 4/24 - loss 0.58450116 - samples/sec: 123.85 - lr: 0.000008
2021-07-23 20:40:55,923 epoch 19 - iter 6/24 - loss 0.57938303 - samples/sec: 104.87 - lr: 0.000008
2021-07-23 20:40:56,392 epoch 19 - iter 8/24 - loss 0.54990590 - samples/sec: 136.62 - lr: 0.000008
2021-07-23 20:40:56,885 epoch 19 - iter 10/24 - loss 0.52669608 - samples/sec: 129.92 - lr: 0.000008
2021-07-23 20:40:57,371 epoch 19 - iter 12/24 - loss 0.49634828 - samples/sec: 131.84 - lr: 0.000008
2021-07-23 20:40:57,855 epoch 19 - iter 14/24 - loss 0.49244562 - samples/sec: 132.14 - lr: 0.000008
2021-07-23 20:40:58,331 epoch 19 - iter 16/24 - loss 0.51810633 - samples/sec: 134.66 - lr: 0.000008
2021-07-23 20:40:58,870 epoch 19 - iter 18/24 - loss 0.52413299 - samples/sec: 118.72 - lr: 0.000008
2021-07-23 20:40:59,408 epoch 19 - iter 20/24 - loss 0.55266335 - samples/sec: 119.10 - lr: 0.000008
2021-07-23 20:40:59,856 epoch 19 - iter 22/24 - loss 0.54543264 - samples/sec: 142.96 - lr: 0.000008
2021-07-23 20:41:00,222 epoch 19 - iter 24/24 - loss 0.55181596 - samples/sec: 175.32 - lr: 0.000008
2021-07-23 20:41:00,223 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:00,223 EPOCH 19 done: loss 0.5518 - lr 0.0000075
2021-07-23 20:41:01,012 DEV : loss 0.3423849642276764 - score 0.8782
2021-07-23 20:41:01,021 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:41:03,440 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:03,989 epoch 20 - iter 2/24 - loss 0.44722286 - samples/sec: 117.06 - lr: 0.000008
2021-07-23 20:41:04,536 epoch 20 - iter 4/24 - loss 0.51449160 - samples/sec: 117.14 - lr: 0.000008
2021-07-23 20:41:05,075 epoch 20 - iter 6/24 - loss 0.47955437 - samples/sec: 118.73 - lr: 0.000008
2021-07-23 20:41:05,619 epoch 20 - iter 8/24 - loss 0.51039231 - samples/sec: 117.77 - lr: 0.000008
2021-07-23 20:41:06,105 epoch 20 - iter 10/24 - loss 0.50844476 - samples/sec: 131.83 - lr: 0.000008
2021-07-23 20:41:06,570 epoch 20 - iter 12/24 - loss 0.52853599 - samples/sec: 137.53 - lr: 0.000008
2021-07-23 20:41:07,049 epoch 20 - iter 14/24 - loss 0.51594680 - samples/sec: 133.71 - lr: 0.000008
2021-07-23 20:41:07,569 epoch 20 - iter 16/24 - loss 0.51763346 - samples/sec: 123.30 - lr: 0.000008
2021-07-23 20:41:08,083 epoch 20 - iter 18/24 - loss 0.50644799 - samples/sec: 124.51 - lr: 0.000008
2021-07-23 20:41:08,597 epoch 20 - iter 20/24 - loss 0.50913876 - samples/sec: 124.64 - lr: 0.000008
2021-07-23 20:41:09,080 epoch 20 - iter 22/24 - loss 0.51434333 - samples/sec: 132.69 - lr: 0.000008
2021-07-23 20:41:09,380 epoch 20 - iter 24/24 - loss 0.51467129 - samples/sec: 213.11 - lr: 0.000008
2021-07-23 20:41:09,382 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:09,382 EPOCH 20 done: loss 0.5147 - lr 0.0000075
2021-07-23 20:41:10,566 DEV : loss 0.3206496834754944 - score 0.9
2021-07-23 20:41:10,581 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:41:14,457 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:14,949 epoch 21 - iter 2/24 - loss 0.44537564 - samples/sec: 130.49 - lr: 0.000008
2021-07-23 20:41:15,475 epoch 21 - iter 4/24 - loss 0.46023465 - samples/sec: 121.73 - lr: 0.000008
2021-07-23 20:41:15,966 epoch 21 - iter 6/24 - loss 0.48596744 - samples/sec: 130.61 - lr: 0.000008
2021-07-23 20:41:16,514 epoch 21 - iter 8/24 - loss 0.46194035 - samples/sec: 116.80 - lr: 0.000008
2021-07-23 20:41:17,067 epoch 21 - iter 10/24 - loss 0.49760165 - samples/sec: 115.80 - lr: 0.000008
2021-07-23 20:41:17,580 epoch 21 - iter 12/24 - loss 0.51000537 - samples/sec: 124.93 - lr: 0.000008
2021-07-23 20:41:18,128 epoch 21 - iter 14/24 - loss 0.50003156 - samples/sec: 116.86 - lr: 0.000008
2021-07-23 20:41:18,604 epoch 21 - iter 16/24 - loss 0.48358887 - samples/sec: 134.52 - lr: 0.000008
2021-07-23 20:41:19,100 epoch 21 - iter 18/24 - loss 0.50061325 - samples/sec: 129.04 - lr: 0.000008
2021-07-23 20:41:19,567 epoch 21 - iter 20/24 - loss 0.49050007 - samples/sec: 137.11 - lr: 0.000008
2021-07-23 20:41:19,992 epoch 21 - iter 22/24 - loss 0.48588653 - samples/sec: 150.93 - lr: 0.000008
2021-07-23 20:41:20,387 epoch 21 - iter 24/24 - loss 0.47441436 - samples/sec: 162.16 - lr: 0.000008
2021-07-23 20:41:20,388 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:20,388 EPOCH 21 done: loss 0.4744 - lr 0.0000075
2021-07-23 20:41:21,181 DEV : loss 0.29852473735809326 - score 0.9036
2021-07-23 20:41:21,191 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:41:23,437 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:23,963 epoch 22 - iter 2/24 - loss 0.60630159 - samples/sec: 122.14 - lr: 0.000008
2021-07-23 20:41:24,505 epoch 22 - iter 4/24 - loss 0.44266786 - samples/sec: 118.24 - lr: 0.000008
2021-07-23 20:41:25,008 epoch 22 - iter 6/24 - loss 0.45325922 - samples/sec: 127.37 - lr: 0.000008
2021-07-23 20:41:25,519 epoch 22 - iter 8/24 - loss 0.47108632 - samples/sec: 125.33 - lr: 0.000008
2021-07-23 20:41:26,051 epoch 22 - iter 10/24 - loss 0.47166640 - samples/sec: 120.22 - lr: 0.000008
2021-07-23 20:41:26,531 epoch 22 - iter 12/24 - loss 0.46564084 - samples/sec: 133.61 - lr: 0.000008
2021-07-23 20:41:27,009 epoch 22 - iter 14/24 - loss 0.45481101 - samples/sec: 134.02 - lr: 0.000008
2021-07-23 20:41:27,492 epoch 22 - iter 16/24 - loss 0.43993628 - samples/sec: 132.63 - lr: 0.000008
2021-07-23 20:41:28,007 epoch 22 - iter 18/24 - loss 0.44008533 - samples/sec: 124.17 - lr: 0.000008
2021-07-23 20:41:28,538 epoch 22 - iter 20/24 - loss 0.45575693 - samples/sec: 120.76 - lr: 0.000008
2021-07-23 20:41:29,057 epoch 22 - iter 22/24 - loss 0.46344640 - samples/sec: 123.28 - lr: 0.000008
2021-07-23 20:41:29,374 epoch 22 - iter 24/24 - loss 0.48860810 - samples/sec: 202.24 - lr: 0.000008
2021-07-23 20:41:29,375 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:29,375 EPOCH 22 done: loss 0.4886 - lr 0.0000075
2021-07-23 20:41:30,170 DEV : loss 0.2786023020744324 - score 0.9272
2021-07-23 20:41:30,179 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:41:32,596 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:33,130 epoch 23 - iter 2/24 - loss 0.49294646 - samples/sec: 120.30 - lr: 0.000008
2021-07-23 20:41:33,599 epoch 23 - iter 4/24 - loss 0.48431265 - samples/sec: 136.61 - lr: 0.000008
2021-07-23 20:41:34,078 epoch 23 - iter 6/24 - loss 0.45804737 - samples/sec: 133.63 - lr: 0.000008
2021-07-23 20:41:34,611 epoch 23 - iter 8/24 - loss 0.47016981 - samples/sec: 120.31 - lr: 0.000008
2021-07-23 20:41:35,127 epoch 23 - iter 10/24 - loss 0.46913638 - samples/sec: 124.10 - lr: 0.000008
2021-07-23 20:41:35,608 epoch 23 - iter 12/24 - loss 0.45443607 - samples/sec: 133.04 - lr: 0.000008
2021-07-23 20:41:36,122 epoch 23 - iter 14/24 - loss 0.46477829 - samples/sec: 124.67 - lr: 0.000008
2021-07-23 20:41:36,623 epoch 23 - iter 16/24 - loss 0.44969409 - samples/sec: 127.78 - lr: 0.000008
2021-07-23 20:41:37,173 epoch 23 - iter 18/24 - loss 0.42965131 - samples/sec: 116.58 - lr: 0.000008
2021-07-23 20:41:37,668 epoch 23 - iter 20/24 - loss 0.43579268 - samples/sec: 129.39 - lr: 0.000008
2021-07-23 20:41:38,175 epoch 23 - iter 22/24 - loss 0.43573326 - samples/sec: 126.17 - lr: 0.000008
2021-07-23 20:41:38,539 epoch 23 - iter 24/24 - loss 0.44769371 - samples/sec: 176.29 - lr: 0.000008
2021-07-23 20:41:38,539 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:38,539 EPOCH 23 done: loss 0.4477 - lr 0.0000075
2021-07-23 20:41:39,334 DEV : loss 0.26013168692588806 - score 0.9415
2021-07-23 20:41:39,343 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:41:41,705 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:42,214 epoch 24 - iter 2/24 - loss 0.43410572 - samples/sec: 126.26 - lr: 0.000008
2021-07-23 20:41:42,757 epoch 24 - iter 4/24 - loss 0.49161980 - samples/sec: 117.91 - lr: 0.000008
2021-07-23 20:41:43,240 epoch 24 - iter 6/24 - loss 0.45736194 - samples/sec: 132.62 - lr: 0.000008
2021-07-23 20:41:43,749 epoch 24 - iter 8/24 - loss 0.44957755 - samples/sec: 126.01 - lr: 0.000008
2021-07-23 20:41:44,276 epoch 24 - iter 10/24 - loss 0.43911140 - samples/sec: 121.38 - lr: 0.000008
2021-07-23 20:41:44,773 epoch 24 - iter 12/24 - loss 0.43950260 - samples/sec: 128.81 - lr: 0.000008
2021-07-23 20:41:45,259 epoch 24 - iter 14/24 - loss 0.43907029 - samples/sec: 131.86 - lr: 0.000008
2021-07-23 20:41:45,833 epoch 24 - iter 16/24 - loss 0.45530655 - samples/sec: 111.59 - lr: 0.000008
2021-07-23 20:41:46,316 epoch 24 - iter 18/24 - loss 0.45256848 - samples/sec: 132.49 - lr: 0.000008
2021-07-23 20:41:46,844 epoch 24 - iter 20/24 - loss 0.45321962 - samples/sec: 121.48 - lr: 0.000008
2021-07-23 20:41:47,335 epoch 24 - iter 22/24 - loss 0.44850121 - samples/sec: 130.24 - lr: 0.000008
2021-07-23 20:41:47,659 epoch 24 - iter 24/24 - loss 0.43359050 - samples/sec: 197.71 - lr: 0.000008
2021-07-23 20:41:47,661 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:47,661 EPOCH 24 done: loss 0.4336 - lr 0.0000075
2021-07-23 20:41:48,456 DEV : loss 0.24399571120738983 - score 0.9443
2021-07-23 20:41:48,466 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:41:50,654 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:51,140 epoch 25 - iter 2/24 - loss 0.45438164 - samples/sec: 132.07 - lr: 0.000008
2021-07-23 20:41:51,684 epoch 25 - iter 4/24 - loss 0.48222299 - samples/sec: 117.88 - lr: 0.000008
2021-07-23 20:41:52,112 epoch 25 - iter 6/24 - loss 0.43799417 - samples/sec: 149.58 - lr: 0.000008
2021-07-23 20:41:52,607 epoch 25 - iter 8/24 - loss 0.41727819 - samples/sec: 129.36 - lr: 0.000008
2021-07-23 20:41:53,166 epoch 25 - iter 10/24 - loss 0.44545856 - samples/sec: 114.66 - lr: 0.000008
2021-07-23 20:41:53,701 epoch 25 - iter 12/24 - loss 0.44606278 - samples/sec: 119.58 - lr: 0.000008
2021-07-23 20:41:54,247 epoch 25 - iter 14/24 - loss 0.43592337 - samples/sec: 117.29 - lr: 0.000008
2021-07-23 20:41:54,720 epoch 25 - iter 16/24 - loss 0.43034485 - samples/sec: 135.36 - lr: 0.000008
2021-07-23 20:41:55,193 epoch 25 - iter 18/24 - loss 0.41958282 - samples/sec: 135.48 - lr: 0.000008
2021-07-23 20:41:55,738 epoch 25 - iter 20/24 - loss 0.41241599 - samples/sec: 117.49 - lr: 0.000008
2021-07-23 20:41:56,265 epoch 25 - iter 22/24 - loss 0.41502629 - samples/sec: 121.64 - lr: 0.000008
2021-07-23 20:41:56,591 epoch 25 - iter 24/24 - loss 0.40215624 - samples/sec: 196.57 - lr: 0.000008
2021-07-23 20:41:56,591 ----------------------------------------------------------------------------------------------------
2021-07-23 20:41:56,591 EPOCH 25 done: loss 0.4022 - lr 0.0000075
2021-07-23 20:41:57,738 DEV : loss 0.22938501834869385 - score 0.9471
2021-07-23 20:41:57,750 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:42:00,800 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:01,264 epoch 26 - iter 2/24 - loss 0.18932874 - samples/sec: 138.67 - lr: 0.000008
2021-07-23 20:42:01,800 epoch 26 - iter 4/24 - loss 0.28858416 - samples/sec: 119.36 - lr: 0.000008
2021-07-23 20:42:02,356 epoch 26 - iter 6/24 - loss 0.34569371 - samples/sec: 115.25 - lr: 0.000008
2021-07-23 20:42:02,904 epoch 26 - iter 8/24 - loss 0.37778820 - samples/sec: 116.91 - lr: 0.000008
2021-07-23 20:42:03,362 epoch 26 - iter 10/24 - loss 0.38990126 - samples/sec: 139.91 - lr: 0.000008
2021-07-23 20:42:03,878 epoch 26 - iter 12/24 - loss 0.40108659 - samples/sec: 124.15 - lr: 0.000008
2021-07-23 20:42:04,379 epoch 26 - iter 14/24 - loss 0.40584572 - samples/sec: 127.88 - lr: 0.000008
2021-07-23 20:42:04,858 epoch 26 - iter 16/24 - loss 0.41324779 - samples/sec: 133.70 - lr: 0.000008
2021-07-23 20:42:05,319 epoch 26 - iter 18/24 - loss 0.41585035 - samples/sec: 138.90 - lr: 0.000008
2021-07-23 20:42:05,890 epoch 26 - iter 20/24 - loss 0.41876508 - samples/sec: 112.08 - lr: 0.000008
2021-07-23 20:42:06,373 epoch 26 - iter 22/24 - loss 0.40479353 - samples/sec: 132.84 - lr: 0.000008
2021-07-23 20:42:06,723 epoch 26 - iter 24/24 - loss 0.40240709 - samples/sec: 182.69 - lr: 0.000008
2021-07-23 20:42:06,724 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:06,724 EPOCH 26 done: loss 0.4024 - lr 0.0000075
2021-07-23 20:42:07,512 DEV : loss 0.21576355397701263 - score 0.9526
2021-07-23 20:42:07,522 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:42:09,777 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:10,352 epoch 27 - iter 2/24 - loss 0.40123777 - samples/sec: 111.59 - lr: 0.000008
2021-07-23 20:42:10,848 epoch 27 - iter 4/24 - loss 0.35110822 - samples/sec: 129.13 - lr: 0.000008
2021-07-23 20:42:11,357 epoch 27 - iter 6/24 - loss 0.36468924 - samples/sec: 125.92 - lr: 0.000008
2021-07-23 20:42:11,850 epoch 27 - iter 8/24 - loss 0.38172023 - samples/sec: 130.04 - lr: 0.000008
2021-07-23 20:42:12,397 epoch 27 - iter 10/24 - loss 0.39289514 - samples/sec: 116.94 - lr: 0.000008
2021-07-23 20:42:12,946 epoch 27 - iter 12/24 - loss 0.37495691 - samples/sec: 116.72 - lr: 0.000008
2021-07-23 20:42:13,490 epoch 27 - iter 14/24 - loss 0.36020828 - samples/sec: 117.69 - lr: 0.000008
2021-07-23 20:42:14,005 epoch 27 - iter 16/24 - loss 0.36452544 - samples/sec: 124.38 - lr: 0.000008
2021-07-23 20:42:14,447 epoch 27 - iter 18/24 - loss 0.36951369 - samples/sec: 145.00 - lr: 0.000008
2021-07-23 20:42:14,972 epoch 27 - iter 20/24 - loss 0.36957651 - samples/sec: 121.91 - lr: 0.000008
2021-07-23 20:42:15,412 epoch 27 - iter 22/24 - loss 0.36121644 - samples/sec: 145.66 - lr: 0.000008
2021-07-23 20:42:15,687 epoch 27 - iter 24/24 - loss 0.36063492 - samples/sec: 232.68 - lr: 0.000008
2021-07-23 20:42:15,688 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:15,688 EPOCH 27 done: loss 0.3606 - lr 0.0000075
2021-07-23 20:42:16,481 DEV : loss 0.2043813019990921 - score 0.9526
2021-07-23 20:42:16,491 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:42:18,702 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:19,225 epoch 28 - iter 2/24 - loss 0.25498583 - samples/sec: 122.92 - lr: 0.000008
2021-07-23 20:42:19,734 epoch 28 - iter 4/24 - loss 0.39741962 - samples/sec: 125.84 - lr: 0.000008
2021-07-23 20:42:20,190 epoch 28 - iter 6/24 - loss 0.37343769 - samples/sec: 140.25 - lr: 0.000008
2021-07-23 20:42:20,689 epoch 28 - iter 8/24 - loss 0.36936628 - samples/sec: 128.44 - lr: 0.000008
2021-07-23 20:42:21,204 epoch 28 - iter 10/24 - loss 0.37587612 - samples/sec: 124.23 - lr: 0.000008
2021-07-23 20:42:21,687 epoch 28 - iter 12/24 - loss 0.37381256 - samples/sec: 132.66 - lr: 0.000008
2021-07-23 20:42:22,219 epoch 28 - iter 14/24 - loss 0.37496802 - samples/sec: 120.45 - lr: 0.000008
2021-07-23 20:42:22,764 epoch 28 - iter 16/24 - loss 0.37423080 - samples/sec: 117.51 - lr: 0.000008
2021-07-23 20:42:23,303 epoch 28 - iter 18/24 - loss 0.37635926 - samples/sec: 118.78 - lr: 0.000008
2021-07-23 20:42:23,787 epoch 28 - iter 20/24 - loss 0.37702673 - samples/sec: 132.23 - lr: 0.000008
2021-07-23 20:42:24,318 epoch 28 - iter 22/24 - loss 0.38031811 - samples/sec: 120.79 - lr: 0.000008
2021-07-23 20:42:24,642 epoch 28 - iter 24/24 - loss 0.36545739 - samples/sec: 197.55 - lr: 0.000008
2021-07-23 20:42:24,643 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:24,643 EPOCH 28 done: loss 0.3655 - lr 0.0000075
2021-07-23 20:42:25,438 DEV : loss 0.19261221587657928 - score 0.9554
2021-07-23 20:42:25,451 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:42:27,573 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:28,091 epoch 29 - iter 2/24 - loss 0.42833936 - samples/sec: 123.95 - lr: 0.000008
2021-07-23 20:42:28,584 epoch 29 - iter 4/24 - loss 0.37685601 - samples/sec: 129.89 - lr: 0.000008
2021-07-23 20:42:29,116 epoch 29 - iter 6/24 - loss 0.37542425 - samples/sec: 120.42 - lr: 0.000008
2021-07-23 20:42:29,596 epoch 29 - iter 8/24 - loss 0.36292950 - samples/sec: 133.38 - lr: 0.000008
2021-07-23 20:42:30,096 epoch 29 - iter 10/24 - loss 0.34617936 - samples/sec: 128.06 - lr: 0.000008
2021-07-23 20:42:30,560 epoch 29 - iter 12/24 - loss 0.34497601 - samples/sec: 138.20 - lr: 0.000008
2021-07-23 20:42:31,083 epoch 29 - iter 14/24 - loss 0.36096436 - samples/sec: 122.29 - lr: 0.000008
2021-07-23 20:42:31,600 epoch 29 - iter 16/24 - loss 0.35177948 - samples/sec: 123.96 - lr: 0.000008
2021-07-23 20:42:32,137 epoch 29 - iter 18/24 - loss 0.34663483 - samples/sec: 119.25 - lr: 0.000008
2021-07-23 20:42:32,672 epoch 29 - iter 20/24 - loss 0.34954564 - samples/sec: 119.70 - lr: 0.000008
2021-07-23 20:42:33,192 epoch 29 - iter 22/24 - loss 0.34315637 - samples/sec: 123.24 - lr: 0.000008
2021-07-23 20:42:33,524 epoch 29 - iter 24/24 - loss 0.32924102 - samples/sec: 192.70 - lr: 0.000008
2021-07-23 20:42:33,525 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:33,526 EPOCH 29 done: loss 0.3292 - lr 0.0000075
2021-07-23 20:42:34,315 DEV : loss 0.18212087452411652 - score 0.9556
2021-07-23 20:42:34,325 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:42:36,806 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:37,323 epoch 30 - iter 2/24 - loss 0.25808762 - samples/sec: 124.49 - lr: 0.000008
2021-07-23 20:42:37,873 epoch 30 - iter 4/24 - loss 0.29674771 - samples/sec: 116.33 - lr: 0.000008
2021-07-23 20:42:38,332 epoch 30 - iter 6/24 - loss 0.25057420 - samples/sec: 139.67 - lr: 0.000008
2021-07-23 20:42:38,880 epoch 30 - iter 8/24 - loss 0.30520588 - samples/sec: 116.77 - lr: 0.000008
2021-07-23 20:42:39,364 epoch 30 - iter 10/24 - loss 0.32649147 - samples/sec: 132.25 - lr: 0.000008
2021-07-23 20:42:39,909 epoch 30 - iter 12/24 - loss 0.34227312 - samples/sec: 117.65 - lr: 0.000008
2021-07-23 20:42:40,412 epoch 30 - iter 14/24 - loss 0.35716745 - samples/sec: 127.13 - lr: 0.000008
2021-07-23 20:42:40,912 epoch 30 - iter 16/24 - loss 0.35200597 - samples/sec: 128.19 - lr: 0.000008
2021-07-23 20:42:41,444 epoch 30 - iter 18/24 - loss 0.36185418 - samples/sec: 120.46 - lr: 0.000008
2021-07-23 20:42:41,916 epoch 30 - iter 20/24 - loss 0.35571977 - samples/sec: 135.52 - lr: 0.000008
2021-07-23 20:42:42,379 epoch 30 - iter 22/24 - loss 0.35382155 - samples/sec: 138.57 - lr: 0.000008
2021-07-23 20:42:42,762 epoch 30 - iter 24/24 - loss 0.34237899 - samples/sec: 167.14 - lr: 0.000008
2021-07-23 20:42:42,763 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:42,763 EPOCH 30 done: loss 0.3424 - lr 0.0000075
2021-07-23 20:42:43,877 DEV : loss 0.17272691428661346 - score 0.9556
2021-07-23 20:42:43,890 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:42:48,389 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:48,894 epoch 31 - iter 2/24 - loss 0.22055255 - samples/sec: 127.42 - lr: 0.000008
2021-07-23 20:42:49,324 epoch 31 - iter 4/24 - loss 0.26974493 - samples/sec: 148.79 - lr: 0.000008
2021-07-23 20:42:49,860 epoch 31 - iter 6/24 - loss 0.29579534 - samples/sec: 119.66 - lr: 0.000008
2021-07-23 20:42:50,380 epoch 31 - iter 8/24 - loss 0.30168854 - samples/sec: 122.96 - lr: 0.000008
2021-07-23 20:42:50,950 epoch 31 - iter 10/24 - loss 0.31057625 - samples/sec: 112.50 - lr: 0.000008
2021-07-23 20:42:51,444 epoch 31 - iter 12/24 - loss 0.31187715 - samples/sec: 129.65 - lr: 0.000008
2021-07-23 20:42:51,961 epoch 31 - iter 14/24 - loss 0.31269924 - samples/sec: 123.77 - lr: 0.000008
2021-07-23 20:42:52,520 epoch 31 - iter 16/24 - loss 0.31669910 - samples/sec: 114.51 - lr: 0.000008
2021-07-23 20:42:53,055 epoch 31 - iter 18/24 - loss 0.31890485 - samples/sec: 119.82 - lr: 0.000008
2021-07-23 20:42:53,588 epoch 31 - iter 20/24 - loss 0.33257882 - samples/sec: 120.02 - lr: 0.000008
2021-07-23 20:42:54,073 epoch 31 - iter 22/24 - loss 0.33623174 - samples/sec: 132.23 - lr: 0.000008
2021-07-23 20:42:54,346 epoch 31 - iter 24/24 - loss 0.32086430 - samples/sec: 234.90 - lr: 0.000008
2021-07-23 20:42:54,346 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:54,346 EPOCH 31 done: loss 0.3209 - lr 0.0000075
2021-07-23 20:42:55,136 DEV : loss 0.1644475907087326 - score 0.9556
2021-07-23 20:42:55,145 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:42:57,376 ----------------------------------------------------------------------------------------------------
2021-07-23 20:42:57,885 epoch 32 - iter 2/24 - loss 0.23404192 - samples/sec: 126.39 - lr: 0.000008
2021-07-23 20:42:58,492 epoch 32 - iter 4/24 - loss 0.42331504 - samples/sec: 105.50 - lr: 0.000008
2021-07-23 20:42:58,993 epoch 32 - iter 6/24 - loss 0.44090732 - samples/sec: 127.71 - lr: 0.000008
2021-07-23 20:42:59,532 epoch 32 - iter 8/24 - loss 0.40784633 - samples/sec: 118.95 - lr: 0.000008
2021-07-23 20:43:00,013 epoch 32 - iter 10/24 - loss 0.39771849 - samples/sec: 133.17 - lr: 0.000008
2021-07-23 20:43:00,499 epoch 32 - iter 12/24 - loss 0.38933925 - samples/sec: 131.65 - lr: 0.000008
2021-07-23 20:43:01,009 epoch 32 - iter 14/24 - loss 0.37260559 - samples/sec: 125.48 - lr: 0.000008
2021-07-23 20:43:01,569 epoch 32 - iter 16/24 - loss 0.36709150 - samples/sec: 114.35 - lr: 0.000008
2021-07-23 20:43:02,060 epoch 32 - iter 18/24 - loss 0.35991029 - samples/sec: 130.62 - lr: 0.000008
2021-07-23 20:43:02,533 epoch 32 - iter 20/24 - loss 0.35287120 - samples/sec: 135.45 - lr: 0.000008
2021-07-23 20:43:03,027 epoch 32 - iter 22/24 - loss 0.34068056 - samples/sec: 129.65 - lr: 0.000008
2021-07-23 20:43:03,439 epoch 32 - iter 24/24 - loss 0.35084299 - samples/sec: 155.21 - lr: 0.000008
2021-07-23 20:43:03,441 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:03,441 EPOCH 32 done: loss 0.3508 - lr 0.0000075
2021-07-23 20:43:04,234 DEV : loss 0.15622299909591675 - score 0.9556
2021-07-23 20:43:04,244 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:43:06,682 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:07,207 epoch 33 - iter 2/24 - loss 0.18735995 - samples/sec: 122.25 - lr: 0.000008
2021-07-23 20:43:07,729 epoch 33 - iter 4/24 - loss 0.30935478 - samples/sec: 122.77 - lr: 0.000008
2021-07-23 20:43:08,254 epoch 33 - iter 6/24 - loss 0.31320740 - samples/sec: 121.94 - lr: 0.000008
2021-07-23 20:43:08,755 epoch 33 - iter 8/24 - loss 0.30668308 - samples/sec: 127.83 - lr: 0.000008
2021-07-23 20:43:09,312 epoch 33 - iter 10/24 - loss 0.31848721 - samples/sec: 115.04 - lr: 0.000008
2021-07-23 20:43:09,816 epoch 33 - iter 12/24 - loss 0.33512094 - samples/sec: 127.23 - lr: 0.000008
2021-07-23 20:43:10,333 epoch 33 - iter 14/24 - loss 0.33252000 - samples/sec: 123.65 - lr: 0.000008
2021-07-23 20:43:10,792 epoch 33 - iter 16/24 - loss 0.32505363 - samples/sec: 139.68 - lr: 0.000008
2021-07-23 20:43:11,285 epoch 33 - iter 18/24 - loss 0.32640823 - samples/sec: 129.95 - lr: 0.000008
2021-07-23 20:43:11,816 epoch 33 - iter 20/24 - loss 0.32567149 - samples/sec: 120.56 - lr: 0.000008
2021-07-23 20:43:12,317 epoch 33 - iter 22/24 - loss 0.32709853 - samples/sec: 127.90 - lr: 0.000008
2021-07-23 20:43:12,635 epoch 33 - iter 24/24 - loss 0.30984702 - samples/sec: 201.48 - lr: 0.000008
2021-07-23 20:43:12,636 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:12,636 EPOCH 33 done: loss 0.3098 - lr 0.0000075
2021-07-23 20:43:13,425 DEV : loss 0.148781880736351 - score 0.9556
2021-07-23 20:43:13,435 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:43:15,751 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:16,256 epoch 34 - iter 2/24 - loss 0.25775847 - samples/sec: 127.36 - lr: 0.000008
2021-07-23 20:43:16,777 epoch 34 - iter 4/24 - loss 0.30892614 - samples/sec: 122.96 - lr: 0.000008
2021-07-23 20:43:17,354 epoch 34 - iter 6/24 - loss 0.32874239 - samples/sec: 110.97 - lr: 0.000008
2021-07-23 20:43:17,844 epoch 34 - iter 8/24 - loss 0.31517755 - samples/sec: 130.61 - lr: 0.000008
2021-07-23 20:43:18,323 epoch 34 - iter 10/24 - loss 0.32136919 - samples/sec: 133.84 - lr: 0.000008
2021-07-23 20:43:18,829 epoch 34 - iter 12/24 - loss 0.32716257 - samples/sec: 126.57 - lr: 0.000008
2021-07-23 20:43:19,332 epoch 34 - iter 14/24 - loss 0.31303577 - samples/sec: 127.19 - lr: 0.000008
2021-07-23 20:43:19,837 epoch 34 - iter 16/24 - loss 0.29975513 - samples/sec: 126.99 - lr: 0.000008
2021-07-23 20:43:20,349 epoch 34 - iter 18/24 - loss 0.30337739 - samples/sec: 125.06 - lr: 0.000008
2021-07-23 20:43:20,808 epoch 34 - iter 20/24 - loss 0.29077404 - samples/sec: 139.45 - lr: 0.000008
2021-07-23 20:43:21,344 epoch 34 - iter 22/24 - loss 0.29805208 - samples/sec: 119.40 - lr: 0.000008
2021-07-23 20:43:21,697 epoch 34 - iter 24/24 - loss 0.29415148 - samples/sec: 181.59 - lr: 0.000008
2021-07-23 20:43:21,698 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:21,698 EPOCH 34 done: loss 0.2942 - lr 0.0000075
2021-07-23 20:43:22,487 DEV : loss 0.1419791579246521 - score 0.9556
2021-07-23 20:43:22,497 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:43:24,884 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:25,359 epoch 35 - iter 2/24 - loss 0.25152799 - samples/sec: 135.38 - lr: 0.000008
2021-07-23 20:43:25,880 epoch 35 - iter 4/24 - loss 0.28620180 - samples/sec: 123.03 - lr: 0.000008
2021-07-23 20:43:26,433 epoch 35 - iter 6/24 - loss 0.30650132 - samples/sec: 115.72 - lr: 0.000008
2021-07-23 20:43:26,964 epoch 35 - iter 8/24 - loss 0.28627565 - samples/sec: 120.53 - lr: 0.000008
2021-07-23 20:43:27,451 epoch 35 - iter 10/24 - loss 0.29882935 - samples/sec: 131.52 - lr: 0.000008
2021-07-23 20:43:27,965 epoch 35 - iter 12/24 - loss 0.30307876 - samples/sec: 124.80 - lr: 0.000008
2021-07-23 20:43:28,457 epoch 35 - iter 14/24 - loss 0.30239026 - samples/sec: 130.01 - lr: 0.000008
2021-07-23 20:43:28,981 epoch 35 - iter 16/24 - loss 0.30209346 - samples/sec: 122.29 - lr: 0.000008
2021-07-23 20:43:29,440 epoch 35 - iter 18/24 - loss 0.30711150 - samples/sec: 139.56 - lr: 0.000008
2021-07-23 20:43:29,971 epoch 35 - iter 20/24 - loss 0.30129487 - samples/sec: 120.52 - lr: 0.000008
2021-07-23 20:43:30,464 epoch 35 - iter 22/24 - loss 0.29917416 - samples/sec: 130.05 - lr: 0.000008
2021-07-23 20:43:30,840 epoch 35 - iter 24/24 - loss 0.28553900 - samples/sec: 170.21 - lr: 0.000008
2021-07-23 20:43:30,841 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:30,842 EPOCH 35 done: loss 0.2855 - lr 0.0000075
2021-07-23 20:43:31,750 DEV : loss 0.13574610650539398 - score 0.9583
2021-07-23 20:43:31,762 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:43:36,123 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:36,664 epoch 36 - iter 2/24 - loss 0.26621275 - samples/sec: 118.77 - lr: 0.000008
2021-07-23 20:43:37,216 epoch 36 - iter 4/24 - loss 0.24936626 - samples/sec: 116.06 - lr: 0.000008
2021-07-23 20:43:37,786 epoch 36 - iter 6/24 - loss 0.27709316 - samples/sec: 112.30 - lr: 0.000008
2021-07-23 20:43:38,297 epoch 36 - iter 8/24 - loss 0.27042555 - samples/sec: 125.38 - lr: 0.000008
2021-07-23 20:43:38,744 epoch 36 - iter 10/24 - loss 0.26938301 - samples/sec: 143.23 - lr: 0.000008
2021-07-23 20:43:39,248 epoch 36 - iter 12/24 - loss 0.27385843 - samples/sec: 127.07 - lr: 0.000008
2021-07-23 20:43:39,752 epoch 36 - iter 14/24 - loss 0.26362228 - samples/sec: 127.08 - lr: 0.000008
2021-07-23 20:43:40,240 epoch 36 - iter 16/24 - loss 0.25659284 - samples/sec: 131.31 - lr: 0.000008
2021-07-23 20:43:40,756 epoch 36 - iter 18/24 - loss 0.26608398 - samples/sec: 124.20 - lr: 0.000008
2021-07-23 20:43:41,272 epoch 36 - iter 20/24 - loss 0.28028182 - samples/sec: 124.08 - lr: 0.000008
2021-07-23 20:43:41,763 epoch 36 - iter 22/24 - loss 0.28007966 - samples/sec: 130.42 - lr: 0.000008
2021-07-23 20:43:42,071 epoch 36 - iter 24/24 - loss 0.27219120 - samples/sec: 208.03 - lr: 0.000008
2021-07-23 20:43:42,072 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:42,072 EPOCH 36 done: loss 0.2722 - lr 0.0000075
2021-07-23 20:43:42,864 DEV : loss 0.1300937682390213 - score 0.9583
2021-07-23 20:43:42,874 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:43:45,287 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:45,828 epoch 37 - iter 2/24 - loss 0.30152375 - samples/sec: 118.73 - lr: 0.000008
2021-07-23 20:43:46,368 epoch 37 - iter 4/24 - loss 0.24731002 - samples/sec: 118.44 - lr: 0.000008
2021-07-23 20:43:46,868 epoch 37 - iter 6/24 - loss 0.22502089 - samples/sec: 128.20 - lr: 0.000008
2021-07-23 20:43:47,361 epoch 37 - iter 8/24 - loss 0.22237219 - samples/sec: 129.97 - lr: 0.000008
2021-07-23 20:43:47,857 epoch 37 - iter 10/24 - loss 0.22573642 - samples/sec: 129.03 - lr: 0.000008
2021-07-23 20:43:48,389 epoch 37 - iter 12/24 - loss 0.23997931 - samples/sec: 120.50 - lr: 0.000008
2021-07-23 20:43:48,848 epoch 37 - iter 14/24 - loss 0.25816803 - samples/sec: 139.48 - lr: 0.000008
2021-07-23 20:43:49,421 epoch 37 - iter 16/24 - loss 0.25450977 - samples/sec: 111.79 - lr: 0.000008
2021-07-23 20:43:49,895 epoch 37 - iter 18/24 - loss 0.26262391 - samples/sec: 135.08 - lr: 0.000008
2021-07-23 20:43:50,364 epoch 37 - iter 20/24 - loss 0.25919114 - samples/sec: 136.58 - lr: 0.000008
2021-07-23 20:43:50,857 epoch 37 - iter 22/24 - loss 0.26538345 - samples/sec: 129.87 - lr: 0.000008
2021-07-23 20:43:51,231 epoch 37 - iter 24/24 - loss 0.28635887 - samples/sec: 171.20 - lr: 0.000008
2021-07-23 20:43:51,232 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:51,232 EPOCH 37 done: loss 0.2864 - lr 0.0000075
2021-07-23 20:43:52,020 DEV : loss 0.12462585419416428 - score 0.961
2021-07-23 20:43:52,030 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:43:54,437 ----------------------------------------------------------------------------------------------------
2021-07-23 20:43:54,965 epoch 38 - iter 2/24 - loss 0.31785420 - samples/sec: 121.81 - lr: 0.000008
2021-07-23 20:43:55,468 epoch 38 - iter 4/24 - loss 0.29225300 - samples/sec: 127.23 - lr: 0.000008
2021-07-23 20:43:56,074 epoch 38 - iter 6/24 - loss 0.29662106 - samples/sec: 105.78 - lr: 0.000008
2021-07-23 20:43:56,548 epoch 38 - iter 8/24 - loss 0.26487299 - samples/sec: 135.07 - lr: 0.000008
2021-07-23 20:43:57,016 epoch 38 - iter 10/24 - loss 0.25538313 - samples/sec: 136.70 - lr: 0.000008
2021-07-23 20:43:57,553 epoch 38 - iter 12/24 - loss 0.25346484 - samples/sec: 119.24 - lr: 0.000008
2021-07-23 20:43:58,097 epoch 38 - iter 14/24 - loss 0.25490123 - samples/sec: 117.87 - lr: 0.000008
2021-07-23 20:43:58,621 epoch 38 - iter 16/24 - loss 0.25704361 - samples/sec: 122.24 - lr: 0.000008
2021-07-23 20:43:59,111 epoch 38 - iter 18/24 - loss 0.25613185 - samples/sec: 130.53 - lr: 0.000008
2021-07-23 20:43:59,605 epoch 38 - iter 20/24 - loss 0.26226668 - samples/sec: 129.82 - lr: 0.000008
2021-07-23 20:44:00,136 epoch 38 - iter 22/24 - loss 0.26391098 - samples/sec: 120.52 - lr: 0.000008
2021-07-23 20:44:00,486 epoch 38 - iter 24/24 - loss 0.28034593 - samples/sec: 183.12 - lr: 0.000008
2021-07-23 20:44:00,487 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:00,487 EPOCH 38 done: loss 0.2803 - lr 0.0000075
2021-07-23 20:44:01,277 DEV : loss 0.1196974441409111 - score 0.9637
2021-07-23 20:44:01,287 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:44:03,591 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:04,113 epoch 39 - iter 2/24 - loss 0.22565424 - samples/sec: 123.26 - lr: 0.000008
2021-07-23 20:44:04,625 epoch 39 - iter 4/24 - loss 0.23012597 - samples/sec: 125.02 - lr: 0.000008
2021-07-23 20:44:05,125 epoch 39 - iter 6/24 - loss 0.21256281 - samples/sec: 128.01 - lr: 0.000008
2021-07-23 20:44:05,573 epoch 39 - iter 8/24 - loss 0.22209766 - samples/sec: 143.20 - lr: 0.000008
2021-07-23 20:44:06,037 epoch 39 - iter 10/24 - loss 0.24377780 - samples/sec: 137.85 - lr: 0.000008
2021-07-23 20:44:06,556 epoch 39 - iter 12/24 - loss 0.24530840 - samples/sec: 123.44 - lr: 0.000008
2021-07-23 20:44:07,060 epoch 39 - iter 14/24 - loss 0.26569205 - samples/sec: 127.11 - lr: 0.000008
2021-07-23 20:44:07,522 epoch 39 - iter 16/24 - loss 0.26094794 - samples/sec: 138.73 - lr: 0.000008
2021-07-23 20:44:08,139 epoch 39 - iter 18/24 - loss 0.27533706 - samples/sec: 103.82 - lr: 0.000008
2021-07-23 20:44:08,620 epoch 39 - iter 20/24 - loss 0.27718636 - samples/sec: 133.03 - lr: 0.000008
2021-07-23 20:44:09,150 epoch 39 - iter 22/24 - loss 0.28104702 - samples/sec: 120.90 - lr: 0.000008
2021-07-23 20:44:09,530 epoch 39 - iter 24/24 - loss 0.26928060 - samples/sec: 168.72 - lr: 0.000008
2021-07-23 20:44:09,531 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:09,531 EPOCH 39 done: loss 0.2693 - lr 0.0000075
2021-07-23 20:44:10,324 DEV : loss 0.11500083655118942 - score 0.9689
2021-07-23 20:44:10,334 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:44:12,765 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:13,318 epoch 40 - iter 2/24 - loss 0.34844074 - samples/sec: 116.11 - lr: 0.000008
2021-07-23 20:44:13,781 epoch 40 - iter 4/24 - loss 0.28776475 - samples/sec: 138.44 - lr: 0.000008
2021-07-23 20:44:14,272 epoch 40 - iter 6/24 - loss 0.31993439 - samples/sec: 130.26 - lr: 0.000008
2021-07-23 20:44:14,800 epoch 40 - iter 8/24 - loss 0.31274895 - samples/sec: 121.25 - lr: 0.000008
2021-07-23 20:44:15,264 epoch 40 - iter 10/24 - loss 0.30045311 - samples/sec: 138.23 - lr: 0.000008
2021-07-23 20:44:15,747 epoch 40 - iter 12/24 - loss 0.26558844 - samples/sec: 132.67 - lr: 0.000008
2021-07-23 20:44:16,297 epoch 40 - iter 14/24 - loss 0.24513514 - samples/sec: 116.40 - lr: 0.000008
2021-07-23 20:44:16,787 epoch 40 - iter 16/24 - loss 0.24051565 - samples/sec: 130.60 - lr: 0.000008
2021-07-23 20:44:17,280 epoch 40 - iter 18/24 - loss 0.23305311 - samples/sec: 130.02 - lr: 0.000008
2021-07-23 20:44:17,831 epoch 40 - iter 20/24 - loss 0.22594626 - samples/sec: 116.13 - lr: 0.000008
2021-07-23 20:44:18,354 epoch 40 - iter 22/24 - loss 0.23680336 - samples/sec: 122.59 - lr: 0.000008
2021-07-23 20:44:18,701 epoch 40 - iter 24/24 - loss 0.23559415 - samples/sec: 184.58 - lr: 0.000008
2021-07-23 20:44:18,702 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:18,702 EPOCH 40 done: loss 0.2356 - lr 0.0000075
2021-07-23 20:44:19,692 DEV : loss 0.11055179685354233 - score 0.9689
2021-07-23 20:44:19,705 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 20:44:23,623 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:23,623 Testing using best model ...
2021-07-23 20:44:23,624 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/spa.rst.sctb/best-model.pt
2021-07-23 20:44:32,855 0.9911	0.9709	0.9809
2021-07-23 20:44:32,855 
Results:
- F1-score (micro) 0.9809
- F1-score (macro) 0.9754

By class:
SENT       tp: 122 - fp: 2 - fn: 10 - precision: 0.9839 - recall: 0.9242 - f1-score: 0.9531
X          tp: 212 - fp: 1 - fn: 0 - precision: 0.9953 - recall: 1.0000 - f1-score: 0.9976
2021-07-23 20:44:32,855 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.pdtb.pdtb/
2021-07-23 20:44:32,886 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.pdtb.pdtb
2021-07-23 20:44:32,886 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.pdtb.pdtb/sent_train.txt
2021-07-23 20:44:32,888 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.pdtb.pdtb/sent_dev.txt
2021-07-23 20:44:32,889 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.pdtb.pdtb/sent_test.txt
Corpus: 108980 train + 5406 dev + 34704 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 20:44:56,016 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:56,018 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 20:44:56,018 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:56,018 Corpus: "Corpus: 108980 train + 5406 dev + 34704 test sentences"
2021-07-23 20:44:56,018 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:56,018 Parameters:
2021-07-23 20:44:56,018  - learning_rate: "3e-05"
2021-07-23 20:44:56,018  - mini_batch_size: "32"
2021-07-23 20:44:56,018  - patience: "3"
2021-07-23 20:44:56,018  - anneal_factor: "0.5"
2021-07-23 20:44:56,018  - max_epochs: "40"
2021-07-23 20:44:56,018  - shuffle: "True"
2021-07-23 20:44:56,018  - train_with_dev: "False"
2021-07-23 20:44:56,018  - batch_growth_annealing: "False"
2021-07-23 20:44:56,018 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:56,018 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.pdtb.pdtb"
2021-07-23 20:44:56,018 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:56,018 Device: cuda:0
2021-07-23 20:44:56,019 ----------------------------------------------------------------------------------------------------
2021-07-23 20:44:56,019 Embeddings storage mode: cpu
2021-07-23 20:44:56,021 ----------------------------------------------------------------------------------------------------
2021-07-23 20:48:15,610 epoch 1 - iter 340/3406 - loss 0.82115721 - samples/sec: 54.52 - lr: 0.000030
2021-07-23 20:51:40,472 epoch 1 - iter 680/3406 - loss 0.50917836 - samples/sec: 53.11 - lr: 0.000030
2021-07-23 20:55:11,864 epoch 1 - iter 1020/3406 - loss 0.38526956 - samples/sec: 51.47 - lr: 0.000030
2021-07-23 20:58:46,821 epoch 1 - iter 1360/3406 - loss 0.32337224 - samples/sec: 50.62 - lr: 0.000030
2021-07-23 21:02:11,314 epoch 1 - iter 1700/3406 - loss 0.28264718 - samples/sec: 53.21 - lr: 0.000030
2021-07-23 21:05:31,253 epoch 1 - iter 2040/3406 - loss 0.25882779 - samples/sec: 54.42 - lr: 0.000030
2021-07-23 21:08:51,283 epoch 1 - iter 2380/3406 - loss 0.23846584 - samples/sec: 54.40 - lr: 0.000030
2021-07-23 21:12:11,569 epoch 1 - iter 2720/3406 - loss 0.22428966 - samples/sec: 54.33 - lr: 0.000030
2021-07-23 21:15:35,107 epoch 1 - iter 3060/3406 - loss 0.21094555 - samples/sec: 53.46 - lr: 0.000030
2021-07-23 21:18:56,211 epoch 1 - iter 3400/3406 - loss 0.20049154 - samples/sec: 54.10 - lr: 0.000030
2021-07-23 21:18:59,545 ----------------------------------------------------------------------------------------------------
2021-07-23 21:18:59,546 EPOCH 1 done: loss 0.2003 - lr 0.0000300
2021-07-23 21:20:10,189 DEV : loss 0.0634215921163559 - score 0.9826
2021-07-23 21:20:10,336 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:20:10,890 ----------------------------------------------------------------------------------------------------
2021-07-23 21:21:32,993 epoch 2 - iter 340/3406 - loss 0.11285106 - samples/sec: 132.55 - lr: 0.000030
2021-07-23 21:22:54,834 epoch 2 - iter 680/3406 - loss 0.10729489 - samples/sec: 132.97 - lr: 0.000030
2021-07-23 21:24:15,992 epoch 2 - iter 1020/3406 - loss 0.10583143 - samples/sec: 134.09 - lr: 0.000030
2021-07-23 21:25:37,507 epoch 2 - iter 1360/3406 - loss 0.10393066 - samples/sec: 133.50 - lr: 0.000030
2021-07-23 21:26:59,628 epoch 2 - iter 1700/3406 - loss 0.10313432 - samples/sec: 132.52 - lr: 0.000030
2021-07-23 21:28:21,711 epoch 2 - iter 2040/3406 - loss 0.10139845 - samples/sec: 132.58 - lr: 0.000030
2021-07-23 21:29:42,925 epoch 2 - iter 2380/3406 - loss 0.10079264 - samples/sec: 134.00 - lr: 0.000030
2021-07-23 21:31:05,468 epoch 2 - iter 2720/3406 - loss 0.09995847 - samples/sec: 131.84 - lr: 0.000030
2021-07-23 21:32:27,064 epoch 2 - iter 3060/3406 - loss 0.09905539 - samples/sec: 133.37 - lr: 0.000030
2021-07-23 21:33:48,460 epoch 2 - iter 3400/3406 - loss 0.09788918 - samples/sec: 133.69 - lr: 0.000030
2021-07-23 21:33:49,915 ----------------------------------------------------------------------------------------------------
2021-07-23 21:33:49,916 EPOCH 2 done: loss 0.0979 - lr 0.0000300
2021-07-23 21:34:02,989 DEV : loss 0.055443521589040756 - score 0.9842
2021-07-23 21:34:03,134 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:34:05,539 ----------------------------------------------------------------------------------------------------
2021-07-23 21:35:28,255 epoch 3 - iter 340/3406 - loss 0.09200951 - samples/sec: 131.58 - lr: 0.000030
2021-07-23 21:36:50,619 epoch 3 - iter 680/3406 - loss 0.08687734 - samples/sec: 132.13 - lr: 0.000030
2021-07-23 21:38:12,712 epoch 3 - iter 1020/3406 - loss 0.08582087 - samples/sec: 132.56 - lr: 0.000030
2021-07-23 21:39:35,388 epoch 3 - iter 1360/3406 - loss 0.08517065 - samples/sec: 131.63 - lr: 0.000030
2021-07-23 21:40:56,883 epoch 3 - iter 1700/3406 - loss 0.08434145 - samples/sec: 133.53 - lr: 0.000030
2021-07-23 21:42:19,237 epoch 3 - iter 2040/3406 - loss 0.08394955 - samples/sec: 132.14 - lr: 0.000030
2021-07-23 21:43:40,383 epoch 3 - iter 2380/3406 - loss 0.08253577 - samples/sec: 134.11 - lr: 0.000030
2021-07-23 21:45:02,109 epoch 3 - iter 2720/3406 - loss 0.08160732 - samples/sec: 133.15 - lr: 0.000030
2021-07-23 21:46:24,951 epoch 3 - iter 3060/3406 - loss 0.08104931 - samples/sec: 131.36 - lr: 0.000030
2021-07-23 21:47:47,740 epoch 3 - iter 3400/3406 - loss 0.08027736 - samples/sec: 131.45 - lr: 0.000030
2021-07-23 21:47:49,084 ----------------------------------------------------------------------------------------------------
2021-07-23 21:47:49,084 EPOCH 3 done: loss 0.0803 - lr 0.0000300
2021-07-23 21:48:02,204 DEV : loss 0.04994850605726242 - score 0.9864
2021-07-23 21:48:02,351 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 21:48:04,808 ----------------------------------------------------------------------------------------------------
2021-07-23 21:49:27,587 epoch 4 - iter 340/3406 - loss 0.07175764 - samples/sec: 131.48 - lr: 0.000030
2021-07-23 21:50:50,759 epoch 4 - iter 680/3406 - loss 0.07207078 - samples/sec: 130.84 - lr: 0.000030
2021-07-23 21:52:14,257 epoch 4 - iter 1020/3406 - loss 0.07403000 - samples/sec: 130.33 - lr: 0.000030
2021-07-23 21:53:37,118 epoch 4 - iter 1360/3406 - loss 0.07510134 - samples/sec: 131.33 - lr: 0.000030
2021-07-23 21:54:59,700 epoch 4 - iter 1700/3406 - loss 0.07491972 - samples/sec: 131.78 - lr: 0.000030
2021-07-23 21:56:22,624 epoch 4 - iter 2040/3406 - loss 0.07508363 - samples/sec: 131.23 - lr: 0.000030
2021-07-23 21:57:44,697 epoch 4 - iter 2380/3406 - loss 0.07485150 - samples/sec: 132.59 - lr: 0.000030
2021-07-23 21:59:07,159 epoch 4 - iter 2720/3406 - loss 0.07424013 - samples/sec: 131.97 - lr: 0.000030
2021-07-23 22:00:29,753 epoch 4 - iter 3060/3406 - loss 0.07423646 - samples/sec: 131.76 - lr: 0.000030
2021-07-23 22:01:52,568 epoch 4 - iter 3400/3406 - loss 0.07365940 - samples/sec: 131.40 - lr: 0.000030
2021-07-23 22:01:53,906 ----------------------------------------------------------------------------------------------------
2021-07-23 22:01:53,907 EPOCH 4 done: loss 0.0737 - lr 0.0000300
2021-07-23 22:02:07,243 DEV : loss 0.048485204577445984 - score 0.9874
2021-07-23 22:02:07,389 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 22:02:10,084 ----------------------------------------------------------------------------------------------------
2021-07-23 22:03:33,092 epoch 5 - iter 340/3406 - loss 0.06729739 - samples/sec: 131.11 - lr: 0.000030
2021-07-23 22:04:55,716 epoch 5 - iter 680/3406 - loss 0.06841676 - samples/sec: 131.71 - lr: 0.000030
2021-07-23 22:06:18,655 epoch 5 - iter 1020/3406 - loss 0.06849035 - samples/sec: 131.21 - lr: 0.000030
2021-07-23 22:07:42,121 epoch 5 - iter 1360/3406 - loss 0.06903710 - samples/sec: 130.38 - lr: 0.000030
2021-07-23 22:09:05,378 epoch 5 - iter 1700/3406 - loss 0.06905338 - samples/sec: 130.71 - lr: 0.000030
2021-07-23 22:10:27,687 epoch 5 - iter 2040/3406 - loss 0.06798706 - samples/sec: 132.21 - lr: 0.000030
2021-07-23 22:11:50,706 epoch 5 - iter 2380/3406 - loss 0.06790407 - samples/sec: 131.08 - lr: 0.000030
2021-07-23 22:13:12,591 epoch 5 - iter 2720/3406 - loss 0.06796668 - samples/sec: 132.90 - lr: 0.000030
2021-07-23 22:14:35,301 epoch 5 - iter 3060/3406 - loss 0.06790821 - samples/sec: 131.57 - lr: 0.000030
2021-07-23 22:15:58,141 epoch 5 - iter 3400/3406 - loss 0.06811220 - samples/sec: 131.36 - lr: 0.000030
2021-07-23 22:15:59,558 ----------------------------------------------------------------------------------------------------
2021-07-23 22:15:59,558 EPOCH 5 done: loss 0.0681 - lr 0.0000300
2021-07-23 22:16:12,962 DEV : loss 0.047120291739702225 - score 0.9862
2021-07-23 22:16:13,109 BAD EPOCHS (no improvement): 1
2021-07-23 22:16:13,109 ----------------------------------------------------------------------------------------------------
2021-07-23 22:17:36,081 epoch 6 - iter 340/3406 - loss 0.06423023 - samples/sec: 131.17 - lr: 0.000030
2021-07-23 22:18:58,816 epoch 6 - iter 680/3406 - loss 0.06535200 - samples/sec: 131.53 - lr: 0.000030
2021-07-23 22:20:22,233 epoch 6 - iter 1020/3406 - loss 0.06525022 - samples/sec: 130.46 - lr: 0.000030
2021-07-23 22:21:45,208 epoch 6 - iter 1360/3406 - loss 0.06359958 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 22:23:08,271 epoch 6 - iter 1700/3406 - loss 0.06388091 - samples/sec: 131.01 - lr: 0.000030
2021-07-23 22:24:30,468 epoch 6 - iter 2040/3406 - loss 0.06361744 - samples/sec: 132.39 - lr: 0.000030
2021-07-23 22:25:53,158 epoch 6 - iter 2380/3406 - loss 0.06382511 - samples/sec: 131.60 - lr: 0.000030
2021-07-23 22:27:16,229 epoch 6 - iter 2720/3406 - loss 0.06328140 - samples/sec: 131.00 - lr: 0.000030
2021-07-23 22:28:40,108 epoch 6 - iter 3060/3406 - loss 0.06312832 - samples/sec: 129.74 - lr: 0.000030
2021-07-23 22:30:02,345 epoch 6 - iter 3400/3406 - loss 0.06295851 - samples/sec: 132.33 - lr: 0.000030
2021-07-23 22:30:03,690 ----------------------------------------------------------------------------------------------------
2021-07-23 22:30:03,690 EPOCH 6 done: loss 0.0629 - lr 0.0000300
2021-07-23 22:30:20,024 DEV : loss 0.044466130435466766 - score 0.9886
2021-07-23 22:30:20,174 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 22:30:22,573 ----------------------------------------------------------------------------------------------------
2021-07-23 22:31:46,438 epoch 7 - iter 340/3406 - loss 0.05822274 - samples/sec: 129.77 - lr: 0.000030
2021-07-23 22:33:09,228 epoch 7 - iter 680/3406 - loss 0.05882556 - samples/sec: 131.44 - lr: 0.000030
2021-07-23 22:34:32,564 epoch 7 - iter 1020/3406 - loss 0.06110557 - samples/sec: 130.58 - lr: 0.000030
2021-07-23 22:35:55,413 epoch 7 - iter 1360/3406 - loss 0.06145918 - samples/sec: 131.35 - lr: 0.000030
2021-07-23 22:37:18,677 epoch 7 - iter 1700/3406 - loss 0.06176050 - samples/sec: 130.70 - lr: 0.000030
2021-07-23 22:38:40,855 epoch 7 - iter 2040/3406 - loss 0.06224856 - samples/sec: 132.42 - lr: 0.000030
2021-07-23 22:40:02,760 epoch 7 - iter 2380/3406 - loss 0.06185832 - samples/sec: 132.87 - lr: 0.000030
2021-07-23 22:41:26,500 epoch 7 - iter 2720/3406 - loss 0.06130185 - samples/sec: 129.95 - lr: 0.000030
2021-07-23 22:42:49,475 epoch 7 - iter 3060/3406 - loss 0.06123362 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 22:44:12,029 epoch 7 - iter 3400/3406 - loss 0.06108385 - samples/sec: 131.82 - lr: 0.000030
2021-07-23 22:44:13,384 ----------------------------------------------------------------------------------------------------
2021-07-23 22:44:13,384 EPOCH 7 done: loss 0.0610 - lr 0.0000300
2021-07-23 22:44:26,703 DEV : loss 0.0429588258266449 - score 0.988
2021-07-23 22:44:26,854 BAD EPOCHS (no improvement): 1
2021-07-23 22:44:26,854 ----------------------------------------------------------------------------------------------------
2021-07-23 22:45:49,834 epoch 8 - iter 340/3406 - loss 0.06447249 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 22:47:12,348 epoch 8 - iter 680/3406 - loss 0.06365003 - samples/sec: 131.88 - lr: 0.000030
2021-07-23 22:48:34,837 epoch 8 - iter 1020/3406 - loss 0.06094629 - samples/sec: 131.92 - lr: 0.000030
2021-07-23 22:49:57,283 epoch 8 - iter 1360/3406 - loss 0.06038348 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 22:51:21,218 epoch 8 - iter 1700/3406 - loss 0.05985117 - samples/sec: 129.65 - lr: 0.000030
2021-07-23 22:52:43,895 epoch 8 - iter 2040/3406 - loss 0.05912335 - samples/sec: 131.62 - lr: 0.000030
2021-07-23 22:54:06,703 epoch 8 - iter 2380/3406 - loss 0.05905386 - samples/sec: 131.42 - lr: 0.000030
2021-07-23 22:55:29,420 epoch 8 - iter 2720/3406 - loss 0.05853909 - samples/sec: 131.56 - lr: 0.000030
2021-07-23 22:56:52,476 epoch 8 - iter 3060/3406 - loss 0.05900581 - samples/sec: 131.02 - lr: 0.000030
2021-07-23 22:58:15,405 epoch 8 - iter 3400/3406 - loss 0.05889041 - samples/sec: 131.22 - lr: 0.000030
2021-07-23 22:58:16,788 ----------------------------------------------------------------------------------------------------
2021-07-23 22:58:16,788 EPOCH 8 done: loss 0.0589 - lr 0.0000300
2021-07-23 22:58:30,044 DEV : loss 0.04199855029582977 - score 0.9891
2021-07-23 22:58:30,194 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 22:58:32,584 ----------------------------------------------------------------------------------------------------
2021-07-23 22:59:56,132 epoch 9 - iter 340/3406 - loss 0.05976625 - samples/sec: 130.26 - lr: 0.000030
2021-07-23 23:01:18,518 epoch 9 - iter 680/3406 - loss 0.05617759 - samples/sec: 132.09 - lr: 0.000030
2021-07-23 23:02:41,296 epoch 9 - iter 1020/3406 - loss 0.05652617 - samples/sec: 131.46 - lr: 0.000030
2021-07-23 23:04:04,268 epoch 9 - iter 1360/3406 - loss 0.05716295 - samples/sec: 131.16 - lr: 0.000030
2021-07-23 23:05:27,276 epoch 9 - iter 1700/3406 - loss 0.05761853 - samples/sec: 131.10 - lr: 0.000030
2021-07-23 23:06:50,845 epoch 9 - iter 2040/3406 - loss 0.05780652 - samples/sec: 130.22 - lr: 0.000030
2021-07-23 23:08:13,961 epoch 9 - iter 2380/3406 - loss 0.05749011 - samples/sec: 130.93 - lr: 0.000030
2021-07-23 23:09:37,492 epoch 9 - iter 2720/3406 - loss 0.05704041 - samples/sec: 130.28 - lr: 0.000030
2021-07-23 23:11:01,060 epoch 9 - iter 3060/3406 - loss 0.05684625 - samples/sec: 130.22 - lr: 0.000030
2021-07-23 23:12:23,539 epoch 9 - iter 3400/3406 - loss 0.05670529 - samples/sec: 131.94 - lr: 0.000030
2021-07-23 23:12:24,885 ----------------------------------------------------------------------------------------------------
2021-07-23 23:12:24,885 EPOCH 9 done: loss 0.0567 - lr 0.0000300
2021-07-23 23:12:38,189 DEV : loss 0.04344440996646881 - score 0.989
2021-07-23 23:12:38,339 BAD EPOCHS (no improvement): 1
2021-07-23 23:12:38,339 ----------------------------------------------------------------------------------------------------
2021-07-23 23:14:01,821 epoch 10 - iter 340/3406 - loss 0.05404913 - samples/sec: 130.36 - lr: 0.000030
2021-07-23 23:15:25,216 epoch 10 - iter 680/3406 - loss 0.05555660 - samples/sec: 130.49 - lr: 0.000030
2021-07-23 23:16:48,567 epoch 10 - iter 1020/3406 - loss 0.05351137 - samples/sec: 130.56 - lr: 0.000030
2021-07-23 23:18:11,464 epoch 10 - iter 1360/3406 - loss 0.05525703 - samples/sec: 131.28 - lr: 0.000030
2021-07-23 23:19:33,950 epoch 10 - iter 1700/3406 - loss 0.05505716 - samples/sec: 131.93 - lr: 0.000030
2021-07-23 23:20:57,047 epoch 10 - iter 2040/3406 - loss 0.05588983 - samples/sec: 130.96 - lr: 0.000030
2021-07-23 23:22:20,963 epoch 10 - iter 2380/3406 - loss 0.05594928 - samples/sec: 129.68 - lr: 0.000030
2021-07-23 23:23:43,719 epoch 10 - iter 2720/3406 - loss 0.05555845 - samples/sec: 131.50 - lr: 0.000030
2021-07-23 23:25:05,836 epoch 10 - iter 3060/3406 - loss 0.05498578 - samples/sec: 132.52 - lr: 0.000030
2021-07-23 23:26:27,978 epoch 10 - iter 3400/3406 - loss 0.05473136 - samples/sec: 132.48 - lr: 0.000030
2021-07-23 23:26:29,350 ----------------------------------------------------------------------------------------------------
2021-07-23 23:26:29,351 EPOCH 10 done: loss 0.0548 - lr 0.0000300
2021-07-23 23:26:42,653 DEV : loss 0.04288347437977791 - score 0.9884
2021-07-23 23:26:42,801 BAD EPOCHS (no improvement): 2
2021-07-23 23:26:42,801 ----------------------------------------------------------------------------------------------------
2021-07-23 23:28:05,786 epoch 11 - iter 340/3406 - loss 0.05136970 - samples/sec: 131.14 - lr: 0.000030
2021-07-23 23:29:28,635 epoch 11 - iter 680/3406 - loss 0.05206549 - samples/sec: 131.35 - lr: 0.000030
2021-07-23 23:30:51,265 epoch 11 - iter 1020/3406 - loss 0.05354929 - samples/sec: 131.70 - lr: 0.000030
2021-07-23 23:32:13,655 epoch 11 - iter 1360/3406 - loss 0.05495228 - samples/sec: 132.08 - lr: 0.000030
2021-07-23 23:33:37,057 epoch 11 - iter 1700/3406 - loss 0.05439766 - samples/sec: 130.48 - lr: 0.000030
2021-07-23 23:34:59,362 epoch 11 - iter 2040/3406 - loss 0.05435563 - samples/sec: 132.22 - lr: 0.000030
2021-07-23 23:36:23,091 epoch 11 - iter 2380/3406 - loss 0.05442985 - samples/sec: 129.97 - lr: 0.000030
2021-07-23 23:37:46,457 epoch 11 - iter 2720/3406 - loss 0.05437827 - samples/sec: 130.54 - lr: 0.000030
2021-07-23 23:39:09,308 epoch 11 - iter 3060/3406 - loss 0.05420051 - samples/sec: 131.35 - lr: 0.000030
2021-07-23 23:40:32,517 epoch 11 - iter 3400/3406 - loss 0.05357791 - samples/sec: 130.78 - lr: 0.000030
2021-07-23 23:40:33,936 ----------------------------------------------------------------------------------------------------
2021-07-23 23:40:33,937 EPOCH 11 done: loss 0.0535 - lr 0.0000300
2021-07-23 23:40:47,272 DEV : loss 0.04201297461986542 - score 0.9892
2021-07-23 23:40:47,421 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 23:40:49,832 ----------------------------------------------------------------------------------------------------
2021-07-23 23:42:12,637 epoch 12 - iter 340/3406 - loss 0.04703683 - samples/sec: 131.44 - lr: 0.000030
2021-07-23 23:43:35,720 epoch 12 - iter 680/3406 - loss 0.04965479 - samples/sec: 130.98 - lr: 0.000030
2021-07-23 23:44:58,129 epoch 12 - iter 1020/3406 - loss 0.04969160 - samples/sec: 132.05 - lr: 0.000030
2021-07-23 23:46:21,206 epoch 12 - iter 1360/3406 - loss 0.05099974 - samples/sec: 130.99 - lr: 0.000030
2021-07-23 23:47:44,585 epoch 12 - iter 1700/3406 - loss 0.05094883 - samples/sec: 130.52 - lr: 0.000030
2021-07-23 23:49:07,701 epoch 12 - iter 2040/3406 - loss 0.05151587 - samples/sec: 130.93 - lr: 0.000030
2021-07-23 23:50:30,132 epoch 12 - iter 2380/3406 - loss 0.05176386 - samples/sec: 132.02 - lr: 0.000030
2021-07-23 23:51:52,940 epoch 12 - iter 2720/3406 - loss 0.05163784 - samples/sec: 131.42 - lr: 0.000030
2021-07-23 23:53:15,478 epoch 12 - iter 3060/3406 - loss 0.05134279 - samples/sec: 131.85 - lr: 0.000030
2021-07-23 23:54:38,320 epoch 12 - iter 3400/3406 - loss 0.05144071 - samples/sec: 131.36 - lr: 0.000030
2021-07-23 23:54:39,649 ----------------------------------------------------------------------------------------------------
2021-07-23 23:54:39,649 EPOCH 12 done: loss 0.0514 - lr 0.0000300
2021-07-23 23:54:52,907 DEV : loss 0.040284641087055206 - score 0.9904
2021-07-23 23:54:53,057 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 23:54:55,666 ----------------------------------------------------------------------------------------------------
2021-07-23 23:56:17,900 epoch 13 - iter 340/3406 - loss 0.05324467 - samples/sec: 132.35 - lr: 0.000030
2021-07-23 23:57:40,667 epoch 13 - iter 680/3406 - loss 0.05167907 - samples/sec: 131.48 - lr: 0.000030
2021-07-23 23:59:03,552 epoch 13 - iter 1020/3406 - loss 0.05105546 - samples/sec: 131.29 - lr: 0.000030
2021-07-24 00:00:25,974 epoch 13 - iter 1360/3406 - loss 0.05083721 - samples/sec: 132.03 - lr: 0.000030
2021-07-24 00:01:48,356 epoch 13 - iter 1700/3406 - loss 0.05137584 - samples/sec: 132.10 - lr: 0.000030
2021-07-24 00:03:11,249 epoch 13 - iter 2040/3406 - loss 0.05191187 - samples/sec: 131.28 - lr: 0.000030
2021-07-24 00:04:33,323 epoch 13 - iter 2380/3406 - loss 0.05111853 - samples/sec: 132.59 - lr: 0.000030
2021-07-24 00:05:55,948 epoch 13 - iter 2720/3406 - loss 0.05133033 - samples/sec: 131.71 - lr: 0.000030
2021-07-24 00:07:19,634 epoch 13 - iter 3060/3406 - loss 0.05163417 - samples/sec: 130.04 - lr: 0.000030
2021-07-24 00:08:42,790 epoch 13 - iter 3400/3406 - loss 0.05162737 - samples/sec: 130.87 - lr: 0.000030
2021-07-24 00:08:44,190 ----------------------------------------------------------------------------------------------------
2021-07-24 00:08:44,190 EPOCH 13 done: loss 0.0516 - lr 0.0000300
2021-07-24 00:09:00,482 DEV : loss 0.04327872768044472 - score 0.9893
2021-07-24 00:09:00,631 BAD EPOCHS (no improvement): 1
2021-07-24 00:09:00,631 ----------------------------------------------------------------------------------------------------
2021-07-24 00:10:23,687 epoch 14 - iter 340/3406 - loss 0.04939807 - samples/sec: 131.03 - lr: 0.000030
2021-07-24 00:11:47,081 epoch 14 - iter 680/3406 - loss 0.04920414 - samples/sec: 130.49 - lr: 0.000030
2021-07-24 00:13:10,276 epoch 14 - iter 1020/3406 - loss 0.05004350 - samples/sec: 130.81 - lr: 0.000030
2021-07-24 00:14:33,226 epoch 14 - iter 1360/3406 - loss 0.04972759 - samples/sec: 131.19 - lr: 0.000030
2021-07-24 00:15:56,701 epoch 14 - iter 1700/3406 - loss 0.04961864 - samples/sec: 130.37 - lr: 0.000030
2021-07-24 00:17:19,484 epoch 14 - iter 2040/3406 - loss 0.04933472 - samples/sec: 131.45 - lr: 0.000030
2021-07-24 00:18:42,387 epoch 14 - iter 2380/3406 - loss 0.04971740 - samples/sec: 131.27 - lr: 0.000030
2021-07-24 00:20:05,285 epoch 14 - iter 2720/3406 - loss 0.04987533 - samples/sec: 131.27 - lr: 0.000030
2021-07-24 00:21:28,152 epoch 14 - iter 3060/3406 - loss 0.04983957 - samples/sec: 131.32 - lr: 0.000030
2021-07-24 00:22:51,067 epoch 14 - iter 3400/3406 - loss 0.04958152 - samples/sec: 131.25 - lr: 0.000030
2021-07-24 00:22:52,363 ----------------------------------------------------------------------------------------------------
2021-07-24 00:22:52,363 EPOCH 14 done: loss 0.0497 - lr 0.0000300
2021-07-24 00:23:05,713 DEV : loss 0.043051715940237045 - score 0.9891
2021-07-24 00:23:05,861 BAD EPOCHS (no improvement): 2
2021-07-24 00:23:05,861 ----------------------------------------------------------------------------------------------------
2021-07-24 00:24:28,425 epoch 15 - iter 340/3406 - loss 0.04461732 - samples/sec: 131.81 - lr: 0.000030
2021-07-24 00:25:50,863 epoch 15 - iter 680/3406 - loss 0.04823518 - samples/sec: 132.01 - lr: 0.000030
2021-07-24 00:27:14,176 epoch 15 - iter 1020/3406 - loss 0.04769525 - samples/sec: 130.62 - lr: 0.000030
2021-07-24 00:28:36,686 epoch 15 - iter 1360/3406 - loss 0.04783059 - samples/sec: 131.89 - lr: 0.000030
2021-07-24 00:29:59,448 epoch 15 - iter 1700/3406 - loss 0.04828776 - samples/sec: 131.49 - lr: 0.000030
2021-07-24 00:31:22,306 epoch 15 - iter 2040/3406 - loss 0.04872230 - samples/sec: 131.34 - lr: 0.000030
2021-07-24 00:32:44,444 epoch 15 - iter 2380/3406 - loss 0.04868730 - samples/sec: 132.49 - lr: 0.000030
2021-07-24 00:34:07,283 epoch 15 - iter 2720/3406 - loss 0.04893470 - samples/sec: 131.36 - lr: 0.000030
2021-07-24 00:35:29,723 epoch 15 - iter 3060/3406 - loss 0.04831467 - samples/sec: 132.00 - lr: 0.000030
2021-07-24 00:36:52,731 epoch 15 - iter 3400/3406 - loss 0.04830058 - samples/sec: 131.10 - lr: 0.000030
2021-07-24 00:36:54,136 ----------------------------------------------------------------------------------------------------
2021-07-24 00:36:54,136 EPOCH 15 done: loss 0.0483 - lr 0.0000300
2021-07-24 00:37:07,388 DEV : loss 0.043692637234926224 - score 0.9898
2021-07-24 00:37:07,537 BAD EPOCHS (no improvement): 3
2021-07-24 00:37:07,538 ----------------------------------------------------------------------------------------------------
2021-07-24 00:38:31,112 epoch 16 - iter 340/3406 - loss 0.04768064 - samples/sec: 130.22 - lr: 0.000030
2021-07-24 00:39:53,576 epoch 16 - iter 680/3406 - loss 0.04718114 - samples/sec: 131.96 - lr: 0.000030
2021-07-24 00:41:16,896 epoch 16 - iter 1020/3406 - loss 0.04706072 - samples/sec: 130.61 - lr: 0.000030
2021-07-24 00:42:39,434 epoch 16 - iter 1360/3406 - loss 0.04588210 - samples/sec: 131.84 - lr: 0.000030
2021-07-24 00:44:02,477 epoch 16 - iter 1700/3406 - loss 0.04681944 - samples/sec: 131.04 - lr: 0.000030
2021-07-24 00:45:25,836 epoch 16 - iter 2040/3406 - loss 0.04654066 - samples/sec: 130.55 - lr: 0.000030
2021-07-24 00:46:48,576 epoch 16 - iter 2380/3406 - loss 0.04694671 - samples/sec: 131.52 - lr: 0.000030
2021-07-24 00:48:10,527 epoch 16 - iter 2720/3406 - loss 0.04715804 - samples/sec: 132.79 - lr: 0.000030
2021-07-24 00:49:34,108 epoch 16 - iter 3060/3406 - loss 0.04739313 - samples/sec: 130.20 - lr: 0.000030
2021-07-24 00:50:56,789 epoch 16 - iter 3400/3406 - loss 0.04745188 - samples/sec: 131.62 - lr: 0.000030
2021-07-24 00:50:58,091 ----------------------------------------------------------------------------------------------------
2021-07-24 00:50:58,091 EPOCH 16 done: loss 0.0475 - lr 0.0000300
2021-07-24 00:51:11,463 DEV : loss 0.042771853506565094 - score 0.9897
Epoch    16: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 00:51:11,612 BAD EPOCHS (no improvement): 4
2021-07-24 00:51:11,612 ----------------------------------------------------------------------------------------------------
2021-07-24 00:52:34,415 epoch 17 - iter 340/3406 - loss 0.04147906 - samples/sec: 131.43 - lr: 0.000015
2021-07-24 00:53:57,724 epoch 17 - iter 680/3406 - loss 0.04243952 - samples/sec: 130.63 - lr: 0.000015
2021-07-24 00:55:20,649 epoch 17 - iter 1020/3406 - loss 0.04389034 - samples/sec: 131.23 - lr: 0.000015
2021-07-24 00:56:44,167 epoch 17 - iter 1360/3406 - loss 0.04547082 - samples/sec: 130.30 - lr: 0.000015
2021-07-24 00:58:06,296 epoch 17 - iter 1700/3406 - loss 0.04562322 - samples/sec: 132.50 - lr: 0.000015
2021-07-24 00:59:29,710 epoch 17 - iter 2040/3406 - loss 0.04427079 - samples/sec: 130.46 - lr: 0.000015
2021-07-24 01:00:52,320 epoch 17 - iter 2380/3406 - loss 0.04461816 - samples/sec: 131.73 - lr: 0.000015
2021-07-24 01:02:14,995 epoch 17 - iter 2720/3406 - loss 0.04496656 - samples/sec: 131.63 - lr: 0.000015
2021-07-24 01:03:38,117 epoch 17 - iter 3060/3406 - loss 0.04518725 - samples/sec: 130.92 - lr: 0.000015
2021-07-24 01:05:00,009 epoch 17 - iter 3400/3406 - loss 0.04506092 - samples/sec: 132.89 - lr: 0.000015
2021-07-24 01:05:01,457 ----------------------------------------------------------------------------------------------------
2021-07-24 01:05:01,457 EPOCH 17 done: loss 0.0451 - lr 0.0000150
2021-07-24 01:05:14,820 DEV : loss 0.04202628135681152 - score 0.9897
2021-07-24 01:05:14,968 BAD EPOCHS (no improvement): 1
2021-07-24 01:05:14,968 ----------------------------------------------------------------------------------------------------
2021-07-24 01:06:37,228 epoch 18 - iter 340/3406 - loss 0.04406473 - samples/sec: 132.30 - lr: 0.000015
2021-07-24 01:07:59,428 epoch 18 - iter 680/3406 - loss 0.04245363 - samples/sec: 132.39 - lr: 0.000015
2021-07-24 01:09:22,448 epoch 18 - iter 1020/3406 - loss 0.04367174 - samples/sec: 131.08 - lr: 0.000015
2021-07-24 01:10:45,828 epoch 18 - iter 1360/3406 - loss 0.04390824 - samples/sec: 130.51 - lr: 0.000015
2021-07-24 01:12:09,065 epoch 18 - iter 1700/3406 - loss 0.04389886 - samples/sec: 130.74 - lr: 0.000015
2021-07-24 01:13:32,227 epoch 18 - iter 2040/3406 - loss 0.04413921 - samples/sec: 130.85 - lr: 0.000015
2021-07-24 01:14:54,649 epoch 18 - iter 2380/3406 - loss 0.04437289 - samples/sec: 132.03 - lr: 0.000015
2021-07-24 01:16:17,995 epoch 18 - iter 2720/3406 - loss 0.04439220 - samples/sec: 130.57 - lr: 0.000015
2021-07-24 01:17:40,383 epoch 18 - iter 3060/3406 - loss 0.04423659 - samples/sec: 132.08 - lr: 0.000015
2021-07-24 01:19:03,526 epoch 18 - iter 3400/3406 - loss 0.04402191 - samples/sec: 130.89 - lr: 0.000015
2021-07-24 01:19:04,929 ----------------------------------------------------------------------------------------------------
2021-07-24 01:19:04,929 EPOCH 18 done: loss 0.0440 - lr 0.0000150
2021-07-24 01:19:18,208 DEV : loss 0.04336506500840187 - score 0.9898
2021-07-24 01:19:18,359 BAD EPOCHS (no improvement): 2
2021-07-24 01:19:18,359 ----------------------------------------------------------------------------------------------------
2021-07-24 01:20:41,108 epoch 19 - iter 340/3406 - loss 0.04443726 - samples/sec: 131.52 - lr: 0.000015
2021-07-24 01:22:04,025 epoch 19 - iter 680/3406 - loss 0.04458596 - samples/sec: 131.24 - lr: 0.000015
2021-07-24 01:23:26,391 epoch 19 - iter 1020/3406 - loss 0.04553978 - samples/sec: 132.12 - lr: 0.000015
2021-07-24 01:24:49,487 epoch 19 - iter 1360/3406 - loss 0.04585728 - samples/sec: 130.96 - lr: 0.000015
2021-07-24 01:26:12,731 epoch 19 - iter 1700/3406 - loss 0.04558313 - samples/sec: 130.73 - lr: 0.000015
2021-07-24 01:27:35,073 epoch 19 - iter 2040/3406 - loss 0.04539036 - samples/sec: 132.16 - lr: 0.000015
2021-07-24 01:28:57,568 epoch 19 - iter 2380/3406 - loss 0.04481992 - samples/sec: 131.91 - lr: 0.000015
2021-07-24 01:30:20,516 epoch 19 - iter 2720/3406 - loss 0.04419266 - samples/sec: 131.19 - lr: 0.000015
2021-07-24 01:31:44,313 epoch 19 - iter 3060/3406 - loss 0.04403487 - samples/sec: 129.86 - lr: 0.000015
2021-07-24 01:33:07,456 epoch 19 - iter 3400/3406 - loss 0.04395897 - samples/sec: 130.89 - lr: 0.000015
2021-07-24 01:33:08,940 ----------------------------------------------------------------------------------------------------
2021-07-24 01:33:08,940 EPOCH 19 done: loss 0.0439 - lr 0.0000150
2021-07-24 01:33:22,221 DEV : loss 0.043784238398075104 - score 0.9891
2021-07-24 01:33:22,371 BAD EPOCHS (no improvement): 3
2021-07-24 01:33:22,372 ----------------------------------------------------------------------------------------------------
2021-07-24 01:34:45,005 epoch 20 - iter 340/3406 - loss 0.04219416 - samples/sec: 131.70 - lr: 0.000015
2021-07-24 01:36:07,816 epoch 20 - iter 680/3406 - loss 0.04221874 - samples/sec: 131.41 - lr: 0.000015
2021-07-24 01:37:29,839 epoch 20 - iter 1020/3406 - loss 0.04254737 - samples/sec: 132.67 - lr: 0.000015
2021-07-24 01:38:53,721 epoch 20 - iter 1360/3406 - loss 0.04401257 - samples/sec: 129.73 - lr: 0.000015
2021-07-24 01:40:16,568 epoch 20 - iter 1700/3406 - loss 0.04413060 - samples/sec: 131.35 - lr: 0.000015
2021-07-24 01:41:39,914 epoch 20 - iter 2040/3406 - loss 0.04365554 - samples/sec: 130.57 - lr: 0.000015
2021-07-24 01:43:02,831 epoch 20 - iter 2380/3406 - loss 0.04350859 - samples/sec: 131.24 - lr: 0.000015
2021-07-24 01:44:25,912 epoch 20 - iter 2720/3406 - loss 0.04343104 - samples/sec: 130.98 - lr: 0.000015
2021-07-24 01:45:48,817 epoch 20 - iter 3060/3406 - loss 0.04332267 - samples/sec: 131.26 - lr: 0.000015
2021-07-24 01:47:11,251 epoch 20 - iter 3400/3406 - loss 0.04319619 - samples/sec: 132.01 - lr: 0.000015
2021-07-24 01:47:12,664 ----------------------------------------------------------------------------------------------------
2021-07-24 01:47:12,665 EPOCH 20 done: loss 0.0432 - lr 0.0000150
2021-07-24 01:47:29,066 DEV : loss 0.04495085030794144 - score 0.9891
Epoch    20: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 01:47:29,217 BAD EPOCHS (no improvement): 4
2021-07-24 01:47:29,217 ----------------------------------------------------------------------------------------------------
2021-07-24 01:48:52,960 epoch 21 - iter 340/3406 - loss 0.04194226 - samples/sec: 129.95 - lr: 0.000008
2021-07-24 01:50:16,077 epoch 21 - iter 680/3406 - loss 0.04086271 - samples/sec: 130.93 - lr: 0.000008
2021-07-24 01:51:39,314 epoch 21 - iter 1020/3406 - loss 0.04130197 - samples/sec: 130.74 - lr: 0.000008
2021-07-24 01:53:02,343 epoch 21 - iter 1360/3406 - loss 0.04130003 - samples/sec: 131.06 - lr: 0.000008
2021-07-24 01:54:25,071 epoch 21 - iter 1700/3406 - loss 0.04214404 - samples/sec: 131.54 - lr: 0.000008
2021-07-24 01:55:47,735 epoch 21 - iter 2040/3406 - loss 0.04262486 - samples/sec: 131.64 - lr: 0.000008
2021-07-24 01:57:10,596 epoch 21 - iter 2380/3406 - loss 0.04268375 - samples/sec: 131.33 - lr: 0.000008
2021-07-24 01:58:33,167 epoch 21 - iter 2720/3406 - loss 0.04239550 - samples/sec: 131.79 - lr: 0.000008
2021-07-24 01:59:56,753 epoch 21 - iter 3060/3406 - loss 0.04208372 - samples/sec: 130.19 - lr: 0.000008
2021-07-24 02:01:20,011 epoch 21 - iter 3400/3406 - loss 0.04223348 - samples/sec: 130.70 - lr: 0.000008
2021-07-24 02:01:21,462 ----------------------------------------------------------------------------------------------------
2021-07-24 02:01:21,463 EPOCH 21 done: loss 0.0422 - lr 0.0000075
2021-07-24 02:01:34,814 DEV : loss 0.044990550726652145 - score 0.9887
2021-07-24 02:01:34,962 BAD EPOCHS (no improvement): 1
2021-07-24 02:01:34,963 ----------------------------------------------------------------------------------------------------
2021-07-24 02:02:58,543 epoch 22 - iter 340/3406 - loss 0.03847453 - samples/sec: 130.21 - lr: 0.000008
2021-07-24 02:04:21,227 epoch 22 - iter 680/3406 - loss 0.04084876 - samples/sec: 131.61 - lr: 0.000008
2021-07-24 02:05:42,612 epoch 22 - iter 1020/3406 - loss 0.04009588 - samples/sec: 133.71 - lr: 0.000008
2021-07-24 02:07:05,840 epoch 22 - iter 1360/3406 - loss 0.04059987 - samples/sec: 130.75 - lr: 0.000008
2021-07-24 02:08:28,076 epoch 22 - iter 1700/3406 - loss 0.04058646 - samples/sec: 132.33 - lr: 0.000008
2021-07-24 02:09:50,749 epoch 22 - iter 2040/3406 - loss 0.04087085 - samples/sec: 131.63 - lr: 0.000008
2021-07-24 02:11:14,208 epoch 22 - iter 2380/3406 - loss 0.04096338 - samples/sec: 130.39 - lr: 0.000008
2021-07-24 02:12:37,164 epoch 22 - iter 2720/3406 - loss 0.04121472 - samples/sec: 131.18 - lr: 0.000008
2021-07-24 02:14:00,457 epoch 22 - iter 3060/3406 - loss 0.04103181 - samples/sec: 130.65 - lr: 0.000008
2021-07-24 02:15:23,407 epoch 22 - iter 3400/3406 - loss 0.04086266 - samples/sec: 131.19 - lr: 0.000008
2021-07-24 02:15:24,808 ----------------------------------------------------------------------------------------------------
2021-07-24 02:15:24,808 EPOCH 22 done: loss 0.0409 - lr 0.0000075
2021-07-24 02:15:38,119 DEV : loss 0.04291646182537079 - score 0.9895
2021-07-24 02:15:38,269 BAD EPOCHS (no improvement): 2
2021-07-24 02:15:38,269 ----------------------------------------------------------------------------------------------------
2021-07-24 02:17:00,936 epoch 23 - iter 340/3406 - loss 0.04035464 - samples/sec: 131.65 - lr: 0.000008
2021-07-24 02:18:23,071 epoch 23 - iter 680/3406 - loss 0.04081458 - samples/sec: 132.49 - lr: 0.000008
2021-07-24 02:19:45,492 epoch 23 - iter 1020/3406 - loss 0.04179894 - samples/sec: 132.03 - lr: 0.000008
2021-07-24 02:21:07,970 epoch 23 - iter 1360/3406 - loss 0.04257389 - samples/sec: 131.94 - lr: 0.000008
2021-07-24 02:22:31,230 epoch 23 - iter 1700/3406 - loss 0.04259819 - samples/sec: 130.70 - lr: 0.000008
2021-07-24 02:23:53,619 epoch 23 - iter 2040/3406 - loss 0.04267220 - samples/sec: 132.08 - lr: 0.000008
2021-07-24 02:25:16,143 epoch 23 - iter 2380/3406 - loss 0.04202366 - samples/sec: 131.87 - lr: 0.000008
2021-07-24 02:26:38,400 epoch 23 - iter 2720/3406 - loss 0.04136104 - samples/sec: 132.30 - lr: 0.000008
2021-07-24 02:28:00,888 epoch 23 - iter 3060/3406 - loss 0.04119885 - samples/sec: 131.93 - lr: 0.000008
2021-07-24 02:29:24,512 epoch 23 - iter 3400/3406 - loss 0.04114537 - samples/sec: 130.13 - lr: 0.000008
2021-07-24 02:29:25,980 ----------------------------------------------------------------------------------------------------
2021-07-24 02:29:25,980 EPOCH 23 done: loss 0.0412 - lr 0.0000075
2021-07-24 02:29:39,343 DEV : loss 0.04260273650288582 - score 0.9893
2021-07-24 02:29:39,494 BAD EPOCHS (no improvement): 3
2021-07-24 02:29:39,494 ----------------------------------------------------------------------------------------------------
2021-07-24 02:31:02,680 epoch 24 - iter 340/3406 - loss 0.04097481 - samples/sec: 130.83 - lr: 0.000008
2021-07-24 02:32:26,040 epoch 24 - iter 680/3406 - loss 0.03987946 - samples/sec: 130.54 - lr: 0.000008
2021-07-24 02:33:48,995 epoch 24 - iter 1020/3406 - loss 0.03909548 - samples/sec: 131.18 - lr: 0.000008
2021-07-24 02:35:11,825 epoch 24 - iter 1360/3406 - loss 0.03964970 - samples/sec: 131.38 - lr: 0.000008
2021-07-24 02:36:35,252 epoch 24 - iter 1700/3406 - loss 0.03940944 - samples/sec: 130.44 - lr: 0.000008
2021-07-24 02:37:57,893 epoch 24 - iter 2040/3406 - loss 0.03988661 - samples/sec: 131.68 - lr: 0.000008
2021-07-24 02:39:19,891 epoch 24 - iter 2380/3406 - loss 0.04000258 - samples/sec: 132.71 - lr: 0.000008
2021-07-24 02:40:43,173 epoch 24 - iter 2720/3406 - loss 0.04006173 - samples/sec: 130.67 - lr: 0.000008
2021-07-24 02:42:05,860 epoch 24 - iter 3060/3406 - loss 0.03992317 - samples/sec: 131.61 - lr: 0.000008
2021-07-24 02:43:29,040 epoch 24 - iter 3400/3406 - loss 0.03983842 - samples/sec: 130.83 - lr: 0.000008
2021-07-24 02:43:30,358 ----------------------------------------------------------------------------------------------------
2021-07-24 02:43:30,359 EPOCH 24 done: loss 0.0398 - lr 0.0000075
2021-07-24 02:43:43,715 DEV : loss 0.042457472532987595 - score 0.9898
Epoch    24: reducing learning rate of group 0 to 3.7500e-06.
2021-07-24 02:43:43,865 BAD EPOCHS (no improvement): 4
2021-07-24 02:43:43,865 ----------------------------------------------------------------------------------------------------
2021-07-24 02:45:06,908 epoch 25 - iter 340/3406 - loss 0.04023153 - samples/sec: 131.05 - lr: 0.000004
2021-07-24 02:46:30,396 epoch 25 - iter 680/3406 - loss 0.03984210 - samples/sec: 130.34 - lr: 0.000004
2021-07-24 02:47:53,467 epoch 25 - iter 1020/3406 - loss 0.03969341 - samples/sec: 131.00 - lr: 0.000004
2021-07-24 02:49:15,999 epoch 25 - iter 1360/3406 - loss 0.03982095 - samples/sec: 131.85 - lr: 0.000004
2021-07-24 02:50:39,184 epoch 25 - iter 1700/3406 - loss 0.03933348 - samples/sec: 130.82 - lr: 0.000004
2021-07-24 02:52:02,077 epoch 25 - iter 2040/3406 - loss 0.03889688 - samples/sec: 131.28 - lr: 0.000004
2021-07-24 02:53:24,289 epoch 25 - iter 2380/3406 - loss 0.03931013 - samples/sec: 132.37 - lr: 0.000004
2021-07-24 02:54:47,232 epoch 25 - iter 2720/3406 - loss 0.03970270 - samples/sec: 131.20 - lr: 0.000004
2021-07-24 02:56:09,816 epoch 25 - iter 3060/3406 - loss 0.03961636 - samples/sec: 131.77 - lr: 0.000004
2021-07-24 02:57:32,564 epoch 25 - iter 3400/3406 - loss 0.03951911 - samples/sec: 131.51 - lr: 0.000004
2021-07-24 02:57:34,027 ----------------------------------------------------------------------------------------------------
2021-07-24 02:57:34,027 EPOCH 25 done: loss 0.0396 - lr 0.0000038
2021-07-24 02:57:47,310 DEV : loss 0.04342305660247803 - score 0.9891
2021-07-24 02:57:47,460 BAD EPOCHS (no improvement): 1
2021-07-24 02:57:47,460 ----------------------------------------------------------------------------------------------------
2021-07-24 02:59:10,290 epoch 26 - iter 340/3406 - loss 0.03850161 - samples/sec: 131.39 - lr: 0.000004
2021-07-24 03:00:33,239 epoch 26 - iter 680/3406 - loss 0.04083359 - samples/sec: 131.19 - lr: 0.000004
2021-07-24 03:01:56,392 epoch 26 - iter 1020/3406 - loss 0.04042249 - samples/sec: 130.87 - lr: 0.000004
2021-07-24 03:03:19,161 epoch 26 - iter 1360/3406 - loss 0.03984770 - samples/sec: 131.48 - lr: 0.000004
2021-07-24 03:04:42,680 epoch 26 - iter 1700/3406 - loss 0.03933893 - samples/sec: 130.30 - lr: 0.000004
2021-07-24 03:06:04,987 epoch 26 - iter 2040/3406 - loss 0.03910307 - samples/sec: 132.21 - lr: 0.000004
2021-07-24 03:07:27,360 epoch 26 - iter 2380/3406 - loss 0.03943560 - samples/sec: 132.11 - lr: 0.000004
2021-07-24 03:08:50,796 epoch 26 - iter 2720/3406 - loss 0.03890995 - samples/sec: 130.43 - lr: 0.000004
2021-07-24 03:10:14,075 epoch 26 - iter 3060/3406 - loss 0.03893972 - samples/sec: 130.67 - lr: 0.000004
2021-07-24 03:11:37,054 epoch 26 - iter 3400/3406 - loss 0.03861917 - samples/sec: 131.14 - lr: 0.000004
2021-07-24 03:11:38,481 ----------------------------------------------------------------------------------------------------
2021-07-24 03:11:38,482 EPOCH 26 done: loss 0.0386 - lr 0.0000038
2021-07-24 03:11:51,874 DEV : loss 0.04248150810599327 - score 0.9897
2021-07-24 03:11:52,023 BAD EPOCHS (no improvement): 2
2021-07-24 03:11:52,023 ----------------------------------------------------------------------------------------------------
2021-07-24 03:13:14,656 epoch 27 - iter 340/3406 - loss 0.03782124 - samples/sec: 131.70 - lr: 0.000004
2021-07-24 03:14:37,576 epoch 27 - iter 680/3406 - loss 0.03763214 - samples/sec: 131.24 - lr: 0.000004
2021-07-24 03:16:00,408 epoch 27 - iter 1020/3406 - loss 0.03849189 - samples/sec: 131.38 - lr: 0.000004
2021-07-24 03:17:23,697 epoch 27 - iter 1360/3406 - loss 0.03841404 - samples/sec: 130.66 - lr: 0.000004
2021-07-24 03:18:46,400 epoch 27 - iter 1700/3406 - loss 0.03906901 - samples/sec: 131.58 - lr: 0.000004
2021-07-24 03:20:09,664 epoch 27 - iter 2040/3406 - loss 0.03936896 - samples/sec: 130.69 - lr: 0.000004
2021-07-24 03:21:32,360 epoch 27 - iter 2380/3406 - loss 0.03877471 - samples/sec: 131.59 - lr: 0.000004
2021-07-24 03:22:56,364 epoch 27 - iter 2720/3406 - loss 0.03926648 - samples/sec: 129.54 - lr: 0.000004
2021-07-24 03:24:19,224 epoch 27 - iter 3060/3406 - loss 0.03938197 - samples/sec: 131.33 - lr: 0.000004
2021-07-24 03:25:42,691 epoch 27 - iter 3400/3406 - loss 0.03930298 - samples/sec: 130.38 - lr: 0.000004
2021-07-24 03:25:44,047 ----------------------------------------------------------------------------------------------------
2021-07-24 03:25:44,047 EPOCH 27 done: loss 0.0393 - lr 0.0000038
2021-07-24 03:26:00,451 DEV : loss 0.044686686247587204 - score 0.989
2021-07-24 03:26:00,601 BAD EPOCHS (no improvement): 3
2021-07-24 03:26:00,602 ----------------------------------------------------------------------------------------------------
2021-07-24 03:27:23,464 epoch 28 - iter 340/3406 - loss 0.03739484 - samples/sec: 131.34 - lr: 0.000004
2021-07-24 03:28:47,408 epoch 28 - iter 680/3406 - loss 0.03927352 - samples/sec: 129.64 - lr: 0.000004
2021-07-24 03:30:10,836 epoch 28 - iter 1020/3406 - loss 0.03841261 - samples/sec: 130.44 - lr: 0.000004
2021-07-24 03:31:33,877 epoch 28 - iter 1360/3406 - loss 0.03845818 - samples/sec: 131.05 - lr: 0.000004
2021-07-24 03:32:56,900 epoch 28 - iter 1700/3406 - loss 0.03832181 - samples/sec: 131.08 - lr: 0.000004
2021-07-24 03:34:19,784 epoch 28 - iter 2040/3406 - loss 0.03835211 - samples/sec: 131.29 - lr: 0.000004
2021-07-24 03:35:42,371 epoch 28 - iter 2380/3406 - loss 0.03894065 - samples/sec: 131.77 - lr: 0.000004
2021-07-24 03:37:05,298 epoch 28 - iter 2720/3406 - loss 0.03933798 - samples/sec: 131.23 - lr: 0.000004
2021-07-24 03:38:26,939 epoch 28 - iter 3060/3406 - loss 0.03924631 - samples/sec: 133.29 - lr: 0.000004
2021-07-24 03:39:48,837 epoch 28 - iter 3400/3406 - loss 0.03965758 - samples/sec: 132.88 - lr: 0.000004
2021-07-24 03:39:50,276 ----------------------------------------------------------------------------------------------------
2021-07-24 03:39:50,276 EPOCH 28 done: loss 0.0396 - lr 0.0000038
2021-07-24 03:40:03,551 DEV : loss 0.04226838797330856 - score 0.9902
Epoch    28: reducing learning rate of group 0 to 1.8750e-06.
2021-07-24 03:40:03,701 BAD EPOCHS (no improvement): 4
2021-07-24 03:40:03,701 ----------------------------------------------------------------------------------------------------
2021-07-24 03:40:03,701 ----------------------------------------------------------------------------------------------------
2021-07-24 03:40:03,701 learning rate too small - quitting training!
2021-07-24 03:40:03,701 ----------------------------------------------------------------------------------------------------
2021-07-24 03:40:04,262 ----------------------------------------------------------------------------------------------------
2021-07-24 03:40:04,262 Testing using best model ...
2021-07-24 03:40:04,263 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.pdtb.pdtb/best-model.pt
2021-07-24 03:47:23,501 0.9893	0.9884	0.9888
2021-07-24 03:47:23,501 
Results:
- F1-score (micro) 0.9888
- F1-score (macro) 0.9880

By class:
SENT       tp: 10517 - fp: 249 - fn: 270 - precision: 0.9769 - recall: 0.9750 - f1-score: 0.9759
X          tp: 12455 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-24 03:47:23,501 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/rus.rst.rrt/
2021-07-24 03:47:23,537 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/rus.rst.rrt
2021-07-24 03:47:23,538 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/rus.rst.rrt/sent_train.txt
2021-07-24 03:47:23,539 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/rus.rst.rrt/sent_dev.txt
2021-07-24 03:47:23,541 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/rus.rst.rrt/sent_test.txt
Corpus: 34661 train + 5825 dev + 20569 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-24 03:47:41,546 ----------------------------------------------------------------------------------------------------
2021-07-24 03:47:41,548 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50021, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-24 03:47:41,548 ----------------------------------------------------------------------------------------------------
2021-07-24 03:47:41,548 Corpus: "Corpus: 34661 train + 5825 dev + 20569 test sentences"
2021-07-24 03:47:41,548 ----------------------------------------------------------------------------------------------------
2021-07-24 03:47:41,548 Parameters:
2021-07-24 03:47:41,548  - learning_rate: "3e-05"
2021-07-24 03:47:41,548  - mini_batch_size: "32"
2021-07-24 03:47:41,548  - patience: "3"
2021-07-24 03:47:41,548  - anneal_factor: "0.5"
2021-07-24 03:47:41,548  - max_epochs: "40"
2021-07-24 03:47:41,548  - shuffle: "True"
2021-07-24 03:47:41,548  - train_with_dev: "False"
2021-07-24 03:47:41,548  - batch_growth_annealing: "False"
2021-07-24 03:47:41,548 ----------------------------------------------------------------------------------------------------
2021-07-24 03:47:41,548 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/rus.rst.rrt"
2021-07-24 03:47:41,548 ----------------------------------------------------------------------------------------------------
2021-07-24 03:47:41,548 Device: cuda:0
2021-07-24 03:47:41,549 ----------------------------------------------------------------------------------------------------
2021-07-24 03:47:41,549 Embeddings storage mode: cpu
2021-07-24 03:47:41,551 ----------------------------------------------------------------------------------------------------
2021-07-24 03:48:44,117 epoch 1 - iter 108/1084 - loss 4.39840978 - samples/sec: 55.24 - lr: 0.000030
2021-07-24 03:49:47,721 epoch 1 - iter 216/1084 - loss 2.35095508 - samples/sec: 54.34 - lr: 0.000030
2021-07-24 03:50:51,562 epoch 1 - iter 324/1084 - loss 1.63184386 - samples/sec: 54.14 - lr: 0.000030
2021-07-24 03:51:54,999 epoch 1 - iter 432/1084 - loss 1.26876329 - samples/sec: 54.48 - lr: 0.000030
2021-07-24 03:52:58,789 epoch 1 - iter 540/1084 - loss 1.06032242 - samples/sec: 54.18 - lr: 0.000030
2021-07-24 03:54:03,643 epoch 1 - iter 648/1084 - loss 0.91276449 - samples/sec: 53.29 - lr: 0.000030
2021-07-24 03:55:08,269 epoch 1 - iter 756/1084 - loss 0.80926242 - samples/sec: 53.48 - lr: 0.000030
2021-07-24 03:56:14,772 epoch 1 - iter 864/1084 - loss 0.73404836 - samples/sec: 51.97 - lr: 0.000030
2021-07-24 03:57:21,126 epoch 1 - iter 972/1084 - loss 0.67117722 - samples/sec: 52.09 - lr: 0.000030
2021-07-24 03:58:26,544 epoch 1 - iter 1080/1084 - loss 0.62473291 - samples/sec: 52.83 - lr: 0.000030
2021-07-24 03:58:28,449 ----------------------------------------------------------------------------------------------------
2021-07-24 03:58:28,450 EPOCH 1 done: loss 0.6243 - lr 0.0000300
2021-07-24 03:59:49,318 DEV : loss 0.12293078750371933 - score 0.9667
2021-07-24 03:59:49,473 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 03:59:50,155 ----------------------------------------------------------------------------------------------------
2021-07-24 04:00:16,283 epoch 2 - iter 108/1084 - loss 0.15684715 - samples/sec: 132.31 - lr: 0.000030
2021-07-24 04:00:42,310 epoch 2 - iter 216/1084 - loss 0.14415917 - samples/sec: 132.81 - lr: 0.000030
2021-07-24 04:01:08,030 epoch 2 - iter 324/1084 - loss 0.14855223 - samples/sec: 134.40 - lr: 0.000030
2021-07-24 04:01:33,713 epoch 2 - iter 432/1084 - loss 0.14834080 - samples/sec: 134.59 - lr: 0.000030
2021-07-24 04:01:59,184 epoch 2 - iter 540/1084 - loss 0.14348577 - samples/sec: 135.71 - lr: 0.000030
2021-07-24 04:02:24,784 epoch 2 - iter 648/1084 - loss 0.14417471 - samples/sec: 135.03 - lr: 0.000030
2021-07-24 04:02:50,243 epoch 2 - iter 756/1084 - loss 0.14344143 - samples/sec: 135.78 - lr: 0.000030
2021-07-24 04:03:15,804 epoch 2 - iter 864/1084 - loss 0.14156270 - samples/sec: 135.23 - lr: 0.000030
2021-07-24 04:03:41,514 epoch 2 - iter 972/1084 - loss 0.13973562 - samples/sec: 134.45 - lr: 0.000030
2021-07-24 04:04:07,634 epoch 2 - iter 1080/1084 - loss 0.13823414 - samples/sec: 132.34 - lr: 0.000030
2021-07-24 04:04:08,414 ----------------------------------------------------------------------------------------------------
2021-07-24 04:04:08,415 EPOCH 2 done: loss 0.1381 - lr 0.0000300
2021-07-24 04:04:22,833 DEV : loss 0.11090806871652603 - score 0.9688
2021-07-24 04:04:22,986 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 04:04:26,001 ----------------------------------------------------------------------------------------------------
2021-07-24 04:04:51,976 epoch 3 - iter 108/1084 - loss 0.13517249 - samples/sec: 133.10 - lr: 0.000030
2021-07-24 04:05:17,996 epoch 3 - iter 216/1084 - loss 0.13835162 - samples/sec: 132.85 - lr: 0.000030
2021-07-24 04:05:44,049 epoch 3 - iter 324/1084 - loss 0.13210457 - samples/sec: 132.68 - lr: 0.000030
2021-07-24 04:06:10,256 epoch 3 - iter 432/1084 - loss 0.12819526 - samples/sec: 131.90 - lr: 0.000030
2021-07-24 04:06:36,168 epoch 3 - iter 540/1084 - loss 0.12414181 - samples/sec: 133.40 - lr: 0.000030
2021-07-24 04:07:02,856 epoch 3 - iter 648/1084 - loss 0.12220619 - samples/sec: 129.52 - lr: 0.000030
2021-07-24 04:07:28,792 epoch 3 - iter 756/1084 - loss 0.11924432 - samples/sec: 133.28 - lr: 0.000030
2021-07-24 04:07:55,324 epoch 3 - iter 864/1084 - loss 0.11862221 - samples/sec: 130.28 - lr: 0.000030
2021-07-24 04:08:21,388 epoch 3 - iter 972/1084 - loss 0.11820364 - samples/sec: 132.63 - lr: 0.000030
2021-07-24 04:08:47,838 epoch 3 - iter 1080/1084 - loss 0.11747880 - samples/sec: 130.69 - lr: 0.000030
2021-07-24 04:08:48,651 ----------------------------------------------------------------------------------------------------
2021-07-24 04:08:48,651 EPOCH 3 done: loss 0.1172 - lr 0.0000300
2021-07-24 04:09:02,928 DEV : loss 0.10020716488361359 - score 0.9696
2021-07-24 04:09:03,081 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 04:09:06,075 ----------------------------------------------------------------------------------------------------
2021-07-24 04:09:32,357 epoch 4 - iter 108/1084 - loss 0.09848165 - samples/sec: 131.55 - lr: 0.000030
2021-07-24 04:09:58,443 epoch 4 - iter 216/1084 - loss 0.10781067 - samples/sec: 132.51 - lr: 0.000030
2021-07-24 04:10:24,823 epoch 4 - iter 324/1084 - loss 0.11049198 - samples/sec: 131.03 - lr: 0.000030
2021-07-24 04:10:51,128 epoch 4 - iter 432/1084 - loss 0.10807115 - samples/sec: 131.41 - lr: 0.000030
2021-07-24 04:11:17,176 epoch 4 - iter 540/1084 - loss 0.10868052 - samples/sec: 132.71 - lr: 0.000030
2021-07-24 04:11:43,162 epoch 4 - iter 648/1084 - loss 0.10543903 - samples/sec: 133.02 - lr: 0.000030
2021-07-24 04:12:09,586 epoch 4 - iter 756/1084 - loss 0.10439568 - samples/sec: 130.82 - lr: 0.000030
2021-07-24 04:12:35,770 epoch 4 - iter 864/1084 - loss 0.10409175 - samples/sec: 132.02 - lr: 0.000030
2021-07-24 04:13:01,537 epoch 4 - iter 972/1084 - loss 0.10451289 - samples/sec: 134.15 - lr: 0.000030
2021-07-24 04:13:27,411 epoch 4 - iter 1080/1084 - loss 0.10438459 - samples/sec: 133.60 - lr: 0.000030
2021-07-24 04:13:28,206 ----------------------------------------------------------------------------------------------------
2021-07-24 04:13:28,206 EPOCH 4 done: loss 0.1044 - lr 0.0000300
2021-07-24 04:13:42,577 DEV : loss 0.09722425788640976 - score 0.9706
2021-07-24 04:13:42,732 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 04:13:45,807 ----------------------------------------------------------------------------------------------------
2021-07-24 04:14:12,205 epoch 5 - iter 108/1084 - loss 0.09490334 - samples/sec: 130.97 - lr: 0.000030
2021-07-24 04:14:38,360 epoch 5 - iter 216/1084 - loss 0.09257029 - samples/sec: 132.17 - lr: 0.000030
2021-07-24 04:15:04,395 epoch 5 - iter 324/1084 - loss 0.09284085 - samples/sec: 132.77 - lr: 0.000030
2021-07-24 04:15:30,167 epoch 5 - iter 432/1084 - loss 0.09577674 - samples/sec: 134.13 - lr: 0.000030
2021-07-24 04:15:56,397 epoch 5 - iter 540/1084 - loss 0.09365184 - samples/sec: 131.79 - lr: 0.000030
2021-07-24 04:16:22,809 epoch 5 - iter 648/1084 - loss 0.09418532 - samples/sec: 130.88 - lr: 0.000030
2021-07-24 04:16:48,872 epoch 5 - iter 756/1084 - loss 0.09385754 - samples/sec: 132.63 - lr: 0.000030
2021-07-24 04:17:15,084 epoch 5 - iter 864/1084 - loss 0.09532679 - samples/sec: 131.88 - lr: 0.000030
2021-07-24 04:17:41,107 epoch 5 - iter 972/1084 - loss 0.09529397 - samples/sec: 132.83 - lr: 0.000030
2021-07-24 04:18:07,289 epoch 5 - iter 1080/1084 - loss 0.09480022 - samples/sec: 132.03 - lr: 0.000030
2021-07-24 04:18:08,158 ----------------------------------------------------------------------------------------------------
2021-07-24 04:18:08,159 EPOCH 5 done: loss 0.0948 - lr 0.0000300
2021-07-24 04:18:24,003 DEV : loss 0.09435877203941345 - score 0.9717
2021-07-24 04:18:24,159 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 04:18:27,319 ----------------------------------------------------------------------------------------------------
2021-07-24 04:18:53,808 epoch 6 - iter 108/1084 - loss 0.09660067 - samples/sec: 130.52 - lr: 0.000030
2021-07-24 04:19:20,372 epoch 6 - iter 216/1084 - loss 0.09218857 - samples/sec: 130.13 - lr: 0.000030
2021-07-24 04:19:46,751 epoch 6 - iter 324/1084 - loss 0.09008509 - samples/sec: 131.04 - lr: 0.000030
2021-07-24 04:20:13,367 epoch 6 - iter 432/1084 - loss 0.08821450 - samples/sec: 129.87 - lr: 0.000030
2021-07-24 04:20:39,304 epoch 6 - iter 540/1084 - loss 0.08758371 - samples/sec: 133.27 - lr: 0.000030
2021-07-24 04:21:05,175 epoch 6 - iter 648/1084 - loss 0.08709053 - samples/sec: 133.61 - lr: 0.000030
2021-07-24 04:21:31,373 epoch 6 - iter 756/1084 - loss 0.08606827 - samples/sec: 131.95 - lr: 0.000030
2021-07-24 04:21:57,672 epoch 6 - iter 864/1084 - loss 0.08510445 - samples/sec: 131.44 - lr: 0.000030
2021-07-24 04:22:24,368 epoch 6 - iter 972/1084 - loss 0.08520120 - samples/sec: 129.48 - lr: 0.000030
2021-07-24 04:22:50,680 epoch 6 - iter 1080/1084 - loss 0.08512703 - samples/sec: 131.37 - lr: 0.000030
2021-07-24 04:22:51,485 ----------------------------------------------------------------------------------------------------
2021-07-24 04:22:51,485 EPOCH 6 done: loss 0.0851 - lr 0.0000300
2021-07-24 04:23:06,014 DEV : loss 0.09126010537147522 - score 0.9701
2021-07-24 04:23:06,168 BAD EPOCHS (no improvement): 1
2021-07-24 04:23:06,168 ----------------------------------------------------------------------------------------------------
2021-07-24 04:23:32,367 epoch 7 - iter 108/1084 - loss 0.07584958 - samples/sec: 131.96 - lr: 0.000030
2021-07-24 04:23:59,157 epoch 7 - iter 216/1084 - loss 0.07936084 - samples/sec: 129.03 - lr: 0.000030
2021-07-24 04:24:25,797 epoch 7 - iter 324/1084 - loss 0.08126032 - samples/sec: 129.76 - lr: 0.000030
2021-07-24 04:24:52,357 epoch 7 - iter 432/1084 - loss 0.08220993 - samples/sec: 130.15 - lr: 0.000030
2021-07-24 04:25:19,039 epoch 7 - iter 540/1084 - loss 0.08083254 - samples/sec: 129.55 - lr: 0.000030
2021-07-24 04:25:45,017 epoch 7 - iter 648/1084 - loss 0.07944531 - samples/sec: 133.07 - lr: 0.000030
2021-07-24 04:26:11,354 epoch 7 - iter 756/1084 - loss 0.07945709 - samples/sec: 131.25 - lr: 0.000030
2021-07-24 04:26:37,760 epoch 7 - iter 864/1084 - loss 0.07968069 - samples/sec: 130.90 - lr: 0.000030
2021-07-24 04:27:03,778 epoch 7 - iter 972/1084 - loss 0.08019824 - samples/sec: 132.86 - lr: 0.000030
2021-07-24 04:27:29,960 epoch 7 - iter 1080/1084 - loss 0.07959022 - samples/sec: 132.03 - lr: 0.000030
2021-07-24 04:27:30,763 ----------------------------------------------------------------------------------------------------
2021-07-24 04:27:30,763 EPOCH 7 done: loss 0.0800 - lr 0.0000300
2021-07-24 04:27:45,201 DEV : loss 0.08842304348945618 - score 0.9715
2021-07-24 04:27:45,356 BAD EPOCHS (no improvement): 2
2021-07-24 04:27:45,357 ----------------------------------------------------------------------------------------------------
2021-07-24 04:28:11,599 epoch 8 - iter 108/1084 - loss 0.06264911 - samples/sec: 131.74 - lr: 0.000030
2021-07-24 04:28:37,901 epoch 8 - iter 216/1084 - loss 0.07207124 - samples/sec: 131.42 - lr: 0.000030
2021-07-24 04:29:04,407 epoch 8 - iter 324/1084 - loss 0.07366760 - samples/sec: 130.41 - lr: 0.000030
2021-07-24 04:29:30,653 epoch 8 - iter 432/1084 - loss 0.07450075 - samples/sec: 131.71 - lr: 0.000030
2021-07-24 04:29:57,030 epoch 8 - iter 540/1084 - loss 0.07585541 - samples/sec: 131.05 - lr: 0.000030
2021-07-24 04:30:23,456 epoch 8 - iter 648/1084 - loss 0.07640383 - samples/sec: 130.80 - lr: 0.000030
2021-07-24 04:30:49,958 epoch 8 - iter 756/1084 - loss 0.07720475 - samples/sec: 130.43 - lr: 0.000030
2021-07-24 04:31:16,281 epoch 8 - iter 864/1084 - loss 0.07662629 - samples/sec: 131.32 - lr: 0.000030
2021-07-24 04:31:42,568 epoch 8 - iter 972/1084 - loss 0.07712642 - samples/sec: 131.50 - lr: 0.000030
2021-07-24 04:32:08,904 epoch 8 - iter 1080/1084 - loss 0.07642589 - samples/sec: 131.25 - lr: 0.000030
2021-07-24 04:32:09,703 ----------------------------------------------------------------------------------------------------
2021-07-24 04:32:09,703 EPOCH 8 done: loss 0.0763 - lr 0.0000300
2021-07-24 04:32:24,159 DEV : loss 0.09358718246221542 - score 0.9706
2021-07-24 04:32:24,316 BAD EPOCHS (no improvement): 3
2021-07-24 04:32:24,316 ----------------------------------------------------------------------------------------------------
2021-07-24 04:32:50,530 epoch 9 - iter 108/1084 - loss 0.07251590 - samples/sec: 131.88 - lr: 0.000030
2021-07-24 04:33:17,029 epoch 9 - iter 216/1084 - loss 0.06952066 - samples/sec: 130.45 - lr: 0.000030
2021-07-24 04:33:43,267 epoch 9 - iter 324/1084 - loss 0.07163303 - samples/sec: 131.74 - lr: 0.000030
2021-07-24 04:34:09,519 epoch 9 - iter 432/1084 - loss 0.07363381 - samples/sec: 131.67 - lr: 0.000030
2021-07-24 04:34:35,524 epoch 9 - iter 540/1084 - loss 0.07393870 - samples/sec: 132.93 - lr: 0.000030
2021-07-24 04:35:01,673 epoch 9 - iter 648/1084 - loss 0.07393536 - samples/sec: 132.19 - lr: 0.000030
2021-07-24 04:35:27,779 epoch 9 - iter 756/1084 - loss 0.07177258 - samples/sec: 132.41 - lr: 0.000030
2021-07-24 04:35:54,217 epoch 9 - iter 864/1084 - loss 0.07219379 - samples/sec: 130.75 - lr: 0.000030
2021-07-24 04:36:20,709 epoch 9 - iter 972/1084 - loss 0.07335877 - samples/sec: 130.48 - lr: 0.000030
2021-07-24 04:36:47,155 epoch 9 - iter 1080/1084 - loss 0.07337834 - samples/sec: 130.70 - lr: 0.000030
2021-07-24 04:36:47,975 ----------------------------------------------------------------------------------------------------
2021-07-24 04:36:47,975 EPOCH 9 done: loss 0.0734 - lr 0.0000300
2021-07-24 04:37:02,560 DEV : loss 0.10441921651363373 - score 0.9665
Epoch     9: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 04:37:02,714 BAD EPOCHS (no improvement): 4
2021-07-24 04:37:02,714 ----------------------------------------------------------------------------------------------------
2021-07-24 04:37:28,784 epoch 10 - iter 108/1084 - loss 0.06378451 - samples/sec: 132.61 - lr: 0.000015
2021-07-24 04:37:55,259 epoch 10 - iter 216/1084 - loss 0.06566746 - samples/sec: 130.57 - lr: 0.000015
2021-07-24 04:38:21,761 epoch 10 - iter 324/1084 - loss 0.06574821 - samples/sec: 130.43 - lr: 0.000015
2021-07-24 04:38:48,213 epoch 10 - iter 432/1084 - loss 0.06516835 - samples/sec: 130.68 - lr: 0.000015
2021-07-24 04:39:14,401 epoch 10 - iter 540/1084 - loss 0.06354162 - samples/sec: 132.00 - lr: 0.000015
2021-07-24 04:39:40,797 epoch 10 - iter 648/1084 - loss 0.06610283 - samples/sec: 130.96 - lr: 0.000015
2021-07-24 04:40:07,058 epoch 10 - iter 756/1084 - loss 0.06569273 - samples/sec: 131.63 - lr: 0.000015
2021-07-24 04:40:32,914 epoch 10 - iter 864/1084 - loss 0.06664666 - samples/sec: 133.69 - lr: 0.000015
2021-07-24 04:40:59,808 epoch 10 - iter 972/1084 - loss 0.06672326 - samples/sec: 128.53 - lr: 0.000015
2021-07-24 04:41:26,016 epoch 10 - iter 1080/1084 - loss 0.06750646 - samples/sec: 131.90 - lr: 0.000015
2021-07-24 04:41:26,751 ----------------------------------------------------------------------------------------------------
2021-07-24 04:41:26,752 EPOCH 10 done: loss 0.0675 - lr 0.0000150
2021-07-24 04:41:42,704 DEV : loss 0.10631120949983597 - score 0.9669
2021-07-24 04:41:42,858 BAD EPOCHS (no improvement): 1
2021-07-24 04:41:42,859 ----------------------------------------------------------------------------------------------------
2021-07-24 04:42:08,896 epoch 11 - iter 108/1084 - loss 0.06245049 - samples/sec: 132.78 - lr: 0.000015
2021-07-24 04:42:35,073 epoch 11 - iter 216/1084 - loss 0.06442255 - samples/sec: 132.05 - lr: 0.000015
2021-07-24 04:43:01,363 epoch 11 - iter 324/1084 - loss 0.06724133 - samples/sec: 131.49 - lr: 0.000015
2021-07-24 04:43:27,909 epoch 11 - iter 432/1084 - loss 0.06879697 - samples/sec: 130.22 - lr: 0.000015
2021-07-24 04:43:53,981 epoch 11 - iter 540/1084 - loss 0.07131072 - samples/sec: 132.58 - lr: 0.000015
2021-07-24 04:44:19,885 epoch 11 - iter 648/1084 - loss 0.07244172 - samples/sec: 133.45 - lr: 0.000015
2021-07-24 04:44:45,908 epoch 11 - iter 756/1084 - loss 0.07155752 - samples/sec: 132.83 - lr: 0.000015
2021-07-24 04:45:12,202 epoch 11 - iter 864/1084 - loss 0.07052941 - samples/sec: 131.46 - lr: 0.000015
2021-07-24 04:45:38,771 epoch 11 - iter 972/1084 - loss 0.06879663 - samples/sec: 130.11 - lr: 0.000015
2021-07-24 04:46:04,934 epoch 11 - iter 1080/1084 - loss 0.06798725 - samples/sec: 132.12 - lr: 0.000015
2021-07-24 04:46:05,763 ----------------------------------------------------------------------------------------------------
2021-07-24 04:46:05,763 EPOCH 11 done: loss 0.0684 - lr 0.0000150
2021-07-24 04:46:20,364 DEV : loss 0.09257970750331879 - score 0.9715
2021-07-24 04:46:20,519 BAD EPOCHS (no improvement): 2
2021-07-24 04:46:20,520 ----------------------------------------------------------------------------------------------------
2021-07-24 04:46:46,848 epoch 12 - iter 108/1084 - loss 0.05862497 - samples/sec: 131.31 - lr: 0.000015
2021-07-24 04:47:13,576 epoch 12 - iter 216/1084 - loss 0.06569310 - samples/sec: 129.33 - lr: 0.000015
2021-07-24 04:47:40,042 epoch 12 - iter 324/1084 - loss 0.06416097 - samples/sec: 130.61 - lr: 0.000015
2021-07-24 04:48:06,299 epoch 12 - iter 432/1084 - loss 0.06640872 - samples/sec: 131.65 - lr: 0.000015
2021-07-24 04:48:32,604 epoch 12 - iter 540/1084 - loss 0.06632955 - samples/sec: 131.41 - lr: 0.000015
2021-07-24 04:48:58,857 epoch 12 - iter 648/1084 - loss 0.06473459 - samples/sec: 131.67 - lr: 0.000015
2021-07-24 04:49:25,032 epoch 12 - iter 756/1084 - loss 0.06501371 - samples/sec: 132.06 - lr: 0.000015
2021-07-24 04:49:51,249 epoch 12 - iter 864/1084 - loss 0.06468441 - samples/sec: 131.85 - lr: 0.000015
2021-07-24 04:50:17,819 epoch 12 - iter 972/1084 - loss 0.06606007 - samples/sec: 130.10 - lr: 0.000015
2021-07-24 04:50:44,088 epoch 12 - iter 1080/1084 - loss 0.06602679 - samples/sec: 131.59 - lr: 0.000015
2021-07-24 04:50:44,865 ----------------------------------------------------------------------------------------------------
2021-07-24 04:50:44,865 EPOCH 12 done: loss 0.0659 - lr 0.0000150
2021-07-24 04:50:59,458 DEV : loss 0.09031900763511658 - score 0.9708
2021-07-24 04:50:59,614 BAD EPOCHS (no improvement): 3
2021-07-24 04:50:59,614 ----------------------------------------------------------------------------------------------------
2021-07-24 04:51:25,612 epoch 13 - iter 108/1084 - loss 0.06767218 - samples/sec: 132.97 - lr: 0.000015
2021-07-24 04:51:52,182 epoch 13 - iter 216/1084 - loss 0.07086574 - samples/sec: 130.10 - lr: 0.000015
2021-07-24 04:52:18,336 epoch 13 - iter 324/1084 - loss 0.06752488 - samples/sec: 132.17 - lr: 0.000015
2021-07-24 04:52:44,996 epoch 13 - iter 432/1084 - loss 0.06707470 - samples/sec: 129.66 - lr: 0.000015
2021-07-24 04:53:11,193 epoch 13 - iter 540/1084 - loss 0.06606060 - samples/sec: 131.95 - lr: 0.000015
2021-07-24 04:53:37,836 epoch 13 - iter 648/1084 - loss 0.06616514 - samples/sec: 129.74 - lr: 0.000015
2021-07-24 04:54:04,396 epoch 13 - iter 756/1084 - loss 0.06644445 - samples/sec: 130.15 - lr: 0.000015
2021-07-24 04:54:30,960 epoch 13 - iter 864/1084 - loss 0.06486668 - samples/sec: 130.13 - lr: 0.000015
2021-07-24 04:54:57,268 epoch 13 - iter 972/1084 - loss 0.06505475 - samples/sec: 131.40 - lr: 0.000015
2021-07-24 04:55:23,443 epoch 13 - iter 1080/1084 - loss 0.06482342 - samples/sec: 132.06 - lr: 0.000015
2021-07-24 04:55:24,206 ----------------------------------------------------------------------------------------------------
2021-07-24 04:55:24,206 EPOCH 13 done: loss 0.0650 - lr 0.0000150
2021-07-24 04:55:38,789 DEV : loss 0.09116711467504501 - score 0.9717
Epoch    13: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 04:55:38,945 BAD EPOCHS (no improvement): 4
2021-07-24 04:55:38,946 ----------------------------------------------------------------------------------------------------
2021-07-24 04:56:05,156 epoch 14 - iter 108/1084 - loss 0.06546337 - samples/sec: 131.90 - lr: 0.000008
2021-07-24 04:56:31,475 epoch 14 - iter 216/1084 - loss 0.06325805 - samples/sec: 131.34 - lr: 0.000008
2021-07-24 04:56:58,010 epoch 14 - iter 324/1084 - loss 0.06474392 - samples/sec: 130.27 - lr: 0.000008
2021-07-24 04:57:24,464 epoch 14 - iter 432/1084 - loss 0.06299102 - samples/sec: 130.67 - lr: 0.000008
2021-07-24 04:57:51,004 epoch 14 - iter 540/1084 - loss 0.06231088 - samples/sec: 130.25 - lr: 0.000008
2021-07-24 04:58:17,712 epoch 14 - iter 648/1084 - loss 0.06349451 - samples/sec: 129.42 - lr: 0.000008
2021-07-24 04:58:43,854 epoch 14 - iter 756/1084 - loss 0.06399461 - samples/sec: 132.23 - lr: 0.000008
2021-07-24 04:59:10,316 epoch 14 - iter 864/1084 - loss 0.06339531 - samples/sec: 130.63 - lr: 0.000008
2021-07-24 04:59:36,581 epoch 14 - iter 972/1084 - loss 0.06411666 - samples/sec: 131.61 - lr: 0.000008
2021-07-24 05:00:02,996 epoch 14 - iter 1080/1084 - loss 0.06507643 - samples/sec: 130.87 - lr: 0.000008
2021-07-24 05:00:03,775 ----------------------------------------------------------------------------------------------------
2021-07-24 05:00:03,775 EPOCH 14 done: loss 0.0649 - lr 0.0000075
2021-07-24 05:00:18,382 DEV : loss 0.0912836566567421 - score 0.9704
2021-07-24 05:00:18,538 BAD EPOCHS (no improvement): 1
2021-07-24 05:00:18,539 ----------------------------------------------------------------------------------------------------
2021-07-24 05:00:44,827 epoch 15 - iter 108/1084 - loss 0.06392384 - samples/sec: 131.50 - lr: 0.000008
2021-07-24 05:01:13,021 epoch 15 - iter 216/1084 - loss 0.06411069 - samples/sec: 122.60 - lr: 0.000008
2021-07-24 05:01:39,385 epoch 15 - iter 324/1084 - loss 0.06531011 - samples/sec: 131.11 - lr: 0.000008
2021-07-24 05:02:06,273 epoch 15 - iter 432/1084 - loss 0.06281076 - samples/sec: 128.56 - lr: 0.000008
2021-07-24 05:02:31,953 epoch 15 - iter 540/1084 - loss 0.06281354 - samples/sec: 134.61 - lr: 0.000008
2021-07-24 05:02:58,557 epoch 15 - iter 648/1084 - loss 0.06210584 - samples/sec: 129.93 - lr: 0.000008
2021-07-24 05:03:24,773 epoch 15 - iter 756/1084 - loss 0.06195517 - samples/sec: 131.85 - lr: 0.000008
2021-07-24 05:03:51,285 epoch 15 - iter 864/1084 - loss 0.06400955 - samples/sec: 130.39 - lr: 0.000008
2021-07-24 05:04:17,329 epoch 15 - iter 972/1084 - loss 0.06382474 - samples/sec: 132.73 - lr: 0.000008
2021-07-24 05:04:43,840 epoch 15 - iter 1080/1084 - loss 0.06445935 - samples/sec: 130.39 - lr: 0.000008
2021-07-24 05:04:44,615 ----------------------------------------------------------------------------------------------------
2021-07-24 05:04:44,615 EPOCH 15 done: loss 0.0643 - lr 0.0000075
2021-07-24 05:04:59,115 DEV : loss 0.09060957282781601 - score 0.9719
2021-07-24 05:04:59,272 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:05:02,400 ----------------------------------------------------------------------------------------------------
2021-07-24 05:05:29,245 epoch 16 - iter 108/1084 - loss 0.06241521 - samples/sec: 128.78 - lr: 0.000008
2021-07-24 05:05:55,517 epoch 16 - iter 216/1084 - loss 0.06234630 - samples/sec: 131.58 - lr: 0.000008
2021-07-24 05:06:21,755 epoch 16 - iter 324/1084 - loss 0.06083792 - samples/sec: 131.74 - lr: 0.000008
2021-07-24 05:06:48,100 epoch 16 - iter 432/1084 - loss 0.05995753 - samples/sec: 131.21 - lr: 0.000008
2021-07-24 05:07:14,448 epoch 16 - iter 540/1084 - loss 0.06248199 - samples/sec: 131.20 - lr: 0.000008
2021-07-24 05:07:40,764 epoch 16 - iter 648/1084 - loss 0.06319819 - samples/sec: 131.36 - lr: 0.000008
2021-07-24 05:08:07,421 epoch 16 - iter 756/1084 - loss 0.06330432 - samples/sec: 129.67 - lr: 0.000008
2021-07-24 05:08:33,796 epoch 16 - iter 864/1084 - loss 0.06329080 - samples/sec: 131.06 - lr: 0.000008
2021-07-24 05:09:00,164 epoch 16 - iter 972/1084 - loss 0.06213769 - samples/sec: 131.09 - lr: 0.000008
2021-07-24 05:09:26,764 epoch 16 - iter 1080/1084 - loss 0.06150275 - samples/sec: 129.96 - lr: 0.000008
2021-07-24 05:09:27,568 ----------------------------------------------------------------------------------------------------
2021-07-24 05:09:27,568 EPOCH 16 done: loss 0.0616 - lr 0.0000075
2021-07-24 05:09:42,126 DEV : loss 0.08957426249980927 - score 0.972
2021-07-24 05:09:42,283 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:09:45,451 ----------------------------------------------------------------------------------------------------
2021-07-24 05:10:11,932 epoch 17 - iter 108/1084 - loss 0.06226081 - samples/sec: 130.56 - lr: 0.000008
2021-07-24 05:10:38,468 epoch 17 - iter 216/1084 - loss 0.06695871 - samples/sec: 130.26 - lr: 0.000008
2021-07-24 05:11:04,864 epoch 17 - iter 324/1084 - loss 0.06471997 - samples/sec: 130.96 - lr: 0.000008
2021-07-24 05:11:30,927 epoch 17 - iter 432/1084 - loss 0.06315872 - samples/sec: 132.63 - lr: 0.000008
2021-07-24 05:11:57,424 epoch 17 - iter 540/1084 - loss 0.06457286 - samples/sec: 130.46 - lr: 0.000008
2021-07-24 05:12:23,742 epoch 17 - iter 648/1084 - loss 0.06481575 - samples/sec: 131.34 - lr: 0.000008
2021-07-24 05:12:50,197 epoch 17 - iter 756/1084 - loss 0.06358458 - samples/sec: 130.66 - lr: 0.000008
2021-07-24 05:13:16,411 epoch 17 - iter 864/1084 - loss 0.06396768 - samples/sec: 131.87 - lr: 0.000008
2021-07-24 05:13:43,390 epoch 17 - iter 972/1084 - loss 0.06320458 - samples/sec: 128.12 - lr: 0.000008
2021-07-24 05:14:09,824 epoch 17 - iter 1080/1084 - loss 0.06292411 - samples/sec: 130.77 - lr: 0.000008
2021-07-24 05:14:10,594 ----------------------------------------------------------------------------------------------------
2021-07-24 05:14:10,594 EPOCH 17 done: loss 0.0628 - lr 0.0000075
2021-07-24 05:14:25,114 DEV : loss 0.08833850920200348 - score 0.9728
2021-07-24 05:14:25,272 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:14:28,453 ----------------------------------------------------------------------------------------------------
2021-07-24 05:14:55,142 epoch 18 - iter 108/1084 - loss 0.06442460 - samples/sec: 129.54 - lr: 0.000008
2021-07-24 05:15:21,460 epoch 18 - iter 216/1084 - loss 0.06265077 - samples/sec: 131.34 - lr: 0.000008
2021-07-24 05:15:48,347 epoch 18 - iter 324/1084 - loss 0.05785710 - samples/sec: 128.57 - lr: 0.000008
2021-07-24 05:16:14,705 epoch 18 - iter 432/1084 - loss 0.05826960 - samples/sec: 131.14 - lr: 0.000008
2021-07-24 05:16:40,976 epoch 18 - iter 540/1084 - loss 0.06048799 - samples/sec: 131.58 - lr: 0.000008
2021-07-24 05:17:07,185 epoch 18 - iter 648/1084 - loss 0.06190732 - samples/sec: 131.89 - lr: 0.000008
2021-07-24 05:17:33,476 epoch 18 - iter 756/1084 - loss 0.06142626 - samples/sec: 131.48 - lr: 0.000008
2021-07-24 05:18:00,264 epoch 18 - iter 864/1084 - loss 0.06045035 - samples/sec: 129.04 - lr: 0.000008
2021-07-24 05:18:26,651 epoch 18 - iter 972/1084 - loss 0.06287806 - samples/sec: 131.00 - lr: 0.000008
2021-07-24 05:18:52,757 epoch 18 - iter 1080/1084 - loss 0.06293795 - samples/sec: 132.41 - lr: 0.000008
2021-07-24 05:18:53,531 ----------------------------------------------------------------------------------------------------
2021-07-24 05:18:53,531 EPOCH 18 done: loss 0.0628 - lr 0.0000075
2021-07-24 05:19:08,062 DEV : loss 0.08855948597192764 - score 0.9719
2021-07-24 05:19:08,218 BAD EPOCHS (no improvement): 1
2021-07-24 05:19:08,218 ----------------------------------------------------------------------------------------------------
2021-07-24 05:19:34,707 epoch 19 - iter 108/1084 - loss 0.06353542 - samples/sec: 130.51 - lr: 0.000008
2021-07-24 05:20:00,732 epoch 19 - iter 216/1084 - loss 0.05951913 - samples/sec: 132.83 - lr: 0.000008
2021-07-24 05:20:26,701 epoch 19 - iter 324/1084 - loss 0.05999806 - samples/sec: 133.11 - lr: 0.000008
2021-07-24 05:20:52,833 epoch 19 - iter 432/1084 - loss 0.05850147 - samples/sec: 132.28 - lr: 0.000008
2021-07-24 05:21:19,519 epoch 19 - iter 540/1084 - loss 0.05938107 - samples/sec: 129.53 - lr: 0.000008
2021-07-24 05:21:45,891 epoch 19 - iter 648/1084 - loss 0.06055004 - samples/sec: 131.07 - lr: 0.000008
2021-07-24 05:22:12,156 epoch 19 - iter 756/1084 - loss 0.06145210 - samples/sec: 131.61 - lr: 0.000008
2021-07-24 05:22:38,479 epoch 19 - iter 864/1084 - loss 0.06147982 - samples/sec: 131.32 - lr: 0.000008
2021-07-24 05:23:04,933 epoch 19 - iter 972/1084 - loss 0.06130560 - samples/sec: 130.67 - lr: 0.000008
2021-07-24 05:23:31,196 epoch 19 - iter 1080/1084 - loss 0.06148151 - samples/sec: 131.62 - lr: 0.000008
2021-07-24 05:23:31,994 ----------------------------------------------------------------------------------------------------
2021-07-24 05:23:31,995 EPOCH 19 done: loss 0.0613 - lr 0.0000075
2021-07-24 05:23:48,081 DEV : loss 0.0930757150053978 - score 0.9718
2021-07-24 05:23:48,236 BAD EPOCHS (no improvement): 2
2021-07-24 05:23:48,237 ----------------------------------------------------------------------------------------------------
2021-07-24 05:24:14,460 epoch 20 - iter 108/1084 - loss 0.05231254 - samples/sec: 131.83 - lr: 0.000008
2021-07-24 05:24:40,756 epoch 20 - iter 216/1084 - loss 0.05627777 - samples/sec: 131.45 - lr: 0.000008
2021-07-24 05:25:07,368 epoch 20 - iter 324/1084 - loss 0.05646185 - samples/sec: 129.90 - lr: 0.000008
2021-07-24 05:25:33,431 epoch 20 - iter 432/1084 - loss 0.05752090 - samples/sec: 132.63 - lr: 0.000008
2021-07-24 05:26:00,092 epoch 20 - iter 540/1084 - loss 0.05907858 - samples/sec: 129.66 - lr: 0.000008
2021-07-24 05:26:26,804 epoch 20 - iter 648/1084 - loss 0.06054053 - samples/sec: 129.41 - lr: 0.000008
2021-07-24 05:26:53,192 epoch 20 - iter 756/1084 - loss 0.06108104 - samples/sec: 130.99 - lr: 0.000008
2021-07-24 05:27:19,568 epoch 20 - iter 864/1084 - loss 0.06048076 - samples/sec: 131.06 - lr: 0.000008
2021-07-24 05:27:45,929 epoch 20 - iter 972/1084 - loss 0.06001406 - samples/sec: 131.13 - lr: 0.000008
2021-07-24 05:28:12,204 epoch 20 - iter 1080/1084 - loss 0.06043448 - samples/sec: 131.56 - lr: 0.000008
2021-07-24 05:28:12,961 ----------------------------------------------------------------------------------------------------
2021-07-24 05:28:12,961 EPOCH 20 done: loss 0.0603 - lr 0.0000075
2021-07-24 05:28:27,546 DEV : loss 0.08965574204921722 - score 0.9717
2021-07-24 05:28:27,701 BAD EPOCHS (no improvement): 3
2021-07-24 05:28:27,701 ----------------------------------------------------------------------------------------------------
2021-07-24 05:28:53,689 epoch 21 - iter 108/1084 - loss 0.05381075 - samples/sec: 133.03 - lr: 0.000008
2021-07-24 05:29:19,896 epoch 21 - iter 216/1084 - loss 0.05886886 - samples/sec: 131.90 - lr: 0.000008
2021-07-24 05:29:46,181 epoch 21 - iter 324/1084 - loss 0.05799003 - samples/sec: 131.51 - lr: 0.000008
2021-07-24 05:30:12,212 epoch 21 - iter 432/1084 - loss 0.05780317 - samples/sec: 132.80 - lr: 0.000008
2021-07-24 05:30:38,837 epoch 21 - iter 540/1084 - loss 0.05768478 - samples/sec: 129.83 - lr: 0.000008
2021-07-24 05:31:05,296 epoch 21 - iter 648/1084 - loss 0.05922838 - samples/sec: 130.64 - lr: 0.000008
2021-07-24 05:31:31,715 epoch 21 - iter 756/1084 - loss 0.05893721 - samples/sec: 130.85 - lr: 0.000008
2021-07-24 05:31:58,140 epoch 21 - iter 864/1084 - loss 0.05879743 - samples/sec: 130.81 - lr: 0.000008
2021-07-24 05:32:24,348 epoch 21 - iter 972/1084 - loss 0.05863154 - samples/sec: 131.90 - lr: 0.000008
2021-07-24 05:32:50,744 epoch 21 - iter 1080/1084 - loss 0.05898266 - samples/sec: 130.96 - lr: 0.000008
2021-07-24 05:32:51,611 ----------------------------------------------------------------------------------------------------
2021-07-24 05:32:51,612 EPOCH 21 done: loss 0.0588 - lr 0.0000075
2021-07-24 05:33:06,197 DEV : loss 0.08649978041648865 - score 0.9744
2021-07-24 05:33:06,354 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 05:33:09,381 ----------------------------------------------------------------------------------------------------
2021-07-24 05:33:35,861 epoch 22 - iter 108/1084 - loss 0.05365638 - samples/sec: 130.56 - lr: 0.000008
2021-07-24 05:34:01,984 epoch 22 - iter 216/1084 - loss 0.05547144 - samples/sec: 132.32 - lr: 0.000008
2021-07-24 05:34:28,562 epoch 22 - iter 324/1084 - loss 0.05679612 - samples/sec: 130.06 - lr: 0.000008
2021-07-24 05:34:54,909 epoch 22 - iter 432/1084 - loss 0.05635061 - samples/sec: 131.20 - lr: 0.000008
2021-07-24 05:35:21,201 epoch 22 - iter 540/1084 - loss 0.05672629 - samples/sec: 131.47 - lr: 0.000008
2021-07-24 05:35:47,439 epoch 22 - iter 648/1084 - loss 0.05520630 - samples/sec: 131.74 - lr: 0.000008
2021-07-24 05:36:13,264 epoch 22 - iter 756/1084 - loss 0.05525876 - samples/sec: 133.85 - lr: 0.000008
2021-07-24 05:36:39,517 epoch 22 - iter 864/1084 - loss 0.05649418 - samples/sec: 131.67 - lr: 0.000008
2021-07-24 05:37:05,984 epoch 22 - iter 972/1084 - loss 0.05776058 - samples/sec: 130.61 - lr: 0.000008
2021-07-24 05:37:32,444 epoch 22 - iter 1080/1084 - loss 0.05762658 - samples/sec: 130.64 - lr: 0.000008
2021-07-24 05:37:33,252 ----------------------------------------------------------------------------------------------------
2021-07-24 05:37:33,252 EPOCH 22 done: loss 0.0581 - lr 0.0000075
2021-07-24 05:37:47,906 DEV : loss 0.09064372628927231 - score 0.9721
2021-07-24 05:37:48,060 BAD EPOCHS (no improvement): 1
2021-07-24 05:37:48,060 ----------------------------------------------------------------------------------------------------
2021-07-24 05:38:14,401 epoch 23 - iter 108/1084 - loss 0.07303649 - samples/sec: 131.25 - lr: 0.000008
2021-07-24 05:38:41,173 epoch 23 - iter 216/1084 - loss 0.06478313 - samples/sec: 129.12 - lr: 0.000008
2021-07-24 05:39:07,860 epoch 23 - iter 324/1084 - loss 0.06028849 - samples/sec: 129.52 - lr: 0.000008
2021-07-24 05:39:34,476 epoch 23 - iter 432/1084 - loss 0.06065755 - samples/sec: 129.87 - lr: 0.000008
2021-07-24 05:40:00,769 epoch 23 - iter 540/1084 - loss 0.06284793 - samples/sec: 131.47 - lr: 0.000008
2021-07-24 05:40:27,261 epoch 23 - iter 648/1084 - loss 0.06236564 - samples/sec: 130.48 - lr: 0.000008
2021-07-24 05:40:53,780 epoch 23 - iter 756/1084 - loss 0.06133665 - samples/sec: 130.34 - lr: 0.000008
2021-07-24 05:41:20,049 epoch 23 - iter 864/1084 - loss 0.05981772 - samples/sec: 131.59 - lr: 0.000008
2021-07-24 05:41:46,130 epoch 23 - iter 972/1084 - loss 0.06029387 - samples/sec: 132.54 - lr: 0.000008
2021-07-24 05:42:12,580 epoch 23 - iter 1080/1084 - loss 0.05963556 - samples/sec: 130.69 - lr: 0.000008
2021-07-24 05:42:13,421 ----------------------------------------------------------------------------------------------------
2021-07-24 05:42:13,421 EPOCH 23 done: loss 0.0595 - lr 0.0000075
2021-07-24 05:42:28,007 DEV : loss 0.09065548330545425 - score 0.9722
2021-07-24 05:42:28,163 BAD EPOCHS (no improvement): 2
2021-07-24 05:42:28,163 ----------------------------------------------------------------------------------------------------
2021-07-24 05:42:54,420 epoch 24 - iter 108/1084 - loss 0.05573158 - samples/sec: 131.66 - lr: 0.000008
2021-07-24 05:43:20,708 epoch 24 - iter 216/1084 - loss 0.05706372 - samples/sec: 131.49 - lr: 0.000008
2021-07-24 05:43:47,177 epoch 24 - iter 324/1084 - loss 0.05949553 - samples/sec: 130.59 - lr: 0.000008
2021-07-24 05:44:13,674 epoch 24 - iter 432/1084 - loss 0.05963684 - samples/sec: 130.46 - lr: 0.000008
2021-07-24 05:44:40,190 epoch 24 - iter 540/1084 - loss 0.05788976 - samples/sec: 130.36 - lr: 0.000008
2021-07-24 05:45:07,808 epoch 24 - iter 648/1084 - loss 0.05975208 - samples/sec: 125.16 - lr: 0.000008
2021-07-24 05:45:34,159 epoch 24 - iter 756/1084 - loss 0.05908695 - samples/sec: 131.18 - lr: 0.000008
2021-07-24 05:46:00,428 epoch 24 - iter 864/1084 - loss 0.05873629 - samples/sec: 131.59 - lr: 0.000008
2021-07-24 05:46:26,917 epoch 24 - iter 972/1084 - loss 0.05851357 - samples/sec: 130.50 - lr: 0.000008
2021-07-24 05:46:53,524 epoch 24 - iter 1080/1084 - loss 0.05897330 - samples/sec: 129.91 - lr: 0.000008
2021-07-24 05:46:54,283 ----------------------------------------------------------------------------------------------------
2021-07-24 05:46:54,283 EPOCH 24 done: loss 0.0589 - lr 0.0000075
2021-07-24 05:47:08,878 DEV : loss 0.08751308172941208 - score 0.9732
2021-07-24 05:47:09,033 BAD EPOCHS (no improvement): 3
2021-07-24 05:47:09,034 ----------------------------------------------------------------------------------------------------
2021-07-24 05:47:35,297 epoch 25 - iter 108/1084 - loss 0.06000093 - samples/sec: 131.63 - lr: 0.000008
2021-07-24 05:48:01,620 epoch 25 - iter 216/1084 - loss 0.06402872 - samples/sec: 131.32 - lr: 0.000008
2021-07-24 05:48:27,818 epoch 25 - iter 324/1084 - loss 0.06089140 - samples/sec: 131.94 - lr: 0.000008
2021-07-24 05:48:54,017 epoch 25 - iter 432/1084 - loss 0.05943272 - samples/sec: 131.94 - lr: 0.000008
2021-07-24 05:49:20,474 epoch 25 - iter 540/1084 - loss 0.05650180 - samples/sec: 130.65 - lr: 0.000008
2021-07-24 05:49:47,062 epoch 25 - iter 648/1084 - loss 0.05684830 - samples/sec: 130.01 - lr: 0.000008
2021-07-24 05:50:13,620 epoch 25 - iter 756/1084 - loss 0.05727693 - samples/sec: 130.16 - lr: 0.000008
2021-07-24 05:50:40,272 epoch 25 - iter 864/1084 - loss 0.05723163 - samples/sec: 129.70 - lr: 0.000008
2021-07-24 05:51:06,743 epoch 25 - iter 972/1084 - loss 0.05693687 - samples/sec: 130.59 - lr: 0.000008
2021-07-24 05:51:32,835 epoch 25 - iter 1080/1084 - loss 0.05745832 - samples/sec: 132.48 - lr: 0.000008
2021-07-24 05:51:33,582 ----------------------------------------------------------------------------------------------------
2021-07-24 05:51:33,582 EPOCH 25 done: loss 0.0573 - lr 0.0000075
2021-07-24 05:51:48,157 DEV : loss 0.09377556294202805 - score 0.971
Epoch    25: reducing learning rate of group 0 to 3.7500e-06.
2021-07-24 05:51:48,314 BAD EPOCHS (no improvement): 4
2021-07-24 05:51:48,315 ----------------------------------------------------------------------------------------------------
2021-07-24 05:52:14,188 epoch 26 - iter 108/1084 - loss 0.05669659 - samples/sec: 133.62 - lr: 0.000004
2021-07-24 05:52:40,112 epoch 26 - iter 216/1084 - loss 0.05464569 - samples/sec: 133.34 - lr: 0.000004
2021-07-24 05:53:06,291 epoch 26 - iter 324/1084 - loss 0.05494468 - samples/sec: 132.04 - lr: 0.000004
2021-07-24 05:53:32,617 epoch 26 - iter 432/1084 - loss 0.05807668 - samples/sec: 131.30 - lr: 0.000004
2021-07-24 05:53:58,856 epoch 26 - iter 540/1084 - loss 0.05742494 - samples/sec: 131.74 - lr: 0.000004
2021-07-24 05:54:25,592 epoch 26 - iter 648/1084 - loss 0.05781473 - samples/sec: 129.29 - lr: 0.000004
2021-07-24 05:54:52,108 epoch 26 - iter 756/1084 - loss 0.05663358 - samples/sec: 130.36 - lr: 0.000004
2021-07-24 05:55:18,453 epoch 26 - iter 864/1084 - loss 0.05595480 - samples/sec: 131.21 - lr: 0.000004
2021-07-24 05:55:44,945 epoch 26 - iter 972/1084 - loss 0.05564829 - samples/sec: 130.48 - lr: 0.000004
2021-07-24 05:56:11,284 epoch 26 - iter 1080/1084 - loss 0.05606065 - samples/sec: 131.24 - lr: 0.000004
2021-07-24 05:56:12,046 ----------------------------------------------------------------------------------------------------
2021-07-24 05:56:12,046 EPOCH 26 done: loss 0.0561 - lr 0.0000038
2021-07-24 05:56:26,677 DEV : loss 0.09287476539611816 - score 0.9714
2021-07-24 05:56:26,833 BAD EPOCHS (no improvement): 1
2021-07-24 05:56:26,833 ----------------------------------------------------------------------------------------------------
2021-07-24 05:56:53,200 epoch 27 - iter 108/1084 - loss 0.04726639 - samples/sec: 131.12 - lr: 0.000004
2021-07-24 05:57:19,539 epoch 27 - iter 216/1084 - loss 0.04819185 - samples/sec: 131.24 - lr: 0.000004
2021-07-24 05:57:45,839 epoch 27 - iter 324/1084 - loss 0.05464064 - samples/sec: 131.44 - lr: 0.000004
2021-07-24 05:58:12,106 epoch 27 - iter 432/1084 - loss 0.05252403 - samples/sec: 131.60 - lr: 0.000004
2021-07-24 05:58:38,753 epoch 27 - iter 540/1084 - loss 0.05400837 - samples/sec: 129.72 - lr: 0.000004
2021-07-24 05:59:04,939 epoch 27 - iter 648/1084 - loss 0.05455262 - samples/sec: 132.01 - lr: 0.000004
2021-07-24 05:59:31,561 epoch 27 - iter 756/1084 - loss 0.05592386 - samples/sec: 129.84 - lr: 0.000004
2021-07-24 05:59:57,909 epoch 27 - iter 864/1084 - loss 0.05679327 - samples/sec: 131.20 - lr: 0.000004
2021-07-24 06:00:24,432 epoch 27 - iter 972/1084 - loss 0.05682765 - samples/sec: 130.33 - lr: 0.000004
2021-07-24 06:00:50,857 epoch 27 - iter 1080/1084 - loss 0.05757157 - samples/sec: 130.81 - lr: 0.000004
2021-07-24 06:00:51,663 ----------------------------------------------------------------------------------------------------
2021-07-24 06:00:51,663 EPOCH 27 done: loss 0.0574 - lr 0.0000038
2021-07-24 06:01:06,186 DEV : loss 0.09258265048265457 - score 0.9713
2021-07-24 06:01:06,341 BAD EPOCHS (no improvement): 2
2021-07-24 06:01:06,342 ----------------------------------------------------------------------------------------------------
2021-07-24 06:01:32,291 epoch 28 - iter 108/1084 - loss 0.05843193 - samples/sec: 133.22 - lr: 0.000004
2021-07-24 06:01:58,484 epoch 28 - iter 216/1084 - loss 0.06353535 - samples/sec: 131.97 - lr: 0.000004
2021-07-24 06:02:24,509 epoch 28 - iter 324/1084 - loss 0.05977796 - samples/sec: 132.82 - lr: 0.000004
2021-07-24 06:02:50,620 epoch 28 - iter 432/1084 - loss 0.06094243 - samples/sec: 132.39 - lr: 0.000004
2021-07-24 06:03:17,207 epoch 28 - iter 540/1084 - loss 0.05827063 - samples/sec: 130.01 - lr: 0.000004
2021-07-24 06:03:43,813 epoch 28 - iter 648/1084 - loss 0.05809676 - samples/sec: 129.92 - lr: 0.000004
2021-07-24 06:04:10,525 epoch 28 - iter 756/1084 - loss 0.05886793 - samples/sec: 129.41 - lr: 0.000004
2021-07-24 06:04:36,929 epoch 28 - iter 864/1084 - loss 0.05885365 - samples/sec: 130.92 - lr: 0.000004
2021-07-24 06:05:03,495 epoch 28 - iter 972/1084 - loss 0.05830177 - samples/sec: 130.12 - lr: 0.000004
2021-07-24 06:05:29,792 epoch 28 - iter 1080/1084 - loss 0.05819457 - samples/sec: 131.45 - lr: 0.000004
2021-07-24 06:05:30,546 ----------------------------------------------------------------------------------------------------
2021-07-24 06:05:30,546 EPOCH 28 done: loss 0.0580 - lr 0.0000038
2021-07-24 06:05:46,556 DEV : loss 0.09556177258491516 - score 0.9716
2021-07-24 06:05:46,711 BAD EPOCHS (no improvement): 3
2021-07-24 06:05:46,711 ----------------------------------------------------------------------------------------------------
2021-07-24 06:06:13,208 epoch 29 - iter 108/1084 - loss 0.05784263 - samples/sec: 130.47 - lr: 0.000004
2021-07-24 06:06:39,745 epoch 29 - iter 216/1084 - loss 0.05828807 - samples/sec: 130.26 - lr: 0.000004
2021-07-24 06:07:06,311 epoch 29 - iter 324/1084 - loss 0.05842957 - samples/sec: 130.12 - lr: 0.000004
2021-07-24 06:07:32,624 epoch 29 - iter 432/1084 - loss 0.05738225 - samples/sec: 131.37 - lr: 0.000004
2021-07-24 06:07:58,891 epoch 29 - iter 540/1084 - loss 0.05783992 - samples/sec: 131.60 - lr: 0.000004
2021-07-24 06:08:24,939 epoch 29 - iter 648/1084 - loss 0.05645241 - samples/sec: 132.70 - lr: 0.000004
2021-07-24 06:08:51,351 epoch 29 - iter 756/1084 - loss 0.05623685 - samples/sec: 130.88 - lr: 0.000004
2021-07-24 06:09:17,804 epoch 29 - iter 864/1084 - loss 0.05639724 - samples/sec: 130.67 - lr: 0.000004
2021-07-24 06:09:44,276 epoch 29 - iter 972/1084 - loss 0.05614581 - samples/sec: 130.58 - lr: 0.000004
2021-07-24 06:10:10,802 epoch 29 - iter 1080/1084 - loss 0.05700778 - samples/sec: 130.32 - lr: 0.000004
2021-07-24 06:10:11,604 ----------------------------------------------------------------------------------------------------
2021-07-24 06:10:11,604 EPOCH 29 done: loss 0.0570 - lr 0.0000038
2021-07-24 06:10:26,249 DEV : loss 0.09545617550611496 - score 0.9715
Epoch    29: reducing learning rate of group 0 to 1.8750e-06.
2021-07-24 06:10:26,406 BAD EPOCHS (no improvement): 4
2021-07-24 06:10:26,406 ----------------------------------------------------------------------------------------------------
2021-07-24 06:10:26,406 ----------------------------------------------------------------------------------------------------
2021-07-24 06:10:26,406 learning rate too small - quitting training!
2021-07-24 06:10:26,406 ----------------------------------------------------------------------------------------------------
2021-07-24 06:10:27,083 ----------------------------------------------------------------------------------------------------
2021-07-24 06:10:27,083 Testing using best model ...
2021-07-24 06:10:27,084 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/rus.rst.rrt/best-model.pt
2021-07-24 06:15:34,125 0.9752	0.9556	0.9653
2021-07-24 06:15:34,125 
Results:
- F1-score (micro) 0.9653
- F1-score (macro) 0.9640

By class:
SENT       tp: 6126 - fp: 337 - fn: 615 - precision: 0.9479 - recall: 0.9088 - f1-score: 0.9279
X          tp: 7113 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-24 06:15:34,125 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.gum/
2021-07-24 06:15:34,182 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.gum
2021-07-24 06:15:34,183 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.gum/sent_train.txt
2021-07-24 06:15:34,185 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.gum/sent_dev.txt
2021-07-24 06:15:34,186 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.gum/sent_test.txt
Corpus: 12555 train + 2617 dev + 4452 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-24 06:15:42,753 ----------------------------------------------------------------------------------------------------
2021-07-24 06:15:42,755 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-24 06:15:42,755 ----------------------------------------------------------------------------------------------------
2021-07-24 06:15:42,755 Corpus: "Corpus: 12555 train + 2617 dev + 4452 test sentences"
2021-07-24 06:15:42,755 ----------------------------------------------------------------------------------------------------
2021-07-24 06:15:42,755 Parameters:
2021-07-24 06:15:42,755  - learning_rate: "3e-05"
2021-07-24 06:15:42,755  - mini_batch_size: "32"
2021-07-24 06:15:42,755  - patience: "3"
2021-07-24 06:15:42,755  - anneal_factor: "0.5"
2021-07-24 06:15:42,755  - max_epochs: "40"
2021-07-24 06:15:42,755  - shuffle: "True"
2021-07-24 06:15:42,755  - train_with_dev: "False"
2021-07-24 06:15:42,756  - batch_growth_annealing: "False"
2021-07-24 06:15:42,756 ----------------------------------------------------------------------------------------------------
2021-07-24 06:15:42,756 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.gum"
2021-07-24 06:15:42,756 ----------------------------------------------------------------------------------------------------
2021-07-24 06:15:42,756 Device: cuda:0
2021-07-24 06:15:42,756 ----------------------------------------------------------------------------------------------------
2021-07-24 06:15:42,756 Embeddings storage mode: cpu
2021-07-24 06:15:42,758 ----------------------------------------------------------------------------------------------------
2021-07-24 06:16:05,188 epoch 1 - iter 39/393 - loss 11.00206717 - samples/sec: 55.65 - lr: 0.000030
2021-07-24 06:16:28,125 epoch 1 - iter 78/393 - loss 8.62125225 - samples/sec: 54.41 - lr: 0.000030
2021-07-24 06:16:51,353 epoch 1 - iter 117/393 - loss 6.58674174 - samples/sec: 53.73 - lr: 0.000030
2021-07-24 06:17:14,255 epoch 1 - iter 156/393 - loss 5.26689122 - samples/sec: 54.50 - lr: 0.000030
2021-07-24 06:17:35,468 epoch 1 - iter 195/393 - loss 4.42296900 - samples/sec: 58.84 - lr: 0.000030
2021-07-24 06:17:57,478 epoch 1 - iter 234/393 - loss 3.80572363 - samples/sec: 56.70 - lr: 0.000030
2021-07-24 06:18:19,916 epoch 1 - iter 273/393 - loss 3.34219749 - samples/sec: 55.63 - lr: 0.000030
2021-07-24 06:18:41,846 epoch 1 - iter 312/393 - loss 2.97934510 - samples/sec: 56.91 - lr: 0.000030
2021-07-24 06:19:04,452 epoch 1 - iter 351/393 - loss 2.69356784 - samples/sec: 55.21 - lr: 0.000030
2021-07-24 06:19:27,455 epoch 1 - iter 390/393 - loss 2.45455588 - samples/sec: 54.26 - lr: 0.000030
2021-07-24 06:19:28,772 ----------------------------------------------------------------------------------------------------
2021-07-24 06:19:28,773 EPOCH 1 done: loss 2.4397 - lr 0.0000300
2021-07-24 06:20:02,714 DEV : loss 0.16213659942150116 - score 0.9735
2021-07-24 06:20:02,786 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:20:03,359 ----------------------------------------------------------------------------------------------------
2021-07-24 06:20:12,375 epoch 2 - iter 39/393 - loss 0.29315654 - samples/sec: 138.47 - lr: 0.000030
2021-07-24 06:20:21,496 epoch 2 - iter 78/393 - loss 0.27830458 - samples/sec: 136.86 - lr: 0.000030
2021-07-24 06:20:30,497 epoch 2 - iter 117/393 - loss 0.27684939 - samples/sec: 138.69 - lr: 0.000030
2021-07-24 06:20:39,605 epoch 2 - iter 156/393 - loss 0.26726237 - samples/sec: 137.05 - lr: 0.000030
2021-07-24 06:20:48,723 epoch 2 - iter 195/393 - loss 0.25955280 - samples/sec: 136.90 - lr: 0.000030
2021-07-24 06:20:57,863 epoch 2 - iter 234/393 - loss 0.25074408 - samples/sec: 136.57 - lr: 0.000030
2021-07-24 06:21:07,195 epoch 2 - iter 273/393 - loss 0.24392327 - samples/sec: 133.76 - lr: 0.000030
2021-07-24 06:21:16,287 epoch 2 - iter 312/393 - loss 0.23692440 - samples/sec: 137.29 - lr: 0.000030
2021-07-24 06:21:25,232 epoch 2 - iter 351/393 - loss 0.23342290 - samples/sec: 139.56 - lr: 0.000030
2021-07-24 06:21:34,484 epoch 2 - iter 390/393 - loss 0.22913186 - samples/sec: 134.91 - lr: 0.000030
2021-07-24 06:21:35,062 ----------------------------------------------------------------------------------------------------
2021-07-24 06:21:35,063 EPOCH 2 done: loss 0.2296 - lr 0.0000300
2021-07-24 06:21:41,295 DEV : loss 0.09120579063892365 - score 0.9824
2021-07-24 06:21:41,366 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:21:44,038 ----------------------------------------------------------------------------------------------------
2021-07-24 06:21:53,815 epoch 3 - iter 39/393 - loss 0.20022841 - samples/sec: 127.71 - lr: 0.000030
2021-07-24 06:22:02,965 epoch 3 - iter 78/393 - loss 0.19770774 - samples/sec: 136.42 - lr: 0.000030
2021-07-24 06:22:12,043 epoch 3 - iter 117/393 - loss 0.18636920 - samples/sec: 137.51 - lr: 0.000030
2021-07-24 06:22:21,263 epoch 3 - iter 156/393 - loss 0.18523268 - samples/sec: 135.39 - lr: 0.000030
2021-07-24 06:22:30,157 epoch 3 - iter 195/393 - loss 0.18306002 - samples/sec: 140.35 - lr: 0.000030
2021-07-24 06:22:39,284 epoch 3 - iter 234/393 - loss 0.17758772 - samples/sec: 136.77 - lr: 0.000030
2021-07-24 06:22:48,432 epoch 3 - iter 273/393 - loss 0.17694136 - samples/sec: 136.46 - lr: 0.000030
2021-07-24 06:22:57,447 epoch 3 - iter 312/393 - loss 0.17915606 - samples/sec: 138.47 - lr: 0.000030
2021-07-24 06:23:06,569 epoch 3 - iter 351/393 - loss 0.17789476 - samples/sec: 136.84 - lr: 0.000030
2021-07-24 06:23:15,881 epoch 3 - iter 390/393 - loss 0.17762804 - samples/sec: 134.04 - lr: 0.000030
2021-07-24 06:23:16,471 ----------------------------------------------------------------------------------------------------
2021-07-24 06:23:16,471 EPOCH 3 done: loss 0.1772 - lr 0.0000300
2021-07-24 06:23:22,763 DEV : loss 0.08110915124416351 - score 0.9837
2021-07-24 06:23:22,835 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:23:25,228 ----------------------------------------------------------------------------------------------------
2021-07-24 06:23:34,486 epoch 4 - iter 39/393 - loss 0.16543345 - samples/sec: 134.86 - lr: 0.000030
2021-07-24 06:23:43,685 epoch 4 - iter 78/393 - loss 0.16914398 - samples/sec: 135.71 - lr: 0.000030
2021-07-24 06:23:52,717 epoch 4 - iter 117/393 - loss 0.16069680 - samples/sec: 138.20 - lr: 0.000030
2021-07-24 06:24:02,058 epoch 4 - iter 156/393 - loss 0.15974334 - samples/sec: 133.64 - lr: 0.000030
2021-07-24 06:24:10,932 epoch 4 - iter 195/393 - loss 0.15606307 - samples/sec: 140.66 - lr: 0.000030
2021-07-24 06:24:20,420 epoch 4 - iter 234/393 - loss 0.15130948 - samples/sec: 131.57 - lr: 0.000030
2021-07-24 06:24:29,607 epoch 4 - iter 273/393 - loss 0.14961162 - samples/sec: 135.87 - lr: 0.000030
2021-07-24 06:24:38,792 epoch 4 - iter 312/393 - loss 0.15169725 - samples/sec: 135.91 - lr: 0.000030
2021-07-24 06:24:48,056 epoch 4 - iter 351/393 - loss 0.14904477 - samples/sec: 134.75 - lr: 0.000030
2021-07-24 06:24:57,320 epoch 4 - iter 390/393 - loss 0.14970427 - samples/sec: 134.75 - lr: 0.000030
2021-07-24 06:24:57,850 ----------------------------------------------------------------------------------------------------
2021-07-24 06:24:57,850 EPOCH 4 done: loss 0.1492 - lr 0.0000300
2021-07-24 06:25:04,120 DEV : loss 0.07308125495910645 - score 0.9838
2021-07-24 06:25:04,192 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:25:06,665 ----------------------------------------------------------------------------------------------------
2021-07-24 06:25:16,004 epoch 5 - iter 39/393 - loss 0.17738976 - samples/sec: 133.71 - lr: 0.000030
2021-07-24 06:25:25,228 epoch 5 - iter 78/393 - loss 0.16757707 - samples/sec: 135.33 - lr: 0.000030
2021-07-24 06:25:34,393 epoch 5 - iter 117/393 - loss 0.16147045 - samples/sec: 136.19 - lr: 0.000030
2021-07-24 06:25:43,608 epoch 5 - iter 156/393 - loss 0.16054088 - samples/sec: 135.47 - lr: 0.000030
2021-07-24 06:25:52,869 epoch 5 - iter 195/393 - loss 0.15397663 - samples/sec: 134.79 - lr: 0.000030
2021-07-24 06:26:02,239 epoch 5 - iter 234/393 - loss 0.15173996 - samples/sec: 133.22 - lr: 0.000030
2021-07-24 06:26:11,388 epoch 5 - iter 273/393 - loss 0.14898797 - samples/sec: 136.44 - lr: 0.000030
2021-07-24 06:26:20,565 epoch 5 - iter 312/393 - loss 0.14958827 - samples/sec: 136.01 - lr: 0.000030
2021-07-24 06:26:29,641 epoch 5 - iter 351/393 - loss 0.15032907 - samples/sec: 137.55 - lr: 0.000030
2021-07-24 06:26:38,740 epoch 5 - iter 390/393 - loss 0.14880351 - samples/sec: 137.18 - lr: 0.000030
2021-07-24 06:26:39,350 ----------------------------------------------------------------------------------------------------
2021-07-24 06:26:39,350 EPOCH 5 done: loss 0.1479 - lr 0.0000300
2021-07-24 06:26:45,654 DEV : loss 0.07217183709144592 - score 0.9845
2021-07-24 06:26:45,726 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:26:48,320 ----------------------------------------------------------------------------------------------------
2021-07-24 06:26:57,397 epoch 6 - iter 39/393 - loss 0.16102797 - samples/sec: 137.55 - lr: 0.000030
2021-07-24 06:27:06,513 epoch 6 - iter 78/393 - loss 0.15082864 - samples/sec: 136.94 - lr: 0.000030
2021-07-24 06:27:15,493 epoch 6 - iter 117/393 - loss 0.14230080 - samples/sec: 139.01 - lr: 0.000030
2021-07-24 06:27:24,652 epoch 6 - iter 156/393 - loss 0.14269812 - samples/sec: 136.28 - lr: 0.000030
2021-07-24 06:27:33,937 epoch 6 - iter 195/393 - loss 0.13738832 - samples/sec: 134.44 - lr: 0.000030
2021-07-24 06:27:43,416 epoch 6 - iter 234/393 - loss 0.13921547 - samples/sec: 131.68 - lr: 0.000030
2021-07-24 06:27:52,641 epoch 6 - iter 273/393 - loss 0.13714214 - samples/sec: 135.32 - lr: 0.000030
2021-07-24 06:28:01,744 epoch 6 - iter 312/393 - loss 0.13388638 - samples/sec: 137.13 - lr: 0.000030
2021-07-24 06:28:11,092 epoch 6 - iter 351/393 - loss 0.13559454 - samples/sec: 133.53 - lr: 0.000030
2021-07-24 06:28:20,291 epoch 6 - iter 390/393 - loss 0.13585633 - samples/sec: 135.70 - lr: 0.000030
2021-07-24 06:28:20,952 ----------------------------------------------------------------------------------------------------
2021-07-24 06:28:20,952 EPOCH 6 done: loss 0.1352 - lr 0.0000300
2021-07-24 06:28:27,749 DEV : loss 0.06980425119400024 - score 0.9851
2021-07-24 06:28:27,821 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:28:32,618 ----------------------------------------------------------------------------------------------------
2021-07-24 06:28:41,674 epoch 7 - iter 39/393 - loss 0.13214156 - samples/sec: 137.87 - lr: 0.000030
2021-07-24 06:28:50,868 epoch 7 - iter 78/393 - loss 0.13845220 - samples/sec: 135.78 - lr: 0.000030
2021-07-24 06:29:00,261 epoch 7 - iter 117/393 - loss 0.13576261 - samples/sec: 132.90 - lr: 0.000030
2021-07-24 06:29:09,473 epoch 7 - iter 156/393 - loss 0.13353484 - samples/sec: 135.50 - lr: 0.000030
2021-07-24 06:29:18,664 epoch 7 - iter 195/393 - loss 0.13518405 - samples/sec: 135.82 - lr: 0.000030
2021-07-24 06:29:28,024 epoch 7 - iter 234/393 - loss 0.13310706 - samples/sec: 133.36 - lr: 0.000030
2021-07-24 06:29:37,285 epoch 7 - iter 273/393 - loss 0.13746376 - samples/sec: 134.79 - lr: 0.000030
2021-07-24 06:29:46,504 epoch 7 - iter 312/393 - loss 0.13519016 - samples/sec: 135.40 - lr: 0.000030
2021-07-24 06:29:55,828 epoch 7 - iter 351/393 - loss 0.13498522 - samples/sec: 133.89 - lr: 0.000030
2021-07-24 06:30:04,877 epoch 7 - iter 390/393 - loss 0.13517336 - samples/sec: 137.95 - lr: 0.000030
2021-07-24 06:30:05,483 ----------------------------------------------------------------------------------------------------
2021-07-24 06:30:05,483 EPOCH 7 done: loss 0.1354 - lr 0.0000300
2021-07-24 06:30:11,784 DEV : loss 0.06750128418207169 - score 0.9851
2021-07-24 06:30:11,856 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:30:14,521 ----------------------------------------------------------------------------------------------------
2021-07-24 06:30:23,628 epoch 8 - iter 39/393 - loss 0.12318132 - samples/sec: 137.10 - lr: 0.000030
2021-07-24 06:30:32,735 epoch 8 - iter 78/393 - loss 0.11497614 - samples/sec: 137.07 - lr: 0.000030
2021-07-24 06:30:41,849 epoch 8 - iter 117/393 - loss 0.12407187 - samples/sec: 136.97 - lr: 0.000030
2021-07-24 06:30:51,112 epoch 8 - iter 156/393 - loss 0.12889783 - samples/sec: 134.76 - lr: 0.000030
2021-07-24 06:31:00,253 epoch 8 - iter 195/393 - loss 0.12861732 - samples/sec: 136.56 - lr: 0.000030
2021-07-24 06:31:09,491 epoch 8 - iter 234/393 - loss 0.12717826 - samples/sec: 135.12 - lr: 0.000030
2021-07-24 06:31:18,982 epoch 8 - iter 273/393 - loss 0.12644309 - samples/sec: 131.53 - lr: 0.000030
2021-07-24 06:31:28,123 epoch 8 - iter 312/393 - loss 0.12394647 - samples/sec: 136.56 - lr: 0.000030
2021-07-24 06:31:37,366 epoch 8 - iter 351/393 - loss 0.12261859 - samples/sec: 135.05 - lr: 0.000030
2021-07-24 06:31:46,613 epoch 8 - iter 390/393 - loss 0.12364680 - samples/sec: 134.98 - lr: 0.000030
2021-07-24 06:31:47,139 ----------------------------------------------------------------------------------------------------
2021-07-24 06:31:47,139 EPOCH 8 done: loss 0.1246 - lr 0.0000300
2021-07-24 06:31:53,447 DEV : loss 0.0654531940817833 - score 0.9848
2021-07-24 06:31:53,519 BAD EPOCHS (no improvement): 1
2021-07-24 06:31:53,519 ----------------------------------------------------------------------------------------------------
2021-07-24 06:32:02,693 epoch 9 - iter 39/393 - loss 0.12279281 - samples/sec: 136.09 - lr: 0.000030
2021-07-24 06:32:11,743 epoch 9 - iter 78/393 - loss 0.11784544 - samples/sec: 137.95 - lr: 0.000030
2021-07-24 06:32:21,025 epoch 9 - iter 117/393 - loss 0.11511574 - samples/sec: 134.48 - lr: 0.000030
2021-07-24 06:32:30,198 epoch 9 - iter 156/393 - loss 0.11131316 - samples/sec: 136.09 - lr: 0.000030
2021-07-24 06:32:39,510 epoch 9 - iter 195/393 - loss 0.12210640 - samples/sec: 134.05 - lr: 0.000030
2021-07-24 06:32:48,641 epoch 9 - iter 234/393 - loss 0.12427258 - samples/sec: 136.71 - lr: 0.000030
2021-07-24 06:32:58,070 epoch 9 - iter 273/393 - loss 0.12492671 - samples/sec: 132.39 - lr: 0.000030
2021-07-24 06:33:07,281 epoch 9 - iter 312/393 - loss 0.12551263 - samples/sec: 135.52 - lr: 0.000030
2021-07-24 06:33:16,503 epoch 9 - iter 351/393 - loss 0.12508959 - samples/sec: 135.37 - lr: 0.000030
2021-07-24 06:33:25,736 epoch 9 - iter 390/393 - loss 0.12486652 - samples/sec: 135.19 - lr: 0.000030
2021-07-24 06:33:26,332 ----------------------------------------------------------------------------------------------------
2021-07-24 06:33:26,332 EPOCH 9 done: loss 0.1252 - lr 0.0000300
2021-07-24 06:33:32,597 DEV : loss 0.06304371356964111 - score 0.9857
2021-07-24 06:33:32,669 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:33:34,955 ----------------------------------------------------------------------------------------------------
2021-07-24 06:33:44,288 epoch 10 - iter 39/393 - loss 0.10654203 - samples/sec: 133.77 - lr: 0.000030
2021-07-24 06:33:53,400 epoch 10 - iter 78/393 - loss 0.09953984 - samples/sec: 137.01 - lr: 0.000030
2021-07-24 06:34:02,749 epoch 10 - iter 117/393 - loss 0.10838240 - samples/sec: 133.51 - lr: 0.000030
2021-07-24 06:34:11,935 epoch 10 - iter 156/393 - loss 0.11490253 - samples/sec: 135.90 - lr: 0.000030
2021-07-24 06:34:21,143 epoch 10 - iter 195/393 - loss 0.11755312 - samples/sec: 135.56 - lr: 0.000030
2021-07-24 06:34:30,535 epoch 10 - iter 234/393 - loss 0.11948352 - samples/sec: 132.90 - lr: 0.000030
2021-07-24 06:34:39,632 epoch 10 - iter 273/393 - loss 0.11839672 - samples/sec: 137.22 - lr: 0.000030
2021-07-24 06:34:48,988 epoch 10 - iter 312/393 - loss 0.12056750 - samples/sec: 133.43 - lr: 0.000030
2021-07-24 06:34:57,920 epoch 10 - iter 351/393 - loss 0.12181345 - samples/sec: 139.75 - lr: 0.000030
2021-07-24 06:35:07,237 epoch 10 - iter 390/393 - loss 0.12067690 - samples/sec: 133.98 - lr: 0.000030
2021-07-24 06:35:07,775 ----------------------------------------------------------------------------------------------------
2021-07-24 06:35:07,775 EPOCH 10 done: loss 0.1200 - lr 0.0000300
2021-07-24 06:35:14,080 DEV : loss 0.06145715340971947 - score 0.9865
2021-07-24 06:35:14,153 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:35:17,189 ----------------------------------------------------------------------------------------------------
2021-07-24 06:35:26,363 epoch 11 - iter 39/393 - loss 0.11884526 - samples/sec: 136.10 - lr: 0.000030
2021-07-24 06:35:35,537 epoch 11 - iter 78/393 - loss 0.11795502 - samples/sec: 136.07 - lr: 0.000030
2021-07-24 06:35:44,717 epoch 11 - iter 117/393 - loss 0.11360100 - samples/sec: 135.98 - lr: 0.000030
2021-07-24 06:35:53,944 epoch 11 - iter 156/393 - loss 0.11592201 - samples/sec: 135.28 - lr: 0.000030
2021-07-24 06:36:03,213 epoch 11 - iter 195/393 - loss 0.11633832 - samples/sec: 134.67 - lr: 0.000030
2021-07-24 06:36:12,467 epoch 11 - iter 234/393 - loss 0.11318067 - samples/sec: 134.89 - lr: 0.000030
2021-07-24 06:36:21,521 epoch 11 - iter 273/393 - loss 0.11174594 - samples/sec: 137.87 - lr: 0.000030
2021-07-24 06:36:30,605 epoch 11 - iter 312/393 - loss 0.11231152 - samples/sec: 137.43 - lr: 0.000030
2021-07-24 06:36:40,003 epoch 11 - iter 351/393 - loss 0.11394013 - samples/sec: 132.81 - lr: 0.000030
2021-07-24 06:36:49,212 epoch 11 - iter 390/393 - loss 0.11399054 - samples/sec: 135.55 - lr: 0.000030
2021-07-24 06:36:49,807 ----------------------------------------------------------------------------------------------------
2021-07-24 06:36:49,808 EPOCH 11 done: loss 0.1141 - lr 0.0000300
2021-07-24 06:36:56,106 DEV : loss 0.061834290623664856 - score 0.9865
2021-07-24 06:36:56,178 BAD EPOCHS (no improvement): 1
2021-07-24 06:36:56,178 ----------------------------------------------------------------------------------------------------
2021-07-24 06:37:05,460 epoch 12 - iter 39/393 - loss 0.11093052 - samples/sec: 134.50 - lr: 0.000030
2021-07-24 06:37:14,551 epoch 12 - iter 78/393 - loss 0.12163723 - samples/sec: 137.31 - lr: 0.000030
2021-07-24 06:37:23,635 epoch 12 - iter 117/393 - loss 0.11970061 - samples/sec: 137.43 - lr: 0.000030
2021-07-24 06:37:33,229 epoch 12 - iter 156/393 - loss 0.11724788 - samples/sec: 130.10 - lr: 0.000030
2021-07-24 06:37:42,375 epoch 12 - iter 195/393 - loss 0.11182546 - samples/sec: 136.48 - lr: 0.000030
2021-07-24 06:37:51,539 epoch 12 - iter 234/393 - loss 0.11050981 - samples/sec: 136.22 - lr: 0.000030
2021-07-24 06:38:00,903 epoch 12 - iter 273/393 - loss 0.10847580 - samples/sec: 133.30 - lr: 0.000030
2021-07-24 06:38:10,067 epoch 12 - iter 312/393 - loss 0.11030483 - samples/sec: 136.22 - lr: 0.000030
2021-07-24 06:38:19,132 epoch 12 - iter 351/393 - loss 0.11251375 - samples/sec: 137.70 - lr: 0.000030
2021-07-24 06:38:28,224 epoch 12 - iter 390/393 - loss 0.11379362 - samples/sec: 137.30 - lr: 0.000030
2021-07-24 06:38:28,779 ----------------------------------------------------------------------------------------------------
2021-07-24 06:38:28,779 EPOCH 12 done: loss 0.1134 - lr 0.0000300
2021-07-24 06:38:35,080 DEV : loss 0.061540886759757996 - score 0.987
2021-07-24 06:38:35,153 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:38:37,767 ----------------------------------------------------------------------------------------------------
2021-07-24 06:38:46,926 epoch 13 - iter 39/393 - loss 0.10925001 - samples/sec: 136.32 - lr: 0.000030
2021-07-24 06:38:56,166 epoch 13 - iter 78/393 - loss 0.11000844 - samples/sec: 135.10 - lr: 0.000030
2021-07-24 06:39:05,451 epoch 13 - iter 117/393 - loss 0.10447327 - samples/sec: 134.44 - lr: 0.000030
2021-07-24 06:39:14,553 epoch 13 - iter 156/393 - loss 0.10643716 - samples/sec: 137.14 - lr: 0.000030
2021-07-24 06:39:23,708 epoch 13 - iter 195/393 - loss 0.10975305 - samples/sec: 136.35 - lr: 0.000030
2021-07-24 06:39:33,092 epoch 13 - iter 234/393 - loss 0.10991892 - samples/sec: 133.02 - lr: 0.000030
2021-07-24 06:39:42,297 epoch 13 - iter 273/393 - loss 0.10827390 - samples/sec: 135.62 - lr: 0.000030
2021-07-24 06:39:51,508 epoch 13 - iter 312/393 - loss 0.10636153 - samples/sec: 135.52 - lr: 0.000030
2021-07-24 06:40:00,755 epoch 13 - iter 351/393 - loss 0.10630306 - samples/sec: 134.99 - lr: 0.000030
2021-07-24 06:40:09,796 epoch 13 - iter 390/393 - loss 0.10669063 - samples/sec: 138.06 - lr: 0.000030
2021-07-24 06:40:10,392 ----------------------------------------------------------------------------------------------------
2021-07-24 06:40:10,392 EPOCH 13 done: loss 0.1063 - lr 0.0000300
2021-07-24 06:40:16,691 DEV : loss 0.06409802287817001 - score 0.9868
2021-07-24 06:40:16,763 BAD EPOCHS (no improvement): 1
2021-07-24 06:40:16,763 ----------------------------------------------------------------------------------------------------
2021-07-24 06:40:25,828 epoch 14 - iter 39/393 - loss 0.09375462 - samples/sec: 137.72 - lr: 0.000030
2021-07-24 06:40:35,176 epoch 14 - iter 78/393 - loss 0.11170138 - samples/sec: 133.53 - lr: 0.000030
2021-07-24 06:40:44,396 epoch 14 - iter 117/393 - loss 0.10742139 - samples/sec: 135.39 - lr: 0.000030
2021-07-24 06:40:53,712 epoch 14 - iter 156/393 - loss 0.10952156 - samples/sec: 134.00 - lr: 0.000030
2021-07-24 06:41:02,847 epoch 14 - iter 195/393 - loss 0.10565976 - samples/sec: 136.64 - lr: 0.000030
2021-07-24 06:41:12,020 epoch 14 - iter 234/393 - loss 0.10500668 - samples/sec: 136.09 - lr: 0.000030
2021-07-24 06:41:21,215 epoch 14 - iter 273/393 - loss 0.10598984 - samples/sec: 135.76 - lr: 0.000030
2021-07-24 06:41:30,357 epoch 14 - iter 312/393 - loss 0.10567065 - samples/sec: 136.55 - lr: 0.000030
2021-07-24 06:41:39,638 epoch 14 - iter 351/393 - loss 0.10624694 - samples/sec: 134.49 - lr: 0.000030
2021-07-24 06:41:48,910 epoch 14 - iter 390/393 - loss 0.10361895 - samples/sec: 134.64 - lr: 0.000030
2021-07-24 06:41:49,452 ----------------------------------------------------------------------------------------------------
2021-07-24 06:41:49,452 EPOCH 14 done: loss 0.1045 - lr 0.0000300
2021-07-24 06:41:55,690 DEV : loss 0.061598461121320724 - score 0.9873
2021-07-24 06:41:55,762 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:41:58,674 ----------------------------------------------------------------------------------------------------
2021-07-24 06:42:08,025 epoch 15 - iter 39/393 - loss 0.10304319 - samples/sec: 133.51 - lr: 0.000030
2021-07-24 06:42:17,081 epoch 15 - iter 78/393 - loss 0.09881758 - samples/sec: 137.83 - lr: 0.000030
2021-07-24 06:42:26,458 epoch 15 - iter 117/393 - loss 0.10222758 - samples/sec: 133.13 - lr: 0.000030
2021-07-24 06:42:35,660 epoch 15 - iter 156/393 - loss 0.09923031 - samples/sec: 135.64 - lr: 0.000030
2021-07-24 06:42:44,944 epoch 15 - iter 195/393 - loss 0.09745063 - samples/sec: 134.46 - lr: 0.000030
2021-07-24 06:42:54,016 epoch 15 - iter 234/393 - loss 0.09683046 - samples/sec: 137.60 - lr: 0.000030
2021-07-24 06:43:03,166 epoch 15 - iter 273/393 - loss 0.10018192 - samples/sec: 136.42 - lr: 0.000030
2021-07-24 06:43:12,500 epoch 15 - iter 312/393 - loss 0.09862389 - samples/sec: 133.73 - lr: 0.000030
2021-07-24 06:43:21,615 epoch 15 - iter 351/393 - loss 0.09826444 - samples/sec: 136.94 - lr: 0.000030
2021-07-24 06:43:30,581 epoch 15 - iter 390/393 - loss 0.09763029 - samples/sec: 139.23 - lr: 0.000030
2021-07-24 06:43:31,151 ----------------------------------------------------------------------------------------------------
2021-07-24 06:43:31,151 EPOCH 15 done: loss 0.0982 - lr 0.0000300
2021-07-24 06:43:37,371 DEV : loss 0.06214213743805885 - score 0.9878
2021-07-24 06:43:37,444 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:43:39,944 ----------------------------------------------------------------------------------------------------
2021-07-24 06:43:49,200 epoch 16 - iter 39/393 - loss 0.09051419 - samples/sec: 134.89 - lr: 0.000030
2021-07-24 06:43:58,380 epoch 16 - iter 78/393 - loss 0.09589395 - samples/sec: 135.98 - lr: 0.000030
2021-07-24 06:44:07,472 epoch 16 - iter 117/393 - loss 0.09702474 - samples/sec: 137.29 - lr: 0.000030
2021-07-24 06:44:16,712 epoch 16 - iter 156/393 - loss 0.09546679 - samples/sec: 135.10 - lr: 0.000030
2021-07-24 06:44:25,915 epoch 16 - iter 195/393 - loss 0.09578981 - samples/sec: 135.64 - lr: 0.000030
2021-07-24 06:44:34,875 epoch 16 - iter 234/393 - loss 0.09639995 - samples/sec: 139.31 - lr: 0.000030
2021-07-24 06:44:43,920 epoch 16 - iter 273/393 - loss 0.09751092 - samples/sec: 138.02 - lr: 0.000030
2021-07-24 06:44:53,027 epoch 16 - iter 312/393 - loss 0.09850790 - samples/sec: 137.06 - lr: 0.000030
2021-07-24 06:45:02,160 epoch 16 - iter 351/393 - loss 0.09807913 - samples/sec: 136.67 - lr: 0.000030
2021-07-24 06:45:11,171 epoch 16 - iter 390/393 - loss 0.09729973 - samples/sec: 138.54 - lr: 0.000030
2021-07-24 06:45:11,703 ----------------------------------------------------------------------------------------------------
2021-07-24 06:45:11,703 EPOCH 16 done: loss 0.0969 - lr 0.0000300
2021-07-24 06:45:17,909 DEV : loss 0.06170007586479187 - score 0.9876
2021-07-24 06:45:17,981 BAD EPOCHS (no improvement): 1
2021-07-24 06:45:17,981 ----------------------------------------------------------------------------------------------------
2021-07-24 06:45:27,300 epoch 17 - iter 39/393 - loss 0.09031733 - samples/sec: 133.98 - lr: 0.000030
2021-07-24 06:45:36,483 epoch 17 - iter 78/393 - loss 0.09094540 - samples/sec: 135.93 - lr: 0.000030
2021-07-24 06:45:45,501 epoch 17 - iter 117/393 - loss 0.08558645 - samples/sec: 138.42 - lr: 0.000030
2021-07-24 06:45:54,376 epoch 17 - iter 156/393 - loss 0.08560053 - samples/sec: 140.65 - lr: 0.000030
2021-07-24 06:46:03,552 epoch 17 - iter 195/393 - loss 0.08765981 - samples/sec: 136.04 - lr: 0.000030
2021-07-24 06:46:12,668 epoch 17 - iter 234/393 - loss 0.08806661 - samples/sec: 136.94 - lr: 0.000030
2021-07-24 06:46:21,648 epoch 17 - iter 273/393 - loss 0.08864051 - samples/sec: 139.01 - lr: 0.000030
2021-07-24 06:46:30,956 epoch 17 - iter 312/393 - loss 0.09015607 - samples/sec: 134.11 - lr: 0.000030
2021-07-24 06:46:40,134 epoch 17 - iter 351/393 - loss 0.09031219 - samples/sec: 136.01 - lr: 0.000030
2021-07-24 06:46:49,287 epoch 17 - iter 390/393 - loss 0.09015960 - samples/sec: 136.37 - lr: 0.000030
2021-07-24 06:46:49,875 ----------------------------------------------------------------------------------------------------
2021-07-24 06:46:49,875 EPOCH 17 done: loss 0.0895 - lr 0.0000300
2021-07-24 06:46:56,116 DEV : loss 0.057763878256082535 - score 0.9887
2021-07-24 06:46:56,189 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:46:58,411 ----------------------------------------------------------------------------------------------------
2021-07-24 06:47:07,612 epoch 18 - iter 39/393 - loss 0.06805860 - samples/sec: 135.71 - lr: 0.000030
2021-07-24 06:47:16,680 epoch 18 - iter 78/393 - loss 0.08584402 - samples/sec: 137.65 - lr: 0.000030
2021-07-24 06:47:25,816 epoch 18 - iter 117/393 - loss 0.08717076 - samples/sec: 136.64 - lr: 0.000030
2021-07-24 06:47:34,921 epoch 18 - iter 156/393 - loss 0.08643851 - samples/sec: 137.10 - lr: 0.000030
2021-07-24 06:47:44,020 epoch 18 - iter 195/393 - loss 0.08551698 - samples/sec: 137.18 - lr: 0.000030
2021-07-24 06:47:53,276 epoch 18 - iter 234/393 - loss 0.08803489 - samples/sec: 134.87 - lr: 0.000030
2021-07-24 06:48:02,553 epoch 18 - iter 273/393 - loss 0.08731435 - samples/sec: 134.55 - lr: 0.000030
2021-07-24 06:48:11,617 epoch 18 - iter 312/393 - loss 0.08771215 - samples/sec: 137.72 - lr: 0.000030
2021-07-24 06:48:21,068 epoch 18 - iter 351/393 - loss 0.09128980 - samples/sec: 132.07 - lr: 0.000030
2021-07-24 06:48:30,132 epoch 18 - iter 390/393 - loss 0.09128424 - samples/sec: 137.73 - lr: 0.000030
2021-07-24 06:48:30,688 ----------------------------------------------------------------------------------------------------
2021-07-24 06:48:30,688 EPOCH 18 done: loss 0.0909 - lr 0.0000300
2021-07-24 06:48:36,935 DEV : loss 0.05922761559486389 - score 0.9879
2021-07-24 06:48:37,008 BAD EPOCHS (no improvement): 1
2021-07-24 06:48:37,008 ----------------------------------------------------------------------------------------------------
2021-07-24 06:48:46,711 epoch 19 - iter 39/393 - loss 0.07588600 - samples/sec: 128.66 - lr: 0.000030
2021-07-24 06:48:55,959 epoch 19 - iter 78/393 - loss 0.07258864 - samples/sec: 134.99 - lr: 0.000030
2021-07-24 06:49:05,138 epoch 19 - iter 117/393 - loss 0.07347255 - samples/sec: 135.98 - lr: 0.000030
2021-07-24 06:49:14,120 epoch 19 - iter 156/393 - loss 0.08286554 - samples/sec: 138.98 - lr: 0.000030
2021-07-24 06:49:23,694 epoch 19 - iter 195/393 - loss 0.08431353 - samples/sec: 130.38 - lr: 0.000030
2021-07-24 06:49:32,883 epoch 19 - iter 234/393 - loss 0.08398871 - samples/sec: 135.83 - lr: 0.000030
2021-07-24 06:49:42,027 epoch 19 - iter 273/393 - loss 0.08434048 - samples/sec: 136.52 - lr: 0.000030
2021-07-24 06:49:51,263 epoch 19 - iter 312/393 - loss 0.08244640 - samples/sec: 135.15 - lr: 0.000030
2021-07-24 06:50:00,464 epoch 19 - iter 351/393 - loss 0.08416215 - samples/sec: 135.68 - lr: 0.000030
2021-07-24 06:50:09,449 epoch 19 - iter 390/393 - loss 0.08410530 - samples/sec: 138.93 - lr: 0.000030
2021-07-24 06:50:10,019 ----------------------------------------------------------------------------------------------------
2021-07-24 06:50:10,019 EPOCH 19 done: loss 0.0843 - lr 0.0000300
2021-07-24 06:50:16,256 DEV : loss 0.05727248266339302 - score 0.9887
2021-07-24 06:50:16,328 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:50:18,494 ----------------------------------------------------------------------------------------------------
2021-07-24 06:50:27,685 epoch 20 - iter 39/393 - loss 0.07643056 - samples/sec: 135.85 - lr: 0.000030
2021-07-24 06:50:36,855 epoch 20 - iter 78/393 - loss 0.08559498 - samples/sec: 136.12 - lr: 0.000030
2021-07-24 06:50:46,085 epoch 20 - iter 117/393 - loss 0.08453037 - samples/sec: 135.25 - lr: 0.000030
2021-07-24 06:50:55,224 epoch 20 - iter 156/393 - loss 0.08166002 - samples/sec: 136.58 - lr: 0.000030
2021-07-24 06:51:04,474 epoch 20 - iter 195/393 - loss 0.07950889 - samples/sec: 134.96 - lr: 0.000030
2021-07-24 06:51:13,652 epoch 20 - iter 234/393 - loss 0.08528986 - samples/sec: 136.00 - lr: 0.000030
2021-07-24 06:51:22,907 epoch 20 - iter 273/393 - loss 0.08431787 - samples/sec: 134.88 - lr: 0.000030
2021-07-24 06:51:31,961 epoch 20 - iter 312/393 - loss 0.08235931 - samples/sec: 137.87 - lr: 0.000030
2021-07-24 06:51:41,041 epoch 20 - iter 351/393 - loss 0.08437792 - samples/sec: 137.49 - lr: 0.000030
2021-07-24 06:51:50,282 epoch 20 - iter 390/393 - loss 0.08299897 - samples/sec: 135.07 - lr: 0.000030
2021-07-24 06:51:50,911 ----------------------------------------------------------------------------------------------------
2021-07-24 06:51:50,911 EPOCH 20 done: loss 0.0833 - lr 0.0000300
2021-07-24 06:51:57,144 DEV : loss 0.05544283613562584 - score 0.9884
2021-07-24 06:51:57,216 BAD EPOCHS (no improvement): 1
2021-07-24 06:51:57,217 ----------------------------------------------------------------------------------------------------
2021-07-24 06:52:06,328 epoch 21 - iter 39/393 - loss 0.08553688 - samples/sec: 137.03 - lr: 0.000030
2021-07-24 06:52:15,488 epoch 21 - iter 78/393 - loss 0.08129986 - samples/sec: 136.27 - lr: 0.000030
2021-07-24 06:52:24,707 epoch 21 - iter 117/393 - loss 0.07816756 - samples/sec: 135.40 - lr: 0.000030
2021-07-24 06:52:33,957 epoch 21 - iter 156/393 - loss 0.07336589 - samples/sec: 134.95 - lr: 0.000030
2021-07-24 06:52:42,893 epoch 21 - iter 195/393 - loss 0.07389643 - samples/sec: 139.70 - lr: 0.000030
2021-07-24 06:52:52,214 epoch 21 - iter 234/393 - loss 0.07556076 - samples/sec: 133.92 - lr: 0.000030
2021-07-24 06:53:01,460 epoch 21 - iter 273/393 - loss 0.07868013 - samples/sec: 135.01 - lr: 0.000030
2021-07-24 06:53:10,651 epoch 21 - iter 312/393 - loss 0.07999327 - samples/sec: 135.81 - lr: 0.000030
2021-07-24 06:53:19,851 epoch 21 - iter 351/393 - loss 0.08172440 - samples/sec: 135.69 - lr: 0.000030
2021-07-24 06:53:29,032 epoch 21 - iter 390/393 - loss 0.08065728 - samples/sec: 135.96 - lr: 0.000030
2021-07-24 06:53:29,619 ----------------------------------------------------------------------------------------------------
2021-07-24 06:53:29,619 EPOCH 21 done: loss 0.0810 - lr 0.0000300
2021-07-24 06:53:35,873 DEV : loss 0.05561660975217819 - score 0.9892
2021-07-24 06:53:35,945 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 06:53:38,232 ----------------------------------------------------------------------------------------------------
2021-07-24 06:53:47,238 epoch 22 - iter 39/393 - loss 0.07941215 - samples/sec: 138.65 - lr: 0.000030
2021-07-24 06:53:56,612 epoch 22 - iter 78/393 - loss 0.08442992 - samples/sec: 133.16 - lr: 0.000030
2021-07-24 06:54:05,722 epoch 22 - iter 117/393 - loss 0.08101417 - samples/sec: 137.02 - lr: 0.000030
2021-07-24 06:54:14,885 epoch 22 - iter 156/393 - loss 0.08138201 - samples/sec: 136.23 - lr: 0.000030
2021-07-24 06:54:24,368 epoch 22 - iter 195/393 - loss 0.08248706 - samples/sec: 131.63 - lr: 0.000030
2021-07-24 06:54:33,685 epoch 22 - iter 234/393 - loss 0.08354527 - samples/sec: 133.98 - lr: 0.000030
2021-07-24 06:54:42,740 epoch 22 - iter 273/393 - loss 0.08101703 - samples/sec: 137.84 - lr: 0.000030
2021-07-24 06:54:51,871 epoch 22 - iter 312/393 - loss 0.08318292 - samples/sec: 136.71 - lr: 0.000030
2021-07-24 06:55:00,873 epoch 22 - iter 351/393 - loss 0.08158588 - samples/sec: 138.68 - lr: 0.000030
2021-07-24 06:55:10,056 epoch 22 - iter 390/393 - loss 0.08171291 - samples/sec: 135.93 - lr: 0.000030
2021-07-24 06:55:10,682 ----------------------------------------------------------------------------------------------------
2021-07-24 06:55:10,682 EPOCH 22 done: loss 0.0816 - lr 0.0000300
2021-07-24 06:55:17,440 DEV : loss 0.05683962628245354 - score 0.9878
2021-07-24 06:55:17,511 BAD EPOCHS (no improvement): 1
2021-07-24 06:55:17,512 ----------------------------------------------------------------------------------------------------
2021-07-24 06:55:26,562 epoch 23 - iter 39/393 - loss 0.07739859 - samples/sec: 137.95 - lr: 0.000030
2021-07-24 06:55:35,663 epoch 23 - iter 78/393 - loss 0.07979560 - samples/sec: 137.15 - lr: 0.000030
2021-07-24 06:55:44,697 epoch 23 - iter 117/393 - loss 0.07161847 - samples/sec: 138.19 - lr: 0.000030
2021-07-24 06:55:53,867 epoch 23 - iter 156/393 - loss 0.07352461 - samples/sec: 136.11 - lr: 0.000030
2021-07-24 06:56:03,210 epoch 23 - iter 195/393 - loss 0.07332043 - samples/sec: 133.61 - lr: 0.000030
2021-07-24 06:56:12,377 epoch 23 - iter 234/393 - loss 0.07561816 - samples/sec: 136.17 - lr: 0.000030
2021-07-24 06:56:21,727 epoch 23 - iter 273/393 - loss 0.07224462 - samples/sec: 133.50 - lr: 0.000030
2021-07-24 06:56:30,941 epoch 23 - iter 312/393 - loss 0.07142008 - samples/sec: 135.47 - lr: 0.000030
2021-07-24 06:56:40,049 epoch 23 - iter 351/393 - loss 0.07265223 - samples/sec: 137.06 - lr: 0.000030
2021-07-24 06:56:49,300 epoch 23 - iter 390/393 - loss 0.07515158 - samples/sec: 134.93 - lr: 0.000030
2021-07-24 06:56:49,875 ----------------------------------------------------------------------------------------------------
2021-07-24 06:56:49,875 EPOCH 23 done: loss 0.0752 - lr 0.0000300
2021-07-24 06:56:56,143 DEV : loss 0.053302548825740814 - score 0.9887
2021-07-24 06:56:56,214 BAD EPOCHS (no improvement): 2
2021-07-24 06:56:56,215 ----------------------------------------------------------------------------------------------------
2021-07-24 06:57:05,145 epoch 24 - iter 39/393 - loss 0.08217750 - samples/sec: 139.80 - lr: 0.000030
2021-07-24 06:57:14,408 epoch 24 - iter 78/393 - loss 0.08330123 - samples/sec: 134.76 - lr: 0.000030
2021-07-24 06:57:23,673 epoch 24 - iter 117/393 - loss 0.07878714 - samples/sec: 134.73 - lr: 0.000030
2021-07-24 06:57:33,204 epoch 24 - iter 156/393 - loss 0.07558814 - samples/sec: 130.96 - lr: 0.000030
2021-07-24 06:57:42,336 epoch 24 - iter 195/393 - loss 0.07521001 - samples/sec: 136.69 - lr: 0.000030
2021-07-24 06:57:51,555 epoch 24 - iter 234/393 - loss 0.07557937 - samples/sec: 135.40 - lr: 0.000030
2021-07-24 06:58:00,653 epoch 24 - iter 273/393 - loss 0.07710319 - samples/sec: 137.22 - lr: 0.000030
2021-07-24 06:58:09,903 epoch 24 - iter 312/393 - loss 0.07612817 - samples/sec: 134.94 - lr: 0.000030
2021-07-24 06:58:18,985 epoch 24 - iter 351/393 - loss 0.07747774 - samples/sec: 137.46 - lr: 0.000030
2021-07-24 06:58:28,209 epoch 24 - iter 390/393 - loss 0.07868815 - samples/sec: 135.33 - lr: 0.000030
2021-07-24 06:58:28,739 ----------------------------------------------------------------------------------------------------
2021-07-24 06:58:28,739 EPOCH 24 done: loss 0.0791 - lr 0.0000300
2021-07-24 06:58:34,965 DEV : loss 0.05346343293786049 - score 0.9884
2021-07-24 06:58:35,037 BAD EPOCHS (no improvement): 3
2021-07-24 06:58:35,037 ----------------------------------------------------------------------------------------------------
2021-07-24 06:58:44,195 epoch 25 - iter 39/393 - loss 0.09541467 - samples/sec: 136.33 - lr: 0.000030
2021-07-24 06:58:53,461 epoch 25 - iter 78/393 - loss 0.08282792 - samples/sec: 134.73 - lr: 0.000030
2021-07-24 06:59:02,654 epoch 25 - iter 117/393 - loss 0.08130243 - samples/sec: 135.79 - lr: 0.000030
2021-07-24 06:59:11,629 epoch 25 - iter 156/393 - loss 0.08155681 - samples/sec: 139.08 - lr: 0.000030
2021-07-24 06:59:20,944 epoch 25 - iter 195/393 - loss 0.07985651 - samples/sec: 134.01 - lr: 0.000030
2021-07-24 06:59:30,091 epoch 25 - iter 234/393 - loss 0.07915738 - samples/sec: 136.47 - lr: 0.000030
2021-07-24 06:59:39,047 epoch 25 - iter 273/393 - loss 0.07686955 - samples/sec: 139.37 - lr: 0.000030
2021-07-24 06:59:48,215 epoch 25 - iter 312/393 - loss 0.07537064 - samples/sec: 136.16 - lr: 0.000030
2021-07-24 06:59:57,351 epoch 25 - iter 351/393 - loss 0.07479878 - samples/sec: 136.63 - lr: 0.000030
2021-07-24 07:00:06,652 epoch 25 - iter 390/393 - loss 0.07518550 - samples/sec: 134.22 - lr: 0.000030
2021-07-24 07:00:07,189 ----------------------------------------------------------------------------------------------------
2021-07-24 07:00:07,190 EPOCH 25 done: loss 0.0755 - lr 0.0000300
2021-07-24 07:00:13,403 DEV : loss 0.055185467004776 - score 0.9884
Epoch    25: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 07:00:13,475 BAD EPOCHS (no improvement): 4
2021-07-24 07:00:13,476 ----------------------------------------------------------------------------------------------------
2021-07-24 07:00:22,912 epoch 26 - iter 39/393 - loss 0.06259927 - samples/sec: 132.31 - lr: 0.000015
2021-07-24 07:00:31,965 epoch 26 - iter 78/393 - loss 0.06304419 - samples/sec: 137.89 - lr: 0.000015
2021-07-24 07:00:41,125 epoch 26 - iter 117/393 - loss 0.06910708 - samples/sec: 136.27 - lr: 0.000015
2021-07-24 07:00:50,369 epoch 26 - iter 156/393 - loss 0.06948851 - samples/sec: 135.04 - lr: 0.000015
2021-07-24 07:00:59,576 epoch 26 - iter 195/393 - loss 0.06738007 - samples/sec: 135.57 - lr: 0.000015
2021-07-24 07:01:08,853 epoch 26 - iter 234/393 - loss 0.06834709 - samples/sec: 134.56 - lr: 0.000015
2021-07-24 07:01:17,881 epoch 26 - iter 273/393 - loss 0.06730985 - samples/sec: 138.27 - lr: 0.000015
2021-07-24 07:01:27,113 epoch 26 - iter 312/393 - loss 0.06843896 - samples/sec: 135.21 - lr: 0.000015
2021-07-24 07:01:36,319 epoch 26 - iter 351/393 - loss 0.06733509 - samples/sec: 135.59 - lr: 0.000015
2021-07-24 07:01:45,440 epoch 26 - iter 390/393 - loss 0.06830972 - samples/sec: 136.86 - lr: 0.000015
2021-07-24 07:01:46,064 ----------------------------------------------------------------------------------------------------
2021-07-24 07:01:46,064 EPOCH 26 done: loss 0.0679 - lr 0.0000150
2021-07-24 07:01:52,834 DEV : loss 0.05569158494472504 - score 0.9881
2021-07-24 07:01:52,906 BAD EPOCHS (no improvement): 1
2021-07-24 07:01:52,906 ----------------------------------------------------------------------------------------------------
2021-07-24 07:02:02,042 epoch 27 - iter 39/393 - loss 0.06221636 - samples/sec: 136.66 - lr: 0.000015
2021-07-24 07:02:11,180 epoch 27 - iter 78/393 - loss 0.07687609 - samples/sec: 136.60 - lr: 0.000015
2021-07-24 07:02:20,356 epoch 27 - iter 117/393 - loss 0.07455580 - samples/sec: 136.04 - lr: 0.000015
2021-07-24 07:02:29,570 epoch 27 - iter 156/393 - loss 0.07368016 - samples/sec: 135.48 - lr: 0.000015
2021-07-24 07:02:38,663 epoch 27 - iter 195/393 - loss 0.07166619 - samples/sec: 137.27 - lr: 0.000015
2021-07-24 07:02:47,901 epoch 27 - iter 234/393 - loss 0.06851009 - samples/sec: 135.13 - lr: 0.000015
2021-07-24 07:02:56,949 epoch 27 - iter 273/393 - loss 0.06735156 - samples/sec: 137.97 - lr: 0.000015
2021-07-24 07:03:06,054 epoch 27 - iter 312/393 - loss 0.06865548 - samples/sec: 137.09 - lr: 0.000015
2021-07-24 07:03:15,128 epoch 27 - iter 351/393 - loss 0.06937346 - samples/sec: 137.57 - lr: 0.000015
2021-07-24 07:03:24,259 epoch 27 - iter 390/393 - loss 0.06801419 - samples/sec: 136.72 - lr: 0.000015
2021-07-24 07:03:24,873 ----------------------------------------------------------------------------------------------------
2021-07-24 07:03:24,874 EPOCH 27 done: loss 0.0677 - lr 0.0000150
2021-07-24 07:03:31,109 DEV : loss 0.05335904657840729 - score 0.9887
2021-07-24 07:03:31,182 BAD EPOCHS (no improvement): 2
2021-07-24 07:03:31,182 ----------------------------------------------------------------------------------------------------
2021-07-24 07:03:40,283 epoch 28 - iter 39/393 - loss 0.07665495 - samples/sec: 137.18 - lr: 0.000015
2021-07-24 07:03:49,243 epoch 28 - iter 78/393 - loss 0.07275871 - samples/sec: 139.32 - lr: 0.000015
2021-07-24 07:03:58,417 epoch 28 - iter 117/393 - loss 0.06864643 - samples/sec: 136.07 - lr: 0.000015
2021-07-24 07:04:07,997 epoch 28 - iter 156/393 - loss 0.06614572 - samples/sec: 130.30 - lr: 0.000015
2021-07-24 07:04:17,401 epoch 28 - iter 195/393 - loss 0.07079951 - samples/sec: 132.74 - lr: 0.000015
2021-07-24 07:04:26,685 epoch 28 - iter 234/393 - loss 0.06873279 - samples/sec: 134.46 - lr: 0.000015
2021-07-24 07:04:35,465 epoch 28 - iter 273/393 - loss 0.06756986 - samples/sec: 142.16 - lr: 0.000015
2021-07-24 07:04:44,767 epoch 28 - iter 312/393 - loss 0.06758760 - samples/sec: 134.20 - lr: 0.000015
2021-07-24 07:04:53,909 epoch 28 - iter 351/393 - loss 0.06842576 - samples/sec: 136.55 - lr: 0.000015
2021-07-24 07:05:03,032 epoch 28 - iter 390/393 - loss 0.06701050 - samples/sec: 136.83 - lr: 0.000015
2021-07-24 07:05:03,600 ----------------------------------------------------------------------------------------------------
2021-07-24 07:05:03,600 EPOCH 28 done: loss 0.0676 - lr 0.0000150
2021-07-24 07:05:09,854 DEV : loss 0.05567755177617073 - score 0.9887
2021-07-24 07:05:09,927 BAD EPOCHS (no improvement): 3
2021-07-24 07:05:09,927 ----------------------------------------------------------------------------------------------------
2021-07-24 07:05:19,143 epoch 29 - iter 39/393 - loss 0.05408524 - samples/sec: 135.46 - lr: 0.000015
2021-07-24 07:05:28,444 epoch 29 - iter 78/393 - loss 0.05888684 - samples/sec: 134.22 - lr: 0.000015
2021-07-24 07:05:37,728 epoch 29 - iter 117/393 - loss 0.05924450 - samples/sec: 134.45 - lr: 0.000015
2021-07-24 07:05:46,885 epoch 29 - iter 156/393 - loss 0.06091157 - samples/sec: 136.32 - lr: 0.000015
2021-07-24 07:05:56,219 epoch 29 - iter 195/393 - loss 0.06121662 - samples/sec: 133.73 - lr: 0.000015
2021-07-24 07:06:05,442 epoch 29 - iter 234/393 - loss 0.06064018 - samples/sec: 135.35 - lr: 0.000015
2021-07-24 07:06:14,456 epoch 29 - iter 273/393 - loss 0.05886641 - samples/sec: 138.48 - lr: 0.000015
2021-07-24 07:06:23,572 epoch 29 - iter 312/393 - loss 0.06092395 - samples/sec: 136.94 - lr: 0.000015
2021-07-24 07:06:32,771 epoch 29 - iter 351/393 - loss 0.06299403 - samples/sec: 135.70 - lr: 0.000015
2021-07-24 07:06:41,987 epoch 29 - iter 390/393 - loss 0.06443957 - samples/sec: 135.44 - lr: 0.000015
2021-07-24 07:06:42,587 ----------------------------------------------------------------------------------------------------
2021-07-24 07:06:42,587 EPOCH 29 done: loss 0.0649 - lr 0.0000150
2021-07-24 07:06:48,873 DEV : loss 0.05430661514401436 - score 0.9887
Epoch    29: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 07:06:48,945 BAD EPOCHS (no improvement): 4
2021-07-24 07:06:48,945 ----------------------------------------------------------------------------------------------------
2021-07-24 07:06:57,952 epoch 30 - iter 39/393 - loss 0.05571900 - samples/sec: 138.61 - lr: 0.000008
2021-07-24 07:07:07,113 epoch 30 - iter 78/393 - loss 0.05691961 - samples/sec: 136.26 - lr: 0.000008
2021-07-24 07:07:16,353 epoch 30 - iter 117/393 - loss 0.06376801 - samples/sec: 135.10 - lr: 0.000008
2021-07-24 07:07:25,630 epoch 30 - iter 156/393 - loss 0.06303678 - samples/sec: 134.55 - lr: 0.000008
2021-07-24 07:07:34,700 epoch 30 - iter 195/393 - loss 0.06500852 - samples/sec: 137.62 - lr: 0.000008
2021-07-24 07:07:43,881 epoch 30 - iter 234/393 - loss 0.06544421 - samples/sec: 135.97 - lr: 0.000008
2021-07-24 07:07:53,111 epoch 30 - iter 273/393 - loss 0.06432496 - samples/sec: 135.23 - lr: 0.000008
2021-07-24 07:08:02,336 epoch 30 - iter 312/393 - loss 0.06258141 - samples/sec: 135.31 - lr: 0.000008
2021-07-24 07:08:11,767 epoch 30 - iter 351/393 - loss 0.06395402 - samples/sec: 132.36 - lr: 0.000008
2021-07-24 07:08:21,115 epoch 30 - iter 390/393 - loss 0.06478534 - samples/sec: 133.53 - lr: 0.000008
2021-07-24 07:08:21,731 ----------------------------------------------------------------------------------------------------
2021-07-24 07:08:21,731 EPOCH 30 done: loss 0.0645 - lr 0.0000075
2021-07-24 07:08:28,024 DEV : loss 0.05410824716091156 - score 0.9884
2021-07-24 07:08:28,096 BAD EPOCHS (no improvement): 1
2021-07-24 07:08:28,096 ----------------------------------------------------------------------------------------------------
2021-07-24 07:08:37,882 epoch 31 - iter 39/393 - loss 0.07357874 - samples/sec: 127.59 - lr: 0.000008
2021-07-24 07:08:47,084 epoch 31 - iter 78/393 - loss 0.06955563 - samples/sec: 135.65 - lr: 0.000008
2021-07-24 07:08:56,456 epoch 31 - iter 117/393 - loss 0.06612356 - samples/sec: 133.19 - lr: 0.000008
2021-07-24 07:09:05,771 epoch 31 - iter 156/393 - loss 0.06535327 - samples/sec: 134.01 - lr: 0.000008
2021-07-24 07:09:14,941 epoch 31 - iter 195/393 - loss 0.06154820 - samples/sec: 136.14 - lr: 0.000008
2021-07-24 07:09:24,197 epoch 31 - iter 234/393 - loss 0.06188220 - samples/sec: 134.85 - lr: 0.000008
2021-07-24 07:09:33,397 epoch 31 - iter 273/393 - loss 0.06133186 - samples/sec: 135.68 - lr: 0.000008
2021-07-24 07:09:42,571 epoch 31 - iter 312/393 - loss 0.06047635 - samples/sec: 136.07 - lr: 0.000008
2021-07-24 07:09:51,757 epoch 31 - iter 351/393 - loss 0.06213022 - samples/sec: 135.90 - lr: 0.000008
2021-07-24 07:10:00,804 epoch 31 - iter 390/393 - loss 0.06132542 - samples/sec: 137.98 - lr: 0.000008
2021-07-24 07:10:01,380 ----------------------------------------------------------------------------------------------------
2021-07-24 07:10:01,380 EPOCH 31 done: loss 0.0610 - lr 0.0000075
2021-07-24 07:10:07,690 DEV : loss 0.05394771322607994 - score 0.9892
2021-07-24 07:10:07,761 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:10:09,876 ----------------------------------------------------------------------------------------------------
2021-07-24 07:10:19,112 epoch 32 - iter 39/393 - loss 0.06237924 - samples/sec: 135.19 - lr: 0.000008
2021-07-24 07:10:28,465 epoch 32 - iter 78/393 - loss 0.05778487 - samples/sec: 133.46 - lr: 0.000008
2021-07-24 07:10:37,741 epoch 32 - iter 117/393 - loss 0.05754808 - samples/sec: 134.57 - lr: 0.000008
2021-07-24 07:10:46,970 epoch 32 - iter 156/393 - loss 0.05762206 - samples/sec: 135.26 - lr: 0.000008
2021-07-24 07:10:56,172 epoch 32 - iter 195/393 - loss 0.06256416 - samples/sec: 135.64 - lr: 0.000008
2021-07-24 07:11:05,256 epoch 32 - iter 234/393 - loss 0.06086727 - samples/sec: 137.42 - lr: 0.000008
2021-07-24 07:11:14,475 epoch 32 - iter 273/393 - loss 0.06138429 - samples/sec: 135.40 - lr: 0.000008
2021-07-24 07:11:23,530 epoch 32 - iter 312/393 - loss 0.06027731 - samples/sec: 137.86 - lr: 0.000008
2021-07-24 07:11:32,780 epoch 32 - iter 351/393 - loss 0.05986427 - samples/sec: 134.95 - lr: 0.000008
2021-07-24 07:11:42,019 epoch 32 - iter 390/393 - loss 0.05981306 - samples/sec: 135.11 - lr: 0.000008
2021-07-24 07:11:42,627 ----------------------------------------------------------------------------------------------------
2021-07-24 07:11:42,627 EPOCH 32 done: loss 0.0598 - lr 0.0000075
2021-07-24 07:11:48,930 DEV : loss 0.05504925549030304 - score 0.9884
2021-07-24 07:11:49,002 BAD EPOCHS (no improvement): 1
2021-07-24 07:11:49,002 ----------------------------------------------------------------------------------------------------
2021-07-24 07:11:58,204 epoch 33 - iter 39/393 - loss 0.05980431 - samples/sec: 135.67 - lr: 0.000008
2021-07-24 07:12:07,534 epoch 33 - iter 78/393 - loss 0.06072530 - samples/sec: 133.80 - lr: 0.000008
2021-07-24 07:12:16,896 epoch 33 - iter 117/393 - loss 0.06128279 - samples/sec: 133.33 - lr: 0.000008
2021-07-24 07:12:25,978 epoch 33 - iter 156/393 - loss 0.06236205 - samples/sec: 137.44 - lr: 0.000008
2021-07-24 07:12:35,161 epoch 33 - iter 195/393 - loss 0.06334759 - samples/sec: 135.94 - lr: 0.000008
2021-07-24 07:12:44,271 epoch 33 - iter 234/393 - loss 0.06506372 - samples/sec: 137.02 - lr: 0.000008
2021-07-24 07:12:53,487 epoch 33 - iter 273/393 - loss 0.06447162 - samples/sec: 135.44 - lr: 0.000008
2021-07-24 07:13:02,750 epoch 33 - iter 312/393 - loss 0.06517067 - samples/sec: 134.76 - lr: 0.000008
2021-07-24 07:13:11,905 epoch 33 - iter 351/393 - loss 0.06527706 - samples/sec: 136.35 - lr: 0.000008
2021-07-24 07:13:21,141 epoch 33 - iter 390/393 - loss 0.06432320 - samples/sec: 135.15 - lr: 0.000008
2021-07-24 07:13:21,718 ----------------------------------------------------------------------------------------------------
2021-07-24 07:13:21,718 EPOCH 33 done: loss 0.0651 - lr 0.0000075
2021-07-24 07:13:28,025 DEV : loss 0.05472477898001671 - score 0.9887
2021-07-24 07:13:28,097 BAD EPOCHS (no improvement): 2
2021-07-24 07:13:28,097 ----------------------------------------------------------------------------------------------------
2021-07-24 07:13:37,327 epoch 34 - iter 39/393 - loss 0.06406453 - samples/sec: 135.26 - lr: 0.000008
2021-07-24 07:13:46,508 epoch 34 - iter 78/393 - loss 0.06512548 - samples/sec: 135.96 - lr: 0.000008
2021-07-24 07:13:55,925 epoch 34 - iter 117/393 - loss 0.06344768 - samples/sec: 132.55 - lr: 0.000008
2021-07-24 07:14:04,856 epoch 34 - iter 156/393 - loss 0.05980912 - samples/sec: 139.78 - lr: 0.000008
2021-07-24 07:14:14,008 epoch 34 - iter 195/393 - loss 0.06090442 - samples/sec: 136.38 - lr: 0.000008
2021-07-24 07:14:23,296 epoch 34 - iter 234/393 - loss 0.06141098 - samples/sec: 134.40 - lr: 0.000008
2021-07-24 07:14:32,341 epoch 34 - iter 273/393 - loss 0.06088195 - samples/sec: 138.00 - lr: 0.000008
2021-07-24 07:14:41,468 epoch 34 - iter 312/393 - loss 0.06189917 - samples/sec: 136.77 - lr: 0.000008
2021-07-24 07:14:50,811 epoch 34 - iter 351/393 - loss 0.06231553 - samples/sec: 133.61 - lr: 0.000008
2021-07-24 07:15:00,247 epoch 34 - iter 390/393 - loss 0.06286583 - samples/sec: 132.28 - lr: 0.000008
2021-07-24 07:15:00,842 ----------------------------------------------------------------------------------------------------
2021-07-24 07:15:00,842 EPOCH 34 done: loss 0.0632 - lr 0.0000075
2021-07-24 07:15:07,168 DEV : loss 0.05502578616142273 - score 0.9881
2021-07-24 07:15:07,240 BAD EPOCHS (no improvement): 3
2021-07-24 07:15:07,240 ----------------------------------------------------------------------------------------------------
2021-07-24 07:15:17,196 epoch 35 - iter 39/393 - loss 0.06778309 - samples/sec: 125.40 - lr: 0.000008
2021-07-24 07:15:26,453 epoch 35 - iter 78/393 - loss 0.06894644 - samples/sec: 134.85 - lr: 0.000008
2021-07-24 07:15:35,564 epoch 35 - iter 117/393 - loss 0.06865548 - samples/sec: 137.00 - lr: 0.000008
2021-07-24 07:15:45,099 epoch 35 - iter 156/393 - loss 0.06912433 - samples/sec: 130.92 - lr: 0.000008
2021-07-24 07:15:54,095 epoch 35 - iter 195/393 - loss 0.06919689 - samples/sec: 138.75 - lr: 0.000008
2021-07-24 07:16:03,238 epoch 35 - iter 234/393 - loss 0.06679023 - samples/sec: 136.53 - lr: 0.000008
2021-07-24 07:16:12,327 epoch 35 - iter 273/393 - loss 0.06798513 - samples/sec: 137.33 - lr: 0.000008
2021-07-24 07:16:21,501 epoch 35 - iter 312/393 - loss 0.06731719 - samples/sec: 136.08 - lr: 0.000008
2021-07-24 07:16:30,531 epoch 35 - iter 351/393 - loss 0.06658697 - samples/sec: 138.23 - lr: 0.000008
2021-07-24 07:16:39,735 epoch 35 - iter 390/393 - loss 0.06652408 - samples/sec: 135.63 - lr: 0.000008
2021-07-24 07:16:40,310 ----------------------------------------------------------------------------------------------------
2021-07-24 07:16:40,310 EPOCH 35 done: loss 0.0664 - lr 0.0000075
2021-07-24 07:16:46,587 DEV : loss 0.05558687075972557 - score 0.9884
Epoch    35: reducing learning rate of group 0 to 3.7500e-06.
2021-07-24 07:16:46,660 BAD EPOCHS (no improvement): 4
2021-07-24 07:16:46,660 ----------------------------------------------------------------------------------------------------
2021-07-24 07:16:55,991 epoch 36 - iter 39/393 - loss 0.07358709 - samples/sec: 133.80 - lr: 0.000004
2021-07-24 07:17:04,895 epoch 36 - iter 78/393 - loss 0.07205385 - samples/sec: 140.20 - lr: 0.000004
2021-07-24 07:17:14,061 epoch 36 - iter 117/393 - loss 0.06513661 - samples/sec: 136.19 - lr: 0.000004
2021-07-24 07:17:23,380 epoch 36 - iter 156/393 - loss 0.06214628 - samples/sec: 133.94 - lr: 0.000004
2021-07-24 07:17:32,759 epoch 36 - iter 195/393 - loss 0.06058320 - samples/sec: 133.10 - lr: 0.000004
2021-07-24 07:17:41,793 epoch 36 - iter 234/393 - loss 0.06161412 - samples/sec: 138.18 - lr: 0.000004
2021-07-24 07:17:51,020 epoch 36 - iter 273/393 - loss 0.06171659 - samples/sec: 135.28 - lr: 0.000004
2021-07-24 07:18:00,361 epoch 36 - iter 312/393 - loss 0.06210058 - samples/sec: 133.64 - lr: 0.000004
2021-07-24 07:18:09,555 epoch 36 - iter 351/393 - loss 0.06219623 - samples/sec: 135.76 - lr: 0.000004
2021-07-24 07:18:18,560 epoch 36 - iter 390/393 - loss 0.06231858 - samples/sec: 138.63 - lr: 0.000004
2021-07-24 07:18:19,136 ----------------------------------------------------------------------------------------------------
2021-07-24 07:18:19,136 EPOCH 36 done: loss 0.0632 - lr 0.0000038
2021-07-24 07:18:25,400 DEV : loss 0.05472750589251518 - score 0.9887
2021-07-24 07:18:25,472 BAD EPOCHS (no improvement): 1
2021-07-24 07:18:25,472 ----------------------------------------------------------------------------------------------------
2021-07-24 07:18:34,576 epoch 37 - iter 39/393 - loss 0.05960399 - samples/sec: 137.15 - lr: 0.000004
2021-07-24 07:18:43,830 epoch 37 - iter 78/393 - loss 0.05796595 - samples/sec: 134.89 - lr: 0.000004
2021-07-24 07:18:53,084 epoch 37 - iter 117/393 - loss 0.06060380 - samples/sec: 134.90 - lr: 0.000004
2021-07-24 07:19:02,348 epoch 37 - iter 156/393 - loss 0.06019228 - samples/sec: 134.75 - lr: 0.000004
2021-07-24 07:19:11,493 epoch 37 - iter 195/393 - loss 0.05972408 - samples/sec: 136.50 - lr: 0.000004
2021-07-24 07:19:20,516 epoch 37 - iter 234/393 - loss 0.06308748 - samples/sec: 138.34 - lr: 0.000004
2021-07-24 07:19:29,737 epoch 37 - iter 273/393 - loss 0.06164218 - samples/sec: 135.37 - lr: 0.000004
2021-07-24 07:19:38,632 epoch 37 - iter 312/393 - loss 0.06042091 - samples/sec: 140.34 - lr: 0.000004
2021-07-24 07:19:47,885 epoch 37 - iter 351/393 - loss 0.06138840 - samples/sec: 134.90 - lr: 0.000004
2021-07-24 07:19:57,076 epoch 37 - iter 390/393 - loss 0.06253268 - samples/sec: 135.81 - lr: 0.000004
2021-07-24 07:19:57,619 ----------------------------------------------------------------------------------------------------
2021-07-24 07:19:57,619 EPOCH 37 done: loss 0.0623 - lr 0.0000038
2021-07-24 07:20:03,892 DEV : loss 0.05422234907746315 - score 0.9884
2021-07-24 07:20:03,965 BAD EPOCHS (no improvement): 2
2021-07-24 07:20:03,965 ----------------------------------------------------------------------------------------------------
2021-07-24 07:20:13,027 epoch 38 - iter 39/393 - loss 0.06555105 - samples/sec: 137.77 - lr: 0.000004
2021-07-24 07:20:21,987 epoch 38 - iter 78/393 - loss 0.06569654 - samples/sec: 139.32 - lr: 0.000004
2021-07-24 07:20:31,107 epoch 38 - iter 117/393 - loss 0.07175483 - samples/sec: 136.87 - lr: 0.000004
2021-07-24 07:20:40,207 epoch 38 - iter 156/393 - loss 0.06962505 - samples/sec: 137.17 - lr: 0.000004
2021-07-24 07:20:49,391 epoch 38 - iter 195/393 - loss 0.06598968 - samples/sec: 135.93 - lr: 0.000004
2021-07-24 07:20:58,510 epoch 38 - iter 234/393 - loss 0.06556706 - samples/sec: 136.89 - lr: 0.000004
2021-07-24 07:21:07,914 epoch 38 - iter 273/393 - loss 0.06361456 - samples/sec: 132.74 - lr: 0.000004
2021-07-24 07:21:17,288 epoch 38 - iter 312/393 - loss 0.06559481 - samples/sec: 133.16 - lr: 0.000004
2021-07-24 07:21:26,492 epoch 38 - iter 351/393 - loss 0.06366731 - samples/sec: 135.62 - lr: 0.000004
2021-07-24 07:21:35,727 epoch 38 - iter 390/393 - loss 0.06309238 - samples/sec: 135.18 - lr: 0.000004
2021-07-24 07:21:36,372 ----------------------------------------------------------------------------------------------------
2021-07-24 07:21:36,372 EPOCH 38 done: loss 0.0635 - lr 0.0000038
2021-07-24 07:21:43,149 DEV : loss 0.05447733402252197 - score 0.9887
2021-07-24 07:21:43,222 BAD EPOCHS (no improvement): 3
2021-07-24 07:21:43,222 ----------------------------------------------------------------------------------------------------
2021-07-24 07:21:52,360 epoch 39 - iter 39/393 - loss 0.06472684 - samples/sec: 136.63 - lr: 0.000004
2021-07-24 07:22:01,557 epoch 39 - iter 78/393 - loss 0.05631468 - samples/sec: 135.72 - lr: 0.000004
2021-07-24 07:22:10,765 epoch 39 - iter 117/393 - loss 0.05616078 - samples/sec: 135.57 - lr: 0.000004
2021-07-24 07:22:20,072 epoch 39 - iter 156/393 - loss 0.05509138 - samples/sec: 134.12 - lr: 0.000004
2021-07-24 07:22:29,554 epoch 39 - iter 195/393 - loss 0.05808279 - samples/sec: 131.64 - lr: 0.000004
2021-07-24 07:22:38,632 epoch 39 - iter 234/393 - loss 0.05955528 - samples/sec: 137.51 - lr: 0.000004
2021-07-24 07:22:47,896 epoch 39 - iter 273/393 - loss 0.06038292 - samples/sec: 134.75 - lr: 0.000004
2021-07-24 07:22:57,018 epoch 39 - iter 312/393 - loss 0.06089657 - samples/sec: 136.83 - lr: 0.000004
2021-07-24 07:23:06,205 epoch 39 - iter 351/393 - loss 0.06138391 - samples/sec: 135.88 - lr: 0.000004
2021-07-24 07:23:15,659 epoch 39 - iter 390/393 - loss 0.06114497 - samples/sec: 132.02 - lr: 0.000004
2021-07-24 07:23:16,262 ----------------------------------------------------------------------------------------------------
2021-07-24 07:23:16,262 EPOCH 39 done: loss 0.0610 - lr 0.0000038
2021-07-24 07:23:22,548 DEV : loss 0.05469973385334015 - score 0.9887
Epoch    39: reducing learning rate of group 0 to 1.8750e-06.
2021-07-24 07:23:22,620 BAD EPOCHS (no improvement): 4
2021-07-24 07:23:22,621 ----------------------------------------------------------------------------------------------------
2021-07-24 07:23:22,621 ----------------------------------------------------------------------------------------------------
2021-07-24 07:23:22,621 learning rate too small - quitting training!
2021-07-24 07:23:22,621 ----------------------------------------------------------------------------------------------------
2021-07-24 07:23:23,200 ----------------------------------------------------------------------------------------------------
2021-07-24 07:23:23,201 Testing using best model ...
2021-07-24 07:23:23,202 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.rst.gum/best-model.pt
2021-07-24 07:24:20,175 0.9851	0.9854	0.9852
2021-07-24 07:24:20,175 
Results:
- F1-score (micro) 0.9852
- F1-score (macro) 0.9866

By class:
SENT       tp: 1690 - fp: 47 - fn: 46 - precision: 0.9729 - recall: 0.9735 - f1-score: 0.9732
X          tp: 1411 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-24 07:24:20,175 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/nld.rst.nldt/
2021-07-24 07:24:20,229 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/nld.rst.nldt
2021-07-24 07:24:20,232 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/nld.rst.nldt/sent_train.txt
2021-07-24 07:24:20,234 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/nld.rst.nldt/sent_dev.txt
2021-07-24 07:24:20,235 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/nld.rst.nldt/sent_test.txt
Corpus: 2096 train + 599 dev + 701 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-24 07:24:23,939 ----------------------------------------------------------------------------------------------------
2021-07-24 07:24:23,940 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30073, 768, padding_idx=3)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-24 07:24:23,941 ----------------------------------------------------------------------------------------------------
2021-07-24 07:24:23,941 Corpus: "Corpus: 2096 train + 599 dev + 701 test sentences"
2021-07-24 07:24:23,941 ----------------------------------------------------------------------------------------------------
2021-07-24 07:24:23,941 Parameters:
2021-07-24 07:24:23,941  - learning_rate: "3e-05"
2021-07-24 07:24:23,941  - mini_batch_size: "32"
2021-07-24 07:24:23,941  - patience: "3"
2021-07-24 07:24:23,941  - anneal_factor: "0.5"
2021-07-24 07:24:23,941  - max_epochs: "40"
2021-07-24 07:24:23,941  - shuffle: "True"
2021-07-24 07:24:23,941  - train_with_dev: "False"
2021-07-24 07:24:23,941  - batch_growth_annealing: "False"
2021-07-24 07:24:23,941 ----------------------------------------------------------------------------------------------------
2021-07-24 07:24:23,941 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/nld.rst.nldt"
2021-07-24 07:24:23,941 ----------------------------------------------------------------------------------------------------
2021-07-24 07:24:23,941 Device: cuda:0
2021-07-24 07:24:23,941 ----------------------------------------------------------------------------------------------------
2021-07-24 07:24:23,941 Embeddings storage mode: cpu
2021-07-24 07:24:23,944 ----------------------------------------------------------------------------------------------------
2021-07-24 07:24:27,296 epoch 1 - iter 6/66 - loss 12.58813063 - samples/sec: 57.30 - lr: 0.000030
2021-07-24 07:24:30,616 epoch 1 - iter 12/66 - loss 12.13700175 - samples/sec: 57.83 - lr: 0.000030
2021-07-24 07:24:34,001 epoch 1 - iter 18/66 - loss 11.82693116 - samples/sec: 56.73 - lr: 0.000030
2021-07-24 07:24:37,436 epoch 1 - iter 24/66 - loss 11.45987626 - samples/sec: 55.90 - lr: 0.000030
2021-07-24 07:24:40,916 epoch 1 - iter 30/66 - loss 11.11029692 - samples/sec: 55.18 - lr: 0.000030
2021-07-24 07:24:44,387 epoch 1 - iter 36/66 - loss 10.76970034 - samples/sec: 55.32 - lr: 0.000030
2021-07-24 07:24:47,819 epoch 1 - iter 42/66 - loss 10.39029266 - samples/sec: 55.95 - lr: 0.000030
2021-07-24 07:24:51,144 epoch 1 - iter 48/66 - loss 10.11427720 - samples/sec: 57.76 - lr: 0.000030
2021-07-24 07:24:54,480 epoch 1 - iter 54/66 - loss 9.82781077 - samples/sec: 57.57 - lr: 0.000030
2021-07-24 07:24:57,797 epoch 1 - iter 60/66 - loss 9.58200802 - samples/sec: 57.89 - lr: 0.000030
2021-07-24 07:25:00,871 epoch 1 - iter 66/66 - loss 9.32214996 - samples/sec: 62.46 - lr: 0.000030
2021-07-24 07:25:00,872 ----------------------------------------------------------------------------------------------------
2021-07-24 07:25:00,872 EPOCH 1 done: loss 9.3221 - lr 0.0000300
2021-07-24 07:25:08,488 DEV : loss 4.837391376495361 - score 0.0
2021-07-24 07:25:08,504 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:25:09,075 ----------------------------------------------------------------------------------------------------
2021-07-24 07:25:10,464 epoch 2 - iter 6/66 - loss 6.32647991 - samples/sec: 138.35 - lr: 0.000030
2021-07-24 07:25:11,874 epoch 2 - iter 12/66 - loss 6.13825802 - samples/sec: 136.26 - lr: 0.000030
2021-07-24 07:25:13,292 epoch 2 - iter 18/66 - loss 6.05156522 - samples/sec: 135.41 - lr: 0.000030
2021-07-24 07:25:14,651 epoch 2 - iter 24/66 - loss 5.87291956 - samples/sec: 141.33 - lr: 0.000030
2021-07-24 07:25:15,972 epoch 2 - iter 30/66 - loss 5.59133393 - samples/sec: 145.43 - lr: 0.000030
2021-07-24 07:25:17,325 epoch 2 - iter 36/66 - loss 5.37847085 - samples/sec: 141.99 - lr: 0.000030
2021-07-24 07:25:18,637 epoch 2 - iter 42/66 - loss 5.14589516 - samples/sec: 146.42 - lr: 0.000030
2021-07-24 07:25:19,987 epoch 2 - iter 48/66 - loss 5.01102843 - samples/sec: 142.20 - lr: 0.000030
2021-07-24 07:25:21,407 epoch 2 - iter 54/66 - loss 4.85051246 - samples/sec: 135.25 - lr: 0.000030
2021-07-24 07:25:22,795 epoch 2 - iter 60/66 - loss 4.65671527 - samples/sec: 138.41 - lr: 0.000030
2021-07-24 07:25:24,054 epoch 2 - iter 66/66 - loss 4.49546410 - samples/sec: 152.60 - lr: 0.000030
2021-07-24 07:25:24,055 ----------------------------------------------------------------------------------------------------
2021-07-24 07:25:24,055 EPOCH 2 done: loss 4.4955 - lr 0.0000300
2021-07-24 07:25:25,554 DEV : loss 2.321929454803467 - score 0.0
2021-07-24 07:25:25,569 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:25:28,027 ----------------------------------------------------------------------------------------------------
2021-07-24 07:25:29,449 epoch 3 - iter 6/66 - loss 2.89717877 - samples/sec: 135.29 - lr: 0.000030
2021-07-24 07:25:30,780 epoch 3 - iter 12/66 - loss 2.60895369 - samples/sec: 144.27 - lr: 0.000030
2021-07-24 07:25:32,181 epoch 3 - iter 18/66 - loss 2.51906963 - samples/sec: 137.11 - lr: 0.000030
2021-07-24 07:25:33,564 epoch 3 - iter 24/66 - loss 2.44565423 - samples/sec: 138.87 - lr: 0.000030
2021-07-24 07:25:34,928 epoch 3 - iter 30/66 - loss 2.37242457 - samples/sec: 140.84 - lr: 0.000030
2021-07-24 07:25:36,247 epoch 3 - iter 36/66 - loss 2.30191185 - samples/sec: 145.54 - lr: 0.000030
2021-07-24 07:25:37,635 epoch 3 - iter 42/66 - loss 2.27424407 - samples/sec: 138.42 - lr: 0.000030
2021-07-24 07:25:38,973 epoch 3 - iter 48/66 - loss 2.21228669 - samples/sec: 143.57 - lr: 0.000030
2021-07-24 07:25:40,299 epoch 3 - iter 54/66 - loss 2.14799943 - samples/sec: 144.87 - lr: 0.000030
2021-07-24 07:25:41,733 epoch 3 - iter 60/66 - loss 2.09922425 - samples/sec: 133.94 - lr: 0.000030
2021-07-24 07:25:42,995 epoch 3 - iter 66/66 - loss 2.04579201 - samples/sec: 152.12 - lr: 0.000030
2021-07-24 07:25:42,996 ----------------------------------------------------------------------------------------------------
2021-07-24 07:25:42,996 EPOCH 3 done: loss 2.0458 - lr 0.0000300
2021-07-24 07:25:44,378 DEV : loss 1.1147778034210205 - score 0.5984
2021-07-24 07:25:44,402 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:25:46,703 ----------------------------------------------------------------------------------------------------
2021-07-24 07:25:48,135 epoch 4 - iter 6/66 - loss 1.44623975 - samples/sec: 134.28 - lr: 0.000030
2021-07-24 07:25:49,470 epoch 4 - iter 12/66 - loss 1.34336747 - samples/sec: 143.88 - lr: 0.000030
2021-07-24 07:25:50,788 epoch 4 - iter 18/66 - loss 1.33016602 - samples/sec: 145.73 - lr: 0.000030
2021-07-24 07:25:52,095 epoch 4 - iter 24/66 - loss 1.27700916 - samples/sec: 146.99 - lr: 0.000030
2021-07-24 07:25:53,437 epoch 4 - iter 30/66 - loss 1.25362782 - samples/sec: 143.14 - lr: 0.000030
2021-07-24 07:25:54,828 epoch 4 - iter 36/66 - loss 1.23948166 - samples/sec: 138.04 - lr: 0.000030
2021-07-24 07:25:56,243 epoch 4 - iter 42/66 - loss 1.20949222 - samples/sec: 135.71 - lr: 0.000030
2021-07-24 07:25:57,596 epoch 4 - iter 48/66 - loss 1.17862085 - samples/sec: 141.97 - lr: 0.000030
2021-07-24 07:25:58,997 epoch 4 - iter 54/66 - loss 1.16669345 - samples/sec: 137.14 - lr: 0.000030
2021-07-24 07:26:00,436 epoch 4 - iter 60/66 - loss 1.15712659 - samples/sec: 133.50 - lr: 0.000030
2021-07-24 07:26:01,712 epoch 4 - iter 66/66 - loss 1.13410974 - samples/sec: 150.52 - lr: 0.000030
2021-07-24 07:26:01,713 ----------------------------------------------------------------------------------------------------
2021-07-24 07:26:01,713 EPOCH 4 done: loss 1.1341 - lr 0.0000300
2021-07-24 07:26:03,098 DEV : loss 0.5500179529190063 - score 0.8089
2021-07-24 07:26:03,113 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:26:05,377 ----------------------------------------------------------------------------------------------------
2021-07-24 07:26:06,786 epoch 5 - iter 6/66 - loss 0.90832811 - samples/sec: 136.42 - lr: 0.000030
2021-07-24 07:26:08,086 epoch 5 - iter 12/66 - loss 0.82945128 - samples/sec: 147.76 - lr: 0.000030
2021-07-24 07:26:09,447 epoch 5 - iter 18/66 - loss 0.80594013 - samples/sec: 141.13 - lr: 0.000030
2021-07-24 07:26:10,785 epoch 5 - iter 24/66 - loss 0.81467201 - samples/sec: 143.65 - lr: 0.000030
2021-07-24 07:26:12,199 epoch 5 - iter 30/66 - loss 0.80727605 - samples/sec: 135.83 - lr: 0.000030
2021-07-24 07:26:13,609 epoch 5 - iter 36/66 - loss 0.78581822 - samples/sec: 136.20 - lr: 0.000030
2021-07-24 07:26:14,948 epoch 5 - iter 42/66 - loss 0.77427397 - samples/sec: 143.43 - lr: 0.000030
2021-07-24 07:26:16,275 epoch 5 - iter 48/66 - loss 0.76852598 - samples/sec: 144.76 - lr: 0.000030
2021-07-24 07:26:17,627 epoch 5 - iter 54/66 - loss 0.75767292 - samples/sec: 142.06 - lr: 0.000030
2021-07-24 07:26:18,947 epoch 5 - iter 60/66 - loss 0.73512901 - samples/sec: 145.51 - lr: 0.000030
2021-07-24 07:26:20,291 epoch 5 - iter 66/66 - loss 0.71704259 - samples/sec: 142.89 - lr: 0.000030
2021-07-24 07:26:20,292 ----------------------------------------------------------------------------------------------------
2021-07-24 07:26:20,292 EPOCH 5 done: loss 0.7170 - lr 0.0000300
2021-07-24 07:26:21,686 DEV : loss 0.2981856167316437 - score 0.9383
2021-07-24 07:26:21,701 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:26:23,955 ----------------------------------------------------------------------------------------------------
2021-07-24 07:26:25,395 epoch 6 - iter 6/66 - loss 0.46628859 - samples/sec: 133.59 - lr: 0.000030
2021-07-24 07:26:26,762 epoch 6 - iter 12/66 - loss 0.50333258 - samples/sec: 140.52 - lr: 0.000030
2021-07-24 07:26:28,183 epoch 6 - iter 18/66 - loss 0.53579938 - samples/sec: 135.18 - lr: 0.000030
2021-07-24 07:26:29,491 epoch 6 - iter 24/66 - loss 0.52110200 - samples/sec: 146.81 - lr: 0.000030
2021-07-24 07:26:30,851 epoch 6 - iter 30/66 - loss 0.52182965 - samples/sec: 141.24 - lr: 0.000030
2021-07-24 07:26:32,119 epoch 6 - iter 36/66 - loss 0.51135214 - samples/sec: 151.44 - lr: 0.000030
2021-07-24 07:26:33,447 epoch 6 - iter 42/66 - loss 0.51990094 - samples/sec: 144.67 - lr: 0.000030
2021-07-24 07:26:34,807 epoch 6 - iter 48/66 - loss 0.52100521 - samples/sec: 141.28 - lr: 0.000030
2021-07-24 07:26:36,219 epoch 6 - iter 54/66 - loss 0.52560363 - samples/sec: 136.01 - lr: 0.000030
2021-07-24 07:26:37,555 epoch 6 - iter 60/66 - loss 0.52001951 - samples/sec: 143.72 - lr: 0.000030
2021-07-24 07:26:38,878 epoch 6 - iter 66/66 - loss 0.51438437 - samples/sec: 145.18 - lr: 0.000030
2021-07-24 07:26:38,879 ----------------------------------------------------------------------------------------------------
2021-07-24 07:26:38,879 EPOCH 6 done: loss 0.5144 - lr 0.0000300
2021-07-24 07:26:40,269 DEV : loss 0.20204201340675354 - score 0.9685
2021-07-24 07:26:40,284 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:26:42,480 ----------------------------------------------------------------------------------------------------
2021-07-24 07:26:43,893 epoch 7 - iter 6/66 - loss 0.35183833 - samples/sec: 136.12 - lr: 0.000030
2021-07-24 07:26:45,216 epoch 7 - iter 12/66 - loss 0.40615926 - samples/sec: 145.16 - lr: 0.000030
2021-07-24 07:26:46,555 epoch 7 - iter 18/66 - loss 0.41655182 - samples/sec: 143.44 - lr: 0.000030
2021-07-24 07:26:47,965 epoch 7 - iter 24/66 - loss 0.43173721 - samples/sec: 136.23 - lr: 0.000030
2021-07-24 07:26:49,292 epoch 7 - iter 30/66 - loss 0.44040108 - samples/sec: 144.68 - lr: 0.000030
2021-07-24 07:26:50,715 epoch 7 - iter 36/66 - loss 0.44891585 - samples/sec: 134.99 - lr: 0.000030
2021-07-24 07:26:52,044 epoch 7 - iter 42/66 - loss 0.46103524 - samples/sec: 144.60 - lr: 0.000030
2021-07-24 07:26:53,443 epoch 7 - iter 48/66 - loss 0.44534136 - samples/sec: 137.20 - lr: 0.000030
2021-07-24 07:26:54,712 epoch 7 - iter 54/66 - loss 0.43779456 - samples/sec: 151.37 - lr: 0.000030
2021-07-24 07:26:56,140 epoch 7 - iter 60/66 - loss 0.43280813 - samples/sec: 134.59 - lr: 0.000030
2021-07-24 07:26:57,439 epoch 7 - iter 66/66 - loss 0.42773544 - samples/sec: 147.82 - lr: 0.000030
2021-07-24 07:26:57,440 ----------------------------------------------------------------------------------------------------
2021-07-24 07:26:57,440 EPOCH 7 done: loss 0.4277 - lr 0.0000300
2021-07-24 07:26:58,830 DEV : loss 0.14709515869617462 - score 0.9774
2021-07-24 07:26:58,845 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:27:01,017 ----------------------------------------------------------------------------------------------------
2021-07-24 07:27:02,412 epoch 8 - iter 6/66 - loss 0.38220794 - samples/sec: 137.87 - lr: 0.000030
2021-07-24 07:27:03,818 epoch 8 - iter 12/66 - loss 0.38689667 - samples/sec: 136.64 - lr: 0.000030
2021-07-24 07:27:05,201 epoch 8 - iter 18/66 - loss 0.37716750 - samples/sec: 138.90 - lr: 0.000030
2021-07-24 07:27:06,480 epoch 8 - iter 24/66 - loss 0.35255644 - samples/sec: 150.14 - lr: 0.000030
2021-07-24 07:27:07,880 epoch 8 - iter 30/66 - loss 0.35001474 - samples/sec: 137.15 - lr: 0.000030
2021-07-24 07:27:09,225 epoch 8 - iter 36/66 - loss 0.33988818 - samples/sec: 142.89 - lr: 0.000030
2021-07-24 07:27:10,629 epoch 8 - iter 42/66 - loss 0.35185375 - samples/sec: 136.78 - lr: 0.000030
2021-07-24 07:27:11,978 epoch 8 - iter 48/66 - loss 0.35735904 - samples/sec: 142.33 - lr: 0.000030
2021-07-24 07:27:13,374 epoch 8 - iter 54/66 - loss 0.35191866 - samples/sec: 137.64 - lr: 0.000030
2021-07-24 07:27:14,720 epoch 8 - iter 60/66 - loss 0.35615811 - samples/sec: 142.71 - lr: 0.000030
2021-07-24 07:27:15,969 epoch 8 - iter 66/66 - loss 0.34946033 - samples/sec: 153.74 - lr: 0.000030
2021-07-24 07:27:15,970 ----------------------------------------------------------------------------------------------------
2021-07-24 07:27:15,970 EPOCH 8 done: loss 0.3495 - lr 0.0000300
2021-07-24 07:27:17,476 DEV : loss 0.12483128905296326 - score 0.9752
2021-07-24 07:27:17,491 BAD EPOCHS (no improvement): 1
2021-07-24 07:27:17,491 ----------------------------------------------------------------------------------------------------
2021-07-24 07:27:18,917 epoch 9 - iter 6/66 - loss 0.32314009 - samples/sec: 134.79 - lr: 0.000030
2021-07-24 07:27:20,262 epoch 9 - iter 12/66 - loss 0.32642707 - samples/sec: 142.84 - lr: 0.000030
2021-07-24 07:27:21,716 epoch 9 - iter 18/66 - loss 0.34817531 - samples/sec: 132.11 - lr: 0.000030
2021-07-24 07:27:23,043 epoch 9 - iter 24/66 - loss 0.33440294 - samples/sec: 144.77 - lr: 0.000030
2021-07-24 07:27:24,424 epoch 9 - iter 30/66 - loss 0.32643100 - samples/sec: 139.07 - lr: 0.000030
2021-07-24 07:27:25,777 epoch 9 - iter 36/66 - loss 0.32488602 - samples/sec: 141.99 - lr: 0.000030
2021-07-24 07:27:27,161 epoch 9 - iter 42/66 - loss 0.32737351 - samples/sec: 138.75 - lr: 0.000030
2021-07-24 07:27:28,517 epoch 9 - iter 48/66 - loss 0.33024304 - samples/sec: 141.69 - lr: 0.000030
2021-07-24 07:27:29,861 epoch 9 - iter 54/66 - loss 0.32556553 - samples/sec: 142.93 - lr: 0.000030
2021-07-24 07:27:31,257 epoch 9 - iter 60/66 - loss 0.33322518 - samples/sec: 137.55 - lr: 0.000030
2021-07-24 07:27:32,479 epoch 9 - iter 66/66 - loss 0.33322519 - samples/sec: 157.15 - lr: 0.000030
2021-07-24 07:27:32,480 ----------------------------------------------------------------------------------------------------
2021-07-24 07:27:32,480 EPOCH 9 done: loss 0.3332 - lr 0.0000300
2021-07-24 07:27:33,864 DEV : loss 0.11468800902366638 - score 0.9764
2021-07-24 07:27:33,880 BAD EPOCHS (no improvement): 2
2021-07-24 07:27:33,880 ----------------------------------------------------------------------------------------------------
2021-07-24 07:27:35,292 epoch 10 - iter 6/66 - loss 0.30927559 - samples/sec: 136.12 - lr: 0.000030
2021-07-24 07:27:36,664 epoch 10 - iter 12/66 - loss 0.30050597 - samples/sec: 139.97 - lr: 0.000030
2021-07-24 07:27:38,045 epoch 10 - iter 18/66 - loss 0.30366271 - samples/sec: 139.13 - lr: 0.000030
2021-07-24 07:27:39,461 epoch 10 - iter 24/66 - loss 0.30101368 - samples/sec: 135.63 - lr: 0.000030
2021-07-24 07:27:40,877 epoch 10 - iter 30/66 - loss 0.31474380 - samples/sec: 135.65 - lr: 0.000030
2021-07-24 07:27:42,252 epoch 10 - iter 36/66 - loss 0.31650623 - samples/sec: 139.69 - lr: 0.000030
2021-07-24 07:27:43,684 epoch 10 - iter 42/66 - loss 0.31448384 - samples/sec: 134.14 - lr: 0.000030
2021-07-24 07:27:44,991 epoch 10 - iter 48/66 - loss 0.31985101 - samples/sec: 146.91 - lr: 0.000030
2021-07-24 07:27:46,367 epoch 10 - iter 54/66 - loss 0.32068095 - samples/sec: 139.59 - lr: 0.000030
2021-07-24 07:27:47,676 epoch 10 - iter 60/66 - loss 0.31442946 - samples/sec: 146.71 - lr: 0.000030
2021-07-24 07:27:48,894 epoch 10 - iter 66/66 - loss 0.30986940 - samples/sec: 157.73 - lr: 0.000030
2021-07-24 07:27:48,895 ----------------------------------------------------------------------------------------------------
2021-07-24 07:27:48,895 EPOCH 10 done: loss 0.3099 - lr 0.0000300
2021-07-24 07:27:50,279 DEV : loss 0.10058687627315521 - score 0.9796
2021-07-24 07:27:50,295 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:27:52,536 ----------------------------------------------------------------------------------------------------
2021-07-24 07:27:53,963 epoch 11 - iter 6/66 - loss 0.29910289 - samples/sec: 134.73 - lr: 0.000030
2021-07-24 07:27:55,360 epoch 11 - iter 12/66 - loss 0.33002999 - samples/sec: 137.46 - lr: 0.000030
2021-07-24 07:27:56,721 epoch 11 - iter 18/66 - loss 0.32116757 - samples/sec: 141.13 - lr: 0.000030
2021-07-24 07:27:58,063 epoch 11 - iter 24/66 - loss 0.31907952 - samples/sec: 143.13 - lr: 0.000030
2021-07-24 07:27:59,483 epoch 11 - iter 30/66 - loss 0.30762067 - samples/sec: 135.31 - lr: 0.000030
2021-07-24 07:28:00,863 epoch 11 - iter 36/66 - loss 0.30122445 - samples/sec: 139.16 - lr: 0.000030
2021-07-24 07:28:02,205 epoch 11 - iter 42/66 - loss 0.30900391 - samples/sec: 143.17 - lr: 0.000030
2021-07-24 07:28:03,580 epoch 11 - iter 48/66 - loss 0.30816037 - samples/sec: 139.64 - lr: 0.000030
2021-07-24 07:28:04,972 epoch 11 - iter 54/66 - loss 0.30452866 - samples/sec: 137.99 - lr: 0.000030
2021-07-24 07:28:06,323 epoch 11 - iter 60/66 - loss 0.30060668 - samples/sec: 142.12 - lr: 0.000030
2021-07-24 07:28:07,558 epoch 11 - iter 66/66 - loss 0.29350548 - samples/sec: 155.59 - lr: 0.000030
2021-07-24 07:28:07,559 ----------------------------------------------------------------------------------------------------
2021-07-24 07:28:07,559 EPOCH 11 done: loss 0.2935 - lr 0.0000300
2021-07-24 07:28:08,944 DEV : loss 0.09461119771003723 - score 0.9808
2021-07-24 07:28:08,960 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:28:11,408 ----------------------------------------------------------------------------------------------------
2021-07-24 07:28:12,784 epoch 12 - iter 6/66 - loss 0.28677814 - samples/sec: 139.70 - lr: 0.000030
2021-07-24 07:28:14,092 epoch 12 - iter 12/66 - loss 0.31739839 - samples/sec: 146.84 - lr: 0.000030
2021-07-24 07:28:15,459 epoch 12 - iter 18/66 - loss 0.31699650 - samples/sec: 140.53 - lr: 0.000030
2021-07-24 07:28:16,899 epoch 12 - iter 24/66 - loss 0.31015686 - samples/sec: 133.38 - lr: 0.000030
2021-07-24 07:28:18,285 epoch 12 - iter 30/66 - loss 0.29658055 - samples/sec: 138.60 - lr: 0.000030
2021-07-24 07:28:19,575 epoch 12 - iter 36/66 - loss 0.27548719 - samples/sec: 148.94 - lr: 0.000030
2021-07-24 07:28:20,922 epoch 12 - iter 42/66 - loss 0.27412144 - samples/sec: 142.51 - lr: 0.000030
2021-07-24 07:28:22,259 epoch 12 - iter 48/66 - loss 0.27412701 - samples/sec: 143.76 - lr: 0.000030
2021-07-24 07:28:23,624 epoch 12 - iter 54/66 - loss 0.27153393 - samples/sec: 140.63 - lr: 0.000030
2021-07-24 07:28:25,051 epoch 12 - iter 60/66 - loss 0.27378262 - samples/sec: 134.62 - lr: 0.000030
2021-07-24 07:28:26,377 epoch 12 - iter 66/66 - loss 0.27214803 - samples/sec: 144.83 - lr: 0.000030
2021-07-24 07:28:26,378 ----------------------------------------------------------------------------------------------------
2021-07-24 07:28:26,378 EPOCH 12 done: loss 0.2721 - lr 0.0000300
2021-07-24 07:28:27,762 DEV : loss 0.09055136889219284 - score 0.9819
2021-07-24 07:28:27,778 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:28:30,042 ----------------------------------------------------------------------------------------------------
2021-07-24 07:28:31,416 epoch 13 - iter 6/66 - loss 0.19113302 - samples/sec: 140.00 - lr: 0.000030
2021-07-24 07:28:32,715 epoch 13 - iter 12/66 - loss 0.23422264 - samples/sec: 147.79 - lr: 0.000030
2021-07-24 07:28:34,051 epoch 13 - iter 18/66 - loss 0.25518228 - samples/sec: 143.83 - lr: 0.000030
2021-07-24 07:28:35,424 epoch 13 - iter 24/66 - loss 0.24737553 - samples/sec: 139.84 - lr: 0.000030
2021-07-24 07:28:36,808 epoch 13 - iter 30/66 - loss 0.26188807 - samples/sec: 138.79 - lr: 0.000030
2021-07-24 07:28:38,207 epoch 13 - iter 36/66 - loss 0.25634368 - samples/sec: 137.28 - lr: 0.000030
2021-07-24 07:28:39,607 epoch 13 - iter 42/66 - loss 0.24586869 - samples/sec: 137.22 - lr: 0.000030
2021-07-24 07:28:40,991 epoch 13 - iter 48/66 - loss 0.23602291 - samples/sec: 138.80 - lr: 0.000030
2021-07-24 07:28:42,381 epoch 13 - iter 54/66 - loss 0.24770394 - samples/sec: 138.18 - lr: 0.000030
2021-07-24 07:28:43,791 epoch 13 - iter 60/66 - loss 0.24098511 - samples/sec: 136.22 - lr: 0.000030
2021-07-24 07:28:45,086 epoch 13 - iter 66/66 - loss 0.24873769 - samples/sec: 148.34 - lr: 0.000030
2021-07-24 07:28:45,087 ----------------------------------------------------------------------------------------------------
2021-07-24 07:28:45,087 EPOCH 13 done: loss 0.2487 - lr 0.0000300
2021-07-24 07:28:46,470 DEV : loss 0.08758563548326492 - score 0.9819
2021-07-24 07:28:46,486 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:28:48,781 ----------------------------------------------------------------------------------------------------
2021-07-24 07:28:50,151 epoch 14 - iter 6/66 - loss 0.31295810 - samples/sec: 140.47 - lr: 0.000030
2021-07-24 07:28:51,635 epoch 14 - iter 12/66 - loss 0.25949238 - samples/sec: 129.40 - lr: 0.000030
2021-07-24 07:28:52,968 epoch 14 - iter 18/66 - loss 0.25646885 - samples/sec: 144.14 - lr: 0.000030
2021-07-24 07:28:54,336 epoch 14 - iter 24/66 - loss 0.24876869 - samples/sec: 140.32 - lr: 0.000030
2021-07-24 07:28:55,756 epoch 14 - iter 30/66 - loss 0.24555395 - samples/sec: 135.28 - lr: 0.000030
2021-07-24 07:28:57,079 epoch 14 - iter 36/66 - loss 0.24524836 - samples/sec: 145.19 - lr: 0.000030
2021-07-24 07:28:58,471 epoch 14 - iter 42/66 - loss 0.25169293 - samples/sec: 137.95 - lr: 0.000030
2021-07-24 07:28:59,859 epoch 14 - iter 48/66 - loss 0.25317472 - samples/sec: 138.38 - lr: 0.000030
2021-07-24 07:29:01,211 epoch 14 - iter 54/66 - loss 0.25135056 - samples/sec: 142.09 - lr: 0.000030
2021-07-24 07:29:02,583 epoch 14 - iter 60/66 - loss 0.25087757 - samples/sec: 140.03 - lr: 0.000030
2021-07-24 07:29:03,892 epoch 14 - iter 66/66 - loss 0.25282055 - samples/sec: 146.75 - lr: 0.000030
2021-07-24 07:29:03,893 ----------------------------------------------------------------------------------------------------
2021-07-24 07:29:03,893 EPOCH 14 done: loss 0.2528 - lr 0.0000300
2021-07-24 07:29:05,281 DEV : loss 0.08455417305231094 - score 0.983
2021-07-24 07:29:05,297 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:29:07,596 ----------------------------------------------------------------------------------------------------
2021-07-24 07:29:08,921 epoch 15 - iter 6/66 - loss 0.30120186 - samples/sec: 145.11 - lr: 0.000030
2021-07-24 07:29:10,308 epoch 15 - iter 12/66 - loss 0.27784356 - samples/sec: 138.43 - lr: 0.000030
2021-07-24 07:29:11,700 epoch 15 - iter 18/66 - loss 0.25666018 - samples/sec: 138.00 - lr: 0.000030
2021-07-24 07:29:13,068 epoch 15 - iter 24/66 - loss 0.25964287 - samples/sec: 140.38 - lr: 0.000030
2021-07-24 07:29:14,455 epoch 15 - iter 30/66 - loss 0.26549568 - samples/sec: 138.52 - lr: 0.000030
2021-07-24 07:29:15,880 epoch 15 - iter 36/66 - loss 0.27729129 - samples/sec: 134.74 - lr: 0.000030
2021-07-24 07:29:17,245 epoch 15 - iter 42/66 - loss 0.27521315 - samples/sec: 140.76 - lr: 0.000030
2021-07-24 07:29:18,671 epoch 15 - iter 48/66 - loss 0.28055807 - samples/sec: 134.65 - lr: 0.000030
2021-07-24 07:29:20,027 epoch 15 - iter 54/66 - loss 0.27303025 - samples/sec: 141.71 - lr: 0.000030
2021-07-24 07:29:21,368 epoch 15 - iter 60/66 - loss 0.27054014 - samples/sec: 143.19 - lr: 0.000030
2021-07-24 07:29:22,614 epoch 15 - iter 66/66 - loss 0.26532357 - samples/sec: 154.25 - lr: 0.000030
2021-07-24 07:29:22,615 ----------------------------------------------------------------------------------------------------
2021-07-24 07:29:22,615 EPOCH 15 done: loss 0.2653 - lr 0.0000300
2021-07-24 07:29:23,996 DEV : loss 0.08293446898460388 - score 0.983
2021-07-24 07:29:24,012 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:29:26,661 ----------------------------------------------------------------------------------------------------
2021-07-24 07:29:28,048 epoch 16 - iter 6/66 - loss 0.24231813 - samples/sec: 138.65 - lr: 0.000030
2021-07-24 07:29:29,512 epoch 16 - iter 12/66 - loss 0.25771614 - samples/sec: 131.14 - lr: 0.000030
2021-07-24 07:29:30,916 epoch 16 - iter 18/66 - loss 0.23548181 - samples/sec: 136.89 - lr: 0.000030
2021-07-24 07:29:32,241 epoch 16 - iter 24/66 - loss 0.20695398 - samples/sec: 144.90 - lr: 0.000030
2021-07-24 07:29:33,665 epoch 16 - iter 30/66 - loss 0.21977219 - samples/sec: 134.88 - lr: 0.000030
2021-07-24 07:29:34,968 epoch 16 - iter 36/66 - loss 0.22332261 - samples/sec: 147.45 - lr: 0.000030
2021-07-24 07:29:36,332 epoch 16 - iter 42/66 - loss 0.22169837 - samples/sec: 140.84 - lr: 0.000030
2021-07-24 07:29:37,749 epoch 16 - iter 48/66 - loss 0.22372143 - samples/sec: 135.50 - lr: 0.000030
2021-07-24 07:29:39,132 epoch 16 - iter 54/66 - loss 0.21582364 - samples/sec: 138.88 - lr: 0.000030
2021-07-24 07:29:40,464 epoch 16 - iter 60/66 - loss 0.21781127 - samples/sec: 144.21 - lr: 0.000030
2021-07-24 07:29:41,710 epoch 16 - iter 66/66 - loss 0.22173070 - samples/sec: 154.22 - lr: 0.000030
2021-07-24 07:29:41,711 ----------------------------------------------------------------------------------------------------
2021-07-24 07:29:41,711 EPOCH 16 done: loss 0.2217 - lr 0.0000300
2021-07-24 07:29:43,097 DEV : loss 0.07832001149654388 - score 0.9853
2021-07-24 07:29:43,113 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:29:45,436 ----------------------------------------------------------------------------------------------------
2021-07-24 07:29:46,889 epoch 17 - iter 6/66 - loss 0.21985504 - samples/sec: 132.35 - lr: 0.000030
2021-07-24 07:29:48,376 epoch 17 - iter 12/66 - loss 0.19026485 - samples/sec: 129.18 - lr: 0.000030
2021-07-24 07:29:49,748 epoch 17 - iter 18/66 - loss 0.19300995 - samples/sec: 139.93 - lr: 0.000030
2021-07-24 07:29:51,136 epoch 17 - iter 24/66 - loss 0.19299990 - samples/sec: 138.42 - lr: 0.000030
2021-07-24 07:29:52,448 epoch 17 - iter 30/66 - loss 0.18360159 - samples/sec: 146.44 - lr: 0.000030
2021-07-24 07:29:53,752 epoch 17 - iter 36/66 - loss 0.19539594 - samples/sec: 147.27 - lr: 0.000030
2021-07-24 07:29:55,099 epoch 17 - iter 42/66 - loss 0.19365406 - samples/sec: 142.61 - lr: 0.000030
2021-07-24 07:29:56,431 epoch 17 - iter 48/66 - loss 0.20309681 - samples/sec: 144.12 - lr: 0.000030
2021-07-24 07:29:57,742 epoch 17 - iter 54/66 - loss 0.22063381 - samples/sec: 146.52 - lr: 0.000030
2021-07-24 07:29:59,116 epoch 17 - iter 60/66 - loss 0.21866789 - samples/sec: 139.85 - lr: 0.000030
2021-07-24 07:30:00,430 epoch 17 - iter 66/66 - loss 0.21500952 - samples/sec: 146.15 - lr: 0.000030
2021-07-24 07:30:00,431 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:00,431 EPOCH 17 done: loss 0.2150 - lr 0.0000300
2021-07-24 07:30:01,818 DEV : loss 0.07966010272502899 - score 0.9831
2021-07-24 07:30:01,833 BAD EPOCHS (no improvement): 1
2021-07-24 07:30:01,833 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:03,258 epoch 18 - iter 6/66 - loss 0.23135415 - samples/sec: 134.91 - lr: 0.000030
2021-07-24 07:30:04,649 epoch 18 - iter 12/66 - loss 0.24948074 - samples/sec: 138.11 - lr: 0.000030
2021-07-24 07:30:06,020 epoch 18 - iter 18/66 - loss 0.22503196 - samples/sec: 140.12 - lr: 0.000030
2021-07-24 07:30:07,445 epoch 18 - iter 24/66 - loss 0.22693689 - samples/sec: 134.75 - lr: 0.000030
2021-07-24 07:30:08,784 epoch 18 - iter 30/66 - loss 0.24048901 - samples/sec: 143.44 - lr: 0.000030
2021-07-24 07:30:10,136 epoch 18 - iter 36/66 - loss 0.23968226 - samples/sec: 142.12 - lr: 0.000030
2021-07-24 07:30:11,552 epoch 18 - iter 42/66 - loss 0.23297716 - samples/sec: 135.60 - lr: 0.000030
2021-07-24 07:30:12,864 epoch 18 - iter 48/66 - loss 0.23424497 - samples/sec: 146.37 - lr: 0.000030
2021-07-24 07:30:14,232 epoch 18 - iter 54/66 - loss 0.22623294 - samples/sec: 140.46 - lr: 0.000030
2021-07-24 07:30:15,592 epoch 18 - iter 60/66 - loss 0.22702972 - samples/sec: 141.16 - lr: 0.000030
2021-07-24 07:30:16,793 epoch 18 - iter 66/66 - loss 0.22886957 - samples/sec: 159.95 - lr: 0.000030
2021-07-24 07:30:16,794 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:16,794 EPOCH 18 done: loss 0.2289 - lr 0.0000300
2021-07-24 07:30:18,185 DEV : loss 0.07597221434116364 - score 0.9853
2021-07-24 07:30:18,205 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:30:20,476 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:21,868 epoch 19 - iter 6/66 - loss 0.13271803 - samples/sec: 138.11 - lr: 0.000030
2021-07-24 07:30:23,107 epoch 19 - iter 12/66 - loss 0.20433187 - samples/sec: 155.04 - lr: 0.000030
2021-07-24 07:30:24,428 epoch 19 - iter 18/66 - loss 0.19911707 - samples/sec: 145.43 - lr: 0.000030
2021-07-24 07:30:25,845 epoch 19 - iter 24/66 - loss 0.19293282 - samples/sec: 135.56 - lr: 0.000030
2021-07-24 07:30:27,270 epoch 19 - iter 30/66 - loss 0.18484874 - samples/sec: 134.75 - lr: 0.000030
2021-07-24 07:30:28,720 epoch 19 - iter 36/66 - loss 0.20240388 - samples/sec: 132.45 - lr: 0.000030
2021-07-24 07:30:30,132 epoch 19 - iter 42/66 - loss 0.20485008 - samples/sec: 136.08 - lr: 0.000030
2021-07-24 07:30:31,525 epoch 19 - iter 48/66 - loss 0.20133409 - samples/sec: 137.89 - lr: 0.000030
2021-07-24 07:30:32,891 epoch 19 - iter 54/66 - loss 0.20661946 - samples/sec: 140.56 - lr: 0.000030
2021-07-24 07:30:34,225 epoch 19 - iter 60/66 - loss 0.20741244 - samples/sec: 144.06 - lr: 0.000030
2021-07-24 07:30:35,481 epoch 19 - iter 66/66 - loss 0.21496294 - samples/sec: 152.84 - lr: 0.000030
2021-07-24 07:30:35,482 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:35,482 EPOCH 19 done: loss 0.2150 - lr 0.0000300
2021-07-24 07:30:36,866 DEV : loss 0.0736728385090828 - score 0.9853
2021-07-24 07:30:36,881 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:30:39,082 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:40,411 epoch 20 - iter 6/66 - loss 0.20488039 - samples/sec: 144.83 - lr: 0.000030
2021-07-24 07:30:41,716 epoch 20 - iter 12/66 - loss 0.23053260 - samples/sec: 147.08 - lr: 0.000030
2021-07-24 07:30:43,216 epoch 20 - iter 18/66 - loss 0.22618773 - samples/sec: 128.13 - lr: 0.000030
2021-07-24 07:30:44,549 epoch 20 - iter 24/66 - loss 0.22217483 - samples/sec: 144.09 - lr: 0.000030
2021-07-24 07:30:46,000 epoch 20 - iter 30/66 - loss 0.22335739 - samples/sec: 132.31 - lr: 0.000030
2021-07-24 07:30:47,379 epoch 20 - iter 36/66 - loss 0.21871994 - samples/sec: 139.29 - lr: 0.000030
2021-07-24 07:30:48,792 epoch 20 - iter 42/66 - loss 0.21987371 - samples/sec: 135.94 - lr: 0.000030
2021-07-24 07:30:50,163 epoch 20 - iter 48/66 - loss 0.20955420 - samples/sec: 140.11 - lr: 0.000030
2021-07-24 07:30:51,568 epoch 20 - iter 54/66 - loss 0.21649644 - samples/sec: 136.69 - lr: 0.000030
2021-07-24 07:30:52,900 epoch 20 - iter 60/66 - loss 0.22014361 - samples/sec: 144.18 - lr: 0.000030
2021-07-24 07:30:54,207 epoch 20 - iter 66/66 - loss 0.22000376 - samples/sec: 146.97 - lr: 0.000030
2021-07-24 07:30:54,208 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:54,208 EPOCH 20 done: loss 0.2200 - lr 0.0000300
2021-07-24 07:30:55,591 DEV : loss 0.07146794348955154 - score 0.9853
2021-07-24 07:30:55,607 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:30:57,963 ----------------------------------------------------------------------------------------------------
2021-07-24 07:30:59,341 epoch 21 - iter 6/66 - loss 0.13202022 - samples/sec: 139.59 - lr: 0.000030
2021-07-24 07:31:00,659 epoch 21 - iter 12/66 - loss 0.21515939 - samples/sec: 145.67 - lr: 0.000030
2021-07-24 07:31:02,078 epoch 21 - iter 18/66 - loss 0.20997281 - samples/sec: 135.36 - lr: 0.000030
2021-07-24 07:31:03,357 epoch 21 - iter 24/66 - loss 0.21211222 - samples/sec: 150.26 - lr: 0.000030
2021-07-24 07:31:04,721 epoch 21 - iter 30/66 - loss 0.20783241 - samples/sec: 140.75 - lr: 0.000030
2021-07-24 07:31:06,109 epoch 21 - iter 36/66 - loss 0.20139663 - samples/sec: 138.37 - lr: 0.000030
2021-07-24 07:31:07,578 epoch 21 - iter 42/66 - loss 0.20278164 - samples/sec: 130.84 - lr: 0.000030
2021-07-24 07:31:08,936 epoch 21 - iter 48/66 - loss 0.20109841 - samples/sec: 141.39 - lr: 0.000030
2021-07-24 07:31:10,251 epoch 21 - iter 54/66 - loss 0.19063156 - samples/sec: 146.07 - lr: 0.000030
2021-07-24 07:31:11,642 epoch 21 - iter 60/66 - loss 0.19482125 - samples/sec: 138.10 - lr: 0.000030
2021-07-24 07:31:12,929 epoch 21 - iter 66/66 - loss 0.19131007 - samples/sec: 149.20 - lr: 0.000030
2021-07-24 07:31:12,930 ----------------------------------------------------------------------------------------------------
2021-07-24 07:31:12,931 EPOCH 21 done: loss 0.1913 - lr 0.0000300
2021-07-24 07:31:14,320 DEV : loss 0.07393182069063187 - score 0.9864
2021-07-24 07:31:14,336 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:31:16,516 ----------------------------------------------------------------------------------------------------
2021-07-24 07:31:17,844 epoch 22 - iter 6/66 - loss 0.15128697 - samples/sec: 144.85 - lr: 0.000030
2021-07-24 07:31:19,266 epoch 22 - iter 12/66 - loss 0.15843537 - samples/sec: 135.14 - lr: 0.000030
2021-07-24 07:31:20,564 epoch 22 - iter 18/66 - loss 0.17588406 - samples/sec: 147.94 - lr: 0.000030
2021-07-24 07:31:21,944 epoch 22 - iter 24/66 - loss 0.16775488 - samples/sec: 139.16 - lr: 0.000030
2021-07-24 07:31:23,272 epoch 22 - iter 30/66 - loss 0.19671368 - samples/sec: 144.70 - lr: 0.000030
2021-07-24 07:31:24,512 epoch 22 - iter 36/66 - loss 0.18430202 - samples/sec: 154.80 - lr: 0.000030
2021-07-24 07:31:25,968 epoch 22 - iter 42/66 - loss 0.18670917 - samples/sec: 131.95 - lr: 0.000030
2021-07-24 07:31:27,391 epoch 22 - iter 48/66 - loss 0.18531925 - samples/sec: 134.93 - lr: 0.000030
2021-07-24 07:31:28,823 epoch 22 - iter 54/66 - loss 0.18179464 - samples/sec: 134.13 - lr: 0.000030
2021-07-24 07:31:30,213 epoch 22 - iter 60/66 - loss 0.18390165 - samples/sec: 138.25 - lr: 0.000030
2021-07-24 07:31:31,511 epoch 22 - iter 66/66 - loss 0.17687486 - samples/sec: 148.00 - lr: 0.000030
2021-07-24 07:31:31,512 ----------------------------------------------------------------------------------------------------
2021-07-24 07:31:31,512 EPOCH 22 done: loss 0.1769 - lr 0.0000300
2021-07-24 07:31:32,905 DEV : loss 0.07095153629779816 - score 0.9852
2021-07-24 07:31:32,920 BAD EPOCHS (no improvement): 1
2021-07-24 07:31:32,921 ----------------------------------------------------------------------------------------------------
2021-07-24 07:31:34,319 epoch 23 - iter 6/66 - loss 0.15020884 - samples/sec: 137.48 - lr: 0.000030
2021-07-24 07:31:35,731 epoch 23 - iter 12/66 - loss 0.16658949 - samples/sec: 135.97 - lr: 0.000030
2021-07-24 07:31:37,127 epoch 23 - iter 18/66 - loss 0.16441801 - samples/sec: 137.60 - lr: 0.000030
2021-07-24 07:31:38,493 epoch 23 - iter 24/66 - loss 0.17192830 - samples/sec: 140.65 - lr: 0.000030
2021-07-24 07:31:39,944 epoch 23 - iter 30/66 - loss 0.17861646 - samples/sec: 132.31 - lr: 0.000030
2021-07-24 07:31:41,298 epoch 23 - iter 36/66 - loss 0.17592108 - samples/sec: 141.84 - lr: 0.000030
2021-07-24 07:31:42,643 epoch 23 - iter 42/66 - loss 0.17647294 - samples/sec: 142.85 - lr: 0.000030
2021-07-24 07:31:44,064 epoch 23 - iter 48/66 - loss 0.17037365 - samples/sec: 135.13 - lr: 0.000030
2021-07-24 07:31:45,390 epoch 23 - iter 54/66 - loss 0.16748510 - samples/sec: 144.87 - lr: 0.000030
2021-07-24 07:31:46,666 epoch 23 - iter 60/66 - loss 0.16903815 - samples/sec: 150.53 - lr: 0.000030
2021-07-24 07:31:47,841 epoch 23 - iter 66/66 - loss 0.16839434 - samples/sec: 163.50 - lr: 0.000030
2021-07-24 07:31:47,842 ----------------------------------------------------------------------------------------------------
2021-07-24 07:31:47,842 EPOCH 23 done: loss 0.1684 - lr 0.0000300
2021-07-24 07:31:49,235 DEV : loss 0.0685904324054718 - score 0.9853
2021-07-24 07:31:49,251 BAD EPOCHS (no improvement): 2
2021-07-24 07:31:49,251 ----------------------------------------------------------------------------------------------------
2021-07-24 07:31:50,660 epoch 24 - iter 6/66 - loss 0.21076697 - samples/sec: 136.41 - lr: 0.000030
2021-07-24 07:31:52,003 epoch 24 - iter 12/66 - loss 0.15515056 - samples/sec: 143.02 - lr: 0.000030
2021-07-24 07:31:53,324 epoch 24 - iter 18/66 - loss 0.16482740 - samples/sec: 145.38 - lr: 0.000030
2021-07-24 07:31:54,670 epoch 24 - iter 24/66 - loss 0.17127740 - samples/sec: 142.66 - lr: 0.000030
2021-07-24 07:31:56,083 epoch 24 - iter 30/66 - loss 0.17906680 - samples/sec: 136.01 - lr: 0.000030
2021-07-24 07:31:57,505 epoch 24 - iter 36/66 - loss 0.19005737 - samples/sec: 135.01 - lr: 0.000030
2021-07-24 07:31:58,913 epoch 24 - iter 42/66 - loss 0.18772012 - samples/sec: 136.47 - lr: 0.000030
2021-07-24 07:32:00,272 epoch 24 - iter 48/66 - loss 0.19354827 - samples/sec: 141.32 - lr: 0.000030
2021-07-24 07:32:01,727 epoch 24 - iter 54/66 - loss 0.18614518 - samples/sec: 131.98 - lr: 0.000030
2021-07-24 07:32:02,991 epoch 24 - iter 60/66 - loss 0.18503203 - samples/sec: 151.93 - lr: 0.000030
2021-07-24 07:32:04,227 epoch 24 - iter 66/66 - loss 0.18818203 - samples/sec: 155.47 - lr: 0.000030
2021-07-24 07:32:04,228 ----------------------------------------------------------------------------------------------------
2021-07-24 07:32:04,228 EPOCH 24 done: loss 0.1882 - lr 0.0000300
2021-07-24 07:32:05,616 DEV : loss 0.06730996072292328 - score 0.9853
2021-07-24 07:32:05,632 BAD EPOCHS (no improvement): 3
2021-07-24 07:32:05,632 ----------------------------------------------------------------------------------------------------
2021-07-24 07:32:07,012 epoch 25 - iter 6/66 - loss 0.15045543 - samples/sec: 139.25 - lr: 0.000030
2021-07-24 07:32:08,449 epoch 25 - iter 12/66 - loss 0.15955277 - samples/sec: 133.73 - lr: 0.000030
2021-07-24 07:32:09,664 epoch 25 - iter 18/66 - loss 0.15286734 - samples/sec: 157.99 - lr: 0.000030
2021-07-24 07:32:11,004 epoch 25 - iter 24/66 - loss 0.16191842 - samples/sec: 143.42 - lr: 0.000030
2021-07-24 07:32:12,396 epoch 25 - iter 30/66 - loss 0.16565173 - samples/sec: 137.98 - lr: 0.000030
2021-07-24 07:32:13,825 epoch 25 - iter 36/66 - loss 0.17784541 - samples/sec: 134.39 - lr: 0.000030
2021-07-24 07:32:15,108 epoch 25 - iter 42/66 - loss 0.17785297 - samples/sec: 149.70 - lr: 0.000030
2021-07-24 07:32:16,485 epoch 25 - iter 48/66 - loss 0.17995044 - samples/sec: 139.47 - lr: 0.000030
2021-07-24 07:32:17,864 epoch 25 - iter 54/66 - loss 0.17888839 - samples/sec: 139.32 - lr: 0.000030
2021-07-24 07:32:19,227 epoch 25 - iter 60/66 - loss 0.17983036 - samples/sec: 140.86 - lr: 0.000030
2021-07-24 07:32:20,547 epoch 25 - iter 66/66 - loss 0.18437854 - samples/sec: 145.59 - lr: 0.000030
2021-07-24 07:32:20,548 ----------------------------------------------------------------------------------------------------
2021-07-24 07:32:20,548 EPOCH 25 done: loss 0.1844 - lr 0.0000300
2021-07-24 07:32:21,937 DEV : loss 0.06715752929449081 - score 0.9852
Epoch    25: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 07:32:21,953 BAD EPOCHS (no improvement): 4
2021-07-24 07:32:21,953 ----------------------------------------------------------------------------------------------------
2021-07-24 07:32:23,296 epoch 26 - iter 6/66 - loss 0.16268563 - samples/sec: 143.10 - lr: 0.000015
2021-07-24 07:32:24,730 epoch 26 - iter 12/66 - loss 0.18077956 - samples/sec: 133.96 - lr: 0.000015
2021-07-24 07:32:26,064 epoch 26 - iter 18/66 - loss 0.16718451 - samples/sec: 143.99 - lr: 0.000015
2021-07-24 07:32:27,442 epoch 26 - iter 24/66 - loss 0.15390455 - samples/sec: 139.44 - lr: 0.000015
2021-07-24 07:32:28,969 epoch 26 - iter 30/66 - loss 0.15397650 - samples/sec: 125.74 - lr: 0.000015
2021-07-24 07:32:30,402 epoch 26 - iter 36/66 - loss 0.15522402 - samples/sec: 134.09 - lr: 0.000015
2021-07-24 07:32:31,712 epoch 26 - iter 42/66 - loss 0.16153857 - samples/sec: 146.67 - lr: 0.000015
2021-07-24 07:32:33,064 epoch 26 - iter 48/66 - loss 0.15825824 - samples/sec: 142.00 - lr: 0.000015
2021-07-24 07:32:34,464 epoch 26 - iter 54/66 - loss 0.16536727 - samples/sec: 137.23 - lr: 0.000015
2021-07-24 07:32:35,775 epoch 26 - iter 60/66 - loss 0.16432238 - samples/sec: 146.48 - lr: 0.000015
2021-07-24 07:32:37,054 epoch 26 - iter 66/66 - loss 0.16951342 - samples/sec: 150.18 - lr: 0.000015
2021-07-24 07:32:37,055 ----------------------------------------------------------------------------------------------------
2021-07-24 07:32:37,055 EPOCH 26 done: loss 0.1695 - lr 0.0000150
2021-07-24 07:32:38,435 DEV : loss 0.06715293973684311 - score 0.9853
2021-07-24 07:32:38,450 BAD EPOCHS (no improvement): 1
2021-07-24 07:32:38,450 ----------------------------------------------------------------------------------------------------
2021-07-24 07:32:39,833 epoch 27 - iter 6/66 - loss 0.19355082 - samples/sec: 138.98 - lr: 0.000015
2021-07-24 07:32:41,116 epoch 27 - iter 12/66 - loss 0.19541936 - samples/sec: 149.73 - lr: 0.000015
2021-07-24 07:32:42,469 epoch 27 - iter 18/66 - loss 0.17419416 - samples/sec: 141.99 - lr: 0.000015
2021-07-24 07:32:43,824 epoch 27 - iter 24/66 - loss 0.18535991 - samples/sec: 141.76 - lr: 0.000015
2021-07-24 07:32:45,159 epoch 27 - iter 30/66 - loss 0.17842688 - samples/sec: 143.82 - lr: 0.000015
2021-07-24 07:32:46,661 epoch 27 - iter 36/66 - loss 0.16631235 - samples/sec: 127.88 - lr: 0.000015
2021-07-24 07:32:47,989 epoch 27 - iter 42/66 - loss 0.16289030 - samples/sec: 144.69 - lr: 0.000015
2021-07-24 07:32:49,437 epoch 27 - iter 48/66 - loss 0.16699229 - samples/sec: 132.64 - lr: 0.000015
2021-07-24 07:32:50,735 epoch 27 - iter 54/66 - loss 0.17966901 - samples/sec: 147.94 - lr: 0.000015
2021-07-24 07:32:52,187 epoch 27 - iter 60/66 - loss 0.17646665 - samples/sec: 132.29 - lr: 0.000015
2021-07-24 07:32:53,443 epoch 27 - iter 66/66 - loss 0.17794910 - samples/sec: 152.97 - lr: 0.000015
2021-07-24 07:32:53,444 ----------------------------------------------------------------------------------------------------
2021-07-24 07:32:53,444 EPOCH 27 done: loss 0.1779 - lr 0.0000150
2021-07-24 07:32:54,826 DEV : loss 0.06749262660741806 - score 0.9852
2021-07-24 07:32:54,842 BAD EPOCHS (no improvement): 2
2021-07-24 07:32:54,842 ----------------------------------------------------------------------------------------------------
2021-07-24 07:32:56,210 epoch 28 - iter 6/66 - loss 0.18134280 - samples/sec: 140.55 - lr: 0.000015
2021-07-24 07:32:57,668 epoch 28 - iter 12/66 - loss 0.16743005 - samples/sec: 131.68 - lr: 0.000015
2021-07-24 07:32:58,992 epoch 28 - iter 18/66 - loss 0.17285909 - samples/sec: 145.07 - lr: 0.000015
2021-07-24 07:33:00,368 epoch 28 - iter 24/66 - loss 0.17916464 - samples/sec: 139.64 - lr: 0.000015
2021-07-24 07:33:01,768 epoch 28 - iter 30/66 - loss 0.16846434 - samples/sec: 137.20 - lr: 0.000015
2021-07-24 07:33:03,127 epoch 28 - iter 36/66 - loss 0.18149813 - samples/sec: 141.26 - lr: 0.000015
2021-07-24 07:33:04,492 epoch 28 - iter 42/66 - loss 0.17660918 - samples/sec: 140.78 - lr: 0.000015
2021-07-24 07:33:05,918 epoch 28 - iter 48/66 - loss 0.17495561 - samples/sec: 134.63 - lr: 0.000015
2021-07-24 07:33:07,308 epoch 28 - iter 54/66 - loss 0.17604490 - samples/sec: 138.27 - lr: 0.000015
2021-07-24 07:33:08,607 epoch 28 - iter 60/66 - loss 0.17091602 - samples/sec: 147.82 - lr: 0.000015
2021-07-24 07:33:09,823 epoch 28 - iter 66/66 - loss 0.17721912 - samples/sec: 158.01 - lr: 0.000015
2021-07-24 07:33:09,823 ----------------------------------------------------------------------------------------------------
2021-07-24 07:33:09,824 EPOCH 28 done: loss 0.1772 - lr 0.0000150
2021-07-24 07:33:11,213 DEV : loss 0.0665455237030983 - score 0.9853
2021-07-24 07:33:11,229 BAD EPOCHS (no improvement): 3
2021-07-24 07:33:11,229 ----------------------------------------------------------------------------------------------------
2021-07-24 07:33:12,597 epoch 29 - iter 6/66 - loss 0.27119704 - samples/sec: 140.57 - lr: 0.000015
2021-07-24 07:33:13,990 epoch 29 - iter 12/66 - loss 0.21561154 - samples/sec: 137.82 - lr: 0.000015
2021-07-24 07:33:15,278 epoch 29 - iter 18/66 - loss 0.20942491 - samples/sec: 149.14 - lr: 0.000015
2021-07-24 07:33:16,667 epoch 29 - iter 24/66 - loss 0.19512677 - samples/sec: 138.29 - lr: 0.000015
2021-07-24 07:33:18,056 epoch 29 - iter 30/66 - loss 0.18471463 - samples/sec: 138.30 - lr: 0.000015
2021-07-24 07:33:19,387 epoch 29 - iter 36/66 - loss 0.17949252 - samples/sec: 144.25 - lr: 0.000015
2021-07-24 07:33:20,740 epoch 29 - iter 42/66 - loss 0.17747267 - samples/sec: 142.04 - lr: 0.000015
2021-07-24 07:33:22,095 epoch 29 - iter 48/66 - loss 0.17835740 - samples/sec: 141.70 - lr: 0.000015
2021-07-24 07:33:23,463 epoch 29 - iter 54/66 - loss 0.17322841 - samples/sec: 140.42 - lr: 0.000015
2021-07-24 07:33:24,943 epoch 29 - iter 60/66 - loss 0.16498988 - samples/sec: 129.78 - lr: 0.000015
2021-07-24 07:33:26,211 epoch 29 - iter 66/66 - loss 0.17005332 - samples/sec: 151.48 - lr: 0.000015
2021-07-24 07:33:26,212 ----------------------------------------------------------------------------------------------------
2021-07-24 07:33:26,212 EPOCH 29 done: loss 0.1701 - lr 0.0000150
2021-07-24 07:33:27,601 DEV : loss 0.0666748583316803 - score 0.9841
Epoch    29: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 07:33:27,617 BAD EPOCHS (no improvement): 4
2021-07-24 07:33:27,617 ----------------------------------------------------------------------------------------------------
2021-07-24 07:33:28,992 epoch 30 - iter 6/66 - loss 0.19811703 - samples/sec: 139.84 - lr: 0.000008
2021-07-24 07:33:30,408 epoch 30 - iter 12/66 - loss 0.19731151 - samples/sec: 135.60 - lr: 0.000008
2021-07-24 07:33:31,787 epoch 30 - iter 18/66 - loss 0.16603405 - samples/sec: 139.28 - lr: 0.000008
2021-07-24 07:33:33,152 epoch 30 - iter 24/66 - loss 0.17946197 - samples/sec: 140.75 - lr: 0.000008
2021-07-24 07:33:34,438 epoch 30 - iter 30/66 - loss 0.17203758 - samples/sec: 149.28 - lr: 0.000008
2021-07-24 07:33:35,804 epoch 30 - iter 36/66 - loss 0.16873379 - samples/sec: 140.61 - lr: 0.000008
2021-07-24 07:33:37,104 epoch 30 - iter 42/66 - loss 0.17065822 - samples/sec: 147.84 - lr: 0.000008
2021-07-24 07:33:38,432 epoch 30 - iter 48/66 - loss 0.16510345 - samples/sec: 144.60 - lr: 0.000008
2021-07-24 07:33:39,884 epoch 30 - iter 54/66 - loss 0.17466566 - samples/sec: 132.24 - lr: 0.000008
2021-07-24 07:33:41,293 epoch 30 - iter 60/66 - loss 0.17429023 - samples/sec: 136.38 - lr: 0.000008
2021-07-24 07:33:42,553 epoch 30 - iter 66/66 - loss 0.18127874 - samples/sec: 152.36 - lr: 0.000008
2021-07-24 07:33:42,554 ----------------------------------------------------------------------------------------------------
2021-07-24 07:33:42,554 EPOCH 30 done: loss 0.1813 - lr 0.0000075
2021-07-24 07:33:43,946 DEV : loss 0.06651528179645538 - score 0.9853
2021-07-24 07:33:43,962 BAD EPOCHS (no improvement): 1
2021-07-24 07:33:43,962 ----------------------------------------------------------------------------------------------------
2021-07-24 07:33:45,376 epoch 31 - iter 6/66 - loss 0.14935552 - samples/sec: 135.96 - lr: 0.000008
2021-07-24 07:33:46,706 epoch 31 - iter 12/66 - loss 0.11275573 - samples/sec: 144.34 - lr: 0.000008
2021-07-24 07:33:48,086 epoch 31 - iter 18/66 - loss 0.13219274 - samples/sec: 139.17 - lr: 0.000008
2021-07-24 07:33:49,571 epoch 31 - iter 24/66 - loss 0.13960408 - samples/sec: 129.35 - lr: 0.000008
2021-07-24 07:33:50,863 epoch 31 - iter 30/66 - loss 0.15219080 - samples/sec: 148.72 - lr: 0.000008
2021-07-24 07:33:52,205 epoch 31 - iter 36/66 - loss 0.16601390 - samples/sec: 143.13 - lr: 0.000008
2021-07-24 07:33:53,579 epoch 31 - iter 42/66 - loss 0.15538314 - samples/sec: 139.74 - lr: 0.000008
2021-07-24 07:33:54,956 epoch 31 - iter 48/66 - loss 0.14906836 - samples/sec: 139.51 - lr: 0.000008
2021-07-24 07:33:56,304 epoch 31 - iter 54/66 - loss 0.15157210 - samples/sec: 142.52 - lr: 0.000008
2021-07-24 07:33:57,640 epoch 31 - iter 60/66 - loss 0.15485601 - samples/sec: 143.76 - lr: 0.000008
2021-07-24 07:33:58,855 epoch 31 - iter 66/66 - loss 0.15524119 - samples/sec: 158.01 - lr: 0.000008
2021-07-24 07:33:58,856 ----------------------------------------------------------------------------------------------------
2021-07-24 07:33:58,856 EPOCH 31 done: loss 0.1552 - lr 0.0000075
2021-07-24 07:34:00,246 DEV : loss 0.06666093319654465 - score 0.9841
2021-07-24 07:34:00,261 BAD EPOCHS (no improvement): 2
2021-07-24 07:34:00,261 ----------------------------------------------------------------------------------------------------
2021-07-24 07:34:01,734 epoch 32 - iter 6/66 - loss 0.20433148 - samples/sec: 130.55 - lr: 0.000008
2021-07-24 07:34:03,055 epoch 32 - iter 12/66 - loss 0.17232611 - samples/sec: 145.42 - lr: 0.000008
2021-07-24 07:34:04,432 epoch 32 - iter 18/66 - loss 0.16301077 - samples/sec: 139.44 - lr: 0.000008
2021-07-24 07:34:05,945 epoch 32 - iter 24/66 - loss 0.16019810 - samples/sec: 126.92 - lr: 0.000008
2021-07-24 07:34:07,339 epoch 32 - iter 30/66 - loss 0.14192031 - samples/sec: 137.84 - lr: 0.000008
2021-07-24 07:34:08,762 epoch 32 - iter 36/66 - loss 0.15694698 - samples/sec: 134.94 - lr: 0.000008
2021-07-24 07:34:10,076 epoch 32 - iter 42/66 - loss 0.16592266 - samples/sec: 146.20 - lr: 0.000008
2021-07-24 07:34:11,379 epoch 32 - iter 48/66 - loss 0.16198762 - samples/sec: 147.42 - lr: 0.000008
2021-07-24 07:34:12,717 epoch 32 - iter 54/66 - loss 0.17031825 - samples/sec: 143.55 - lr: 0.000008
2021-07-24 07:34:14,008 epoch 32 - iter 60/66 - loss 0.16805500 - samples/sec: 148.76 - lr: 0.000008
2021-07-24 07:34:15,368 epoch 32 - iter 66/66 - loss 0.17240279 - samples/sec: 141.22 - lr: 0.000008
2021-07-24 07:34:15,369 ----------------------------------------------------------------------------------------------------
2021-07-24 07:34:15,369 EPOCH 32 done: loss 0.1724 - lr 0.0000075
2021-07-24 07:34:16,753 DEV : loss 0.06645586341619492 - score 0.9841
2021-07-24 07:34:16,769 BAD EPOCHS (no improvement): 3
2021-07-24 07:34:16,769 ----------------------------------------------------------------------------------------------------
2021-07-24 07:34:18,197 epoch 33 - iter 6/66 - loss 0.12383125 - samples/sec: 134.63 - lr: 0.000008
2021-07-24 07:34:19,532 epoch 33 - iter 12/66 - loss 0.15103262 - samples/sec: 143.88 - lr: 0.000008
2021-07-24 07:34:20,860 epoch 33 - iter 18/66 - loss 0.17014120 - samples/sec: 144.64 - lr: 0.000008
2021-07-24 07:34:22,208 epoch 33 - iter 24/66 - loss 0.17389910 - samples/sec: 142.42 - lr: 0.000008
2021-07-24 07:34:23,688 epoch 33 - iter 30/66 - loss 0.17229106 - samples/sec: 129.83 - lr: 0.000008
2021-07-24 07:34:25,100 epoch 33 - iter 36/66 - loss 0.18233305 - samples/sec: 135.98 - lr: 0.000008
2021-07-24 07:34:26,469 epoch 33 - iter 42/66 - loss 0.17879920 - samples/sec: 140.33 - lr: 0.000008
2021-07-24 07:34:27,781 epoch 33 - iter 48/66 - loss 0.18205463 - samples/sec: 146.37 - lr: 0.000008
2021-07-24 07:34:29,141 epoch 33 - iter 54/66 - loss 0.18355447 - samples/sec: 141.24 - lr: 0.000008
2021-07-24 07:34:30,562 epoch 33 - iter 60/66 - loss 0.18008634 - samples/sec: 135.14 - lr: 0.000008
2021-07-24 07:34:31,802 epoch 33 - iter 66/66 - loss 0.17812219 - samples/sec: 155.01 - lr: 0.000008
2021-07-24 07:34:31,803 ----------------------------------------------------------------------------------------------------
2021-07-24 07:34:31,803 EPOCH 33 done: loss 0.1781 - lr 0.0000075
2021-07-24 07:34:33,194 DEV : loss 0.06614464521408081 - score 0.9841
Epoch    33: reducing learning rate of group 0 to 3.7500e-06.
2021-07-24 07:34:33,214 BAD EPOCHS (no improvement): 4
2021-07-24 07:34:33,214 ----------------------------------------------------------------------------------------------------
2021-07-24 07:34:34,594 epoch 34 - iter 6/66 - loss 0.18014312 - samples/sec: 139.29 - lr: 0.000004
2021-07-24 07:34:35,951 epoch 34 - iter 12/66 - loss 0.14276635 - samples/sec: 141.53 - lr: 0.000004
2021-07-24 07:34:37,335 epoch 34 - iter 18/66 - loss 0.15963414 - samples/sec: 138.74 - lr: 0.000004
2021-07-24 07:34:38,706 epoch 34 - iter 24/66 - loss 0.17620308 - samples/sec: 140.13 - lr: 0.000004
2021-07-24 07:34:40,064 epoch 34 - iter 30/66 - loss 0.16023499 - samples/sec: 141.46 - lr: 0.000004
2021-07-24 07:34:41,412 epoch 34 - iter 36/66 - loss 0.15275398 - samples/sec: 142.44 - lr: 0.000004
2021-07-24 07:34:42,819 epoch 34 - iter 42/66 - loss 0.15845349 - samples/sec: 136.51 - lr: 0.000004
2021-07-24 07:34:44,200 epoch 34 - iter 48/66 - loss 0.15319677 - samples/sec: 139.16 - lr: 0.000004
2021-07-24 07:34:45,589 epoch 34 - iter 54/66 - loss 0.16064202 - samples/sec: 138.26 - lr: 0.000004
2021-07-24 07:34:46,956 epoch 34 - iter 60/66 - loss 0.15587739 - samples/sec: 140.50 - lr: 0.000004
2021-07-24 07:34:48,213 epoch 34 - iter 66/66 - loss 0.15290172 - samples/sec: 152.76 - lr: 0.000004
2021-07-24 07:34:48,214 ----------------------------------------------------------------------------------------------------
2021-07-24 07:34:48,214 EPOCH 34 done: loss 0.1529 - lr 0.0000038
2021-07-24 07:34:49,604 DEV : loss 0.06588923931121826 - score 0.9841
2021-07-24 07:34:49,619 BAD EPOCHS (no improvement): 1
2021-07-24 07:34:49,620 ----------------------------------------------------------------------------------------------------
2021-07-24 07:34:50,968 epoch 35 - iter 6/66 - loss 0.18174526 - samples/sec: 142.60 - lr: 0.000004
2021-07-24 07:34:52,258 epoch 35 - iter 12/66 - loss 0.18214524 - samples/sec: 148.82 - lr: 0.000004
2021-07-24 07:34:53,725 epoch 35 - iter 18/66 - loss 0.18111853 - samples/sec: 130.96 - lr: 0.000004
2021-07-24 07:34:55,135 epoch 35 - iter 24/66 - loss 0.18444991 - samples/sec: 136.24 - lr: 0.000004
2021-07-24 07:34:56,548 epoch 35 - iter 30/66 - loss 0.16642563 - samples/sec: 135.92 - lr: 0.000004
2021-07-24 07:34:57,876 epoch 35 - iter 36/66 - loss 0.16369858 - samples/sec: 144.59 - lr: 0.000004
2021-07-24 07:34:59,172 epoch 35 - iter 42/66 - loss 0.15546442 - samples/sec: 148.20 - lr: 0.000004
2021-07-24 07:35:00,549 epoch 35 - iter 48/66 - loss 0.15390385 - samples/sec: 139.55 - lr: 0.000004
2021-07-24 07:35:01,920 epoch 35 - iter 54/66 - loss 0.15527636 - samples/sec: 140.07 - lr: 0.000004
2021-07-24 07:35:03,254 epoch 35 - iter 60/66 - loss 0.14893423 - samples/sec: 143.98 - lr: 0.000004
2021-07-24 07:35:04,553 epoch 35 - iter 66/66 - loss 0.14789643 - samples/sec: 147.93 - lr: 0.000004
2021-07-24 07:35:04,554 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:04,554 EPOCH 35 done: loss 0.1479 - lr 0.0000038
2021-07-24 07:35:05,933 DEV : loss 0.06547509133815765 - score 0.9841
2021-07-24 07:35:05,949 BAD EPOCHS (no improvement): 2
2021-07-24 07:35:05,949 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:07,301 epoch 36 - iter 6/66 - loss 0.17065009 - samples/sec: 142.22 - lr: 0.000004
2021-07-24 07:35:08,747 epoch 36 - iter 12/66 - loss 0.17877918 - samples/sec: 132.77 - lr: 0.000004
2021-07-24 07:35:10,140 epoch 36 - iter 18/66 - loss 0.15145000 - samples/sec: 137.88 - lr: 0.000004
2021-07-24 07:35:11,515 epoch 36 - iter 24/66 - loss 0.14527224 - samples/sec: 139.70 - lr: 0.000004
2021-07-24 07:35:12,844 epoch 36 - iter 30/66 - loss 0.14732191 - samples/sec: 144.58 - lr: 0.000004
2021-07-24 07:35:14,221 epoch 36 - iter 36/66 - loss 0.15396979 - samples/sec: 139.46 - lr: 0.000004
2021-07-24 07:35:15,557 epoch 36 - iter 42/66 - loss 0.16570727 - samples/sec: 143.78 - lr: 0.000004
2021-07-24 07:35:16,888 epoch 36 - iter 48/66 - loss 0.16052127 - samples/sec: 144.34 - lr: 0.000004
2021-07-24 07:35:18,223 epoch 36 - iter 54/66 - loss 0.15720209 - samples/sec: 143.81 - lr: 0.000004
2021-07-24 07:35:19,604 epoch 36 - iter 60/66 - loss 0.14905026 - samples/sec: 139.13 - lr: 0.000004
2021-07-24 07:35:20,917 epoch 36 - iter 66/66 - loss 0.15244275 - samples/sec: 146.20 - lr: 0.000004
2021-07-24 07:35:20,918 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:20,918 EPOCH 36 done: loss 0.1524 - lr 0.0000038
2021-07-24 07:35:22,300 DEV : loss 0.06504243612289429 - score 0.9841
2021-07-24 07:35:22,315 BAD EPOCHS (no improvement): 3
2021-07-24 07:35:22,316 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:23,681 epoch 37 - iter 6/66 - loss 0.11867668 - samples/sec: 140.78 - lr: 0.000004
2021-07-24 07:35:25,117 epoch 37 - iter 12/66 - loss 0.13284266 - samples/sec: 133.79 - lr: 0.000004
2021-07-24 07:35:26,507 epoch 37 - iter 18/66 - loss 0.13506836 - samples/sec: 138.11 - lr: 0.000004
2021-07-24 07:35:27,879 epoch 37 - iter 24/66 - loss 0.12428614 - samples/sec: 140.01 - lr: 0.000004
2021-07-24 07:35:29,289 epoch 37 - iter 30/66 - loss 0.14351790 - samples/sec: 136.29 - lr: 0.000004
2021-07-24 07:35:30,624 epoch 37 - iter 36/66 - loss 0.14374504 - samples/sec: 143.84 - lr: 0.000004
2021-07-24 07:35:31,946 epoch 37 - iter 42/66 - loss 0.14294840 - samples/sec: 145.25 - lr: 0.000004
2021-07-24 07:35:33,264 epoch 37 - iter 48/66 - loss 0.15017383 - samples/sec: 145.81 - lr: 0.000004
2021-07-24 07:35:34,655 epoch 37 - iter 54/66 - loss 0.14591370 - samples/sec: 137.99 - lr: 0.000004
2021-07-24 07:35:36,027 epoch 37 - iter 60/66 - loss 0.14489264 - samples/sec: 140.03 - lr: 0.000004
2021-07-24 07:35:37,307 epoch 37 - iter 66/66 - loss 0.14514620 - samples/sec: 150.11 - lr: 0.000004
2021-07-24 07:35:37,308 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:37,308 EPOCH 37 done: loss 0.1451 - lr 0.0000038
2021-07-24 07:35:38,690 DEV : loss 0.06517915427684784 - score 0.9841
Epoch    37: reducing learning rate of group 0 to 1.8750e-06.
2021-07-24 07:35:38,705 BAD EPOCHS (no improvement): 4
2021-07-24 07:35:38,705 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:38,705 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:38,705 learning rate too small - quitting training!
2021-07-24 07:35:38,705 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:39,275 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:39,275 Testing using best model ...
2021-07-24 07:35:39,276 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/nld.rst.nldt/best-model.pt
2021-07-24 07:35:50,441 0.9743	0.9781	0.9762
2021-07-24 07:35:50,441 
Results:
- F1-score (micro) 0.9762
- F1-score (macro) 0.9788

By class:
SENT       tp: 271 - fp: 13 - fn: 11 - precision: 0.9542 - recall: 0.9610 - f1-score: 0.9576
X          tp: 221 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-24 07:35:50,441 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.sdrt.stac/
2021-07-24 07:35:50,477 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.sdrt.stac
2021-07-24 07:35:50,479 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.sdrt.stac/sent_train.txt
2021-07-24 07:35:50,481 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.sdrt.stac/sent_dev.txt
2021-07-24 07:35:50,483 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.sdrt.stac/sent_test.txt
Corpus: 10164 train + 1406 dev + 2068 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-24 07:35:53,883 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:53,885 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-24 07:35:53,885 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:53,885 Corpus: "Corpus: 10164 train + 1406 dev + 2068 test sentences"
2021-07-24 07:35:53,885 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:53,885 Parameters:
2021-07-24 07:35:53,885  - learning_rate: "3e-05"
2021-07-24 07:35:53,885  - mini_batch_size: "32"
2021-07-24 07:35:53,885  - patience: "3"
2021-07-24 07:35:53,885  - anneal_factor: "0.5"
2021-07-24 07:35:53,885  - max_epochs: "40"
2021-07-24 07:35:53,886  - shuffle: "True"
2021-07-24 07:35:53,886  - train_with_dev: "False"
2021-07-24 07:35:53,886  - batch_growth_annealing: "False"
2021-07-24 07:35:53,886 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:53,886 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.sdrt.stac"
2021-07-24 07:35:53,886 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:53,886 Device: cuda:0
2021-07-24 07:35:53,886 ----------------------------------------------------------------------------------------------------
2021-07-24 07:35:53,886 Embeddings storage mode: cpu
2021-07-24 07:35:53,889 ----------------------------------------------------------------------------------------------------
2021-07-24 07:36:09,330 epoch 1 - iter 31/318 - loss 9.32615457 - samples/sec: 64.25 - lr: 0.000030
2021-07-24 07:36:23,947 epoch 1 - iter 62/318 - loss 7.36586340 - samples/sec: 67.87 - lr: 0.000030
2021-07-24 07:36:38,692 epoch 1 - iter 93/318 - loss 6.29060805 - samples/sec: 67.29 - lr: 0.000030
2021-07-24 07:36:53,418 epoch 1 - iter 124/318 - loss 5.39996489 - samples/sec: 67.37 - lr: 0.000030
2021-07-24 07:37:08,151 epoch 1 - iter 155/318 - loss 4.66709351 - samples/sec: 67.34 - lr: 0.000030
2021-07-24 07:37:22,695 epoch 1 - iter 186/318 - loss 4.08068822 - samples/sec: 68.21 - lr: 0.000030
2021-07-24 07:37:37,361 epoch 1 - iter 217/318 - loss 3.63213164 - samples/sec: 67.65 - lr: 0.000030
2021-07-24 07:37:52,104 epoch 1 - iter 248/318 - loss 3.26622661 - samples/sec: 67.29 - lr: 0.000030
2021-07-24 07:38:06,676 epoch 1 - iter 279/318 - loss 2.97433393 - samples/sec: 68.08 - lr: 0.000030
2021-07-24 07:38:21,244 epoch 1 - iter 310/318 - loss 2.73401909 - samples/sec: 68.10 - lr: 0.000030
2021-07-24 07:38:24,834 ----------------------------------------------------------------------------------------------------
2021-07-24 07:38:24,834 EPOCH 1 done: loss 2.6777 - lr 0.0000300
2021-07-24 07:38:40,738 DEV : loss 0.3870135247707367 - score 0.9309
2021-07-24 07:38:40,759 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:38:41,331 ----------------------------------------------------------------------------------------------------
2021-07-24 07:38:46,202 epoch 2 - iter 31/318 - loss 0.48880938 - samples/sec: 203.78 - lr: 0.000030
2021-07-24 07:38:51,110 epoch 2 - iter 62/318 - loss 0.47223048 - samples/sec: 202.20 - lr: 0.000030
2021-07-24 07:38:56,128 epoch 2 - iter 93/318 - loss 0.48214658 - samples/sec: 197.74 - lr: 0.000030
2021-07-24 07:39:01,046 epoch 2 - iter 124/318 - loss 0.47765330 - samples/sec: 201.76 - lr: 0.000030
2021-07-24 07:39:06,076 epoch 2 - iter 155/318 - loss 0.48913908 - samples/sec: 197.31 - lr: 0.000030
2021-07-24 07:39:11,062 epoch 2 - iter 186/318 - loss 0.48073825 - samples/sec: 199.00 - lr: 0.000030
2021-07-24 07:39:15,842 epoch 2 - iter 217/318 - loss 0.47759114 - samples/sec: 207.59 - lr: 0.000030
2021-07-24 07:39:20,871 epoch 2 - iter 248/318 - loss 0.47338791 - samples/sec: 197.34 - lr: 0.000030
2021-07-24 07:39:25,708 epoch 2 - iter 279/318 - loss 0.46740195 - samples/sec: 205.16 - lr: 0.000030
2021-07-24 07:39:30,607 epoch 2 - iter 310/318 - loss 0.46396719 - samples/sec: 202.56 - lr: 0.000030
2021-07-24 07:39:31,854 ----------------------------------------------------------------------------------------------------
2021-07-24 07:39:31,855 EPOCH 2 done: loss 0.4613 - lr 0.0000300
2021-07-24 07:39:34,153 DEV : loss 0.28946855664253235 - score 0.9327
2021-07-24 07:39:34,174 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:39:36,473 ----------------------------------------------------------------------------------------------------
2021-07-24 07:39:41,487 epoch 3 - iter 31/318 - loss 0.42298626 - samples/sec: 197.98 - lr: 0.000030
2021-07-24 07:39:46,279 epoch 3 - iter 62/318 - loss 0.38523347 - samples/sec: 207.09 - lr: 0.000030
2021-07-24 07:39:51,190 epoch 3 - iter 93/318 - loss 0.39337573 - samples/sec: 202.04 - lr: 0.000030
2021-07-24 07:39:56,122 epoch 3 - iter 124/318 - loss 0.40429291 - samples/sec: 201.21 - lr: 0.000030
2021-07-24 07:40:00,965 epoch 3 - iter 155/318 - loss 0.40004039 - samples/sec: 204.92 - lr: 0.000030
2021-07-24 07:40:06,035 epoch 3 - iter 186/318 - loss 0.40938500 - samples/sec: 195.71 - lr: 0.000030
2021-07-24 07:40:10,906 epoch 3 - iter 217/318 - loss 0.40705604 - samples/sec: 203.72 - lr: 0.000030
2021-07-24 07:40:15,883 epoch 3 - iter 248/318 - loss 0.40394604 - samples/sec: 199.42 - lr: 0.000030
2021-07-24 07:40:20,771 epoch 3 - iter 279/318 - loss 0.40543956 - samples/sec: 202.99 - lr: 0.000030
2021-07-24 07:40:25,779 epoch 3 - iter 310/318 - loss 0.40491009 - samples/sec: 198.15 - lr: 0.000030
2021-07-24 07:40:27,002 ----------------------------------------------------------------------------------------------------
2021-07-24 07:40:27,002 EPOCH 3 done: loss 0.4044 - lr 0.0000300
2021-07-24 07:40:29,291 DEV : loss 0.29047447443008423 - score 0.9332
2021-07-24 07:40:29,312 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:40:31,646 ----------------------------------------------------------------------------------------------------
2021-07-24 07:40:36,459 epoch 4 - iter 31/318 - loss 0.34924289 - samples/sec: 206.27 - lr: 0.000030
2021-07-24 07:40:41,358 epoch 4 - iter 62/318 - loss 0.36759027 - samples/sec: 202.56 - lr: 0.000030
2021-07-24 07:40:46,284 epoch 4 - iter 93/318 - loss 0.37106972 - samples/sec: 201.49 - lr: 0.000030
2021-07-24 07:40:51,364 epoch 4 - iter 124/318 - loss 0.37620248 - samples/sec: 195.33 - lr: 0.000030
2021-07-24 07:40:56,212 epoch 4 - iter 155/318 - loss 0.37886451 - samples/sec: 204.70 - lr: 0.000030
2021-07-24 07:41:01,092 epoch 4 - iter 186/318 - loss 0.37727541 - samples/sec: 203.34 - lr: 0.000030
2021-07-24 07:41:06,095 epoch 4 - iter 217/318 - loss 0.37595309 - samples/sec: 198.35 - lr: 0.000030
2021-07-24 07:41:11,123 epoch 4 - iter 248/318 - loss 0.37109936 - samples/sec: 197.35 - lr: 0.000030
2021-07-24 07:41:16,153 epoch 4 - iter 279/318 - loss 0.37441895 - samples/sec: 197.31 - lr: 0.000030
2021-07-24 07:41:21,074 epoch 4 - iter 310/318 - loss 0.37237891 - samples/sec: 201.66 - lr: 0.000030
2021-07-24 07:41:22,314 ----------------------------------------------------------------------------------------------------
2021-07-24 07:41:22,314 EPOCH 4 done: loss 0.3728 - lr 0.0000300
2021-07-24 07:41:24,602 DEV : loss 0.25009891390800476 - score 0.9441
2021-07-24 07:41:24,622 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:41:26,824 ----------------------------------------------------------------------------------------------------
2021-07-24 07:41:31,707 epoch 5 - iter 31/318 - loss 0.34321132 - samples/sec: 203.30 - lr: 0.000030
2021-07-24 07:41:36,713 epoch 5 - iter 62/318 - loss 0.34212699 - samples/sec: 198.23 - lr: 0.000030
2021-07-24 07:41:41,627 epoch 5 - iter 93/318 - loss 0.33984417 - samples/sec: 201.96 - lr: 0.000030
2021-07-24 07:41:46,555 epoch 5 - iter 124/318 - loss 0.34324649 - samples/sec: 201.37 - lr: 0.000030
2021-07-24 07:41:51,505 epoch 5 - iter 155/318 - loss 0.35534394 - samples/sec: 200.48 - lr: 0.000030
2021-07-24 07:41:56,506 epoch 5 - iter 186/318 - loss 0.35750893 - samples/sec: 198.42 - lr: 0.000030
2021-07-24 07:42:01,319 epoch 5 - iter 217/318 - loss 0.35771554 - samples/sec: 206.17 - lr: 0.000030
2021-07-24 07:42:06,278 epoch 5 - iter 248/318 - loss 0.35786971 - samples/sec: 200.14 - lr: 0.000030
2021-07-24 07:42:11,311 epoch 5 - iter 279/318 - loss 0.35822769 - samples/sec: 197.16 - lr: 0.000030
2021-07-24 07:42:16,306 epoch 5 - iter 310/318 - loss 0.36084055 - samples/sec: 198.69 - lr: 0.000030
2021-07-24 07:42:17,562 ----------------------------------------------------------------------------------------------------
2021-07-24 07:42:17,562 EPOCH 5 done: loss 0.3600 - lr 0.0000300
2021-07-24 07:42:19,829 DEV : loss 0.253970205783844 - score 0.9422
2021-07-24 07:42:19,850 BAD EPOCHS (no improvement): 1
2021-07-24 07:42:19,850 ----------------------------------------------------------------------------------------------------
2021-07-24 07:42:24,771 epoch 6 - iter 31/318 - loss 0.36030709 - samples/sec: 201.71 - lr: 0.000030
2021-07-24 07:42:29,712 epoch 6 - iter 62/318 - loss 0.35610929 - samples/sec: 200.86 - lr: 0.000030
2021-07-24 07:42:34,706 epoch 6 - iter 93/318 - loss 0.35419427 - samples/sec: 198.69 - lr: 0.000030
2021-07-24 07:42:39,604 epoch 6 - iter 124/318 - loss 0.35424614 - samples/sec: 202.62 - lr: 0.000030
2021-07-24 07:42:44,568 epoch 6 - iter 155/318 - loss 0.35935908 - samples/sec: 199.89 - lr: 0.000030
2021-07-24 07:42:49,499 epoch 6 - iter 186/318 - loss 0.35890862 - samples/sec: 201.27 - lr: 0.000030
2021-07-24 07:42:54,486 epoch 6 - iter 217/318 - loss 0.35566277 - samples/sec: 198.97 - lr: 0.000030
2021-07-24 07:42:59,402 epoch 6 - iter 248/318 - loss 0.34850646 - samples/sec: 201.86 - lr: 0.000030
2021-07-24 07:43:04,344 epoch 6 - iter 279/318 - loss 0.34904500 - samples/sec: 200.82 - lr: 0.000030
2021-07-24 07:43:09,369 epoch 6 - iter 310/318 - loss 0.34608098 - samples/sec: 197.47 - lr: 0.000030
2021-07-24 07:43:10,565 ----------------------------------------------------------------------------------------------------
2021-07-24 07:43:10,566 EPOCH 6 done: loss 0.3455 - lr 0.0000300
2021-07-24 07:43:12,834 DEV : loss 0.25884026288986206 - score 0.9411
2021-07-24 07:43:12,854 BAD EPOCHS (no improvement): 2
2021-07-24 07:43:12,855 ----------------------------------------------------------------------------------------------------
2021-07-24 07:43:17,784 epoch 7 - iter 31/318 - loss 0.33988282 - samples/sec: 201.37 - lr: 0.000030
2021-07-24 07:43:22,803 epoch 7 - iter 62/318 - loss 0.34070166 - samples/sec: 197.73 - lr: 0.000030
2021-07-24 07:43:27,768 epoch 7 - iter 93/318 - loss 0.34476981 - samples/sec: 199.86 - lr: 0.000030
2021-07-24 07:43:32,610 epoch 7 - iter 124/318 - loss 0.34036167 - samples/sec: 204.95 - lr: 0.000030
2021-07-24 07:43:37,448 epoch 7 - iter 155/318 - loss 0.34269070 - samples/sec: 205.13 - lr: 0.000030
2021-07-24 07:43:42,374 epoch 7 - iter 186/318 - loss 0.34641160 - samples/sec: 201.42 - lr: 0.000030
2021-07-24 07:43:47,337 epoch 7 - iter 217/318 - loss 0.34495996 - samples/sec: 199.95 - lr: 0.000030
2021-07-24 07:43:52,303 epoch 7 - iter 248/318 - loss 0.34930746 - samples/sec: 199.84 - lr: 0.000030
2021-07-24 07:43:57,318 epoch 7 - iter 279/318 - loss 0.34884490 - samples/sec: 197.87 - lr: 0.000030
2021-07-24 07:44:02,284 epoch 7 - iter 310/318 - loss 0.34703817 - samples/sec: 199.83 - lr: 0.000030
2021-07-24 07:44:03,514 ----------------------------------------------------------------------------------------------------
2021-07-24 07:44:03,514 EPOCH 7 done: loss 0.3463 - lr 0.0000300
2021-07-24 07:44:05,790 DEV : loss 0.23883722722530365 - score 0.9466
2021-07-24 07:44:05,811 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:44:08,081 ----------------------------------------------------------------------------------------------------
2021-07-24 07:44:12,975 epoch 8 - iter 31/318 - loss 0.36213919 - samples/sec: 202.84 - lr: 0.000030
2021-07-24 07:44:17,939 epoch 8 - iter 62/318 - loss 0.33813214 - samples/sec: 199.92 - lr: 0.000030
2021-07-24 07:44:22,867 epoch 8 - iter 93/318 - loss 0.32928549 - samples/sec: 201.36 - lr: 0.000030
2021-07-24 07:44:27,656 epoch 8 - iter 124/318 - loss 0.33373476 - samples/sec: 207.24 - lr: 0.000030
2021-07-24 07:44:32,415 epoch 8 - iter 155/318 - loss 0.32691193 - samples/sec: 208.51 - lr: 0.000030
2021-07-24 07:44:37,347 epoch 8 - iter 186/318 - loss 0.32641127 - samples/sec: 201.18 - lr: 0.000030
2021-07-24 07:44:42,250 epoch 8 - iter 217/318 - loss 0.32588722 - samples/sec: 202.42 - lr: 0.000030
2021-07-24 07:44:47,214 epoch 8 - iter 248/318 - loss 0.33214646 - samples/sec: 199.91 - lr: 0.000030
2021-07-24 07:44:52,125 epoch 8 - iter 279/318 - loss 0.33090358 - samples/sec: 202.07 - lr: 0.000030
2021-07-24 07:44:57,102 epoch 8 - iter 310/318 - loss 0.32594834 - samples/sec: 199.39 - lr: 0.000030
2021-07-24 07:44:58,270 ----------------------------------------------------------------------------------------------------
2021-07-24 07:44:58,270 EPOCH 8 done: loss 0.3259 - lr 0.0000300
2021-07-24 07:45:00,540 DEV : loss 0.24183325469493866 - score 0.9442
2021-07-24 07:45:00,561 BAD EPOCHS (no improvement): 1
2021-07-24 07:45:00,561 ----------------------------------------------------------------------------------------------------
2021-07-24 07:45:05,486 epoch 9 - iter 31/318 - loss 0.34182293 - samples/sec: 201.52 - lr: 0.000030
2021-07-24 07:45:10,355 epoch 9 - iter 62/318 - loss 0.32374789 - samples/sec: 203.84 - lr: 0.000030
2021-07-24 07:45:15,324 epoch 9 - iter 93/318 - loss 0.32315856 - samples/sec: 199.71 - lr: 0.000030
2021-07-24 07:45:20,245 epoch 9 - iter 124/318 - loss 0.32152899 - samples/sec: 201.65 - lr: 0.000030
2021-07-24 07:45:25,107 epoch 9 - iter 155/318 - loss 0.32783527 - samples/sec: 204.09 - lr: 0.000030
2021-07-24 07:45:30,095 epoch 9 - iter 186/318 - loss 0.32228016 - samples/sec: 198.96 - lr: 0.000030
2021-07-24 07:45:34,956 epoch 9 - iter 217/318 - loss 0.31641252 - samples/sec: 204.13 - lr: 0.000030
2021-07-24 07:45:39,831 epoch 9 - iter 248/318 - loss 0.31949946 - samples/sec: 203.55 - lr: 0.000030
2021-07-24 07:45:44,651 epoch 9 - iter 279/318 - loss 0.32034766 - samples/sec: 205.88 - lr: 0.000030
2021-07-24 07:45:49,679 epoch 9 - iter 310/318 - loss 0.31710628 - samples/sec: 197.37 - lr: 0.000030
2021-07-24 07:45:50,935 ----------------------------------------------------------------------------------------------------
2021-07-24 07:45:50,935 EPOCH 9 done: loss 0.3175 - lr 0.0000300
2021-07-24 07:45:53,224 DEV : loss 0.2654828727245331 - score 0.9419
2021-07-24 07:45:53,244 BAD EPOCHS (no improvement): 2
2021-07-24 07:45:53,245 ----------------------------------------------------------------------------------------------------
2021-07-24 07:45:58,178 epoch 10 - iter 31/318 - loss 0.28710380 - samples/sec: 201.20 - lr: 0.000030
2021-07-24 07:46:03,130 epoch 10 - iter 62/318 - loss 0.31075574 - samples/sec: 200.37 - lr: 0.000030
2021-07-24 07:46:08,033 epoch 10 - iter 93/318 - loss 0.32163874 - samples/sec: 202.42 - lr: 0.000030
2021-07-24 07:46:12,905 epoch 10 - iter 124/318 - loss 0.32663157 - samples/sec: 203.70 - lr: 0.000030
2021-07-24 07:46:17,865 epoch 10 - iter 155/318 - loss 0.32735113 - samples/sec: 200.06 - lr: 0.000030
2021-07-24 07:46:22,781 epoch 10 - iter 186/318 - loss 0.32545108 - samples/sec: 201.89 - lr: 0.000030
2021-07-24 07:46:27,671 epoch 10 - iter 217/318 - loss 0.32326644 - samples/sec: 202.97 - lr: 0.000030
2021-07-24 07:46:32,610 epoch 10 - iter 248/318 - loss 0.32594807 - samples/sec: 200.90 - lr: 0.000030
2021-07-24 07:46:37,630 epoch 10 - iter 279/318 - loss 0.32351543 - samples/sec: 197.69 - lr: 0.000030
2021-07-24 07:46:42,628 epoch 10 - iter 310/318 - loss 0.32241729 - samples/sec: 198.56 - lr: 0.000030
2021-07-24 07:46:43,842 ----------------------------------------------------------------------------------------------------
2021-07-24 07:46:43,842 EPOCH 10 done: loss 0.3219 - lr 0.0000300
2021-07-24 07:46:46,114 DEV : loss 0.24571169912815094 - score 0.9431
2021-07-24 07:46:46,134 BAD EPOCHS (no improvement): 3
2021-07-24 07:46:46,135 ----------------------------------------------------------------------------------------------------
2021-07-24 07:46:51,053 epoch 11 - iter 31/318 - loss 0.33135203 - samples/sec: 201.79 - lr: 0.000030
2021-07-24 07:46:55,943 epoch 11 - iter 62/318 - loss 0.31685346 - samples/sec: 202.96 - lr: 0.000030
2021-07-24 07:47:00,938 epoch 11 - iter 93/318 - loss 0.31525247 - samples/sec: 198.68 - lr: 0.000030
2021-07-24 07:47:05,848 epoch 11 - iter 124/318 - loss 0.31829282 - samples/sec: 202.11 - lr: 0.000030
2021-07-24 07:47:10,871 epoch 11 - iter 155/318 - loss 0.31952966 - samples/sec: 197.56 - lr: 0.000030
2021-07-24 07:47:15,906 epoch 11 - iter 186/318 - loss 0.31760514 - samples/sec: 197.10 - lr: 0.000030
2021-07-24 07:47:20,896 epoch 11 - iter 217/318 - loss 0.31173110 - samples/sec: 198.86 - lr: 0.000030
2021-07-24 07:47:25,851 epoch 11 - iter 248/318 - loss 0.31353820 - samples/sec: 200.24 - lr: 0.000030
2021-07-24 07:47:30,755 epoch 11 - iter 279/318 - loss 0.31687195 - samples/sec: 202.35 - lr: 0.000030
2021-07-24 07:47:35,654 epoch 11 - iter 310/318 - loss 0.31670196 - samples/sec: 202.60 - lr: 0.000030
2021-07-24 07:47:36,874 ----------------------------------------------------------------------------------------------------
2021-07-24 07:47:36,875 EPOCH 11 done: loss 0.3172 - lr 0.0000300
2021-07-24 07:47:39,146 DEV : loss 0.22918838262557983 - score 0.9462
Epoch    11: reducing learning rate of group 0 to 1.5000e-05.
2021-07-24 07:47:39,167 BAD EPOCHS (no improvement): 4
2021-07-24 07:47:39,167 ----------------------------------------------------------------------------------------------------
2021-07-24 07:47:44,048 epoch 12 - iter 31/318 - loss 0.31671760 - samples/sec: 203.37 - lr: 0.000015
2021-07-24 07:47:48,980 epoch 12 - iter 62/318 - loss 0.32134007 - samples/sec: 201.21 - lr: 0.000015
2021-07-24 07:47:53,914 epoch 12 - iter 93/318 - loss 0.31380719 - samples/sec: 201.11 - lr: 0.000015
2021-07-24 07:47:58,996 epoch 12 - iter 124/318 - loss 0.31876308 - samples/sec: 195.25 - lr: 0.000015
2021-07-24 07:48:03,923 epoch 12 - iter 155/318 - loss 0.32024149 - samples/sec: 201.43 - lr: 0.000015
2021-07-24 07:48:08,878 epoch 12 - iter 186/318 - loss 0.31545630 - samples/sec: 200.27 - lr: 0.000015
2021-07-24 07:48:13,760 epoch 12 - iter 217/318 - loss 0.31165724 - samples/sec: 203.28 - lr: 0.000015
2021-07-24 07:48:18,699 epoch 12 - iter 248/318 - loss 0.31330040 - samples/sec: 200.91 - lr: 0.000015
2021-07-24 07:48:23,714 epoch 12 - iter 279/318 - loss 0.31369560 - samples/sec: 197.85 - lr: 0.000015
2021-07-24 07:48:28,610 epoch 12 - iter 310/318 - loss 0.31606493 - samples/sec: 202.69 - lr: 0.000015
2021-07-24 07:48:29,872 ----------------------------------------------------------------------------------------------------
2021-07-24 07:48:29,872 EPOCH 12 done: loss 0.3169 - lr 0.0000150
2021-07-24 07:48:32,144 DEV : loss 0.23450498282909393 - score 0.9462
2021-07-24 07:48:32,165 BAD EPOCHS (no improvement): 1
2021-07-24 07:48:32,165 ----------------------------------------------------------------------------------------------------
2021-07-24 07:48:37,114 epoch 13 - iter 31/318 - loss 0.29601070 - samples/sec: 200.55 - lr: 0.000015
2021-07-24 07:48:42,052 epoch 13 - iter 62/318 - loss 0.31781547 - samples/sec: 200.98 - lr: 0.000015
2021-07-24 07:48:47,039 epoch 13 - iter 93/318 - loss 0.32409500 - samples/sec: 198.97 - lr: 0.000015
2021-07-24 07:48:51,920 epoch 13 - iter 124/318 - loss 0.32376595 - samples/sec: 203.32 - lr: 0.000015
2021-07-24 07:48:56,794 epoch 13 - iter 155/318 - loss 0.31500319 - samples/sec: 203.57 - lr: 0.000015
2021-07-24 07:49:01,750 epoch 13 - iter 186/318 - loss 0.31235237 - samples/sec: 200.25 - lr: 0.000015
2021-07-24 07:49:06,706 epoch 13 - iter 217/318 - loss 0.31260552 - samples/sec: 200.22 - lr: 0.000015
2021-07-24 07:49:11,684 epoch 13 - iter 248/318 - loss 0.31083235 - samples/sec: 199.36 - lr: 0.000015
2021-07-24 07:49:16,656 epoch 13 - iter 279/318 - loss 0.30976215 - samples/sec: 199.58 - lr: 0.000015
2021-07-24 07:49:21,606 epoch 13 - iter 310/318 - loss 0.31043091 - samples/sec: 200.47 - lr: 0.000015
2021-07-24 07:49:22,878 ----------------------------------------------------------------------------------------------------
2021-07-24 07:49:22,878 EPOCH 13 done: loss 0.3093 - lr 0.0000150
2021-07-24 07:49:25,151 DEV : loss 0.2438027262687683 - score 0.9442
2021-07-24 07:49:25,172 BAD EPOCHS (no improvement): 2
2021-07-24 07:49:25,172 ----------------------------------------------------------------------------------------------------
2021-07-24 07:49:30,103 epoch 14 - iter 31/318 - loss 0.30198446 - samples/sec: 201.30 - lr: 0.000015
2021-07-24 07:49:35,023 epoch 14 - iter 62/318 - loss 0.29989961 - samples/sec: 201.72 - lr: 0.000015
2021-07-24 07:49:39,934 epoch 14 - iter 93/318 - loss 0.29783616 - samples/sec: 202.05 - lr: 0.000015
2021-07-24 07:49:44,884 epoch 14 - iter 124/318 - loss 0.30678346 - samples/sec: 200.50 - lr: 0.000015
2021-07-24 07:49:49,873 epoch 14 - iter 155/318 - loss 0.31464694 - samples/sec: 198.90 - lr: 0.000015
2021-07-24 07:49:54,854 epoch 14 - iter 186/318 - loss 0.31589923 - samples/sec: 199.22 - lr: 0.000015
2021-07-24 07:49:59,775 epoch 14 - iter 217/318 - loss 0.31525407 - samples/sec: 201.67 - lr: 0.000015
2021-07-24 07:50:04,690 epoch 14 - iter 248/318 - loss 0.31389431 - samples/sec: 201.89 - lr: 0.000015
2021-07-24 07:50:09,603 epoch 14 - iter 279/318 - loss 0.31064909 - samples/sec: 202.01 - lr: 0.000015
2021-07-24 07:50:14,523 epoch 14 - iter 310/318 - loss 0.31282095 - samples/sec: 201.68 - lr: 0.000015
2021-07-24 07:50:15,758 ----------------------------------------------------------------------------------------------------
2021-07-24 07:50:15,759 EPOCH 14 done: loss 0.3104 - lr 0.0000150
2021-07-24 07:50:18,044 DEV : loss 0.23132552206516266 - score 0.9474
2021-07-24 07:50:18,065 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:50:20,406 ----------------------------------------------------------------------------------------------------
2021-07-24 07:50:25,473 epoch 15 - iter 31/318 - loss 0.29398085 - samples/sec: 195.92 - lr: 0.000015
2021-07-24 07:50:30,344 epoch 15 - iter 62/318 - loss 0.28545883 - samples/sec: 203.75 - lr: 0.000015
2021-07-24 07:50:35,219 epoch 15 - iter 93/318 - loss 0.28980538 - samples/sec: 203.55 - lr: 0.000015
2021-07-24 07:50:40,146 epoch 15 - iter 124/318 - loss 0.29925295 - samples/sec: 201.41 - lr: 0.000015
2021-07-24 07:50:45,089 epoch 15 - iter 155/318 - loss 0.30015880 - samples/sec: 200.78 - lr: 0.000015
2021-07-24 07:50:49,959 epoch 15 - iter 186/318 - loss 0.30764634 - samples/sec: 203.75 - lr: 0.000015
2021-07-24 07:50:54,810 epoch 15 - iter 217/318 - loss 0.31006488 - samples/sec: 204.56 - lr: 0.000015
2021-07-24 07:50:59,734 epoch 15 - iter 248/318 - loss 0.31247293 - samples/sec: 201.54 - lr: 0.000015
2021-07-24 07:51:04,730 epoch 15 - iter 279/318 - loss 0.31497262 - samples/sec: 198.62 - lr: 0.000015
2021-07-24 07:51:09,727 epoch 15 - iter 310/318 - loss 0.31187063 - samples/sec: 198.61 - lr: 0.000015
2021-07-24 07:51:10,987 ----------------------------------------------------------------------------------------------------
2021-07-24 07:51:10,987 EPOCH 15 done: loss 0.3110 - lr 0.0000150
2021-07-24 07:51:13,266 DEV : loss 0.24600844085216522 - score 0.9447
2021-07-24 07:51:13,287 BAD EPOCHS (no improvement): 1
2021-07-24 07:51:13,287 ----------------------------------------------------------------------------------------------------
2021-07-24 07:51:18,156 epoch 16 - iter 31/318 - loss 0.28372874 - samples/sec: 203.89 - lr: 0.000015
2021-07-24 07:51:23,132 epoch 16 - iter 62/318 - loss 0.29950891 - samples/sec: 199.43 - lr: 0.000015
2021-07-24 07:51:28,078 epoch 16 - iter 93/318 - loss 0.29985066 - samples/sec: 200.61 - lr: 0.000015
2021-07-24 07:51:32,923 epoch 16 - iter 124/318 - loss 0.29291536 - samples/sec: 204.83 - lr: 0.000015
2021-07-24 07:51:37,882 epoch 16 - iter 155/318 - loss 0.29569525 - samples/sec: 200.11 - lr: 0.000015
2021-07-24 07:51:42,887 epoch 16 - iter 186/318 - loss 0.29905313 - samples/sec: 198.28 - lr: 0.000015
2021-07-24 07:51:47,850 epoch 16 - iter 217/318 - loss 0.29664498 - samples/sec: 199.94 - lr: 0.000015
2021-07-24 07:51:52,846 epoch 16 - iter 248/318 - loss 0.29901446 - samples/sec: 198.65 - lr: 0.000015
2021-07-24 07:51:57,698 epoch 16 - iter 279/318 - loss 0.29819485 - samples/sec: 204.52 - lr: 0.000015
2021-07-24 07:52:02,804 epoch 16 - iter 310/318 - loss 0.29686630 - samples/sec: 194.33 - lr: 0.000015
2021-07-24 07:52:04,032 ----------------------------------------------------------------------------------------------------
2021-07-24 07:52:04,032 EPOCH 16 done: loss 0.2975 - lr 0.0000150
2021-07-24 07:52:06,310 DEV : loss 0.22766627371311188 - score 0.9463
2021-07-24 07:52:06,331 BAD EPOCHS (no improvement): 2
2021-07-24 07:52:06,331 ----------------------------------------------------------------------------------------------------
2021-07-24 07:52:11,114 epoch 17 - iter 31/318 - loss 0.28437949 - samples/sec: 207.50 - lr: 0.000015
2021-07-24 07:52:16,114 epoch 17 - iter 62/318 - loss 0.29774792 - samples/sec: 198.49 - lr: 0.000015
2021-07-24 07:52:21,055 epoch 17 - iter 93/318 - loss 0.29354597 - samples/sec: 200.81 - lr: 0.000015
2021-07-24 07:52:26,059 epoch 17 - iter 124/318 - loss 0.29958644 - samples/sec: 198.33 - lr: 0.000015
2021-07-24 07:52:30,963 epoch 17 - iter 155/318 - loss 0.29682253 - samples/sec: 202.34 - lr: 0.000015
2021-07-24 07:52:35,893 epoch 17 - iter 186/318 - loss 0.29796240 - samples/sec: 201.28 - lr: 0.000015
2021-07-24 07:52:40,881 epoch 17 - iter 217/318 - loss 0.29630010 - samples/sec: 198.96 - lr: 0.000015
2021-07-24 07:52:45,845 epoch 17 - iter 248/318 - loss 0.29661086 - samples/sec: 199.90 - lr: 0.000015
2021-07-24 07:52:50,785 epoch 17 - iter 279/318 - loss 0.29674846 - samples/sec: 200.91 - lr: 0.000015
2021-07-24 07:52:55,767 epoch 17 - iter 310/318 - loss 0.29770846 - samples/sec: 199.22 - lr: 0.000015
2021-07-24 07:52:56,992 ----------------------------------------------------------------------------------------------------
2021-07-24 07:52:56,992 EPOCH 17 done: loss 0.2974 - lr 0.0000150
2021-07-24 07:52:59,267 DEV : loss 0.22727182507514954 - score 0.947
2021-07-24 07:52:59,288 BAD EPOCHS (no improvement): 3
2021-07-24 07:52:59,288 ----------------------------------------------------------------------------------------------------
2021-07-24 07:53:04,256 epoch 18 - iter 31/318 - loss 0.28889274 - samples/sec: 199.83 - lr: 0.000015
2021-07-24 07:53:09,105 epoch 18 - iter 62/318 - loss 0.28473051 - samples/sec: 204.66 - lr: 0.000015
2021-07-24 07:53:14,061 epoch 18 - iter 93/318 - loss 0.27998264 - samples/sec: 200.24 - lr: 0.000015
2021-07-24 07:53:18,989 epoch 18 - iter 124/318 - loss 0.29126649 - samples/sec: 201.39 - lr: 0.000015
2021-07-24 07:53:23,841 epoch 18 - iter 155/318 - loss 0.29047169 - samples/sec: 204.52 - lr: 0.000015
2021-07-24 07:53:28,812 epoch 18 - iter 186/318 - loss 0.29592517 - samples/sec: 199.64 - lr: 0.000015
2021-07-24 07:53:33,670 epoch 18 - iter 217/318 - loss 0.29778211 - samples/sec: 204.28 - lr: 0.000015
2021-07-24 07:53:38,670 epoch 18 - iter 248/318 - loss 0.29678391 - samples/sec: 198.49 - lr: 0.000015
2021-07-24 07:53:43,694 epoch 18 - iter 279/318 - loss 0.29559827 - samples/sec: 197.50 - lr: 0.000015
2021-07-24 07:53:48,667 epoch 18 - iter 310/318 - loss 0.29676784 - samples/sec: 199.56 - lr: 0.000015
2021-07-24 07:53:49,888 ----------------------------------------------------------------------------------------------------
2021-07-24 07:53:49,888 EPOCH 18 done: loss 0.2967 - lr 0.0000150
2021-07-24 07:53:52,155 DEV : loss 0.23131002485752106 - score 0.9477
2021-07-24 07:53:52,176 BAD EPOCHS (no improvement): 0
saving best model
2021-07-24 07:53:54,480 ----------------------------------------------------------------------------------------------------
2021-07-24 07:53:59,485 epoch 19 - iter 31/318 - loss 0.25786279 - samples/sec: 198.39 - lr: 0.000015
2021-07-24 07:54:04,427 epoch 19 - iter 62/318 - loss 0.28027585 - samples/sec: 200.80 - lr: 0.000015
2021-07-24 07:54:09,424 epoch 19 - iter 93/318 - loss 0.28092091 - samples/sec: 198.61 - lr: 0.000015
2021-07-24 07:54:14,362 epoch 19 - iter 124/318 - loss 0.28705395 - samples/sec: 200.99 - lr: 0.000015
2021-07-24 07:54:19,263 epoch 19 - iter 155/318 - loss 0.27707647 - samples/sec: 202.45 - lr: 0.000015
2021-07-24 07:54:24,178 epoch 19 - iter 186/318 - loss 0.27125915 - samples/sec: 201.93 - lr: 0.000015
2021-07-24 07:54:29,140 epoch 19 - iter 217/318 - loss 0.27236679 - samples/sec: 199.99 - lr: 0.000015
2021-07-24 07:54:34,011 epoch 19 - iter 248/318 - loss 0.27626568 - samples/sec: 203.70 - lr: 0.000015
2021-07-24 07:54:38,960 epoch 19 - iter 279/318 - loss 0.28230223 - samples/sec: 200.53 - lr: 0.000015
2021-07-24 07:54:43,970 epoch 19 - iter 310/318 - loss 0.28202915 - samples/sec: 198.05 - lr: 0.000015
2021-07-24 07:54:45,179 ----------------------------------------------------------------------------------------------------
2021-07-24 07:54:45,180 EPOCH 19 done: loss 0.2819 - lr 0.0000150
2021-07-24 07:54:47,466 DEV : loss 0.2257491797208786 - score 0.947
2021-07-24 07:54:47,487 BAD EPOCHS (no improvement): 1
2021-07-24 07:54:47,487 ----------------------------------------------------------------------------------------------------
2021-07-24 07:54:52,455 epoch 20 - iter 31/318 - loss 0.30330492 - samples/sec: 199.81 - lr: 0.000015
2021-07-24 07:54:57,338 epoch 20 - iter 62/318 - loss 0.30119807 - samples/sec: 203.22 - lr: 0.000015
2021-07-24 07:55:02,361 epoch 20 - iter 93/318 - loss 0.30262616 - samples/sec: 197.55 - lr: 0.000015
2021-07-24 07:55:07,245 epoch 20 - iter 124/318 - loss 0.29420822 - samples/sec: 203.20 - lr: 0.000015
2021-07-24 07:55:12,160 epoch 20 - iter 155/318 - loss 0.28951124 - samples/sec: 201.90 - lr: 0.000015
2021-07-24 07:55:17,066 epoch 20 - iter 186/318 - loss 0.28689397 - samples/sec: 202.26 - lr: 0.000015
2021-07-24 07:55:22,071 epoch 20 - iter 217/318 - loss 0.28807387 - samples/sec: 198.29 - lr: 0.000015
2021-07-24 07:55:26,976 epoch 20 - iter 248/318 - loss 0.28817539 - samples/sec: 202.31 - lr: 0.000015
2021-07-24 07:55:31,782 epoch 20 - iter 279/318 - loss 0.29004343 - samples/sec: 206.49 - lr: 0.000015
2021-07-24 07:55:36,631 epoch 20 - iter 310/318 - loss 0.29038310 - samples/sec: 204.65 - lr: 0.000015
2021-07-24 07:55:37,827 ----------------------------------------------------------------------------------------------------
2021-07-24 07:55:37,827 EPOCH 20 done: loss 0.2909 - lr 0.0000150
2021-07-24 07:55:40,096 DEV : loss 0.22675155103206635 - score 0.9475
2021-07-24 07:55:40,117 BAD EPOCHS (no improvement): 2
2021-07-24 07:55:40,117 ----------------------------------------------------------------------------------------------------
2021-07-24 07:55:45,038 epoch 21 - iter 31/318 - loss 0.30155232 - samples/sec: 201.69 - lr: 0.000015
2021-07-24 07:55:49,855 epoch 21 - iter 62/318 - loss 0.30561652 - samples/sec: 206.02 - lr: 0.000015
2021-07-24 07:55:54,817 epoch 21 - iter 93/318 - loss 0.28700291 - samples/sec: 199.99 - lr: 0.000015
2021-07-24 07:55:59,840 epoch 21 - iter 124/318 - loss 0.28352823 - samples/sec: 197.57 - lr: 0.000015
2021-07-24 07:56:04,650 epoch 21 - iter 155/318 - loss 0.28617127 - samples/sec: 206.29 - lr: 0.000015
2021-07-24 07:56:09,587 epoch 21 - iter 186/318 - loss 0.28441219 - samples/sec: 201.01 - lr: 0.000015
2021-07-24 07:56:14,465 epoch 21 - iter 217/318 - loss 0.28514129 - samples/sec: 203.43 - lr: 0.000015
2021-07-24 07:56:19,241 epoch 21 - iter 248/318 - loss 0.28297929 - samples/sec: 207.81 - lr: 0.000015
2021-07-24 07:56:24,147 epoch 21 - iter 279/318 - loss 0.28536746 - samples/sec: 202.28 - lr: 0.000015
2021-07-24 07:56:29,116 epoch 21 - iter 310/318 - loss 0.28553304 - samples/sec: 199.71 - lr: 0.000015
2021-07-24 07:56:30,326 ----------------------------------------------------------------------------------------------------
2021-07-24 07:56:30,326 EPOCH 21 done: loss 0.2861 - lr 0.0000150
2021-07-24 07:56:32,594 DEV : loss 0.22552649676799774 - score 0.947
2021-07-24 07:56:32,615 BAD EPOCHS (no improvement): 3
2021-07-24 07:56:32,615 ----------------------------------------------------------------------------------------------------
2021-07-24 07:56:37,474 epoch 22 - iter 31/318 - loss 0.28482319 - samples/sec: 204.28 - lr: 0.000015
2021-07-24 07:56:42,329 epoch 22 - iter 62/318 - loss 0.28097275 - samples/sec: 204.39 - lr: 0.000015
2021-07-24 07:56:47,235 epoch 22 - iter 93/318 - loss 0.27989157 - samples/sec: 202.29 - lr: 0.000015
2021-07-24 07:56:52,158 epoch 22 - iter 124/318 - loss 0.28214497 - samples/sec: 201.55 - lr: 0.000015
2021-07-24 07:56:57,115 epoch 22 - iter 155/318 - loss 0.28379546 - samples/sec: 200.19 - lr: 0.000015
2021-07-24 07:57:01,976 epoch 22 - iter 186/318 - loss 0.28082332 - samples/sec: 204.17 - lr: 0.000015
2021-07-24 07:57:06,845 epoch 22 - iter 217/318 - loss 0.28404129 - samples/sec: 203.80 - lr: 0.000015
2021-07-24 07:57:11,809 epoch 22 - iter 248/318 - loss 0.28685661 - samples/sec: 199.93 - lr: 0.000015
2021-07-24 07:57:16,752 epoch 22 - iter 279/318 - loss 0.28383090 - samples/sec: 200.79 - lr: 0.000015
2021-07-24 07:57:21,728 epoch 22 - iter 310/318 - loss 0.28003466 - samples/sec: 199.43 - lr: 0.000015
2021-07-24 07:57:22,946 ----------------------------------------------------------------------------------------------------
2021-07-24 07:57:22,946 EPOCH 22 done: loss 0.2789 - lr 0.0000150
2021-07-24 07:57:25,425 DEV : loss 0.22748994827270508 - score 0.9472
Epoch    22: reducing learning rate of group 0 to 7.5000e-06.
2021-07-24 07:57:25,446 BAD EPOCHS (no improvement): 4
2021-07-24 07:57:25,446 ----------------------------------------------------------------------------------------------------
2021-07-24 07:57:30,409 epoch 23 - iter 31/318 - loss 0.28377338 - samples/sec: 200.01 - lr: 0.000008
2021-07-24 07:57:35,419 epoch 23 - iter 62/318 - loss 0.26667087 - samples/sec: 198.08 - lr: 0.000008
2021-07-24 07:57:40,342 epoch 23 - iter 93/318 - loss 0.28497010 - samples/sec: 201.62 - lr: 0.000008
2021-07-24 07:57:45,358 epoch 23 - iter 124/318 - loss 0.27152218 - samples/sec: 197.81 - lr: 0.000008
2021-07-24 07:57:50,284 epoch 23 - iter 155/318 - loss 0.27168722 - samples/sec: 201.47 - lr: 0.000008
2021-07-24 07:57:55,312 epoch 23 - iter 186/318 - loss 0.27639761 - samples/sec: 197.35 - lr: 0.000008
2021-07-24 07:58:00,226 epoch 23 - iter 217/318 - loss 0.28101383 - samples/sec: 201.92 - lr: 0.000008
2021-07-24 07:58:05,151 epoch 23 - iter 248/318 - loss 0.28062997 - samples/sec: 201.51 - lr: 0.000008
2021-07-24 07:58:09,995 epoch 23 - iter 279/318 - loss 0.28018186 - samples/sec: 204.86 - lr: 0.000008
2021-07-24 07:58:14,925 epoch 23 - iter 310/318 - loss 0.27829926 - samples/sec: 201.27 - lr: 0.000008
2021-07-24 07:58:16,133 ----------------------------------------------------------------------------------------------------
2021-07-24 07:58:16,134 EPOCH 23 done: loss 0.2772 - lr 0.0000075
2021-07-24 07:58:18,416 DEV : loss 0.22869624197483063 - score 0.9476
2021-07-24 07:58:18,436 BAD EPOCHS (no improvement): 1
2021-07-24 07:58:18,436 ----------------------------------------------------------------------------------------------------
2021-07-24 07:58:23,358 epoch 24 - iter 31/318 - loss 0.30898678 - samples/sec: 201.68 - lr: 0.000008
2021-07-24 07:58:28,351 epoch 24 - iter 62/318 - loss 0.30280003 - samples/sec: 198.73 - lr: 0.000008
2021-07-24 07:58:33,264 epoch 24 - iter 93/318 - loss 0.28964984 - samples/sec: 202.00 - lr: 0.000008
2021-07-24 07:58:38,271 epoch 24 - iter 124/318 - loss 0.28462840 - samples/sec: 198.19 - lr: 0.000008
2021-07-24 07:58:43,211 epoch 24 - iter 155/318 - loss 0.28198216 - samples/sec: 200.91 - lr: 0.000008
2021-07-24 07:58:48,205 epoch 24 - iter 186/318 - loss 0.28094649 - samples/sec: 198.72 - lr: 0.000008
2021-07-24 07:58:53,186 epoch 24 - iter 217/318 - loss 0.27788766 - samples/sec: 199.22 - lr: 0.000008
2021-07-24 07:58:58,110 epoch 24 - iter 248/318 - loss 0.28142851 - samples/sec: 201.52 - lr: 0.000008
2021-07-24 07:59:02,974 epoch 24 - iter 279/318 - loss 0.28182543 - samples/sec: 204.02 - lr: 0.000008
2021-07-24 07:59:07,874 epoch 24 - iter 310/318 - loss 0.28208361 - samples/sec: 202.55 - lr: 0.000008
2021-07-24 07:59:09,116 ----------------------------------------------------------------------------------------------------
2021-07-24 07:59:09,116 EPOCH 24 done: loss 0.2816 - lr 0.0000075
2021-07-24 07:59:11,389 DEV : loss 0.2226114571094513 - score 0.9476
2021-07-24 07:59:11,409 BAD EPOCHS (no improvement): 2
2021-07-24 07:59:11,410 ----------------------------------------------------------------------------------------------------
2021-07-24 07:59:16,307 epoch 25 - iter 31/318 - loss 0.26165508 - samples/sec: 202.67 - lr: 0.000008
2021-07-24 07:59:21,295 epoch 25 - iter 62/318 - loss 0.27567858 - samples/sec: 198.97 - lr: 0.000008
2021-07-24 07:59:26,202 epoch 25 - iter 93/318 - loss 0.27445859 - samples/sec: 202.21 - lr: 0.000008
2021-07-24 07:59:31,015 epoch 25 - iter 124/318 - loss 0.28116087 - samples/sec: 206.19 - lr: 0.000008
2021-07-24 07:59:36,068 epoch 25 - iter 155/318 - loss 0.27865842 - samples/sec: 196.40 - lr: 0.000008
2021-07-24 07:59:40,870 epoch 25 - iter 186/318 - loss 0.28078492 - samples/sec: 206.64 - lr: 0.000008
2021-07-24 07:59:45,931 epoch 25 - iter 217/318 - loss 0.28321871 - samples/sec: 196.09 - lr: 0.000008
2021-07-24 07:59:50,932 epoch 25 - iter 248/318 - loss 0.28005759 - samples/sec: 198.43 - lr: 0.000008
2021-07-24 07:59:55,920 epoch 25 - iter 279/318 - loss 0.28207316 - samples/sec: 198.93 - lr: 0.000008
2021-07-24 08:00:00,922 epoch 25 - iter 310/318 - loss 0.28150701 - samples/sec: 198.39 - lr: 0.000008
2021-07-24 08:00:02,175 ----------------------------------------------------------------------------------------------------
2021-07-24 08:00:02,175 EPOCH 25 done: loss 0.2816 - lr 0.0000075
2021-07-24 08:00:04,447 DEV : loss 0.22350648045539856 - score 0.9473
2021-07-24 08:00:04,468 BAD EPOCHS (no improvement): 3
2021-07-24 08:00:04,468 ----------------------------------------------------------------------------------------------------
2021-07-24 08:00:09,539 epoch 26 - iter 31/318 - loss 0.24536292 - samples/sec: 195.76 - lr: 0.000008
2021-07-24 08:00:14,363 epoch 26 - iter 62/318 - loss 0.24250156 - samples/sec: 205.69 - lr: 0.000008
2021-07-24 08:00:19,187 epoch 26 - iter 93/318 - loss 0.24662046 - samples/sec: 205.71 - lr: 0.000008
2021-07-24 08:00:24,190 epoch 26 - iter 124/318 - loss 0.25842056 - samples/sec: 198.37 - lr: 0.000008
2021-07-24 08:00:29,174 epoch 26 - iter 155/318 - loss 0.26210149 - samples/sec: 199.08 - lr: 0.000008
2021-07-24 08:00:33,966 epoch 26 - iter 186/318 - loss 0.26727995 - samples/sec: 207.09 - lr: 0.000008
2021-07-24 08:00:38,899 epoch 26 - iter 217/318 - loss 0.27118970 - samples/sec: 201.17 - lr: 0.000008
2021-07-24 08:00:43,803 epoch 26 - iter 248/318 - loss 0.26989396 - samples/sec: 202.33 - lr: 0.000008
2021-07-24 08:00:48,806 epoch 26 - iter 279/318 - loss 0.26927239 - samples/sec: 198.38 - lr: 0.000008
2021-07-24 08:00:53,756 epoch 26 - iter 310/318 - loss 0.27167525 - samples/sec: 200.45 - lr: 0.000008
2021-07-24 08:00:54,994 ----------------------------------------------------------------------------------------------------
2021-07-24 08:00:54,995 EPOCH 26 done: loss 0.2736 - lr 0.0000075
2021-07-24 08:00:57,281 DEV : loss 0.2235613316297531 - score 0.9473
Epoch    26: reducing learning rate of group 0 to 3.7500e-06.
2021-07-24 08:00:57,302 BAD EPOCHS (no improvement): 4
2021-07-24 08:00:57,302 ----------------------------------------------------------------------------------------------------
2021-07-24 08:01:02,360 epoch 27 - iter 31/318 - loss 0.27140141 - samples/sec: 196.24 - lr: 0.000004
2021-07-24 08:01:07,347 epoch 27 - iter 62/318 - loss 0.27982409 - samples/sec: 198.98 - lr: 0.000004
2021-07-24 08:01:12,278 epoch 27 - iter 93/318 - loss 0.27398101 - samples/sec: 201.24 - lr: 0.000004
2021-07-24 08:01:17,250 epoch 27 - iter 124/318 - loss 0.27173690 - samples/sec: 199.56 - lr: 0.000004
2021-07-24 08:01:22,268 epoch 27 - iter 155/318 - loss 0.26816428 - samples/sec: 197.76 - lr: 0.000004
2021-07-24 08:01:27,111 epoch 27 - iter 186/318 - loss 0.26849427 - samples/sec: 204.89 - lr: 0.000004
2021-07-24 08:01:31,998 epoch 27 - iter 217/318 - loss 0.26668042 - samples/sec: 203.08 - lr: 0.000004
2021-07-24 08:01:36,790 epoch 27 - iter 248/318 - loss 0.26870247 - samples/sec: 207.10 - lr: 0.000004
2021-07-24 08:01:41,616 epoch 27 - iter 279/318 - loss 0.27108590 - samples/sec: 205.62 - lr: 0.000004
2021-07-24 08:01:46,475 epoch 27 - iter 310/318 - loss 0.27288090 - samples/sec: 204.22 - lr: 0.000004
2021-07-24 08:01:47,719 ----------------------------------------------------------------------------------------------------
2021-07-24 08:01:47,719 EPOCH 27 done: loss 0.2725 - lr 0.0000038
2021-07-24 08:01:49,988 DEV : loss 0.22430364787578583 - score 0.9474
2021-07-24 08:01:50,008 BAD EPOCHS (no improvement): 1
2021-07-24 08:01:50,009 ----------------------------------------------------------------------------------------------------
2021-07-24 08:01:54,815 epoch 28 - iter 31/318 - loss 0.28522720 - samples/sec: 206.53 - lr: 0.000004
2021-07-24 08:01:59,715 epoch 28 - iter 62/318 - loss 0.27175817 - samples/sec: 202.53 - lr: 0.000004
2021-07-24 08:02:04,549 epoch 28 - iter 93/318 - loss 0.26810327 - samples/sec: 205.27 - lr: 0.000004
2021-07-24 08:02:09,398 epoch 28 - iter 124/318 - loss 0.27564944 - samples/sec: 204.65 - lr: 0.000004
2021-07-24 08:02:14,399 epoch 28 - iter 155/318 - loss 0.27472260 - samples/sec: 198.40 - lr: 0.000004
2021-07-24 08:02:19,305 epoch 28 - iter 186/318 - loss 0.27530973 - samples/sec: 202.27 - lr: 0.000004
2021-07-24 08:02:24,258 epoch 28 - iter 217/318 - loss 0.27560304 - samples/sec: 200.38 - lr: 0.000004
2021-07-24 08:02:29,182 epoch 28 - iter 248/318 - loss 0.27642167 - samples/sec: 201.51 - lr: 0.000004
2021-07-24 08:02:34,174 epoch 28 - iter 279/318 - loss 0.27774443 - samples/sec: 198.79 - lr: 0.000004
2021-07-24 08:02:39,127 epoch 28 - iter 310/318 - loss 0.27941595 - samples/sec: 200.33 - lr: 0.000004
2021-07-24 08:02:40,408 ----------------------------------------------------------------------------------------------------
2021-07-24 08:02:40,408 EPOCH 28 done: loss 0.2788 - lr 0.0000038
2021-07-24 08:02:42,697 DEV : loss 0.22333410382270813 - score 0.9473
2021-07-24 08:02:42,717 BAD EPOCHS (no improvement): 2
2021-07-24 08:02:42,718 ----------------------------------------------------------------------------------------------------
2021-07-24 08:02:47,682 epoch 29 - iter 31/318 - loss 0.25140770 - samples/sec: 199.92 - lr: 0.000004
2021-07-24 08:02:52,551 epoch 29 - iter 62/318 - loss 0.24831182 - samples/sec: 203.82 - lr: 0.000004
2021-07-24 08:02:57,494 epoch 29 - iter 93/318 - loss 0.24305365 - samples/sec: 200.75 - lr: 0.000004
2021-07-24 08:03:02,532 epoch 29 - iter 124/318 - loss 0.24888724 - samples/sec: 196.99 - lr: 0.000004
2021-07-24 08:03:07,605 epoch 29 - iter 155/318 - loss 0.26108723 - samples/sec: 195.62 - lr: 0.000004
2021-07-24 08:03:12,572 epoch 29 - iter 186/318 - loss 0.26808197 - samples/sec: 199.79 - lr: 0.000004
2021-07-24 08:03:17,462 epoch 29 - iter 217/318 - loss 0.26627583 - samples/sec: 202.92 - lr: 0.000004
2021-07-24 08:03:22,395 epoch 29 - iter 248/318 - loss 0.26494762 - samples/sec: 201.16 - lr: 0.000004
2021-07-24 08:03:27,308 epoch 29 - iter 279/318 - loss 0.26579906 - samples/sec: 202.01 - lr: 0.000004
2021-07-24 08:03:32,233 epoch 29 - iter 310/318 - loss 0.26751143 - samples/sec: 201.47 - lr: 0.000004
2021-07-24 08:03:33,463 ----------------------------------------------------------------------------------------------------
2021-07-24 08:03:33,463 EPOCH 29 done: loss 0.2672 - lr 0.0000038
2021-07-24 08:03:35,737 DEV : loss 0.2246062010526657 - score 0.9474
2021-07-24 08:03:35,757 BAD EPOCHS (no improvement): 3
2021-07-24 08:03:35,758 ----------------------------------------------------------------------------------------------------
2021-07-24 08:03:40,814 epoch 30 - iter 31/318 - loss 0.25851097 - samples/sec: 196.29 - lr: 0.000004
2021-07-24 08:03:45,733 epoch 30 - iter 62/318 - loss 0.25850631 - samples/sec: 201.74 - lr: 0.000004
2021-07-24 08:03:50,551 epoch 30 - iter 93/318 - loss 0.26180178 - samples/sec: 205.96 - lr: 0.000004
2021-07-24 08:03:55,496 epoch 30 - iter 124/318 - loss 0.26284636 - samples/sec: 200.69 - lr: 0.000004
2021-07-24 08:04:00,490 epoch 30 - iter 155/318 - loss 0.26966322 - samples/sec: 198.72 - lr: 0.000004
2021-07-24 08:04:05,379 epoch 30 - iter 186/318 - loss 0.27419151 - samples/sec: 202.94 - lr: 0.000004
2021-07-24 08:04:10,351 epoch 30 - iter 217/318 - loss 0.27429183 - samples/sec: 199.60 - lr: 0.000004
2021-07-24 08:04:15,386 epoch 30 - iter 248/318 - loss 0.27134207 - samples/sec: 197.09 - lr: 0.000004
2021-07-24 08:04:20,315 epoch 30 - iter 279/318 - loss 0.27227579 - samples/sec: 201.32 - lr: 0.000004
2021-07-24 08:04:25,188 epoch 30 - iter 310/318 - loss 0.27369308 - samples/sec: 203.65 - lr: 0.000004
2021-07-24 08:04:26,435 ----------------------------------------------------------------------------------------------------
2021-07-24 08:04:26,436 EPOCH 30 done: loss 0.2738 - lr 0.0000038
2021-07-24 08:04:28,713 DEV : loss 0.22259019315242767 - score 0.9472
Epoch    30: reducing learning rate of group 0 to 1.8750e-06.
2021-07-24 08:04:28,734 BAD EPOCHS (no improvement): 4
2021-07-24 08:04:28,734 ----------------------------------------------------------------------------------------------------
2021-07-24 08:04:28,734 ----------------------------------------------------------------------------------------------------
2021-07-24 08:04:28,734 learning rate too small - quitting training!
2021-07-24 08:04:28,734 ----------------------------------------------------------------------------------------------------
2021-07-24 08:04:29,300 ----------------------------------------------------------------------------------------------------
2021-07-24 08:04:29,300 Testing using best model ...
2021-07-24 08:04:29,301 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-3/eng.sdrt.stac/best-model.pt
2021-07-24 08:04:54,167 0.9129	0.9827	0.9465
2021-07-24 08:04:54,167 
Results:
- F1-score (micro) 0.9465
- F1-score (macro) 0.9670

By class:
SENT       tp: 1406 - fp: 168 - fn: 31 - precision: 0.8933 - recall: 0.9784 - f1-score: 0.9339
X          tp: 354 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-24 08:04:54,167 ----------------------------------------------------------------------------------------------------
