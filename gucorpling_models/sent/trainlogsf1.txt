/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.pdtb.cdtb/
2021-07-15 13:17:42,745 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.pdtb.cdtb
2021-07-15 13:17:42,745 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.pdtb.cdtb/sent_train.txt
2021-07-15 13:17:42,745 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.pdtb.cdtb/sent_dev.txt
2021-07-15 13:17:42,746 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.pdtb.cdtb/sent_test.txt
Corpus: 1980 train + 541 dev + 558 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 13:17:48,457 ----------------------------------------------------------------------------------------------------
2021-07-15 13:17:48,458 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(21128, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 13:17:48,458 ----------------------------------------------------------------------------------------------------
2021-07-15 13:17:48,458 Corpus: "Corpus: 1980 train + 541 dev + 558 test sentences"
2021-07-15 13:17:48,458 ----------------------------------------------------------------------------------------------------
2021-07-15 13:17:48,459 Parameters:
2021-07-15 13:17:48,459  - learning_rate: "3e-05"
2021-07-15 13:17:48,459  - mini_batch_size: "32"
2021-07-15 13:17:48,459  - patience: "3"
2021-07-15 13:17:48,459  - anneal_factor: "0.5"
2021-07-15 13:17:48,459  - max_epochs: "40"
2021-07-15 13:17:48,459  - shuffle: "True"
2021-07-15 13:17:48,459  - train_with_dev: "False"
2021-07-15 13:17:48,459  - batch_growth_annealing: "False"
2021-07-15 13:17:48,459 ----------------------------------------------------------------------------------------------------
2021-07-15 13:17:48,459 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.pdtb.cdtb"
2021-07-15 13:17:48,459 ----------------------------------------------------------------------------------------------------
2021-07-15 13:17:48,459 Device: cuda:0
2021-07-15 13:17:48,459 ----------------------------------------------------------------------------------------------------
2021-07-15 13:17:48,459 Embeddings storage mode: cpu
2021-07-15 13:17:48,462 ----------------------------------------------------------------------------------------------------
2021-07-15 13:17:53,808 epoch 1 - iter 6/62 - loss 11.62264315 - samples/sec: 35.91 - lr: 0.000030
2021-07-15 13:17:59,157 epoch 1 - iter 12/62 - loss 8.23029725 - samples/sec: 35.90 - lr: 0.000030
2021-07-15 13:18:04,586 epoch 1 - iter 18/62 - loss 6.73687489 - samples/sec: 35.37 - lr: 0.000030
2021-07-15 13:18:10,025 epoch 1 - iter 24/62 - loss 5.87657663 - samples/sec: 35.30 - lr: 0.000030
2021-07-15 13:18:15,453 epoch 1 - iter 30/62 - loss 5.31772567 - samples/sec: 35.37 - lr: 0.000030
2021-07-15 13:18:21,088 epoch 1 - iter 36/62 - loss 4.93442172 - samples/sec: 34.08 - lr: 0.000030
2021-07-15 13:18:26,546 epoch 1 - iter 42/62 - loss 4.61445097 - samples/sec: 35.18 - lr: 0.000030
2021-07-15 13:18:32,047 epoch 1 - iter 48/62 - loss 4.33244538 - samples/sec: 34.91 - lr: 0.000030
2021-07-15 13:18:37,504 epoch 1 - iter 54/62 - loss 4.10181142 - samples/sec: 35.19 - lr: 0.000030
2021-07-15 13:18:43,034 epoch 1 - iter 60/62 - loss 3.91903801 - samples/sec: 34.72 - lr: 0.000030
2021-07-15 13:18:44,764 ----------------------------------------------------------------------------------------------------
2021-07-15 13:18:44,764 EPOCH 1 done: loss 3.8570 - lr 0.0000300
2021-07-15 13:18:54,349 DEV : loss 1.7670193910598755 - score 0.3979
2021-07-15 13:18:54,386 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:18:55,022 ----------------------------------------------------------------------------------------------------
2021-07-15 13:18:57,743 epoch 2 - iter 6/62 - loss 1.87169987 - samples/sec: 70.58 - lr: 0.000030
2021-07-15 13:19:00,476 epoch 2 - iter 12/62 - loss 1.85750622 - samples/sec: 70.27 - lr: 0.000030
2021-07-15 13:19:03,204 epoch 2 - iter 18/62 - loss 1.84495176 - samples/sec: 70.42 - lr: 0.000030
2021-07-15 13:19:05,949 epoch 2 - iter 24/62 - loss 1.77778117 - samples/sec: 69.96 - lr: 0.000030
2021-07-15 13:19:08,679 epoch 2 - iter 30/62 - loss 1.70691044 - samples/sec: 70.33 - lr: 0.000030
2021-07-15 13:19:11,408 epoch 2 - iter 36/62 - loss 1.64548856 - samples/sec: 70.39 - lr: 0.000030
2021-07-15 13:19:14,172 epoch 2 - iter 42/62 - loss 1.61328633 - samples/sec: 69.47 - lr: 0.000030
2021-07-15 13:19:17,111 epoch 2 - iter 48/62 - loss 1.58207032 - samples/sec: 65.35 - lr: 0.000030
2021-07-15 13:19:19,843 epoch 2 - iter 54/62 - loss 1.55943593 - samples/sec: 70.30 - lr: 0.000030
2021-07-15 13:19:22,564 epoch 2 - iter 60/62 - loss 1.53206850 - samples/sec: 70.58 - lr: 0.000030
2021-07-15 13:19:23,441 ----------------------------------------------------------------------------------------------------
2021-07-15 13:19:23,441 EPOCH 2 done: loss 1.5192 - lr 0.0000300
2021-07-15 13:19:26,080 DEV : loss 0.9939651489257812 - score 0.7696
2021-07-15 13:19:26,118 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:19:29,638 ----------------------------------------------------------------------------------------------------
2021-07-15 13:19:32,401 epoch 3 - iter 6/62 - loss 1.08072652 - samples/sec: 69.52 - lr: 0.000030
2021-07-15 13:19:35,136 epoch 3 - iter 12/62 - loss 1.10708157 - samples/sec: 70.21 - lr: 0.000030
2021-07-15 13:19:37,844 epoch 3 - iter 18/62 - loss 1.12243170 - samples/sec: 70.93 - lr: 0.000030
2021-07-15 13:19:40,583 epoch 3 - iter 24/62 - loss 1.12963290 - samples/sec: 70.09 - lr: 0.000030
2021-07-15 13:19:43,336 epoch 3 - iter 30/62 - loss 1.10779959 - samples/sec: 69.76 - lr: 0.000030
2021-07-15 13:19:46,080 epoch 3 - iter 36/62 - loss 1.06212804 - samples/sec: 69.98 - lr: 0.000030
2021-07-15 13:19:48,808 epoch 3 - iter 42/62 - loss 1.04166314 - samples/sec: 70.40 - lr: 0.000030
2021-07-15 13:19:51,566 epoch 3 - iter 48/62 - loss 1.01036300 - samples/sec: 69.64 - lr: 0.000030
2021-07-15 13:19:54,349 epoch 3 - iter 54/62 - loss 0.99629858 - samples/sec: 69.00 - lr: 0.000030
2021-07-15 13:19:57,103 epoch 3 - iter 60/62 - loss 0.98679592 - samples/sec: 69.72 - lr: 0.000030
2021-07-15 13:19:57,960 ----------------------------------------------------------------------------------------------------
2021-07-15 13:19:57,960 EPOCH 3 done: loss 0.9797 - lr 0.0000300
2021-07-15 13:20:00,603 DEV : loss 0.6802369356155396 - score 0.8592
2021-07-15 13:20:00,641 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:20:04,047 ----------------------------------------------------------------------------------------------------
2021-07-15 13:20:06,783 epoch 4 - iter 6/62 - loss 0.84804607 - samples/sec: 70.21 - lr: 0.000030
2021-07-15 13:20:09,512 epoch 4 - iter 12/62 - loss 0.81284314 - samples/sec: 70.37 - lr: 0.000030
2021-07-15 13:20:12,250 epoch 4 - iter 18/62 - loss 0.83011075 - samples/sec: 70.15 - lr: 0.000030
2021-07-15 13:20:15,008 epoch 4 - iter 24/62 - loss 0.80377473 - samples/sec: 69.63 - lr: 0.000030
2021-07-15 13:20:17,760 epoch 4 - iter 30/62 - loss 0.80576860 - samples/sec: 69.77 - lr: 0.000030
2021-07-15 13:20:20,509 epoch 4 - iter 36/62 - loss 0.78043222 - samples/sec: 69.87 - lr: 0.000030
2021-07-15 13:20:23,243 epoch 4 - iter 42/62 - loss 0.77152972 - samples/sec: 70.25 - lr: 0.000030
2021-07-15 13:20:26,012 epoch 4 - iter 48/62 - loss 0.74701578 - samples/sec: 69.34 - lr: 0.000030
2021-07-15 13:20:28,785 epoch 4 - iter 54/62 - loss 0.73190637 - samples/sec: 69.25 - lr: 0.000030
2021-07-15 13:20:31,549 epoch 4 - iter 60/62 - loss 0.71216032 - samples/sec: 69.49 - lr: 0.000030
2021-07-15 13:20:32,419 ----------------------------------------------------------------------------------------------------
2021-07-15 13:20:32,419 EPOCH 4 done: loss 0.7157 - lr 0.0000300
2021-07-15 13:20:35,055 DEV : loss 0.5649848580360413 - score 0.8858
2021-07-15 13:20:35,094 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:20:38,411 ----------------------------------------------------------------------------------------------------
2021-07-15 13:20:41,179 epoch 5 - iter 6/62 - loss 0.56988396 - samples/sec: 69.38 - lr: 0.000030
2021-07-15 13:20:43,896 epoch 5 - iter 12/62 - loss 0.56404501 - samples/sec: 70.69 - lr: 0.000030
2021-07-15 13:20:46,649 epoch 5 - iter 18/62 - loss 0.57092905 - samples/sec: 69.76 - lr: 0.000030
2021-07-15 13:20:49,402 epoch 5 - iter 24/62 - loss 0.55363745 - samples/sec: 69.75 - lr: 0.000030
2021-07-15 13:20:52,108 epoch 5 - iter 30/62 - loss 0.59094749 - samples/sec: 70.97 - lr: 0.000030
2021-07-15 13:20:54,855 epoch 5 - iter 36/62 - loss 0.57309393 - samples/sec: 69.92 - lr: 0.000030
2021-07-15 13:20:57,623 epoch 5 - iter 42/62 - loss 0.57786913 - samples/sec: 69.37 - lr: 0.000030
2021-07-15 13:21:00,375 epoch 5 - iter 48/62 - loss 0.59447901 - samples/sec: 69.78 - lr: 0.000030
2021-07-15 13:21:03,152 epoch 5 - iter 54/62 - loss 0.59516983 - samples/sec: 69.16 - lr: 0.000030
2021-07-15 13:21:05,907 epoch 5 - iter 60/62 - loss 0.58718250 - samples/sec: 69.70 - lr: 0.000030
2021-07-15 13:21:06,779 ----------------------------------------------------------------------------------------------------
2021-07-15 13:21:06,779 EPOCH 5 done: loss 0.5828 - lr 0.0000300
2021-07-15 13:21:09,622 DEV : loss 0.44847843050956726 - score 0.9081
2021-07-15 13:21:09,661 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:21:13,206 ----------------------------------------------------------------------------------------------------
2021-07-15 13:21:15,955 epoch 6 - iter 6/62 - loss 0.51656586 - samples/sec: 69.86 - lr: 0.000030
2021-07-15 13:21:18,715 epoch 6 - iter 12/62 - loss 0.50882932 - samples/sec: 69.58 - lr: 0.000030
2021-07-15 13:21:21,462 epoch 6 - iter 18/62 - loss 0.51378209 - samples/sec: 69.91 - lr: 0.000030
2021-07-15 13:21:24,262 epoch 6 - iter 24/62 - loss 0.50693278 - samples/sec: 68.61 - lr: 0.000030
2021-07-15 13:21:27,007 epoch 6 - iter 30/62 - loss 0.49286159 - samples/sec: 69.95 - lr: 0.000030
2021-07-15 13:21:29,740 epoch 6 - iter 36/62 - loss 0.49284158 - samples/sec: 70.29 - lr: 0.000030
2021-07-15 13:21:32,459 epoch 6 - iter 42/62 - loss 0.48793072 - samples/sec: 70.62 - lr: 0.000030
2021-07-15 13:21:35,232 epoch 6 - iter 48/62 - loss 0.48097071 - samples/sec: 69.28 - lr: 0.000030
2021-07-15 13:21:37,975 epoch 6 - iter 54/62 - loss 0.46935813 - samples/sec: 70.00 - lr: 0.000030
2021-07-15 13:21:40,732 epoch 6 - iter 60/62 - loss 0.47237189 - samples/sec: 69.67 - lr: 0.000030
2021-07-15 13:21:41,603 ----------------------------------------------------------------------------------------------------
2021-07-15 13:21:41,604 EPOCH 6 done: loss 0.4717 - lr 0.0000300
2021-07-15 13:21:44,246 DEV : loss 0.4141553044319153 - score 0.9195
2021-07-15 13:21:44,284 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:21:47,763 ----------------------------------------------------------------------------------------------------
2021-07-15 13:21:50,528 epoch 7 - iter 6/62 - loss 0.45943924 - samples/sec: 69.48 - lr: 0.000030
2021-07-15 13:21:53,305 epoch 7 - iter 12/62 - loss 0.45893293 - samples/sec: 69.16 - lr: 0.000030
2021-07-15 13:21:56,064 epoch 7 - iter 18/62 - loss 0.45362116 - samples/sec: 69.61 - lr: 0.000030
2021-07-15 13:21:58,829 epoch 7 - iter 24/62 - loss 0.43132316 - samples/sec: 69.45 - lr: 0.000030
2021-07-15 13:22:01,592 epoch 7 - iter 30/62 - loss 0.43166006 - samples/sec: 69.50 - lr: 0.000030
2021-07-15 13:22:04,321 epoch 7 - iter 36/62 - loss 0.42851698 - samples/sec: 70.38 - lr: 0.000030
2021-07-15 13:22:07,076 epoch 7 - iter 42/62 - loss 0.42988558 - samples/sec: 69.69 - lr: 0.000030
2021-07-15 13:22:09,831 epoch 7 - iter 48/62 - loss 0.43256722 - samples/sec: 69.73 - lr: 0.000030
2021-07-15 13:22:12,607 epoch 7 - iter 54/62 - loss 0.42687433 - samples/sec: 69.16 - lr: 0.000030
2021-07-15 13:22:15,343 epoch 7 - iter 60/62 - loss 0.42001386 - samples/sec: 70.19 - lr: 0.000030
2021-07-15 13:22:16,212 ----------------------------------------------------------------------------------------------------
2021-07-15 13:22:16,213 EPOCH 7 done: loss 0.4259 - lr 0.0000300
2021-07-15 13:22:18,868 DEV : loss 0.35847318172454834 - score 0.9215
2021-07-15 13:22:18,907 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:22:22,180 ----------------------------------------------------------------------------------------------------
2021-07-15 13:22:24,952 epoch 8 - iter 6/62 - loss 0.34886499 - samples/sec: 69.29 - lr: 0.000030
2021-07-15 13:22:27,722 epoch 8 - iter 12/62 - loss 0.35709546 - samples/sec: 69.33 - lr: 0.000030
2021-07-15 13:22:30,480 epoch 8 - iter 18/62 - loss 0.37847101 - samples/sec: 69.65 - lr: 0.000030
2021-07-15 13:22:33,248 epoch 8 - iter 24/62 - loss 0.39277672 - samples/sec: 69.37 - lr: 0.000030
2021-07-15 13:22:35,992 epoch 8 - iter 30/62 - loss 0.39672209 - samples/sec: 69.99 - lr: 0.000030
2021-07-15 13:22:38,755 epoch 8 - iter 36/62 - loss 0.40023150 - samples/sec: 69.49 - lr: 0.000030
2021-07-15 13:22:41,483 epoch 8 - iter 42/62 - loss 0.40643209 - samples/sec: 70.40 - lr: 0.000030
2021-07-15 13:22:44,267 epoch 8 - iter 48/62 - loss 0.39994869 - samples/sec: 68.98 - lr: 0.000030
2021-07-15 13:22:47,004 epoch 8 - iter 54/62 - loss 0.39176864 - samples/sec: 70.17 - lr: 0.000030
2021-07-15 13:22:49,743 epoch 8 - iter 60/62 - loss 0.38866259 - samples/sec: 70.11 - lr: 0.000030
2021-07-15 13:22:50,625 ----------------------------------------------------------------------------------------------------
2021-07-15 13:22:50,625 EPOCH 8 done: loss 0.3921 - lr 0.0000300
2021-07-15 13:22:53,480 DEV : loss 0.3499336242675781 - score 0.93
2021-07-15 13:22:53,518 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:22:57,071 ----------------------------------------------------------------------------------------------------
2021-07-15 13:22:59,837 epoch 9 - iter 6/62 - loss 0.39674841 - samples/sec: 69.44 - lr: 0.000030
2021-07-15 13:23:02,608 epoch 9 - iter 12/62 - loss 0.39784001 - samples/sec: 69.30 - lr: 0.000030
2021-07-15 13:23:05,391 epoch 9 - iter 18/62 - loss 0.36729922 - samples/sec: 69.00 - lr: 0.000030
2021-07-15 13:23:08,145 epoch 9 - iter 24/62 - loss 0.36552378 - samples/sec: 69.74 - lr: 0.000030
2021-07-15 13:23:10,924 epoch 9 - iter 30/62 - loss 0.36892987 - samples/sec: 69.11 - lr: 0.000030
2021-07-15 13:23:13,676 epoch 9 - iter 36/62 - loss 0.37249002 - samples/sec: 69.77 - lr: 0.000030
2021-07-15 13:23:16,396 epoch 9 - iter 42/62 - loss 0.35674932 - samples/sec: 70.60 - lr: 0.000030
2021-07-15 13:23:19,133 epoch 9 - iter 48/62 - loss 0.35664971 - samples/sec: 70.17 - lr: 0.000030
2021-07-15 13:23:21,876 epoch 9 - iter 54/62 - loss 0.34669730 - samples/sec: 70.02 - lr: 0.000030
2021-07-15 13:23:24,633 epoch 9 - iter 60/62 - loss 0.34776542 - samples/sec: 69.66 - lr: 0.000030
2021-07-15 13:23:25,523 ----------------------------------------------------------------------------------------------------
2021-07-15 13:23:25,523 EPOCH 9 done: loss 0.3434 - lr 0.0000300
2021-07-15 13:23:28,170 DEV : loss 0.3389023542404175 - score 0.9315
2021-07-15 13:23:28,209 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:23:31,873 ----------------------------------------------------------------------------------------------------
2021-07-15 13:23:34,644 epoch 10 - iter 6/62 - loss 0.33335642 - samples/sec: 69.32 - lr: 0.000030
2021-07-15 13:23:37,381 epoch 10 - iter 12/62 - loss 0.30577713 - samples/sec: 70.17 - lr: 0.000030
2021-07-15 13:23:40,148 epoch 10 - iter 18/62 - loss 0.30840923 - samples/sec: 69.41 - lr: 0.000030
2021-07-15 13:23:42,912 epoch 10 - iter 24/62 - loss 0.31408071 - samples/sec: 69.46 - lr: 0.000030
2021-07-15 13:23:45,688 epoch 10 - iter 30/62 - loss 0.30466580 - samples/sec: 69.20 - lr: 0.000030
2021-07-15 13:23:48,428 epoch 10 - iter 36/62 - loss 0.30602867 - samples/sec: 70.07 - lr: 0.000030
2021-07-15 13:23:51,197 epoch 10 - iter 42/62 - loss 0.29097052 - samples/sec: 69.36 - lr: 0.000030
2021-07-15 13:23:53,902 epoch 10 - iter 48/62 - loss 0.29119473 - samples/sec: 71.00 - lr: 0.000030
2021-07-15 13:23:56,611 epoch 10 - iter 54/62 - loss 0.29796926 - samples/sec: 70.88 - lr: 0.000030
2021-07-15 13:23:59,285 epoch 10 - iter 60/62 - loss 0.30642485 - samples/sec: 71.82 - lr: 0.000030
2021-07-15 13:24:00,152 ----------------------------------------------------------------------------------------------------
2021-07-15 13:24:00,152 EPOCH 10 done: loss 0.3034 - lr 0.0000300
2021-07-15 13:24:02,792 DEV : loss 0.32512474060058594 - score 0.9332
2021-07-15 13:24:02,831 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:24:06,158 ----------------------------------------------------------------------------------------------------
2021-07-15 13:24:08,865 epoch 11 - iter 6/62 - loss 0.37525053 - samples/sec: 70.95 - lr: 0.000030
2021-07-15 13:24:11,576 epoch 11 - iter 12/62 - loss 0.37524094 - samples/sec: 70.84 - lr: 0.000030
2021-07-15 13:24:14,254 epoch 11 - iter 18/62 - loss 0.32978557 - samples/sec: 71.70 - lr: 0.000030
2021-07-15 13:24:16,958 epoch 11 - iter 24/62 - loss 0.32225581 - samples/sec: 71.04 - lr: 0.000030
2021-07-15 13:24:19,651 epoch 11 - iter 30/62 - loss 0.32802362 - samples/sec: 71.32 - lr: 0.000030
2021-07-15 13:24:22,353 epoch 11 - iter 36/62 - loss 0.32014955 - samples/sec: 71.08 - lr: 0.000030
2021-07-15 13:24:25,061 epoch 11 - iter 42/62 - loss 0.30840101 - samples/sec: 70.92 - lr: 0.000030
2021-07-15 13:24:27,782 epoch 11 - iter 48/62 - loss 0.29913819 - samples/sec: 70.57 - lr: 0.000030
2021-07-15 13:24:30,490 epoch 11 - iter 54/62 - loss 0.29716079 - samples/sec: 70.93 - lr: 0.000030
2021-07-15 13:24:33,189 epoch 11 - iter 60/62 - loss 0.29839481 - samples/sec: 71.15 - lr: 0.000030
2021-07-15 13:24:34,049 ----------------------------------------------------------------------------------------------------
2021-07-15 13:24:34,050 EPOCH 11 done: loss 0.2983 - lr 0.0000300
2021-07-15 13:24:36,690 DEV : loss 0.3048648536205292 - score 0.9342
2021-07-15 13:24:36,730 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:24:40,066 ----------------------------------------------------------------------------------------------------
2021-07-15 13:24:42,995 epoch 12 - iter 6/62 - loss 0.32343992 - samples/sec: 65.57 - lr: 0.000030
2021-07-15 13:24:45,663 epoch 12 - iter 12/62 - loss 0.35715951 - samples/sec: 71.98 - lr: 0.000030
2021-07-15 13:24:48,367 epoch 12 - iter 18/62 - loss 0.34181917 - samples/sec: 71.03 - lr: 0.000030
2021-07-15 13:24:51,066 epoch 12 - iter 24/62 - loss 0.31051222 - samples/sec: 71.16 - lr: 0.000030
2021-07-15 13:24:53,779 epoch 12 - iter 30/62 - loss 0.30612051 - samples/sec: 70.78 - lr: 0.000030
2021-07-15 13:24:56,505 epoch 12 - iter 36/62 - loss 0.30087282 - samples/sec: 70.44 - lr: 0.000030
2021-07-15 13:24:59,203 epoch 12 - iter 42/62 - loss 0.28745050 - samples/sec: 71.17 - lr: 0.000030
2021-07-15 13:25:01,908 epoch 12 - iter 48/62 - loss 0.28720736 - samples/sec: 71.01 - lr: 0.000030
2021-07-15 13:25:04,594 epoch 12 - iter 54/62 - loss 0.29089349 - samples/sec: 71.49 - lr: 0.000030
2021-07-15 13:25:07,283 epoch 12 - iter 60/62 - loss 0.28365264 - samples/sec: 71.43 - lr: 0.000030
2021-07-15 13:25:08,145 ----------------------------------------------------------------------------------------------------
2021-07-15 13:25:08,145 EPOCH 12 done: loss 0.2860 - lr 0.0000300
2021-07-15 13:25:10,781 DEV : loss 0.28846338391304016 - score 0.9401
2021-07-15 13:25:10,820 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:25:14,392 ----------------------------------------------------------------------------------------------------
2021-07-15 13:25:17,113 epoch 13 - iter 6/62 - loss 0.19160417 - samples/sec: 70.60 - lr: 0.000030
2021-07-15 13:25:19,842 epoch 13 - iter 12/62 - loss 0.22678376 - samples/sec: 70.37 - lr: 0.000030
2021-07-15 13:25:22,573 epoch 13 - iter 18/62 - loss 0.22557750 - samples/sec: 70.31 - lr: 0.000030
2021-07-15 13:25:25,352 epoch 13 - iter 24/62 - loss 0.22187420 - samples/sec: 69.12 - lr: 0.000030
2021-07-15 13:25:28,117 epoch 13 - iter 30/62 - loss 0.23095329 - samples/sec: 69.46 - lr: 0.000030
2021-07-15 13:25:30,845 epoch 13 - iter 36/62 - loss 0.24085549 - samples/sec: 70.38 - lr: 0.000030
2021-07-15 13:25:33,602 epoch 13 - iter 42/62 - loss 0.23358008 - samples/sec: 69.67 - lr: 0.000030
2021-07-15 13:25:36,357 epoch 13 - iter 48/62 - loss 0.24077605 - samples/sec: 69.70 - lr: 0.000030
2021-07-15 13:25:39,087 epoch 13 - iter 54/62 - loss 0.24602990 - samples/sec: 70.35 - lr: 0.000030
2021-07-15 13:25:41,795 epoch 13 - iter 60/62 - loss 0.25643133 - samples/sec: 70.92 - lr: 0.000030
2021-07-15 13:25:42,677 ----------------------------------------------------------------------------------------------------
2021-07-15 13:25:42,677 EPOCH 13 done: loss 0.2559 - lr 0.0000300
2021-07-15 13:25:45,327 DEV : loss 0.3191564083099365 - score 0.9357
2021-07-15 13:25:45,366 BAD EPOCHS (no improvement): 1
2021-07-15 13:25:45,366 ----------------------------------------------------------------------------------------------------
2021-07-15 13:25:48,140 epoch 14 - iter 6/62 - loss 0.27426104 - samples/sec: 69.23 - lr: 0.000030
2021-07-15 13:25:50,863 epoch 14 - iter 12/62 - loss 0.23188899 - samples/sec: 70.53 - lr: 0.000030
2021-07-15 13:25:53,612 epoch 14 - iter 18/62 - loss 0.23397537 - samples/sec: 69.87 - lr: 0.000030
2021-07-15 13:25:56,352 epoch 14 - iter 24/62 - loss 0.23199044 - samples/sec: 70.10 - lr: 0.000030
2021-07-15 13:25:59,120 epoch 14 - iter 30/62 - loss 0.25466434 - samples/sec: 69.36 - lr: 0.000030
2021-07-15 13:26:01,868 epoch 14 - iter 36/62 - loss 0.25221478 - samples/sec: 69.91 - lr: 0.000030
2021-07-15 13:26:04,628 epoch 14 - iter 42/62 - loss 0.24736858 - samples/sec: 69.56 - lr: 0.000030
2021-07-15 13:26:07,393 epoch 14 - iter 48/62 - loss 0.24435570 - samples/sec: 69.47 - lr: 0.000030
2021-07-15 13:26:10,141 epoch 14 - iter 54/62 - loss 0.24761374 - samples/sec: 69.88 - lr: 0.000030
2021-07-15 13:26:12,908 epoch 14 - iter 60/62 - loss 0.24759515 - samples/sec: 69.40 - lr: 0.000030
2021-07-15 13:26:13,767 ----------------------------------------------------------------------------------------------------
2021-07-15 13:26:13,767 EPOCH 14 done: loss 0.2499 - lr 0.0000300
2021-07-15 13:26:16,612 DEV : loss 0.2826150357723236 - score 0.9385
2021-07-15 13:26:16,651 BAD EPOCHS (no improvement): 2
2021-07-15 13:26:16,652 ----------------------------------------------------------------------------------------------------
2021-07-15 13:26:19,416 epoch 15 - iter 6/62 - loss 0.22807498 - samples/sec: 69.48 - lr: 0.000030
2021-07-15 13:26:22,133 epoch 15 - iter 12/62 - loss 0.22756395 - samples/sec: 70.66 - lr: 0.000030
2021-07-15 13:26:24,884 epoch 15 - iter 18/62 - loss 0.20477260 - samples/sec: 69.83 - lr: 0.000030
2021-07-15 13:26:27,667 epoch 15 - iter 24/62 - loss 0.20435706 - samples/sec: 68.98 - lr: 0.000030
2021-07-15 13:26:30,433 epoch 15 - iter 30/62 - loss 0.20481420 - samples/sec: 69.45 - lr: 0.000030
2021-07-15 13:26:33,172 epoch 15 - iter 36/62 - loss 0.20217536 - samples/sec: 70.10 - lr: 0.000030
2021-07-15 13:26:35,945 epoch 15 - iter 42/62 - loss 0.19632142 - samples/sec: 69.26 - lr: 0.000030
2021-07-15 13:26:38,712 epoch 15 - iter 48/62 - loss 0.21183956 - samples/sec: 69.40 - lr: 0.000030
2021-07-15 13:26:41,442 epoch 15 - iter 54/62 - loss 0.20848414 - samples/sec: 70.37 - lr: 0.000030
2021-07-15 13:26:44,199 epoch 15 - iter 60/62 - loss 0.21206083 - samples/sec: 69.64 - lr: 0.000030
2021-07-15 13:26:45,081 ----------------------------------------------------------------------------------------------------
2021-07-15 13:26:45,081 EPOCH 15 done: loss 0.2125 - lr 0.0000300
2021-07-15 13:26:47,724 DEV : loss 0.26773685216903687 - score 0.9408
2021-07-15 13:26:47,763 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:26:50,588 ----------------------------------------------------------------------------------------------------
2021-07-15 13:26:53,313 epoch 16 - iter 6/62 - loss 0.18393422 - samples/sec: 70.50 - lr: 0.000030
2021-07-15 13:26:56,054 epoch 16 - iter 12/62 - loss 0.17725475 - samples/sec: 70.05 - lr: 0.000030
2021-07-15 13:26:58,807 epoch 16 - iter 18/62 - loss 0.18684607 - samples/sec: 69.78 - lr: 0.000030
2021-07-15 13:27:01,580 epoch 16 - iter 24/62 - loss 0.17903114 - samples/sec: 69.24 - lr: 0.000030
2021-07-15 13:27:04,343 epoch 16 - iter 30/62 - loss 0.19070277 - samples/sec: 69.51 - lr: 0.000030
2021-07-15 13:27:07,055 epoch 16 - iter 36/62 - loss 0.18783332 - samples/sec: 70.83 - lr: 0.000030
2021-07-15 13:27:09,773 epoch 16 - iter 42/62 - loss 0.19628115 - samples/sec: 70.64 - lr: 0.000030
2021-07-15 13:27:12,476 epoch 16 - iter 48/62 - loss 0.19613520 - samples/sec: 71.07 - lr: 0.000030
2021-07-15 13:27:15,212 epoch 16 - iter 54/62 - loss 0.19777101 - samples/sec: 70.18 - lr: 0.000030
2021-07-15 13:27:17,948 epoch 16 - iter 60/62 - loss 0.20074977 - samples/sec: 70.19 - lr: 0.000030
2021-07-15 13:27:18,821 ----------------------------------------------------------------------------------------------------
2021-07-15 13:27:18,821 EPOCH 16 done: loss 0.2019 - lr 0.0000300
2021-07-15 13:27:21,473 DEV : loss 0.26045429706573486 - score 0.942
2021-07-15 13:27:21,513 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:27:25,056 ----------------------------------------------------------------------------------------------------
2021-07-15 13:27:27,807 epoch 17 - iter 6/62 - loss 0.19504282 - samples/sec: 69.81 - lr: 0.000030
2021-07-15 13:27:30,512 epoch 17 - iter 12/62 - loss 0.21996645 - samples/sec: 71.01 - lr: 0.000030
2021-07-15 13:27:33,228 epoch 17 - iter 18/62 - loss 0.22766214 - samples/sec: 70.70 - lr: 0.000030
2021-07-15 13:27:35,988 epoch 17 - iter 24/62 - loss 0.21658702 - samples/sec: 69.58 - lr: 0.000030
2021-07-15 13:27:38,708 epoch 17 - iter 30/62 - loss 0.20520856 - samples/sec: 70.60 - lr: 0.000030
2021-07-15 13:27:41,460 epoch 17 - iter 36/62 - loss 0.20328386 - samples/sec: 69.80 - lr: 0.000030
2021-07-15 13:27:44,203 epoch 17 - iter 42/62 - loss 0.20961553 - samples/sec: 70.00 - lr: 0.000030
2021-07-15 13:27:46,934 epoch 17 - iter 48/62 - loss 0.21244832 - samples/sec: 70.34 - lr: 0.000030
2021-07-15 13:27:49,654 epoch 17 - iter 54/62 - loss 0.21885502 - samples/sec: 70.58 - lr: 0.000030
2021-07-15 13:27:52,372 epoch 17 - iter 60/62 - loss 0.21060361 - samples/sec: 70.68 - lr: 0.000030
2021-07-15 13:27:53,238 ----------------------------------------------------------------------------------------------------
2021-07-15 13:27:53,239 EPOCH 17 done: loss 0.2086 - lr 0.0000300
2021-07-15 13:27:55,878 DEV : loss 0.2573550343513489 - score 0.9393
2021-07-15 13:27:55,917 BAD EPOCHS (no improvement): 1
2021-07-15 13:27:55,917 ----------------------------------------------------------------------------------------------------
2021-07-15 13:27:58,861 epoch 18 - iter 6/62 - loss 0.16704152 - samples/sec: 65.23 - lr: 0.000030
2021-07-15 13:28:01,593 epoch 18 - iter 12/62 - loss 0.17607701 - samples/sec: 70.31 - lr: 0.000030
2021-07-15 13:28:04,324 epoch 18 - iter 18/62 - loss 0.17400622 - samples/sec: 70.32 - lr: 0.000030
2021-07-15 13:28:07,035 epoch 18 - iter 24/62 - loss 0.18479372 - samples/sec: 70.82 - lr: 0.000030
2021-07-15 13:28:09,781 epoch 18 - iter 30/62 - loss 0.17806077 - samples/sec: 69.94 - lr: 0.000030
2021-07-15 13:28:12,506 epoch 18 - iter 36/62 - loss 0.17264649 - samples/sec: 70.47 - lr: 0.000030
2021-07-15 13:28:15,226 epoch 18 - iter 42/62 - loss 0.17350476 - samples/sec: 70.62 - lr: 0.000030
2021-07-15 13:28:17,968 epoch 18 - iter 48/62 - loss 0.17043862 - samples/sec: 70.03 - lr: 0.000030
2021-07-15 13:28:20,718 epoch 18 - iter 54/62 - loss 0.16767127 - samples/sec: 69.84 - lr: 0.000030
2021-07-15 13:28:23,438 epoch 18 - iter 60/62 - loss 0.16794957 - samples/sec: 70.60 - lr: 0.000030
2021-07-15 13:28:24,301 ----------------------------------------------------------------------------------------------------
2021-07-15 13:28:24,302 EPOCH 18 done: loss 0.1691 - lr 0.0000300
2021-07-15 13:28:26,966 DEV : loss 0.24226102232933044 - score 0.944
2021-07-15 13:28:27,005 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:28:30,353 ----------------------------------------------------------------------------------------------------
2021-07-15 13:28:33,120 epoch 19 - iter 6/62 - loss 0.14697800 - samples/sec: 69.41 - lr: 0.000030
2021-07-15 13:28:35,884 epoch 19 - iter 12/62 - loss 0.16544334 - samples/sec: 69.47 - lr: 0.000030
2021-07-15 13:28:38,620 epoch 19 - iter 18/62 - loss 0.16475741 - samples/sec: 70.19 - lr: 0.000030
2021-07-15 13:28:41,364 epoch 19 - iter 24/62 - loss 0.16394411 - samples/sec: 70.00 - lr: 0.000030
2021-07-15 13:28:44,099 epoch 19 - iter 30/62 - loss 0.16562468 - samples/sec: 70.20 - lr: 0.000030
2021-07-15 13:28:46,820 epoch 19 - iter 36/62 - loss 0.16860608 - samples/sec: 70.59 - lr: 0.000030
2021-07-15 13:28:49,586 epoch 19 - iter 42/62 - loss 0.17660849 - samples/sec: 69.44 - lr: 0.000030
2021-07-15 13:28:52,344 epoch 19 - iter 48/62 - loss 0.17446316 - samples/sec: 69.63 - lr: 0.000030
2021-07-15 13:28:55,103 epoch 19 - iter 54/62 - loss 0.17637719 - samples/sec: 69.59 - lr: 0.000030
2021-07-15 13:28:57,852 epoch 19 - iter 60/62 - loss 0.17771817 - samples/sec: 69.86 - lr: 0.000030
2021-07-15 13:28:58,723 ----------------------------------------------------------------------------------------------------
2021-07-15 13:28:58,724 EPOCH 19 done: loss 0.1777 - lr 0.0000300
2021-07-15 13:29:01,367 DEV : loss 0.2547314465045929 - score 0.9412
2021-07-15 13:29:01,406 BAD EPOCHS (no improvement): 1
2021-07-15 13:29:01,406 ----------------------------------------------------------------------------------------------------
2021-07-15 13:29:04,126 epoch 20 - iter 6/62 - loss 0.17031554 - samples/sec: 70.61 - lr: 0.000030
2021-07-15 13:29:06,814 epoch 20 - iter 12/62 - loss 0.16150815 - samples/sec: 71.44 - lr: 0.000030
2021-07-15 13:29:09,535 epoch 20 - iter 18/62 - loss 0.16367443 - samples/sec: 70.57 - lr: 0.000030
2021-07-15 13:29:12,227 epoch 20 - iter 24/62 - loss 0.15984224 - samples/sec: 71.36 - lr: 0.000030
2021-07-15 13:29:14,904 epoch 20 - iter 30/62 - loss 0.15787054 - samples/sec: 71.73 - lr: 0.000030
2021-07-15 13:29:17,607 epoch 20 - iter 36/62 - loss 0.15744698 - samples/sec: 71.05 - lr: 0.000030
2021-07-15 13:29:20,322 epoch 20 - iter 42/62 - loss 0.16075901 - samples/sec: 70.74 - lr: 0.000030
2021-07-15 13:29:23,025 epoch 20 - iter 48/62 - loss 0.16175807 - samples/sec: 71.04 - lr: 0.000030
2021-07-15 13:29:25,722 epoch 20 - iter 54/62 - loss 0.16212867 - samples/sec: 71.22 - lr: 0.000030
2021-07-15 13:29:28,452 epoch 20 - iter 60/62 - loss 0.16518803 - samples/sec: 70.35 - lr: 0.000030
2021-07-15 13:29:29,295 ----------------------------------------------------------------------------------------------------
2021-07-15 13:29:29,295 EPOCH 20 done: loss 0.1694 - lr 0.0000300
2021-07-15 13:29:31,938 DEV : loss 0.24051158130168915 - score 0.9428
2021-07-15 13:29:31,977 BAD EPOCHS (no improvement): 2
2021-07-15 13:29:31,978 ----------------------------------------------------------------------------------------------------
2021-07-15 13:29:34,671 epoch 21 - iter 6/62 - loss 0.16451542 - samples/sec: 71.30 - lr: 0.000030
2021-07-15 13:29:37,352 epoch 21 - iter 12/62 - loss 0.15085445 - samples/sec: 71.64 - lr: 0.000030
2021-07-15 13:29:40,223 epoch 21 - iter 18/62 - loss 0.17528035 - samples/sec: 66.90 - lr: 0.000030
2021-07-15 13:29:42,938 epoch 21 - iter 24/62 - loss 0.17761219 - samples/sec: 70.73 - lr: 0.000030
2021-07-15 13:29:45,638 epoch 21 - iter 30/62 - loss 0.17240306 - samples/sec: 71.13 - lr: 0.000030
2021-07-15 13:29:48,367 epoch 21 - iter 36/62 - loss 0.17886423 - samples/sec: 70.36 - lr: 0.000030
2021-07-15 13:29:51,085 epoch 21 - iter 42/62 - loss 0.17684793 - samples/sec: 70.66 - lr: 0.000030
2021-07-15 13:29:53,789 epoch 21 - iter 48/62 - loss 0.18184162 - samples/sec: 71.03 - lr: 0.000030
2021-07-15 13:29:56,470 epoch 21 - iter 54/62 - loss 0.18043843 - samples/sec: 71.63 - lr: 0.000030
2021-07-15 13:29:59,159 epoch 21 - iter 60/62 - loss 0.17998052 - samples/sec: 71.41 - lr: 0.000030
2021-07-15 13:30:00,023 ----------------------------------------------------------------------------------------------------
2021-07-15 13:30:00,023 EPOCH 21 done: loss 0.1789 - lr 0.0000300
2021-07-15 13:30:02,663 DEV : loss 0.2315261960029602 - score 0.9486
2021-07-15 13:30:02,702 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:30:05,675 ----------------------------------------------------------------------------------------------------
2021-07-15 13:30:08,361 epoch 22 - iter 6/62 - loss 0.12820878 - samples/sec: 71.52 - lr: 0.000030
2021-07-15 13:30:11,082 epoch 22 - iter 12/62 - loss 0.13217759 - samples/sec: 70.57 - lr: 0.000030
2021-07-15 13:30:13,779 epoch 22 - iter 18/62 - loss 0.14520038 - samples/sec: 71.23 - lr: 0.000030
2021-07-15 13:30:16,463 epoch 22 - iter 24/62 - loss 0.14245558 - samples/sec: 71.54 - lr: 0.000030
2021-07-15 13:30:19,163 epoch 22 - iter 30/62 - loss 0.15435295 - samples/sec: 71.11 - lr: 0.000030
2021-07-15 13:30:21,868 epoch 22 - iter 36/62 - loss 0.16036893 - samples/sec: 71.02 - lr: 0.000030
2021-07-15 13:30:24,569 epoch 22 - iter 42/62 - loss 0.16061587 - samples/sec: 71.09 - lr: 0.000030
2021-07-15 13:30:27,272 epoch 22 - iter 48/62 - loss 0.16626605 - samples/sec: 71.06 - lr: 0.000030
2021-07-15 13:30:29,967 epoch 22 - iter 54/62 - loss 0.16344632 - samples/sec: 71.27 - lr: 0.000030
2021-07-15 13:30:32,674 epoch 22 - iter 60/62 - loss 0.16529057 - samples/sec: 70.94 - lr: 0.000030
2021-07-15 13:30:33,519 ----------------------------------------------------------------------------------------------------
2021-07-15 13:30:33,520 EPOCH 22 done: loss 0.1639 - lr 0.0000300
2021-07-15 13:30:36,164 DEV : loss 0.23017781972885132 - score 0.9495
2021-07-15 13:30:36,203 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:30:39,543 ----------------------------------------------------------------------------------------------------
2021-07-15 13:30:42,216 epoch 23 - iter 6/62 - loss 0.14830585 - samples/sec: 71.86 - lr: 0.000030
2021-07-15 13:30:44,937 epoch 23 - iter 12/62 - loss 0.15477150 - samples/sec: 70.58 - lr: 0.000030
2021-07-15 13:30:47,650 epoch 23 - iter 18/62 - loss 0.15026316 - samples/sec: 70.77 - lr: 0.000030
2021-07-15 13:30:50,345 epoch 23 - iter 24/62 - loss 0.15349526 - samples/sec: 71.28 - lr: 0.000030
2021-07-15 13:30:53,054 epoch 23 - iter 30/62 - loss 0.14918960 - samples/sec: 70.89 - lr: 0.000030
2021-07-15 13:30:55,773 epoch 23 - iter 36/62 - loss 0.14866132 - samples/sec: 70.61 - lr: 0.000030
2021-07-15 13:30:58,458 epoch 23 - iter 42/62 - loss 0.14241544 - samples/sec: 71.55 - lr: 0.000030
2021-07-15 13:31:01,180 epoch 23 - iter 48/62 - loss 0.14340874 - samples/sec: 70.55 - lr: 0.000030
2021-07-15 13:31:03,844 epoch 23 - iter 54/62 - loss 0.13784415 - samples/sec: 72.09 - lr: 0.000030
2021-07-15 13:31:06,542 epoch 23 - iter 60/62 - loss 0.13703746 - samples/sec: 71.17 - lr: 0.000030
2021-07-15 13:31:07,401 ----------------------------------------------------------------------------------------------------
2021-07-15 13:31:07,402 EPOCH 23 done: loss 0.1353 - lr 0.0000300
2021-07-15 13:31:10,244 DEV : loss 0.2458115965127945 - score 0.9464
2021-07-15 13:31:10,283 BAD EPOCHS (no improvement): 1
2021-07-15 13:31:10,283 ----------------------------------------------------------------------------------------------------
2021-07-15 13:31:12,994 epoch 24 - iter 6/62 - loss 0.15781012 - samples/sec: 70.86 - lr: 0.000030
2021-07-15 13:31:15,682 epoch 24 - iter 12/62 - loss 0.17274132 - samples/sec: 71.44 - lr: 0.000030
2021-07-15 13:31:18,370 epoch 24 - iter 18/62 - loss 0.15493693 - samples/sec: 71.44 - lr: 0.000030
2021-07-15 13:31:21,064 epoch 24 - iter 24/62 - loss 0.15861691 - samples/sec: 71.31 - lr: 0.000030
2021-07-15 13:31:23,774 epoch 24 - iter 30/62 - loss 0.15848900 - samples/sec: 70.86 - lr: 0.000030
2021-07-15 13:31:26,493 epoch 24 - iter 36/62 - loss 0.15701778 - samples/sec: 70.63 - lr: 0.000030
2021-07-15 13:31:29,169 epoch 24 - iter 42/62 - loss 0.15221334 - samples/sec: 71.77 - lr: 0.000030
2021-07-15 13:31:31,906 epoch 24 - iter 48/62 - loss 0.15235422 - samples/sec: 70.16 - lr: 0.000030
2021-07-15 13:31:34,605 epoch 24 - iter 54/62 - loss 0.15434560 - samples/sec: 71.16 - lr: 0.000030
2021-07-15 13:31:37,317 epoch 24 - iter 60/62 - loss 0.15725120 - samples/sec: 70.81 - lr: 0.000030
2021-07-15 13:31:38,153 ----------------------------------------------------------------------------------------------------
2021-07-15 13:31:38,154 EPOCH 24 done: loss 0.1565 - lr 0.0000300
2021-07-15 13:31:40,793 DEV : loss 0.2308778315782547 - score 0.9497
2021-07-15 13:31:40,833 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:31:44,631 ----------------------------------------------------------------------------------------------------
2021-07-15 13:31:47,340 epoch 25 - iter 6/62 - loss 0.13839825 - samples/sec: 70.92 - lr: 0.000030
2021-07-15 13:31:50,062 epoch 25 - iter 12/62 - loss 0.15268257 - samples/sec: 70.53 - lr: 0.000030
2021-07-15 13:31:52,759 epoch 25 - iter 18/62 - loss 0.15962238 - samples/sec: 71.23 - lr: 0.000030
2021-07-15 13:31:55,489 epoch 25 - iter 24/62 - loss 0.15055423 - samples/sec: 70.34 - lr: 0.000030
2021-07-15 13:31:58,176 epoch 25 - iter 30/62 - loss 0.13969204 - samples/sec: 71.46 - lr: 0.000030
2021-07-15 13:32:00,918 epoch 25 - iter 36/62 - loss 0.13912005 - samples/sec: 70.04 - lr: 0.000030
2021-07-15 13:32:03,610 epoch 25 - iter 42/62 - loss 0.13606793 - samples/sec: 71.34 - lr: 0.000030
2021-07-15 13:32:06,292 epoch 25 - iter 48/62 - loss 0.13681989 - samples/sec: 71.61 - lr: 0.000030
2021-07-15 13:32:08,991 epoch 25 - iter 54/62 - loss 0.13295462 - samples/sec: 71.17 - lr: 0.000030
2021-07-15 13:32:11,714 epoch 25 - iter 60/62 - loss 0.13710840 - samples/sec: 70.51 - lr: 0.000030
2021-07-15 13:32:12,568 ----------------------------------------------------------------------------------------------------
2021-07-15 13:32:12,569 EPOCH 25 done: loss 0.1358 - lr 0.0000300
2021-07-15 13:32:15,211 DEV : loss 0.24136173725128174 - score 0.9414
2021-07-15 13:32:15,250 BAD EPOCHS (no improvement): 1
2021-07-15 13:32:15,250 ----------------------------------------------------------------------------------------------------
2021-07-15 13:32:17,941 epoch 26 - iter 6/62 - loss 0.13643393 - samples/sec: 71.36 - lr: 0.000030
2021-07-15 13:32:20,644 epoch 26 - iter 12/62 - loss 0.15176093 - samples/sec: 71.05 - lr: 0.000030
2021-07-15 13:32:23,361 epoch 26 - iter 18/62 - loss 0.14478845 - samples/sec: 70.68 - lr: 0.000030
2021-07-15 13:32:26,070 epoch 26 - iter 24/62 - loss 0.14358314 - samples/sec: 70.91 - lr: 0.000030
2021-07-15 13:32:28,764 epoch 26 - iter 30/62 - loss 0.14112482 - samples/sec: 71.28 - lr: 0.000030
2021-07-15 13:32:31,466 epoch 26 - iter 36/62 - loss 0.13850628 - samples/sec: 71.08 - lr: 0.000030
2021-07-15 13:32:34,141 epoch 26 - iter 42/62 - loss 0.13907750 - samples/sec: 71.80 - lr: 0.000030
2021-07-15 13:32:36,862 epoch 26 - iter 48/62 - loss 0.14269637 - samples/sec: 70.56 - lr: 0.000030
2021-07-15 13:32:39,576 epoch 26 - iter 54/62 - loss 0.15224023 - samples/sec: 70.78 - lr: 0.000030
2021-07-15 13:32:42,273 epoch 26 - iter 60/62 - loss 0.15170354 - samples/sec: 71.20 - lr: 0.000030
2021-07-15 13:32:43,119 ----------------------------------------------------------------------------------------------------
2021-07-15 13:32:43,119 EPOCH 26 done: loss 0.1487 - lr 0.0000300
2021-07-15 13:32:45,960 DEV : loss 0.2424701601266861 - score 0.948
2021-07-15 13:32:45,999 BAD EPOCHS (no improvement): 2
2021-07-15 13:32:46,000 ----------------------------------------------------------------------------------------------------
2021-07-15 13:32:48,717 epoch 27 - iter 6/62 - loss 0.09273127 - samples/sec: 70.69 - lr: 0.000030
2021-07-15 13:32:51,463 epoch 27 - iter 12/62 - loss 0.11479782 - samples/sec: 69.92 - lr: 0.000030
2021-07-15 13:32:54,184 epoch 27 - iter 18/62 - loss 0.12256040 - samples/sec: 70.59 - lr: 0.000030
2021-07-15 13:32:56,901 epoch 27 - iter 24/62 - loss 0.13815142 - samples/sec: 70.68 - lr: 0.000030
2021-07-15 13:32:59,628 epoch 27 - iter 30/62 - loss 0.13969033 - samples/sec: 70.43 - lr: 0.000030
2021-07-15 13:33:02,336 epoch 27 - iter 36/62 - loss 0.13233575 - samples/sec: 70.92 - lr: 0.000030
2021-07-15 13:33:05,096 epoch 27 - iter 42/62 - loss 0.13057971 - samples/sec: 69.56 - lr: 0.000030
2021-07-15 13:33:07,832 epoch 27 - iter 48/62 - loss 0.13448998 - samples/sec: 70.21 - lr: 0.000030
2021-07-15 13:33:10,584 epoch 27 - iter 54/62 - loss 0.13281200 - samples/sec: 69.77 - lr: 0.000030
2021-07-15 13:33:13,332 epoch 27 - iter 60/62 - loss 0.13225045 - samples/sec: 69.90 - lr: 0.000030
2021-07-15 13:33:14,201 ----------------------------------------------------------------------------------------------------
2021-07-15 13:33:14,202 EPOCH 27 done: loss 0.1316 - lr 0.0000300
2021-07-15 13:33:16,855 DEV : loss 0.24258321523666382 - score 0.942
2021-07-15 13:33:16,894 BAD EPOCHS (no improvement): 3
2021-07-15 13:33:16,894 ----------------------------------------------------------------------------------------------------
2021-07-15 13:33:19,652 epoch 28 - iter 6/62 - loss 0.08154541 - samples/sec: 69.64 - lr: 0.000030
2021-07-15 13:33:22,409 epoch 28 - iter 12/62 - loss 0.10139040 - samples/sec: 69.68 - lr: 0.000030
2021-07-15 13:33:25,149 epoch 28 - iter 18/62 - loss 0.11089035 - samples/sec: 70.09 - lr: 0.000030
2021-07-15 13:33:27,857 epoch 28 - iter 24/62 - loss 0.09716108 - samples/sec: 70.91 - lr: 0.000030
2021-07-15 13:33:30,612 epoch 28 - iter 30/62 - loss 0.10745718 - samples/sec: 69.70 - lr: 0.000030
2021-07-15 13:33:33,365 epoch 28 - iter 36/62 - loss 0.11444726 - samples/sec: 69.78 - lr: 0.000030
2021-07-15 13:33:36,137 epoch 28 - iter 42/62 - loss 0.11843005 - samples/sec: 69.26 - lr: 0.000030
2021-07-15 13:33:38,885 epoch 28 - iter 48/62 - loss 0.12039903 - samples/sec: 69.90 - lr: 0.000030
2021-07-15 13:33:41,636 epoch 28 - iter 54/62 - loss 0.12132874 - samples/sec: 69.81 - lr: 0.000030
2021-07-15 13:33:44,426 epoch 28 - iter 60/62 - loss 0.12373341 - samples/sec: 68.84 - lr: 0.000030
2021-07-15 13:33:45,273 ----------------------------------------------------------------------------------------------------
2021-07-15 13:33:45,274 EPOCH 28 done: loss 0.1228 - lr 0.0000300
2021-07-15 13:33:47,917 DEV : loss 0.23459655046463013 - score 0.9459
Epoch    28: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 13:33:47,956 BAD EPOCHS (no improvement): 4
2021-07-15 13:33:47,956 ----------------------------------------------------------------------------------------------------
2021-07-15 13:33:50,720 epoch 29 - iter 6/62 - loss 0.09373501 - samples/sec: 69.49 - lr: 0.000015
2021-07-15 13:33:53,479 epoch 29 - iter 12/62 - loss 0.10237884 - samples/sec: 69.60 - lr: 0.000015
2021-07-15 13:33:56,249 epoch 29 - iter 18/62 - loss 0.10295707 - samples/sec: 69.35 - lr: 0.000015
2021-07-15 13:33:58,991 epoch 29 - iter 24/62 - loss 0.10325262 - samples/sec: 70.03 - lr: 0.000015
2021-07-15 13:34:01,741 epoch 29 - iter 30/62 - loss 0.10892717 - samples/sec: 69.84 - lr: 0.000015
2021-07-15 13:34:04,515 epoch 29 - iter 36/62 - loss 0.10773727 - samples/sec: 69.21 - lr: 0.000015
2021-07-15 13:34:07,268 epoch 29 - iter 42/62 - loss 0.10333423 - samples/sec: 69.77 - lr: 0.000015
2021-07-15 13:34:09,990 epoch 29 - iter 48/62 - loss 0.10946442 - samples/sec: 70.54 - lr: 0.000015
2021-07-15 13:34:12,752 epoch 29 - iter 54/62 - loss 0.10953950 - samples/sec: 69.55 - lr: 0.000015
2021-07-15 13:34:15,461 epoch 29 - iter 60/62 - loss 0.10657277 - samples/sec: 70.89 - lr: 0.000015
2021-07-15 13:34:16,323 ----------------------------------------------------------------------------------------------------
2021-07-15 13:34:16,323 EPOCH 29 done: loss 0.1100 - lr 0.0000150
2021-07-15 13:34:18,973 DEV : loss 0.23655666410923004 - score 0.946
2021-07-15 13:34:19,012 BAD EPOCHS (no improvement): 1
2021-07-15 13:34:19,013 ----------------------------------------------------------------------------------------------------
2021-07-15 13:34:21,969 epoch 30 - iter 6/62 - loss 0.09638606 - samples/sec: 64.97 - lr: 0.000015
2021-07-15 13:34:24,720 epoch 30 - iter 12/62 - loss 0.09240763 - samples/sec: 69.79 - lr: 0.000015
2021-07-15 13:34:27,487 epoch 30 - iter 18/62 - loss 0.09256649 - samples/sec: 69.42 - lr: 0.000015
2021-07-15 13:34:30,222 epoch 30 - iter 24/62 - loss 0.10256743 - samples/sec: 70.22 - lr: 0.000015
2021-07-15 13:34:32,991 epoch 30 - iter 30/62 - loss 0.09833015 - samples/sec: 69.34 - lr: 0.000015
2021-07-15 13:34:35,713 epoch 30 - iter 36/62 - loss 0.10815639 - samples/sec: 70.56 - lr: 0.000015
2021-07-15 13:34:38,496 epoch 30 - iter 42/62 - loss 0.11720022 - samples/sec: 69.02 - lr: 0.000015
2021-07-15 13:34:41,252 epoch 30 - iter 48/62 - loss 0.11920878 - samples/sec: 69.68 - lr: 0.000015
2021-07-15 13:34:43,999 epoch 30 - iter 54/62 - loss 0.11817630 - samples/sec: 69.89 - lr: 0.000015
2021-07-15 13:34:46,753 epoch 30 - iter 60/62 - loss 0.11667114 - samples/sec: 69.74 - lr: 0.000015
2021-07-15 13:34:47,619 ----------------------------------------------------------------------------------------------------
2021-07-15 13:34:47,619 EPOCH 30 done: loss 0.1177 - lr 0.0000150
2021-07-15 13:34:50,275 DEV : loss 0.23285862803459167 - score 0.9494
2021-07-15 13:34:50,314 BAD EPOCHS (no improvement): 2
2021-07-15 13:34:50,314 ----------------------------------------------------------------------------------------------------
2021-07-15 13:34:53,041 epoch 31 - iter 6/62 - loss 0.15801802 - samples/sec: 70.44 - lr: 0.000015
2021-07-15 13:34:55,795 epoch 31 - iter 12/62 - loss 0.12388035 - samples/sec: 69.72 - lr: 0.000015
2021-07-15 13:34:58,561 epoch 31 - iter 18/62 - loss 0.11488413 - samples/sec: 69.44 - lr: 0.000015
2021-07-15 13:35:01,338 epoch 31 - iter 24/62 - loss 0.10253251 - samples/sec: 69.16 - lr: 0.000015
2021-07-15 13:35:04,087 epoch 31 - iter 30/62 - loss 0.09829300 - samples/sec: 69.86 - lr: 0.000015
2021-07-15 13:35:06,833 epoch 31 - iter 36/62 - loss 0.11684799 - samples/sec: 69.94 - lr: 0.000015
2021-07-15 13:35:09,589 epoch 31 - iter 42/62 - loss 0.11433622 - samples/sec: 69.68 - lr: 0.000015
2021-07-15 13:35:12,356 epoch 31 - iter 48/62 - loss 0.11528694 - samples/sec: 69.39 - lr: 0.000015
2021-07-15 13:35:15,122 epoch 31 - iter 54/62 - loss 0.11449971 - samples/sec: 69.45 - lr: 0.000015
2021-07-15 13:35:17,854 epoch 31 - iter 60/62 - loss 0.11351100 - samples/sec: 70.28 - lr: 0.000015
2021-07-15 13:35:18,707 ----------------------------------------------------------------------------------------------------
2021-07-15 13:35:18,708 EPOCH 31 done: loss 0.1151 - lr 0.0000150
2021-07-15 13:35:21,353 DEV : loss 0.23233255743980408 - score 0.9505
2021-07-15 13:35:21,393 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:35:24,479 ----------------------------------------------------------------------------------------------------
2021-07-15 13:35:27,249 epoch 32 - iter 6/62 - loss 0.07280584 - samples/sec: 69.35 - lr: 0.000015
2021-07-15 13:35:29,985 epoch 32 - iter 12/62 - loss 0.08189656 - samples/sec: 70.19 - lr: 0.000015
2021-07-15 13:35:32,748 epoch 32 - iter 18/62 - loss 0.09732560 - samples/sec: 69.49 - lr: 0.000015
2021-07-15 13:35:35,503 epoch 32 - iter 24/62 - loss 0.09879642 - samples/sec: 69.70 - lr: 0.000015
2021-07-15 13:35:38,258 epoch 32 - iter 30/62 - loss 0.10264907 - samples/sec: 69.73 - lr: 0.000015
2021-07-15 13:35:41,001 epoch 32 - iter 36/62 - loss 0.10396956 - samples/sec: 70.01 - lr: 0.000015
2021-07-15 13:35:43,763 epoch 32 - iter 42/62 - loss 0.10621323 - samples/sec: 69.52 - lr: 0.000015
2021-07-15 13:35:46,489 epoch 32 - iter 48/62 - loss 0.10494289 - samples/sec: 70.45 - lr: 0.000015
2021-07-15 13:35:49,236 epoch 32 - iter 54/62 - loss 0.10122662 - samples/sec: 69.93 - lr: 0.000015
2021-07-15 13:35:51,956 epoch 32 - iter 60/62 - loss 0.09717951 - samples/sec: 70.60 - lr: 0.000015
2021-07-15 13:35:52,826 ----------------------------------------------------------------------------------------------------
2021-07-15 13:35:52,826 EPOCH 32 done: loss 0.0978 - lr 0.0000150
2021-07-15 13:35:55,679 DEV : loss 0.23313701152801514 - score 0.9463
2021-07-15 13:35:55,718 BAD EPOCHS (no improvement): 1
2021-07-15 13:35:55,718 ----------------------------------------------------------------------------------------------------
2021-07-15 13:35:58,457 epoch 33 - iter 6/62 - loss 0.13047208 - samples/sec: 70.13 - lr: 0.000015
2021-07-15 13:36:01,218 epoch 33 - iter 12/62 - loss 0.11387332 - samples/sec: 69.55 - lr: 0.000015
2021-07-15 13:36:03,991 epoch 33 - iter 18/62 - loss 0.11001531 - samples/sec: 69.26 - lr: 0.000015
2021-07-15 13:36:06,747 epoch 33 - iter 24/62 - loss 0.10765723 - samples/sec: 69.69 - lr: 0.000015
2021-07-15 13:36:09,509 epoch 33 - iter 30/62 - loss 0.10346633 - samples/sec: 69.52 - lr: 0.000015
2021-07-15 13:36:12,277 epoch 33 - iter 36/62 - loss 0.09625202 - samples/sec: 69.39 - lr: 0.000015
2021-07-15 13:36:15,016 epoch 33 - iter 42/62 - loss 0.09710124 - samples/sec: 70.10 - lr: 0.000015
2021-07-15 13:36:17,793 epoch 33 - iter 48/62 - loss 0.09922392 - samples/sec: 69.18 - lr: 0.000015
2021-07-15 13:36:20,513 epoch 33 - iter 54/62 - loss 0.09987271 - samples/sec: 70.59 - lr: 0.000015
2021-07-15 13:36:23,244 epoch 33 - iter 60/62 - loss 0.10221015 - samples/sec: 70.33 - lr: 0.000015
2021-07-15 13:36:24,107 ----------------------------------------------------------------------------------------------------
2021-07-15 13:36:24,108 EPOCH 33 done: loss 0.1056 - lr 0.0000150
2021-07-15 13:36:26,755 DEV : loss 0.23432135581970215 - score 0.9463
2021-07-15 13:36:26,795 BAD EPOCHS (no improvement): 2
2021-07-15 13:36:26,795 ----------------------------------------------------------------------------------------------------
2021-07-15 13:36:29,531 epoch 34 - iter 6/62 - loss 0.07230657 - samples/sec: 70.20 - lr: 0.000015
2021-07-15 13:36:32,237 epoch 34 - iter 12/62 - loss 0.08882395 - samples/sec: 70.96 - lr: 0.000015
2021-07-15 13:36:34,988 epoch 34 - iter 18/62 - loss 0.08659582 - samples/sec: 69.82 - lr: 0.000015
2021-07-15 13:36:37,753 epoch 34 - iter 24/62 - loss 0.09262460 - samples/sec: 69.45 - lr: 0.000015
2021-07-15 13:36:40,520 epoch 34 - iter 30/62 - loss 0.09102615 - samples/sec: 69.41 - lr: 0.000015
2021-07-15 13:36:43,284 epoch 34 - iter 36/62 - loss 0.09729197 - samples/sec: 69.48 - lr: 0.000015
2021-07-15 13:36:46,041 epoch 34 - iter 42/62 - loss 0.10185215 - samples/sec: 69.65 - lr: 0.000015
2021-07-15 13:36:48,810 epoch 34 - iter 48/62 - loss 0.10292436 - samples/sec: 69.37 - lr: 0.000015
2021-07-15 13:36:51,547 epoch 34 - iter 54/62 - loss 0.10088348 - samples/sec: 70.15 - lr: 0.000015
2021-07-15 13:36:54,296 epoch 34 - iter 60/62 - loss 0.10543253 - samples/sec: 69.88 - lr: 0.000015
2021-07-15 13:36:55,176 ----------------------------------------------------------------------------------------------------
2021-07-15 13:36:55,176 EPOCH 34 done: loss 0.1055 - lr 0.0000150
2021-07-15 13:36:57,825 DEV : loss 0.24021494388580322 - score 0.9475
2021-07-15 13:36:57,864 BAD EPOCHS (no improvement): 3
2021-07-15 13:36:57,864 ----------------------------------------------------------------------------------------------------
2021-07-15 13:37:00,616 epoch 35 - iter 6/62 - loss 0.08907921 - samples/sec: 69.81 - lr: 0.000015
2021-07-15 13:37:03,393 epoch 35 - iter 12/62 - loss 0.11110656 - samples/sec: 69.14 - lr: 0.000015
2021-07-15 13:37:06,121 epoch 35 - iter 18/62 - loss 0.11064725 - samples/sec: 70.40 - lr: 0.000015
2021-07-15 13:37:08,877 epoch 35 - iter 24/62 - loss 0.11437567 - samples/sec: 69.69 - lr: 0.000015
2021-07-15 13:37:11,603 epoch 35 - iter 30/62 - loss 0.10776665 - samples/sec: 70.44 - lr: 0.000015
2021-07-15 13:37:14,359 epoch 35 - iter 36/62 - loss 0.10679848 - samples/sec: 69.69 - lr: 0.000015
2021-07-15 13:37:17,137 epoch 35 - iter 42/62 - loss 0.11446456 - samples/sec: 69.14 - lr: 0.000015
2021-07-15 13:37:19,892 epoch 35 - iter 48/62 - loss 0.10655880 - samples/sec: 69.70 - lr: 0.000015
2021-07-15 13:37:22,641 epoch 35 - iter 54/62 - loss 0.10890240 - samples/sec: 69.87 - lr: 0.000015
2021-07-15 13:37:25,400 epoch 35 - iter 60/62 - loss 0.10890657 - samples/sec: 69.59 - lr: 0.000015
2021-07-15 13:37:26,255 ----------------------------------------------------------------------------------------------------
2021-07-15 13:37:26,255 EPOCH 35 done: loss 0.1077 - lr 0.0000150
2021-07-15 13:37:29,110 DEV : loss 0.23857276141643524 - score 0.9441
Epoch    35: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 13:37:29,150 BAD EPOCHS (no improvement): 4
2021-07-15 13:37:29,150 ----------------------------------------------------------------------------------------------------
2021-07-15 13:37:31,895 epoch 36 - iter 6/62 - loss 0.09088142 - samples/sec: 69.95 - lr: 0.000008
2021-07-15 13:37:34,651 epoch 36 - iter 12/62 - loss 0.09241501 - samples/sec: 69.68 - lr: 0.000008
2021-07-15 13:37:37,404 epoch 36 - iter 18/62 - loss 0.09214072 - samples/sec: 69.78 - lr: 0.000008
2021-07-15 13:37:40,165 epoch 36 - iter 24/62 - loss 0.09508756 - samples/sec: 69.55 - lr: 0.000008
2021-07-15 13:37:42,947 epoch 36 - iter 30/62 - loss 0.09636078 - samples/sec: 69.02 - lr: 0.000008
2021-07-15 13:37:45,673 epoch 36 - iter 36/62 - loss 0.09777682 - samples/sec: 70.45 - lr: 0.000008
2021-07-15 13:37:48,416 epoch 36 - iter 42/62 - loss 0.09273678 - samples/sec: 70.01 - lr: 0.000008
2021-07-15 13:37:51,163 epoch 36 - iter 48/62 - loss 0.08941335 - samples/sec: 69.91 - lr: 0.000008
2021-07-15 13:37:53,921 epoch 36 - iter 54/62 - loss 0.09143925 - samples/sec: 69.65 - lr: 0.000008
2021-07-15 13:37:56,677 epoch 36 - iter 60/62 - loss 0.09216352 - samples/sec: 69.68 - lr: 0.000008
2021-07-15 13:37:57,535 ----------------------------------------------------------------------------------------------------
2021-07-15 13:37:57,535 EPOCH 36 done: loss 0.0920 - lr 0.0000075
2021-07-15 13:38:00,178 DEV : loss 0.24007533490657806 - score 0.9472
2021-07-15 13:38:00,217 BAD EPOCHS (no improvement): 1
2021-07-15 13:38:00,217 ----------------------------------------------------------------------------------------------------
2021-07-15 13:38:03,000 epoch 37 - iter 6/62 - loss 0.09720258 - samples/sec: 69.02 - lr: 0.000008
2021-07-15 13:38:05,764 epoch 37 - iter 12/62 - loss 0.11079708 - samples/sec: 69.47 - lr: 0.000008
2021-07-15 13:38:08,525 epoch 37 - iter 18/62 - loss 0.11994794 - samples/sec: 69.57 - lr: 0.000008
2021-07-15 13:38:11,284 epoch 37 - iter 24/62 - loss 0.11296381 - samples/sec: 69.60 - lr: 0.000008
2021-07-15 13:38:14,033 epoch 37 - iter 30/62 - loss 0.10747247 - samples/sec: 69.84 - lr: 0.000008
2021-07-15 13:38:16,793 epoch 37 - iter 36/62 - loss 0.10842829 - samples/sec: 69.60 - lr: 0.000008
2021-07-15 13:38:19,547 epoch 37 - iter 42/62 - loss 0.10643406 - samples/sec: 69.71 - lr: 0.000008
2021-07-15 13:38:22,300 epoch 37 - iter 48/62 - loss 0.10752658 - samples/sec: 69.77 - lr: 0.000008
2021-07-15 13:38:25,013 epoch 37 - iter 54/62 - loss 0.10374263 - samples/sec: 70.77 - lr: 0.000008
2021-07-15 13:38:27,739 epoch 37 - iter 60/62 - loss 0.10302393 - samples/sec: 70.44 - lr: 0.000008
2021-07-15 13:38:28,582 ----------------------------------------------------------------------------------------------------
2021-07-15 13:38:28,582 EPOCH 37 done: loss 0.1017 - lr 0.0000075
2021-07-15 13:38:31,223 DEV : loss 0.24057231843471527 - score 0.948
2021-07-15 13:38:31,261 BAD EPOCHS (no improvement): 2
2021-07-15 13:38:31,262 ----------------------------------------------------------------------------------------------------
2021-07-15 13:38:33,980 epoch 38 - iter 6/62 - loss 0.11904333 - samples/sec: 70.65 - lr: 0.000008
2021-07-15 13:38:36,648 epoch 38 - iter 12/62 - loss 0.09410555 - samples/sec: 71.98 - lr: 0.000008
2021-07-15 13:38:39,354 epoch 38 - iter 18/62 - loss 0.09177442 - samples/sec: 70.96 - lr: 0.000008
2021-07-15 13:38:42,058 epoch 38 - iter 24/62 - loss 0.08944375 - samples/sec: 71.03 - lr: 0.000008
2021-07-15 13:38:44,754 epoch 38 - iter 30/62 - loss 0.08810692 - samples/sec: 71.24 - lr: 0.000008
2021-07-15 13:38:47,455 epoch 38 - iter 36/62 - loss 0.08737588 - samples/sec: 71.11 - lr: 0.000008
2021-07-15 13:38:50,159 epoch 38 - iter 42/62 - loss 0.08554534 - samples/sec: 71.01 - lr: 0.000008
2021-07-15 13:38:52,883 epoch 38 - iter 48/62 - loss 0.09215120 - samples/sec: 70.52 - lr: 0.000008
2021-07-15 13:38:55,607 epoch 38 - iter 54/62 - loss 0.08954685 - samples/sec: 70.49 - lr: 0.000008
2021-07-15 13:38:58,299 epoch 38 - iter 60/62 - loss 0.08831074 - samples/sec: 71.33 - lr: 0.000008
2021-07-15 13:38:59,162 ----------------------------------------------------------------------------------------------------
2021-07-15 13:38:59,162 EPOCH 38 done: loss 0.0877 - lr 0.0000075
2021-07-15 13:39:02,002 DEV : loss 0.23723335564136505 - score 0.9506
2021-07-15 13:39:02,041 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:39:05,413 ----------------------------------------------------------------------------------------------------
2021-07-15 13:39:08,127 epoch 39 - iter 6/62 - loss 0.11596055 - samples/sec: 70.75 - lr: 0.000008
2021-07-15 13:39:10,858 epoch 39 - iter 12/62 - loss 0.14571248 - samples/sec: 70.34 - lr: 0.000008
2021-07-15 13:39:13,583 epoch 39 - iter 18/62 - loss 0.12322325 - samples/sec: 70.46 - lr: 0.000008
2021-07-15 13:39:16,311 epoch 39 - iter 24/62 - loss 0.11612998 - samples/sec: 70.39 - lr: 0.000008
2021-07-15 13:39:19,039 epoch 39 - iter 30/62 - loss 0.11465189 - samples/sec: 70.40 - lr: 0.000008
2021-07-15 13:39:21,768 epoch 39 - iter 36/62 - loss 0.10655942 - samples/sec: 70.38 - lr: 0.000008
2021-07-15 13:39:24,489 epoch 39 - iter 42/62 - loss 0.11054517 - samples/sec: 70.57 - lr: 0.000008
2021-07-15 13:39:27,232 epoch 39 - iter 48/62 - loss 0.11290273 - samples/sec: 70.01 - lr: 0.000008
2021-07-15 13:39:29,996 epoch 39 - iter 54/62 - loss 0.10734491 - samples/sec: 69.48 - lr: 0.000008
2021-07-15 13:39:32,701 epoch 39 - iter 60/62 - loss 0.10804385 - samples/sec: 71.01 - lr: 0.000008
2021-07-15 13:39:33,575 ----------------------------------------------------------------------------------------------------
2021-07-15 13:39:33,575 EPOCH 39 done: loss 0.1061 - lr 0.0000075
2021-07-15 13:39:36,222 DEV : loss 0.24055610597133636 - score 0.9486
2021-07-15 13:39:36,261 BAD EPOCHS (no improvement): 1
2021-07-15 13:39:36,261 ----------------------------------------------------------------------------------------------------
2021-07-15 13:39:39,008 epoch 40 - iter 6/62 - loss 0.09307547 - samples/sec: 69.91 - lr: 0.000008
2021-07-15 13:39:41,736 epoch 40 - iter 12/62 - loss 0.09691642 - samples/sec: 70.40 - lr: 0.000008
2021-07-15 13:39:44,493 epoch 40 - iter 18/62 - loss 0.07910493 - samples/sec: 69.65 - lr: 0.000008
2021-07-15 13:39:47,195 epoch 40 - iter 24/62 - loss 0.07948831 - samples/sec: 71.08 - lr: 0.000008
2021-07-15 13:39:49,901 epoch 40 - iter 30/62 - loss 0.08080328 - samples/sec: 70.98 - lr: 0.000008
2021-07-15 13:39:52,635 epoch 40 - iter 36/62 - loss 0.09430339 - samples/sec: 70.24 - lr: 0.000008
2021-07-15 13:39:55,364 epoch 40 - iter 42/62 - loss 0.09446666 - samples/sec: 70.37 - lr: 0.000008
2021-07-15 13:39:58,112 epoch 40 - iter 48/62 - loss 0.09584193 - samples/sec: 69.90 - lr: 0.000008
2021-07-15 13:40:00,837 epoch 40 - iter 54/62 - loss 0.09396046 - samples/sec: 70.47 - lr: 0.000008
2021-07-15 13:40:03,592 epoch 40 - iter 60/62 - loss 0.09190978 - samples/sec: 69.71 - lr: 0.000008
2021-07-15 13:40:04,455 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:04,455 EPOCH 40 done: loss 0.0903 - lr 0.0000075
2021-07-15 13:40:07,109 DEV : loss 0.23965294659137726 - score 0.9483
2021-07-15 13:40:07,148 BAD EPOCHS (no improvement): 2
2021-07-15 13:40:07,787 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:07,787 Testing using best model ...
2021-07-15 13:40:07,787 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.pdtb.cdtb/best-model.pt
2021-07-15 13:40:17,560 0.9702	0.9614	0.9658
2021-07-15 13:40:17,560 
Results:
- F1-score (micro) 0.9658
- F1-score (macro) 0.9658

By class:
SENT       tp: 423 - fp: 13 - fn: 17 - precision: 0.9702 - recall: 0.9614 - f1-score: 0.9658
2021-07-15 13:40:17,560 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.rststb/
2021-07-15 13:40:17,570 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.rststb
2021-07-15 13:40:17,570 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.rststb/sent_train.txt
2021-07-15 13:40:17,571 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.rststb/sent_dev.txt
2021-07-15 13:40:17,572 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.rststb/sent_test.txt
Corpus: 1472 train + 372 dev + 672 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 13:40:21,061 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:21,062 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 13:40:21,063 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:21,063 Corpus: "Corpus: 1472 train + 372 dev + 672 test sentences"
2021-07-15 13:40:21,063 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:21,063 Parameters:
2021-07-15 13:40:21,063  - learning_rate: "3e-05"
2021-07-15 13:40:21,063  - mini_batch_size: "32"
2021-07-15 13:40:21,063  - patience: "3"
2021-07-15 13:40:21,063  - anneal_factor: "0.5"
2021-07-15 13:40:21,063  - max_epochs: "40"
2021-07-15 13:40:21,063  - shuffle: "True"
2021-07-15 13:40:21,063  - train_with_dev: "False"
2021-07-15 13:40:21,063  - batch_growth_annealing: "False"
2021-07-15 13:40:21,063 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:21,063 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.rststb"
2021-07-15 13:40:21,063 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:21,063 Device: cuda:0
2021-07-15 13:40:21,063 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:21,063 Embeddings storage mode: cpu
2021-07-15 13:40:21,066 ----------------------------------------------------------------------------------------------------
2021-07-15 13:40:24,930 epoch 1 - iter 4/46 - loss 29.01247406 - samples/sec: 33.13 - lr: 0.000030
2021-07-15 13:40:28,797 epoch 1 - iter 8/46 - loss 24.23011804 - samples/sec: 33.10 - lr: 0.000030
2021-07-15 13:40:32,650 epoch 1 - iter 12/46 - loss 20.58384864 - samples/sec: 33.23 - lr: 0.000030
2021-07-15 13:40:36,486 epoch 1 - iter 16/46 - loss 17.55499929 - samples/sec: 33.37 - lr: 0.000030
2021-07-15 13:40:40,360 epoch 1 - iter 20/46 - loss 15.30369818 - samples/sec: 33.05 - lr: 0.000030
2021-07-15 13:40:44,188 epoch 1 - iter 24/46 - loss 13.49445263 - samples/sec: 33.44 - lr: 0.000030
2021-07-15 13:40:48,031 epoch 1 - iter 28/46 - loss 12.08799142 - samples/sec: 33.31 - lr: 0.000030
2021-07-15 13:40:51,865 epoch 1 - iter 32/46 - loss 10.96321924 - samples/sec: 33.39 - lr: 0.000030
2021-07-15 13:40:55,752 epoch 1 - iter 36/46 - loss 10.07003874 - samples/sec: 32.94 - lr: 0.000030
2021-07-15 13:40:59,773 epoch 1 - iter 40/46 - loss 9.30204695 - samples/sec: 31.83 - lr: 0.000030
2021-07-15 13:41:03,642 epoch 1 - iter 44/46 - loss 8.68149531 - samples/sec: 33.09 - lr: 0.000030
2021-07-15 13:41:05,598 ----------------------------------------------------------------------------------------------------
2021-07-15 13:41:05,598 EPOCH 1 done: loss 8.3936 - lr 0.0000300
2021-07-15 13:41:12,230 DEV : loss 1.5220783948898315 - score 0.146
2021-07-15 13:41:12,255 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:41:12,932 ----------------------------------------------------------------------------------------------------
2021-07-15 13:41:14,897 epoch 2 - iter 4/46 - loss 1.68456081 - samples/sec: 65.18 - lr: 0.000030
2021-07-15 13:41:16,882 epoch 2 - iter 8/46 - loss 1.62395689 - samples/sec: 64.48 - lr: 0.000030
2021-07-15 13:41:18,863 epoch 2 - iter 12/46 - loss 1.54274877 - samples/sec: 64.64 - lr: 0.000030
2021-07-15 13:41:20,866 epoch 2 - iter 16/46 - loss 1.44849926 - samples/sec: 63.92 - lr: 0.000030
2021-07-15 13:41:22,831 epoch 2 - iter 20/46 - loss 1.34793857 - samples/sec: 65.16 - lr: 0.000030
2021-07-15 13:41:24,792 epoch 2 - iter 24/46 - loss 1.28436161 - samples/sec: 65.28 - lr: 0.000030
2021-07-15 13:41:26,764 epoch 2 - iter 28/46 - loss 1.23611044 - samples/sec: 64.92 - lr: 0.000030
2021-07-15 13:41:28,747 epoch 2 - iter 32/46 - loss 1.20190503 - samples/sec: 64.57 - lr: 0.000030
2021-07-15 13:41:30,752 epoch 2 - iter 36/46 - loss 1.15892945 - samples/sec: 63.85 - lr: 0.000030
2021-07-15 13:41:32,734 epoch 2 - iter 40/46 - loss 1.11656330 - samples/sec: 64.63 - lr: 0.000030
2021-07-15 13:41:34,739 epoch 2 - iter 44/46 - loss 1.07623020 - samples/sec: 63.86 - lr: 0.000030
2021-07-15 13:41:35,725 ----------------------------------------------------------------------------------------------------
2021-07-15 13:41:35,726 EPOCH 2 done: loss 1.0623 - lr 0.0000300
2021-07-15 13:41:37,710 DEV : loss 0.3723333775997162 - score 0.9149
2021-07-15 13:41:37,736 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:41:41,227 ----------------------------------------------------------------------------------------------------
2021-07-15 13:41:43,188 epoch 3 - iter 4/46 - loss 0.64722192 - samples/sec: 65.30 - lr: 0.000030
2021-07-15 13:41:45,157 epoch 3 - iter 8/46 - loss 0.58042232 - samples/sec: 65.01 - lr: 0.000030
2021-07-15 13:41:47,125 epoch 3 - iter 12/46 - loss 0.58066251 - samples/sec: 65.06 - lr: 0.000030
2021-07-15 13:41:49,101 epoch 3 - iter 16/46 - loss 0.55339905 - samples/sec: 64.81 - lr: 0.000030
2021-07-15 13:41:51,099 epoch 3 - iter 20/46 - loss 0.54073521 - samples/sec: 64.08 - lr: 0.000030
2021-07-15 13:41:53,085 epoch 3 - iter 24/46 - loss 0.54246150 - samples/sec: 64.48 - lr: 0.000030
2021-07-15 13:41:55,078 epoch 3 - iter 28/46 - loss 0.52647376 - samples/sec: 64.24 - lr: 0.000030
2021-07-15 13:41:57,072 epoch 3 - iter 32/46 - loss 0.51943258 - samples/sec: 64.18 - lr: 0.000030
2021-07-15 13:41:59,078 epoch 3 - iter 36/46 - loss 0.51549343 - samples/sec: 63.83 - lr: 0.000030
2021-07-15 13:42:01,060 epoch 3 - iter 40/46 - loss 0.51141298 - samples/sec: 64.61 - lr: 0.000030
2021-07-15 13:42:03,075 epoch 3 - iter 44/46 - loss 0.50806821 - samples/sec: 63.53 - lr: 0.000030
2021-07-15 13:42:04,064 ----------------------------------------------------------------------------------------------------
2021-07-15 13:42:04,064 EPOCH 3 done: loss 0.5036 - lr 0.0000300
2021-07-15 13:42:06,224 DEV : loss 0.2869081497192383 - score 0.9274
2021-07-15 13:42:06,250 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:42:09,841 ----------------------------------------------------------------------------------------------------
2021-07-15 13:42:11,819 epoch 4 - iter 4/46 - loss 0.47950149 - samples/sec: 64.77 - lr: 0.000030
2021-07-15 13:42:13,769 epoch 4 - iter 8/46 - loss 0.50204899 - samples/sec: 65.64 - lr: 0.000030
2021-07-15 13:42:15,778 epoch 4 - iter 12/46 - loss 0.45917787 - samples/sec: 63.74 - lr: 0.000030
2021-07-15 13:42:17,786 epoch 4 - iter 16/46 - loss 0.47363655 - samples/sec: 63.75 - lr: 0.000030
2021-07-15 13:42:19,764 epoch 4 - iter 20/46 - loss 0.46535302 - samples/sec: 64.74 - lr: 0.000030
2021-07-15 13:42:21,749 epoch 4 - iter 24/46 - loss 0.46453904 - samples/sec: 64.51 - lr: 0.000030
2021-07-15 13:42:23,764 epoch 4 - iter 28/46 - loss 0.45825167 - samples/sec: 63.52 - lr: 0.000030
2021-07-15 13:42:25,761 epoch 4 - iter 32/46 - loss 0.44639570 - samples/sec: 64.14 - lr: 0.000030
2021-07-15 13:42:27,779 epoch 4 - iter 36/46 - loss 0.45912500 - samples/sec: 63.42 - lr: 0.000030
2021-07-15 13:42:29,794 epoch 4 - iter 40/46 - loss 0.44484102 - samples/sec: 63.54 - lr: 0.000030
2021-07-15 13:42:31,777 epoch 4 - iter 44/46 - loss 0.43905245 - samples/sec: 64.56 - lr: 0.000030
2021-07-15 13:42:32,762 ----------------------------------------------------------------------------------------------------
2021-07-15 13:42:32,762 EPOCH 4 done: loss 0.4320 - lr 0.0000300
2021-07-15 13:42:34,752 DEV : loss 0.2663300335407257 - score 0.9282
2021-07-15 13:42:34,778 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:42:38,477 ----------------------------------------------------------------------------------------------------
2021-07-15 13:42:40,469 epoch 5 - iter 4/46 - loss 0.48120991 - samples/sec: 64.31 - lr: 0.000030
2021-07-15 13:42:42,440 epoch 5 - iter 8/46 - loss 0.45478084 - samples/sec: 64.94 - lr: 0.000030
2021-07-15 13:42:44,441 epoch 5 - iter 12/46 - loss 0.43502437 - samples/sec: 63.99 - lr: 0.000030
2021-07-15 13:42:46,458 epoch 5 - iter 16/46 - loss 0.40923016 - samples/sec: 63.47 - lr: 0.000030
2021-07-15 13:42:48,447 epoch 5 - iter 20/46 - loss 0.39014390 - samples/sec: 64.38 - lr: 0.000030
2021-07-15 13:42:50,480 epoch 5 - iter 24/46 - loss 0.39571131 - samples/sec: 62.99 - lr: 0.000030
2021-07-15 13:42:52,412 epoch 5 - iter 28/46 - loss 0.39288706 - samples/sec: 66.25 - lr: 0.000030
2021-07-15 13:42:54,375 epoch 5 - iter 32/46 - loss 0.39023120 - samples/sec: 65.24 - lr: 0.000030
2021-07-15 13:42:56,378 epoch 5 - iter 36/46 - loss 0.39284654 - samples/sec: 63.90 - lr: 0.000030
2021-07-15 13:42:58,408 epoch 5 - iter 40/46 - loss 0.39741872 - samples/sec: 63.09 - lr: 0.000030
2021-07-15 13:43:00,360 epoch 5 - iter 44/46 - loss 0.39626465 - samples/sec: 65.59 - lr: 0.000030
2021-07-15 13:43:01,372 ----------------------------------------------------------------------------------------------------
2021-07-15 13:43:01,373 EPOCH 5 done: loss 0.3965 - lr 0.0000300
2021-07-15 13:43:03,361 DEV : loss 0.24410901963710785 - score 0.9282
2021-07-15 13:43:03,387 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:43:07,205 ----------------------------------------------------------------------------------------------------
2021-07-15 13:43:09,189 epoch 6 - iter 4/46 - loss 0.44039032 - samples/sec: 64.52 - lr: 0.000030
2021-07-15 13:43:11,181 epoch 6 - iter 8/46 - loss 0.41762166 - samples/sec: 64.28 - lr: 0.000030
2021-07-15 13:43:13,175 epoch 6 - iter 12/46 - loss 0.41256709 - samples/sec: 64.23 - lr: 0.000030
2021-07-15 13:43:15,173 epoch 6 - iter 16/46 - loss 0.41310323 - samples/sec: 64.08 - lr: 0.000030
2021-07-15 13:43:17,159 epoch 6 - iter 20/46 - loss 0.39771270 - samples/sec: 64.45 - lr: 0.000030
2021-07-15 13:43:19,162 epoch 6 - iter 24/46 - loss 0.39529587 - samples/sec: 63.95 - lr: 0.000030
2021-07-15 13:43:21,140 epoch 6 - iter 28/46 - loss 0.37746875 - samples/sec: 64.70 - lr: 0.000030
2021-07-15 13:43:23,133 epoch 6 - iter 32/46 - loss 0.37847382 - samples/sec: 64.25 - lr: 0.000030
2021-07-15 13:43:25,145 epoch 6 - iter 36/46 - loss 0.37698898 - samples/sec: 63.63 - lr: 0.000030
2021-07-15 13:43:27,138 epoch 6 - iter 40/46 - loss 0.37549105 - samples/sec: 64.26 - lr: 0.000030
2021-07-15 13:43:29,104 epoch 6 - iter 44/46 - loss 0.36352348 - samples/sec: 65.13 - lr: 0.000030
2021-07-15 13:43:30,112 ----------------------------------------------------------------------------------------------------
2021-07-15 13:43:30,112 EPOCH 6 done: loss 0.3582 - lr 0.0000300
2021-07-15 13:43:32,092 DEV : loss 0.20736096799373627 - score 0.9401
2021-07-15 13:43:32,118 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:43:35,710 ----------------------------------------------------------------------------------------------------
2021-07-15 13:43:37,708 epoch 7 - iter 4/46 - loss 0.25390279 - samples/sec: 64.11 - lr: 0.000030
2021-07-15 13:43:39,674 epoch 7 - iter 8/46 - loss 0.35823685 - samples/sec: 65.13 - lr: 0.000030
2021-07-15 13:43:41,697 epoch 7 - iter 12/46 - loss 0.32664301 - samples/sec: 63.29 - lr: 0.000030
2021-07-15 13:43:43,658 epoch 7 - iter 16/46 - loss 0.32218651 - samples/sec: 65.30 - lr: 0.000030
2021-07-15 13:43:45,672 epoch 7 - iter 20/46 - loss 0.31314879 - samples/sec: 63.56 - lr: 0.000030
2021-07-15 13:43:47,828 epoch 7 - iter 24/46 - loss 0.30286178 - samples/sec: 59.38 - lr: 0.000030
2021-07-15 13:43:49,810 epoch 7 - iter 28/46 - loss 0.29483858 - samples/sec: 64.61 - lr: 0.000030
2021-07-15 13:43:51,794 epoch 7 - iter 32/46 - loss 0.29389667 - samples/sec: 64.53 - lr: 0.000030
2021-07-15 13:43:53,788 epoch 7 - iter 36/46 - loss 0.29669770 - samples/sec: 64.22 - lr: 0.000030
2021-07-15 13:43:55,812 epoch 7 - iter 40/46 - loss 0.29654471 - samples/sec: 63.27 - lr: 0.000030
2021-07-15 13:43:57,801 epoch 7 - iter 44/46 - loss 0.29403718 - samples/sec: 64.37 - lr: 0.000030
2021-07-15 13:43:58,806 ----------------------------------------------------------------------------------------------------
2021-07-15 13:43:58,807 EPOCH 7 done: loss 0.2945 - lr 0.0000300
2021-07-15 13:44:00,799 DEV : loss 0.18621277809143066 - score 0.9436
2021-07-15 13:44:00,825 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:44:04,797 ----------------------------------------------------------------------------------------------------
2021-07-15 13:44:06,788 epoch 8 - iter 4/46 - loss 0.22758766 - samples/sec: 64.30 - lr: 0.000030
2021-07-15 13:44:08,744 epoch 8 - iter 8/46 - loss 0.30712627 - samples/sec: 65.46 - lr: 0.000030
2021-07-15 13:44:10,721 epoch 8 - iter 12/46 - loss 0.30283798 - samples/sec: 64.78 - lr: 0.000030
2021-07-15 13:44:12,683 epoch 8 - iter 16/46 - loss 0.30736018 - samples/sec: 65.24 - lr: 0.000030
2021-07-15 13:44:14,694 epoch 8 - iter 20/46 - loss 0.30539514 - samples/sec: 63.67 - lr: 0.000030
2021-07-15 13:44:16,686 epoch 8 - iter 24/46 - loss 0.29392696 - samples/sec: 64.27 - lr: 0.000030
2021-07-15 13:44:18,691 epoch 8 - iter 28/46 - loss 0.28510811 - samples/sec: 63.87 - lr: 0.000030
2021-07-15 13:44:20,710 epoch 8 - iter 32/46 - loss 0.27971739 - samples/sec: 63.43 - lr: 0.000030
2021-07-15 13:44:22,717 epoch 8 - iter 36/46 - loss 0.28642227 - samples/sec: 63.78 - lr: 0.000030
2021-07-15 13:44:24,663 epoch 8 - iter 40/46 - loss 0.28048852 - samples/sec: 65.79 - lr: 0.000030
2021-07-15 13:44:26,675 epoch 8 - iter 44/46 - loss 0.26927393 - samples/sec: 63.63 - lr: 0.000030
2021-07-15 13:44:27,684 ----------------------------------------------------------------------------------------------------
2021-07-15 13:44:27,685 EPOCH 8 done: loss 0.2762 - lr 0.0000300
2021-07-15 13:44:29,666 DEV : loss 0.18099534511566162 - score 0.9436
2021-07-15 13:44:29,691 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:44:33,220 ----------------------------------------------------------------------------------------------------
2021-07-15 13:44:35,232 epoch 9 - iter 4/46 - loss 0.34222344 - samples/sec: 63.65 - lr: 0.000030
2021-07-15 13:44:37,181 epoch 9 - iter 8/46 - loss 0.26874044 - samples/sec: 65.69 - lr: 0.000030
2021-07-15 13:44:39,155 epoch 9 - iter 12/46 - loss 0.25449892 - samples/sec: 64.85 - lr: 0.000030
2021-07-15 13:44:41,148 epoch 9 - iter 16/46 - loss 0.25816528 - samples/sec: 64.27 - lr: 0.000030
2021-07-15 13:44:43,164 epoch 9 - iter 20/46 - loss 0.25554704 - samples/sec: 63.50 - lr: 0.000030
2021-07-15 13:44:45,132 epoch 9 - iter 24/46 - loss 0.25251584 - samples/sec: 65.08 - lr: 0.000030
2021-07-15 13:44:47,164 epoch 9 - iter 28/46 - loss 0.24848504 - samples/sec: 63.01 - lr: 0.000030
2021-07-15 13:44:49,159 epoch 9 - iter 32/46 - loss 0.24597012 - samples/sec: 64.16 - lr: 0.000030
2021-07-15 13:44:51,149 epoch 9 - iter 36/46 - loss 0.25119637 - samples/sec: 64.36 - lr: 0.000030
2021-07-15 13:44:53,130 epoch 9 - iter 40/46 - loss 0.26353951 - samples/sec: 64.63 - lr: 0.000030
2021-07-15 13:44:55,177 epoch 9 - iter 44/46 - loss 0.25235216 - samples/sec: 62.54 - lr: 0.000030
2021-07-15 13:44:56,161 ----------------------------------------------------------------------------------------------------
2021-07-15 13:44:56,161 EPOCH 9 done: loss 0.2506 - lr 0.0000300
2021-07-15 13:44:58,157 DEV : loss 0.16897337138652802 - score 0.9474
2021-07-15 13:44:58,183 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:45:01,708 ----------------------------------------------------------------------------------------------------
2021-07-15 13:45:03,725 epoch 10 - iter 4/46 - loss 0.22870215 - samples/sec: 63.48 - lr: 0.000030
2021-07-15 13:45:05,670 epoch 10 - iter 8/46 - loss 0.26139739 - samples/sec: 65.82 - lr: 0.000030
2021-07-15 13:45:07,654 epoch 10 - iter 12/46 - loss 0.23763212 - samples/sec: 64.53 - lr: 0.000030
2021-07-15 13:45:09,614 epoch 10 - iter 16/46 - loss 0.23880075 - samples/sec: 65.32 - lr: 0.000030
2021-07-15 13:45:11,591 epoch 10 - iter 20/46 - loss 0.23211060 - samples/sec: 64.77 - lr: 0.000030
2021-07-15 13:45:13,570 epoch 10 - iter 24/46 - loss 0.23357998 - samples/sec: 64.70 - lr: 0.000030
2021-07-15 13:45:15,588 epoch 10 - iter 28/46 - loss 0.22978345 - samples/sec: 63.44 - lr: 0.000030
2021-07-15 13:45:17,640 epoch 10 - iter 32/46 - loss 0.23162924 - samples/sec: 62.40 - lr: 0.000030
2021-07-15 13:45:19,685 epoch 10 - iter 36/46 - loss 0.22577465 - samples/sec: 62.61 - lr: 0.000030
2021-07-15 13:45:21,696 epoch 10 - iter 40/46 - loss 0.22263061 - samples/sec: 63.65 - lr: 0.000030
2021-07-15 13:45:23,692 epoch 10 - iter 44/46 - loss 0.21966514 - samples/sec: 64.15 - lr: 0.000030
2021-07-15 13:45:24,672 ----------------------------------------------------------------------------------------------------
2021-07-15 13:45:24,672 EPOCH 10 done: loss 0.2176 - lr 0.0000300
2021-07-15 13:45:26,845 DEV : loss 0.15333563089370728 - score 0.9526
2021-07-15 13:45:26,871 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:45:30,457 ----------------------------------------------------------------------------------------------------
2021-07-15 13:45:32,457 epoch 11 - iter 4/46 - loss 0.26775715 - samples/sec: 64.03 - lr: 0.000030
2021-07-15 13:45:34,429 epoch 11 - iter 8/46 - loss 0.21085897 - samples/sec: 64.93 - lr: 0.000030
2021-07-15 13:45:36,438 epoch 11 - iter 12/46 - loss 0.21540906 - samples/sec: 63.73 - lr: 0.000030
2021-07-15 13:45:38,417 epoch 11 - iter 16/46 - loss 0.22334301 - samples/sec: 64.71 - lr: 0.000030
2021-07-15 13:45:40,400 epoch 11 - iter 20/46 - loss 0.22670304 - samples/sec: 64.57 - lr: 0.000030
2021-07-15 13:45:42,425 epoch 11 - iter 24/46 - loss 0.21692037 - samples/sec: 63.21 - lr: 0.000030
2021-07-15 13:45:44,443 epoch 11 - iter 28/46 - loss 0.20743788 - samples/sec: 63.45 - lr: 0.000030
2021-07-15 13:45:46,405 epoch 11 - iter 32/46 - loss 0.21412962 - samples/sec: 65.25 - lr: 0.000030
2021-07-15 13:45:48,399 epoch 11 - iter 36/46 - loss 0.22279654 - samples/sec: 64.22 - lr: 0.000030
2021-07-15 13:45:50,410 epoch 11 - iter 40/46 - loss 0.22370965 - samples/sec: 63.67 - lr: 0.000030
2021-07-15 13:45:52,430 epoch 11 - iter 44/46 - loss 0.22472746 - samples/sec: 63.37 - lr: 0.000030
2021-07-15 13:45:53,447 ----------------------------------------------------------------------------------------------------
2021-07-15 13:45:53,448 EPOCH 11 done: loss 0.2245 - lr 0.0000300
2021-07-15 13:45:55,433 DEV : loss 0.14940229058265686 - score 0.9518
2021-07-15 13:45:55,459 BAD EPOCHS (no improvement): 1
2021-07-15 13:45:55,459 ----------------------------------------------------------------------------------------------------
2021-07-15 13:45:57,460 epoch 12 - iter 4/46 - loss 0.12767158 - samples/sec: 64.00 - lr: 0.000030
2021-07-15 13:45:59,483 epoch 12 - iter 8/46 - loss 0.17181756 - samples/sec: 63.30 - lr: 0.000030
2021-07-15 13:46:01,493 epoch 12 - iter 12/46 - loss 0.18719371 - samples/sec: 63.69 - lr: 0.000030
2021-07-15 13:46:03,501 epoch 12 - iter 16/46 - loss 0.20146202 - samples/sec: 63.76 - lr: 0.000030
2021-07-15 13:46:05,519 epoch 12 - iter 20/46 - loss 0.19187256 - samples/sec: 63.45 - lr: 0.000030
2021-07-15 13:46:07,488 epoch 12 - iter 24/46 - loss 0.19629272 - samples/sec: 65.03 - lr: 0.000030
2021-07-15 13:46:09,484 epoch 12 - iter 28/46 - loss 0.19577142 - samples/sec: 64.14 - lr: 0.000030
2021-07-15 13:46:11,468 epoch 12 - iter 32/46 - loss 0.20154590 - samples/sec: 64.53 - lr: 0.000030
2021-07-15 13:46:13,496 epoch 12 - iter 36/46 - loss 0.19666070 - samples/sec: 63.13 - lr: 0.000030
2021-07-15 13:46:15,477 epoch 12 - iter 40/46 - loss 0.19385794 - samples/sec: 64.65 - lr: 0.000030
2021-07-15 13:46:17,479 epoch 12 - iter 44/46 - loss 0.19552934 - samples/sec: 63.93 - lr: 0.000030
2021-07-15 13:46:18,482 ----------------------------------------------------------------------------------------------------
2021-07-15 13:46:18,482 EPOCH 12 done: loss 0.1939 - lr 0.0000300
2021-07-15 13:46:20,466 DEV : loss 0.14496484398841858 - score 0.9542
2021-07-15 13:46:20,492 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:46:24,167 ----------------------------------------------------------------------------------------------------
2021-07-15 13:46:26,184 epoch 13 - iter 4/46 - loss 0.22340442 - samples/sec: 63.47 - lr: 0.000030
2021-07-15 13:46:28,208 epoch 13 - iter 8/46 - loss 0.23878297 - samples/sec: 63.26 - lr: 0.000030
2021-07-15 13:46:30,202 epoch 13 - iter 12/46 - loss 0.22690293 - samples/sec: 64.23 - lr: 0.000030
2021-07-15 13:46:32,177 epoch 13 - iter 16/46 - loss 0.20689875 - samples/sec: 64.81 - lr: 0.000030
2021-07-15 13:46:34,203 epoch 13 - iter 20/46 - loss 0.20329813 - samples/sec: 63.19 - lr: 0.000030
2021-07-15 13:46:36,241 epoch 13 - iter 24/46 - loss 0.20031578 - samples/sec: 62.84 - lr: 0.000030
2021-07-15 13:46:38,199 epoch 13 - iter 28/46 - loss 0.19470194 - samples/sec: 65.37 - lr: 0.000030
2021-07-15 13:46:40,200 epoch 13 - iter 32/46 - loss 0.19153990 - samples/sec: 63.98 - lr: 0.000030
2021-07-15 13:46:42,230 epoch 13 - iter 36/46 - loss 0.18440759 - samples/sec: 63.07 - lr: 0.000030
2021-07-15 13:46:44,231 epoch 13 - iter 40/46 - loss 0.18553632 - samples/sec: 64.00 - lr: 0.000030
2021-07-15 13:46:46,235 epoch 13 - iter 44/46 - loss 0.18135769 - samples/sec: 63.89 - lr: 0.000030
2021-07-15 13:46:47,213 ----------------------------------------------------------------------------------------------------
2021-07-15 13:46:47,213 EPOCH 13 done: loss 0.1791 - lr 0.0000300
2021-07-15 13:46:49,200 DEV : loss 0.15445943176746368 - score 0.9565
2021-07-15 13:46:49,226 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:46:52,852 ----------------------------------------------------------------------------------------------------
2021-07-15 13:46:54,833 epoch 14 - iter 4/46 - loss 0.20976128 - samples/sec: 64.64 - lr: 0.000030
2021-07-15 13:46:56,796 epoch 14 - iter 8/46 - loss 0.22488852 - samples/sec: 65.20 - lr: 0.000030
2021-07-15 13:46:58,830 epoch 14 - iter 12/46 - loss 0.20063896 - samples/sec: 62.96 - lr: 0.000030
2021-07-15 13:47:00,872 epoch 14 - iter 16/46 - loss 0.17921190 - samples/sec: 62.71 - lr: 0.000030
2021-07-15 13:47:02,866 epoch 14 - iter 20/46 - loss 0.18001671 - samples/sec: 64.21 - lr: 0.000030
2021-07-15 13:47:04,863 epoch 14 - iter 24/46 - loss 0.18995208 - samples/sec: 64.10 - lr: 0.000030
2021-07-15 13:47:06,865 epoch 14 - iter 28/46 - loss 0.18671100 - samples/sec: 63.98 - lr: 0.000030
2021-07-15 13:47:08,809 epoch 14 - iter 32/46 - loss 0.18200272 - samples/sec: 65.85 - lr: 0.000030
2021-07-15 13:47:10,824 epoch 14 - iter 36/46 - loss 0.18091770 - samples/sec: 63.53 - lr: 0.000030
2021-07-15 13:47:12,820 epoch 14 - iter 40/46 - loss 0.17878117 - samples/sec: 64.15 - lr: 0.000030
2021-07-15 13:47:14,834 epoch 14 - iter 44/46 - loss 0.17383851 - samples/sec: 63.57 - lr: 0.000030
2021-07-15 13:47:15,861 ----------------------------------------------------------------------------------------------------
2021-07-15 13:47:15,861 EPOCH 14 done: loss 0.1724 - lr 0.0000300
2021-07-15 13:47:18,030 DEV : loss 0.12268855422735214 - score 0.9632
2021-07-15 13:47:18,057 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:47:21,754 ----------------------------------------------------------------------------------------------------
2021-07-15 13:47:23,731 epoch 15 - iter 4/46 - loss 0.19353574 - samples/sec: 64.77 - lr: 0.000030
2021-07-15 13:47:25,731 epoch 15 - iter 8/46 - loss 0.15617175 - samples/sec: 64.02 - lr: 0.000030
2021-07-15 13:47:27,728 epoch 15 - iter 12/46 - loss 0.13801232 - samples/sec: 64.13 - lr: 0.000030
2021-07-15 13:47:29,739 epoch 15 - iter 16/46 - loss 0.16018266 - samples/sec: 63.65 - lr: 0.000030
2021-07-15 13:47:31,765 epoch 15 - iter 20/46 - loss 0.14573139 - samples/sec: 63.19 - lr: 0.000030
2021-07-15 13:47:33,807 epoch 15 - iter 24/46 - loss 0.14137110 - samples/sec: 62.73 - lr: 0.000030
2021-07-15 13:47:35,816 epoch 15 - iter 28/46 - loss 0.14434337 - samples/sec: 63.72 - lr: 0.000030
2021-07-15 13:47:37,799 epoch 15 - iter 32/46 - loss 0.14148391 - samples/sec: 64.55 - lr: 0.000030
2021-07-15 13:47:39,786 epoch 15 - iter 36/46 - loss 0.14084331 - samples/sec: 64.47 - lr: 0.000030
2021-07-15 13:47:41,762 epoch 15 - iter 40/46 - loss 0.14582770 - samples/sec: 64.77 - lr: 0.000030
2021-07-15 13:47:43,749 epoch 15 - iter 44/46 - loss 0.14187401 - samples/sec: 64.44 - lr: 0.000030
2021-07-15 13:47:44,745 ----------------------------------------------------------------------------------------------------
2021-07-15 13:47:44,746 EPOCH 15 done: loss 0.1432 - lr 0.0000300
2021-07-15 13:47:46,733 DEV : loss 0.1348395049571991 - score 0.9579
2021-07-15 13:47:46,759 BAD EPOCHS (no improvement): 1
2021-07-15 13:47:46,760 ----------------------------------------------------------------------------------------------------
2021-07-15 13:47:48,721 epoch 16 - iter 4/46 - loss 0.08755953 - samples/sec: 65.28 - lr: 0.000030
2021-07-15 13:47:50,705 epoch 16 - iter 8/46 - loss 0.15074379 - samples/sec: 64.53 - lr: 0.000030
2021-07-15 13:47:52,740 epoch 16 - iter 12/46 - loss 0.15094062 - samples/sec: 62.93 - lr: 0.000030
2021-07-15 13:47:54,756 epoch 16 - iter 16/46 - loss 0.15271135 - samples/sec: 63.50 - lr: 0.000030
2021-07-15 13:47:56,736 epoch 16 - iter 20/46 - loss 0.14793593 - samples/sec: 64.65 - lr: 0.000030
2021-07-15 13:47:58,709 epoch 16 - iter 24/46 - loss 0.14241766 - samples/sec: 64.91 - lr: 0.000030
2021-07-15 13:48:00,695 epoch 16 - iter 28/46 - loss 0.13714773 - samples/sec: 64.46 - lr: 0.000030
2021-07-15 13:48:02,727 epoch 16 - iter 32/46 - loss 0.13927288 - samples/sec: 63.03 - lr: 0.000030
2021-07-15 13:48:04,700 epoch 16 - iter 36/46 - loss 0.13816614 - samples/sec: 64.90 - lr: 0.000030
2021-07-15 13:48:06,693 epoch 16 - iter 40/46 - loss 0.14094016 - samples/sec: 64.22 - lr: 0.000030
2021-07-15 13:48:08,690 epoch 16 - iter 44/46 - loss 0.13985973 - samples/sec: 64.13 - lr: 0.000030
2021-07-15 13:48:09,696 ----------------------------------------------------------------------------------------------------
2021-07-15 13:48:09,697 EPOCH 16 done: loss 0.1404 - lr 0.0000300
2021-07-15 13:48:11,680 DEV : loss 0.12558305263519287 - score 0.9575
2021-07-15 13:48:11,706 BAD EPOCHS (no improvement): 2
2021-07-15 13:48:11,707 ----------------------------------------------------------------------------------------------------
2021-07-15 13:48:13,730 epoch 17 - iter 4/46 - loss 0.12701588 - samples/sec: 63.29 - lr: 0.000030
2021-07-15 13:48:15,747 epoch 17 - iter 8/46 - loss 0.11966264 - samples/sec: 63.48 - lr: 0.000030
2021-07-15 13:48:17,796 epoch 17 - iter 12/46 - loss 0.13705518 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 13:48:19,724 epoch 17 - iter 16/46 - loss 0.13267089 - samples/sec: 66.42 - lr: 0.000030
2021-07-15 13:48:21,737 epoch 17 - iter 20/46 - loss 0.14198653 - samples/sec: 63.59 - lr: 0.000030
2021-07-15 13:48:23,749 epoch 17 - iter 24/46 - loss 0.14375902 - samples/sec: 63.66 - lr: 0.000030
2021-07-15 13:48:25,738 epoch 17 - iter 28/46 - loss 0.13707505 - samples/sec: 64.37 - lr: 0.000030
2021-07-15 13:48:27,749 epoch 17 - iter 32/46 - loss 0.13982666 - samples/sec: 63.67 - lr: 0.000030
2021-07-15 13:48:29,761 epoch 17 - iter 36/46 - loss 0.14520672 - samples/sec: 63.63 - lr: 0.000030
2021-07-15 13:48:31,772 epoch 17 - iter 40/46 - loss 0.14262786 - samples/sec: 63.67 - lr: 0.000030
2021-07-15 13:48:33,809 epoch 17 - iter 44/46 - loss 0.14343783 - samples/sec: 62.86 - lr: 0.000030
2021-07-15 13:48:34,828 ----------------------------------------------------------------------------------------------------
2021-07-15 13:48:34,828 EPOCH 17 done: loss 0.1411 - lr 0.0000300
2021-07-15 13:48:36,813 DEV : loss 0.11742265522480011 - score 0.9651
2021-07-15 13:48:36,839 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:48:40,468 ----------------------------------------------------------------------------------------------------
2021-07-15 13:48:42,501 epoch 18 - iter 4/46 - loss 0.18585154 - samples/sec: 62.99 - lr: 0.000030
2021-07-15 13:48:44,460 epoch 18 - iter 8/46 - loss 0.16605204 - samples/sec: 65.35 - lr: 0.000030
2021-07-15 13:48:46,453 epoch 18 - iter 12/46 - loss 0.15229829 - samples/sec: 64.26 - lr: 0.000030
2021-07-15 13:48:48,442 epoch 18 - iter 16/46 - loss 0.13948599 - samples/sec: 64.36 - lr: 0.000030
2021-07-15 13:48:50,473 epoch 18 - iter 20/46 - loss 0.14945971 - samples/sec: 63.03 - lr: 0.000030
2021-07-15 13:48:52,476 epoch 18 - iter 24/46 - loss 0.13723702 - samples/sec: 63.94 - lr: 0.000030
2021-07-15 13:48:54,512 epoch 18 - iter 28/46 - loss 0.13780572 - samples/sec: 62.87 - lr: 0.000030
2021-07-15 13:48:56,533 epoch 18 - iter 32/46 - loss 0.14671611 - samples/sec: 63.37 - lr: 0.000030
2021-07-15 13:48:58,565 epoch 18 - iter 36/46 - loss 0.14903171 - samples/sec: 63.00 - lr: 0.000030
2021-07-15 13:49:00,577 epoch 18 - iter 40/46 - loss 0.14677625 - samples/sec: 63.63 - lr: 0.000030
2021-07-15 13:49:02,609 epoch 18 - iter 44/46 - loss 0.14878376 - samples/sec: 63.02 - lr: 0.000030
2021-07-15 13:49:03,645 ----------------------------------------------------------------------------------------------------
2021-07-15 13:49:03,645 EPOCH 18 done: loss 0.1495 - lr 0.0000300
2021-07-15 13:49:05,808 DEV : loss 0.12661027908325195 - score 0.9597
2021-07-15 13:49:05,833 BAD EPOCHS (no improvement): 1
2021-07-15 13:49:05,834 ----------------------------------------------------------------------------------------------------
2021-07-15 13:49:07,868 epoch 19 - iter 4/46 - loss 0.12173540 - samples/sec: 62.95 - lr: 0.000030
2021-07-15 13:49:09,864 epoch 19 - iter 8/46 - loss 0.13874756 - samples/sec: 64.14 - lr: 0.000030
2021-07-15 13:49:11,884 epoch 19 - iter 12/46 - loss 0.12272183 - samples/sec: 63.38 - lr: 0.000030
2021-07-15 13:49:13,907 epoch 19 - iter 16/46 - loss 0.13036857 - samples/sec: 63.29 - lr: 0.000030
2021-07-15 13:49:15,914 epoch 19 - iter 20/46 - loss 0.12454443 - samples/sec: 63.80 - lr: 0.000030
2021-07-15 13:49:17,941 epoch 19 - iter 24/46 - loss 0.12311458 - samples/sec: 63.18 - lr: 0.000030
2021-07-15 13:49:19,936 epoch 19 - iter 28/46 - loss 0.12890665 - samples/sec: 64.16 - lr: 0.000030
2021-07-15 13:49:21,944 epoch 19 - iter 32/46 - loss 0.12184195 - samples/sec: 63.75 - lr: 0.000030
2021-07-15 13:49:23,965 epoch 19 - iter 36/46 - loss 0.11821002 - samples/sec: 63.37 - lr: 0.000030
2021-07-15 13:49:25,957 epoch 19 - iter 40/46 - loss 0.11411110 - samples/sec: 64.28 - lr: 0.000030
2021-07-15 13:49:27,977 epoch 19 - iter 44/46 - loss 0.11416327 - samples/sec: 63.37 - lr: 0.000030
2021-07-15 13:49:28,994 ----------------------------------------------------------------------------------------------------
2021-07-15 13:49:28,994 EPOCH 19 done: loss 0.1150 - lr 0.0000300
2021-07-15 13:49:30,975 DEV : loss 0.12545445561408997 - score 0.9614
2021-07-15 13:49:31,000 BAD EPOCHS (no improvement): 2
2021-07-15 13:49:31,000 ----------------------------------------------------------------------------------------------------
2021-07-15 13:49:33,029 epoch 20 - iter 4/46 - loss 0.06643961 - samples/sec: 63.13 - lr: 0.000030
2021-07-15 13:49:35,045 epoch 20 - iter 8/46 - loss 0.10943539 - samples/sec: 63.49 - lr: 0.000030
2021-07-15 13:49:37,061 epoch 20 - iter 12/46 - loss 0.11588350 - samples/sec: 63.52 - lr: 0.000030
2021-07-15 13:49:39,081 epoch 20 - iter 16/46 - loss 0.11551069 - samples/sec: 63.40 - lr: 0.000030
2021-07-15 13:49:41,132 epoch 20 - iter 20/46 - loss 0.12066608 - samples/sec: 62.43 - lr: 0.000030
2021-07-15 13:49:43,127 epoch 20 - iter 24/46 - loss 0.11351792 - samples/sec: 64.17 - lr: 0.000030
2021-07-15 13:49:45,149 epoch 20 - iter 28/46 - loss 0.11385617 - samples/sec: 63.31 - lr: 0.000030
2021-07-15 13:49:47,193 epoch 20 - iter 32/46 - loss 0.11284326 - samples/sec: 62.66 - lr: 0.000030
2021-07-15 13:49:49,202 epoch 20 - iter 36/46 - loss 0.11432270 - samples/sec: 63.74 - lr: 0.000030
2021-07-15 13:49:51,204 epoch 20 - iter 40/46 - loss 0.11833173 - samples/sec: 63.93 - lr: 0.000030
2021-07-15 13:49:53,168 epoch 20 - iter 44/46 - loss 0.11968625 - samples/sec: 65.18 - lr: 0.000030
2021-07-15 13:49:54,168 ----------------------------------------------------------------------------------------------------
2021-07-15 13:49:54,168 EPOCH 20 done: loss 0.1232 - lr 0.0000300
2021-07-15 13:49:56,154 DEV : loss 0.14045485854148865 - score 0.9598
2021-07-15 13:49:56,180 BAD EPOCHS (no improvement): 3
2021-07-15 13:49:56,181 ----------------------------------------------------------------------------------------------------
2021-07-15 13:49:58,178 epoch 21 - iter 4/46 - loss 0.10706489 - samples/sec: 64.09 - lr: 0.000030
2021-07-15 13:50:00,185 epoch 21 - iter 8/46 - loss 0.10545261 - samples/sec: 63.79 - lr: 0.000030
2021-07-15 13:50:02,189 epoch 21 - iter 12/46 - loss 0.10517198 - samples/sec: 63.92 - lr: 0.000030
2021-07-15 13:50:04,238 epoch 21 - iter 16/46 - loss 0.10660311 - samples/sec: 62.48 - lr: 0.000030
2021-07-15 13:50:06,224 epoch 21 - iter 20/46 - loss 0.10417419 - samples/sec: 64.46 - lr: 0.000030
2021-07-15 13:50:08,248 epoch 21 - iter 24/46 - loss 0.10311526 - samples/sec: 63.27 - lr: 0.000030
2021-07-15 13:50:10,273 epoch 21 - iter 28/46 - loss 0.11230887 - samples/sec: 63.22 - lr: 0.000030
2021-07-15 13:50:12,272 epoch 21 - iter 32/46 - loss 0.10830435 - samples/sec: 64.06 - lr: 0.000030
2021-07-15 13:50:14,317 epoch 21 - iter 36/46 - loss 0.11133370 - samples/sec: 62.61 - lr: 0.000030
2021-07-15 13:50:16,332 epoch 21 - iter 40/46 - loss 0.10911410 - samples/sec: 63.55 - lr: 0.000030
2021-07-15 13:50:18,344 epoch 21 - iter 44/46 - loss 0.11409395 - samples/sec: 63.62 - lr: 0.000030
2021-07-15 13:50:19,360 ----------------------------------------------------------------------------------------------------
2021-07-15 13:50:19,361 EPOCH 21 done: loss 0.1127 - lr 0.0000300
2021-07-15 13:50:21,519 DEV : loss 0.13751477003097534 - score 0.9618
Epoch    21: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 13:50:21,545 BAD EPOCHS (no improvement): 4
2021-07-15 13:50:21,545 ----------------------------------------------------------------------------------------------------
2021-07-15 13:50:23,589 epoch 22 - iter 4/46 - loss 0.14609820 - samples/sec: 62.65 - lr: 0.000015
2021-07-15 13:50:25,636 epoch 22 - iter 8/46 - loss 0.14253335 - samples/sec: 62.52 - lr: 0.000015
2021-07-15 13:50:27,637 epoch 22 - iter 12/46 - loss 0.14511840 - samples/sec: 64.00 - lr: 0.000015
2021-07-15 13:50:29,653 epoch 22 - iter 16/46 - loss 0.13849979 - samples/sec: 63.52 - lr: 0.000015
2021-07-15 13:50:31,709 epoch 22 - iter 20/46 - loss 0.13444018 - samples/sec: 62.26 - lr: 0.000015
2021-07-15 13:50:33,721 epoch 22 - iter 24/46 - loss 0.12915551 - samples/sec: 63.64 - lr: 0.000015
2021-07-15 13:50:35,692 epoch 22 - iter 28/46 - loss 0.12442150 - samples/sec: 64.97 - lr: 0.000015
2021-07-15 13:50:37,706 epoch 22 - iter 32/46 - loss 0.12337703 - samples/sec: 63.57 - lr: 0.000015
2021-07-15 13:50:39,752 epoch 22 - iter 36/46 - loss 0.12213353 - samples/sec: 62.57 - lr: 0.000015
2021-07-15 13:50:41,729 epoch 22 - iter 40/46 - loss 0.11822391 - samples/sec: 64.78 - lr: 0.000015
2021-07-15 13:50:43,745 epoch 22 - iter 44/46 - loss 0.11716998 - samples/sec: 63.50 - lr: 0.000015
2021-07-15 13:50:44,741 ----------------------------------------------------------------------------------------------------
2021-07-15 13:50:44,741 EPOCH 22 done: loss 0.1150 - lr 0.0000150
2021-07-15 13:50:46,728 DEV : loss 0.1276364028453827 - score 0.9617
2021-07-15 13:50:46,754 BAD EPOCHS (no improvement): 1
2021-07-15 13:50:46,754 ----------------------------------------------------------------------------------------------------
2021-07-15 13:50:48,768 epoch 23 - iter 4/46 - loss 0.15682368 - samples/sec: 63.57 - lr: 0.000015
2021-07-15 13:50:50,784 epoch 23 - iter 8/46 - loss 0.11541927 - samples/sec: 63.53 - lr: 0.000015
2021-07-15 13:50:52,820 epoch 23 - iter 12/46 - loss 0.10648393 - samples/sec: 62.88 - lr: 0.000015
2021-07-15 13:50:54,836 epoch 23 - iter 16/46 - loss 0.09753885 - samples/sec: 63.50 - lr: 0.000015
2021-07-15 13:50:56,841 epoch 23 - iter 20/46 - loss 0.09643940 - samples/sec: 63.86 - lr: 0.000015
2021-07-15 13:50:58,843 epoch 23 - iter 24/46 - loss 0.09894176 - samples/sec: 63.96 - lr: 0.000015
2021-07-15 13:51:00,904 epoch 23 - iter 28/46 - loss 0.09611578 - samples/sec: 62.11 - lr: 0.000015
2021-07-15 13:51:02,928 epoch 23 - iter 32/46 - loss 0.09487333 - samples/sec: 63.28 - lr: 0.000015
2021-07-15 13:51:04,945 epoch 23 - iter 36/46 - loss 0.10053919 - samples/sec: 63.46 - lr: 0.000015
2021-07-15 13:51:06,946 epoch 23 - iter 40/46 - loss 0.10074606 - samples/sec: 63.98 - lr: 0.000015
2021-07-15 13:51:08,960 epoch 23 - iter 44/46 - loss 0.10506065 - samples/sec: 63.57 - lr: 0.000015
2021-07-15 13:51:09,950 ----------------------------------------------------------------------------------------------------
2021-07-15 13:51:09,950 EPOCH 23 done: loss 0.1042 - lr 0.0000150
2021-07-15 13:51:11,933 DEV : loss 0.12702734768390656 - score 0.9617
2021-07-15 13:51:11,959 BAD EPOCHS (no improvement): 2
2021-07-15 13:51:11,959 ----------------------------------------------------------------------------------------------------
2021-07-15 13:51:13,977 epoch 24 - iter 4/46 - loss 0.10099473 - samples/sec: 63.43 - lr: 0.000015
2021-07-15 13:51:15,999 epoch 24 - iter 8/46 - loss 0.10175719 - samples/sec: 63.32 - lr: 0.000015
2021-07-15 13:51:18,004 epoch 24 - iter 12/46 - loss 0.08995549 - samples/sec: 63.88 - lr: 0.000015
2021-07-15 13:51:20,004 epoch 24 - iter 16/46 - loss 0.09390777 - samples/sec: 64.01 - lr: 0.000015
2021-07-15 13:51:21,993 epoch 24 - iter 20/46 - loss 0.09387824 - samples/sec: 64.37 - lr: 0.000015
2021-07-15 13:51:23,993 epoch 24 - iter 24/46 - loss 0.08961364 - samples/sec: 64.00 - lr: 0.000015
2021-07-15 13:51:26,012 epoch 24 - iter 28/46 - loss 0.08748580 - samples/sec: 63.42 - lr: 0.000015
2021-07-15 13:51:28,032 epoch 24 - iter 32/46 - loss 0.08414554 - samples/sec: 63.38 - lr: 0.000015
2021-07-15 13:51:30,070 epoch 24 - iter 36/46 - loss 0.08549129 - samples/sec: 62.84 - lr: 0.000015
2021-07-15 13:51:32,052 epoch 24 - iter 40/46 - loss 0.08399819 - samples/sec: 64.61 - lr: 0.000015
2021-07-15 13:51:34,086 epoch 24 - iter 44/46 - loss 0.08719818 - samples/sec: 62.95 - lr: 0.000015
2021-07-15 13:51:35,102 ----------------------------------------------------------------------------------------------------
2021-07-15 13:51:35,102 EPOCH 24 done: loss 0.0850 - lr 0.0000150
2021-07-15 13:51:37,089 DEV : loss 0.1330600082874298 - score 0.9617
2021-07-15 13:51:37,115 BAD EPOCHS (no improvement): 3
2021-07-15 13:51:37,115 ----------------------------------------------------------------------------------------------------
2021-07-15 13:51:39,112 epoch 25 - iter 4/46 - loss 0.11009473 - samples/sec: 64.11 - lr: 0.000015
2021-07-15 13:51:41,136 epoch 25 - iter 8/46 - loss 0.11041990 - samples/sec: 63.28 - lr: 0.000015
2021-07-15 13:51:43,159 epoch 25 - iter 12/46 - loss 0.10894060 - samples/sec: 63.27 - lr: 0.000015
2021-07-15 13:51:45,140 epoch 25 - iter 16/46 - loss 0.09938930 - samples/sec: 64.64 - lr: 0.000015
2021-07-15 13:51:47,135 epoch 25 - iter 20/46 - loss 0.09913478 - samples/sec: 64.17 - lr: 0.000015
2021-07-15 13:51:49,156 epoch 25 - iter 24/46 - loss 0.10370059 - samples/sec: 63.36 - lr: 0.000015
2021-07-15 13:51:51,176 epoch 25 - iter 28/46 - loss 0.09461201 - samples/sec: 63.39 - lr: 0.000015
2021-07-15 13:51:53,212 epoch 25 - iter 32/46 - loss 0.08908338 - samples/sec: 62.88 - lr: 0.000015
2021-07-15 13:51:55,265 epoch 25 - iter 36/46 - loss 0.09371022 - samples/sec: 62.36 - lr: 0.000015
2021-07-15 13:51:57,272 epoch 25 - iter 40/46 - loss 0.09193234 - samples/sec: 63.79 - lr: 0.000015
2021-07-15 13:51:59,320 epoch 25 - iter 44/46 - loss 0.09529246 - samples/sec: 62.52 - lr: 0.000015
2021-07-15 13:52:00,325 ----------------------------------------------------------------------------------------------------
2021-07-15 13:52:00,325 EPOCH 25 done: loss 0.0945 - lr 0.0000150
2021-07-15 13:52:02,314 DEV : loss 0.1368538737297058 - score 0.9598
Epoch    25: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 13:52:02,340 BAD EPOCHS (no improvement): 4
2021-07-15 13:52:02,340 ----------------------------------------------------------------------------------------------------
2021-07-15 13:52:04,496 epoch 26 - iter 4/46 - loss 0.10272077 - samples/sec: 59.39 - lr: 0.000008
2021-07-15 13:52:06,521 epoch 26 - iter 8/46 - loss 0.09644065 - samples/sec: 63.24 - lr: 0.000008
2021-07-15 13:52:08,529 epoch 26 - iter 12/46 - loss 0.09807654 - samples/sec: 63.77 - lr: 0.000008
2021-07-15 13:52:10,530 epoch 26 - iter 16/46 - loss 0.09267743 - samples/sec: 63.99 - lr: 0.000008
2021-07-15 13:52:12,560 epoch 26 - iter 20/46 - loss 0.09088820 - samples/sec: 63.05 - lr: 0.000008
2021-07-15 13:52:14,599 epoch 26 - iter 24/46 - loss 0.08788278 - samples/sec: 62.79 - lr: 0.000008
2021-07-15 13:52:16,628 epoch 26 - iter 28/46 - loss 0.08735820 - samples/sec: 63.13 - lr: 0.000008
2021-07-15 13:52:18,665 epoch 26 - iter 32/46 - loss 0.09161317 - samples/sec: 62.83 - lr: 0.000008
2021-07-15 13:52:20,677 epoch 26 - iter 36/46 - loss 0.09594886 - samples/sec: 63.63 - lr: 0.000008
2021-07-15 13:52:22,705 epoch 26 - iter 40/46 - loss 0.09428309 - samples/sec: 63.13 - lr: 0.000008
2021-07-15 13:52:24,696 epoch 26 - iter 44/46 - loss 0.09299676 - samples/sec: 64.31 - lr: 0.000008
2021-07-15 13:52:25,708 ----------------------------------------------------------------------------------------------------
2021-07-15 13:52:25,709 EPOCH 26 done: loss 0.0915 - lr 0.0000075
2021-07-15 13:52:27,691 DEV : loss 0.1262103170156479 - score 0.9577
2021-07-15 13:52:27,717 BAD EPOCHS (no improvement): 1
2021-07-15 13:52:27,717 ----------------------------------------------------------------------------------------------------
2021-07-15 13:52:29,752 epoch 27 - iter 4/46 - loss 0.13197677 - samples/sec: 62.93 - lr: 0.000008
2021-07-15 13:52:31,764 epoch 27 - iter 8/46 - loss 0.10501988 - samples/sec: 63.61 - lr: 0.000008
2021-07-15 13:52:33,790 epoch 27 - iter 12/46 - loss 0.10618655 - samples/sec: 63.21 - lr: 0.000008
2021-07-15 13:52:35,800 epoch 27 - iter 16/46 - loss 0.09868737 - samples/sec: 63.71 - lr: 0.000008
2021-07-15 13:52:37,761 epoch 27 - iter 20/46 - loss 0.09702339 - samples/sec: 65.29 - lr: 0.000008
2021-07-15 13:52:39,790 epoch 27 - iter 24/46 - loss 0.09606577 - samples/sec: 63.09 - lr: 0.000008
2021-07-15 13:52:41,831 epoch 27 - iter 28/46 - loss 0.10025915 - samples/sec: 62.73 - lr: 0.000008
2021-07-15 13:52:43,885 epoch 27 - iter 32/46 - loss 0.10011365 - samples/sec: 62.32 - lr: 0.000008
2021-07-15 13:52:45,896 epoch 27 - iter 36/46 - loss 0.09461373 - samples/sec: 63.67 - lr: 0.000008
2021-07-15 13:52:47,900 epoch 27 - iter 40/46 - loss 0.09240943 - samples/sec: 63.90 - lr: 0.000008
2021-07-15 13:52:49,904 epoch 27 - iter 44/46 - loss 0.09179631 - samples/sec: 63.89 - lr: 0.000008
2021-07-15 13:52:50,881 ----------------------------------------------------------------------------------------------------
2021-07-15 13:52:50,882 EPOCH 27 done: loss 0.0904 - lr 0.0000075
2021-07-15 13:52:52,869 DEV : loss 0.12864086031913757 - score 0.9597
2021-07-15 13:52:52,895 BAD EPOCHS (no improvement): 2
2021-07-15 13:52:52,895 ----------------------------------------------------------------------------------------------------
2021-07-15 13:52:54,933 epoch 28 - iter 4/46 - loss 0.08522768 - samples/sec: 62.83 - lr: 0.000008
2021-07-15 13:52:56,965 epoch 28 - iter 8/46 - loss 0.08460432 - samples/sec: 63.01 - lr: 0.000008
2021-07-15 13:52:59,009 epoch 28 - iter 12/46 - loss 0.08126633 - samples/sec: 62.66 - lr: 0.000008
2021-07-15 13:53:00,984 epoch 28 - iter 16/46 - loss 0.09155903 - samples/sec: 64.83 - lr: 0.000008
2021-07-15 13:53:03,028 epoch 28 - iter 20/46 - loss 0.10215711 - samples/sec: 62.62 - lr: 0.000008
2021-07-15 13:53:05,016 epoch 28 - iter 24/46 - loss 0.09789854 - samples/sec: 64.41 - lr: 0.000008
2021-07-15 13:53:07,010 epoch 28 - iter 28/46 - loss 0.09771187 - samples/sec: 64.22 - lr: 0.000008
2021-07-15 13:53:09,048 epoch 28 - iter 32/46 - loss 0.09732590 - samples/sec: 62.80 - lr: 0.000008
2021-07-15 13:53:11,039 epoch 28 - iter 36/46 - loss 0.09807282 - samples/sec: 64.31 - lr: 0.000008
2021-07-15 13:53:13,056 epoch 28 - iter 40/46 - loss 0.09747105 - samples/sec: 63.50 - lr: 0.000008
2021-07-15 13:53:15,101 epoch 28 - iter 44/46 - loss 0.10134702 - samples/sec: 62.60 - lr: 0.000008
2021-07-15 13:53:16,084 ----------------------------------------------------------------------------------------------------
2021-07-15 13:53:16,085 EPOCH 28 done: loss 0.0999 - lr 0.0000075
2021-07-15 13:53:18,068 DEV : loss 0.12910127639770508 - score 0.9597
2021-07-15 13:53:18,094 BAD EPOCHS (no improvement): 3
2021-07-15 13:53:18,094 ----------------------------------------------------------------------------------------------------
2021-07-15 13:53:20,056 epoch 29 - iter 4/46 - loss 0.09361365 - samples/sec: 65.27 - lr: 0.000008
2021-07-15 13:53:22,128 epoch 29 - iter 8/46 - loss 0.08408202 - samples/sec: 61.77 - lr: 0.000008
2021-07-15 13:53:24,145 epoch 29 - iter 12/46 - loss 0.08042242 - samples/sec: 63.50 - lr: 0.000008
2021-07-15 13:53:26,165 epoch 29 - iter 16/46 - loss 0.07974593 - samples/sec: 63.39 - lr: 0.000008
2021-07-15 13:53:28,169 epoch 29 - iter 20/46 - loss 0.08875015 - samples/sec: 63.86 - lr: 0.000008
2021-07-15 13:53:30,153 epoch 29 - iter 24/46 - loss 0.08963432 - samples/sec: 64.56 - lr: 0.000008
2021-07-15 13:53:32,185 epoch 29 - iter 28/46 - loss 0.09219960 - samples/sec: 62.98 - lr: 0.000008
2021-07-15 13:53:34,220 epoch 29 - iter 32/46 - loss 0.09768038 - samples/sec: 62.92 - lr: 0.000008
2021-07-15 13:53:36,229 epoch 29 - iter 36/46 - loss 0.10066459 - samples/sec: 63.76 - lr: 0.000008
2021-07-15 13:53:38,248 epoch 29 - iter 40/46 - loss 0.09609678 - samples/sec: 63.40 - lr: 0.000008
2021-07-15 13:53:40,260 epoch 29 - iter 44/46 - loss 0.09582912 - samples/sec: 63.66 - lr: 0.000008
2021-07-15 13:53:41,276 ----------------------------------------------------------------------------------------------------
2021-07-15 13:53:41,276 EPOCH 29 done: loss 0.0960 - lr 0.0000075
2021-07-15 13:53:43,437 DEV : loss 0.1296965330839157 - score 0.9634
Epoch    29: reducing learning rate of group 0 to 3.7500e-06.
2021-07-15 13:53:43,463 BAD EPOCHS (no improvement): 4
2021-07-15 13:53:43,463 ----------------------------------------------------------------------------------------------------
2021-07-15 13:53:45,469 epoch 30 - iter 4/46 - loss 0.06532220 - samples/sec: 63.84 - lr: 0.000004
2021-07-15 13:53:47,498 epoch 30 - iter 8/46 - loss 0.08293848 - samples/sec: 63.10 - lr: 0.000004
2021-07-15 13:53:49,473 epoch 30 - iter 12/46 - loss 0.09470827 - samples/sec: 64.81 - lr: 0.000004
2021-07-15 13:53:51,513 epoch 30 - iter 16/46 - loss 0.08321683 - samples/sec: 62.75 - lr: 0.000004
2021-07-15 13:53:53,533 epoch 30 - iter 20/46 - loss 0.08430912 - samples/sec: 63.38 - lr: 0.000004
2021-07-15 13:53:55,557 epoch 30 - iter 24/46 - loss 0.08545252 - samples/sec: 63.28 - lr: 0.000004
2021-07-15 13:53:57,525 epoch 30 - iter 28/46 - loss 0.09243129 - samples/sec: 65.06 - lr: 0.000004
2021-07-15 13:53:59,573 epoch 30 - iter 32/46 - loss 0.08931221 - samples/sec: 62.50 - lr: 0.000004
2021-07-15 13:54:01,582 epoch 30 - iter 36/46 - loss 0.08455069 - samples/sec: 63.73 - lr: 0.000004
2021-07-15 13:54:03,579 epoch 30 - iter 40/46 - loss 0.08691951 - samples/sec: 64.11 - lr: 0.000004
2021-07-15 13:54:05,620 epoch 30 - iter 44/46 - loss 0.09034651 - samples/sec: 62.75 - lr: 0.000004
2021-07-15 13:54:06,636 ----------------------------------------------------------------------------------------------------
2021-07-15 13:54:06,637 EPOCH 30 done: loss 0.0892 - lr 0.0000038
2021-07-15 13:54:08,623 DEV : loss 0.12791526317596436 - score 0.9653
2021-07-15 13:54:08,649 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:54:12,228 ----------------------------------------------------------------------------------------------------
2021-07-15 13:54:14,216 epoch 31 - iter 4/46 - loss 0.13977842 - samples/sec: 64.42 - lr: 0.000004
2021-07-15 13:54:16,248 epoch 31 - iter 8/46 - loss 0.11754665 - samples/sec: 63.01 - lr: 0.000004
2021-07-15 13:54:18,287 epoch 31 - iter 12/46 - loss 0.10706690 - samples/sec: 62.81 - lr: 0.000004
2021-07-15 13:54:20,312 epoch 31 - iter 16/46 - loss 0.10032755 - samples/sec: 63.23 - lr: 0.000004
2021-07-15 13:54:22,345 epoch 31 - iter 20/46 - loss 0.08848376 - samples/sec: 62.96 - lr: 0.000004
2021-07-15 13:54:24,349 epoch 31 - iter 24/46 - loss 0.09197988 - samples/sec: 63.91 - lr: 0.000004
2021-07-15 13:54:26,357 epoch 31 - iter 28/46 - loss 0.09106299 - samples/sec: 63.75 - lr: 0.000004
2021-07-15 13:54:28,370 epoch 31 - iter 32/46 - loss 0.08698112 - samples/sec: 63.61 - lr: 0.000004
2021-07-15 13:54:30,380 epoch 31 - iter 36/46 - loss 0.08516897 - samples/sec: 63.69 - lr: 0.000004
2021-07-15 13:54:32,396 epoch 31 - iter 40/46 - loss 0.08228774 - samples/sec: 63.52 - lr: 0.000004
2021-07-15 13:54:34,401 epoch 31 - iter 44/46 - loss 0.08418007 - samples/sec: 63.85 - lr: 0.000004
2021-07-15 13:54:35,413 ----------------------------------------------------------------------------------------------------
2021-07-15 13:54:35,414 EPOCH 31 done: loss 0.0852 - lr 0.0000038
2021-07-15 13:54:37,393 DEV : loss 0.12845635414123535 - score 0.9634
2021-07-15 13:54:37,419 BAD EPOCHS (no improvement): 1
2021-07-15 13:54:37,419 ----------------------------------------------------------------------------------------------------
2021-07-15 13:54:39,449 epoch 32 - iter 4/46 - loss 0.08943716 - samples/sec: 63.06 - lr: 0.000004
2021-07-15 13:54:41,474 epoch 32 - iter 8/46 - loss 0.10606653 - samples/sec: 63.26 - lr: 0.000004
2021-07-15 13:54:43,488 epoch 32 - iter 12/46 - loss 0.11590236 - samples/sec: 63.57 - lr: 0.000004
2021-07-15 13:54:45,516 epoch 32 - iter 16/46 - loss 0.10911723 - samples/sec: 63.12 - lr: 0.000004
2021-07-15 13:54:47,553 epoch 32 - iter 20/46 - loss 0.10459867 - samples/sec: 62.87 - lr: 0.000004
2021-07-15 13:54:49,567 epoch 32 - iter 24/46 - loss 0.09873249 - samples/sec: 63.57 - lr: 0.000004
2021-07-15 13:54:51,521 epoch 32 - iter 28/46 - loss 0.10498331 - samples/sec: 65.53 - lr: 0.000004
2021-07-15 13:54:53,530 epoch 32 - iter 32/46 - loss 0.10342766 - samples/sec: 63.72 - lr: 0.000004
2021-07-15 13:54:55,557 epoch 32 - iter 36/46 - loss 0.10288178 - samples/sec: 63.18 - lr: 0.000004
2021-07-15 13:54:57,585 epoch 32 - iter 40/46 - loss 0.09945399 - samples/sec: 63.13 - lr: 0.000004
2021-07-15 13:54:59,598 epoch 32 - iter 44/46 - loss 0.10083055 - samples/sec: 63.60 - lr: 0.000004
2021-07-15 13:55:00,592 ----------------------------------------------------------------------------------------------------
2021-07-15 13:55:00,592 EPOCH 32 done: loss 0.0990 - lr 0.0000038
2021-07-15 13:55:02,763 DEV : loss 0.12726223468780518 - score 0.9634
2021-07-15 13:55:02,789 BAD EPOCHS (no improvement): 2
2021-07-15 13:55:02,789 ----------------------------------------------------------------------------------------------------
2021-07-15 13:55:04,817 epoch 33 - iter 4/46 - loss 0.07421718 - samples/sec: 63.14 - lr: 0.000004
2021-07-15 13:55:06,801 epoch 33 - iter 8/46 - loss 0.08540215 - samples/sec: 64.55 - lr: 0.000004
2021-07-15 13:55:08,743 epoch 33 - iter 12/46 - loss 0.09128646 - samples/sec: 65.91 - lr: 0.000004
2021-07-15 13:55:10,765 epoch 33 - iter 16/46 - loss 0.09410063 - samples/sec: 63.32 - lr: 0.000004
2021-07-15 13:55:12,774 epoch 33 - iter 20/46 - loss 0.09119091 - samples/sec: 63.76 - lr: 0.000004
2021-07-15 13:55:14,771 epoch 33 - iter 24/46 - loss 0.08583244 - samples/sec: 64.09 - lr: 0.000004
2021-07-15 13:55:16,809 epoch 33 - iter 28/46 - loss 0.08533833 - samples/sec: 62.82 - lr: 0.000004
2021-07-15 13:55:18,864 epoch 33 - iter 32/46 - loss 0.08012944 - samples/sec: 62.32 - lr: 0.000004
2021-07-15 13:55:20,874 epoch 33 - iter 36/46 - loss 0.07911735 - samples/sec: 63.70 - lr: 0.000004
2021-07-15 13:55:22,905 epoch 33 - iter 40/46 - loss 0.08390324 - samples/sec: 63.03 - lr: 0.000004
2021-07-15 13:55:24,922 epoch 33 - iter 44/46 - loss 0.08236638 - samples/sec: 63.50 - lr: 0.000004
2021-07-15 13:55:25,953 ----------------------------------------------------------------------------------------------------
2021-07-15 13:55:25,953 EPOCH 33 done: loss 0.0847 - lr 0.0000038
2021-07-15 13:55:27,936 DEV : loss 0.1313629001379013 - score 0.9654
2021-07-15 13:55:27,962 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:55:31,664 ----------------------------------------------------------------------------------------------------
2021-07-15 13:55:33,716 epoch 34 - iter 4/46 - loss 0.08713691 - samples/sec: 62.42 - lr: 0.000004
2021-07-15 13:55:35,757 epoch 34 - iter 8/46 - loss 0.09959575 - samples/sec: 62.75 - lr: 0.000004
2021-07-15 13:55:37,805 epoch 34 - iter 12/46 - loss 0.08716769 - samples/sec: 62.51 - lr: 0.000004
2021-07-15 13:55:39,820 epoch 34 - iter 16/46 - loss 0.08927279 - samples/sec: 63.53 - lr: 0.000004
2021-07-15 13:55:41,782 epoch 34 - iter 20/46 - loss 0.08102838 - samples/sec: 65.26 - lr: 0.000004
2021-07-15 13:55:43,788 epoch 34 - iter 24/46 - loss 0.07896516 - samples/sec: 63.82 - lr: 0.000004
2021-07-15 13:55:45,785 epoch 34 - iter 28/46 - loss 0.08090803 - samples/sec: 64.13 - lr: 0.000004
2021-07-15 13:55:47,821 epoch 34 - iter 32/46 - loss 0.09506939 - samples/sec: 62.90 - lr: 0.000004
2021-07-15 13:55:49,845 epoch 34 - iter 36/46 - loss 0.09122779 - samples/sec: 63.25 - lr: 0.000004
2021-07-15 13:55:51,835 epoch 34 - iter 40/46 - loss 0.09122289 - samples/sec: 64.32 - lr: 0.000004
2021-07-15 13:55:53,808 epoch 34 - iter 44/46 - loss 0.09263722 - samples/sec: 64.90 - lr: 0.000004
2021-07-15 13:55:54,817 ----------------------------------------------------------------------------------------------------
2021-07-15 13:55:54,818 EPOCH 34 done: loss 0.0914 - lr 0.0000038
2021-07-15 13:55:56,799 DEV : loss 0.12895140051841736 - score 0.9672
2021-07-15 13:55:56,825 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:56:00,434 ----------------------------------------------------------------------------------------------------
2021-07-15 13:56:02,437 epoch 35 - iter 4/46 - loss 0.09129423 - samples/sec: 63.95 - lr: 0.000004
2021-07-15 13:56:04,433 epoch 35 - iter 8/46 - loss 0.09101177 - samples/sec: 64.14 - lr: 0.000004
2021-07-15 13:56:06,396 epoch 35 - iter 12/46 - loss 0.09151589 - samples/sec: 65.23 - lr: 0.000004
2021-07-15 13:56:08,393 epoch 35 - iter 16/46 - loss 0.09322417 - samples/sec: 64.14 - lr: 0.000004
2021-07-15 13:56:10,368 epoch 35 - iter 20/46 - loss 0.09526997 - samples/sec: 64.81 - lr: 0.000004
2021-07-15 13:56:12,313 epoch 35 - iter 24/46 - loss 0.09819588 - samples/sec: 65.82 - lr: 0.000004
2021-07-15 13:56:14,259 epoch 35 - iter 28/46 - loss 0.09835190 - samples/sec: 65.82 - lr: 0.000004
2021-07-15 13:56:16,291 epoch 35 - iter 32/46 - loss 0.09654376 - samples/sec: 63.02 - lr: 0.000004
2021-07-15 13:56:18,315 epoch 35 - iter 36/46 - loss 0.09177626 - samples/sec: 63.26 - lr: 0.000004
2021-07-15 13:56:20,313 epoch 35 - iter 40/46 - loss 0.09235435 - samples/sec: 64.08 - lr: 0.000004
2021-07-15 13:56:22,326 epoch 35 - iter 44/46 - loss 0.09189747 - samples/sec: 63.60 - lr: 0.000004
2021-07-15 13:56:23,326 ----------------------------------------------------------------------------------------------------
2021-07-15 13:56:23,327 EPOCH 35 done: loss 0.0909 - lr 0.0000038
2021-07-15 13:56:25,310 DEV : loss 0.12619392573833466 - score 0.9672
2021-07-15 13:56:25,336 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:56:29,275 ----------------------------------------------------------------------------------------------------
2021-07-15 13:56:31,265 epoch 36 - iter 4/46 - loss 0.05986965 - samples/sec: 64.38 - lr: 0.000004
2021-07-15 13:56:33,270 epoch 36 - iter 8/46 - loss 0.06802266 - samples/sec: 63.85 - lr: 0.000004
2021-07-15 13:56:35,230 epoch 36 - iter 12/46 - loss 0.06985366 - samples/sec: 65.33 - lr: 0.000004
2021-07-15 13:56:37,186 epoch 36 - iter 16/46 - loss 0.06568200 - samples/sec: 65.44 - lr: 0.000004
2021-07-15 13:56:39,171 epoch 36 - iter 20/46 - loss 0.07329939 - samples/sec: 64.50 - lr: 0.000004
2021-07-15 13:56:41,158 epoch 36 - iter 24/46 - loss 0.07296517 - samples/sec: 64.44 - lr: 0.000004
2021-07-15 13:56:43,150 epoch 36 - iter 28/46 - loss 0.07455467 - samples/sec: 64.26 - lr: 0.000004
2021-07-15 13:56:45,139 epoch 36 - iter 32/46 - loss 0.07834798 - samples/sec: 64.39 - lr: 0.000004
2021-07-15 13:56:47,127 epoch 36 - iter 36/46 - loss 0.08124991 - samples/sec: 64.39 - lr: 0.000004
2021-07-15 13:56:49,115 epoch 36 - iter 40/46 - loss 0.08020051 - samples/sec: 64.41 - lr: 0.000004
2021-07-15 13:56:51,108 epoch 36 - iter 44/46 - loss 0.08168396 - samples/sec: 64.23 - lr: 0.000004
2021-07-15 13:56:52,126 ----------------------------------------------------------------------------------------------------
2021-07-15 13:56:52,127 EPOCH 36 done: loss 0.0814 - lr 0.0000038
2021-07-15 13:56:54,288 DEV : loss 0.12262087315320969 - score 0.9653
2021-07-15 13:56:54,314 BAD EPOCHS (no improvement): 1
2021-07-15 13:56:54,314 ----------------------------------------------------------------------------------------------------
2021-07-15 13:56:56,313 epoch 37 - iter 4/46 - loss 0.08739477 - samples/sec: 64.06 - lr: 0.000004
2021-07-15 13:56:58,333 epoch 37 - iter 8/46 - loss 0.07988723 - samples/sec: 63.37 - lr: 0.000004
2021-07-15 13:57:00,362 epoch 37 - iter 12/46 - loss 0.07829271 - samples/sec: 63.10 - lr: 0.000004
2021-07-15 13:57:02,358 epoch 37 - iter 16/46 - loss 0.08761320 - samples/sec: 64.15 - lr: 0.000004
2021-07-15 13:57:04,383 epoch 37 - iter 20/46 - loss 0.09241043 - samples/sec: 63.25 - lr: 0.000004
2021-07-15 13:57:06,350 epoch 37 - iter 24/46 - loss 0.08811386 - samples/sec: 65.07 - lr: 0.000004
2021-07-15 13:57:08,323 epoch 37 - iter 28/46 - loss 0.08544600 - samples/sec: 64.92 - lr: 0.000004
2021-07-15 13:57:10,292 epoch 37 - iter 32/46 - loss 0.08653265 - samples/sec: 65.02 - lr: 0.000004
2021-07-15 13:57:12,310 epoch 37 - iter 36/46 - loss 0.08570395 - samples/sec: 63.43 - lr: 0.000004
2021-07-15 13:57:14,295 epoch 37 - iter 40/46 - loss 0.08334552 - samples/sec: 64.53 - lr: 0.000004
2021-07-15 13:57:16,269 epoch 37 - iter 44/46 - loss 0.08065499 - samples/sec: 64.86 - lr: 0.000004
2021-07-15 13:57:17,228 ----------------------------------------------------------------------------------------------------
2021-07-15 13:57:17,228 EPOCH 37 done: loss 0.0789 - lr 0.0000038
2021-07-15 13:57:19,208 DEV : loss 0.12245653569698334 - score 0.9632
2021-07-15 13:57:19,234 BAD EPOCHS (no improvement): 2
2021-07-15 13:57:19,234 ----------------------------------------------------------------------------------------------------
2021-07-15 13:57:21,197 epoch 38 - iter 4/46 - loss 0.12905643 - samples/sec: 65.23 - lr: 0.000004
2021-07-15 13:57:23,188 epoch 38 - iter 8/46 - loss 0.12713955 - samples/sec: 64.29 - lr: 0.000004
2021-07-15 13:57:25,182 epoch 38 - iter 12/46 - loss 0.11165581 - samples/sec: 64.21 - lr: 0.000004
2021-07-15 13:57:27,161 epoch 38 - iter 16/46 - loss 0.10410007 - samples/sec: 64.70 - lr: 0.000004
2021-07-15 13:57:29,160 epoch 38 - iter 20/46 - loss 0.09952603 - samples/sec: 64.06 - lr: 0.000004
2021-07-15 13:57:31,150 epoch 38 - iter 24/46 - loss 0.09853182 - samples/sec: 64.33 - lr: 0.000004
2021-07-15 13:57:33,136 epoch 38 - iter 28/46 - loss 0.09389822 - samples/sec: 64.48 - lr: 0.000004
2021-07-15 13:57:35,128 epoch 38 - iter 32/46 - loss 0.09054145 - samples/sec: 64.28 - lr: 0.000004
2021-07-15 13:57:37,071 epoch 38 - iter 36/46 - loss 0.08472298 - samples/sec: 65.88 - lr: 0.000004
2021-07-15 13:57:39,075 epoch 38 - iter 40/46 - loss 0.08687023 - samples/sec: 63.91 - lr: 0.000004
2021-07-15 13:57:41,070 epoch 38 - iter 44/46 - loss 0.08330384 - samples/sec: 64.17 - lr: 0.000004
2021-07-15 13:57:42,081 ----------------------------------------------------------------------------------------------------
2021-07-15 13:57:42,081 EPOCH 38 done: loss 0.0850 - lr 0.0000038
2021-07-15 13:57:44,059 DEV : loss 0.12182879447937012 - score 0.9653
2021-07-15 13:57:44,085 BAD EPOCHS (no improvement): 3
2021-07-15 13:57:44,086 ----------------------------------------------------------------------------------------------------
2021-07-15 13:57:46,052 epoch 39 - iter 4/46 - loss 0.08382132 - samples/sec: 65.13 - lr: 0.000004
2021-07-15 13:57:48,026 epoch 39 - iter 8/46 - loss 0.06537082 - samples/sec: 64.84 - lr: 0.000004
2021-07-15 13:57:50,042 epoch 39 - iter 12/46 - loss 0.06140514 - samples/sec: 63.52 - lr: 0.000004
2021-07-15 13:57:52,045 epoch 39 - iter 16/46 - loss 0.06623684 - samples/sec: 63.93 - lr: 0.000004
2021-07-15 13:57:54,051 epoch 39 - iter 20/46 - loss 0.07589883 - samples/sec: 63.80 - lr: 0.000004
2021-07-15 13:57:56,020 epoch 39 - iter 24/46 - loss 0.07777696 - samples/sec: 65.03 - lr: 0.000004
2021-07-15 13:57:58,023 epoch 39 - iter 28/46 - loss 0.07777297 - samples/sec: 63.94 - lr: 0.000004
2021-07-15 13:57:59,990 epoch 39 - iter 32/46 - loss 0.07738910 - samples/sec: 65.07 - lr: 0.000004
2021-07-15 13:58:01,948 epoch 39 - iter 36/46 - loss 0.08219861 - samples/sec: 65.39 - lr: 0.000004
2021-07-15 13:58:03,984 epoch 39 - iter 40/46 - loss 0.08190512 - samples/sec: 62.89 - lr: 0.000004
2021-07-15 13:58:05,927 epoch 39 - iter 44/46 - loss 0.07912597 - samples/sec: 65.88 - lr: 0.000004
2021-07-15 13:58:06,942 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:06,942 EPOCH 39 done: loss 0.0785 - lr 0.0000038
2021-07-15 13:58:08,925 DEV : loss 0.12036575376987457 - score 0.9651
Epoch    39: reducing learning rate of group 0 to 1.8750e-06.
2021-07-15 13:58:08,951 BAD EPOCHS (no improvement): 4
2021-07-15 13:58:08,951 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:08,951 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:08,951 learning rate too small - quitting training!
2021-07-15 13:58:08,951 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:09,645 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:09,645 Testing using best model ...
2021-07-15 13:58:09,645 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.rststb/best-model.pt
2021-07-15 13:58:26,668 0.8603	0.9149	0.8867
2021-07-15 13:58:26,668 
Results:
- F1-score (micro) 0.8867
- F1-score (macro) 0.8867

By class:
SENT       tp: 505 - fp: 82 - fn: 47 - precision: 0.8603 - recall: 0.9149 - f1-score: 0.8867
2021-07-15 13:58:26,668 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.rst.sctb/
2021-07-15 13:58:26,681 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.rst.sctb
2021-07-15 13:58:26,681 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.rst.sctb/sent_train.txt
2021-07-15 13:58:26,683 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.rst.sctb/sent_dev.txt
2021-07-15 13:58:26,684 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.rst.sctb/sent_test.txt
Corpus: 390 train + 111 dev + 84 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 13:58:28,800 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:28,802 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(21128, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 13:58:28,802 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:28,802 Corpus: "Corpus: 390 train + 111 dev + 84 test sentences"
2021-07-15 13:58:28,802 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:28,802 Parameters:
2021-07-15 13:58:28,802  - learning_rate: "3e-05"
2021-07-15 13:58:28,802  - mini_batch_size: "32"
2021-07-15 13:58:28,802  - patience: "3"
2021-07-15 13:58:28,802  - anneal_factor: "0.5"
2021-07-15 13:58:28,803  - max_epochs: "40"
2021-07-15 13:58:28,803  - shuffle: "True"
2021-07-15 13:58:28,803  - train_with_dev: "False"
2021-07-15 13:58:28,803  - batch_growth_annealing: "False"
2021-07-15 13:58:28,803 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:28,803 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.rst.sctb"
2021-07-15 13:58:28,803 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:28,803 Device: cuda:0
2021-07-15 13:58:28,803 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:28,803 Embeddings storage mode: cpu
2021-07-15 13:58:28,805 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:29,722 epoch 1 - iter 1/13 - loss 30.32270432 - samples/sec: 34.94 - lr: 0.000030
2021-07-15 13:58:30,629 epoch 1 - iter 2/13 - loss 26.54756165 - samples/sec: 35.28 - lr: 0.000030
2021-07-15 13:58:31,544 epoch 1 - iter 3/13 - loss 23.33330854 - samples/sec: 34.99 - lr: 0.000030
2021-07-15 13:58:32,461 epoch 1 - iter 4/13 - loss 20.91354728 - samples/sec: 34.92 - lr: 0.000030
2021-07-15 13:58:33,378 epoch 1 - iter 5/13 - loss 18.85404320 - samples/sec: 34.87 - lr: 0.000030
2021-07-15 13:58:34,290 epoch 1 - iter 6/13 - loss 17.11377494 - samples/sec: 35.13 - lr: 0.000030
2021-07-15 13:58:35,208 epoch 1 - iter 7/13 - loss 15.66405896 - samples/sec: 34.84 - lr: 0.000030
2021-07-15 13:58:36,130 epoch 1 - iter 8/13 - loss 14.56985033 - samples/sec: 34.74 - lr: 0.000030
2021-07-15 13:58:37,046 epoch 1 - iter 9/13 - loss 13.60770883 - samples/sec: 34.93 - lr: 0.000030
2021-07-15 13:58:37,960 epoch 1 - iter 10/13 - loss 12.77118158 - samples/sec: 35.03 - lr: 0.000030
2021-07-15 13:58:38,878 epoch 1 - iter 11/13 - loss 12.05661860 - samples/sec: 34.87 - lr: 0.000030
2021-07-15 13:58:39,793 epoch 1 - iter 12/13 - loss 11.42771741 - samples/sec: 34.96 - lr: 0.000030
2021-07-15 13:58:40,013 epoch 1 - iter 13/13 - loss 10.80927521 - samples/sec: 146.11 - lr: 0.000030
2021-07-15 13:58:40,013 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:40,013 EPOCH 1 done: loss 10.8093 - lr 0.0000300
2021-07-15 13:58:42,413 DEV : loss 3.3669188022613525 - score 0.0
2021-07-15 13:58:42,421 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:58:43,060 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:43,505 epoch 2 - iter 1/13 - loss 3.93963742 - samples/sec: 71.97 - lr: 0.000030
2021-07-15 13:58:43,969 epoch 2 - iter 2/13 - loss 3.73136806 - samples/sec: 69.05 - lr: 0.000030
2021-07-15 13:58:44,428 epoch 2 - iter 3/13 - loss 3.79429690 - samples/sec: 69.77 - lr: 0.000030
2021-07-15 13:58:44,873 epoch 2 - iter 4/13 - loss 3.86353111 - samples/sec: 71.98 - lr: 0.000030
2021-07-15 13:58:45,324 epoch 2 - iter 5/13 - loss 3.70992432 - samples/sec: 70.98 - lr: 0.000030
2021-07-15 13:58:45,776 epoch 2 - iter 6/13 - loss 3.72740682 - samples/sec: 70.96 - lr: 0.000030
2021-07-15 13:58:46,226 epoch 2 - iter 7/13 - loss 3.81163434 - samples/sec: 71.16 - lr: 0.000030
2021-07-15 13:58:46,680 epoch 2 - iter 8/13 - loss 3.70157540 - samples/sec: 70.48 - lr: 0.000030
2021-07-15 13:58:47,141 epoch 2 - iter 9/13 - loss 3.71977610 - samples/sec: 69.54 - lr: 0.000030
2021-07-15 13:58:47,604 epoch 2 - iter 10/13 - loss 3.68566942 - samples/sec: 69.19 - lr: 0.000030
2021-07-15 13:58:48,055 epoch 2 - iter 11/13 - loss 3.65401134 - samples/sec: 70.98 - lr: 0.000030
2021-07-15 13:58:48,510 epoch 2 - iter 12/13 - loss 3.58268984 - samples/sec: 70.49 - lr: 0.000030
2021-07-15 13:58:48,643 epoch 2 - iter 13/13 - loss 3.59277865 - samples/sec: 240.95 - lr: 0.000030
2021-07-15 13:58:48,643 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:48,643 EPOCH 2 done: loss 3.5928 - lr 0.0000300
2021-07-15 13:58:49,191 DEV : loss 3.1715757846832275 - score 0.0
2021-07-15 13:58:49,199 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:58:53,892 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:54,338 epoch 3 - iter 1/13 - loss 3.21495700 - samples/sec: 71.96 - lr: 0.000030
2021-07-15 13:58:54,787 epoch 3 - iter 2/13 - loss 3.65441453 - samples/sec: 71.24 - lr: 0.000030
2021-07-15 13:58:55,249 epoch 3 - iter 3/13 - loss 3.39695175 - samples/sec: 69.37 - lr: 0.000030
2021-07-15 13:58:55,706 epoch 3 - iter 4/13 - loss 3.32243091 - samples/sec: 70.06 - lr: 0.000030
2021-07-15 13:58:56,160 epoch 3 - iter 5/13 - loss 3.31465750 - samples/sec: 70.49 - lr: 0.000030
2021-07-15 13:58:56,631 epoch 3 - iter 6/13 - loss 3.30744604 - samples/sec: 68.06 - lr: 0.000030
2021-07-15 13:58:57,080 epoch 3 - iter 7/13 - loss 3.23981578 - samples/sec: 71.26 - lr: 0.000030
2021-07-15 13:58:57,544 epoch 3 - iter 8/13 - loss 3.18138146 - samples/sec: 69.04 - lr: 0.000030
2021-07-15 13:58:58,004 epoch 3 - iter 9/13 - loss 3.15830321 - samples/sec: 69.65 - lr: 0.000030
2021-07-15 13:58:58,469 epoch 3 - iter 10/13 - loss 3.19452803 - samples/sec: 68.87 - lr: 0.000030
2021-07-15 13:58:58,930 epoch 3 - iter 11/13 - loss 3.17245590 - samples/sec: 69.50 - lr: 0.000030
2021-07-15 13:58:59,397 epoch 3 - iter 12/13 - loss 3.10662822 - samples/sec: 68.54 - lr: 0.000030
2021-07-15 13:58:59,525 epoch 3 - iter 13/13 - loss 3.00910942 - samples/sec: 252.11 - lr: 0.000030
2021-07-15 13:58:59,525 ----------------------------------------------------------------------------------------------------
2021-07-15 13:58:59,525 EPOCH 3 done: loss 3.0091 - lr 0.0000300
2021-07-15 13:59:00,068 DEV : loss 2.5018129348754883 - score 0.0449
2021-07-15 13:59:00,076 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:59:03,433 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:03,890 epoch 4 - iter 1/13 - loss 2.86654139 - samples/sec: 70.10 - lr: 0.000030
2021-07-15 13:59:04,336 epoch 4 - iter 2/13 - loss 2.91594791 - samples/sec: 71.79 - lr: 0.000030
2021-07-15 13:59:04,789 epoch 4 - iter 3/13 - loss 2.86440937 - samples/sec: 70.69 - lr: 0.000030
2021-07-15 13:59:05,252 epoch 4 - iter 4/13 - loss 2.84260827 - samples/sec: 69.15 - lr: 0.000030
2021-07-15 13:59:05,697 epoch 4 - iter 5/13 - loss 2.88247223 - samples/sec: 72.06 - lr: 0.000030
2021-07-15 13:59:06,148 epoch 4 - iter 6/13 - loss 2.92721387 - samples/sec: 70.99 - lr: 0.000030
2021-07-15 13:59:06,608 epoch 4 - iter 7/13 - loss 2.85285378 - samples/sec: 69.56 - lr: 0.000030
2021-07-15 13:59:07,069 epoch 4 - iter 8/13 - loss 2.79060081 - samples/sec: 69.51 - lr: 0.000030
2021-07-15 13:59:07,529 epoch 4 - iter 9/13 - loss 2.75786959 - samples/sec: 69.73 - lr: 0.000030
2021-07-15 13:59:07,981 epoch 4 - iter 10/13 - loss 2.66605960 - samples/sec: 70.84 - lr: 0.000030
2021-07-15 13:59:08,444 epoch 4 - iter 11/13 - loss 2.61153742 - samples/sec: 69.06 - lr: 0.000030
2021-07-15 13:59:08,913 epoch 4 - iter 12/13 - loss 2.59811263 - samples/sec: 68.33 - lr: 0.000030
2021-07-15 13:59:09,048 epoch 4 - iter 13/13 - loss 2.61568129 - samples/sec: 237.39 - lr: 0.000030
2021-07-15 13:59:09,049 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:09,049 EPOCH 4 done: loss 2.6157 - lr 0.0000300
2021-07-15 13:59:09,591 DEV : loss 2.1398534774780273 - score 0.0659
2021-07-15 13:59:09,599 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:59:12,943 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:13,389 epoch 5 - iter 1/13 - loss 1.96345150 - samples/sec: 71.88 - lr: 0.000030
2021-07-15 13:59:13,849 epoch 5 - iter 2/13 - loss 2.16189295 - samples/sec: 69.72 - lr: 0.000030
2021-07-15 13:59:14,312 epoch 5 - iter 3/13 - loss 2.31955596 - samples/sec: 69.06 - lr: 0.000030
2021-07-15 13:59:14,772 epoch 5 - iter 4/13 - loss 2.24138954 - samples/sec: 69.61 - lr: 0.000030
2021-07-15 13:59:15,228 epoch 5 - iter 5/13 - loss 2.24803488 - samples/sec: 70.25 - lr: 0.000030
2021-07-15 13:59:15,693 epoch 5 - iter 6/13 - loss 2.33069887 - samples/sec: 68.99 - lr: 0.000030
2021-07-15 13:59:16,160 epoch 5 - iter 7/13 - loss 2.30640587 - samples/sec: 68.57 - lr: 0.000030
2021-07-15 13:59:16,604 epoch 5 - iter 8/13 - loss 2.25722563 - samples/sec: 72.11 - lr: 0.000030
2021-07-15 13:59:17,061 epoch 5 - iter 9/13 - loss 2.21121919 - samples/sec: 70.11 - lr: 0.000030
2021-07-15 13:59:17,520 epoch 5 - iter 10/13 - loss 2.24254974 - samples/sec: 69.67 - lr: 0.000030
2021-07-15 13:59:17,973 epoch 5 - iter 11/13 - loss 2.25303701 - samples/sec: 70.76 - lr: 0.000030
2021-07-15 13:59:18,437 epoch 5 - iter 12/13 - loss 2.22023667 - samples/sec: 68.98 - lr: 0.000030
2021-07-15 13:59:18,573 epoch 5 - iter 13/13 - loss 2.18615312 - samples/sec: 237.25 - lr: 0.000030
2021-07-15 13:59:18,573 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:18,573 EPOCH 5 done: loss 2.1862 - lr 0.0000300
2021-07-15 13:59:19,115 DEV : loss 1.8135621547698975 - score 0.375
2021-07-15 13:59:19,122 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:59:22,676 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:23,132 epoch 6 - iter 1/13 - loss 2.24475288 - samples/sec: 70.29 - lr: 0.000030
2021-07-15 13:59:23,665 epoch 6 - iter 2/13 - loss 2.35567403 - samples/sec: 60.04 - lr: 0.000030
2021-07-15 13:59:24,125 epoch 6 - iter 3/13 - loss 2.11129514 - samples/sec: 69.63 - lr: 0.000030
2021-07-15 13:59:24,592 epoch 6 - iter 4/13 - loss 2.16643488 - samples/sec: 68.61 - lr: 0.000030
2021-07-15 13:59:25,033 epoch 6 - iter 5/13 - loss 2.16651840 - samples/sec: 72.63 - lr: 0.000030
2021-07-15 13:59:25,471 epoch 6 - iter 6/13 - loss 2.07049628 - samples/sec: 73.16 - lr: 0.000030
2021-07-15 13:59:25,933 epoch 6 - iter 7/13 - loss 1.98501158 - samples/sec: 69.32 - lr: 0.000030
2021-07-15 13:59:26,395 epoch 6 - iter 8/13 - loss 2.01625124 - samples/sec: 69.38 - lr: 0.000030
2021-07-15 13:59:26,844 epoch 6 - iter 9/13 - loss 2.01958643 - samples/sec: 71.25 - lr: 0.000030
2021-07-15 13:59:27,299 epoch 6 - iter 10/13 - loss 2.01585077 - samples/sec: 70.50 - lr: 0.000030
2021-07-15 13:59:27,746 epoch 6 - iter 11/13 - loss 2.02456168 - samples/sec: 71.56 - lr: 0.000030
2021-07-15 13:59:28,194 epoch 6 - iter 12/13 - loss 1.98501206 - samples/sec: 71.55 - lr: 0.000030
2021-07-15 13:59:28,332 epoch 6 - iter 13/13 - loss 1.91357414 - samples/sec: 232.14 - lr: 0.000030
2021-07-15 13:59:28,332 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:28,332 EPOCH 6 done: loss 1.9136 - lr 0.0000300
2021-07-15 13:59:28,875 DEV : loss 1.588538646697998 - score 0.496
2021-07-15 13:59:28,883 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:59:32,360 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:32,815 epoch 7 - iter 1/13 - loss 2.03887558 - samples/sec: 70.43 - lr: 0.000030
2021-07-15 13:59:33,257 epoch 7 - iter 2/13 - loss 1.80534184 - samples/sec: 72.46 - lr: 0.000030
2021-07-15 13:59:33,710 epoch 7 - iter 3/13 - loss 1.82960979 - samples/sec: 70.70 - lr: 0.000030
2021-07-15 13:59:34,151 epoch 7 - iter 4/13 - loss 1.76885694 - samples/sec: 72.60 - lr: 0.000030
2021-07-15 13:59:34,606 epoch 7 - iter 5/13 - loss 1.91341758 - samples/sec: 70.40 - lr: 0.000030
2021-07-15 13:59:35,054 epoch 7 - iter 6/13 - loss 1.81370598 - samples/sec: 71.45 - lr: 0.000030
2021-07-15 13:59:35,502 epoch 7 - iter 7/13 - loss 1.73143572 - samples/sec: 71.51 - lr: 0.000030
2021-07-15 13:59:35,946 epoch 7 - iter 8/13 - loss 1.75208563 - samples/sec: 72.13 - lr: 0.000030
2021-07-15 13:59:36,393 epoch 7 - iter 9/13 - loss 1.71969957 - samples/sec: 71.66 - lr: 0.000030
2021-07-15 13:59:36,844 epoch 7 - iter 10/13 - loss 1.73983189 - samples/sec: 71.00 - lr: 0.000030
2021-07-15 13:59:37,300 epoch 7 - iter 11/13 - loss 1.71809297 - samples/sec: 70.28 - lr: 0.000030
2021-07-15 13:59:37,755 epoch 7 - iter 12/13 - loss 1.72208845 - samples/sec: 70.43 - lr: 0.000030
2021-07-15 13:59:37,889 epoch 7 - iter 13/13 - loss 1.64028779 - samples/sec: 238.80 - lr: 0.000030
2021-07-15 13:59:37,889 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:37,890 EPOCH 7 done: loss 1.6403 - lr 0.0000300
2021-07-15 13:59:38,432 DEV : loss 1.3850985765457153 - score 0.5649
2021-07-15 13:59:38,440 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:59:41,882 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:42,321 epoch 8 - iter 1/13 - loss 1.18999982 - samples/sec: 73.15 - lr: 0.000030
2021-07-15 13:59:42,773 epoch 8 - iter 2/13 - loss 1.49691749 - samples/sec: 70.78 - lr: 0.000030
2021-07-15 13:59:43,224 epoch 8 - iter 3/13 - loss 1.39016994 - samples/sec: 71.01 - lr: 0.000030
2021-07-15 13:59:43,658 epoch 8 - iter 4/13 - loss 1.33563614 - samples/sec: 73.82 - lr: 0.000030
2021-07-15 13:59:44,119 epoch 8 - iter 5/13 - loss 1.41616783 - samples/sec: 69.49 - lr: 0.000030
2021-07-15 13:59:44,562 epoch 8 - iter 6/13 - loss 1.41620195 - samples/sec: 72.20 - lr: 0.000030
2021-07-15 13:59:45,010 epoch 8 - iter 7/13 - loss 1.40819866 - samples/sec: 71.63 - lr: 0.000030
2021-07-15 13:59:45,468 epoch 8 - iter 8/13 - loss 1.44700319 - samples/sec: 69.95 - lr: 0.000030
2021-07-15 13:59:45,920 epoch 8 - iter 9/13 - loss 1.42060943 - samples/sec: 70.75 - lr: 0.000030
2021-07-15 13:59:46,381 epoch 8 - iter 10/13 - loss 1.43502795 - samples/sec: 69.45 - lr: 0.000030
2021-07-15 13:59:46,840 epoch 8 - iter 11/13 - loss 1.46088476 - samples/sec: 69.83 - lr: 0.000030
2021-07-15 13:59:47,294 epoch 8 - iter 12/13 - loss 1.46226385 - samples/sec: 70.57 - lr: 0.000030
2021-07-15 13:59:47,426 epoch 8 - iter 13/13 - loss 1.53219127 - samples/sec: 242.42 - lr: 0.000030
2021-07-15 13:59:47,427 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:47,427 EPOCH 8 done: loss 1.5322 - lr 0.0000300
2021-07-15 13:59:47,969 DEV : loss 1.2280176877975464 - score 0.6479
2021-07-15 13:59:47,977 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 13:59:51,448 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:51,901 epoch 9 - iter 1/13 - loss 1.55949676 - samples/sec: 70.76 - lr: 0.000030
2021-07-15 13:59:52,349 epoch 9 - iter 2/13 - loss 1.29127967 - samples/sec: 71.42 - lr: 0.000030
2021-07-15 13:59:52,806 epoch 9 - iter 3/13 - loss 1.40281709 - samples/sec: 70.14 - lr: 0.000030
2021-07-15 13:59:53,253 epoch 9 - iter 4/13 - loss 1.41474807 - samples/sec: 71.71 - lr: 0.000030
2021-07-15 13:59:53,688 epoch 9 - iter 5/13 - loss 1.47108181 - samples/sec: 73.56 - lr: 0.000030
2021-07-15 13:59:54,140 epoch 9 - iter 6/13 - loss 1.47064428 - samples/sec: 70.87 - lr: 0.000030
2021-07-15 13:59:54,587 epoch 9 - iter 7/13 - loss 1.43079502 - samples/sec: 71.66 - lr: 0.000030
2021-07-15 13:59:55,043 epoch 9 - iter 8/13 - loss 1.42291579 - samples/sec: 70.31 - lr: 0.000030
2021-07-15 13:59:55,486 epoch 9 - iter 9/13 - loss 1.40591155 - samples/sec: 72.24 - lr: 0.000030
2021-07-15 13:59:55,942 epoch 9 - iter 10/13 - loss 1.37048843 - samples/sec: 70.17 - lr: 0.000030
2021-07-15 13:59:56,394 epoch 9 - iter 11/13 - loss 1.34528805 - samples/sec: 70.95 - lr: 0.000030
2021-07-15 13:59:56,855 epoch 9 - iter 12/13 - loss 1.36329134 - samples/sec: 69.48 - lr: 0.000030
2021-07-15 13:59:56,988 epoch 9 - iter 13/13 - loss 1.36932855 - samples/sec: 240.49 - lr: 0.000030
2021-07-15 13:59:56,989 ----------------------------------------------------------------------------------------------------
2021-07-15 13:59:56,989 EPOCH 9 done: loss 1.3693 - lr 0.0000300
2021-07-15 13:59:57,530 DEV : loss 1.1052649021148682 - score 0.7
2021-07-15 13:59:57,538 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:00:00,885 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:01,347 epoch 10 - iter 1/13 - loss 0.91219437 - samples/sec: 69.50 - lr: 0.000030
2021-07-15 14:00:01,800 epoch 10 - iter 2/13 - loss 1.01616400 - samples/sec: 70.63 - lr: 0.000030
2021-07-15 14:00:02,241 epoch 10 - iter 3/13 - loss 0.96073870 - samples/sec: 72.61 - lr: 0.000030
2021-07-15 14:00:02,692 epoch 10 - iter 4/13 - loss 0.98771033 - samples/sec: 71.04 - lr: 0.000030
2021-07-15 14:00:03,147 epoch 10 - iter 5/13 - loss 1.03699539 - samples/sec: 70.44 - lr: 0.000030
2021-07-15 14:00:03,602 epoch 10 - iter 6/13 - loss 1.04041276 - samples/sec: 70.32 - lr: 0.000030
2021-07-15 14:00:04,061 epoch 10 - iter 7/13 - loss 1.10323472 - samples/sec: 69.85 - lr: 0.000030
2021-07-15 14:00:04,514 epoch 10 - iter 8/13 - loss 1.18033229 - samples/sec: 70.73 - lr: 0.000030
2021-07-15 14:00:04,969 epoch 10 - iter 9/13 - loss 1.15801889 - samples/sec: 70.40 - lr: 0.000030
2021-07-15 14:00:05,418 epoch 10 - iter 10/13 - loss 1.19540756 - samples/sec: 71.21 - lr: 0.000030
2021-07-15 14:00:05,857 epoch 10 - iter 11/13 - loss 1.19944751 - samples/sec: 73.09 - lr: 0.000030
2021-07-15 14:00:06,291 epoch 10 - iter 12/13 - loss 1.18065536 - samples/sec: 73.76 - lr: 0.000030
2021-07-15 14:00:06,429 epoch 10 - iter 13/13 - loss 1.31662231 - samples/sec: 232.68 - lr: 0.000030
2021-07-15 14:00:06,429 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:06,429 EPOCH 10 done: loss 1.3166 - lr 0.0000300
2021-07-15 14:00:06,971 DEV : loss 0.9943574070930481 - score 0.732
2021-07-15 14:00:06,979 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:00:10,664 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:11,127 epoch 11 - iter 1/13 - loss 1.06685138 - samples/sec: 69.19 - lr: 0.000030
2021-07-15 14:00:11,566 epoch 11 - iter 2/13 - loss 0.97133207 - samples/sec: 72.89 - lr: 0.000030
2021-07-15 14:00:12,021 epoch 11 - iter 3/13 - loss 0.99356492 - samples/sec: 70.46 - lr: 0.000030
2021-07-15 14:00:12,476 epoch 11 - iter 4/13 - loss 1.17828467 - samples/sec: 70.33 - lr: 0.000030
2021-07-15 14:00:12,938 epoch 11 - iter 5/13 - loss 1.16985981 - samples/sec: 69.39 - lr: 0.000030
2021-07-15 14:00:13,389 epoch 11 - iter 6/13 - loss 1.10861631 - samples/sec: 71.06 - lr: 0.000030
2021-07-15 14:00:13,838 epoch 11 - iter 7/13 - loss 1.06187857 - samples/sec: 71.36 - lr: 0.000030
2021-07-15 14:00:14,298 epoch 11 - iter 8/13 - loss 1.05801719 - samples/sec: 69.64 - lr: 0.000030
2021-07-15 14:00:14,750 epoch 11 - iter 9/13 - loss 1.12891546 - samples/sec: 70.76 - lr: 0.000030
2021-07-15 14:00:15,199 epoch 11 - iter 10/13 - loss 1.13708367 - samples/sec: 71.43 - lr: 0.000030
2021-07-15 14:00:15,638 epoch 11 - iter 11/13 - loss 1.10856710 - samples/sec: 72.89 - lr: 0.000030
2021-07-15 14:00:16,087 epoch 11 - iter 12/13 - loss 1.09227045 - samples/sec: 71.37 - lr: 0.000030
2021-07-15 14:00:16,209 epoch 11 - iter 13/13 - loss 1.03181117 - samples/sec: 262.76 - lr: 0.000030
2021-07-15 14:00:16,209 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:16,209 EPOCH 11 done: loss 1.0318 - lr 0.0000300
2021-07-15 14:00:16,824 DEV : loss 0.9335428476333618 - score 0.7133
2021-07-15 14:00:16,832 BAD EPOCHS (no improvement): 1
2021-07-15 14:00:16,832 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:17,274 epoch 12 - iter 1/13 - loss 0.90257621 - samples/sec: 72.46 - lr: 0.000030
2021-07-15 14:00:17,739 epoch 12 - iter 2/13 - loss 0.99056935 - samples/sec: 68.94 - lr: 0.000030
2021-07-15 14:00:18,167 epoch 12 - iter 3/13 - loss 0.88913647 - samples/sec: 74.80 - lr: 0.000030
2021-07-15 14:00:18,622 epoch 12 - iter 4/13 - loss 0.96195883 - samples/sec: 70.32 - lr: 0.000030
2021-07-15 14:00:19,078 epoch 12 - iter 5/13 - loss 0.92328017 - samples/sec: 70.33 - lr: 0.000030
2021-07-15 14:00:19,515 epoch 12 - iter 6/13 - loss 0.88597709 - samples/sec: 73.22 - lr: 0.000030
2021-07-15 14:00:19,973 epoch 12 - iter 7/13 - loss 1.03764188 - samples/sec: 69.93 - lr: 0.000030
2021-07-15 14:00:20,437 epoch 12 - iter 8/13 - loss 1.07954501 - samples/sec: 69.13 - lr: 0.000030
2021-07-15 14:00:20,887 epoch 12 - iter 9/13 - loss 1.06208902 - samples/sec: 71.08 - lr: 0.000030
2021-07-15 14:00:21,342 epoch 12 - iter 10/13 - loss 1.05873939 - samples/sec: 70.39 - lr: 0.000030
2021-07-15 14:00:21,800 epoch 12 - iter 11/13 - loss 1.08831706 - samples/sec: 70.03 - lr: 0.000030
2021-07-15 14:00:22,236 epoch 12 - iter 12/13 - loss 1.07011615 - samples/sec: 73.40 - lr: 0.000030
2021-07-15 14:00:22,364 epoch 12 - iter 13/13 - loss 1.02740019 - samples/sec: 251.26 - lr: 0.000030
2021-07-15 14:00:22,364 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:22,364 EPOCH 12 done: loss 1.0274 - lr 0.0000300
2021-07-15 14:00:22,906 DEV : loss 0.8818738460540771 - score 0.8024
2021-07-15 14:00:22,914 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:00:26,545 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:27,000 epoch 13 - iter 1/13 - loss 1.10913765 - samples/sec: 70.55 - lr: 0.000030
2021-07-15 14:00:27,438 epoch 13 - iter 2/13 - loss 0.86052191 - samples/sec: 73.17 - lr: 0.000030
2021-07-15 14:00:27,875 epoch 13 - iter 3/13 - loss 0.81961711 - samples/sec: 73.17 - lr: 0.000030
2021-07-15 14:00:28,323 epoch 13 - iter 4/13 - loss 0.77792627 - samples/sec: 71.59 - lr: 0.000030
2021-07-15 14:00:28,770 epoch 13 - iter 5/13 - loss 0.77395113 - samples/sec: 71.56 - lr: 0.000030
2021-07-15 14:00:29,227 epoch 13 - iter 6/13 - loss 0.92428960 - samples/sec: 70.18 - lr: 0.000030
2021-07-15 14:00:29,694 epoch 13 - iter 7/13 - loss 0.91678996 - samples/sec: 68.48 - lr: 0.000030
2021-07-15 14:00:30,158 epoch 13 - iter 8/13 - loss 0.92976613 - samples/sec: 69.11 - lr: 0.000030
2021-07-15 14:00:30,609 epoch 13 - iter 9/13 - loss 0.90113307 - samples/sec: 71.03 - lr: 0.000030
2021-07-15 14:00:31,055 epoch 13 - iter 10/13 - loss 0.97535726 - samples/sec: 71.71 - lr: 0.000030
2021-07-15 14:00:31,522 epoch 13 - iter 11/13 - loss 0.96732752 - samples/sec: 68.72 - lr: 0.000030
2021-07-15 14:00:31,976 epoch 13 - iter 12/13 - loss 0.95994919 - samples/sec: 70.41 - lr: 0.000030
2021-07-15 14:00:32,113 epoch 13 - iter 13/13 - loss 0.99344764 - samples/sec: 235.19 - lr: 0.000030
2021-07-15 14:00:32,113 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:32,113 EPOCH 13 done: loss 0.9934 - lr 0.0000300
2021-07-15 14:00:32,658 DEV : loss 0.8124642968177795 - score 0.8
2021-07-15 14:00:32,666 BAD EPOCHS (no improvement): 1
2021-07-15 14:00:32,666 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:33,097 epoch 14 - iter 1/13 - loss 0.96788067 - samples/sec: 74.29 - lr: 0.000030
2021-07-15 14:00:33,546 epoch 14 - iter 2/13 - loss 0.87844142 - samples/sec: 71.39 - lr: 0.000030
2021-07-15 14:00:34,006 epoch 14 - iter 3/13 - loss 0.96157346 - samples/sec: 69.63 - lr: 0.000030
2021-07-15 14:00:34,472 epoch 14 - iter 4/13 - loss 0.94945045 - samples/sec: 68.67 - lr: 0.000030
2021-07-15 14:00:34,926 epoch 14 - iter 5/13 - loss 1.01239425 - samples/sec: 70.62 - lr: 0.000030
2021-07-15 14:00:35,397 epoch 14 - iter 6/13 - loss 0.96377139 - samples/sec: 68.03 - lr: 0.000030
2021-07-15 14:00:35,846 epoch 14 - iter 7/13 - loss 0.91213155 - samples/sec: 71.30 - lr: 0.000030
2021-07-15 14:00:36,305 epoch 14 - iter 8/13 - loss 0.88539593 - samples/sec: 69.76 - lr: 0.000030
2021-07-15 14:00:36,769 epoch 14 - iter 9/13 - loss 0.91551040 - samples/sec: 69.05 - lr: 0.000030
2021-07-15 14:00:37,228 epoch 14 - iter 10/13 - loss 0.90476348 - samples/sec: 69.75 - lr: 0.000030
2021-07-15 14:00:37,685 epoch 14 - iter 11/13 - loss 0.90996125 - samples/sec: 70.15 - lr: 0.000030
2021-07-15 14:00:38,140 epoch 14 - iter 12/13 - loss 0.90581712 - samples/sec: 70.28 - lr: 0.000030
2021-07-15 14:00:38,277 epoch 14 - iter 13/13 - loss 0.97235018 - samples/sec: 235.55 - lr: 0.000030
2021-07-15 14:00:38,277 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:38,277 EPOCH 14 done: loss 0.9724 - lr 0.0000300
2021-07-15 14:00:38,821 DEV : loss 0.7752809524536133 - score 0.8272
2021-07-15 14:00:38,828 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:00:42,207 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:42,665 epoch 15 - iter 1/13 - loss 1.02085888 - samples/sec: 70.12 - lr: 0.000030
2021-07-15 14:00:43,122 epoch 15 - iter 2/13 - loss 0.81688398 - samples/sec: 70.09 - lr: 0.000030
2021-07-15 14:00:43,581 epoch 15 - iter 3/13 - loss 0.86517759 - samples/sec: 69.68 - lr: 0.000030
2021-07-15 14:00:44,017 epoch 15 - iter 4/13 - loss 0.84927642 - samples/sec: 73.42 - lr: 0.000030
2021-07-15 14:00:44,476 epoch 15 - iter 5/13 - loss 0.85611808 - samples/sec: 69.78 - lr: 0.000030
2021-07-15 14:00:44,909 epoch 15 - iter 6/13 - loss 0.84016044 - samples/sec: 74.08 - lr: 0.000030
2021-07-15 14:00:45,349 epoch 15 - iter 7/13 - loss 0.83108247 - samples/sec: 72.84 - lr: 0.000030
2021-07-15 14:00:45,807 epoch 15 - iter 8/13 - loss 0.83822530 - samples/sec: 69.89 - lr: 0.000030
2021-07-15 14:00:46,259 epoch 15 - iter 9/13 - loss 0.80760131 - samples/sec: 70.81 - lr: 0.000030
2021-07-15 14:00:46,721 epoch 15 - iter 10/13 - loss 0.84815544 - samples/sec: 69.31 - lr: 0.000030
2021-07-15 14:00:47,177 epoch 15 - iter 11/13 - loss 0.85689425 - samples/sec: 70.21 - lr: 0.000030
2021-07-15 14:00:47,644 epoch 15 - iter 12/13 - loss 0.84402688 - samples/sec: 68.62 - lr: 0.000030
2021-07-15 14:00:47,780 epoch 15 - iter 13/13 - loss 0.85179363 - samples/sec: 236.15 - lr: 0.000030
2021-07-15 14:00:47,780 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:47,780 EPOCH 15 done: loss 0.8518 - lr 0.0000300
2021-07-15 14:00:48,324 DEV : loss 0.7433557510375977 - score 0.8263
2021-07-15 14:00:48,332 BAD EPOCHS (no improvement): 1
2021-07-15 14:00:48,332 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:48,786 epoch 16 - iter 1/13 - loss 1.28121710 - samples/sec: 70.60 - lr: 0.000030
2021-07-15 14:00:49,248 epoch 16 - iter 2/13 - loss 0.94319189 - samples/sec: 69.29 - lr: 0.000030
2021-07-15 14:00:49,703 epoch 16 - iter 3/13 - loss 0.92668247 - samples/sec: 70.31 - lr: 0.000030
2021-07-15 14:00:50,161 epoch 16 - iter 4/13 - loss 0.84682541 - samples/sec: 70.05 - lr: 0.000030
2021-07-15 14:00:50,612 epoch 16 - iter 5/13 - loss 0.96003212 - samples/sec: 70.92 - lr: 0.000030
2021-07-15 14:00:51,073 epoch 16 - iter 6/13 - loss 0.91491138 - samples/sec: 69.50 - lr: 0.000030
2021-07-15 14:00:51,512 epoch 16 - iter 7/13 - loss 0.87889691 - samples/sec: 72.94 - lr: 0.000030
2021-07-15 14:00:51,961 epoch 16 - iter 8/13 - loss 0.86374369 - samples/sec: 71.39 - lr: 0.000030
2021-07-15 14:00:52,417 epoch 16 - iter 9/13 - loss 0.87854086 - samples/sec: 70.18 - lr: 0.000030
2021-07-15 14:00:52,869 epoch 16 - iter 10/13 - loss 0.89070597 - samples/sec: 70.94 - lr: 0.000030
2021-07-15 14:00:53,304 epoch 16 - iter 11/13 - loss 0.89266779 - samples/sec: 73.60 - lr: 0.000030
2021-07-15 14:00:53,765 epoch 16 - iter 12/13 - loss 0.88202019 - samples/sec: 69.40 - lr: 0.000030
2021-07-15 14:00:53,900 epoch 16 - iter 13/13 - loss 0.90035060 - samples/sec: 238.36 - lr: 0.000030
2021-07-15 14:00:53,900 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:53,900 EPOCH 16 done: loss 0.9004 - lr 0.0000300
2021-07-15 14:00:54,442 DEV : loss 0.7050917148590088 - score 0.8148
2021-07-15 14:00:54,450 BAD EPOCHS (no improvement): 2
2021-07-15 14:00:54,450 ----------------------------------------------------------------------------------------------------
2021-07-15 14:00:54,895 epoch 17 - iter 1/13 - loss 0.71685386 - samples/sec: 72.09 - lr: 0.000030
2021-07-15 14:00:55,341 epoch 17 - iter 2/13 - loss 0.76225376 - samples/sec: 71.78 - lr: 0.000030
2021-07-15 14:00:55,803 epoch 17 - iter 3/13 - loss 0.93173496 - samples/sec: 69.31 - lr: 0.000030
2021-07-15 14:00:56,244 epoch 17 - iter 4/13 - loss 0.94925892 - samples/sec: 72.60 - lr: 0.000030
2021-07-15 14:00:56,701 epoch 17 - iter 5/13 - loss 0.86049938 - samples/sec: 70.11 - lr: 0.000030
2021-07-15 14:00:57,147 epoch 17 - iter 6/13 - loss 0.83542517 - samples/sec: 71.76 - lr: 0.000030
2021-07-15 14:00:57,603 epoch 17 - iter 7/13 - loss 0.79727368 - samples/sec: 70.23 - lr: 0.000030
2021-07-15 14:00:58,048 epoch 17 - iter 8/13 - loss 0.82813884 - samples/sec: 71.96 - lr: 0.000030
2021-07-15 14:00:58,507 epoch 17 - iter 9/13 - loss 0.79604187 - samples/sec: 69.81 - lr: 0.000030
2021-07-15 14:00:58,967 epoch 17 - iter 10/13 - loss 0.79707969 - samples/sec: 69.63 - lr: 0.000030
2021-07-15 14:00:59,424 epoch 17 - iter 11/13 - loss 0.78313369 - samples/sec: 70.11 - lr: 0.000030
2021-07-15 14:00:59,876 epoch 17 - iter 12/13 - loss 0.77767282 - samples/sec: 70.88 - lr: 0.000030
2021-07-15 14:01:00,011 epoch 17 - iter 13/13 - loss 0.74666571 - samples/sec: 238.09 - lr: 0.000030
2021-07-15 14:01:00,011 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:00,011 EPOCH 17 done: loss 0.7467 - lr 0.0000300
2021-07-15 14:01:00,553 DEV : loss 0.6738038063049316 - score 0.8383
2021-07-15 14:01:00,561 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:01:04,191 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:04,648 epoch 18 - iter 1/13 - loss 0.67721462 - samples/sec: 70.26 - lr: 0.000030
2021-07-15 14:01:05,099 epoch 18 - iter 2/13 - loss 0.60565138 - samples/sec: 70.93 - lr: 0.000030
2021-07-15 14:01:05,554 epoch 18 - iter 3/13 - loss 0.65133548 - samples/sec: 70.51 - lr: 0.000030
2021-07-15 14:01:05,996 epoch 18 - iter 4/13 - loss 0.67218314 - samples/sec: 72.35 - lr: 0.000030
2021-07-15 14:01:06,445 epoch 18 - iter 5/13 - loss 0.66471475 - samples/sec: 71.30 - lr: 0.000030
2021-07-15 14:01:06,903 epoch 18 - iter 6/13 - loss 0.72424971 - samples/sec: 69.94 - lr: 0.000030
2021-07-15 14:01:07,344 epoch 18 - iter 7/13 - loss 0.70129707 - samples/sec: 72.77 - lr: 0.000030
2021-07-15 14:01:07,783 epoch 18 - iter 8/13 - loss 0.70387635 - samples/sec: 72.87 - lr: 0.000030
2021-07-15 14:01:08,228 epoch 18 - iter 9/13 - loss 0.69163438 - samples/sec: 71.98 - lr: 0.000030
2021-07-15 14:01:08,685 epoch 18 - iter 10/13 - loss 0.71312039 - samples/sec: 70.01 - lr: 0.000030
2021-07-15 14:01:09,145 epoch 18 - iter 11/13 - loss 0.74178917 - samples/sec: 69.68 - lr: 0.000030
2021-07-15 14:01:09,604 epoch 18 - iter 12/13 - loss 0.74816428 - samples/sec: 69.78 - lr: 0.000030
2021-07-15 14:01:09,736 epoch 18 - iter 13/13 - loss 0.74181600 - samples/sec: 242.92 - lr: 0.000030
2021-07-15 14:01:09,737 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:09,737 EPOCH 18 done: loss 0.7418 - lr 0.0000300
2021-07-15 14:01:10,279 DEV : loss 0.6446360349655151 - score 0.8706
2021-07-15 14:01:10,287 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:01:13,711 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:14,158 epoch 19 - iter 1/13 - loss 0.67385763 - samples/sec: 71.71 - lr: 0.000030
2021-07-15 14:01:14,605 epoch 19 - iter 2/13 - loss 0.85118929 - samples/sec: 71.67 - lr: 0.000030
2021-07-15 14:01:15,073 epoch 19 - iter 3/13 - loss 0.72602409 - samples/sec: 68.42 - lr: 0.000030
2021-07-15 14:01:15,536 epoch 19 - iter 4/13 - loss 0.70644750 - samples/sec: 69.16 - lr: 0.000030
2021-07-15 14:01:16,009 epoch 19 - iter 5/13 - loss 0.70660230 - samples/sec: 67.76 - lr: 0.000030
2021-07-15 14:01:16,467 epoch 19 - iter 6/13 - loss 0.66879116 - samples/sec: 69.89 - lr: 0.000030
2021-07-15 14:01:16,917 epoch 19 - iter 7/13 - loss 0.68006576 - samples/sec: 71.25 - lr: 0.000030
2021-07-15 14:01:17,375 epoch 19 - iter 8/13 - loss 0.67943036 - samples/sec: 69.96 - lr: 0.000030
2021-07-15 14:01:17,840 epoch 19 - iter 9/13 - loss 0.64582276 - samples/sec: 68.86 - lr: 0.000030
2021-07-15 14:01:18,304 epoch 19 - iter 10/13 - loss 0.65415339 - samples/sec: 68.93 - lr: 0.000030
2021-07-15 14:01:18,748 epoch 19 - iter 11/13 - loss 0.62660126 - samples/sec: 72.14 - lr: 0.000030
2021-07-15 14:01:19,201 epoch 19 - iter 12/13 - loss 0.65029809 - samples/sec: 70.69 - lr: 0.000030
2021-07-15 14:01:19,336 epoch 19 - iter 13/13 - loss 0.63740214 - samples/sec: 238.09 - lr: 0.000030
2021-07-15 14:01:19,336 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:19,337 EPOCH 19 done: loss 0.6374 - lr 0.0000300
2021-07-15 14:01:19,879 DEV : loss 0.6360494494438171 - score 0.8344
2021-07-15 14:01:19,887 BAD EPOCHS (no improvement): 1
2021-07-15 14:01:19,887 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:20,344 epoch 20 - iter 1/13 - loss 0.51461244 - samples/sec: 70.12 - lr: 0.000030
2021-07-15 14:01:20,797 epoch 20 - iter 2/13 - loss 0.69462234 - samples/sec: 70.77 - lr: 0.000030
2021-07-15 14:01:21,250 epoch 20 - iter 3/13 - loss 0.65884888 - samples/sec: 70.66 - lr: 0.000030
2021-07-15 14:01:21,716 epoch 20 - iter 4/13 - loss 0.72650632 - samples/sec: 68.74 - lr: 0.000030
2021-07-15 14:01:22,174 epoch 20 - iter 5/13 - loss 0.73733404 - samples/sec: 69.92 - lr: 0.000030
2021-07-15 14:01:22,638 epoch 20 - iter 6/13 - loss 0.68734847 - samples/sec: 68.93 - lr: 0.000030
2021-07-15 14:01:23,103 epoch 20 - iter 7/13 - loss 0.67578583 - samples/sec: 68.91 - lr: 0.000030
2021-07-15 14:01:23,524 epoch 20 - iter 8/13 - loss 0.64735753 - samples/sec: 76.19 - lr: 0.000030
2021-07-15 14:01:23,988 epoch 20 - iter 9/13 - loss 0.63765784 - samples/sec: 68.99 - lr: 0.000030
2021-07-15 14:01:24,449 epoch 20 - iter 10/13 - loss 0.64493662 - samples/sec: 69.50 - lr: 0.000030
2021-07-15 14:01:24,909 epoch 20 - iter 11/13 - loss 0.63131892 - samples/sec: 69.65 - lr: 0.000030
2021-07-15 14:01:25,366 epoch 20 - iter 12/13 - loss 0.63398958 - samples/sec: 69.97 - lr: 0.000030
2021-07-15 14:01:25,503 epoch 20 - iter 13/13 - loss 0.60139997 - samples/sec: 235.10 - lr: 0.000030
2021-07-15 14:01:25,503 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:25,503 EPOCH 20 done: loss 0.6014 - lr 0.0000300
2021-07-15 14:01:26,046 DEV : loss 0.6265676617622375 - score 0.8323
2021-07-15 14:01:26,054 BAD EPOCHS (no improvement): 2
2021-07-15 14:01:26,054 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:26,513 epoch 21 - iter 1/13 - loss 0.79971862 - samples/sec: 69.78 - lr: 0.000030
2021-07-15 14:01:26,973 epoch 21 - iter 2/13 - loss 0.79856122 - samples/sec: 69.61 - lr: 0.000030
2021-07-15 14:01:27,436 epoch 21 - iter 3/13 - loss 0.78015439 - samples/sec: 69.14 - lr: 0.000030
2021-07-15 14:01:27,897 epoch 21 - iter 4/13 - loss 0.72801198 - samples/sec: 69.50 - lr: 0.000030
2021-07-15 14:01:28,357 epoch 21 - iter 5/13 - loss 0.68441244 - samples/sec: 69.60 - lr: 0.000030
2021-07-15 14:01:28,817 epoch 21 - iter 6/13 - loss 0.62918048 - samples/sec: 69.68 - lr: 0.000030
2021-07-15 14:01:29,259 epoch 21 - iter 7/13 - loss 0.60166978 - samples/sec: 72.44 - lr: 0.000030
2021-07-15 14:01:29,724 epoch 21 - iter 8/13 - loss 0.58831491 - samples/sec: 68.84 - lr: 0.000030
2021-07-15 14:01:30,188 epoch 21 - iter 9/13 - loss 0.60846299 - samples/sec: 69.13 - lr: 0.000030
2021-07-15 14:01:30,640 epoch 21 - iter 10/13 - loss 0.61145230 - samples/sec: 70.79 - lr: 0.000030
2021-07-15 14:01:31,076 epoch 21 - iter 11/13 - loss 0.60114893 - samples/sec: 73.42 - lr: 0.000030
2021-07-15 14:01:31,532 epoch 21 - iter 12/13 - loss 0.61066989 - samples/sec: 70.34 - lr: 0.000030
2021-07-15 14:01:31,669 epoch 21 - iter 13/13 - loss 0.72625725 - samples/sec: 234.04 - lr: 0.000030
2021-07-15 14:01:31,669 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:31,669 EPOCH 21 done: loss 0.7263 - lr 0.0000300
2021-07-15 14:01:32,213 DEV : loss 0.5984005928039551 - score 0.8772
2021-07-15 14:01:32,221 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:01:35,645 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:36,110 epoch 22 - iter 1/13 - loss 1.04339361 - samples/sec: 69.00 - lr: 0.000030
2021-07-15 14:01:36,558 epoch 22 - iter 2/13 - loss 0.80434054 - samples/sec: 71.49 - lr: 0.000030
2021-07-15 14:01:36,996 epoch 22 - iter 3/13 - loss 0.73841659 - samples/sec: 73.03 - lr: 0.000030
2021-07-15 14:01:37,458 epoch 22 - iter 4/13 - loss 0.70164508 - samples/sec: 69.35 - lr: 0.000030
2021-07-15 14:01:37,914 epoch 22 - iter 5/13 - loss 0.79378967 - samples/sec: 70.22 - lr: 0.000030
2021-07-15 14:01:38,370 epoch 22 - iter 6/13 - loss 0.75582908 - samples/sec: 70.30 - lr: 0.000030
2021-07-15 14:01:38,822 epoch 22 - iter 7/13 - loss 0.71044883 - samples/sec: 70.77 - lr: 0.000030
2021-07-15 14:01:39,259 epoch 22 - iter 8/13 - loss 0.67622440 - samples/sec: 73.40 - lr: 0.000030
2021-07-15 14:01:39,706 epoch 22 - iter 9/13 - loss 0.68136021 - samples/sec: 71.59 - lr: 0.000030
2021-07-15 14:01:40,159 epoch 22 - iter 10/13 - loss 0.66218942 - samples/sec: 70.70 - lr: 0.000030
2021-07-15 14:01:40,613 epoch 22 - iter 11/13 - loss 0.66702518 - samples/sec: 70.55 - lr: 0.000030
2021-07-15 14:01:41,070 epoch 22 - iter 12/13 - loss 0.64155962 - samples/sec: 70.08 - lr: 0.000030
2021-07-15 14:01:41,203 epoch 22 - iter 13/13 - loss 0.66545019 - samples/sec: 242.23 - lr: 0.000030
2021-07-15 14:01:41,203 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:41,203 EPOCH 22 done: loss 0.6655 - lr 0.0000300
2021-07-15 14:01:41,746 DEV : loss 0.5893259644508362 - score 0.8848
2021-07-15 14:01:41,754 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:01:45,212 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:45,668 epoch 23 - iter 1/13 - loss 0.65665555 - samples/sec: 70.33 - lr: 0.000030
2021-07-15 14:01:46,110 epoch 23 - iter 2/13 - loss 0.57618767 - samples/sec: 72.46 - lr: 0.000030
2021-07-15 14:01:46,570 epoch 23 - iter 3/13 - loss 0.57655458 - samples/sec: 69.62 - lr: 0.000030
2021-07-15 14:01:47,028 epoch 23 - iter 4/13 - loss 0.59297532 - samples/sec: 69.97 - lr: 0.000030
2021-07-15 14:01:47,490 epoch 23 - iter 5/13 - loss 0.57218537 - samples/sec: 69.33 - lr: 0.000030
2021-07-15 14:01:47,942 epoch 23 - iter 6/13 - loss 0.53604709 - samples/sec: 70.92 - lr: 0.000030
2021-07-15 14:01:48,398 epoch 23 - iter 7/13 - loss 0.54693272 - samples/sec: 70.26 - lr: 0.000030
2021-07-15 14:01:48,837 epoch 23 - iter 8/13 - loss 0.53812368 - samples/sec: 72.82 - lr: 0.000030
2021-07-15 14:01:49,268 epoch 23 - iter 9/13 - loss 0.53653010 - samples/sec: 74.45 - lr: 0.000030
2021-07-15 14:01:49,731 epoch 23 - iter 10/13 - loss 0.56058192 - samples/sec: 69.09 - lr: 0.000030
2021-07-15 14:01:50,185 epoch 23 - iter 11/13 - loss 0.56430609 - samples/sec: 70.60 - lr: 0.000030
2021-07-15 14:01:50,635 epoch 23 - iter 12/13 - loss 0.57078701 - samples/sec: 71.24 - lr: 0.000030
2021-07-15 14:01:50,766 epoch 23 - iter 13/13 - loss 0.57436401 - samples/sec: 244.24 - lr: 0.000030
2021-07-15 14:01:50,766 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:50,766 EPOCH 23 done: loss 0.5744 - lr 0.0000300
2021-07-15 14:01:51,309 DEV : loss 0.5749790072441101 - score 0.8743
2021-07-15 14:01:51,317 BAD EPOCHS (no improvement): 1
2021-07-15 14:01:51,317 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:51,809 epoch 24 - iter 1/13 - loss 0.95613587 - samples/sec: 65.01 - lr: 0.000030
2021-07-15 14:01:52,260 epoch 24 - iter 2/13 - loss 0.69210356 - samples/sec: 71.14 - lr: 0.000030
2021-07-15 14:01:52,714 epoch 24 - iter 3/13 - loss 0.83214851 - samples/sec: 70.53 - lr: 0.000030
2021-07-15 14:01:53,162 epoch 24 - iter 4/13 - loss 0.73082040 - samples/sec: 71.45 - lr: 0.000030
2021-07-15 14:01:53,612 epoch 24 - iter 5/13 - loss 0.65709788 - samples/sec: 71.20 - lr: 0.000030
2021-07-15 14:01:54,046 epoch 24 - iter 6/13 - loss 0.60967562 - samples/sec: 73.81 - lr: 0.000030
2021-07-15 14:01:54,507 epoch 24 - iter 7/13 - loss 0.61578574 - samples/sec: 69.53 - lr: 0.000030
2021-07-15 14:01:54,956 epoch 24 - iter 8/13 - loss 0.59018330 - samples/sec: 71.25 - lr: 0.000030
2021-07-15 14:01:55,417 epoch 24 - iter 9/13 - loss 0.59835503 - samples/sec: 69.47 - lr: 0.000030
2021-07-15 14:01:55,854 epoch 24 - iter 10/13 - loss 0.58145154 - samples/sec: 73.34 - lr: 0.000030
2021-07-15 14:01:56,313 epoch 24 - iter 11/13 - loss 0.56173606 - samples/sec: 69.76 - lr: 0.000030
2021-07-15 14:01:56,777 epoch 24 - iter 12/13 - loss 0.57026296 - samples/sec: 69.08 - lr: 0.000030
2021-07-15 14:01:56,912 epoch 24 - iter 13/13 - loss 0.54269688 - samples/sec: 236.91 - lr: 0.000030
2021-07-15 14:01:56,912 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:56,912 EPOCH 24 done: loss 0.5427 - lr 0.0000300
2021-07-15 14:01:57,453 DEV : loss 0.5641821622848511 - score 0.881
2021-07-15 14:01:57,461 BAD EPOCHS (no improvement): 2
2021-07-15 14:01:57,461 ----------------------------------------------------------------------------------------------------
2021-07-15 14:01:57,910 epoch 25 - iter 1/13 - loss 0.36020529 - samples/sec: 71.44 - lr: 0.000030
2021-07-15 14:01:58,343 epoch 25 - iter 2/13 - loss 0.43558785 - samples/sec: 73.86 - lr: 0.000030
2021-07-15 14:01:58,801 epoch 25 - iter 3/13 - loss 0.53658285 - samples/sec: 70.00 - lr: 0.000030
2021-07-15 14:01:59,260 epoch 25 - iter 4/13 - loss 0.56998812 - samples/sec: 69.78 - lr: 0.000030
2021-07-15 14:01:59,720 epoch 25 - iter 5/13 - loss 0.55725412 - samples/sec: 69.65 - lr: 0.000030
2021-07-15 14:02:00,172 epoch 25 - iter 6/13 - loss 0.50923872 - samples/sec: 70.86 - lr: 0.000030
2021-07-15 14:02:00,616 epoch 25 - iter 7/13 - loss 0.47738352 - samples/sec: 72.13 - lr: 0.000030
2021-07-15 14:02:01,068 epoch 25 - iter 8/13 - loss 0.50128759 - samples/sec: 70.80 - lr: 0.000030
2021-07-15 14:02:01,525 epoch 25 - iter 9/13 - loss 0.50521680 - samples/sec: 70.18 - lr: 0.000030
2021-07-15 14:02:01,979 epoch 25 - iter 10/13 - loss 0.48167369 - samples/sec: 70.44 - lr: 0.000030
2021-07-15 14:02:02,440 epoch 25 - iter 11/13 - loss 0.48354541 - samples/sec: 69.57 - lr: 0.000030
2021-07-15 14:02:02,900 epoch 25 - iter 12/13 - loss 0.53419409 - samples/sec: 69.53 - lr: 0.000030
2021-07-15 14:02:03,036 epoch 25 - iter 13/13 - loss 0.50726122 - samples/sec: 235.96 - lr: 0.000030
2021-07-15 14:02:03,037 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:03,037 EPOCH 25 done: loss 0.5073 - lr 0.0000300
2021-07-15 14:02:03,579 DEV : loss 0.5556461811065674 - score 0.878
2021-07-15 14:02:03,587 BAD EPOCHS (no improvement): 3
2021-07-15 14:02:03,587 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:04,029 epoch 26 - iter 1/13 - loss 0.39140499 - samples/sec: 72.47 - lr: 0.000030
2021-07-15 14:02:04,488 epoch 26 - iter 2/13 - loss 0.48195988 - samples/sec: 69.79 - lr: 0.000030
2021-07-15 14:02:04,929 epoch 26 - iter 3/13 - loss 0.43220477 - samples/sec: 72.57 - lr: 0.000030
2021-07-15 14:02:05,385 epoch 26 - iter 4/13 - loss 0.40339059 - samples/sec: 70.24 - lr: 0.000030
2021-07-15 14:02:05,844 epoch 26 - iter 5/13 - loss 0.38834205 - samples/sec: 69.86 - lr: 0.000030
2021-07-15 14:02:06,282 epoch 26 - iter 6/13 - loss 0.46048390 - samples/sec: 73.10 - lr: 0.000030
2021-07-15 14:02:06,739 epoch 26 - iter 7/13 - loss 0.46382185 - samples/sec: 70.06 - lr: 0.000030
2021-07-15 14:02:07,198 epoch 26 - iter 8/13 - loss 0.45831361 - samples/sec: 69.73 - lr: 0.000030
2021-07-15 14:02:07,664 epoch 26 - iter 9/13 - loss 0.46218339 - samples/sec: 68.80 - lr: 0.000030
2021-07-15 14:02:08,107 epoch 26 - iter 10/13 - loss 0.47896672 - samples/sec: 72.33 - lr: 0.000030
2021-07-15 14:02:08,553 epoch 26 - iter 11/13 - loss 0.45642914 - samples/sec: 71.84 - lr: 0.000030
2021-07-15 14:02:09,004 epoch 26 - iter 12/13 - loss 0.46635557 - samples/sec: 70.89 - lr: 0.000030
2021-07-15 14:02:09,140 epoch 26 - iter 13/13 - loss 0.48135721 - samples/sec: 236.53 - lr: 0.000030
2021-07-15 14:02:09,140 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:09,140 EPOCH 26 done: loss 0.4814 - lr 0.0000300
2021-07-15 14:02:09,683 DEV : loss 0.5538438558578491 - score 0.8834
Epoch    26: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 14:02:09,690 BAD EPOCHS (no improvement): 4
2021-07-15 14:02:09,691 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:10,152 epoch 27 - iter 1/13 - loss 0.53510022 - samples/sec: 69.41 - lr: 0.000015
2021-07-15 14:02:10,599 epoch 27 - iter 2/13 - loss 0.56140047 - samples/sec: 71.57 - lr: 0.000015
2021-07-15 14:02:11,047 epoch 27 - iter 3/13 - loss 0.51349366 - samples/sec: 71.52 - lr: 0.000015
2021-07-15 14:02:11,500 epoch 27 - iter 4/13 - loss 0.56551111 - samples/sec: 70.70 - lr: 0.000015
2021-07-15 14:02:11,961 epoch 27 - iter 5/13 - loss 0.55888376 - samples/sec: 69.58 - lr: 0.000015
2021-07-15 14:02:12,417 epoch 27 - iter 6/13 - loss 0.53231418 - samples/sec: 70.17 - lr: 0.000015
2021-07-15 14:02:12,868 epoch 27 - iter 7/13 - loss 0.52017874 - samples/sec: 70.97 - lr: 0.000015
2021-07-15 14:02:13,318 epoch 27 - iter 8/13 - loss 0.52319394 - samples/sec: 71.31 - lr: 0.000015
2021-07-15 14:02:13,768 epoch 27 - iter 9/13 - loss 0.51612993 - samples/sec: 71.03 - lr: 0.000015
2021-07-15 14:02:14,217 epoch 27 - iter 10/13 - loss 0.50000977 - samples/sec: 71.38 - lr: 0.000015
2021-07-15 14:02:14,677 epoch 27 - iter 11/13 - loss 0.49669072 - samples/sec: 69.58 - lr: 0.000015
2021-07-15 14:02:15,131 epoch 27 - iter 12/13 - loss 0.47944401 - samples/sec: 70.54 - lr: 0.000015
2021-07-15 14:02:15,268 epoch 27 - iter 13/13 - loss 0.45780733 - samples/sec: 235.47 - lr: 0.000015
2021-07-15 14:02:15,268 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:15,268 EPOCH 27 done: loss 0.4578 - lr 0.0000150
2021-07-15 14:02:15,809 DEV : loss 0.5395719408988953 - score 0.8916
2021-07-15 14:02:15,817 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:02:19,156 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:19,617 epoch 28 - iter 1/13 - loss 0.41367054 - samples/sec: 69.55 - lr: 0.000015
2021-07-15 14:02:20,077 epoch 28 - iter 2/13 - loss 0.33667946 - samples/sec: 69.60 - lr: 0.000015
2021-07-15 14:02:20,537 epoch 28 - iter 3/13 - loss 0.38196770 - samples/sec: 69.61 - lr: 0.000015
2021-07-15 14:02:20,985 epoch 28 - iter 4/13 - loss 0.56673819 - samples/sec: 71.45 - lr: 0.000015
2021-07-15 14:02:21,440 epoch 28 - iter 5/13 - loss 0.55508491 - samples/sec: 70.51 - lr: 0.000015
2021-07-15 14:02:21,892 epoch 28 - iter 6/13 - loss 0.51592367 - samples/sec: 70.76 - lr: 0.000015
2021-07-15 14:02:22,333 epoch 28 - iter 7/13 - loss 0.48629149 - samples/sec: 72.71 - lr: 0.000015
2021-07-15 14:02:22,792 epoch 28 - iter 8/13 - loss 0.46833874 - samples/sec: 69.72 - lr: 0.000015
2021-07-15 14:02:23,244 epoch 28 - iter 9/13 - loss 0.44908358 - samples/sec: 70.92 - lr: 0.000015
2021-07-15 14:02:23,693 epoch 28 - iter 10/13 - loss 0.43812321 - samples/sec: 71.28 - lr: 0.000015
2021-07-15 14:02:24,136 epoch 28 - iter 11/13 - loss 0.42199053 - samples/sec: 72.32 - lr: 0.000015
2021-07-15 14:02:24,586 epoch 28 - iter 12/13 - loss 0.42552018 - samples/sec: 71.19 - lr: 0.000015
2021-07-15 14:02:24,720 epoch 28 - iter 13/13 - loss 0.42864856 - samples/sec: 239.81 - lr: 0.000015
2021-07-15 14:02:24,720 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:24,720 EPOCH 28 done: loss 0.4286 - lr 0.0000150
2021-07-15 14:02:25,262 DEV : loss 0.543449878692627 - score 0.878
2021-07-15 14:02:25,270 BAD EPOCHS (no improvement): 1
2021-07-15 14:02:25,270 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:25,707 epoch 29 - iter 1/13 - loss 0.34221217 - samples/sec: 73.33 - lr: 0.000015
2021-07-15 14:02:26,165 epoch 29 - iter 2/13 - loss 0.36147557 - samples/sec: 69.92 - lr: 0.000015
2021-07-15 14:02:26,606 epoch 29 - iter 3/13 - loss 0.41136244 - samples/sec: 72.54 - lr: 0.000015
2021-07-15 14:02:27,059 epoch 29 - iter 4/13 - loss 0.46703475 - samples/sec: 70.77 - lr: 0.000015
2021-07-15 14:02:27,524 epoch 29 - iter 5/13 - loss 0.43005232 - samples/sec: 68.89 - lr: 0.000015
2021-07-15 14:02:27,988 epoch 29 - iter 6/13 - loss 0.42751173 - samples/sec: 69.05 - lr: 0.000015
2021-07-15 14:02:28,430 epoch 29 - iter 7/13 - loss 0.40552353 - samples/sec: 72.38 - lr: 0.000015
2021-07-15 14:02:28,876 epoch 29 - iter 8/13 - loss 0.40663774 - samples/sec: 71.78 - lr: 0.000015
2021-07-15 14:02:29,333 epoch 29 - iter 9/13 - loss 0.40125988 - samples/sec: 70.20 - lr: 0.000015
2021-07-15 14:02:29,786 epoch 29 - iter 10/13 - loss 0.39710132 - samples/sec: 70.67 - lr: 0.000015
2021-07-15 14:02:30,234 epoch 29 - iter 11/13 - loss 0.43483565 - samples/sec: 71.52 - lr: 0.000015
2021-07-15 14:02:30,684 epoch 29 - iter 12/13 - loss 0.42736846 - samples/sec: 71.14 - lr: 0.000015
2021-07-15 14:02:30,816 epoch 29 - iter 13/13 - loss 0.42265963 - samples/sec: 243.32 - lr: 0.000015
2021-07-15 14:02:30,816 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:30,816 EPOCH 29 done: loss 0.4227 - lr 0.0000150
2021-07-15 14:02:31,359 DEV : loss 0.5352342128753662 - score 0.8916
2021-07-15 14:02:31,367 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:02:34,815 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:35,259 epoch 30 - iter 1/13 - loss 0.39925742 - samples/sec: 72.28 - lr: 0.000015
2021-07-15 14:02:35,695 epoch 30 - iter 2/13 - loss 0.37675735 - samples/sec: 73.35 - lr: 0.000015
2021-07-15 14:02:36,205 epoch 30 - iter 3/13 - loss 0.34422602 - samples/sec: 62.80 - lr: 0.000015
2021-07-15 14:02:36,661 epoch 30 - iter 4/13 - loss 0.34921806 - samples/sec: 70.37 - lr: 0.000015
2021-07-15 14:02:37,120 epoch 30 - iter 5/13 - loss 0.37066244 - samples/sec: 69.74 - lr: 0.000015
2021-07-15 14:02:37,558 epoch 30 - iter 6/13 - loss 0.37484366 - samples/sec: 73.16 - lr: 0.000015
2021-07-15 14:02:38,010 epoch 30 - iter 7/13 - loss 0.36713057 - samples/sec: 70.78 - lr: 0.000015
2021-07-15 14:02:38,451 epoch 30 - iter 8/13 - loss 0.35824187 - samples/sec: 72.66 - lr: 0.000015
2021-07-15 14:02:38,910 epoch 30 - iter 9/13 - loss 0.38626039 - samples/sec: 69.83 - lr: 0.000015
2021-07-15 14:02:39,362 epoch 30 - iter 10/13 - loss 0.44403475 - samples/sec: 70.85 - lr: 0.000015
2021-07-15 14:02:39,815 epoch 30 - iter 11/13 - loss 0.45824488 - samples/sec: 70.60 - lr: 0.000015
2021-07-15 14:02:40,266 epoch 30 - iter 12/13 - loss 0.46085769 - samples/sec: 71.04 - lr: 0.000015
2021-07-15 14:02:40,400 epoch 30 - iter 13/13 - loss 0.43641866 - samples/sec: 240.45 - lr: 0.000015
2021-07-15 14:02:40,400 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:40,400 EPOCH 30 done: loss 0.4364 - lr 0.0000150
2021-07-15 14:02:40,944 DEV : loss 0.5380545854568481 - score 0.8848
2021-07-15 14:02:40,952 BAD EPOCHS (no improvement): 1
2021-07-15 14:02:40,952 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:41,396 epoch 31 - iter 1/13 - loss 0.43452740 - samples/sec: 72.17 - lr: 0.000015
2021-07-15 14:02:41,827 epoch 31 - iter 2/13 - loss 0.42214857 - samples/sec: 74.30 - lr: 0.000015
2021-07-15 14:02:42,283 epoch 31 - iter 3/13 - loss 0.40377203 - samples/sec: 70.14 - lr: 0.000015
2021-07-15 14:02:42,725 epoch 31 - iter 4/13 - loss 0.40725905 - samples/sec: 72.54 - lr: 0.000015
2021-07-15 14:02:43,183 epoch 31 - iter 5/13 - loss 0.38592281 - samples/sec: 69.90 - lr: 0.000015
2021-07-15 14:02:43,637 epoch 31 - iter 6/13 - loss 0.42580843 - samples/sec: 70.64 - lr: 0.000015
2021-07-15 14:02:44,101 epoch 31 - iter 7/13 - loss 0.43753355 - samples/sec: 68.91 - lr: 0.000015
2021-07-15 14:02:44,546 epoch 31 - iter 8/13 - loss 0.47759248 - samples/sec: 72.07 - lr: 0.000015
2021-07-15 14:02:45,004 epoch 31 - iter 9/13 - loss 0.47402506 - samples/sec: 69.92 - lr: 0.000015
2021-07-15 14:02:45,458 epoch 31 - iter 10/13 - loss 0.47874526 - samples/sec: 70.49 - lr: 0.000015
2021-07-15 14:02:45,917 epoch 31 - iter 11/13 - loss 0.47410256 - samples/sec: 69.80 - lr: 0.000015
2021-07-15 14:02:46,370 epoch 31 - iter 12/13 - loss 0.48586216 - samples/sec: 70.66 - lr: 0.000015
2021-07-15 14:02:46,497 epoch 31 - iter 13/13 - loss 0.50717903 - samples/sec: 254.11 - lr: 0.000015
2021-07-15 14:02:46,497 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:46,497 EPOCH 31 done: loss 0.5072 - lr 0.0000150
2021-07-15 14:02:47,040 DEV : loss 0.5321661829948425 - score 0.8889
2021-07-15 14:02:47,048 BAD EPOCHS (no improvement): 2
2021-07-15 14:02:47,048 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:47,472 epoch 32 - iter 1/13 - loss 0.93381548 - samples/sec: 75.62 - lr: 0.000015
2021-07-15 14:02:47,922 epoch 32 - iter 2/13 - loss 0.71136892 - samples/sec: 71.18 - lr: 0.000015
2021-07-15 14:02:48,362 epoch 32 - iter 3/13 - loss 0.56270091 - samples/sec: 72.79 - lr: 0.000015
2021-07-15 14:02:48,814 epoch 32 - iter 4/13 - loss 0.51919205 - samples/sec: 70.86 - lr: 0.000015
2021-07-15 14:02:49,270 epoch 32 - iter 5/13 - loss 0.49630820 - samples/sec: 70.25 - lr: 0.000015
2021-07-15 14:02:49,722 epoch 32 - iter 6/13 - loss 0.50520323 - samples/sec: 70.78 - lr: 0.000015
2021-07-15 14:02:50,166 epoch 32 - iter 7/13 - loss 0.47923187 - samples/sec: 72.18 - lr: 0.000015
2021-07-15 14:02:50,623 epoch 32 - iter 8/13 - loss 0.46827874 - samples/sec: 70.16 - lr: 0.000015
2021-07-15 14:02:51,076 epoch 32 - iter 9/13 - loss 0.44727461 - samples/sec: 70.57 - lr: 0.000015
2021-07-15 14:02:51,530 epoch 32 - iter 10/13 - loss 0.43818769 - samples/sec: 70.60 - lr: 0.000015
2021-07-15 14:02:51,987 epoch 32 - iter 11/13 - loss 0.42499156 - samples/sec: 70.04 - lr: 0.000015
2021-07-15 14:02:52,438 epoch 32 - iter 12/13 - loss 0.42564756 - samples/sec: 71.03 - lr: 0.000015
2021-07-15 14:02:52,571 epoch 32 - iter 13/13 - loss 0.42041919 - samples/sec: 241.67 - lr: 0.000015
2021-07-15 14:02:52,571 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:52,572 EPOCH 32 done: loss 0.4204 - lr 0.0000150
2021-07-15 14:02:53,114 DEV : loss 0.5440222024917603 - score 0.878
2021-07-15 14:02:53,122 BAD EPOCHS (no improvement): 3
2021-07-15 14:02:53,122 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:53,559 epoch 33 - iter 1/13 - loss 0.25457358 - samples/sec: 73.33 - lr: 0.000015
2021-07-15 14:02:54,011 epoch 33 - iter 2/13 - loss 0.33089969 - samples/sec: 70.89 - lr: 0.000015
2021-07-15 14:02:54,472 epoch 33 - iter 3/13 - loss 0.44086852 - samples/sec: 69.42 - lr: 0.000015
2021-07-15 14:02:54,932 epoch 33 - iter 4/13 - loss 0.42265950 - samples/sec: 69.67 - lr: 0.000015
2021-07-15 14:02:55,383 epoch 33 - iter 5/13 - loss 0.45367541 - samples/sec: 70.90 - lr: 0.000015
2021-07-15 14:02:55,840 epoch 33 - iter 6/13 - loss 0.42974722 - samples/sec: 70.13 - lr: 0.000015
2021-07-15 14:02:56,294 epoch 33 - iter 7/13 - loss 0.40854543 - samples/sec: 70.51 - lr: 0.000015
2021-07-15 14:02:56,730 epoch 33 - iter 8/13 - loss 0.39994986 - samples/sec: 73.48 - lr: 0.000015
2021-07-15 14:02:57,171 epoch 33 - iter 9/13 - loss 0.38814022 - samples/sec: 72.61 - lr: 0.000015
2021-07-15 14:02:57,618 epoch 33 - iter 10/13 - loss 0.38118344 - samples/sec: 71.71 - lr: 0.000015
2021-07-15 14:02:58,057 epoch 33 - iter 11/13 - loss 0.40642145 - samples/sec: 72.97 - lr: 0.000015
2021-07-15 14:02:58,506 epoch 33 - iter 12/13 - loss 0.41140072 - samples/sec: 71.37 - lr: 0.000015
2021-07-15 14:02:58,643 epoch 33 - iter 13/13 - loss 0.41227569 - samples/sec: 233.57 - lr: 0.000015
2021-07-15 14:02:58,644 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:58,644 EPOCH 33 done: loss 0.4123 - lr 0.0000150
2021-07-15 14:02:59,185 DEV : loss 0.5252417922019958 - score 0.8876
Epoch    33: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 14:02:59,193 BAD EPOCHS (no improvement): 4
2021-07-15 14:02:59,193 ----------------------------------------------------------------------------------------------------
2021-07-15 14:02:59,626 epoch 34 - iter 1/13 - loss 0.17632657 - samples/sec: 74.08 - lr: 0.000008
2021-07-15 14:03:00,076 epoch 34 - iter 2/13 - loss 0.32332495 - samples/sec: 71.13 - lr: 0.000008
2021-07-15 14:03:00,533 epoch 34 - iter 3/13 - loss 0.31313008 - samples/sec: 70.06 - lr: 0.000008
2021-07-15 14:03:00,980 epoch 34 - iter 4/13 - loss 0.34174432 - samples/sec: 71.69 - lr: 0.000008
2021-07-15 14:03:01,414 epoch 34 - iter 5/13 - loss 0.35250683 - samples/sec: 73.85 - lr: 0.000008
2021-07-15 14:03:01,869 epoch 34 - iter 6/13 - loss 0.38286384 - samples/sec: 70.42 - lr: 0.000008
2021-07-15 14:03:02,323 epoch 34 - iter 7/13 - loss 0.40612982 - samples/sec: 70.48 - lr: 0.000008
2021-07-15 14:03:02,782 epoch 34 - iter 8/13 - loss 0.40758969 - samples/sec: 69.76 - lr: 0.000008
2021-07-15 14:03:03,239 epoch 34 - iter 9/13 - loss 0.39315837 - samples/sec: 70.06 - lr: 0.000008
2021-07-15 14:03:03,682 epoch 34 - iter 10/13 - loss 0.40481372 - samples/sec: 72.34 - lr: 0.000008
2021-07-15 14:03:04,121 epoch 34 - iter 11/13 - loss 0.40451662 - samples/sec: 72.90 - lr: 0.000008
2021-07-15 14:03:04,576 epoch 34 - iter 12/13 - loss 0.39882153 - samples/sec: 70.50 - lr: 0.000008
2021-07-15 14:03:04,711 epoch 34 - iter 13/13 - loss 0.38128468 - samples/sec: 237.05 - lr: 0.000008
2021-07-15 14:03:04,712 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:04,712 EPOCH 34 done: loss 0.3813 - lr 0.0000075
2021-07-15 14:03:05,253 DEV : loss 0.5215058922767639 - score 0.9006
2021-07-15 14:03:05,260 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:03:08,691 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:09,149 epoch 35 - iter 1/13 - loss 0.50538540 - samples/sec: 69.85 - lr: 0.000008
2021-07-15 14:03:09,575 epoch 35 - iter 2/13 - loss 0.35638772 - samples/sec: 75.33 - lr: 0.000008
2021-07-15 14:03:10,027 epoch 35 - iter 3/13 - loss 0.40345084 - samples/sec: 70.82 - lr: 0.000008
2021-07-15 14:03:10,479 epoch 35 - iter 4/13 - loss 0.39091375 - samples/sec: 70.87 - lr: 0.000008
2021-07-15 14:03:10,941 epoch 35 - iter 5/13 - loss 0.40497314 - samples/sec: 69.37 - lr: 0.000008
2021-07-15 14:03:11,396 epoch 35 - iter 6/13 - loss 0.38772046 - samples/sec: 70.33 - lr: 0.000008
2021-07-15 14:03:11,856 epoch 35 - iter 7/13 - loss 0.42756567 - samples/sec: 69.58 - lr: 0.000008
2021-07-15 14:03:12,305 epoch 35 - iter 8/13 - loss 0.42275406 - samples/sec: 71.43 - lr: 0.000008
2021-07-15 14:03:12,761 epoch 35 - iter 9/13 - loss 0.39780210 - samples/sec: 70.24 - lr: 0.000008
2021-07-15 14:03:13,213 epoch 35 - iter 10/13 - loss 0.42641769 - samples/sec: 70.82 - lr: 0.000008
2021-07-15 14:03:13,664 epoch 35 - iter 11/13 - loss 0.41465917 - samples/sec: 70.92 - lr: 0.000008
2021-07-15 14:03:14,128 epoch 35 - iter 12/13 - loss 0.39479124 - samples/sec: 69.11 - lr: 0.000008
2021-07-15 14:03:14,260 epoch 35 - iter 13/13 - loss 0.37800056 - samples/sec: 242.46 - lr: 0.000008
2021-07-15 14:03:14,261 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:14,261 EPOCH 35 done: loss 0.3780 - lr 0.0000075
2021-07-15 14:03:14,803 DEV : loss 0.5252277255058289 - score 0.8929
2021-07-15 14:03:14,811 BAD EPOCHS (no improvement): 1
2021-07-15 14:03:14,811 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:15,266 epoch 36 - iter 1/13 - loss 0.22658825 - samples/sec: 70.30 - lr: 0.000008
2021-07-15 14:03:15,719 epoch 36 - iter 2/13 - loss 0.40752140 - samples/sec: 70.74 - lr: 0.000008
2021-07-15 14:03:16,173 epoch 36 - iter 3/13 - loss 0.43605640 - samples/sec: 70.56 - lr: 0.000008
2021-07-15 14:03:16,622 epoch 36 - iter 4/13 - loss 0.44217107 - samples/sec: 71.33 - lr: 0.000008
2021-07-15 14:03:17,081 epoch 36 - iter 5/13 - loss 0.55227053 - samples/sec: 69.85 - lr: 0.000008
2021-07-15 14:03:17,616 epoch 36 - iter 6/13 - loss 0.50855607 - samples/sec: 59.79 - lr: 0.000008
2021-07-15 14:03:18,069 epoch 36 - iter 7/13 - loss 0.47068146 - samples/sec: 70.82 - lr: 0.000008
2021-07-15 14:03:18,524 epoch 36 - iter 8/13 - loss 0.46684292 - samples/sec: 70.40 - lr: 0.000008
2021-07-15 14:03:18,960 epoch 36 - iter 9/13 - loss 0.44669354 - samples/sec: 73.35 - lr: 0.000008
2021-07-15 14:03:19,415 epoch 36 - iter 10/13 - loss 0.45859555 - samples/sec: 70.39 - lr: 0.000008
2021-07-15 14:03:19,860 epoch 36 - iter 11/13 - loss 0.44625805 - samples/sec: 72.02 - lr: 0.000008
2021-07-15 14:03:20,316 epoch 36 - iter 12/13 - loss 0.42989554 - samples/sec: 70.20 - lr: 0.000008
2021-07-15 14:03:20,452 epoch 36 - iter 13/13 - loss 0.40979555 - samples/sec: 236.34 - lr: 0.000008
2021-07-15 14:03:20,452 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:20,452 EPOCH 36 done: loss 0.4098 - lr 0.0000075
2021-07-15 14:03:20,994 DEV : loss 0.5228233933448792 - score 0.8929
2021-07-15 14:03:21,001 BAD EPOCHS (no improvement): 2
2021-07-15 14:03:21,002 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:21,452 epoch 37 - iter 1/13 - loss 0.37313318 - samples/sec: 71.16 - lr: 0.000008
2021-07-15 14:03:21,917 epoch 37 - iter 2/13 - loss 0.36694896 - samples/sec: 68.86 - lr: 0.000008
2021-07-15 14:03:22,351 epoch 37 - iter 3/13 - loss 0.42749522 - samples/sec: 73.78 - lr: 0.000008
2021-07-15 14:03:22,803 epoch 37 - iter 4/13 - loss 0.42324604 - samples/sec: 70.90 - lr: 0.000008
2021-07-15 14:03:23,256 epoch 37 - iter 5/13 - loss 0.42641336 - samples/sec: 70.59 - lr: 0.000008
2021-07-15 14:03:23,715 epoch 37 - iter 6/13 - loss 0.42417452 - samples/sec: 69.76 - lr: 0.000008
2021-07-15 14:03:24,176 epoch 37 - iter 7/13 - loss 0.42156186 - samples/sec: 69.51 - lr: 0.000008
2021-07-15 14:03:24,628 epoch 37 - iter 8/13 - loss 0.40014885 - samples/sec: 70.97 - lr: 0.000008
2021-07-15 14:03:25,076 epoch 37 - iter 9/13 - loss 0.43100821 - samples/sec: 71.41 - lr: 0.000008
2021-07-15 14:03:25,517 epoch 37 - iter 10/13 - loss 0.42516630 - samples/sec: 72.70 - lr: 0.000008
2021-07-15 14:03:25,973 epoch 37 - iter 11/13 - loss 0.43549271 - samples/sec: 70.16 - lr: 0.000008
2021-07-15 14:03:26,436 epoch 37 - iter 12/13 - loss 0.42419076 - samples/sec: 69.24 - lr: 0.000008
2021-07-15 14:03:26,563 epoch 37 - iter 13/13 - loss 0.40512178 - samples/sec: 252.35 - lr: 0.000008
2021-07-15 14:03:26,563 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:26,563 EPOCH 37 done: loss 0.4051 - lr 0.0000075
2021-07-15 14:03:27,106 DEV : loss 0.5197887420654297 - score 0.8889
2021-07-15 14:03:27,114 BAD EPOCHS (no improvement): 3
2021-07-15 14:03:27,114 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:27,565 epoch 38 - iter 1/13 - loss 0.48021930 - samples/sec: 71.04 - lr: 0.000008
2021-07-15 14:03:28,015 epoch 38 - iter 2/13 - loss 0.51533127 - samples/sec: 71.21 - lr: 0.000008
2021-07-15 14:03:28,471 epoch 38 - iter 3/13 - loss 0.50261184 - samples/sec: 70.23 - lr: 0.000008
2021-07-15 14:03:28,936 epoch 38 - iter 4/13 - loss 0.44289556 - samples/sec: 68.81 - lr: 0.000008
2021-07-15 14:03:29,389 epoch 38 - iter 5/13 - loss 0.47449106 - samples/sec: 70.84 - lr: 0.000008
2021-07-15 14:03:29,847 epoch 38 - iter 6/13 - loss 0.46454087 - samples/sec: 69.93 - lr: 0.000008
2021-07-15 14:03:30,296 epoch 38 - iter 7/13 - loss 0.46662570 - samples/sec: 71.21 - lr: 0.000008
2021-07-15 14:03:30,742 epoch 38 - iter 8/13 - loss 0.43228347 - samples/sec: 71.81 - lr: 0.000008
2021-07-15 14:03:31,188 epoch 38 - iter 9/13 - loss 0.42647782 - samples/sec: 71.85 - lr: 0.000008
2021-07-15 14:03:31,639 epoch 38 - iter 10/13 - loss 0.41499112 - samples/sec: 70.97 - lr: 0.000008
2021-07-15 14:03:32,088 epoch 38 - iter 11/13 - loss 0.41157401 - samples/sec: 71.42 - lr: 0.000008
2021-07-15 14:03:32,541 epoch 38 - iter 12/13 - loss 0.40350371 - samples/sec: 70.75 - lr: 0.000008
2021-07-15 14:03:32,676 epoch 38 - iter 13/13 - loss 0.39038690 - samples/sec: 237.27 - lr: 0.000008
2021-07-15 14:03:32,676 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:32,676 EPOCH 38 done: loss 0.3904 - lr 0.0000075
2021-07-15 14:03:33,219 DEV : loss 0.519371509552002 - score 0.8982
Epoch    38: reducing learning rate of group 0 to 3.7500e-06.
2021-07-15 14:03:33,227 BAD EPOCHS (no improvement): 4
2021-07-15 14:03:33,227 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:33,655 epoch 39 - iter 1/13 - loss 0.22874683 - samples/sec: 74.76 - lr: 0.000004
2021-07-15 14:03:34,105 epoch 39 - iter 2/13 - loss 0.27421182 - samples/sec: 71.20 - lr: 0.000004
2021-07-15 14:03:34,556 epoch 39 - iter 3/13 - loss 0.28414595 - samples/sec: 71.08 - lr: 0.000004
2021-07-15 14:03:35,007 epoch 39 - iter 4/13 - loss 0.37831517 - samples/sec: 70.94 - lr: 0.000004
2021-07-15 14:03:35,451 epoch 39 - iter 5/13 - loss 0.36301439 - samples/sec: 72.20 - lr: 0.000004
2021-07-15 14:03:35,911 epoch 39 - iter 6/13 - loss 0.37027516 - samples/sec: 69.55 - lr: 0.000004
2021-07-15 14:03:36,372 epoch 39 - iter 7/13 - loss 0.35924106 - samples/sec: 69.52 - lr: 0.000004
2021-07-15 14:03:36,832 epoch 39 - iter 8/13 - loss 0.37619727 - samples/sec: 69.58 - lr: 0.000004
2021-07-15 14:03:37,287 epoch 39 - iter 9/13 - loss 0.38701744 - samples/sec: 70.41 - lr: 0.000004
2021-07-15 14:03:37,749 epoch 39 - iter 10/13 - loss 0.38425985 - samples/sec: 69.44 - lr: 0.000004
2021-07-15 14:03:38,194 epoch 39 - iter 11/13 - loss 0.38208476 - samples/sec: 71.94 - lr: 0.000004
2021-07-15 14:03:38,656 epoch 39 - iter 12/13 - loss 0.38318287 - samples/sec: 69.30 - lr: 0.000004
2021-07-15 14:03:38,791 epoch 39 - iter 13/13 - loss 0.37024476 - samples/sec: 237.22 - lr: 0.000004
2021-07-15 14:03:38,792 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:38,792 EPOCH 39 done: loss 0.3702 - lr 0.0000038
2021-07-15 14:03:39,335 DEV : loss 0.5146329998970032 - score 0.8953
2021-07-15 14:03:39,342 BAD EPOCHS (no improvement): 1
2021-07-15 14:03:39,343 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:39,799 epoch 40 - iter 1/13 - loss 0.31508470 - samples/sec: 70.24 - lr: 0.000004
2021-07-15 14:03:40,259 epoch 40 - iter 2/13 - loss 0.36042809 - samples/sec: 69.62 - lr: 0.000004
2021-07-15 14:03:40,713 epoch 40 - iter 3/13 - loss 0.31835628 - samples/sec: 70.50 - lr: 0.000004
2021-07-15 14:03:41,158 epoch 40 - iter 4/13 - loss 0.30252647 - samples/sec: 71.90 - lr: 0.000004
2021-07-15 14:03:41,611 epoch 40 - iter 5/13 - loss 0.30252796 - samples/sec: 70.76 - lr: 0.000004
2021-07-15 14:03:42,048 epoch 40 - iter 6/13 - loss 0.34974077 - samples/sec: 73.41 - lr: 0.000004
2021-07-15 14:03:42,505 epoch 40 - iter 7/13 - loss 0.34802971 - samples/sec: 69.99 - lr: 0.000004
2021-07-15 14:03:42,965 epoch 40 - iter 8/13 - loss 0.35553176 - samples/sec: 69.63 - lr: 0.000004
2021-07-15 14:03:43,413 epoch 40 - iter 9/13 - loss 0.35005747 - samples/sec: 71.44 - lr: 0.000004
2021-07-15 14:03:43,868 epoch 40 - iter 10/13 - loss 0.34942875 - samples/sec: 70.38 - lr: 0.000004
2021-07-15 14:03:44,309 epoch 40 - iter 11/13 - loss 0.35051618 - samples/sec: 72.77 - lr: 0.000004
2021-07-15 14:03:44,767 epoch 40 - iter 12/13 - loss 0.34503060 - samples/sec: 69.89 - lr: 0.000004
2021-07-15 14:03:44,897 epoch 40 - iter 13/13 - loss 0.35233290 - samples/sec: 246.97 - lr: 0.000004
2021-07-15 14:03:44,897 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:44,897 EPOCH 40 done: loss 0.3523 - lr 0.0000038
2021-07-15 14:03:45,440 DEV : loss 0.5153416991233826 - score 0.8929
2021-07-15 14:03:45,448 BAD EPOCHS (no improvement): 2
2021-07-15 14:03:46,082 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:46,082 Testing using best model ...
2021-07-15 14:03:46,082 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/zho.rst.sctb/best-model.pt
2021-07-15 14:03:47,981 0.8889	0.8571	0.8727
2021-07-15 14:03:47,981 
Results:
- F1-score (micro) 0.8727
- F1-score (macro) 0.8727

By class:
SENT       tp: 48 - fp: 6 - fn: 8 - precision: 0.8889 - recall: 0.8571 - f1-score: 0.8727
2021-07-15 14:03:47,981 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eus.rst.ert/
2021-07-15 14:03:47,988 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eus.rst.ert
2021-07-15 14:03:47,989 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eus.rst.ert/sent_train.txt
2021-07-15 14:03:47,989 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eus.rst.ert/sent_dev.txt
2021-07-15 14:03:47,989 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eus.rst.ert/sent_test.txt
Corpus: 1210 train + 356 dev + 305 test sentences
Dictionary with 6 tags: <unk>, O, B-SENT, ., <START>, <STOP>
2021-07-15 14:03:50,687 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:50,688 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(52000, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 14:03:50,688 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:50,688 Corpus: "Corpus: 1210 train + 356 dev + 305 test sentences"
2021-07-15 14:03:50,688 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:50,688 Parameters:
2021-07-15 14:03:50,688  - learning_rate: "3e-05"
2021-07-15 14:03:50,689  - mini_batch_size: "32"
2021-07-15 14:03:50,689  - patience: "3"
2021-07-15 14:03:50,689  - anneal_factor: "0.5"
2021-07-15 14:03:50,689  - max_epochs: "40"
2021-07-15 14:03:50,689  - shuffle: "True"
2021-07-15 14:03:50,689  - train_with_dev: "False"
2021-07-15 14:03:50,689  - batch_growth_annealing: "False"
2021-07-15 14:03:50,689 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:50,689 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eus.rst.ert"
2021-07-15 14:03:50,689 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:50,689 Device: cuda:0
2021-07-15 14:03:50,689 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:50,689 Embeddings storage mode: cpu
2021-07-15 14:03:50,690 ----------------------------------------------------------------------------------------------------
2021-07-15 14:03:53,759 epoch 1 - iter 3/38 - loss 52.27148819 - samples/sec: 31.29 - lr: 0.000030
2021-07-15 14:03:56,454 epoch 1 - iter 6/38 - loss 47.29171880 - samples/sec: 35.62 - lr: 0.000030
2021-07-15 14:03:58,880 epoch 1 - iter 9/38 - loss 42.06059964 - samples/sec: 39.58 - lr: 0.000030
2021-07-15 14:04:01,296 epoch 1 - iter 12/38 - loss 38.00257428 - samples/sec: 39.74 - lr: 0.000030
2021-07-15 14:04:03,724 epoch 1 - iter 15/38 - loss 34.27808876 - samples/sec: 39.55 - lr: 0.000030
2021-07-15 14:04:06,140 epoch 1 - iter 18/38 - loss 30.94980314 - samples/sec: 39.74 - lr: 0.000030
2021-07-15 14:04:08,572 epoch 1 - iter 21/38 - loss 28.04277606 - samples/sec: 39.47 - lr: 0.000030
2021-07-15 14:04:10,969 epoch 1 - iter 24/38 - loss 25.43661940 - samples/sec: 40.06 - lr: 0.000030
2021-07-15 14:04:13,380 epoch 1 - iter 27/38 - loss 23.28487266 - samples/sec: 39.82 - lr: 0.000030
2021-07-15 14:04:15,808 epoch 1 - iter 30/38 - loss 21.48622314 - samples/sec: 39.56 - lr: 0.000030
2021-07-15 14:04:18,368 epoch 1 - iter 33/38 - loss 19.99006416 - samples/sec: 37.50 - lr: 0.000030
2021-07-15 14:04:20,743 epoch 1 - iter 36/38 - loss 18.73281625 - samples/sec: 40.43 - lr: 0.000030
2021-07-15 14:04:22,216 ----------------------------------------------------------------------------------------------------
2021-07-15 14:04:22,216 EPOCH 1 done: loss 17.9963 - lr 0.0000300
2021-07-15 14:04:27,229 DEV : loss 3.570220947265625 - score 0.0
2021-07-15 14:04:27,254 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:04:27,766 ----------------------------------------------------------------------------------------------------
2021-07-15 14:04:29,291 epoch 2 - iter 3/38 - loss 3.85076896 - samples/sec: 62.96 - lr: 0.000030
2021-07-15 14:04:30,820 epoch 2 - iter 6/38 - loss 3.52484039 - samples/sec: 62.83 - lr: 0.000030
2021-07-15 14:04:32,376 epoch 2 - iter 9/38 - loss 3.33653975 - samples/sec: 61.70 - lr: 0.000030
2021-07-15 14:04:33,915 epoch 2 - iter 12/38 - loss 3.16066724 - samples/sec: 62.40 - lr: 0.000030
2021-07-15 14:04:35,472 epoch 2 - iter 15/38 - loss 3.07322432 - samples/sec: 61.70 - lr: 0.000030
2021-07-15 14:04:37,059 epoch 2 - iter 18/38 - loss 2.95513303 - samples/sec: 60.50 - lr: 0.000030
2021-07-15 14:04:38,621 epoch 2 - iter 21/38 - loss 2.85721002 - samples/sec: 61.50 - lr: 0.000030
2021-07-15 14:04:40,177 epoch 2 - iter 24/38 - loss 2.76274306 - samples/sec: 61.71 - lr: 0.000030
2021-07-15 14:04:41,743 epoch 2 - iter 27/38 - loss 2.63216265 - samples/sec: 61.30 - lr: 0.000030
2021-07-15 14:04:43,280 epoch 2 - iter 30/38 - loss 2.52906027 - samples/sec: 62.51 - lr: 0.000030
2021-07-15 14:04:44,850 epoch 2 - iter 33/38 - loss 2.43501269 - samples/sec: 61.14 - lr: 0.000030
2021-07-15 14:04:46,405 epoch 2 - iter 36/38 - loss 2.35057962 - samples/sec: 61.77 - lr: 0.000030
2021-07-15 14:04:47,346 ----------------------------------------------------------------------------------------------------
2021-07-15 14:04:47,346 EPOCH 2 done: loss 2.2790 - lr 0.0000300
2021-07-15 14:04:49,281 DEV : loss 0.8696915507316589 - score 0.8405
2021-07-15 14:04:49,306 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:04:52,094 ----------------------------------------------------------------------------------------------------
2021-07-15 14:04:53,627 epoch 3 - iter 3/38 - loss 1.10224080 - samples/sec: 62.64 - lr: 0.000030
2021-07-15 14:04:55,168 epoch 3 - iter 6/38 - loss 1.13383355 - samples/sec: 62.33 - lr: 0.000030
2021-07-15 14:04:56,736 epoch 3 - iter 9/38 - loss 1.16648106 - samples/sec: 61.25 - lr: 0.000030
2021-07-15 14:04:58,408 epoch 3 - iter 12/38 - loss 1.11080130 - samples/sec: 57.43 - lr: 0.000030
2021-07-15 14:04:59,960 epoch 3 - iter 15/38 - loss 1.06650100 - samples/sec: 61.88 - lr: 0.000030
2021-07-15 14:05:01,527 epoch 3 - iter 18/38 - loss 1.06625070 - samples/sec: 61.26 - lr: 0.000030
2021-07-15 14:05:03,091 epoch 3 - iter 21/38 - loss 1.05005127 - samples/sec: 61.42 - lr: 0.000030
2021-07-15 14:05:04,631 epoch 3 - iter 24/38 - loss 1.03835218 - samples/sec: 62.37 - lr: 0.000030
2021-07-15 14:05:06,163 epoch 3 - iter 27/38 - loss 1.00524238 - samples/sec: 62.68 - lr: 0.000030
2021-07-15 14:05:07,719 epoch 3 - iter 30/38 - loss 1.00996608 - samples/sec: 61.72 - lr: 0.000030
2021-07-15 14:05:09,263 epoch 3 - iter 33/38 - loss 0.98550268 - samples/sec: 62.17 - lr: 0.000030
2021-07-15 14:05:10,805 epoch 3 - iter 36/38 - loss 0.96220334 - samples/sec: 62.30 - lr: 0.000030
2021-07-15 14:05:11,749 ----------------------------------------------------------------------------------------------------
2021-07-15 14:05:11,750 EPOCH 3 done: loss 0.9591 - lr 0.0000300
2021-07-15 14:05:13,675 DEV : loss 0.5967008471488953 - score 0.8927
2021-07-15 14:05:13,700 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:05:16,647 ----------------------------------------------------------------------------------------------------
2021-07-15 14:05:18,198 epoch 4 - iter 3/38 - loss 0.73414948 - samples/sec: 61.91 - lr: 0.000030
2021-07-15 14:05:19,760 epoch 4 - iter 6/38 - loss 0.83432463 - samples/sec: 61.50 - lr: 0.000030
2021-07-15 14:05:21,268 epoch 4 - iter 9/38 - loss 0.77827610 - samples/sec: 63.67 - lr: 0.000030
2021-07-15 14:05:22,815 epoch 4 - iter 12/38 - loss 0.73935986 - samples/sec: 62.08 - lr: 0.000030
2021-07-15 14:05:24,287 epoch 4 - iter 15/38 - loss 0.73463467 - samples/sec: 65.23 - lr: 0.000030
2021-07-15 14:05:25,827 epoch 4 - iter 18/38 - loss 0.74307807 - samples/sec: 62.35 - lr: 0.000030
2021-07-15 14:05:27,374 epoch 4 - iter 21/38 - loss 0.71645760 - samples/sec: 62.10 - lr: 0.000030
2021-07-15 14:05:28,935 epoch 4 - iter 24/38 - loss 0.70841076 - samples/sec: 61.50 - lr: 0.000030
2021-07-15 14:05:30,478 epoch 4 - iter 27/38 - loss 0.69693920 - samples/sec: 62.23 - lr: 0.000030
2021-07-15 14:05:32,004 epoch 4 - iter 30/38 - loss 0.69749550 - samples/sec: 62.97 - lr: 0.000030
2021-07-15 14:05:33,568 epoch 4 - iter 33/38 - loss 0.69204202 - samples/sec: 61.38 - lr: 0.000030
2021-07-15 14:05:35,123 epoch 4 - iter 36/38 - loss 0.69137243 - samples/sec: 61.77 - lr: 0.000030
2021-07-15 14:05:36,064 ----------------------------------------------------------------------------------------------------
2021-07-15 14:05:36,065 EPOCH 4 done: loss 0.6779 - lr 0.0000300
2021-07-15 14:05:37,995 DEV : loss 0.521168053150177 - score 0.9175
2021-07-15 14:05:38,020 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:05:40,847 ----------------------------------------------------------------------------------------------------
2021-07-15 14:05:42,391 epoch 5 - iter 3/38 - loss 0.80067903 - samples/sec: 62.22 - lr: 0.000030
2021-07-15 14:05:43,907 epoch 5 - iter 6/38 - loss 0.66408667 - samples/sec: 63.34 - lr: 0.000030
2021-07-15 14:05:45,452 epoch 5 - iter 9/38 - loss 0.66186641 - samples/sec: 62.17 - lr: 0.000030
2021-07-15 14:05:46,988 epoch 5 - iter 12/38 - loss 0.68620832 - samples/sec: 62.49 - lr: 0.000030
2021-07-15 14:05:48,539 epoch 5 - iter 15/38 - loss 0.65029852 - samples/sec: 61.93 - lr: 0.000030
2021-07-15 14:05:50,119 epoch 5 - iter 18/38 - loss 0.65032464 - samples/sec: 60.80 - lr: 0.000030
2021-07-15 14:05:51,684 epoch 5 - iter 21/38 - loss 0.63889918 - samples/sec: 61.33 - lr: 0.000030
2021-07-15 14:05:53,235 epoch 5 - iter 24/38 - loss 0.65309457 - samples/sec: 61.92 - lr: 0.000030
2021-07-15 14:05:54,785 epoch 5 - iter 27/38 - loss 0.65013832 - samples/sec: 61.99 - lr: 0.000030
2021-07-15 14:05:56,323 epoch 5 - iter 30/38 - loss 0.64518150 - samples/sec: 62.42 - lr: 0.000030
2021-07-15 14:05:57,836 epoch 5 - iter 33/38 - loss 0.62383788 - samples/sec: 63.48 - lr: 0.000030
2021-07-15 14:05:59,419 epoch 5 - iter 36/38 - loss 0.60619149 - samples/sec: 60.64 - lr: 0.000030
2021-07-15 14:06:00,386 ----------------------------------------------------------------------------------------------------
2021-07-15 14:06:00,387 EPOCH 5 done: loss 0.5979 - lr 0.0000300
2021-07-15 14:06:02,314 DEV : loss 0.48093098402023315 - score 0.9283
2021-07-15 14:06:02,338 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:06:05,236 ----------------------------------------------------------------------------------------------------
2021-07-15 14:06:06,780 epoch 6 - iter 3/38 - loss 0.49934015 - samples/sec: 62.22 - lr: 0.000030
2021-07-15 14:06:08,318 epoch 6 - iter 6/38 - loss 0.50671362 - samples/sec: 62.43 - lr: 0.000030
2021-07-15 14:06:09,852 epoch 6 - iter 9/38 - loss 0.54509529 - samples/sec: 62.61 - lr: 0.000030
2021-07-15 14:06:11,443 epoch 6 - iter 12/38 - loss 0.57444647 - samples/sec: 60.37 - lr: 0.000030
2021-07-15 14:06:13,002 epoch 6 - iter 15/38 - loss 0.57399850 - samples/sec: 61.58 - lr: 0.000030
2021-07-15 14:06:14,679 epoch 6 - iter 18/38 - loss 0.55946279 - samples/sec: 57.28 - lr: 0.000030
2021-07-15 14:06:16,271 epoch 6 - iter 21/38 - loss 0.59107193 - samples/sec: 60.33 - lr: 0.000030
2021-07-15 14:06:17,808 epoch 6 - iter 24/38 - loss 0.58366959 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 14:06:19,351 epoch 6 - iter 27/38 - loss 0.57065761 - samples/sec: 62.23 - lr: 0.000030
2021-07-15 14:06:20,903 epoch 6 - iter 30/38 - loss 0.55817880 - samples/sec: 61.89 - lr: 0.000030
2021-07-15 14:06:22,455 epoch 6 - iter 33/38 - loss 0.54707021 - samples/sec: 61.85 - lr: 0.000030
2021-07-15 14:06:23,995 epoch 6 - iter 36/38 - loss 0.54755013 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 14:06:24,950 ----------------------------------------------------------------------------------------------------
2021-07-15 14:06:24,950 EPOCH 6 done: loss 0.5371 - lr 0.0000300
2021-07-15 14:06:26,881 DEV : loss 0.46139854192733765 - score 0.9313
2021-07-15 14:06:26,905 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:06:29,839 ----------------------------------------------------------------------------------------------------
2021-07-15 14:06:31,416 epoch 7 - iter 3/38 - loss 0.46355971 - samples/sec: 60.93 - lr: 0.000030
2021-07-15 14:06:32,959 epoch 7 - iter 6/38 - loss 0.53255241 - samples/sec: 62.23 - lr: 0.000030
2021-07-15 14:06:34,527 epoch 7 - iter 9/38 - loss 0.50043031 - samples/sec: 61.25 - lr: 0.000030
2021-07-15 14:06:36,100 epoch 7 - iter 12/38 - loss 0.47606420 - samples/sec: 61.05 - lr: 0.000030
2021-07-15 14:06:37,651 epoch 7 - iter 15/38 - loss 0.45969270 - samples/sec: 61.89 - lr: 0.000030
2021-07-15 14:06:39,175 epoch 7 - iter 18/38 - loss 0.48131021 - samples/sec: 63.03 - lr: 0.000030
2021-07-15 14:06:40,731 epoch 7 - iter 21/38 - loss 0.48663746 - samples/sec: 61.73 - lr: 0.000030
2021-07-15 14:06:42,272 epoch 7 - iter 24/38 - loss 0.49059341 - samples/sec: 62.28 - lr: 0.000030
2021-07-15 14:06:43,832 epoch 7 - iter 27/38 - loss 0.50525279 - samples/sec: 61.57 - lr: 0.000030
2021-07-15 14:06:45,383 epoch 7 - iter 30/38 - loss 0.50189309 - samples/sec: 61.95 - lr: 0.000030
2021-07-15 14:06:46,933 epoch 7 - iter 33/38 - loss 0.50974515 - samples/sec: 61.95 - lr: 0.000030
2021-07-15 14:06:48,471 epoch 7 - iter 36/38 - loss 0.50499265 - samples/sec: 62.42 - lr: 0.000030
2021-07-15 14:06:49,424 ----------------------------------------------------------------------------------------------------
2021-07-15 14:06:49,425 EPOCH 7 done: loss 0.5082 - lr 0.0000300
2021-07-15 14:06:51,355 DEV : loss 0.4554100036621094 - score 0.9326
2021-07-15 14:06:51,380 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:06:54,211 ----------------------------------------------------------------------------------------------------
2021-07-15 14:06:55,732 epoch 8 - iter 3/38 - loss 0.39581677 - samples/sec: 63.15 - lr: 0.000030
2021-07-15 14:06:57,283 epoch 8 - iter 6/38 - loss 0.43993499 - samples/sec: 61.92 - lr: 0.000030
2021-07-15 14:06:58,841 epoch 8 - iter 9/38 - loss 0.41539963 - samples/sec: 61.66 - lr: 0.000030
2021-07-15 14:07:00,399 epoch 8 - iter 12/38 - loss 0.42441910 - samples/sec: 61.63 - lr: 0.000030
2021-07-15 14:07:01,965 epoch 8 - iter 15/38 - loss 0.41662408 - samples/sec: 61.34 - lr: 0.000030
2021-07-15 14:07:03,536 epoch 8 - iter 18/38 - loss 0.41103759 - samples/sec: 61.13 - lr: 0.000030
2021-07-15 14:07:05,090 epoch 8 - iter 21/38 - loss 0.41343747 - samples/sec: 61.79 - lr: 0.000030
2021-07-15 14:07:06,637 epoch 8 - iter 24/38 - loss 0.40508905 - samples/sec: 62.07 - lr: 0.000030
2021-07-15 14:07:08,170 epoch 8 - iter 27/38 - loss 0.42700433 - samples/sec: 62.65 - lr: 0.000030
2021-07-15 14:07:09,724 epoch 8 - iter 30/38 - loss 0.43927202 - samples/sec: 61.79 - lr: 0.000030
2021-07-15 14:07:11,276 epoch 8 - iter 33/38 - loss 0.44672825 - samples/sec: 61.88 - lr: 0.000030
2021-07-15 14:07:12,840 epoch 8 - iter 36/38 - loss 0.44426462 - samples/sec: 61.40 - lr: 0.000030
2021-07-15 14:07:13,787 ----------------------------------------------------------------------------------------------------
2021-07-15 14:07:13,788 EPOCH 8 done: loss 0.4381 - lr 0.0000300
2021-07-15 14:07:15,718 DEV : loss 0.4265184998512268 - score 0.9297
2021-07-15 14:07:15,743 BAD EPOCHS (no improvement): 1
2021-07-15 14:07:15,743 ----------------------------------------------------------------------------------------------------
2021-07-15 14:07:17,298 epoch 9 - iter 3/38 - loss 0.33765537 - samples/sec: 61.78 - lr: 0.000030
2021-07-15 14:07:18,839 epoch 9 - iter 6/38 - loss 0.38210203 - samples/sec: 62.31 - lr: 0.000030
2021-07-15 14:07:20,390 epoch 9 - iter 9/38 - loss 0.39695540 - samples/sec: 61.91 - lr: 0.000030
2021-07-15 14:07:21,909 epoch 9 - iter 12/38 - loss 0.46535428 - samples/sec: 63.25 - lr: 0.000030
2021-07-15 14:07:23,443 epoch 9 - iter 15/38 - loss 0.43278588 - samples/sec: 62.59 - lr: 0.000030
2021-07-15 14:07:25,000 epoch 9 - iter 18/38 - loss 0.43790645 - samples/sec: 61.68 - lr: 0.000030
2021-07-15 14:07:26,564 epoch 9 - iter 21/38 - loss 0.43118852 - samples/sec: 61.41 - lr: 0.000030
2021-07-15 14:07:28,123 epoch 9 - iter 24/38 - loss 0.44329424 - samples/sec: 61.59 - lr: 0.000030
2021-07-15 14:07:29,676 epoch 9 - iter 27/38 - loss 0.42978859 - samples/sec: 61.84 - lr: 0.000030
2021-07-15 14:07:31,228 epoch 9 - iter 30/38 - loss 0.43008010 - samples/sec: 61.87 - lr: 0.000030
2021-07-15 14:07:32,791 epoch 9 - iter 33/38 - loss 0.42358021 - samples/sec: 61.44 - lr: 0.000030
2021-07-15 14:07:34,344 epoch 9 - iter 36/38 - loss 0.41768378 - samples/sec: 61.83 - lr: 0.000030
2021-07-15 14:07:35,306 ----------------------------------------------------------------------------------------------------
2021-07-15 14:07:35,306 EPOCH 9 done: loss 0.4177 - lr 0.0000300
2021-07-15 14:07:37,377 DEV : loss 0.4259178340435028 - score 0.933
2021-07-15 14:07:37,401 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:07:40,235 ----------------------------------------------------------------------------------------------------
2021-07-15 14:07:41,815 epoch 10 - iter 3/38 - loss 0.31899297 - samples/sec: 60.81 - lr: 0.000030
2021-07-15 14:07:43,370 epoch 10 - iter 6/38 - loss 0.35948765 - samples/sec: 61.73 - lr: 0.000030
2021-07-15 14:07:44,960 epoch 10 - iter 9/38 - loss 0.36040788 - samples/sec: 60.41 - lr: 0.000030
2021-07-15 14:07:46,487 epoch 10 - iter 12/38 - loss 0.37646424 - samples/sec: 62.92 - lr: 0.000030
2021-07-15 14:07:48,047 epoch 10 - iter 15/38 - loss 0.36119332 - samples/sec: 61.54 - lr: 0.000030
2021-07-15 14:07:49,575 epoch 10 - iter 18/38 - loss 0.34341974 - samples/sec: 62.86 - lr: 0.000030
2021-07-15 14:07:51,121 epoch 10 - iter 21/38 - loss 0.33798124 - samples/sec: 62.12 - lr: 0.000030
2021-07-15 14:07:52,667 epoch 10 - iter 24/38 - loss 0.35760559 - samples/sec: 62.10 - lr: 0.000030
2021-07-15 14:07:54,224 epoch 10 - iter 27/38 - loss 0.36145271 - samples/sec: 61.67 - lr: 0.000030
2021-07-15 14:07:55,802 epoch 10 - iter 30/38 - loss 0.35937467 - samples/sec: 60.86 - lr: 0.000030
2021-07-15 14:07:57,352 epoch 10 - iter 33/38 - loss 0.35975532 - samples/sec: 61.94 - lr: 0.000030
2021-07-15 14:07:58,891 epoch 10 - iter 36/38 - loss 0.37038105 - samples/sec: 62.43 - lr: 0.000030
2021-07-15 14:07:59,826 ----------------------------------------------------------------------------------------------------
2021-07-15 14:07:59,826 EPOCH 10 done: loss 0.3790 - lr 0.0000300
2021-07-15 14:08:01,756 DEV : loss 0.42487162351608276 - score 0.9317
2021-07-15 14:08:01,782 BAD EPOCHS (no improvement): 1
2021-07-15 14:08:01,782 ----------------------------------------------------------------------------------------------------
2021-07-15 14:08:03,336 epoch 11 - iter 3/38 - loss 0.42008964 - samples/sec: 61.80 - lr: 0.000030
2021-07-15 14:08:04,907 epoch 11 - iter 6/38 - loss 0.36860327 - samples/sec: 61.14 - lr: 0.000030
2021-07-15 14:08:06,452 epoch 11 - iter 9/38 - loss 0.35720968 - samples/sec: 62.15 - lr: 0.000030
2021-07-15 14:08:08,037 epoch 11 - iter 12/38 - loss 0.34761198 - samples/sec: 60.61 - lr: 0.000030
2021-07-15 14:08:09,595 epoch 11 - iter 15/38 - loss 0.34975187 - samples/sec: 61.61 - lr: 0.000030
2021-07-15 14:08:11,126 epoch 11 - iter 18/38 - loss 0.36254595 - samples/sec: 62.72 - lr: 0.000030
2021-07-15 14:08:12,659 epoch 11 - iter 21/38 - loss 0.36370299 - samples/sec: 62.66 - lr: 0.000030
2021-07-15 14:08:14,203 epoch 11 - iter 24/38 - loss 0.36625378 - samples/sec: 62.19 - lr: 0.000030
2021-07-15 14:08:15,742 epoch 11 - iter 27/38 - loss 0.36336339 - samples/sec: 62.40 - lr: 0.000030
2021-07-15 14:08:17,312 epoch 11 - iter 30/38 - loss 0.35773964 - samples/sec: 61.19 - lr: 0.000030
2021-07-15 14:08:18,872 epoch 11 - iter 33/38 - loss 0.35128916 - samples/sec: 61.53 - lr: 0.000030
2021-07-15 14:08:20,435 epoch 11 - iter 36/38 - loss 0.34384929 - samples/sec: 61.44 - lr: 0.000030
2021-07-15 14:08:21,379 ----------------------------------------------------------------------------------------------------
2021-07-15 14:08:21,379 EPOCH 11 done: loss 0.3484 - lr 0.0000300
2021-07-15 14:08:23,306 DEV : loss 0.4292047917842865 - score 0.9343
2021-07-15 14:08:23,331 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:08:26,127 ----------------------------------------------------------------------------------------------------
2021-07-15 14:08:27,656 epoch 12 - iter 3/38 - loss 0.25467775 - samples/sec: 62.82 - lr: 0.000030
2021-07-15 14:08:29,230 epoch 12 - iter 6/38 - loss 0.31272800 - samples/sec: 61.01 - lr: 0.000030
2021-07-15 14:08:30,779 epoch 12 - iter 9/38 - loss 0.31003530 - samples/sec: 62.01 - lr: 0.000030
2021-07-15 14:08:32,346 epoch 12 - iter 12/38 - loss 0.31034790 - samples/sec: 61.26 - lr: 0.000030
2021-07-15 14:08:33,881 epoch 12 - iter 15/38 - loss 0.30854838 - samples/sec: 62.59 - lr: 0.000030
2021-07-15 14:08:35,424 epoch 12 - iter 18/38 - loss 0.29617322 - samples/sec: 62.22 - lr: 0.000030
2021-07-15 14:08:36,984 epoch 12 - iter 21/38 - loss 0.29130379 - samples/sec: 61.57 - lr: 0.000030
2021-07-15 14:08:38,544 epoch 12 - iter 24/38 - loss 0.32128974 - samples/sec: 61.58 - lr: 0.000030
2021-07-15 14:08:40,107 epoch 12 - iter 27/38 - loss 0.32772620 - samples/sec: 61.41 - lr: 0.000030
2021-07-15 14:08:41,639 epoch 12 - iter 30/38 - loss 0.32386800 - samples/sec: 62.69 - lr: 0.000030
2021-07-15 14:08:43,203 epoch 12 - iter 33/38 - loss 0.32513061 - samples/sec: 61.42 - lr: 0.000030
2021-07-15 14:08:44,748 epoch 12 - iter 36/38 - loss 0.32016954 - samples/sec: 62.14 - lr: 0.000030
2021-07-15 14:08:45,702 ----------------------------------------------------------------------------------------------------
2021-07-15 14:08:45,702 EPOCH 12 done: loss 0.3193 - lr 0.0000300
2021-07-15 14:08:47,628 DEV : loss 0.4040970802307129 - score 0.9297
2021-07-15 14:08:47,653 BAD EPOCHS (no improvement): 1
2021-07-15 14:08:47,653 ----------------------------------------------------------------------------------------------------
2021-07-15 14:08:49,335 epoch 13 - iter 3/38 - loss 0.27591838 - samples/sec: 57.10 - lr: 0.000030
2021-07-15 14:08:50,913 epoch 13 - iter 6/38 - loss 0.28513836 - samples/sec: 60.88 - lr: 0.000030
2021-07-15 14:08:52,468 epoch 13 - iter 9/38 - loss 0.29272362 - samples/sec: 61.75 - lr: 0.000030
2021-07-15 14:08:54,028 epoch 13 - iter 12/38 - loss 0.27991543 - samples/sec: 61.54 - lr: 0.000030
2021-07-15 14:08:55,572 epoch 13 - iter 15/38 - loss 0.29055255 - samples/sec: 62.19 - lr: 0.000030
2021-07-15 14:08:57,079 epoch 13 - iter 18/38 - loss 0.28828557 - samples/sec: 63.73 - lr: 0.000030
2021-07-15 14:08:58,652 epoch 13 - iter 21/38 - loss 0.29028788 - samples/sec: 61.04 - lr: 0.000030
2021-07-15 14:09:00,212 epoch 13 - iter 24/38 - loss 0.29669577 - samples/sec: 61.57 - lr: 0.000030
2021-07-15 14:09:01,775 epoch 13 - iter 27/38 - loss 0.29952900 - samples/sec: 61.44 - lr: 0.000030
2021-07-15 14:09:03,303 epoch 13 - iter 30/38 - loss 0.29930949 - samples/sec: 62.85 - lr: 0.000030
2021-07-15 14:09:04,867 epoch 13 - iter 33/38 - loss 0.29945243 - samples/sec: 61.41 - lr: 0.000030
2021-07-15 14:09:06,415 epoch 13 - iter 36/38 - loss 0.30013889 - samples/sec: 62.04 - lr: 0.000030
2021-07-15 14:09:07,368 ----------------------------------------------------------------------------------------------------
2021-07-15 14:09:07,368 EPOCH 13 done: loss 0.2981 - lr 0.0000300
2021-07-15 14:09:09,290 DEV : loss 0.4088892936706543 - score 0.9331
2021-07-15 14:09:09,315 BAD EPOCHS (no improvement): 2
2021-07-15 14:09:09,316 ----------------------------------------------------------------------------------------------------
2021-07-15 14:09:10,872 epoch 14 - iter 3/38 - loss 0.28066125 - samples/sec: 61.72 - lr: 0.000030
2021-07-15 14:09:12,430 epoch 14 - iter 6/38 - loss 0.24692995 - samples/sec: 61.61 - lr: 0.000030
2021-07-15 14:09:13,972 epoch 14 - iter 9/38 - loss 0.24855304 - samples/sec: 62.28 - lr: 0.000030
2021-07-15 14:09:15,531 epoch 14 - iter 12/38 - loss 0.26794793 - samples/sec: 61.60 - lr: 0.000030
2021-07-15 14:09:17,070 epoch 14 - iter 15/38 - loss 0.28483741 - samples/sec: 62.41 - lr: 0.000030
2021-07-15 14:09:18,603 epoch 14 - iter 18/38 - loss 0.29452212 - samples/sec: 62.63 - lr: 0.000030
2021-07-15 14:09:20,111 epoch 14 - iter 21/38 - loss 0.30055301 - samples/sec: 63.69 - lr: 0.000030
2021-07-15 14:09:21,663 epoch 14 - iter 24/38 - loss 0.29335401 - samples/sec: 61.90 - lr: 0.000030
2021-07-15 14:09:23,239 epoch 14 - iter 27/38 - loss 0.29629612 - samples/sec: 60.91 - lr: 0.000030
2021-07-15 14:09:24,808 epoch 14 - iter 30/38 - loss 0.29895395 - samples/sec: 61.23 - lr: 0.000030
2021-07-15 14:09:26,365 epoch 14 - iter 33/38 - loss 0.30689941 - samples/sec: 61.66 - lr: 0.000030
2021-07-15 14:09:27,920 epoch 14 - iter 36/38 - loss 0.30376178 - samples/sec: 61.78 - lr: 0.000030
2021-07-15 14:09:28,875 ----------------------------------------------------------------------------------------------------
2021-07-15 14:09:28,875 EPOCH 14 done: loss 0.3004 - lr 0.0000300
2021-07-15 14:09:30,801 DEV : loss 0.40194153785705566 - score 0.9344
2021-07-15 14:09:30,826 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:09:33,551 ----------------------------------------------------------------------------------------------------
2021-07-15 14:09:35,118 epoch 15 - iter 3/38 - loss 0.27399906 - samples/sec: 61.28 - lr: 0.000030
2021-07-15 14:09:36,672 epoch 15 - iter 6/38 - loss 0.27042921 - samples/sec: 61.82 - lr: 0.000030
2021-07-15 14:09:38,240 epoch 15 - iter 9/38 - loss 0.28944306 - samples/sec: 61.23 - lr: 0.000030
2021-07-15 14:09:39,799 epoch 15 - iter 12/38 - loss 0.28188247 - samples/sec: 61.59 - lr: 0.000030
2021-07-15 14:09:41,369 epoch 15 - iter 15/38 - loss 0.28108734 - samples/sec: 61.20 - lr: 0.000030
2021-07-15 14:09:42,940 epoch 15 - iter 18/38 - loss 0.27993033 - samples/sec: 61.11 - lr: 0.000030
2021-07-15 14:09:44,511 epoch 15 - iter 21/38 - loss 0.26878797 - samples/sec: 61.11 - lr: 0.000030
2021-07-15 14:09:46,024 epoch 15 - iter 24/38 - loss 0.26502140 - samples/sec: 63.49 - lr: 0.000030
2021-07-15 14:09:47,611 epoch 15 - iter 27/38 - loss 0.27334439 - samples/sec: 60.52 - lr: 0.000030
2021-07-15 14:09:49,158 epoch 15 - iter 30/38 - loss 0.26567371 - samples/sec: 62.05 - lr: 0.000030
2021-07-15 14:09:50,683 epoch 15 - iter 33/38 - loss 0.25479952 - samples/sec: 62.98 - lr: 0.000030
2021-07-15 14:09:52,163 epoch 15 - iter 36/38 - loss 0.25155463 - samples/sec: 64.90 - lr: 0.000030
2021-07-15 14:09:53,122 ----------------------------------------------------------------------------------------------------
2021-07-15 14:09:53,122 EPOCH 15 done: loss 0.2575 - lr 0.0000300
2021-07-15 14:09:55,048 DEV : loss 0.43269070982933044 - score 0.9382
2021-07-15 14:09:55,073 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:09:58,061 ----------------------------------------------------------------------------------------------------
2021-07-15 14:09:59,632 epoch 16 - iter 3/38 - loss 0.15066973 - samples/sec: 61.14 - lr: 0.000030
2021-07-15 14:10:01,167 epoch 16 - iter 6/38 - loss 0.23684163 - samples/sec: 62.57 - lr: 0.000030
2021-07-15 14:10:02,743 epoch 16 - iter 9/38 - loss 0.24693163 - samples/sec: 60.95 - lr: 0.000030
2021-07-15 14:10:04,315 epoch 16 - iter 12/38 - loss 0.24618470 - samples/sec: 61.09 - lr: 0.000030
2021-07-15 14:10:05,858 epoch 16 - iter 15/38 - loss 0.24749215 - samples/sec: 62.21 - lr: 0.000030
2021-07-15 14:10:07,411 epoch 16 - iter 18/38 - loss 0.26303749 - samples/sec: 61.85 - lr: 0.000030
2021-07-15 14:10:08,916 epoch 16 - iter 21/38 - loss 0.26028210 - samples/sec: 63.81 - lr: 0.000030
2021-07-15 14:10:10,467 epoch 16 - iter 24/38 - loss 0.26535902 - samples/sec: 61.91 - lr: 0.000030
2021-07-15 14:10:12,063 epoch 16 - iter 27/38 - loss 0.26890925 - samples/sec: 60.17 - lr: 0.000030
2021-07-15 14:10:13,619 epoch 16 - iter 30/38 - loss 0.26643396 - samples/sec: 61.70 - lr: 0.000030
2021-07-15 14:10:15,184 epoch 16 - iter 33/38 - loss 0.26763900 - samples/sec: 61.37 - lr: 0.000030
2021-07-15 14:10:16,713 epoch 16 - iter 36/38 - loss 0.26669451 - samples/sec: 62.82 - lr: 0.000030
2021-07-15 14:10:17,645 ----------------------------------------------------------------------------------------------------
2021-07-15 14:10:17,645 EPOCH 16 done: loss 0.2685 - lr 0.0000300
2021-07-15 14:10:19,727 DEV : loss 0.40061625838279724 - score 0.9288
2021-07-15 14:10:19,752 BAD EPOCHS (no improvement): 1
2021-07-15 14:10:19,752 ----------------------------------------------------------------------------------------------------
2021-07-15 14:10:21,319 epoch 17 - iter 3/38 - loss 0.23069269 - samples/sec: 61.32 - lr: 0.000030
2021-07-15 14:10:22,896 epoch 17 - iter 6/38 - loss 0.23893707 - samples/sec: 60.89 - lr: 0.000030
2021-07-15 14:10:24,440 epoch 17 - iter 9/38 - loss 0.23231776 - samples/sec: 62.20 - lr: 0.000030
2021-07-15 14:10:25,996 epoch 17 - iter 12/38 - loss 0.23812664 - samples/sec: 61.68 - lr: 0.000030
2021-07-15 14:10:27,535 epoch 17 - iter 15/38 - loss 0.24354200 - samples/sec: 62.41 - lr: 0.000030
2021-07-15 14:10:29,103 epoch 17 - iter 18/38 - loss 0.24797522 - samples/sec: 61.23 - lr: 0.000030
2021-07-15 14:10:30,606 epoch 17 - iter 21/38 - loss 0.23888382 - samples/sec: 63.90 - lr: 0.000030
2021-07-15 14:10:32,161 epoch 17 - iter 24/38 - loss 0.23936216 - samples/sec: 61.78 - lr: 0.000030
2021-07-15 14:10:33,739 epoch 17 - iter 27/38 - loss 0.23088578 - samples/sec: 60.84 - lr: 0.000030
2021-07-15 14:10:35,311 epoch 17 - iter 30/38 - loss 0.23297246 - samples/sec: 61.11 - lr: 0.000030
2021-07-15 14:10:36,860 epoch 17 - iter 33/38 - loss 0.23779764 - samples/sec: 62.00 - lr: 0.000030
2021-07-15 14:10:38,396 epoch 17 - iter 36/38 - loss 0.23518962 - samples/sec: 62.51 - lr: 0.000030
2021-07-15 14:10:39,344 ----------------------------------------------------------------------------------------------------
2021-07-15 14:10:39,344 EPOCH 17 done: loss 0.2416 - lr 0.0000300
2021-07-15 14:10:41,270 DEV : loss 0.4005155563354492 - score 0.9313
2021-07-15 14:10:41,295 BAD EPOCHS (no improvement): 2
2021-07-15 14:10:41,295 ----------------------------------------------------------------------------------------------------
2021-07-15 14:10:42,852 epoch 18 - iter 3/38 - loss 0.30394340 - samples/sec: 61.68 - lr: 0.000030
2021-07-15 14:10:44,401 epoch 18 - iter 6/38 - loss 0.27522725 - samples/sec: 62.00 - lr: 0.000030
2021-07-15 14:10:45,961 epoch 18 - iter 9/38 - loss 0.25558255 - samples/sec: 61.55 - lr: 0.000030
2021-07-15 14:10:47,503 epoch 18 - iter 12/38 - loss 0.24934730 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 14:10:49,027 epoch 18 - iter 15/38 - loss 0.24624062 - samples/sec: 63.00 - lr: 0.000030
2021-07-15 14:10:50,555 epoch 18 - iter 18/38 - loss 0.23879895 - samples/sec: 62.84 - lr: 0.000030
2021-07-15 14:10:52,119 epoch 18 - iter 21/38 - loss 0.24417699 - samples/sec: 61.43 - lr: 0.000030
2021-07-15 14:10:53,655 epoch 18 - iter 24/38 - loss 0.23392628 - samples/sec: 62.49 - lr: 0.000030
2021-07-15 14:10:55,202 epoch 18 - iter 27/38 - loss 0.24207066 - samples/sec: 62.09 - lr: 0.000030
2021-07-15 14:10:56,780 epoch 18 - iter 30/38 - loss 0.24172993 - samples/sec: 60.85 - lr: 0.000030
2021-07-15 14:10:58,316 epoch 18 - iter 33/38 - loss 0.23435793 - samples/sec: 62.53 - lr: 0.000030
2021-07-15 14:10:59,874 epoch 18 - iter 36/38 - loss 0.23472766 - samples/sec: 61.65 - lr: 0.000030
2021-07-15 14:11:00,834 ----------------------------------------------------------------------------------------------------
2021-07-15 14:11:00,834 EPOCH 18 done: loss 0.2322 - lr 0.0000300
2021-07-15 14:11:02,767 DEV : loss 0.3967965841293335 - score 0.9365
2021-07-15 14:11:02,792 BAD EPOCHS (no improvement): 3
2021-07-15 14:11:02,792 ----------------------------------------------------------------------------------------------------
2021-07-15 14:11:04,360 epoch 19 - iter 3/38 - loss 0.28694121 - samples/sec: 61.27 - lr: 0.000030
2021-07-15 14:11:05,901 epoch 19 - iter 6/38 - loss 0.28534759 - samples/sec: 62.31 - lr: 0.000030
2021-07-15 14:11:07,444 epoch 19 - iter 9/38 - loss 0.23786124 - samples/sec: 62.23 - lr: 0.000030
2021-07-15 14:11:09,018 epoch 19 - iter 12/38 - loss 0.23695624 - samples/sec: 60.99 - lr: 0.000030
2021-07-15 14:11:10,531 epoch 19 - iter 15/38 - loss 0.24339190 - samples/sec: 63.51 - lr: 0.000030
2021-07-15 14:11:12,064 epoch 19 - iter 18/38 - loss 0.23307443 - samples/sec: 62.62 - lr: 0.000030
2021-07-15 14:11:13,636 epoch 19 - iter 21/38 - loss 0.22056031 - samples/sec: 61.09 - lr: 0.000030
2021-07-15 14:11:15,171 epoch 19 - iter 24/38 - loss 0.21267436 - samples/sec: 62.55 - lr: 0.000030
2021-07-15 14:11:16,703 epoch 19 - iter 27/38 - loss 0.22575139 - samples/sec: 62.71 - lr: 0.000030
2021-07-15 14:11:18,270 epoch 19 - iter 30/38 - loss 0.22200063 - samples/sec: 61.26 - lr: 0.000030
2021-07-15 14:11:19,831 epoch 19 - iter 33/38 - loss 0.22105195 - samples/sec: 61.52 - lr: 0.000030
2021-07-15 14:11:21,399 epoch 19 - iter 36/38 - loss 0.22626340 - samples/sec: 61.25 - lr: 0.000030
2021-07-15 14:11:22,346 ----------------------------------------------------------------------------------------------------
2021-07-15 14:11:22,346 EPOCH 19 done: loss 0.2246 - lr 0.0000300
2021-07-15 14:11:24,415 DEV : loss 0.41244634985923767 - score 0.9307
Epoch    19: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 14:11:24,440 BAD EPOCHS (no improvement): 4
2021-07-15 14:11:24,440 ----------------------------------------------------------------------------------------------------
2021-07-15 14:11:25,999 epoch 20 - iter 3/38 - loss 0.25675996 - samples/sec: 61.60 - lr: 0.000015
2021-07-15 14:11:27,536 epoch 20 - iter 6/38 - loss 0.18927335 - samples/sec: 62.47 - lr: 0.000015
2021-07-15 14:11:29,095 epoch 20 - iter 9/38 - loss 0.19502761 - samples/sec: 61.63 - lr: 0.000015
2021-07-15 14:11:30,635 epoch 20 - iter 12/38 - loss 0.19790273 - samples/sec: 62.35 - lr: 0.000015
2021-07-15 14:11:32,196 epoch 20 - iter 15/38 - loss 0.20497801 - samples/sec: 61.51 - lr: 0.000015
2021-07-15 14:11:33,744 epoch 20 - iter 18/38 - loss 0.22055608 - samples/sec: 62.05 - lr: 0.000015
2021-07-15 14:11:35,308 epoch 20 - iter 21/38 - loss 0.22241317 - samples/sec: 61.40 - lr: 0.000015
2021-07-15 14:11:36,836 epoch 20 - iter 24/38 - loss 0.21722253 - samples/sec: 62.85 - lr: 0.000015
2021-07-15 14:11:38,370 epoch 20 - iter 27/38 - loss 0.22867150 - samples/sec: 62.61 - lr: 0.000015
2021-07-15 14:11:39,924 epoch 20 - iter 30/38 - loss 0.22601450 - samples/sec: 61.79 - lr: 0.000015
2021-07-15 14:11:41,472 epoch 20 - iter 33/38 - loss 0.22751042 - samples/sec: 62.02 - lr: 0.000015
2021-07-15 14:11:43,048 epoch 20 - iter 36/38 - loss 0.22642192 - samples/sec: 60.95 - lr: 0.000015
2021-07-15 14:11:43,974 ----------------------------------------------------------------------------------------------------
2021-07-15 14:11:43,975 EPOCH 20 done: loss 0.2271 - lr 0.0000150
2021-07-15 14:11:45,901 DEV : loss 0.40072232484817505 - score 0.9322
2021-07-15 14:11:45,926 BAD EPOCHS (no improvement): 1
2021-07-15 14:11:45,926 ----------------------------------------------------------------------------------------------------
2021-07-15 14:11:47,487 epoch 21 - iter 3/38 - loss 0.15462184 - samples/sec: 61.50 - lr: 0.000015
2021-07-15 14:11:49,047 epoch 21 - iter 6/38 - loss 0.17346740 - samples/sec: 61.57 - lr: 0.000015
2021-07-15 14:11:50,596 epoch 21 - iter 9/38 - loss 0.19027193 - samples/sec: 62.01 - lr: 0.000015
2021-07-15 14:11:52,140 epoch 21 - iter 12/38 - loss 0.19820540 - samples/sec: 62.17 - lr: 0.000015
2021-07-15 14:11:53,688 epoch 21 - iter 15/38 - loss 0.20016378 - samples/sec: 62.04 - lr: 0.000015
2021-07-15 14:11:55,231 epoch 21 - iter 18/38 - loss 0.19612508 - samples/sec: 62.24 - lr: 0.000015
2021-07-15 14:11:56,792 epoch 21 - iter 21/38 - loss 0.19031837 - samples/sec: 61.53 - lr: 0.000015
2021-07-15 14:11:58,343 epoch 21 - iter 24/38 - loss 0.19484614 - samples/sec: 61.93 - lr: 0.000015
2021-07-15 14:11:59,923 epoch 21 - iter 27/38 - loss 0.19621672 - samples/sec: 60.78 - lr: 0.000015
2021-07-15 14:12:01,471 epoch 21 - iter 30/38 - loss 0.19887536 - samples/sec: 62.00 - lr: 0.000015
2021-07-15 14:12:02,995 epoch 21 - iter 33/38 - loss 0.20028422 - samples/sec: 63.04 - lr: 0.000015
2021-07-15 14:12:04,572 epoch 21 - iter 36/38 - loss 0.19582741 - samples/sec: 60.89 - lr: 0.000015
2021-07-15 14:12:05,531 ----------------------------------------------------------------------------------------------------
2021-07-15 14:12:05,531 EPOCH 21 done: loss 0.1957 - lr 0.0000150
2021-07-15 14:12:07,456 DEV : loss 0.39089685678482056 - score 0.9352
2021-07-15 14:12:07,480 BAD EPOCHS (no improvement): 2
2021-07-15 14:12:07,480 ----------------------------------------------------------------------------------------------------
2021-07-15 14:12:08,996 epoch 22 - iter 3/38 - loss 0.20017358 - samples/sec: 63.38 - lr: 0.000015
2021-07-15 14:12:10,547 epoch 22 - iter 6/38 - loss 0.21054180 - samples/sec: 61.89 - lr: 0.000015
2021-07-15 14:12:12,096 epoch 22 - iter 9/38 - loss 0.19460282 - samples/sec: 62.02 - lr: 0.000015
2021-07-15 14:12:13,648 epoch 22 - iter 12/38 - loss 0.18053860 - samples/sec: 61.85 - lr: 0.000015
2021-07-15 14:12:15,190 epoch 22 - iter 15/38 - loss 0.18106105 - samples/sec: 62.30 - lr: 0.000015
2021-07-15 14:12:16,748 epoch 22 - iter 18/38 - loss 0.19106147 - samples/sec: 61.63 - lr: 0.000015
2021-07-15 14:12:18,318 epoch 22 - iter 21/38 - loss 0.19491241 - samples/sec: 61.14 - lr: 0.000015
2021-07-15 14:12:19,852 epoch 22 - iter 24/38 - loss 0.20108883 - samples/sec: 62.64 - lr: 0.000015
2021-07-15 14:12:21,393 epoch 22 - iter 27/38 - loss 0.21182857 - samples/sec: 62.31 - lr: 0.000015
2021-07-15 14:12:22,941 epoch 22 - iter 30/38 - loss 0.21065765 - samples/sec: 62.04 - lr: 0.000015
2021-07-15 14:12:24,512 epoch 22 - iter 33/38 - loss 0.21878643 - samples/sec: 61.13 - lr: 0.000015
2021-07-15 14:12:26,088 epoch 22 - iter 36/38 - loss 0.21843068 - samples/sec: 60.91 - lr: 0.000015
2021-07-15 14:12:27,046 ----------------------------------------------------------------------------------------------------
2021-07-15 14:12:27,046 EPOCH 22 done: loss 0.2158 - lr 0.0000150
2021-07-15 14:12:28,969 DEV : loss 0.3827552795410156 - score 0.9357
2021-07-15 14:12:28,994 BAD EPOCHS (no improvement): 3
2021-07-15 14:12:28,994 ----------------------------------------------------------------------------------------------------
2021-07-15 14:12:30,563 epoch 23 - iter 3/38 - loss 0.21825775 - samples/sec: 61.20 - lr: 0.000015
2021-07-15 14:12:32,086 epoch 23 - iter 6/38 - loss 0.23195912 - samples/sec: 63.04 - lr: 0.000015
2021-07-15 14:12:33,635 epoch 23 - iter 9/38 - loss 0.21179290 - samples/sec: 62.01 - lr: 0.000015
2021-07-15 14:12:35,176 epoch 23 - iter 12/38 - loss 0.21000664 - samples/sec: 62.32 - lr: 0.000015
2021-07-15 14:12:36,720 epoch 23 - iter 15/38 - loss 0.20747902 - samples/sec: 62.21 - lr: 0.000015
2021-07-15 14:12:38,267 epoch 23 - iter 18/38 - loss 0.20804448 - samples/sec: 62.07 - lr: 0.000015
2021-07-15 14:12:39,794 epoch 23 - iter 21/38 - loss 0.20442530 - samples/sec: 62.91 - lr: 0.000015
2021-07-15 14:12:41,360 epoch 23 - iter 24/38 - loss 0.20081754 - samples/sec: 61.32 - lr: 0.000015
2021-07-15 14:12:42,902 epoch 23 - iter 27/38 - loss 0.20222518 - samples/sec: 62.25 - lr: 0.000015
2021-07-15 14:12:44,475 epoch 23 - iter 30/38 - loss 0.21626935 - samples/sec: 61.07 - lr: 0.000015
2021-07-15 14:12:46,043 epoch 23 - iter 33/38 - loss 0.21573237 - samples/sec: 61.23 - lr: 0.000015
2021-07-15 14:12:47,589 epoch 23 - iter 36/38 - loss 0.20908717 - samples/sec: 62.14 - lr: 0.000015
2021-07-15 14:12:48,669 ----------------------------------------------------------------------------------------------------
2021-07-15 14:12:48,670 EPOCH 23 done: loss 0.2091 - lr 0.0000150
2021-07-15 14:12:50,597 DEV : loss 0.39006873965263367 - score 0.9311
Epoch    23: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 14:12:50,622 BAD EPOCHS (no improvement): 4
2021-07-15 14:12:50,622 ----------------------------------------------------------------------------------------------------
2021-07-15 14:12:52,183 epoch 24 - iter 3/38 - loss 0.18920966 - samples/sec: 61.50 - lr: 0.000008
2021-07-15 14:12:53,743 epoch 24 - iter 6/38 - loss 0.17144890 - samples/sec: 61.59 - lr: 0.000008
2021-07-15 14:12:55,303 epoch 24 - iter 9/38 - loss 0.16987395 - samples/sec: 61.54 - lr: 0.000008
2021-07-15 14:12:56,835 epoch 24 - iter 12/38 - loss 0.17853272 - samples/sec: 62.70 - lr: 0.000008
2021-07-15 14:12:58,388 epoch 24 - iter 15/38 - loss 0.18416302 - samples/sec: 61.82 - lr: 0.000008
2021-07-15 14:12:59,973 epoch 24 - iter 18/38 - loss 0.18728231 - samples/sec: 60.59 - lr: 0.000008
2021-07-15 14:13:01,523 epoch 24 - iter 21/38 - loss 0.18622260 - samples/sec: 61.93 - lr: 0.000008
2021-07-15 14:13:03,087 epoch 24 - iter 24/38 - loss 0.19087474 - samples/sec: 61.42 - lr: 0.000008
2021-07-15 14:13:04,629 epoch 24 - iter 27/38 - loss 0.18886867 - samples/sec: 62.30 - lr: 0.000008
2021-07-15 14:13:06,150 epoch 24 - iter 30/38 - loss 0.18885697 - samples/sec: 63.10 - lr: 0.000008
2021-07-15 14:13:07,721 epoch 24 - iter 33/38 - loss 0.18276736 - samples/sec: 61.16 - lr: 0.000008
2021-07-15 14:13:09,283 epoch 24 - iter 36/38 - loss 0.19084562 - samples/sec: 61.47 - lr: 0.000008
2021-07-15 14:13:10,193 ----------------------------------------------------------------------------------------------------
2021-07-15 14:13:10,193 EPOCH 24 done: loss 0.1902 - lr 0.0000075
2021-07-15 14:13:12,123 DEV : loss 0.3890650272369385 - score 0.9337
2021-07-15 14:13:12,148 BAD EPOCHS (no improvement): 1
2021-07-15 14:13:12,148 ----------------------------------------------------------------------------------------------------
2021-07-15 14:13:13,708 epoch 25 - iter 3/38 - loss 0.17744970 - samples/sec: 61.54 - lr: 0.000008
2021-07-15 14:13:15,272 epoch 25 - iter 6/38 - loss 0.21013861 - samples/sec: 61.43 - lr: 0.000008
2021-07-15 14:13:16,841 epoch 25 - iter 9/38 - loss 0.21703999 - samples/sec: 61.21 - lr: 0.000008
2021-07-15 14:13:18,364 epoch 25 - iter 12/38 - loss 0.20047172 - samples/sec: 63.05 - lr: 0.000008
2021-07-15 14:13:19,891 epoch 25 - iter 15/38 - loss 0.19048479 - samples/sec: 62.85 - lr: 0.000008
2021-07-15 14:13:21,412 epoch 25 - iter 18/38 - loss 0.18184095 - samples/sec: 63.17 - lr: 0.000008
2021-07-15 14:13:22,970 epoch 25 - iter 21/38 - loss 0.18559610 - samples/sec: 61.61 - lr: 0.000008
2021-07-15 14:13:24,551 epoch 25 - iter 24/38 - loss 0.17805851 - samples/sec: 60.74 - lr: 0.000008
2021-07-15 14:13:26,133 epoch 25 - iter 27/38 - loss 0.17541685 - samples/sec: 60.72 - lr: 0.000008
2021-07-15 14:13:27,647 epoch 25 - iter 30/38 - loss 0.17606847 - samples/sec: 63.41 - lr: 0.000008
2021-07-15 14:13:29,205 epoch 25 - iter 33/38 - loss 0.17384581 - samples/sec: 61.67 - lr: 0.000008
2021-07-15 14:13:30,759 epoch 25 - iter 36/38 - loss 0.17267015 - samples/sec: 61.78 - lr: 0.000008
2021-07-15 14:13:31,698 ----------------------------------------------------------------------------------------------------
2021-07-15 14:13:31,698 EPOCH 25 done: loss 0.1750 - lr 0.0000075
2021-07-15 14:13:33,622 DEV : loss 0.39729493856430054 - score 0.9389
2021-07-15 14:13:33,647 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:13:36,531 ----------------------------------------------------------------------------------------------------
2021-07-15 14:13:38,093 epoch 26 - iter 3/38 - loss 0.17408101 - samples/sec: 61.51 - lr: 0.000008
2021-07-15 14:13:39,651 epoch 26 - iter 6/38 - loss 0.16701956 - samples/sec: 61.61 - lr: 0.000008
2021-07-15 14:13:41,177 epoch 26 - iter 9/38 - loss 0.16554437 - samples/sec: 62.97 - lr: 0.000008
2021-07-15 14:13:42,747 epoch 26 - iter 12/38 - loss 0.16699519 - samples/sec: 61.14 - lr: 0.000008
2021-07-15 14:13:44,280 epoch 26 - iter 15/38 - loss 0.16718954 - samples/sec: 62.66 - lr: 0.000008
2021-07-15 14:13:45,807 epoch 26 - iter 18/38 - loss 0.16648456 - samples/sec: 62.86 - lr: 0.000008
2021-07-15 14:13:47,387 epoch 26 - iter 21/38 - loss 0.17872105 - samples/sec: 60.78 - lr: 0.000008
2021-07-15 14:13:48,956 epoch 26 - iter 24/38 - loss 0.18080041 - samples/sec: 61.22 - lr: 0.000008
2021-07-15 14:13:50,527 epoch 26 - iter 27/38 - loss 0.18681762 - samples/sec: 61.12 - lr: 0.000008
2021-07-15 14:13:52,039 epoch 26 - iter 30/38 - loss 0.19431886 - samples/sec: 63.53 - lr: 0.000008
2021-07-15 14:13:53,591 epoch 26 - iter 33/38 - loss 0.19413715 - samples/sec: 61.87 - lr: 0.000008
2021-07-15 14:13:55,161 epoch 26 - iter 36/38 - loss 0.19493970 - samples/sec: 61.16 - lr: 0.000008
2021-07-15 14:13:56,105 ----------------------------------------------------------------------------------------------------
2021-07-15 14:13:56,105 EPOCH 26 done: loss 0.1915 - lr 0.0000075
2021-07-15 14:13:58,171 DEV : loss 0.3906590938568115 - score 0.9324
2021-07-15 14:13:58,196 BAD EPOCHS (no improvement): 1
2021-07-15 14:13:58,196 ----------------------------------------------------------------------------------------------------
2021-07-15 14:13:59,742 epoch 27 - iter 3/38 - loss 0.20484570 - samples/sec: 62.11 - lr: 0.000008
2021-07-15 14:14:01,321 epoch 27 - iter 6/38 - loss 0.20816885 - samples/sec: 60.81 - lr: 0.000008
2021-07-15 14:14:02,897 epoch 27 - iter 9/38 - loss 0.17759602 - samples/sec: 60.97 - lr: 0.000008
2021-07-15 14:14:04,435 epoch 27 - iter 12/38 - loss 0.18439554 - samples/sec: 62.41 - lr: 0.000008
2021-07-15 14:14:05,989 epoch 27 - iter 15/38 - loss 0.20432671 - samples/sec: 61.82 - lr: 0.000008
2021-07-15 14:14:07,523 epoch 27 - iter 18/38 - loss 0.19534272 - samples/sec: 62.60 - lr: 0.000008
2021-07-15 14:14:09,085 epoch 27 - iter 21/38 - loss 0.19737191 - samples/sec: 61.48 - lr: 0.000008
2021-07-15 14:14:10,640 epoch 27 - iter 24/38 - loss 0.20091120 - samples/sec: 61.73 - lr: 0.000008
2021-07-15 14:14:12,140 epoch 27 - iter 27/38 - loss 0.19462559 - samples/sec: 64.05 - lr: 0.000008
2021-07-15 14:14:13,688 epoch 27 - iter 30/38 - loss 0.19197649 - samples/sec: 62.02 - lr: 0.000008
2021-07-15 14:14:15,255 epoch 27 - iter 33/38 - loss 0.19042551 - samples/sec: 61.28 - lr: 0.000008
2021-07-15 14:14:16,810 epoch 27 - iter 36/38 - loss 0.19089522 - samples/sec: 61.76 - lr: 0.000008
2021-07-15 14:14:17,746 ----------------------------------------------------------------------------------------------------
2021-07-15 14:14:17,747 EPOCH 27 done: loss 0.1889 - lr 0.0000075
2021-07-15 14:14:19,665 DEV : loss 0.3890867233276367 - score 0.9337
2021-07-15 14:14:19,690 BAD EPOCHS (no improvement): 2
2021-07-15 14:14:19,690 ----------------------------------------------------------------------------------------------------
2021-07-15 14:14:21,247 epoch 28 - iter 3/38 - loss 0.22153414 - samples/sec: 61.69 - lr: 0.000008
2021-07-15 14:14:22,796 epoch 28 - iter 6/38 - loss 0.22460165 - samples/sec: 61.98 - lr: 0.000008
2021-07-15 14:14:24,355 epoch 28 - iter 9/38 - loss 0.18302842 - samples/sec: 61.62 - lr: 0.000008
2021-07-15 14:14:25,892 epoch 28 - iter 12/38 - loss 0.17029320 - samples/sec: 62.48 - lr: 0.000008
2021-07-15 14:14:27,463 epoch 28 - iter 15/38 - loss 0.17337216 - samples/sec: 61.11 - lr: 0.000008
2021-07-15 14:14:29,006 epoch 28 - iter 18/38 - loss 0.17565345 - samples/sec: 62.22 - lr: 0.000008
2021-07-15 14:14:30,564 epoch 28 - iter 21/38 - loss 0.17723074 - samples/sec: 61.65 - lr: 0.000008
2021-07-15 14:14:32,099 epoch 28 - iter 24/38 - loss 0.17618543 - samples/sec: 62.57 - lr: 0.000008
2021-07-15 14:14:33,630 epoch 28 - iter 27/38 - loss 0.18062393 - samples/sec: 62.72 - lr: 0.000008
2021-07-15 14:14:35,164 epoch 28 - iter 30/38 - loss 0.17813429 - samples/sec: 62.60 - lr: 0.000008
2021-07-15 14:14:36,717 epoch 28 - iter 33/38 - loss 0.17700607 - samples/sec: 61.86 - lr: 0.000008
2021-07-15 14:14:38,282 epoch 28 - iter 36/38 - loss 0.18769714 - samples/sec: 61.34 - lr: 0.000008
2021-07-15 14:14:39,247 ----------------------------------------------------------------------------------------------------
2021-07-15 14:14:39,247 EPOCH 28 done: loss 0.1871 - lr 0.0000075
2021-07-15 14:14:41,172 DEV : loss 0.3837195336818695 - score 0.9339
2021-07-15 14:14:41,197 BAD EPOCHS (no improvement): 3
2021-07-15 14:14:41,197 ----------------------------------------------------------------------------------------------------
2021-07-15 14:14:42,740 epoch 29 - iter 3/38 - loss 0.14735714 - samples/sec: 62.26 - lr: 0.000008
2021-07-15 14:14:44,303 epoch 29 - iter 6/38 - loss 0.13130716 - samples/sec: 61.44 - lr: 0.000008
2021-07-15 14:14:45,859 epoch 29 - iter 9/38 - loss 0.13540696 - samples/sec: 61.73 - lr: 0.000008
2021-07-15 14:14:47,400 epoch 29 - iter 12/38 - loss 0.12929564 - samples/sec: 62.31 - lr: 0.000008
2021-07-15 14:14:48,947 epoch 29 - iter 15/38 - loss 0.14035051 - samples/sec: 62.06 - lr: 0.000008
2021-07-15 14:14:50,488 epoch 29 - iter 18/38 - loss 0.14239441 - samples/sec: 62.33 - lr: 0.000008
2021-07-15 14:14:51,999 epoch 29 - iter 21/38 - loss 0.15316703 - samples/sec: 63.55 - lr: 0.000008
2021-07-15 14:14:53,552 epoch 29 - iter 24/38 - loss 0.15241054 - samples/sec: 61.83 - lr: 0.000008
2021-07-15 14:14:55,108 epoch 29 - iter 27/38 - loss 0.16061977 - samples/sec: 61.71 - lr: 0.000008
2021-07-15 14:14:56,668 epoch 29 - iter 30/38 - loss 0.15697117 - samples/sec: 61.56 - lr: 0.000008
2021-07-15 14:14:58,228 epoch 29 - iter 33/38 - loss 0.16115832 - samples/sec: 61.57 - lr: 0.000008
2021-07-15 14:14:59,787 epoch 29 - iter 36/38 - loss 0.16345680 - samples/sec: 61.60 - lr: 0.000008
2021-07-15 14:15:00,742 ----------------------------------------------------------------------------------------------------
2021-07-15 14:15:00,743 EPOCH 29 done: loss 0.1662 - lr 0.0000075
2021-07-15 14:15:02,816 DEV : loss 0.39063701033592224 - score 0.935
Epoch    29: reducing learning rate of group 0 to 3.7500e-06.
2021-07-15 14:15:02,841 BAD EPOCHS (no improvement): 4
2021-07-15 14:15:02,841 ----------------------------------------------------------------------------------------------------
2021-07-15 14:15:04,395 epoch 30 - iter 3/38 - loss 0.11759448 - samples/sec: 61.80 - lr: 0.000004
2021-07-15 14:15:05,920 epoch 30 - iter 6/38 - loss 0.15465509 - samples/sec: 63.00 - lr: 0.000004
2021-07-15 14:15:07,463 epoch 30 - iter 9/38 - loss 0.19371964 - samples/sec: 62.23 - lr: 0.000004
2021-07-15 14:15:09,043 epoch 30 - iter 12/38 - loss 0.18643334 - samples/sec: 60.76 - lr: 0.000004
2021-07-15 14:15:10,594 epoch 30 - iter 15/38 - loss 0.18164141 - samples/sec: 61.92 - lr: 0.000004
2021-07-15 14:15:12,140 epoch 30 - iter 18/38 - loss 0.18262698 - samples/sec: 62.13 - lr: 0.000004
2021-07-15 14:15:13,700 epoch 30 - iter 21/38 - loss 0.18105924 - samples/sec: 61.57 - lr: 0.000004
2021-07-15 14:15:15,248 epoch 30 - iter 24/38 - loss 0.19358335 - samples/sec: 62.04 - lr: 0.000004
2021-07-15 14:15:16,811 epoch 30 - iter 27/38 - loss 0.19185192 - samples/sec: 61.43 - lr: 0.000004
2021-07-15 14:15:18,351 epoch 30 - iter 30/38 - loss 0.18407787 - samples/sec: 62.35 - lr: 0.000004
2021-07-15 14:15:19,921 epoch 30 - iter 33/38 - loss 0.18397485 - samples/sec: 61.20 - lr: 0.000004
2021-07-15 14:15:21,440 epoch 30 - iter 36/38 - loss 0.18394479 - samples/sec: 63.22 - lr: 0.000004
2021-07-15 14:15:22,391 ----------------------------------------------------------------------------------------------------
2021-07-15 14:15:22,392 EPOCH 30 done: loss 0.1868 - lr 0.0000038
2021-07-15 14:15:24,317 DEV : loss 0.39018985629081726 - score 0.9363
2021-07-15 14:15:24,342 BAD EPOCHS (no improvement): 1
2021-07-15 14:15:24,342 ----------------------------------------------------------------------------------------------------
2021-07-15 14:15:25,851 epoch 31 - iter 3/38 - loss 0.17138603 - samples/sec: 63.63 - lr: 0.000004
2021-07-15 14:15:27,399 epoch 31 - iter 6/38 - loss 0.19252406 - samples/sec: 62.05 - lr: 0.000004
2021-07-15 14:15:28,955 epoch 31 - iter 9/38 - loss 0.16019229 - samples/sec: 61.70 - lr: 0.000004
2021-07-15 14:15:30,512 epoch 31 - iter 12/38 - loss 0.16002340 - samples/sec: 61.69 - lr: 0.000004
2021-07-15 14:15:32,072 epoch 31 - iter 15/38 - loss 0.16460487 - samples/sec: 61.57 - lr: 0.000004
2021-07-15 14:15:33,604 epoch 31 - iter 18/38 - loss 0.16719175 - samples/sec: 62.68 - lr: 0.000004
2021-07-15 14:15:35,132 epoch 31 - iter 21/38 - loss 0.17169110 - samples/sec: 62.86 - lr: 0.000004
2021-07-15 14:15:36,668 epoch 31 - iter 24/38 - loss 0.16771035 - samples/sec: 62.51 - lr: 0.000004
2021-07-15 14:15:38,238 epoch 31 - iter 27/38 - loss 0.17029552 - samples/sec: 61.15 - lr: 0.000004
2021-07-15 14:15:39,819 epoch 31 - iter 30/38 - loss 0.17490455 - samples/sec: 60.74 - lr: 0.000004
2021-07-15 14:15:41,372 epoch 31 - iter 33/38 - loss 0.17238568 - samples/sec: 61.86 - lr: 0.000004
2021-07-15 14:15:42,955 epoch 31 - iter 36/38 - loss 0.17121631 - samples/sec: 60.64 - lr: 0.000004
2021-07-15 14:15:43,907 ----------------------------------------------------------------------------------------------------
2021-07-15 14:15:43,907 EPOCH 31 done: loss 0.1689 - lr 0.0000038
2021-07-15 14:15:45,832 DEV : loss 0.39057835936546326 - score 0.9376
2021-07-15 14:15:45,857 BAD EPOCHS (no improvement): 2
2021-07-15 14:15:45,857 ----------------------------------------------------------------------------------------------------
2021-07-15 14:15:47,420 epoch 32 - iter 3/38 - loss 0.17930790 - samples/sec: 61.44 - lr: 0.000004
2021-07-15 14:15:48,995 epoch 32 - iter 6/38 - loss 0.22382834 - samples/sec: 60.97 - lr: 0.000004
2021-07-15 14:15:50,531 epoch 32 - iter 9/38 - loss 0.20705190 - samples/sec: 62.52 - lr: 0.000004
2021-07-15 14:15:52,087 epoch 32 - iter 12/38 - loss 0.21330913 - samples/sec: 61.73 - lr: 0.000004
2021-07-15 14:15:53,639 epoch 32 - iter 15/38 - loss 0.21264314 - samples/sec: 61.86 - lr: 0.000004
2021-07-15 14:15:55,186 epoch 32 - iter 18/38 - loss 0.19786432 - samples/sec: 62.09 - lr: 0.000004
2021-07-15 14:15:56,723 epoch 32 - iter 21/38 - loss 0.19289032 - samples/sec: 62.47 - lr: 0.000004
2021-07-15 14:15:58,305 epoch 32 - iter 24/38 - loss 0.19564828 - samples/sec: 60.72 - lr: 0.000004
2021-07-15 14:15:59,855 epoch 32 - iter 27/38 - loss 0.19870313 - samples/sec: 61.95 - lr: 0.000004
2021-07-15 14:16:01,374 epoch 32 - iter 30/38 - loss 0.19226770 - samples/sec: 63.20 - lr: 0.000004
2021-07-15 14:16:02,903 epoch 32 - iter 33/38 - loss 0.19078584 - samples/sec: 62.81 - lr: 0.000004
2021-07-15 14:16:04,459 epoch 32 - iter 36/38 - loss 0.18679077 - samples/sec: 61.73 - lr: 0.000004
2021-07-15 14:16:05,408 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:05,408 EPOCH 32 done: loss 0.1892 - lr 0.0000038
2021-07-15 14:16:07,332 DEV : loss 0.38481491804122925 - score 0.9368
2021-07-15 14:16:07,356 BAD EPOCHS (no improvement): 3
2021-07-15 14:16:07,356 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:08,890 epoch 33 - iter 3/38 - loss 0.23865612 - samples/sec: 62.61 - lr: 0.000004
2021-07-15 14:16:10,424 epoch 33 - iter 6/38 - loss 0.17680582 - samples/sec: 62.63 - lr: 0.000004
2021-07-15 14:16:11,969 epoch 33 - iter 9/38 - loss 0.19254054 - samples/sec: 62.13 - lr: 0.000004
2021-07-15 14:16:13,522 epoch 33 - iter 12/38 - loss 0.17708326 - samples/sec: 61.84 - lr: 0.000004
2021-07-15 14:16:15,083 epoch 33 - iter 15/38 - loss 0.17246940 - samples/sec: 61.54 - lr: 0.000004
2021-07-15 14:16:16,632 epoch 33 - iter 18/38 - loss 0.16703373 - samples/sec: 61.98 - lr: 0.000004
2021-07-15 14:16:18,195 epoch 33 - iter 21/38 - loss 0.16423776 - samples/sec: 61.43 - lr: 0.000004
2021-07-15 14:16:19,733 epoch 33 - iter 24/38 - loss 0.16523445 - samples/sec: 62.44 - lr: 0.000004
2021-07-15 14:16:21,285 epoch 33 - iter 27/38 - loss 0.16738662 - samples/sec: 61.90 - lr: 0.000004
2021-07-15 14:16:22,822 epoch 33 - iter 30/38 - loss 0.16824643 - samples/sec: 62.44 - lr: 0.000004
2021-07-15 14:16:24,390 epoch 33 - iter 33/38 - loss 0.16653272 - samples/sec: 61.28 - lr: 0.000004
2021-07-15 14:16:25,956 epoch 33 - iter 36/38 - loss 0.16545434 - samples/sec: 61.32 - lr: 0.000004
2021-07-15 14:16:26,920 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:26,920 EPOCH 33 done: loss 0.1657 - lr 0.0000038
2021-07-15 14:16:28,986 DEV : loss 0.38376471400260925 - score 0.9366
Epoch    33: reducing learning rate of group 0 to 1.8750e-06.
2021-07-15 14:16:29,011 BAD EPOCHS (no improvement): 4
2021-07-15 14:16:29,011 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:29,011 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:29,011 learning rate too small - quitting training!
2021-07-15 14:16:29,011 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:29,524 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:29,524 Testing using best model ...
2021-07-15 14:16:29,525 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eus.rst.ert/best-model.pt
2021-07-15 14:16:34,242 0.9766	0.9305	0.9530
2021-07-15 14:16:34,242 
Results:
- F1-score (micro) 0.9530
- F1-score (macro) 0.4771

By class:
.          tp: 0 - fp: 0 - fn: 1 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000
SENT       tp: 375 - fp: 9 - fn: 27 - precision: 0.9766 - recall: 0.9328 - f1-score: 0.9542
2021-07-15 14:16:34,242 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.pdtb.pdtb/
2021-07-15 14:16:34,256 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.pdtb.pdtb
2021-07-15 14:16:34,258 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.pdtb.pdtb/sent_train.txt
2021-07-15 14:16:34,259 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.pdtb.pdtb/sent_dev.txt
2021-07-15 14:16:34,261 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.pdtb.pdtb/sent_test.txt
Corpus: 38539 train + 1929 dev + 12942 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 14:16:55,460 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:55,461 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 14:16:55,461 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:55,461 Corpus: "Corpus: 38539 train + 1929 dev + 12942 test sentences"
2021-07-15 14:16:55,461 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:55,461 Parameters:
2021-07-15 14:16:55,461  - learning_rate: "3e-05"
2021-07-15 14:16:55,461  - mini_batch_size: "32"
2021-07-15 14:16:55,462  - patience: "3"
2021-07-15 14:16:55,462  - anneal_factor: "0.5"
2021-07-15 14:16:55,462  - max_epochs: "40"
2021-07-15 14:16:55,462  - shuffle: "True"
2021-07-15 14:16:55,462  - train_with_dev: "False"
2021-07-15 14:16:55,462  - batch_growth_annealing: "False"
2021-07-15 14:16:55,462 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:55,462 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.pdtb.pdtb"
2021-07-15 14:16:55,462 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:55,462 Device: cuda:0
2021-07-15 14:16:55,462 ----------------------------------------------------------------------------------------------------
2021-07-15 14:16:55,462 Embeddings storage mode: cpu
2021-07-15 14:16:55,464 ----------------------------------------------------------------------------------------------------
2021-07-15 14:18:54,752 epoch 1 - iter 120/1205 - loss 2.31672154 - samples/sec: 32.19 - lr: 0.000030
2021-07-15 14:20:51,842 epoch 1 - iter 240/1205 - loss 1.47361127 - samples/sec: 32.80 - lr: 0.000030
2021-07-15 14:22:49,162 epoch 1 - iter 360/1205 - loss 1.14274326 - samples/sec: 32.73 - lr: 0.000030
2021-07-15 14:24:46,823 epoch 1 - iter 480/1205 - loss 0.94857032 - samples/sec: 32.64 - lr: 0.000030
2021-07-15 14:26:44,622 epoch 1 - iter 600/1205 - loss 0.83231210 - samples/sec: 32.60 - lr: 0.000030
2021-07-15 14:28:42,606 epoch 1 - iter 720/1205 - loss 0.74845129 - samples/sec: 32.55 - lr: 0.000030
2021-07-15 14:30:40,340 epoch 1 - iter 840/1205 - loss 0.68521935 - samples/sec: 32.62 - lr: 0.000030
2021-07-15 14:32:38,208 epoch 1 - iter 960/1205 - loss 0.63473094 - samples/sec: 32.58 - lr: 0.000030
2021-07-15 14:34:38,688 epoch 1 - iter 1080/1205 - loss 0.59294621 - samples/sec: 31.87 - lr: 0.000030
2021-07-15 14:36:36,991 epoch 1 - iter 1200/1205 - loss 0.56147560 - samples/sec: 32.46 - lr: 0.000030
2021-07-15 14:36:41,299 ----------------------------------------------------------------------------------------------------
2021-07-15 14:36:41,299 EPOCH 1 done: loss 0.5600 - lr 0.0000300
2021-07-15 14:37:16,709 DEV : loss 0.17216810584068298 - score 0.9606
2021-07-15 14:37:16,843 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:37:17,671 ----------------------------------------------------------------------------------------------------
2021-07-15 14:38:18,422 epoch 2 - iter 120/1205 - loss 0.24176573 - samples/sec: 63.22 - lr: 0.000030
2021-07-15 14:39:19,132 epoch 2 - iter 240/1205 - loss 0.25145225 - samples/sec: 63.26 - lr: 0.000030
2021-07-15 14:40:19,735 epoch 2 - iter 360/1205 - loss 0.25159842 - samples/sec: 63.37 - lr: 0.000030
2021-07-15 14:41:20,408 epoch 2 - iter 480/1205 - loss 0.24725558 - samples/sec: 63.30 - lr: 0.000030
2021-07-15 14:42:21,009 epoch 2 - iter 600/1205 - loss 0.24491343 - samples/sec: 63.37 - lr: 0.000030
2021-07-15 14:43:21,635 epoch 2 - iter 720/1205 - loss 0.24320450 - samples/sec: 63.35 - lr: 0.000030
2021-07-15 14:44:22,182 epoch 2 - iter 840/1205 - loss 0.23986022 - samples/sec: 63.43 - lr: 0.000030
2021-07-15 14:45:22,890 epoch 2 - iter 960/1205 - loss 0.23717635 - samples/sec: 63.26 - lr: 0.000030
2021-07-15 14:46:23,637 epoch 2 - iter 1080/1205 - loss 0.23470170 - samples/sec: 63.22 - lr: 0.000030
2021-07-15 14:47:24,327 epoch 2 - iter 1200/1205 - loss 0.23106517 - samples/sec: 63.28 - lr: 0.000030
2021-07-15 14:47:26,568 ----------------------------------------------------------------------------------------------------
2021-07-15 14:47:26,568 EPOCH 2 done: loss 0.2313 - lr 0.0000300
2021-07-15 14:47:36,808 DEV : loss 0.14933085441589355 - score 0.9661
2021-07-15 14:47:36,940 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:47:40,599 ----------------------------------------------------------------------------------------------------
2021-07-15 14:48:41,798 epoch 3 - iter 120/1205 - loss 0.18086627 - samples/sec: 62.76 - lr: 0.000030
2021-07-15 14:49:42,284 epoch 3 - iter 240/1205 - loss 0.18895039 - samples/sec: 63.49 - lr: 0.000030
2021-07-15 14:50:43,411 epoch 3 - iter 360/1205 - loss 0.19612828 - samples/sec: 62.83 - lr: 0.000030
2021-07-15 14:51:44,428 epoch 3 - iter 480/1205 - loss 0.19804113 - samples/sec: 62.94 - lr: 0.000030
2021-07-15 14:52:45,428 epoch 3 - iter 600/1205 - loss 0.19740250 - samples/sec: 62.96 - lr: 0.000030
2021-07-15 14:53:46,459 epoch 3 - iter 720/1205 - loss 0.19715064 - samples/sec: 62.93 - lr: 0.000030
2021-07-15 14:54:47,491 epoch 3 - iter 840/1205 - loss 0.19651432 - samples/sec: 62.92 - lr: 0.000030
2021-07-15 14:55:48,467 epoch 3 - iter 960/1205 - loss 0.19513592 - samples/sec: 62.98 - lr: 0.000030
2021-07-15 14:56:49,480 epoch 3 - iter 1080/1205 - loss 0.19502647 - samples/sec: 62.94 - lr: 0.000030
2021-07-15 14:57:51,088 epoch 3 - iter 1200/1205 - loss 0.19529634 - samples/sec: 62.34 - lr: 0.000030
2021-07-15 14:57:53,358 ----------------------------------------------------------------------------------------------------
2021-07-15 14:57:53,358 EPOCH 3 done: loss 0.1949 - lr 0.0000300
2021-07-15 14:58:03,628 DEV : loss 0.1360023021697998 - score 0.9692
2021-07-15 14:58:03,763 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 14:58:07,492 ----------------------------------------------------------------------------------------------------
2021-07-15 14:59:08,836 epoch 4 - iter 120/1205 - loss 0.18528732 - samples/sec: 62.61 - lr: 0.000030
2021-07-15 15:00:10,272 epoch 4 - iter 240/1205 - loss 0.18932809 - samples/sec: 62.51 - lr: 0.000030
2021-07-15 15:01:11,752 epoch 4 - iter 360/1205 - loss 0.19133420 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 15:02:12,124 epoch 4 - iter 480/1205 - loss 0.18475973 - samples/sec: 63.61 - lr: 0.000030
2021-07-15 15:03:13,109 epoch 4 - iter 600/1205 - loss 0.18548040 - samples/sec: 62.97 - lr: 0.000030
2021-07-15 15:04:14,175 epoch 4 - iter 720/1205 - loss 0.18221510 - samples/sec: 62.89 - lr: 0.000030
2021-07-15 15:05:15,008 epoch 4 - iter 840/1205 - loss 0.18160135 - samples/sec: 63.13 - lr: 0.000030
2021-07-15 15:06:15,979 epoch 4 - iter 960/1205 - loss 0.18070231 - samples/sec: 62.99 - lr: 0.000030
2021-07-15 15:07:17,148 epoch 4 - iter 1080/1205 - loss 0.17874498 - samples/sec: 62.78 - lr: 0.000030
2021-07-15 15:08:18,617 epoch 4 - iter 1200/1205 - loss 0.17652296 - samples/sec: 62.48 - lr: 0.000030
2021-07-15 15:08:20,897 ----------------------------------------------------------------------------------------------------
2021-07-15 15:08:20,897 EPOCH 4 done: loss 0.1763 - lr 0.0000300
2021-07-15 15:08:31,173 DEV : loss 0.13255447149276733 - score 0.9692
2021-07-15 15:08:31,307 BAD EPOCHS (no improvement): 1
2021-07-15 15:08:31,307 ----------------------------------------------------------------------------------------------------
2021-07-15 15:09:33,072 epoch 5 - iter 120/1205 - loss 0.15627765 - samples/sec: 62.18 - lr: 0.000030
2021-07-15 15:10:34,748 epoch 5 - iter 240/1205 - loss 0.15137060 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 15:11:36,021 epoch 5 - iter 360/1205 - loss 0.15445410 - samples/sec: 62.68 - lr: 0.000030
2021-07-15 15:12:37,789 epoch 5 - iter 480/1205 - loss 0.15789144 - samples/sec: 62.17 - lr: 0.000030
2021-07-15 15:13:41,730 epoch 5 - iter 600/1205 - loss 0.15783830 - samples/sec: 60.06 - lr: 0.000030
2021-07-15 15:14:42,992 epoch 5 - iter 720/1205 - loss 0.16053149 - samples/sec: 62.69 - lr: 0.000030
2021-07-15 15:15:44,184 epoch 5 - iter 840/1205 - loss 0.15957090 - samples/sec: 62.76 - lr: 0.000030
2021-07-15 15:16:45,489 epoch 5 - iter 960/1205 - loss 0.16033173 - samples/sec: 62.64 - lr: 0.000030
2021-07-15 15:17:47,165 epoch 5 - iter 1080/1205 - loss 0.15846322 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 15:18:48,887 epoch 5 - iter 1200/1205 - loss 0.15926963 - samples/sec: 62.22 - lr: 0.000030
2021-07-15 15:18:51,182 ----------------------------------------------------------------------------------------------------
2021-07-15 15:18:51,182 EPOCH 5 done: loss 0.1592 - lr 0.0000300
2021-07-15 15:19:01,456 DEV : loss 0.1274081915616989 - score 0.9709
2021-07-15 15:19:01,590 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 15:19:05,418 ----------------------------------------------------------------------------------------------------
2021-07-15 15:20:07,055 epoch 6 - iter 120/1205 - loss 0.15884377 - samples/sec: 62.31 - lr: 0.000030
2021-07-15 15:21:08,549 epoch 6 - iter 240/1205 - loss 0.15427096 - samples/sec: 62.45 - lr: 0.000030
2021-07-15 15:22:09,953 epoch 6 - iter 360/1205 - loss 0.15147102 - samples/sec: 62.54 - lr: 0.000030
2021-07-15 15:23:11,181 epoch 6 - iter 480/1205 - loss 0.14829108 - samples/sec: 62.72 - lr: 0.000030
2021-07-15 15:24:12,880 epoch 6 - iter 600/1205 - loss 0.14709664 - samples/sec: 62.24 - lr: 0.000030
2021-07-15 15:25:14,628 epoch 6 - iter 720/1205 - loss 0.14360500 - samples/sec: 62.19 - lr: 0.000030
2021-07-15 15:26:15,969 epoch 6 - iter 840/1205 - loss 0.14327491 - samples/sec: 62.61 - lr: 0.000030
2021-07-15 15:27:17,340 epoch 6 - iter 960/1205 - loss 0.14552746 - samples/sec: 62.58 - lr: 0.000030
2021-07-15 15:28:18,809 epoch 6 - iter 1080/1205 - loss 0.14632465 - samples/sec: 62.48 - lr: 0.000030
2021-07-15 15:29:19,995 epoch 6 - iter 1200/1205 - loss 0.14646466 - samples/sec: 62.76 - lr: 0.000030
2021-07-15 15:29:22,266 ----------------------------------------------------------------------------------------------------
2021-07-15 15:29:22,266 EPOCH 6 done: loss 0.1461 - lr 0.0000300
2021-07-15 15:29:32,551 DEV : loss 0.12224787473678589 - score 0.9717
2021-07-15 15:29:32,687 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 15:29:36,520 ----------------------------------------------------------------------------------------------------
2021-07-15 15:30:37,776 epoch 7 - iter 120/1205 - loss 0.12680689 - samples/sec: 62.70 - lr: 0.000030
2021-07-15 15:31:38,960 epoch 7 - iter 240/1205 - loss 0.12985312 - samples/sec: 62.77 - lr: 0.000030
2021-07-15 15:32:40,509 epoch 7 - iter 360/1205 - loss 0.13180968 - samples/sec: 62.39 - lr: 0.000030
2021-07-15 15:33:41,915 epoch 7 - iter 480/1205 - loss 0.13273242 - samples/sec: 62.54 - lr: 0.000030
2021-07-15 15:34:43,641 epoch 7 - iter 600/1205 - loss 0.13492456 - samples/sec: 62.22 - lr: 0.000030
2021-07-15 15:35:45,400 epoch 7 - iter 720/1205 - loss 0.13452150 - samples/sec: 62.18 - lr: 0.000030
2021-07-15 15:36:47,164 epoch 7 - iter 840/1205 - loss 0.13639554 - samples/sec: 62.18 - lr: 0.000030
2021-07-15 15:37:48,920 epoch 7 - iter 960/1205 - loss 0.13706654 - samples/sec: 62.19 - lr: 0.000030
2021-07-15 15:38:50,495 epoch 7 - iter 1080/1205 - loss 0.13952222 - samples/sec: 62.37 - lr: 0.000030
2021-07-15 15:39:52,168 epoch 7 - iter 1200/1205 - loss 0.13844391 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 15:39:54,386 ----------------------------------------------------------------------------------------------------
2021-07-15 15:39:54,386 EPOCH 7 done: loss 0.1383 - lr 0.0000300
2021-07-15 15:40:04,676 DEV : loss 0.11719770729541779 - score 0.9724
2021-07-15 15:40:04,809 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 15:40:08,441 ----------------------------------------------------------------------------------------------------
2021-07-15 15:41:09,868 epoch 8 - iter 120/1205 - loss 0.13082829 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 15:42:11,512 epoch 8 - iter 240/1205 - loss 0.12905722 - samples/sec: 62.30 - lr: 0.000030
2021-07-15 15:43:12,941 epoch 8 - iter 360/1205 - loss 0.12846983 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 15:44:14,272 epoch 8 - iter 480/1205 - loss 0.13196118 - samples/sec: 62.62 - lr: 0.000030
2021-07-15 15:45:15,949 epoch 8 - iter 600/1205 - loss 0.13003187 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 15:46:17,536 epoch 8 - iter 720/1205 - loss 0.13034459 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 15:47:19,240 epoch 8 - iter 840/1205 - loss 0.13008792 - samples/sec: 62.24 - lr: 0.000030
2021-07-15 15:48:20,712 epoch 8 - iter 960/1205 - loss 0.12865530 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 15:49:21,597 epoch 8 - iter 1080/1205 - loss 0.12763615 - samples/sec: 63.08 - lr: 0.000030
2021-07-15 15:50:22,276 epoch 8 - iter 1200/1205 - loss 0.12840052 - samples/sec: 63.29 - lr: 0.000030
2021-07-15 15:50:24,527 ----------------------------------------------------------------------------------------------------
2021-07-15 15:50:24,528 EPOCH 8 done: loss 0.1284 - lr 0.0000300
2021-07-15 15:50:34,817 DEV : loss 0.11453527212142944 - score 0.9748
2021-07-15 15:50:34,951 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 15:50:38,671 ----------------------------------------------------------------------------------------------------
2021-07-15 15:51:40,159 epoch 9 - iter 120/1205 - loss 0.11518824 - samples/sec: 62.46 - lr: 0.000030
2021-07-15 15:52:41,781 epoch 9 - iter 240/1205 - loss 0.11852059 - samples/sec: 62.32 - lr: 0.000030
2021-07-15 15:53:43,272 epoch 9 - iter 360/1205 - loss 0.11551511 - samples/sec: 62.45 - lr: 0.000030
2021-07-15 15:54:44,739 epoch 9 - iter 480/1205 - loss 0.11240694 - samples/sec: 62.48 - lr: 0.000030
2021-07-15 15:55:46,325 epoch 9 - iter 600/1205 - loss 0.11557046 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 15:56:47,920 epoch 9 - iter 720/1205 - loss 0.11533167 - samples/sec: 62.35 - lr: 0.000030
2021-07-15 15:57:49,500 epoch 9 - iter 840/1205 - loss 0.11723935 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 15:58:50,155 epoch 9 - iter 960/1205 - loss 0.11799170 - samples/sec: 63.31 - lr: 0.000030
2021-07-15 15:59:50,750 epoch 9 - iter 1080/1205 - loss 0.11838341 - samples/sec: 63.38 - lr: 0.000030
2021-07-15 16:00:51,226 epoch 9 - iter 1200/1205 - loss 0.11949913 - samples/sec: 63.50 - lr: 0.000030
2021-07-15 16:00:53,421 ----------------------------------------------------------------------------------------------------
2021-07-15 16:00:53,421 EPOCH 9 done: loss 0.1198 - lr 0.0000300
2021-07-15 16:01:03,731 DEV : loss 0.11735425889492035 - score 0.9725
2021-07-15 16:01:03,867 BAD EPOCHS (no improvement): 1
2021-07-15 16:01:03,867 ----------------------------------------------------------------------------------------------------
2021-07-15 16:02:04,400 epoch 10 - iter 120/1205 - loss 0.12350146 - samples/sec: 63.44 - lr: 0.000030
2021-07-15 16:03:05,236 epoch 10 - iter 240/1205 - loss 0.11668533 - samples/sec: 63.13 - lr: 0.000030
2021-07-15 16:04:06,154 epoch 10 - iter 360/1205 - loss 0.11401624 - samples/sec: 63.04 - lr: 0.000030
2021-07-15 16:05:07,330 epoch 10 - iter 480/1205 - loss 0.11193993 - samples/sec: 62.78 - lr: 0.000030
2021-07-15 16:06:08,294 epoch 10 - iter 600/1205 - loss 0.11588869 - samples/sec: 62.99 - lr: 0.000030
2021-07-15 16:07:09,220 epoch 10 - iter 720/1205 - loss 0.11522448 - samples/sec: 63.03 - lr: 0.000030
2021-07-15 16:08:10,282 epoch 10 - iter 840/1205 - loss 0.11472430 - samples/sec: 62.89 - lr: 0.000030
2021-07-15 16:09:11,300 epoch 10 - iter 960/1205 - loss 0.11613780 - samples/sec: 62.94 - lr: 0.000030
2021-07-15 16:10:12,101 epoch 10 - iter 1080/1205 - loss 0.11555025 - samples/sec: 63.16 - lr: 0.000030
2021-07-15 16:11:13,118 epoch 10 - iter 1200/1205 - loss 0.11654655 - samples/sec: 62.94 - lr: 0.000030
2021-07-15 16:11:15,360 ----------------------------------------------------------------------------------------------------
2021-07-15 16:11:15,360 EPOCH 10 done: loss 0.1167 - lr 0.0000300
2021-07-15 16:11:25,689 DEV : loss 0.11453037708997726 - score 0.9742
2021-07-15 16:11:25,821 BAD EPOCHS (no improvement): 2
2021-07-15 16:11:25,822 ----------------------------------------------------------------------------------------------------
2021-07-15 16:12:29,438 epoch 11 - iter 120/1205 - loss 0.10774844 - samples/sec: 60.37 - lr: 0.000030
2021-07-15 16:13:30,341 epoch 11 - iter 240/1205 - loss 0.11219462 - samples/sec: 63.06 - lr: 0.000030
2021-07-15 16:14:31,294 epoch 11 - iter 360/1205 - loss 0.10807532 - samples/sec: 63.01 - lr: 0.000030
2021-07-15 16:15:32,314 epoch 11 - iter 480/1205 - loss 0.10641146 - samples/sec: 62.94 - lr: 0.000030
2021-07-15 16:16:33,380 epoch 11 - iter 600/1205 - loss 0.10663088 - samples/sec: 62.89 - lr: 0.000030
2021-07-15 16:17:34,255 epoch 11 - iter 720/1205 - loss 0.10914710 - samples/sec: 63.09 - lr: 0.000030
2021-07-15 16:18:35,186 epoch 11 - iter 840/1205 - loss 0.10864369 - samples/sec: 63.03 - lr: 0.000030
2021-07-15 16:19:36,294 epoch 11 - iter 960/1205 - loss 0.10994644 - samples/sec: 62.85 - lr: 0.000030
2021-07-15 16:20:37,469 epoch 11 - iter 1080/1205 - loss 0.10918483 - samples/sec: 62.78 - lr: 0.000030
2021-07-15 16:21:38,994 epoch 11 - iter 1200/1205 - loss 0.10847253 - samples/sec: 62.42 - lr: 0.000030
2021-07-15 16:21:41,248 ----------------------------------------------------------------------------------------------------
2021-07-15 16:21:41,249 EPOCH 11 done: loss 0.1084 - lr 0.0000300
2021-07-15 16:21:51,552 DEV : loss 0.11223866790533066 - score 0.9746
2021-07-15 16:21:51,686 BAD EPOCHS (no improvement): 3
2021-07-15 16:21:51,686 ----------------------------------------------------------------------------------------------------
2021-07-15 16:22:53,417 epoch 12 - iter 120/1205 - loss 0.10246416 - samples/sec: 62.21 - lr: 0.000030
2021-07-15 16:23:54,890 epoch 12 - iter 240/1205 - loss 0.10346080 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 16:24:56,457 epoch 12 - iter 360/1205 - loss 0.10053978 - samples/sec: 62.38 - lr: 0.000030
2021-07-15 16:25:58,032 epoch 12 - iter 480/1205 - loss 0.09949246 - samples/sec: 62.37 - lr: 0.000030
2021-07-15 16:26:59,581 epoch 12 - iter 600/1205 - loss 0.10024945 - samples/sec: 62.40 - lr: 0.000030
2021-07-15 16:28:01,082 epoch 12 - iter 720/1205 - loss 0.10124257 - samples/sec: 62.44 - lr: 0.000030
2021-07-15 16:29:02,667 epoch 12 - iter 840/1205 - loss 0.10240867 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 16:30:03,558 epoch 12 - iter 960/1205 - loss 0.10360465 - samples/sec: 63.07 - lr: 0.000030
2021-07-15 16:31:05,094 epoch 12 - iter 1080/1205 - loss 0.10200331 - samples/sec: 62.41 - lr: 0.000030
2021-07-15 16:32:06,571 epoch 12 - iter 1200/1205 - loss 0.10129697 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 16:32:08,813 ----------------------------------------------------------------------------------------------------
2021-07-15 16:32:08,814 EPOCH 12 done: loss 0.1013 - lr 0.0000300
2021-07-15 16:32:19,122 DEV : loss 0.11200913041830063 - score 0.9763
2021-07-15 16:32:19,257 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 16:32:22,995 ----------------------------------------------------------------------------------------------------
2021-07-15 16:33:24,467 epoch 13 - iter 120/1205 - loss 0.08990857 - samples/sec: 62.48 - lr: 0.000030
2021-07-15 16:34:26,037 epoch 13 - iter 240/1205 - loss 0.09186506 - samples/sec: 62.37 - lr: 0.000030
2021-07-15 16:35:27,565 epoch 13 - iter 360/1205 - loss 0.09320748 - samples/sec: 62.42 - lr: 0.000030
2021-07-15 16:36:29,059 epoch 13 - iter 480/1205 - loss 0.09424661 - samples/sec: 62.45 - lr: 0.000030
2021-07-15 16:37:30,374 epoch 13 - iter 600/1205 - loss 0.09383511 - samples/sec: 62.63 - lr: 0.000030
2021-07-15 16:38:32,026 epoch 13 - iter 720/1205 - loss 0.09573844 - samples/sec: 62.29 - lr: 0.000030
2021-07-15 16:39:33,486 epoch 13 - iter 840/1205 - loss 0.09658513 - samples/sec: 62.49 - lr: 0.000030
2021-07-15 16:40:34,991 epoch 13 - iter 960/1205 - loss 0.09636191 - samples/sec: 62.44 - lr: 0.000030
2021-07-15 16:41:36,506 epoch 13 - iter 1080/1205 - loss 0.09711364 - samples/sec: 62.43 - lr: 0.000030
2021-07-15 16:42:38,182 epoch 13 - iter 1200/1205 - loss 0.09824126 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 16:42:40,437 ----------------------------------------------------------------------------------------------------
2021-07-15 16:42:40,437 EPOCH 13 done: loss 0.0980 - lr 0.0000300
2021-07-15 16:42:50,750 DEV : loss 0.10957037657499313 - score 0.976
2021-07-15 16:42:50,887 BAD EPOCHS (no improvement): 1
2021-07-15 16:42:50,888 ----------------------------------------------------------------------------------------------------
2021-07-15 16:43:52,266 epoch 14 - iter 120/1205 - loss 0.09123509 - samples/sec: 62.57 - lr: 0.000030
2021-07-15 16:44:53,504 epoch 14 - iter 240/1205 - loss 0.09139399 - samples/sec: 62.71 - lr: 0.000030
2021-07-15 16:45:54,475 epoch 14 - iter 360/1205 - loss 0.09482552 - samples/sec: 62.99 - lr: 0.000030
2021-07-15 16:46:55,740 epoch 14 - iter 480/1205 - loss 0.09266520 - samples/sec: 62.68 - lr: 0.000030
2021-07-15 16:47:56,848 epoch 14 - iter 600/1205 - loss 0.09555592 - samples/sec: 62.85 - lr: 0.000030
2021-07-15 16:48:57,646 epoch 14 - iter 720/1205 - loss 0.09657469 - samples/sec: 63.17 - lr: 0.000030
2021-07-15 16:49:59,121 epoch 14 - iter 840/1205 - loss 0.09633924 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 16:51:00,652 epoch 14 - iter 960/1205 - loss 0.09634229 - samples/sec: 62.41 - lr: 0.000030
2021-07-15 16:52:02,254 epoch 14 - iter 1080/1205 - loss 0.09476954 - samples/sec: 62.34 - lr: 0.000030
2021-07-15 16:53:03,767 epoch 14 - iter 1200/1205 - loss 0.09432837 - samples/sec: 62.43 - lr: 0.000030
2021-07-15 16:53:06,023 ----------------------------------------------------------------------------------------------------
2021-07-15 16:53:06,023 EPOCH 14 done: loss 0.0944 - lr 0.0000300
2021-07-15 16:53:16,350 DEV : loss 0.11358316987752914 - score 0.9736
2021-07-15 16:53:16,487 BAD EPOCHS (no improvement): 2
2021-07-15 16:53:16,487 ----------------------------------------------------------------------------------------------------
2021-07-15 16:54:18,007 epoch 15 - iter 120/1205 - loss 0.09455510 - samples/sec: 62.43 - lr: 0.000030
2021-07-15 16:55:19,647 epoch 15 - iter 240/1205 - loss 0.08940996 - samples/sec: 62.30 - lr: 0.000030
2021-07-15 16:56:21,300 epoch 15 - iter 360/1205 - loss 0.08644361 - samples/sec: 62.29 - lr: 0.000030
2021-07-15 16:57:22,982 epoch 15 - iter 480/1205 - loss 0.08508436 - samples/sec: 62.26 - lr: 0.000030
2021-07-15 16:58:24,727 epoch 15 - iter 600/1205 - loss 0.08585605 - samples/sec: 62.20 - lr: 0.000030
2021-07-15 16:59:26,338 epoch 15 - iter 720/1205 - loss 0.08637068 - samples/sec: 62.33 - lr: 0.000030
2021-07-15 17:00:27,926 epoch 15 - iter 840/1205 - loss 0.08648177 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 17:01:29,398 epoch 15 - iter 960/1205 - loss 0.08687047 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 17:02:30,957 epoch 15 - iter 1080/1205 - loss 0.08752128 - samples/sec: 62.39 - lr: 0.000030
2021-07-15 17:03:32,587 epoch 15 - iter 1200/1205 - loss 0.08722544 - samples/sec: 62.31 - lr: 0.000030
2021-07-15 17:03:34,824 ----------------------------------------------------------------------------------------------------
2021-07-15 17:03:34,825 EPOCH 15 done: loss 0.0876 - lr 0.0000300
2021-07-15 17:03:45,149 DEV : loss 0.11311821639537811 - score 0.9763
2021-07-15 17:03:45,284 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 17:03:49,055 ----------------------------------------------------------------------------------------------------
2021-07-15 17:04:50,257 epoch 16 - iter 120/1205 - loss 0.09120920 - samples/sec: 62.75 - lr: 0.000030
2021-07-15 17:05:51,831 epoch 16 - iter 240/1205 - loss 0.08281944 - samples/sec: 62.37 - lr: 0.000030
2021-07-15 17:06:53,516 epoch 16 - iter 360/1205 - loss 0.08387800 - samples/sec: 62.26 - lr: 0.000030
2021-07-15 17:07:54,829 epoch 16 - iter 480/1205 - loss 0.08341925 - samples/sec: 62.64 - lr: 0.000030
2021-07-15 17:08:56,310 epoch 16 - iter 600/1205 - loss 0.08637352 - samples/sec: 62.46 - lr: 0.000030
2021-07-15 17:09:57,952 epoch 16 - iter 720/1205 - loss 0.08365661 - samples/sec: 62.30 - lr: 0.000030
2021-07-15 17:10:58,794 epoch 16 - iter 840/1205 - loss 0.08265555 - samples/sec: 63.12 - lr: 0.000030
2021-07-15 17:11:59,973 epoch 16 - iter 960/1205 - loss 0.08257517 - samples/sec: 62.77 - lr: 0.000030
2021-07-15 17:13:01,173 epoch 16 - iter 1080/1205 - loss 0.08413562 - samples/sec: 62.75 - lr: 0.000030
2021-07-15 17:14:02,361 epoch 16 - iter 1200/1205 - loss 0.08425279 - samples/sec: 62.76 - lr: 0.000030
2021-07-15 17:14:04,631 ----------------------------------------------------------------------------------------------------
2021-07-15 17:14:04,631 EPOCH 16 done: loss 0.0845 - lr 0.0000300
2021-07-15 17:14:17,626 DEV : loss 0.10917496681213379 - score 0.9751
2021-07-15 17:14:17,760 BAD EPOCHS (no improvement): 1
2021-07-15 17:14:17,761 ----------------------------------------------------------------------------------------------------
2021-07-15 17:15:19,193 epoch 17 - iter 120/1205 - loss 0.08490051 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 17:16:20,689 epoch 17 - iter 240/1205 - loss 0.08446273 - samples/sec: 62.45 - lr: 0.000030
2021-07-15 17:17:22,118 epoch 17 - iter 360/1205 - loss 0.08463983 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 17:18:23,717 epoch 17 - iter 480/1205 - loss 0.08677929 - samples/sec: 62.35 - lr: 0.000030
2021-07-15 17:19:25,353 epoch 17 - iter 600/1205 - loss 0.08427647 - samples/sec: 62.31 - lr: 0.000030
2021-07-15 17:20:26,664 epoch 17 - iter 720/1205 - loss 0.08429214 - samples/sec: 62.64 - lr: 0.000030
2021-07-15 17:21:27,589 epoch 17 - iter 840/1205 - loss 0.08244773 - samples/sec: 63.03 - lr: 0.000030
2021-07-15 17:22:29,281 epoch 17 - iter 960/1205 - loss 0.08274260 - samples/sec: 62.25 - lr: 0.000030
2021-07-15 17:23:30,814 epoch 17 - iter 1080/1205 - loss 0.08143321 - samples/sec: 62.41 - lr: 0.000030
2021-07-15 17:24:32,296 epoch 17 - iter 1200/1205 - loss 0.08151991 - samples/sec: 62.46 - lr: 0.000030
2021-07-15 17:24:34,576 ----------------------------------------------------------------------------------------------------
2021-07-15 17:24:34,577 EPOCH 17 done: loss 0.0814 - lr 0.0000300
2021-07-15 17:24:44,914 DEV : loss 0.10732082277536392 - score 0.9754
2021-07-15 17:24:45,050 BAD EPOCHS (no improvement): 2
2021-07-15 17:24:45,050 ----------------------------------------------------------------------------------------------------
2021-07-15 17:25:46,614 epoch 18 - iter 120/1205 - loss 0.07882002 - samples/sec: 62.38 - lr: 0.000030
2021-07-15 17:26:48,310 epoch 18 - iter 240/1205 - loss 0.07092417 - samples/sec: 62.25 - lr: 0.000030
2021-07-15 17:27:49,379 epoch 18 - iter 360/1205 - loss 0.07181892 - samples/sec: 62.89 - lr: 0.000030
2021-07-15 17:28:50,266 epoch 18 - iter 480/1205 - loss 0.07307572 - samples/sec: 63.07 - lr: 0.000030
2021-07-15 17:29:51,574 epoch 18 - iter 600/1205 - loss 0.07351190 - samples/sec: 62.64 - lr: 0.000030
2021-07-15 17:30:52,998 epoch 18 - iter 720/1205 - loss 0.07544794 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 17:31:53,990 epoch 18 - iter 840/1205 - loss 0.07587015 - samples/sec: 62.96 - lr: 0.000030
2021-07-15 17:32:55,058 epoch 18 - iter 960/1205 - loss 0.07605456 - samples/sec: 62.89 - lr: 0.000030
2021-07-15 17:33:56,093 epoch 18 - iter 1080/1205 - loss 0.07637480 - samples/sec: 62.92 - lr: 0.000030
2021-07-15 17:34:57,206 epoch 18 - iter 1200/1205 - loss 0.07633725 - samples/sec: 62.84 - lr: 0.000030
2021-07-15 17:34:59,477 ----------------------------------------------------------------------------------------------------
2021-07-15 17:34:59,477 EPOCH 18 done: loss 0.0764 - lr 0.0000300
2021-07-15 17:35:09,820 DEV : loss 0.11027868837118149 - score 0.9774
2021-07-15 17:35:09,959 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 17:35:13,727 ----------------------------------------------------------------------------------------------------
2021-07-15 17:36:15,026 epoch 19 - iter 120/1205 - loss 0.06973789 - samples/sec: 62.65 - lr: 0.000030
2021-07-15 17:37:16,358 epoch 19 - iter 240/1205 - loss 0.07051698 - samples/sec: 62.62 - lr: 0.000030
2021-07-15 17:38:17,879 epoch 19 - iter 360/1205 - loss 0.07016760 - samples/sec: 62.42 - lr: 0.000030
2021-07-15 17:39:19,191 epoch 19 - iter 480/1205 - loss 0.07148854 - samples/sec: 62.64 - lr: 0.000030
2021-07-15 17:40:20,405 epoch 19 - iter 600/1205 - loss 0.07297165 - samples/sec: 62.74 - lr: 0.000030
2021-07-15 17:41:21,829 epoch 19 - iter 720/1205 - loss 0.07408773 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 17:42:23,238 epoch 19 - iter 840/1205 - loss 0.07296984 - samples/sec: 62.54 - lr: 0.000030
2021-07-15 17:43:24,919 epoch 19 - iter 960/1205 - loss 0.07271661 - samples/sec: 62.26 - lr: 0.000030
2021-07-15 17:44:26,377 epoch 19 - iter 1080/1205 - loss 0.07250834 - samples/sec: 62.49 - lr: 0.000030
2021-07-15 17:45:27,943 epoch 19 - iter 1200/1205 - loss 0.07340636 - samples/sec: 62.38 - lr: 0.000030
2021-07-15 17:45:30,224 ----------------------------------------------------------------------------------------------------
2021-07-15 17:45:30,224 EPOCH 19 done: loss 0.0735 - lr 0.0000300
2021-07-15 17:45:40,556 DEV : loss 0.10891396552324295 - score 0.976
2021-07-15 17:45:40,693 BAD EPOCHS (no improvement): 1
2021-07-15 17:45:40,693 ----------------------------------------------------------------------------------------------------
2021-07-15 17:46:42,244 epoch 20 - iter 120/1205 - loss 0.06148711 - samples/sec: 62.39 - lr: 0.000030
2021-07-15 17:47:43,268 epoch 20 - iter 240/1205 - loss 0.06142186 - samples/sec: 62.93 - lr: 0.000030
2021-07-15 17:48:43,959 epoch 20 - iter 360/1205 - loss 0.06707696 - samples/sec: 63.28 - lr: 0.000030
2021-07-15 17:49:44,644 epoch 20 - iter 480/1205 - loss 0.06742292 - samples/sec: 63.28 - lr: 0.000030
2021-07-15 17:50:45,606 epoch 20 - iter 600/1205 - loss 0.07114061 - samples/sec: 63.00 - lr: 0.000030
2021-07-15 17:51:46,535 epoch 20 - iter 720/1205 - loss 0.07126057 - samples/sec: 63.03 - lr: 0.000030
2021-07-15 17:52:47,326 epoch 20 - iter 840/1205 - loss 0.06983539 - samples/sec: 63.17 - lr: 0.000030
2021-07-15 17:53:48,112 epoch 20 - iter 960/1205 - loss 0.06975941 - samples/sec: 63.18 - lr: 0.000030
2021-07-15 17:54:49,019 epoch 20 - iter 1080/1205 - loss 0.07098818 - samples/sec: 63.05 - lr: 0.000030
2021-07-15 17:55:49,636 epoch 20 - iter 1200/1205 - loss 0.07180110 - samples/sec: 63.36 - lr: 0.000030
2021-07-15 17:55:51,885 ----------------------------------------------------------------------------------------------------
2021-07-15 17:55:51,885 EPOCH 20 done: loss 0.0717 - lr 0.0000300
2021-07-15 17:56:02,193 DEV : loss 0.11922387033700943 - score 0.9745
2021-07-15 17:56:02,330 BAD EPOCHS (no improvement): 2
2021-07-15 17:56:02,330 ----------------------------------------------------------------------------------------------------
2021-07-15 17:57:03,007 epoch 21 - iter 120/1205 - loss 0.07400829 - samples/sec: 63.29 - lr: 0.000030
2021-07-15 17:58:03,625 epoch 21 - iter 240/1205 - loss 0.06782908 - samples/sec: 63.35 - lr: 0.000030
2021-07-15 17:59:04,577 epoch 21 - iter 360/1205 - loss 0.06696905 - samples/sec: 63.01 - lr: 0.000030
2021-07-15 18:00:05,803 epoch 21 - iter 480/1205 - loss 0.06652429 - samples/sec: 62.72 - lr: 0.000030
2021-07-15 18:01:06,904 epoch 21 - iter 600/1205 - loss 0.06613192 - samples/sec: 62.85 - lr: 0.000030
2021-07-15 18:02:07,917 epoch 21 - iter 720/1205 - loss 0.06653518 - samples/sec: 62.94 - lr: 0.000030
2021-07-15 18:03:08,969 epoch 21 - iter 840/1205 - loss 0.06658917 - samples/sec: 62.90 - lr: 0.000030
2021-07-15 18:04:10,164 epoch 21 - iter 960/1205 - loss 0.06651559 - samples/sec: 62.76 - lr: 0.000030
2021-07-15 18:05:11,378 epoch 21 - iter 1080/1205 - loss 0.06637951 - samples/sec: 62.74 - lr: 0.000030
2021-07-15 18:06:12,451 epoch 21 - iter 1200/1205 - loss 0.06704663 - samples/sec: 62.88 - lr: 0.000030
2021-07-15 18:06:14,682 ----------------------------------------------------------------------------------------------------
2021-07-15 18:06:14,683 EPOCH 21 done: loss 0.0670 - lr 0.0000300
2021-07-15 18:06:25,001 DEV : loss 0.11557769030332565 - score 0.9763
2021-07-15 18:06:25,137 BAD EPOCHS (no improvement): 3
2021-07-15 18:06:25,137 ----------------------------------------------------------------------------------------------------
2021-07-15 18:07:26,277 epoch 22 - iter 120/1205 - loss 0.06023785 - samples/sec: 62.81 - lr: 0.000030
2021-07-15 18:08:27,369 epoch 22 - iter 240/1205 - loss 0.05850675 - samples/sec: 62.86 - lr: 0.000030
2021-07-15 18:09:28,953 epoch 22 - iter 360/1205 - loss 0.05939754 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 18:10:30,681 epoch 22 - iter 480/1205 - loss 0.06020842 - samples/sec: 62.21 - lr: 0.000030
2021-07-15 18:11:32,141 epoch 22 - iter 600/1205 - loss 0.05951974 - samples/sec: 62.49 - lr: 0.000030
2021-07-15 18:12:33,677 epoch 22 - iter 720/1205 - loss 0.06109149 - samples/sec: 62.41 - lr: 0.000030
2021-07-15 18:13:37,969 epoch 22 - iter 840/1205 - loss 0.06014389 - samples/sec: 59.73 - lr: 0.000030
2021-07-15 18:14:39,586 epoch 22 - iter 960/1205 - loss 0.06153447 - samples/sec: 62.33 - lr: 0.000030
2021-07-15 18:15:41,174 epoch 22 - iter 1080/1205 - loss 0.06252691 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 18:16:42,766 epoch 22 - iter 1200/1205 - loss 0.06215412 - samples/sec: 62.35 - lr: 0.000030
2021-07-15 18:16:45,029 ----------------------------------------------------------------------------------------------------
2021-07-15 18:16:45,029 EPOCH 22 done: loss 0.0620 - lr 0.0000300
2021-07-15 18:16:55,370 DEV : loss 0.11156286299228668 - score 0.9771
Epoch    22: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 18:16:55,506 BAD EPOCHS (no improvement): 4
2021-07-15 18:16:55,506 ----------------------------------------------------------------------------------------------------
2021-07-15 18:17:57,207 epoch 23 - iter 120/1205 - loss 0.05829947 - samples/sec: 62.24 - lr: 0.000015
2021-07-15 18:18:58,913 epoch 23 - iter 240/1205 - loss 0.05487377 - samples/sec: 62.24 - lr: 0.000015
2021-07-15 18:20:00,621 epoch 23 - iter 360/1205 - loss 0.05552383 - samples/sec: 62.23 - lr: 0.000015
2021-07-15 18:21:01,818 epoch 23 - iter 480/1205 - loss 0.05531431 - samples/sec: 62.75 - lr: 0.000015
2021-07-15 18:22:03,381 epoch 23 - iter 600/1205 - loss 0.05695415 - samples/sec: 62.38 - lr: 0.000015
2021-07-15 18:23:05,097 epoch 23 - iter 720/1205 - loss 0.05709555 - samples/sec: 62.23 - lr: 0.000015
2021-07-15 18:24:06,060 epoch 23 - iter 840/1205 - loss 0.05794904 - samples/sec: 63.00 - lr: 0.000015
2021-07-15 18:25:06,709 epoch 23 - iter 960/1205 - loss 0.05736911 - samples/sec: 63.32 - lr: 0.000015
2021-07-15 18:26:08,160 epoch 23 - iter 1080/1205 - loss 0.05697931 - samples/sec: 62.49 - lr: 0.000015
2021-07-15 18:27:09,853 epoch 23 - iter 1200/1205 - loss 0.05693645 - samples/sec: 62.25 - lr: 0.000015
2021-07-15 18:27:12,154 ----------------------------------------------------------------------------------------------------
2021-07-15 18:27:12,154 EPOCH 23 done: loss 0.0569 - lr 0.0000150
2021-07-15 18:27:22,487 DEV : loss 0.11942461133003235 - score 0.976
2021-07-15 18:27:22,621 BAD EPOCHS (no improvement): 1
2021-07-15 18:27:22,622 ----------------------------------------------------------------------------------------------------
2021-07-15 18:28:24,448 epoch 24 - iter 120/1205 - loss 0.06093490 - samples/sec: 62.12 - lr: 0.000015
2021-07-15 18:29:25,665 epoch 24 - iter 240/1205 - loss 0.05325974 - samples/sec: 62.73 - lr: 0.000015
2021-07-15 18:30:27,257 epoch 24 - iter 360/1205 - loss 0.05324143 - samples/sec: 62.35 - lr: 0.000015
2021-07-15 18:31:28,934 epoch 24 - iter 480/1205 - loss 0.05264121 - samples/sec: 62.27 - lr: 0.000015
2021-07-15 18:32:30,298 epoch 24 - iter 600/1205 - loss 0.05216365 - samples/sec: 62.58 - lr: 0.000015
2021-07-15 18:33:31,870 epoch 24 - iter 720/1205 - loss 0.05168699 - samples/sec: 62.37 - lr: 0.000015
2021-07-15 18:34:33,496 epoch 24 - iter 840/1205 - loss 0.05156922 - samples/sec: 62.32 - lr: 0.000015
2021-07-15 18:35:34,578 epoch 24 - iter 960/1205 - loss 0.05197017 - samples/sec: 62.87 - lr: 0.000015
2021-07-15 18:36:36,204 epoch 24 - iter 1080/1205 - loss 0.05233197 - samples/sec: 62.32 - lr: 0.000015
2021-07-15 18:37:37,875 epoch 24 - iter 1200/1205 - loss 0.05290039 - samples/sec: 62.27 - lr: 0.000015
2021-07-15 18:37:40,129 ----------------------------------------------------------------------------------------------------
2021-07-15 18:37:40,129 EPOCH 24 done: loss 0.0531 - lr 0.0000150
2021-07-15 18:37:50,461 DEV : loss 0.11626503616571426 - score 0.9756
2021-07-15 18:37:50,595 BAD EPOCHS (no improvement): 2
2021-07-15 18:37:50,596 ----------------------------------------------------------------------------------------------------
2021-07-15 18:38:52,285 epoch 25 - iter 120/1205 - loss 0.04582004 - samples/sec: 62.25 - lr: 0.000015
2021-07-15 18:39:54,122 epoch 25 - iter 240/1205 - loss 0.05536347 - samples/sec: 62.11 - lr: 0.000015
2021-07-15 18:40:55,636 epoch 25 - iter 360/1205 - loss 0.05215210 - samples/sec: 62.43 - lr: 0.000015
2021-07-15 18:41:56,863 epoch 25 - iter 480/1205 - loss 0.05353100 - samples/sec: 62.72 - lr: 0.000015
2021-07-15 18:42:58,481 epoch 25 - iter 600/1205 - loss 0.05360610 - samples/sec: 62.33 - lr: 0.000015
2021-07-15 18:44:00,008 epoch 25 - iter 720/1205 - loss 0.05510713 - samples/sec: 62.42 - lr: 0.000015
2021-07-15 18:45:01,438 epoch 25 - iter 840/1205 - loss 0.05376407 - samples/sec: 62.52 - lr: 0.000015
2021-07-15 18:46:03,106 epoch 25 - iter 960/1205 - loss 0.05310293 - samples/sec: 62.28 - lr: 0.000015
2021-07-15 18:47:04,732 epoch 25 - iter 1080/1205 - loss 0.05253012 - samples/sec: 62.32 - lr: 0.000015
2021-07-15 18:48:06,468 epoch 25 - iter 1200/1205 - loss 0.05224237 - samples/sec: 62.21 - lr: 0.000015
2021-07-15 18:48:08,762 ----------------------------------------------------------------------------------------------------
2021-07-15 18:48:08,762 EPOCH 25 done: loss 0.0526 - lr 0.0000150
2021-07-15 18:48:19,098 DEV : loss 0.12995629012584686 - score 0.9745
2021-07-15 18:48:19,233 BAD EPOCHS (no improvement): 3
2021-07-15 18:48:19,233 ----------------------------------------------------------------------------------------------------
2021-07-15 18:49:20,541 epoch 26 - iter 120/1205 - loss 0.05353003 - samples/sec: 62.64 - lr: 0.000015
2021-07-15 18:50:21,701 epoch 26 - iter 240/1205 - loss 0.05095357 - samples/sec: 62.79 - lr: 0.000015
2021-07-15 18:51:22,905 epoch 26 - iter 360/1205 - loss 0.05080130 - samples/sec: 62.75 - lr: 0.000015
2021-07-15 18:52:23,888 epoch 26 - iter 480/1205 - loss 0.04852919 - samples/sec: 62.98 - lr: 0.000015
2021-07-15 18:53:25,360 epoch 26 - iter 600/1205 - loss 0.04713392 - samples/sec: 62.47 - lr: 0.000015
2021-07-15 18:54:27,030 epoch 26 - iter 720/1205 - loss 0.04726764 - samples/sec: 62.27 - lr: 0.000015
2021-07-15 18:55:28,441 epoch 26 - iter 840/1205 - loss 0.04755092 - samples/sec: 62.54 - lr: 0.000015
2021-07-15 18:56:29,806 epoch 26 - iter 960/1205 - loss 0.04743803 - samples/sec: 62.58 - lr: 0.000015
2021-07-15 18:57:31,025 epoch 26 - iter 1080/1205 - loss 0.04792295 - samples/sec: 62.73 - lr: 0.000015
2021-07-15 18:58:32,262 epoch 26 - iter 1200/1205 - loss 0.04767930 - samples/sec: 62.71 - lr: 0.000015
2021-07-15 18:58:34,500 ----------------------------------------------------------------------------------------------------
2021-07-15 18:58:34,501 EPOCH 26 done: loss 0.0477 - lr 0.0000150
2021-07-15 18:58:44,828 DEV : loss 0.11949887871742249 - score 0.9783
2021-07-15 18:58:44,964 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 18:58:48,678 ----------------------------------------------------------------------------------------------------
2021-07-15 18:59:50,142 epoch 27 - iter 120/1205 - loss 0.04649346 - samples/sec: 62.48 - lr: 0.000015
2021-07-15 19:00:51,257 epoch 27 - iter 240/1205 - loss 0.04476485 - samples/sec: 62.84 - lr: 0.000015
2021-07-15 19:01:52,466 epoch 27 - iter 360/1205 - loss 0.04404988 - samples/sec: 62.74 - lr: 0.000015
2021-07-15 19:02:53,518 epoch 27 - iter 480/1205 - loss 0.04535888 - samples/sec: 62.90 - lr: 0.000015
2021-07-15 19:03:54,841 epoch 27 - iter 600/1205 - loss 0.04630215 - samples/sec: 62.62 - lr: 0.000015
2021-07-15 19:04:56,039 epoch 27 - iter 720/1205 - loss 0.04660520 - samples/sec: 62.75 - lr: 0.000015
2021-07-15 19:05:57,673 epoch 27 - iter 840/1205 - loss 0.04653636 - samples/sec: 62.31 - lr: 0.000015
2021-07-15 19:06:59,466 epoch 27 - iter 960/1205 - loss 0.04654091 - samples/sec: 62.15 - lr: 0.000015
2021-07-15 19:08:01,170 epoch 27 - iter 1080/1205 - loss 0.04695632 - samples/sec: 62.24 - lr: 0.000015
2021-07-15 19:09:02,863 epoch 27 - iter 1200/1205 - loss 0.04762456 - samples/sec: 62.25 - lr: 0.000015
2021-07-15 19:09:05,141 ----------------------------------------------------------------------------------------------------
2021-07-15 19:09:05,141 EPOCH 27 done: loss 0.0476 - lr 0.0000150
2021-07-15 19:09:15,463 DEV : loss 0.11977863311767578 - score 0.9763
2021-07-15 19:09:15,597 BAD EPOCHS (no improvement): 1
2021-07-15 19:09:15,598 ----------------------------------------------------------------------------------------------------
2021-07-15 19:10:17,286 epoch 28 - iter 120/1205 - loss 0.04534963 - samples/sec: 62.26 - lr: 0.000015
2021-07-15 19:11:21,677 epoch 28 - iter 240/1205 - loss 0.04246093 - samples/sec: 59.64 - lr: 0.000015
2021-07-15 19:12:23,262 epoch 28 - iter 360/1205 - loss 0.04223815 - samples/sec: 62.36 - lr: 0.000015
2021-07-15 19:13:24,798 epoch 28 - iter 480/1205 - loss 0.04318900 - samples/sec: 62.41 - lr: 0.000015
2021-07-15 19:14:26,474 epoch 28 - iter 600/1205 - loss 0.04374602 - samples/sec: 62.27 - lr: 0.000015
2021-07-15 19:15:27,761 epoch 28 - iter 720/1205 - loss 0.04407425 - samples/sec: 62.66 - lr: 0.000015
2021-07-15 19:16:29,338 epoch 28 - iter 840/1205 - loss 0.04511411 - samples/sec: 62.37 - lr: 0.000015
2021-07-15 19:17:31,045 epoch 28 - iter 960/1205 - loss 0.04450266 - samples/sec: 62.23 - lr: 0.000015
2021-07-15 19:18:32,593 epoch 28 - iter 1080/1205 - loss 0.04415649 - samples/sec: 62.40 - lr: 0.000015
2021-07-15 19:19:33,849 epoch 28 - iter 1200/1205 - loss 0.04411700 - samples/sec: 62.69 - lr: 0.000015
2021-07-15 19:19:36,113 ----------------------------------------------------------------------------------------------------
2021-07-15 19:19:36,114 EPOCH 28 done: loss 0.0441 - lr 0.0000150
2021-07-15 19:19:46,423 DEV : loss 0.12362027913331985 - score 0.976
2021-07-15 19:19:46,559 BAD EPOCHS (no improvement): 2
2021-07-15 19:19:46,560 ----------------------------------------------------------------------------------------------------
2021-07-15 19:20:48,042 epoch 29 - iter 120/1205 - loss 0.04772644 - samples/sec: 62.46 - lr: 0.000015
2021-07-15 19:21:49,052 epoch 29 - iter 240/1205 - loss 0.04571155 - samples/sec: 62.95 - lr: 0.000015
2021-07-15 19:22:50,223 epoch 29 - iter 360/1205 - loss 0.04575481 - samples/sec: 62.78 - lr: 0.000015
2021-07-15 19:23:51,498 epoch 29 - iter 480/1205 - loss 0.04570515 - samples/sec: 62.67 - lr: 0.000015
2021-07-15 19:24:53,244 epoch 29 - iter 600/1205 - loss 0.04495549 - samples/sec: 62.20 - lr: 0.000015
2021-07-15 19:25:54,969 epoch 29 - iter 720/1205 - loss 0.04480249 - samples/sec: 62.22 - lr: 0.000015
2021-07-15 19:26:56,585 epoch 29 - iter 840/1205 - loss 0.04557127 - samples/sec: 62.33 - lr: 0.000015
2021-07-15 19:27:57,898 epoch 29 - iter 960/1205 - loss 0.04516741 - samples/sec: 62.64 - lr: 0.000015
2021-07-15 19:28:59,245 epoch 29 - iter 1080/1205 - loss 0.04494521 - samples/sec: 62.60 - lr: 0.000015
2021-07-15 19:30:00,705 epoch 29 - iter 1200/1205 - loss 0.04505971 - samples/sec: 62.49 - lr: 0.000015
2021-07-15 19:30:02,983 ----------------------------------------------------------------------------------------------------
2021-07-15 19:30:02,983 EPOCH 29 done: loss 0.0450 - lr 0.0000150
2021-07-15 19:30:13,306 DEV : loss 0.12409986555576324 - score 0.9754
2021-07-15 19:30:13,443 BAD EPOCHS (no improvement): 3
2021-07-15 19:30:13,443 ----------------------------------------------------------------------------------------------------
2021-07-15 19:31:15,078 epoch 30 - iter 120/1205 - loss 0.04269451 - samples/sec: 62.31 - lr: 0.000015
2021-07-15 19:32:16,837 epoch 30 - iter 240/1205 - loss 0.04430473 - samples/sec: 62.18 - lr: 0.000015
2021-07-15 19:33:18,532 epoch 30 - iter 360/1205 - loss 0.04168081 - samples/sec: 62.25 - lr: 0.000015
2021-07-15 19:34:20,315 epoch 30 - iter 480/1205 - loss 0.04456343 - samples/sec: 62.16 - lr: 0.000015
2021-07-15 19:35:21,922 epoch 30 - iter 600/1205 - loss 0.04512301 - samples/sec: 62.34 - lr: 0.000015
2021-07-15 19:36:23,261 epoch 30 - iter 720/1205 - loss 0.04624911 - samples/sec: 62.61 - lr: 0.000015
2021-07-15 19:37:24,510 epoch 30 - iter 840/1205 - loss 0.04535100 - samples/sec: 62.70 - lr: 0.000015
2021-07-15 19:38:25,707 epoch 30 - iter 960/1205 - loss 0.04489692 - samples/sec: 62.75 - lr: 0.000015
2021-07-15 19:39:27,263 epoch 30 - iter 1080/1205 - loss 0.04495030 - samples/sec: 62.39 - lr: 0.000015
2021-07-15 19:40:28,781 epoch 30 - iter 1200/1205 - loss 0.04496246 - samples/sec: 62.43 - lr: 0.000015
2021-07-15 19:40:31,073 ----------------------------------------------------------------------------------------------------
2021-07-15 19:40:31,073 EPOCH 30 done: loss 0.0448 - lr 0.0000150
2021-07-15 19:40:41,403 DEV : loss 0.1292896270751953 - score 0.975
Epoch    30: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 19:40:41,539 BAD EPOCHS (no improvement): 4
2021-07-15 19:40:41,539 ----------------------------------------------------------------------------------------------------
2021-07-15 19:41:43,061 epoch 31 - iter 120/1205 - loss 0.04706557 - samples/sec: 62.42 - lr: 0.000008
2021-07-15 19:42:44,520 epoch 31 - iter 240/1205 - loss 0.04324536 - samples/sec: 62.49 - lr: 0.000008
2021-07-15 19:43:46,044 epoch 31 - iter 360/1205 - loss 0.04367350 - samples/sec: 62.42 - lr: 0.000008
2021-07-15 19:44:47,691 epoch 31 - iter 480/1205 - loss 0.04209439 - samples/sec: 62.30 - lr: 0.000008
2021-07-15 19:45:49,211 epoch 31 - iter 600/1205 - loss 0.04177407 - samples/sec: 62.42 - lr: 0.000008
2021-07-15 19:46:50,783 epoch 31 - iter 720/1205 - loss 0.04100166 - samples/sec: 62.37 - lr: 0.000008
2021-07-15 19:47:52,012 epoch 31 - iter 840/1205 - loss 0.04042232 - samples/sec: 62.72 - lr: 0.000008
2021-07-15 19:48:53,416 epoch 31 - iter 960/1205 - loss 0.03956332 - samples/sec: 62.54 - lr: 0.000008
2021-07-15 19:49:55,121 epoch 31 - iter 1080/1205 - loss 0.03913511 - samples/sec: 62.24 - lr: 0.000008
2021-07-15 19:50:56,734 epoch 31 - iter 1200/1205 - loss 0.03914094 - samples/sec: 62.33 - lr: 0.000008
2021-07-15 19:50:59,018 ----------------------------------------------------------------------------------------------------
2021-07-15 19:50:59,018 EPOCH 31 done: loss 0.0391 - lr 0.0000075
2021-07-15 19:51:09,343 DEV : loss 0.12522056698799133 - score 0.9763
2021-07-15 19:51:09,480 BAD EPOCHS (no improvement): 1
2021-07-15 19:51:09,481 ----------------------------------------------------------------------------------------------------
2021-07-15 19:52:11,168 epoch 32 - iter 120/1205 - loss 0.04057502 - samples/sec: 62.26 - lr: 0.000008
2021-07-15 19:53:12,965 epoch 32 - iter 240/1205 - loss 0.03724585 - samples/sec: 62.15 - lr: 0.000008
2021-07-15 19:54:14,625 epoch 32 - iter 360/1205 - loss 0.04006424 - samples/sec: 62.28 - lr: 0.000008
2021-07-15 19:55:16,039 epoch 32 - iter 480/1205 - loss 0.03951789 - samples/sec: 62.53 - lr: 0.000008
2021-07-15 19:56:17,952 epoch 32 - iter 600/1205 - loss 0.03946218 - samples/sec: 62.03 - lr: 0.000008
2021-07-15 19:57:19,678 epoch 32 - iter 720/1205 - loss 0.03917257 - samples/sec: 62.22 - lr: 0.000008
2021-07-15 19:58:21,291 epoch 32 - iter 840/1205 - loss 0.03976143 - samples/sec: 62.33 - lr: 0.000008
2021-07-15 19:59:22,934 epoch 32 - iter 960/1205 - loss 0.03990456 - samples/sec: 62.30 - lr: 0.000008
2021-07-15 20:00:24,673 epoch 32 - iter 1080/1205 - loss 0.03890080 - samples/sec: 62.20 - lr: 0.000008
2021-07-15 20:01:26,225 epoch 32 - iter 1200/1205 - loss 0.03874403 - samples/sec: 62.39 - lr: 0.000008
2021-07-15 20:01:28,516 ----------------------------------------------------------------------------------------------------
2021-07-15 20:01:28,516 EPOCH 32 done: loss 0.0387 - lr 0.0000075
2021-07-15 20:01:38,846 DEV : loss 0.12908433377742767 - score 0.9757
2021-07-15 20:01:38,984 BAD EPOCHS (no improvement): 2
2021-07-15 20:01:38,984 ----------------------------------------------------------------------------------------------------
2021-07-15 20:02:40,177 epoch 33 - iter 120/1205 - loss 0.03310393 - samples/sec: 62.76 - lr: 0.000008
2021-07-15 20:03:41,495 epoch 33 - iter 240/1205 - loss 0.03940995 - samples/sec: 62.63 - lr: 0.000008
2021-07-15 20:04:42,585 epoch 33 - iter 360/1205 - loss 0.03721017 - samples/sec: 62.86 - lr: 0.000008
2021-07-15 20:05:43,854 epoch 33 - iter 480/1205 - loss 0.03764840 - samples/sec: 62.68 - lr: 0.000008
2021-07-15 20:06:45,176 epoch 33 - iter 600/1205 - loss 0.03703196 - samples/sec: 62.63 - lr: 0.000008
2021-07-15 20:07:46,398 epoch 33 - iter 720/1205 - loss 0.03688503 - samples/sec: 62.73 - lr: 0.000008
2021-07-15 20:08:47,572 epoch 33 - iter 840/1205 - loss 0.03667570 - samples/sec: 62.78 - lr: 0.000008
2021-07-15 20:09:48,772 epoch 33 - iter 960/1205 - loss 0.03622111 - samples/sec: 62.75 - lr: 0.000008
2021-07-15 20:10:50,235 epoch 33 - iter 1080/1205 - loss 0.03658783 - samples/sec: 62.48 - lr: 0.000008
2021-07-15 20:11:51,690 epoch 33 - iter 1200/1205 - loss 0.03630360 - samples/sec: 62.49 - lr: 0.000008
2021-07-15 20:11:53,958 ----------------------------------------------------------------------------------------------------
2021-07-15 20:11:53,958 EPOCH 33 done: loss 0.0363 - lr 0.0000075
2021-07-15 20:12:07,027 DEV : loss 0.12702947854995728 - score 0.9771
2021-07-15 20:12:07,164 BAD EPOCHS (no improvement): 3
2021-07-15 20:12:07,164 ----------------------------------------------------------------------------------------------------
2021-07-15 20:13:08,508 epoch 34 - iter 120/1205 - loss 0.03722122 - samples/sec: 62.61 - lr: 0.000008
2021-07-15 20:14:09,726 epoch 34 - iter 240/1205 - loss 0.03582528 - samples/sec: 62.73 - lr: 0.000008
2021-07-15 20:15:11,174 epoch 34 - iter 360/1205 - loss 0.03739286 - samples/sec: 62.50 - lr: 0.000008
2021-07-15 20:16:12,236 epoch 34 - iter 480/1205 - loss 0.03590107 - samples/sec: 62.89 - lr: 0.000008
2021-07-15 20:17:13,819 epoch 34 - iter 600/1205 - loss 0.03752655 - samples/sec: 62.36 - lr: 0.000008
2021-07-15 20:18:15,546 epoch 34 - iter 720/1205 - loss 0.03741408 - samples/sec: 62.21 - lr: 0.000008
2021-07-15 20:19:16,686 epoch 34 - iter 840/1205 - loss 0.03753530 - samples/sec: 62.81 - lr: 0.000008
2021-07-15 20:20:17,945 epoch 34 - iter 960/1205 - loss 0.03752215 - samples/sec: 62.69 - lr: 0.000008
2021-07-15 20:21:19,115 epoch 34 - iter 1080/1205 - loss 0.03776372 - samples/sec: 62.78 - lr: 0.000008
2021-07-15 20:22:20,477 epoch 34 - iter 1200/1205 - loss 0.03715395 - samples/sec: 62.59 - lr: 0.000008
2021-07-15 20:22:22,737 ----------------------------------------------------------------------------------------------------
2021-07-15 20:22:22,737 EPOCH 34 done: loss 0.0374 - lr 0.0000075
2021-07-15 20:22:33,072 DEV : loss 0.13362593948841095 - score 0.9733
Epoch    34: reducing learning rate of group 0 to 3.7500e-06.
2021-07-15 20:22:33,210 BAD EPOCHS (no improvement): 4
2021-07-15 20:22:33,210 ----------------------------------------------------------------------------------------------------
2021-07-15 20:23:34,694 epoch 35 - iter 120/1205 - loss 0.03830724 - samples/sec: 62.46 - lr: 0.000004
2021-07-15 20:24:36,090 epoch 35 - iter 240/1205 - loss 0.03629850 - samples/sec: 62.55 - lr: 0.000004
2021-07-15 20:25:37,645 epoch 35 - iter 360/1205 - loss 0.03611843 - samples/sec: 62.39 - lr: 0.000004
2021-07-15 20:26:38,986 epoch 35 - iter 480/1205 - loss 0.03691064 - samples/sec: 62.61 - lr: 0.000004
2021-07-15 20:27:40,642 epoch 35 - iter 600/1205 - loss 0.03595206 - samples/sec: 62.29 - lr: 0.000004
2021-07-15 20:28:42,348 epoch 35 - iter 720/1205 - loss 0.03627165 - samples/sec: 62.24 - lr: 0.000004
2021-07-15 20:29:43,889 epoch 35 - iter 840/1205 - loss 0.03554795 - samples/sec: 62.40 - lr: 0.000004
2021-07-15 20:30:45,560 epoch 35 - iter 960/1205 - loss 0.03491145 - samples/sec: 62.27 - lr: 0.000004
2021-07-15 20:31:47,261 epoch 35 - iter 1080/1205 - loss 0.03437235 - samples/sec: 62.24 - lr: 0.000004
2021-07-15 20:32:48,888 epoch 35 - iter 1200/1205 - loss 0.03518619 - samples/sec: 62.32 - lr: 0.000004
2021-07-15 20:32:51,161 ----------------------------------------------------------------------------------------------------
2021-07-15 20:32:51,161 EPOCH 35 done: loss 0.0352 - lr 0.0000038
2021-07-15 20:33:01,485 DEV : loss 0.1325434148311615 - score 0.9751
2021-07-15 20:33:01,621 BAD EPOCHS (no improvement): 1
2021-07-15 20:33:01,621 ----------------------------------------------------------------------------------------------------
2021-07-15 20:34:02,613 epoch 36 - iter 120/1205 - loss 0.02678384 - samples/sec: 62.97 - lr: 0.000004
2021-07-15 20:35:03,813 epoch 36 - iter 240/1205 - loss 0.03055637 - samples/sec: 62.75 - lr: 0.000004
2021-07-15 20:36:05,021 epoch 36 - iter 360/1205 - loss 0.03122153 - samples/sec: 62.74 - lr: 0.000004
2021-07-15 20:37:06,398 epoch 36 - iter 480/1205 - loss 0.03226101 - samples/sec: 62.57 - lr: 0.000004
2021-07-15 20:38:07,654 epoch 36 - iter 600/1205 - loss 0.03182390 - samples/sec: 62.69 - lr: 0.000004
2021-07-15 20:39:08,944 epoch 36 - iter 720/1205 - loss 0.03139292 - samples/sec: 62.66 - lr: 0.000004
2021-07-15 20:40:10,081 epoch 36 - iter 840/1205 - loss 0.03255734 - samples/sec: 62.82 - lr: 0.000004
2021-07-15 20:41:11,700 epoch 36 - iter 960/1205 - loss 0.03280470 - samples/sec: 62.32 - lr: 0.000004
2021-07-15 20:42:13,386 epoch 36 - iter 1080/1205 - loss 0.03363135 - samples/sec: 62.26 - lr: 0.000004
2021-07-15 20:43:14,713 epoch 36 - iter 1200/1205 - loss 0.03408601 - samples/sec: 62.62 - lr: 0.000004
2021-07-15 20:43:16,972 ----------------------------------------------------------------------------------------------------
2021-07-15 20:43:16,972 EPOCH 36 done: loss 0.0345 - lr 0.0000038
2021-07-15 20:43:27,324 DEV : loss 0.12964841723442078 - score 0.9754
2021-07-15 20:43:27,461 BAD EPOCHS (no improvement): 2
2021-07-15 20:43:27,461 ----------------------------------------------------------------------------------------------------
2021-07-15 20:44:28,638 epoch 37 - iter 120/1205 - loss 0.04052845 - samples/sec: 62.78 - lr: 0.000004
2021-07-15 20:45:29,792 epoch 37 - iter 240/1205 - loss 0.03645615 - samples/sec: 62.80 - lr: 0.000004
2021-07-15 20:46:30,942 epoch 37 - iter 360/1205 - loss 0.03547871 - samples/sec: 62.80 - lr: 0.000004
2021-07-15 20:47:32,323 epoch 37 - iter 480/1205 - loss 0.03505996 - samples/sec: 62.57 - lr: 0.000004
2021-07-15 20:48:33,965 epoch 37 - iter 600/1205 - loss 0.03556539 - samples/sec: 62.30 - lr: 0.000004
2021-07-15 20:49:35,533 epoch 37 - iter 720/1205 - loss 0.03490891 - samples/sec: 62.38 - lr: 0.000004
2021-07-15 20:50:37,116 epoch 37 - iter 840/1205 - loss 0.03478501 - samples/sec: 62.36 - lr: 0.000004
2021-07-15 20:51:38,801 epoch 37 - iter 960/1205 - loss 0.03432686 - samples/sec: 62.26 - lr: 0.000004
2021-07-15 20:52:40,522 epoch 37 - iter 1080/1205 - loss 0.03395826 - samples/sec: 62.22 - lr: 0.000004
2021-07-15 20:53:42,341 epoch 37 - iter 1200/1205 - loss 0.03409693 - samples/sec: 62.12 - lr: 0.000004
2021-07-15 20:53:44,623 ----------------------------------------------------------------------------------------------------
2021-07-15 20:53:44,624 EPOCH 37 done: loss 0.0341 - lr 0.0000038
2021-07-15 20:53:54,966 DEV : loss 0.13285982608795166 - score 0.9751
2021-07-15 20:53:55,102 BAD EPOCHS (no improvement): 3
2021-07-15 20:53:55,102 ----------------------------------------------------------------------------------------------------
2021-07-15 20:54:56,829 epoch 38 - iter 120/1205 - loss 0.03492760 - samples/sec: 62.22 - lr: 0.000004
2021-07-15 20:55:58,660 epoch 38 - iter 240/1205 - loss 0.03461887 - samples/sec: 62.11 - lr: 0.000004
2021-07-15 20:57:00,365 epoch 38 - iter 360/1205 - loss 0.03501847 - samples/sec: 62.24 - lr: 0.000004
2021-07-15 20:58:01,259 epoch 38 - iter 480/1205 - loss 0.03327868 - samples/sec: 63.07 - lr: 0.000004
2021-07-15 20:59:02,376 epoch 38 - iter 600/1205 - loss 0.03403220 - samples/sec: 62.84 - lr: 0.000004
2021-07-15 21:00:03,946 epoch 38 - iter 720/1205 - loss 0.03420439 - samples/sec: 62.37 - lr: 0.000004
2021-07-15 21:01:05,686 epoch 38 - iter 840/1205 - loss 0.03366893 - samples/sec: 62.20 - lr: 0.000004
2021-07-15 21:02:07,276 epoch 38 - iter 960/1205 - loss 0.03398272 - samples/sec: 62.35 - lr: 0.000004
2021-07-15 21:03:08,974 epoch 38 - iter 1080/1205 - loss 0.03435221 - samples/sec: 62.24 - lr: 0.000004
2021-07-15 21:04:10,718 epoch 38 - iter 1200/1205 - loss 0.03454629 - samples/sec: 62.20 - lr: 0.000004
2021-07-15 21:04:12,973 ----------------------------------------------------------------------------------------------------
2021-07-15 21:04:12,973 EPOCH 38 done: loss 0.0345 - lr 0.0000038
2021-07-15 21:04:23,314 DEV : loss 0.13277064263820648 - score 0.9759
Epoch    38: reducing learning rate of group 0 to 1.8750e-06.
2021-07-15 21:04:23,451 BAD EPOCHS (no improvement): 4
2021-07-15 21:04:23,451 ----------------------------------------------------------------------------------------------------
2021-07-15 21:04:23,451 ----------------------------------------------------------------------------------------------------
2021-07-15 21:04:23,451 learning rate too small - quitting training!
2021-07-15 21:04:23,451 ----------------------------------------------------------------------------------------------------
2021-07-15 21:04:24,279 ----------------------------------------------------------------------------------------------------
2021-07-15 21:04:24,280 Testing using best model ...
2021-07-15 21:04:24,280 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.pdtb.pdtb/best-model.pt
2021-07-15 21:08:03,275 0.9746	0.9792	0.9769
2021-07-15 21:08:03,276 
Results:
- F1-score (micro) 0.9769
- F1-score (macro) 0.9769

By class:
SENT       tp: 10984 - fp: 286 - fn: 233 - precision: 0.9746 - recall: 0.9792 - f1-score: 0.9769
2021-07-15 21:08:03,276 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.gum/
2021-07-15 21:08:03,300 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.gum
2021-07-15 21:08:03,301 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.gum/sent_train.txt
2021-07-15 21:08:03,301 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.gum/sent_dev.txt
2021-07-15 21:08:03,301 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.gum/sent_test.txt
Corpus: 4075 train + 865 dev + 1457 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 21:08:07,125 ----------------------------------------------------------------------------------------------------
2021-07-15 21:08:07,127 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 21:08:07,127 ----------------------------------------------------------------------------------------------------
2021-07-15 21:08:07,127 Corpus: "Corpus: 4075 train + 865 dev + 1457 test sentences"
2021-07-15 21:08:07,127 ----------------------------------------------------------------------------------------------------
2021-07-15 21:08:07,127 Parameters:
2021-07-15 21:08:07,127  - learning_rate: "3e-05"
2021-07-15 21:08:07,127  - mini_batch_size: "32"
2021-07-15 21:08:07,127  - patience: "3"
2021-07-15 21:08:07,127  - anneal_factor: "0.5"
2021-07-15 21:08:07,127  - max_epochs: "40"
2021-07-15 21:08:07,128  - shuffle: "True"
2021-07-15 21:08:07,128  - train_with_dev: "False"
2021-07-15 21:08:07,128  - batch_growth_annealing: "False"
2021-07-15 21:08:07,128 ----------------------------------------------------------------------------------------------------
2021-07-15 21:08:07,128 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.gum"
2021-07-15 21:08:07,128 ----------------------------------------------------------------------------------------------------
2021-07-15 21:08:07,128 Device: cuda:0
2021-07-15 21:08:07,128 ----------------------------------------------------------------------------------------------------
2021-07-15 21:08:07,128 Embeddings storage mode: cpu
2021-07-15 21:08:07,130 ----------------------------------------------------------------------------------------------------
2021-07-15 21:08:19,119 epoch 1 - iter 12/128 - loss 6.84423880 - samples/sec: 32.03 - lr: 0.000030
2021-07-15 21:08:31,019 epoch 1 - iter 24/128 - loss 5.87482031 - samples/sec: 32.27 - lr: 0.000030
2021-07-15 21:08:43,379 epoch 1 - iter 36/128 - loss 5.14468113 - samples/sec: 31.07 - lr: 0.000030
2021-07-15 21:08:55,328 epoch 1 - iter 48/128 - loss 4.61625368 - samples/sec: 32.14 - lr: 0.000030
2021-07-15 21:09:07,256 epoch 1 - iter 60/128 - loss 4.22749411 - samples/sec: 32.20 - lr: 0.000030
2021-07-15 21:09:19,028 epoch 1 - iter 72/128 - loss 3.87065621 - samples/sec: 32.62 - lr: 0.000030
2021-07-15 21:09:30,823 epoch 1 - iter 84/128 - loss 3.58720551 - samples/sec: 32.56 - lr: 0.000030
2021-07-15 21:09:42,636 epoch 1 - iter 96/128 - loss 3.34901972 - samples/sec: 32.51 - lr: 0.000030
2021-07-15 21:09:54,439 epoch 1 - iter 108/128 - loss 3.15124159 - samples/sec: 32.54 - lr: 0.000030
2021-07-15 21:10:06,187 epoch 1 - iter 120/128 - loss 2.96177859 - samples/sec: 32.69 - lr: 0.000030
2021-07-15 21:10:13,471 ----------------------------------------------------------------------------------------------------
2021-07-15 21:10:13,471 EPOCH 1 done: loss 2.8644 - lr 0.0000300
2021-07-15 21:10:29,184 DEV : loss 0.623191773891449 - score 0.9191
2021-07-15 21:10:29,245 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:10:29,940 ----------------------------------------------------------------------------------------------------
2021-07-15 21:10:36,046 epoch 2 - iter 12/128 - loss 1.06429417 - samples/sec: 62.90 - lr: 0.000030
2021-07-15 21:10:42,157 epoch 2 - iter 24/128 - loss 1.08710825 - samples/sec: 62.84 - lr: 0.000030
2021-07-15 21:10:48,263 epoch 2 - iter 36/128 - loss 1.09266211 - samples/sec: 62.90 - lr: 0.000030
2021-07-15 21:10:54,407 epoch 2 - iter 48/128 - loss 1.08351339 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 21:11:00,550 epoch 2 - iter 60/128 - loss 1.06912607 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 21:11:06,677 epoch 2 - iter 72/128 - loss 1.05945161 - samples/sec: 62.68 - lr: 0.000030
2021-07-15 21:11:12,769 epoch 2 - iter 84/128 - loss 1.04633514 - samples/sec: 63.04 - lr: 0.000030
2021-07-15 21:11:18,890 epoch 2 - iter 96/128 - loss 1.02777912 - samples/sec: 62.74 - lr: 0.000030
2021-07-15 21:11:25,002 epoch 2 - iter 108/128 - loss 1.02492499 - samples/sec: 62.84 - lr: 0.000030
2021-07-15 21:11:31,121 epoch 2 - iter 120/128 - loss 1.01202906 - samples/sec: 62.76 - lr: 0.000030
2021-07-15 21:11:34,864 ----------------------------------------------------------------------------------------------------
2021-07-15 21:11:34,864 EPOCH 2 done: loss 0.9978 - lr 0.0000300
2021-07-15 21:11:39,450 DEV : loss 0.4409298300743103 - score 0.9419
2021-07-15 21:11:39,509 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:11:43,115 ----------------------------------------------------------------------------------------------------
2021-07-15 21:11:49,165 epoch 3 - iter 12/128 - loss 0.97374933 - samples/sec: 63.48 - lr: 0.000030
2021-07-15 21:11:55,294 epoch 3 - iter 24/128 - loss 0.88139719 - samples/sec: 62.67 - lr: 0.000030
2021-07-15 21:12:01,480 epoch 3 - iter 36/128 - loss 0.85085424 - samples/sec: 62.08 - lr: 0.000030
2021-07-15 21:12:07,655 epoch 3 - iter 48/128 - loss 0.81369032 - samples/sec: 62.19 - lr: 0.000030
2021-07-15 21:12:13,836 epoch 3 - iter 60/128 - loss 0.81874025 - samples/sec: 62.13 - lr: 0.000030
2021-07-15 21:12:20,040 epoch 3 - iter 72/128 - loss 0.80348812 - samples/sec: 61.91 - lr: 0.000030
2021-07-15 21:12:26,240 epoch 3 - iter 84/128 - loss 0.80445200 - samples/sec: 61.95 - lr: 0.000030
2021-07-15 21:12:32,404 epoch 3 - iter 96/128 - loss 0.80439448 - samples/sec: 62.31 - lr: 0.000030
2021-07-15 21:12:38,636 epoch 3 - iter 108/128 - loss 0.79569342 - samples/sec: 61.63 - lr: 0.000030
2021-07-15 21:12:44,777 epoch 3 - iter 120/128 - loss 0.78459724 - samples/sec: 62.54 - lr: 0.000030
2021-07-15 21:12:48,620 ----------------------------------------------------------------------------------------------------
2021-07-15 21:12:48,620 EPOCH 3 done: loss 0.7778 - lr 0.0000300
2021-07-15 21:13:02,265 DEV : loss 0.36743447184562683 - score 0.9498
2021-07-15 21:13:02,326 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:13:05,907 ----------------------------------------------------------------------------------------------------
2021-07-15 21:13:12,254 epoch 4 - iter 12/128 - loss 0.62371712 - samples/sec: 60.51 - lr: 0.000030
2021-07-15 21:13:18,574 epoch 4 - iter 24/128 - loss 0.64780055 - samples/sec: 60.77 - lr: 0.000030
2021-07-15 21:13:24,918 epoch 4 - iter 36/128 - loss 0.66283738 - samples/sec: 60.54 - lr: 0.000030
2021-07-15 21:13:31,232 epoch 4 - iter 48/128 - loss 0.64388799 - samples/sec: 60.82 - lr: 0.000030
2021-07-15 21:13:37,541 epoch 4 - iter 60/128 - loss 0.65293151 - samples/sec: 60.88 - lr: 0.000030
2021-07-15 21:13:43,880 epoch 4 - iter 72/128 - loss 0.63151596 - samples/sec: 60.58 - lr: 0.000030
2021-07-15 21:13:50,208 epoch 4 - iter 84/128 - loss 0.63111708 - samples/sec: 60.69 - lr: 0.000030
2021-07-15 21:13:56,479 epoch 4 - iter 96/128 - loss 0.63263311 - samples/sec: 61.25 - lr: 0.000030
2021-07-15 21:14:02,845 epoch 4 - iter 108/128 - loss 0.62636339 - samples/sec: 60.33 - lr: 0.000030
2021-07-15 21:14:09,186 epoch 4 - iter 120/128 - loss 0.63029248 - samples/sec: 60.56 - lr: 0.000030
2021-07-15 21:14:13,109 ----------------------------------------------------------------------------------------------------
2021-07-15 21:14:13,109 EPOCH 4 done: loss 0.6336 - lr 0.0000300
2021-07-15 21:14:17,790 DEV : loss 0.3139849305152893 - score 0.9549
2021-07-15 21:14:17,851 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:14:21,539 ----------------------------------------------------------------------------------------------------
2021-07-15 21:14:27,902 epoch 5 - iter 12/128 - loss 0.61118354 - samples/sec: 60.36 - lr: 0.000030
2021-07-15 21:14:34,260 epoch 5 - iter 24/128 - loss 0.58709373 - samples/sec: 60.41 - lr: 0.000030
2021-07-15 21:14:40,627 epoch 5 - iter 36/128 - loss 0.59989338 - samples/sec: 60.32 - lr: 0.000030
2021-07-15 21:14:46,964 epoch 5 - iter 48/128 - loss 0.56579067 - samples/sec: 60.61 - lr: 0.000030
2021-07-15 21:14:53,323 epoch 5 - iter 60/128 - loss 0.54648778 - samples/sec: 60.39 - lr: 0.000030
2021-07-15 21:14:59,662 epoch 5 - iter 72/128 - loss 0.54676518 - samples/sec: 60.59 - lr: 0.000030
2021-07-15 21:15:06,019 epoch 5 - iter 84/128 - loss 0.53426454 - samples/sec: 60.42 - lr: 0.000030
2021-07-15 21:15:12,339 epoch 5 - iter 96/128 - loss 0.54258254 - samples/sec: 60.76 - lr: 0.000030
2021-07-15 21:15:18,660 epoch 5 - iter 108/128 - loss 0.54674050 - samples/sec: 60.76 - lr: 0.000030
2021-07-15 21:15:25,036 epoch 5 - iter 120/128 - loss 0.55837385 - samples/sec: 60.24 - lr: 0.000030
2021-07-15 21:15:28,970 ----------------------------------------------------------------------------------------------------
2021-07-15 21:15:28,970 EPOCH 5 done: loss 0.5501 - lr 0.0000300
2021-07-15 21:15:33,652 DEV : loss 0.2884300947189331 - score 0.9546
2021-07-15 21:15:33,713 BAD EPOCHS (no improvement): 1
2021-07-15 21:15:33,713 ----------------------------------------------------------------------------------------------------
2021-07-15 21:15:40,031 epoch 6 - iter 12/128 - loss 0.35138986 - samples/sec: 60.79 - lr: 0.000030
2021-07-15 21:15:46,368 epoch 6 - iter 24/128 - loss 0.42503615 - samples/sec: 60.61 - lr: 0.000030
2021-07-15 21:15:52,759 epoch 6 - iter 36/128 - loss 0.47371881 - samples/sec: 60.10 - lr: 0.000030
2021-07-15 21:15:59,131 epoch 6 - iter 48/128 - loss 0.48651608 - samples/sec: 60.27 - lr: 0.000030
2021-07-15 21:16:05,511 epoch 6 - iter 60/128 - loss 0.48536583 - samples/sec: 60.19 - lr: 0.000030
2021-07-15 21:16:11,869 epoch 6 - iter 72/128 - loss 0.48552389 - samples/sec: 60.41 - lr: 0.000030
2021-07-15 21:16:18,256 epoch 6 - iter 84/128 - loss 0.48322575 - samples/sec: 60.13 - lr: 0.000030
2021-07-15 21:16:24,636 epoch 6 - iter 96/128 - loss 0.48387175 - samples/sec: 60.19 - lr: 0.000030
2021-07-15 21:16:31,028 epoch 6 - iter 108/128 - loss 0.48344289 - samples/sec: 60.08 - lr: 0.000030
2021-07-15 21:16:37,402 epoch 6 - iter 120/128 - loss 0.48360318 - samples/sec: 60.25 - lr: 0.000030
2021-07-15 21:16:41,351 ----------------------------------------------------------------------------------------------------
2021-07-15 21:16:41,352 EPOCH 6 done: loss 0.4755 - lr 0.0000300
2021-07-15 21:16:46,040 DEV : loss 0.28469523787498474 - score 0.9534
2021-07-15 21:16:46,102 BAD EPOCHS (no improvement): 2
2021-07-15 21:16:46,103 ----------------------------------------------------------------------------------------------------
2021-07-15 21:16:52,453 epoch 7 - iter 12/128 - loss 0.38331593 - samples/sec: 60.48 - lr: 0.000030
2021-07-15 21:16:58,855 epoch 7 - iter 24/128 - loss 0.44071502 - samples/sec: 59.99 - lr: 0.000030
2021-07-15 21:17:05,263 epoch 7 - iter 36/128 - loss 0.42060885 - samples/sec: 59.93 - lr: 0.000030
2021-07-15 21:17:11,648 epoch 7 - iter 48/128 - loss 0.43163727 - samples/sec: 60.15 - lr: 0.000030
2021-07-15 21:17:17,984 epoch 7 - iter 60/128 - loss 0.43948265 - samples/sec: 60.62 - lr: 0.000030
2021-07-15 21:17:24,345 epoch 7 - iter 72/128 - loss 0.42907735 - samples/sec: 60.37 - lr: 0.000030
2021-07-15 21:17:30,708 epoch 7 - iter 84/128 - loss 0.43404635 - samples/sec: 60.37 - lr: 0.000030
2021-07-15 21:17:37,071 epoch 7 - iter 96/128 - loss 0.44398082 - samples/sec: 60.36 - lr: 0.000030
2021-07-15 21:17:43,447 epoch 7 - iter 108/128 - loss 0.44286815 - samples/sec: 60.23 - lr: 0.000030
2021-07-15 21:17:49,838 epoch 7 - iter 120/128 - loss 0.46003746 - samples/sec: 60.09 - lr: 0.000030
2021-07-15 21:17:54,157 ----------------------------------------------------------------------------------------------------
2021-07-15 21:17:54,158 EPOCH 7 done: loss 0.4618 - lr 0.0000300
2021-07-15 21:17:58,842 DEV : loss 0.2846802771091461 - score 0.9556
2021-07-15 21:17:58,904 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:18:02,594 ----------------------------------------------------------------------------------------------------
2021-07-15 21:18:08,976 epoch 8 - iter 12/128 - loss 0.45691757 - samples/sec: 60.18 - lr: 0.000030
2021-07-15 21:18:15,392 epoch 8 - iter 24/128 - loss 0.44801624 - samples/sec: 59.86 - lr: 0.000030
2021-07-15 21:18:21,744 epoch 8 - iter 36/128 - loss 0.43345389 - samples/sec: 60.47 - lr: 0.000030
2021-07-15 21:18:28,080 epoch 8 - iter 48/128 - loss 0.41390703 - samples/sec: 60.62 - lr: 0.000030
2021-07-15 21:18:34,443 epoch 8 - iter 60/128 - loss 0.42341871 - samples/sec: 60.35 - lr: 0.000030
2021-07-15 21:18:40,814 epoch 8 - iter 72/128 - loss 0.42223549 - samples/sec: 60.29 - lr: 0.000030
2021-07-15 21:18:47,176 epoch 8 - iter 84/128 - loss 0.41593139 - samples/sec: 60.37 - lr: 0.000030
2021-07-15 21:18:53,538 epoch 8 - iter 96/128 - loss 0.41908463 - samples/sec: 60.37 - lr: 0.000030
2021-07-15 21:18:59,934 epoch 8 - iter 108/128 - loss 0.41852694 - samples/sec: 60.04 - lr: 0.000030
2021-07-15 21:19:06,330 epoch 8 - iter 120/128 - loss 0.40599425 - samples/sec: 60.05 - lr: 0.000030
2021-07-15 21:19:10,293 ----------------------------------------------------------------------------------------------------
2021-07-15 21:19:10,293 EPOCH 8 done: loss 0.4077 - lr 0.0000300
2021-07-15 21:19:14,992 DEV : loss 0.27967140078544617 - score 0.9562
2021-07-15 21:19:15,054 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:19:18,591 ----------------------------------------------------------------------------------------------------
2021-07-15 21:19:25,015 epoch 9 - iter 12/128 - loss 0.36082966 - samples/sec: 59.80 - lr: 0.000030
2021-07-15 21:19:31,406 epoch 9 - iter 24/128 - loss 0.37887349 - samples/sec: 60.09 - lr: 0.000030
2021-07-15 21:19:37,732 epoch 9 - iter 36/128 - loss 0.36749856 - samples/sec: 60.71 - lr: 0.000030
2021-07-15 21:19:44,106 epoch 9 - iter 48/128 - loss 0.37732117 - samples/sec: 60.25 - lr: 0.000030
2021-07-15 21:19:50,515 epoch 9 - iter 60/128 - loss 0.37117310 - samples/sec: 59.93 - lr: 0.000030
2021-07-15 21:19:56,895 epoch 9 - iter 72/128 - loss 0.37172717 - samples/sec: 60.20 - lr: 0.000030
2021-07-15 21:20:03,283 epoch 9 - iter 84/128 - loss 0.37809836 - samples/sec: 60.12 - lr: 0.000030
2021-07-15 21:20:09,655 epoch 9 - iter 96/128 - loss 0.37749202 - samples/sec: 60.27 - lr: 0.000030
2021-07-15 21:20:16,047 epoch 9 - iter 108/128 - loss 0.37067483 - samples/sec: 60.08 - lr: 0.000030
2021-07-15 21:20:22,434 epoch 9 - iter 120/128 - loss 0.38033068 - samples/sec: 60.13 - lr: 0.000030
2021-07-15 21:20:26,325 ----------------------------------------------------------------------------------------------------
2021-07-15 21:20:26,326 EPOCH 9 done: loss 0.3803 - lr 0.0000300
2021-07-15 21:20:31,018 DEV : loss 0.2760602831840515 - score 0.9563
2021-07-15 21:20:31,082 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:20:34,788 ----------------------------------------------------------------------------------------------------
2021-07-15 21:20:41,184 epoch 10 - iter 12/128 - loss 0.39056173 - samples/sec: 60.05 - lr: 0.000030
2021-07-15 21:20:47,579 epoch 10 - iter 24/128 - loss 0.37039268 - samples/sec: 60.06 - lr: 0.000030
2021-07-15 21:20:53,964 epoch 10 - iter 36/128 - loss 0.34286258 - samples/sec: 60.15 - lr: 0.000030
2021-07-15 21:21:00,319 epoch 10 - iter 48/128 - loss 0.35472094 - samples/sec: 60.44 - lr: 0.000030
2021-07-15 21:21:06,707 epoch 10 - iter 60/128 - loss 0.34919498 - samples/sec: 60.12 - lr: 0.000030
2021-07-15 21:21:13,067 epoch 10 - iter 72/128 - loss 0.34542427 - samples/sec: 60.39 - lr: 0.000030
2021-07-15 21:21:19,427 epoch 10 - iter 84/128 - loss 0.36253302 - samples/sec: 60.38 - lr: 0.000030
2021-07-15 21:21:25,818 epoch 10 - iter 96/128 - loss 0.35758818 - samples/sec: 60.09 - lr: 0.000030
2021-07-15 21:21:32,186 epoch 10 - iter 108/128 - loss 0.34979180 - samples/sec: 60.31 - lr: 0.000030
2021-07-15 21:21:38,526 epoch 10 - iter 120/128 - loss 0.34772188 - samples/sec: 60.57 - lr: 0.000030
2021-07-15 21:21:42,461 ----------------------------------------------------------------------------------------------------
2021-07-15 21:21:42,461 EPOCH 10 done: loss 0.3463 - lr 0.0000300
2021-07-15 21:21:47,550 DEV : loss 0.26314255595207214 - score 0.9589
2021-07-15 21:21:47,612 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:21:51,213 ----------------------------------------------------------------------------------------------------
2021-07-15 21:21:57,628 epoch 11 - iter 12/128 - loss 0.21631468 - samples/sec: 59.87 - lr: 0.000030
2021-07-15 21:22:03,989 epoch 11 - iter 24/128 - loss 0.26398701 - samples/sec: 60.38 - lr: 0.000030
2021-07-15 21:22:10,395 epoch 11 - iter 36/128 - loss 0.30239480 - samples/sec: 59.95 - lr: 0.000030
2021-07-15 21:22:16,830 epoch 11 - iter 48/128 - loss 0.29000451 - samples/sec: 59.68 - lr: 0.000030
2021-07-15 21:22:23,246 epoch 11 - iter 60/128 - loss 0.30616943 - samples/sec: 59.86 - lr: 0.000030
2021-07-15 21:22:29,656 epoch 11 - iter 72/128 - loss 0.30913709 - samples/sec: 59.92 - lr: 0.000030
2021-07-15 21:22:36,084 epoch 11 - iter 84/128 - loss 0.33397435 - samples/sec: 59.75 - lr: 0.000030
2021-07-15 21:22:42,548 epoch 11 - iter 96/128 - loss 0.33459667 - samples/sec: 59.42 - lr: 0.000030
2021-07-15 21:22:48,942 epoch 11 - iter 108/128 - loss 0.33927923 - samples/sec: 60.06 - lr: 0.000030
2021-07-15 21:22:55,371 epoch 11 - iter 120/128 - loss 0.34057651 - samples/sec: 59.74 - lr: 0.000030
2021-07-15 21:22:59,329 ----------------------------------------------------------------------------------------------------
2021-07-15 21:22:59,330 EPOCH 11 done: loss 0.3369 - lr 0.0000300
2021-07-15 21:23:04,023 DEV : loss 0.2680605947971344 - score 0.9559
2021-07-15 21:23:04,086 BAD EPOCHS (no improvement): 1
2021-07-15 21:23:04,087 ----------------------------------------------------------------------------------------------------
2021-07-15 21:23:10,486 epoch 12 - iter 12/128 - loss 0.34388319 - samples/sec: 60.01 - lr: 0.000030
2021-07-15 21:23:16,920 epoch 12 - iter 24/128 - loss 0.32859689 - samples/sec: 59.69 - lr: 0.000030
2021-07-15 21:23:23,352 epoch 12 - iter 36/128 - loss 0.35678093 - samples/sec: 59.71 - lr: 0.000030
2021-07-15 21:23:29,751 epoch 12 - iter 48/128 - loss 0.34926319 - samples/sec: 60.02 - lr: 0.000030
2021-07-15 21:23:36,160 epoch 12 - iter 60/128 - loss 0.34165366 - samples/sec: 59.93 - lr: 0.000030
2021-07-15 21:23:42,576 epoch 12 - iter 72/128 - loss 0.32266189 - samples/sec: 59.86 - lr: 0.000030
2021-07-15 21:23:48,982 epoch 12 - iter 84/128 - loss 0.31265196 - samples/sec: 59.96 - lr: 0.000030
2021-07-15 21:23:55,375 epoch 12 - iter 96/128 - loss 0.32267119 - samples/sec: 60.07 - lr: 0.000030
2021-07-15 21:24:01,827 epoch 12 - iter 108/128 - loss 0.32818315 - samples/sec: 59.53 - lr: 0.000030
2021-07-15 21:24:08,240 epoch 12 - iter 120/128 - loss 0.31833176 - samples/sec: 59.89 - lr: 0.000030
2021-07-15 21:24:12,202 ----------------------------------------------------------------------------------------------------
2021-07-15 21:24:12,202 EPOCH 12 done: loss 0.3179 - lr 0.0000300
2021-07-15 21:24:16,909 DEV : loss 0.2643941044807434 - score 0.9519
2021-07-15 21:24:16,972 BAD EPOCHS (no improvement): 2
2021-07-15 21:24:16,973 ----------------------------------------------------------------------------------------------------
2021-07-15 21:24:23,403 epoch 13 - iter 12/128 - loss 0.37928107 - samples/sec: 59.72 - lr: 0.000030
2021-07-15 21:24:29,831 epoch 13 - iter 24/128 - loss 0.31285217 - samples/sec: 59.75 - lr: 0.000030
2021-07-15 21:24:36,256 epoch 13 - iter 36/128 - loss 0.31909010 - samples/sec: 59.78 - lr: 0.000030
2021-07-15 21:24:42,648 epoch 13 - iter 48/128 - loss 0.30768410 - samples/sec: 60.08 - lr: 0.000030
2021-07-15 21:24:49,059 epoch 13 - iter 60/128 - loss 0.31148880 - samples/sec: 59.91 - lr: 0.000030
2021-07-15 21:24:55,471 epoch 13 - iter 72/128 - loss 0.30752420 - samples/sec: 59.89 - lr: 0.000030
2021-07-15 21:25:01,938 epoch 13 - iter 84/128 - loss 0.31396476 - samples/sec: 59.39 - lr: 0.000030
2021-07-15 21:25:08,327 epoch 13 - iter 96/128 - loss 0.31191840 - samples/sec: 60.12 - lr: 0.000030
2021-07-15 21:25:14,730 epoch 13 - iter 108/128 - loss 0.30501438 - samples/sec: 59.98 - lr: 0.000030
2021-07-15 21:25:21,164 epoch 13 - iter 120/128 - loss 0.30430425 - samples/sec: 59.69 - lr: 0.000030
2021-07-15 21:25:25,138 ----------------------------------------------------------------------------------------------------
2021-07-15 21:25:25,138 EPOCH 13 done: loss 0.3055 - lr 0.0000300
2021-07-15 21:25:30,249 DEV : loss 0.2616419494152069 - score 0.9577
2021-07-15 21:25:30,312 BAD EPOCHS (no improvement): 3
2021-07-15 21:25:30,313 ----------------------------------------------------------------------------------------------------
2021-07-15 21:25:36,703 epoch 14 - iter 12/128 - loss 0.35023701 - samples/sec: 60.10 - lr: 0.000030
2021-07-15 21:25:43,135 epoch 14 - iter 24/128 - loss 0.29805799 - samples/sec: 59.71 - lr: 0.000030
2021-07-15 21:25:49,576 epoch 14 - iter 36/128 - loss 0.28467827 - samples/sec: 59.63 - lr: 0.000030
2021-07-15 21:25:55,999 epoch 14 - iter 48/128 - loss 0.29188794 - samples/sec: 59.80 - lr: 0.000030
2021-07-15 21:26:02,439 epoch 14 - iter 60/128 - loss 0.30163713 - samples/sec: 59.63 - lr: 0.000030
2021-07-15 21:26:08,871 epoch 14 - iter 72/128 - loss 0.31069110 - samples/sec: 59.71 - lr: 0.000030
2021-07-15 21:26:15,289 epoch 14 - iter 84/128 - loss 0.30702853 - samples/sec: 59.84 - lr: 0.000030
2021-07-15 21:26:21,702 epoch 14 - iter 96/128 - loss 0.30748472 - samples/sec: 59.90 - lr: 0.000030
2021-07-15 21:26:28,120 epoch 14 - iter 108/128 - loss 0.30310510 - samples/sec: 59.84 - lr: 0.000030
2021-07-15 21:26:34,559 epoch 14 - iter 120/128 - loss 0.29884671 - samples/sec: 59.64 - lr: 0.000030
2021-07-15 21:26:38,546 ----------------------------------------------------------------------------------------------------
2021-07-15 21:26:38,546 EPOCH 14 done: loss 0.2989 - lr 0.0000300
2021-07-15 21:26:43,243 DEV : loss 0.25873178243637085 - score 0.9587
Epoch    14: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 21:26:43,306 BAD EPOCHS (no improvement): 4
2021-07-15 21:26:43,306 ----------------------------------------------------------------------------------------------------
2021-07-15 21:26:49,714 epoch 15 - iter 12/128 - loss 0.31646590 - samples/sec: 59.94 - lr: 0.000015
2021-07-15 21:26:56,144 epoch 15 - iter 24/128 - loss 0.29130083 - samples/sec: 59.73 - lr: 0.000015
2021-07-15 21:27:02,556 epoch 15 - iter 36/128 - loss 0.28688817 - samples/sec: 59.90 - lr: 0.000015
2021-07-15 21:27:08,929 epoch 15 - iter 48/128 - loss 0.28484338 - samples/sec: 60.26 - lr: 0.000015
2021-07-15 21:27:15,351 epoch 15 - iter 60/128 - loss 0.27917329 - samples/sec: 59.81 - lr: 0.000015
2021-07-15 21:27:21,795 epoch 15 - iter 72/128 - loss 0.27888741 - samples/sec: 59.60 - lr: 0.000015
2021-07-15 21:27:28,212 epoch 15 - iter 84/128 - loss 0.27917988 - samples/sec: 59.85 - lr: 0.000015
2021-07-15 21:27:34,606 epoch 15 - iter 96/128 - loss 0.28125785 - samples/sec: 60.07 - lr: 0.000015
2021-07-15 21:27:40,998 epoch 15 - iter 108/128 - loss 0.28134509 - samples/sec: 60.08 - lr: 0.000015
2021-07-15 21:27:47,423 epoch 15 - iter 120/128 - loss 0.27840428 - samples/sec: 59.78 - lr: 0.000015
2021-07-15 21:27:51,357 ----------------------------------------------------------------------------------------------------
2021-07-15 21:27:51,358 EPOCH 15 done: loss 0.2726 - lr 0.0000150
2021-07-15 21:27:56,058 DEV : loss 0.25612306594848633 - score 0.9589
2021-07-15 21:27:56,123 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:27:59,700 ----------------------------------------------------------------------------------------------------
2021-07-15 21:28:06,122 epoch 16 - iter 12/128 - loss 0.24642936 - samples/sec: 59.80 - lr: 0.000015
2021-07-15 21:28:12,544 epoch 16 - iter 24/128 - loss 0.26013885 - samples/sec: 59.81 - lr: 0.000015
2021-07-15 21:28:18,992 epoch 16 - iter 36/128 - loss 0.25715270 - samples/sec: 59.57 - lr: 0.000015
2021-07-15 21:28:25,383 epoch 16 - iter 48/128 - loss 0.26738400 - samples/sec: 60.09 - lr: 0.000015
2021-07-15 21:28:31,808 epoch 16 - iter 60/128 - loss 0.25599539 - samples/sec: 59.78 - lr: 0.000015
2021-07-15 21:28:38,256 epoch 16 - iter 72/128 - loss 0.24951388 - samples/sec: 59.57 - lr: 0.000015
2021-07-15 21:28:44,684 epoch 16 - iter 84/128 - loss 0.25077929 - samples/sec: 59.74 - lr: 0.000015
2021-07-15 21:28:51,104 epoch 16 - iter 96/128 - loss 0.25366443 - samples/sec: 59.82 - lr: 0.000015
2021-07-15 21:28:57,495 epoch 16 - iter 108/128 - loss 0.26469041 - samples/sec: 60.10 - lr: 0.000015
2021-07-15 21:29:03,934 epoch 16 - iter 120/128 - loss 0.26444697 - samples/sec: 59.65 - lr: 0.000015
2021-07-15 21:29:07,918 ----------------------------------------------------------------------------------------------------
2021-07-15 21:29:07,919 EPOCH 16 done: loss 0.2652 - lr 0.0000150
2021-07-15 21:29:12,627 DEV : loss 0.26204270124435425 - score 0.9572
2021-07-15 21:29:12,690 BAD EPOCHS (no improvement): 1
2021-07-15 21:29:12,690 ----------------------------------------------------------------------------------------------------
2021-07-15 21:29:19,110 epoch 17 - iter 12/128 - loss 0.19841510 - samples/sec: 59.83 - lr: 0.000015
2021-07-15 21:29:25,539 epoch 17 - iter 24/128 - loss 0.20837681 - samples/sec: 59.73 - lr: 0.000015
2021-07-15 21:29:31,930 epoch 17 - iter 36/128 - loss 0.22637832 - samples/sec: 60.10 - lr: 0.000015
2021-07-15 21:29:38,354 epoch 17 - iter 48/128 - loss 0.22328684 - samples/sec: 59.79 - lr: 0.000015
2021-07-15 21:29:44,811 epoch 17 - iter 60/128 - loss 0.24195627 - samples/sec: 59.47 - lr: 0.000015
2021-07-15 21:29:51,691 epoch 17 - iter 72/128 - loss 0.24166733 - samples/sec: 55.82 - lr: 0.000015
2021-07-15 21:29:58,134 epoch 17 - iter 84/128 - loss 0.24480171 - samples/sec: 59.62 - lr: 0.000015
2021-07-15 21:30:04,551 epoch 17 - iter 96/128 - loss 0.23996114 - samples/sec: 59.84 - lr: 0.000015
2021-07-15 21:30:10,917 epoch 17 - iter 108/128 - loss 0.24428744 - samples/sec: 60.33 - lr: 0.000015
2021-07-15 21:30:17,248 epoch 17 - iter 120/128 - loss 0.25175270 - samples/sec: 60.67 - lr: 0.000015
2021-07-15 21:30:21,170 ----------------------------------------------------------------------------------------------------
2021-07-15 21:30:21,170 EPOCH 17 done: loss 0.2477 - lr 0.0000150
2021-07-15 21:30:25,866 DEV : loss 0.2594434320926666 - score 0.9579
2021-07-15 21:30:25,929 BAD EPOCHS (no improvement): 2
2021-07-15 21:30:25,930 ----------------------------------------------------------------------------------------------------
2021-07-15 21:30:32,287 epoch 18 - iter 12/128 - loss 0.19227411 - samples/sec: 60.41 - lr: 0.000015
2021-07-15 21:30:38,691 epoch 18 - iter 24/128 - loss 0.22643944 - samples/sec: 59.97 - lr: 0.000015
2021-07-15 21:30:45,079 epoch 18 - iter 36/128 - loss 0.22371597 - samples/sec: 60.12 - lr: 0.000015
2021-07-15 21:30:51,420 epoch 18 - iter 48/128 - loss 0.21384960 - samples/sec: 60.57 - lr: 0.000015
2021-07-15 21:30:57,783 epoch 18 - iter 60/128 - loss 0.21451194 - samples/sec: 60.36 - lr: 0.000015
2021-07-15 21:31:04,182 epoch 18 - iter 72/128 - loss 0.22850914 - samples/sec: 60.02 - lr: 0.000015
2021-07-15 21:31:10,630 epoch 18 - iter 84/128 - loss 0.23113010 - samples/sec: 59.56 - lr: 0.000015
2021-07-15 21:31:17,060 epoch 18 - iter 96/128 - loss 0.23554714 - samples/sec: 59.73 - lr: 0.000015
2021-07-15 21:31:23,488 epoch 18 - iter 108/128 - loss 0.24414210 - samples/sec: 59.75 - lr: 0.000015
2021-07-15 21:31:29,899 epoch 18 - iter 120/128 - loss 0.23971455 - samples/sec: 59.90 - lr: 0.000015
2021-07-15 21:31:33,870 ----------------------------------------------------------------------------------------------------
2021-07-15 21:31:33,870 EPOCH 18 done: loss 0.2410 - lr 0.0000150
2021-07-15 21:31:38,557 DEV : loss 0.26515108346939087 - score 0.9605
2021-07-15 21:31:38,621 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:31:42,203 ----------------------------------------------------------------------------------------------------
2021-07-15 21:31:48,630 epoch 19 - iter 12/128 - loss 0.31066277 - samples/sec: 59.76 - lr: 0.000015
2021-07-15 21:31:55,074 epoch 19 - iter 24/128 - loss 0.24436926 - samples/sec: 59.60 - lr: 0.000015
2021-07-15 21:32:01,479 epoch 19 - iter 36/128 - loss 0.23726570 - samples/sec: 59.96 - lr: 0.000015
2021-07-15 21:32:07,890 epoch 19 - iter 48/128 - loss 0.23105308 - samples/sec: 59.91 - lr: 0.000015
2021-07-15 21:32:14,294 epoch 19 - iter 60/128 - loss 0.23865538 - samples/sec: 59.98 - lr: 0.000015
2021-07-15 21:32:20,736 epoch 19 - iter 72/128 - loss 0.24621627 - samples/sec: 59.62 - lr: 0.000015
2021-07-15 21:32:27,198 epoch 19 - iter 84/128 - loss 0.24088818 - samples/sec: 59.43 - lr: 0.000015
2021-07-15 21:32:33,626 epoch 19 - iter 96/128 - loss 0.23520198 - samples/sec: 59.75 - lr: 0.000015
2021-07-15 21:32:40,038 epoch 19 - iter 108/128 - loss 0.23705556 - samples/sec: 59.90 - lr: 0.000015
2021-07-15 21:32:46,506 epoch 19 - iter 120/128 - loss 0.23350800 - samples/sec: 59.38 - lr: 0.000015
2021-07-15 21:32:50,475 ----------------------------------------------------------------------------------------------------
2021-07-15 21:32:50,475 EPOCH 19 done: loss 0.2396 - lr 0.0000150
2021-07-15 21:32:55,177 DEV : loss 0.2633335590362549 - score 0.9609
2021-07-15 21:32:55,240 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:32:58,840 ----------------------------------------------------------------------------------------------------
2021-07-15 21:33:05,207 epoch 20 - iter 12/128 - loss 0.23647984 - samples/sec: 60.32 - lr: 0.000015
2021-07-15 21:33:11,608 epoch 20 - iter 24/128 - loss 0.24221988 - samples/sec: 60.00 - lr: 0.000015
2021-07-15 21:33:18,004 epoch 20 - iter 36/128 - loss 0.22215932 - samples/sec: 60.05 - lr: 0.000015
2021-07-15 21:33:24,378 epoch 20 - iter 48/128 - loss 0.22543943 - samples/sec: 60.25 - lr: 0.000015
2021-07-15 21:33:30,752 epoch 20 - iter 60/128 - loss 0.22646794 - samples/sec: 60.25 - lr: 0.000015
2021-07-15 21:33:37,163 epoch 20 - iter 72/128 - loss 0.22549401 - samples/sec: 59.91 - lr: 0.000015
2021-07-15 21:33:43,993 epoch 20 - iter 84/128 - loss 0.23116139 - samples/sec: 56.24 - lr: 0.000015
2021-07-15 21:33:50,372 epoch 20 - iter 96/128 - loss 0.24001882 - samples/sec: 60.20 - lr: 0.000015
2021-07-15 21:33:56,783 epoch 20 - iter 108/128 - loss 0.23539714 - samples/sec: 59.91 - lr: 0.000015
2021-07-15 21:34:03,203 epoch 20 - iter 120/128 - loss 0.23552797 - samples/sec: 59.83 - lr: 0.000015
2021-07-15 21:34:07,152 ----------------------------------------------------------------------------------------------------
2021-07-15 21:34:07,152 EPOCH 20 done: loss 0.2343 - lr 0.0000150
2021-07-15 21:34:11,847 DEV : loss 0.2624098062515259 - score 0.959
2021-07-15 21:34:11,913 BAD EPOCHS (no improvement): 1
2021-07-15 21:34:11,913 ----------------------------------------------------------------------------------------------------
2021-07-15 21:34:18,310 epoch 21 - iter 12/128 - loss 0.17882675 - samples/sec: 60.04 - lr: 0.000015
2021-07-15 21:34:24,712 epoch 21 - iter 24/128 - loss 0.17946943 - samples/sec: 59.98 - lr: 0.000015
2021-07-15 21:34:31,138 epoch 21 - iter 36/128 - loss 0.18482956 - samples/sec: 59.77 - lr: 0.000015
2021-07-15 21:34:37,559 epoch 21 - iter 48/128 - loss 0.19362402 - samples/sec: 59.82 - lr: 0.000015
2021-07-15 21:34:43,935 epoch 21 - iter 60/128 - loss 0.20297172 - samples/sec: 60.24 - lr: 0.000015
2021-07-15 21:34:50,327 epoch 21 - iter 72/128 - loss 0.20217282 - samples/sec: 60.08 - lr: 0.000015
2021-07-15 21:34:56,762 epoch 21 - iter 84/128 - loss 0.20169906 - samples/sec: 59.68 - lr: 0.000015
2021-07-15 21:35:03,226 epoch 21 - iter 96/128 - loss 0.20378418 - samples/sec: 59.41 - lr: 0.000015
2021-07-15 21:35:09,655 epoch 21 - iter 108/128 - loss 0.20493914 - samples/sec: 59.74 - lr: 0.000015
2021-07-15 21:35:16,083 epoch 21 - iter 120/128 - loss 0.20997414 - samples/sec: 59.75 - lr: 0.000015
2021-07-15 21:35:20,015 ----------------------------------------------------------------------------------------------------
2021-07-15 21:35:20,015 EPOCH 21 done: loss 0.2134 - lr 0.0000150
2021-07-15 21:35:24,704 DEV : loss 0.26557663083076477 - score 0.9566
2021-07-15 21:35:24,766 BAD EPOCHS (no improvement): 2
2021-07-15 21:35:24,767 ----------------------------------------------------------------------------------------------------
2021-07-15 21:35:31,145 epoch 22 - iter 12/128 - loss 0.21536517 - samples/sec: 60.21 - lr: 0.000015
2021-07-15 21:35:37,565 epoch 22 - iter 24/128 - loss 0.22812508 - samples/sec: 59.82 - lr: 0.000015
2021-07-15 21:35:44,024 epoch 22 - iter 36/128 - loss 0.23046927 - samples/sec: 59.46 - lr: 0.000015
2021-07-15 21:35:50,454 epoch 22 - iter 48/128 - loss 0.22039572 - samples/sec: 59.74 - lr: 0.000015
2021-07-15 21:35:56,903 epoch 22 - iter 60/128 - loss 0.21634365 - samples/sec: 59.55 - lr: 0.000015
2021-07-15 21:36:03,348 epoch 22 - iter 72/128 - loss 0.21633039 - samples/sec: 59.59 - lr: 0.000015
2021-07-15 21:36:09,803 epoch 22 - iter 84/128 - loss 0.22009338 - samples/sec: 59.49 - lr: 0.000015
2021-07-15 21:36:16,195 epoch 22 - iter 96/128 - loss 0.22322244 - samples/sec: 60.09 - lr: 0.000015
2021-07-15 21:36:22,647 epoch 22 - iter 108/128 - loss 0.22389260 - samples/sec: 59.53 - lr: 0.000015
2021-07-15 21:36:29,086 epoch 22 - iter 120/128 - loss 0.21606430 - samples/sec: 59.65 - lr: 0.000015
2021-07-15 21:36:33,076 ----------------------------------------------------------------------------------------------------
2021-07-15 21:36:33,076 EPOCH 22 done: loss 0.2151 - lr 0.0000150
2021-07-15 21:36:37,772 DEV : loss 0.2617283761501312 - score 0.9598
2021-07-15 21:36:37,835 BAD EPOCHS (no improvement): 3
2021-07-15 21:36:37,836 ----------------------------------------------------------------------------------------------------
2021-07-15 21:36:44,233 epoch 23 - iter 12/128 - loss 0.19107173 - samples/sec: 60.04 - lr: 0.000015
2021-07-15 21:36:50,568 epoch 23 - iter 24/128 - loss 0.23165523 - samples/sec: 60.62 - lr: 0.000015
2021-07-15 21:36:56,940 epoch 23 - iter 36/128 - loss 0.20985252 - samples/sec: 60.28 - lr: 0.000015
2021-07-15 21:37:03,332 epoch 23 - iter 48/128 - loss 0.21084594 - samples/sec: 60.09 - lr: 0.000015
2021-07-15 21:37:10,096 epoch 23 - iter 60/128 - loss 0.22635686 - samples/sec: 56.78 - lr: 0.000015
2021-07-15 21:37:16,496 epoch 23 - iter 72/128 - loss 0.22107483 - samples/sec: 60.01 - lr: 0.000015
2021-07-15 21:37:22,855 epoch 23 - iter 84/128 - loss 0.21697527 - samples/sec: 60.39 - lr: 0.000015
2021-07-15 21:37:29,250 epoch 23 - iter 96/128 - loss 0.21802834 - samples/sec: 60.06 - lr: 0.000015
2021-07-15 21:37:35,714 epoch 23 - iter 108/128 - loss 0.21488492 - samples/sec: 59.42 - lr: 0.000015
2021-07-15 21:37:42,167 epoch 23 - iter 120/128 - loss 0.21933026 - samples/sec: 59.51 - lr: 0.000015
2021-07-15 21:37:46,134 ----------------------------------------------------------------------------------------------------
2021-07-15 21:37:46,134 EPOCH 23 done: loss 0.2197 - lr 0.0000150
2021-07-15 21:37:50,839 DEV : loss 0.2625774145126343 - score 0.9618
2021-07-15 21:37:50,903 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:37:54,575 ----------------------------------------------------------------------------------------------------
2021-07-15 21:38:00,999 epoch 24 - iter 12/128 - loss 0.11982975 - samples/sec: 59.79 - lr: 0.000015
2021-07-15 21:38:07,472 epoch 24 - iter 24/128 - loss 0.20143531 - samples/sec: 59.34 - lr: 0.000015
2021-07-15 21:38:13,903 epoch 24 - iter 36/128 - loss 0.20998259 - samples/sec: 59.72 - lr: 0.000015
2021-07-15 21:38:20,340 epoch 24 - iter 48/128 - loss 0.20655955 - samples/sec: 59.66 - lr: 0.000015
2021-07-15 21:38:26,778 epoch 24 - iter 60/128 - loss 0.20531037 - samples/sec: 59.66 - lr: 0.000015
2021-07-15 21:38:33,185 epoch 24 - iter 72/128 - loss 0.21103970 - samples/sec: 59.94 - lr: 0.000015
2021-07-15 21:38:39,647 epoch 24 - iter 84/128 - loss 0.21329237 - samples/sec: 59.44 - lr: 0.000015
2021-07-15 21:38:46,063 epoch 24 - iter 96/128 - loss 0.20675881 - samples/sec: 59.86 - lr: 0.000015
2021-07-15 21:38:52,488 epoch 24 - iter 108/128 - loss 0.20152565 - samples/sec: 59.78 - lr: 0.000015
2021-07-15 21:38:58,928 epoch 24 - iter 120/128 - loss 0.20516824 - samples/sec: 59.63 - lr: 0.000015
2021-07-15 21:39:02,919 ----------------------------------------------------------------------------------------------------
2021-07-15 21:39:02,920 EPOCH 24 done: loss 0.2038 - lr 0.0000150
2021-07-15 21:39:07,614 DEV : loss 0.26246199011802673 - score 0.9585
2021-07-15 21:39:07,678 BAD EPOCHS (no improvement): 1
2021-07-15 21:39:07,678 ----------------------------------------------------------------------------------------------------
2021-07-15 21:39:14,050 epoch 25 - iter 12/128 - loss 0.25594638 - samples/sec: 60.27 - lr: 0.000015
2021-07-15 21:39:20,416 epoch 25 - iter 24/128 - loss 0.21586856 - samples/sec: 60.32 - lr: 0.000015
2021-07-15 21:39:26,774 epoch 25 - iter 36/128 - loss 0.20953585 - samples/sec: 60.41 - lr: 0.000015
2021-07-15 21:39:33,177 epoch 25 - iter 48/128 - loss 0.21826275 - samples/sec: 59.98 - lr: 0.000015
2021-07-15 21:39:39,540 epoch 25 - iter 60/128 - loss 0.20229783 - samples/sec: 60.36 - lr: 0.000015
2021-07-15 21:39:45,918 epoch 25 - iter 72/128 - loss 0.20285721 - samples/sec: 60.21 - lr: 0.000015
2021-07-15 21:39:52,275 epoch 25 - iter 84/128 - loss 0.19782839 - samples/sec: 60.41 - lr: 0.000015
2021-07-15 21:39:58,647 epoch 25 - iter 96/128 - loss 0.20017159 - samples/sec: 60.27 - lr: 0.000015
2021-07-15 21:40:05,120 epoch 25 - iter 108/128 - loss 0.19881067 - samples/sec: 59.34 - lr: 0.000015
2021-07-15 21:40:11,548 epoch 25 - iter 120/128 - loss 0.19939843 - samples/sec: 59.75 - lr: 0.000015
2021-07-15 21:40:15,529 ----------------------------------------------------------------------------------------------------
2021-07-15 21:40:15,529 EPOCH 25 done: loss 0.1965 - lr 0.0000150
2021-07-15 21:40:20,218 DEV : loss 0.2575624883174896 - score 0.9579
2021-07-15 21:40:20,281 BAD EPOCHS (no improvement): 2
2021-07-15 21:40:20,281 ----------------------------------------------------------------------------------------------------
2021-07-15 21:40:26,738 epoch 26 - iter 12/128 - loss 0.20115122 - samples/sec: 59.48 - lr: 0.000015
2021-07-15 21:40:33,158 epoch 26 - iter 24/128 - loss 0.21990755 - samples/sec: 59.82 - lr: 0.000015
2021-07-15 21:40:39,602 epoch 26 - iter 36/128 - loss 0.22416194 - samples/sec: 59.60 - lr: 0.000015
2021-07-15 21:40:46,043 epoch 26 - iter 48/128 - loss 0.20791969 - samples/sec: 59.63 - lr: 0.000015
2021-07-15 21:40:52,451 epoch 26 - iter 60/128 - loss 0.20564814 - samples/sec: 59.94 - lr: 0.000015
2021-07-15 21:40:58,826 epoch 26 - iter 72/128 - loss 0.19953283 - samples/sec: 60.25 - lr: 0.000015
2021-07-15 21:41:05,269 epoch 26 - iter 84/128 - loss 0.20095619 - samples/sec: 59.61 - lr: 0.000015
2021-07-15 21:41:11,668 epoch 26 - iter 96/128 - loss 0.19878911 - samples/sec: 60.02 - lr: 0.000015
2021-07-15 21:41:18,114 epoch 26 - iter 108/128 - loss 0.19658422 - samples/sec: 59.58 - lr: 0.000015
2021-07-15 21:41:24,567 epoch 26 - iter 120/128 - loss 0.19480804 - samples/sec: 59.52 - lr: 0.000015
2021-07-15 21:41:28,561 ----------------------------------------------------------------------------------------------------
2021-07-15 21:41:28,561 EPOCH 26 done: loss 0.1938 - lr 0.0000150
2021-07-15 21:41:33,663 DEV : loss 0.2648904323577881 - score 0.9589
2021-07-15 21:41:33,727 BAD EPOCHS (no improvement): 3
2021-07-15 21:41:33,727 ----------------------------------------------------------------------------------------------------
2021-07-15 21:41:40,181 epoch 27 - iter 12/128 - loss 0.16676031 - samples/sec: 59.51 - lr: 0.000015
2021-07-15 21:41:46,628 epoch 27 - iter 24/128 - loss 0.17442525 - samples/sec: 59.57 - lr: 0.000015
2021-07-15 21:41:53,063 epoch 27 - iter 36/128 - loss 0.21369150 - samples/sec: 59.69 - lr: 0.000015
2021-07-15 21:41:59,490 epoch 27 - iter 48/128 - loss 0.20874628 - samples/sec: 59.75 - lr: 0.000015
2021-07-15 21:42:05,934 epoch 27 - iter 60/128 - loss 0.20030530 - samples/sec: 59.60 - lr: 0.000015
2021-07-15 21:42:12,375 epoch 27 - iter 72/128 - loss 0.20653171 - samples/sec: 59.62 - lr: 0.000015
2021-07-15 21:42:18,842 epoch 27 - iter 84/128 - loss 0.19978474 - samples/sec: 59.39 - lr: 0.000015
2021-07-15 21:42:25,275 epoch 27 - iter 96/128 - loss 0.20332535 - samples/sec: 59.70 - lr: 0.000015
2021-07-15 21:42:31,700 epoch 27 - iter 108/128 - loss 0.20060880 - samples/sec: 59.78 - lr: 0.000015
2021-07-15 21:42:38,114 epoch 27 - iter 120/128 - loss 0.19449105 - samples/sec: 59.88 - lr: 0.000015
2021-07-15 21:42:42,102 ----------------------------------------------------------------------------------------------------
2021-07-15 21:42:42,102 EPOCH 27 done: loss 0.1958 - lr 0.0000150
2021-07-15 21:42:46,792 DEV : loss 0.2642911374568939 - score 0.9588
Epoch    27: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 21:42:46,855 BAD EPOCHS (no improvement): 4
2021-07-15 21:42:46,856 ----------------------------------------------------------------------------------------------------
2021-07-15 21:42:53,276 epoch 28 - iter 12/128 - loss 0.14852423 - samples/sec: 59.82 - lr: 0.000008
2021-07-15 21:42:59,743 epoch 28 - iter 24/128 - loss 0.16429426 - samples/sec: 59.39 - lr: 0.000008
2021-07-15 21:43:06,179 epoch 28 - iter 36/128 - loss 0.16139695 - samples/sec: 59.68 - lr: 0.000008
2021-07-15 21:43:12,623 epoch 28 - iter 48/128 - loss 0.17157938 - samples/sec: 59.59 - lr: 0.000008
2021-07-15 21:43:19,063 epoch 28 - iter 60/128 - loss 0.17704015 - samples/sec: 59.64 - lr: 0.000008
2021-07-15 21:43:25,495 epoch 28 - iter 72/128 - loss 0.17893785 - samples/sec: 59.70 - lr: 0.000008
2021-07-15 21:43:31,916 epoch 28 - iter 84/128 - loss 0.17775840 - samples/sec: 59.82 - lr: 0.000008
2021-07-15 21:43:38,370 epoch 28 - iter 96/128 - loss 0.17464950 - samples/sec: 59.50 - lr: 0.000008
2021-07-15 21:43:44,819 epoch 28 - iter 108/128 - loss 0.17967659 - samples/sec: 59.55 - lr: 0.000008
2021-07-15 21:43:51,271 epoch 28 - iter 120/128 - loss 0.18083118 - samples/sec: 59.53 - lr: 0.000008
2021-07-15 21:43:55,237 ----------------------------------------------------------------------------------------------------
2021-07-15 21:43:55,237 EPOCH 28 done: loss 0.1846 - lr 0.0000075
2021-07-15 21:43:59,943 DEV : loss 0.2647615075111389 - score 0.9603
2021-07-15 21:44:00,006 BAD EPOCHS (no improvement): 1
2021-07-15 21:44:00,006 ----------------------------------------------------------------------------------------------------
2021-07-15 21:44:06,459 epoch 29 - iter 12/128 - loss 0.16611872 - samples/sec: 59.52 - lr: 0.000008
2021-07-15 21:44:12,888 epoch 29 - iter 24/128 - loss 0.15751251 - samples/sec: 59.74 - lr: 0.000008
2021-07-15 21:44:19,326 epoch 29 - iter 36/128 - loss 0.15941023 - samples/sec: 59.65 - lr: 0.000008
2021-07-15 21:44:25,785 epoch 29 - iter 48/128 - loss 0.18149702 - samples/sec: 59.47 - lr: 0.000008
2021-07-15 21:44:32,239 epoch 29 - iter 60/128 - loss 0.18004463 - samples/sec: 59.50 - lr: 0.000008
2021-07-15 21:44:38,656 epoch 29 - iter 72/128 - loss 0.18202681 - samples/sec: 59.86 - lr: 0.000008
2021-07-15 21:44:45,106 epoch 29 - iter 84/128 - loss 0.17601511 - samples/sec: 59.54 - lr: 0.000008
2021-07-15 21:44:51,560 epoch 29 - iter 96/128 - loss 0.17074288 - samples/sec: 59.51 - lr: 0.000008
2021-07-15 21:44:57,999 epoch 29 - iter 108/128 - loss 0.16949657 - samples/sec: 59.64 - lr: 0.000008
2021-07-15 21:45:04,422 epoch 29 - iter 120/128 - loss 0.17122099 - samples/sec: 59.80 - lr: 0.000008
2021-07-15 21:45:08,410 ----------------------------------------------------------------------------------------------------
2021-07-15 21:45:08,411 EPOCH 29 done: loss 0.1720 - lr 0.0000075
2021-07-15 21:45:13,507 DEV : loss 0.26526278257369995 - score 0.9604
2021-07-15 21:45:13,570 BAD EPOCHS (no improvement): 2
2021-07-15 21:45:13,570 ----------------------------------------------------------------------------------------------------
2021-07-15 21:45:19,986 epoch 30 - iter 12/128 - loss 0.16420166 - samples/sec: 59.86 - lr: 0.000008
2021-07-15 21:45:26,425 epoch 30 - iter 24/128 - loss 0.16916371 - samples/sec: 59.65 - lr: 0.000008
2021-07-15 21:45:32,860 epoch 30 - iter 36/128 - loss 0.15247930 - samples/sec: 59.68 - lr: 0.000008
2021-07-15 21:45:39,305 epoch 30 - iter 48/128 - loss 0.15908361 - samples/sec: 59.59 - lr: 0.000008
2021-07-15 21:45:45,708 epoch 30 - iter 60/128 - loss 0.15908736 - samples/sec: 59.98 - lr: 0.000008
2021-07-15 21:45:52,123 epoch 30 - iter 72/128 - loss 0.15438149 - samples/sec: 59.87 - lr: 0.000008
2021-07-15 21:45:58,563 epoch 30 - iter 84/128 - loss 0.15704901 - samples/sec: 59.63 - lr: 0.000008
2021-07-15 21:46:05,028 epoch 30 - iter 96/128 - loss 0.15965907 - samples/sec: 59.41 - lr: 0.000008
2021-07-15 21:46:11,459 epoch 30 - iter 108/128 - loss 0.16273020 - samples/sec: 59.72 - lr: 0.000008
2021-07-15 21:46:17,882 epoch 30 - iter 120/128 - loss 0.16517219 - samples/sec: 59.80 - lr: 0.000008
2021-07-15 21:46:21,866 ----------------------------------------------------------------------------------------------------
2021-07-15 21:46:21,866 EPOCH 30 done: loss 0.1732 - lr 0.0000075
2021-07-15 21:46:26,559 DEV : loss 0.2684438228607178 - score 0.9594
2021-07-15 21:46:26,622 BAD EPOCHS (no improvement): 3
2021-07-15 21:46:26,622 ----------------------------------------------------------------------------------------------------
2021-07-15 21:46:33,023 epoch 31 - iter 12/128 - loss 0.19322906 - samples/sec: 60.01 - lr: 0.000008
2021-07-15 21:46:39,452 epoch 31 - iter 24/128 - loss 0.19122853 - samples/sec: 59.73 - lr: 0.000008
2021-07-15 21:46:45,886 epoch 31 - iter 36/128 - loss 0.18724854 - samples/sec: 59.69 - lr: 0.000008
2021-07-15 21:46:52,347 epoch 31 - iter 48/128 - loss 0.18463566 - samples/sec: 59.44 - lr: 0.000008
2021-07-15 21:46:58,756 epoch 31 - iter 60/128 - loss 0.17827110 - samples/sec: 59.93 - lr: 0.000008
2021-07-15 21:47:05,207 epoch 31 - iter 72/128 - loss 0.17653979 - samples/sec: 59.53 - lr: 0.000008
2021-07-15 21:47:11,663 epoch 31 - iter 84/128 - loss 0.18253137 - samples/sec: 59.49 - lr: 0.000008
2021-07-15 21:47:18,094 epoch 31 - iter 96/128 - loss 0.18046018 - samples/sec: 59.72 - lr: 0.000008
2021-07-15 21:47:24,543 epoch 31 - iter 108/128 - loss 0.18271322 - samples/sec: 59.56 - lr: 0.000008
2021-07-15 21:47:30,987 epoch 31 - iter 120/128 - loss 0.17960243 - samples/sec: 59.60 - lr: 0.000008
2021-07-15 21:47:34,957 ----------------------------------------------------------------------------------------------------
2021-07-15 21:47:34,957 EPOCH 31 done: loss 0.1801 - lr 0.0000075
2021-07-15 21:47:39,662 DEV : loss 0.2670575976371765 - score 0.9595
Epoch    31: reducing learning rate of group 0 to 3.7500e-06.
2021-07-15 21:47:39,725 BAD EPOCHS (no improvement): 4
2021-07-15 21:47:39,725 ----------------------------------------------------------------------------------------------------
2021-07-15 21:47:46,160 epoch 32 - iter 12/128 - loss 0.15413185 - samples/sec: 59.69 - lr: 0.000004
2021-07-15 21:47:52,555 epoch 32 - iter 24/128 - loss 0.18145167 - samples/sec: 60.06 - lr: 0.000004
2021-07-15 21:47:59,014 epoch 32 - iter 36/128 - loss 0.18336215 - samples/sec: 59.45 - lr: 0.000004
2021-07-15 21:48:05,460 epoch 32 - iter 48/128 - loss 0.19037191 - samples/sec: 59.59 - lr: 0.000004
2021-07-15 21:48:11,903 epoch 32 - iter 60/128 - loss 0.18519059 - samples/sec: 59.61 - lr: 0.000004
2021-07-15 21:48:18,375 epoch 32 - iter 72/128 - loss 0.18228304 - samples/sec: 59.34 - lr: 0.000004
2021-07-15 21:48:24,803 epoch 32 - iter 84/128 - loss 0.18017704 - samples/sec: 59.74 - lr: 0.000004
2021-07-15 21:48:31,242 epoch 32 - iter 96/128 - loss 0.17606848 - samples/sec: 59.65 - lr: 0.000004
2021-07-15 21:48:37,638 epoch 32 - iter 108/128 - loss 0.17695942 - samples/sec: 60.05 - lr: 0.000004
2021-07-15 21:48:44,058 epoch 32 - iter 120/128 - loss 0.17851703 - samples/sec: 59.82 - lr: 0.000004
2021-07-15 21:48:48,034 ----------------------------------------------------------------------------------------------------
2021-07-15 21:48:48,034 EPOCH 32 done: loss 0.1765 - lr 0.0000038
2021-07-15 21:48:52,726 DEV : loss 0.2691173255443573 - score 0.96
2021-07-15 21:48:52,790 BAD EPOCHS (no improvement): 1
2021-07-15 21:48:52,790 ----------------------------------------------------------------------------------------------------
2021-07-15 21:48:59,231 epoch 33 - iter 12/128 - loss 0.16039229 - samples/sec: 59.63 - lr: 0.000004
2021-07-15 21:49:06,108 epoch 33 - iter 24/128 - loss 0.16700359 - samples/sec: 55.85 - lr: 0.000004
2021-07-15 21:49:12,499 epoch 33 - iter 36/128 - loss 0.17970026 - samples/sec: 60.09 - lr: 0.000004
2021-07-15 21:49:18,958 epoch 33 - iter 48/128 - loss 0.16788226 - samples/sec: 59.46 - lr: 0.000004
2021-07-15 21:49:25,378 epoch 33 - iter 60/128 - loss 0.16826287 - samples/sec: 59.82 - lr: 0.000004
2021-07-15 21:49:31,806 epoch 33 - iter 72/128 - loss 0.16126355 - samples/sec: 59.75 - lr: 0.000004
2021-07-15 21:49:38,223 epoch 33 - iter 84/128 - loss 0.16558861 - samples/sec: 59.85 - lr: 0.000004
2021-07-15 21:49:44,672 epoch 33 - iter 96/128 - loss 0.16132646 - samples/sec: 59.56 - lr: 0.000004
2021-07-15 21:49:51,119 epoch 33 - iter 108/128 - loss 0.16802087 - samples/sec: 59.57 - lr: 0.000004
2021-07-15 21:49:57,518 epoch 33 - iter 120/128 - loss 0.16516423 - samples/sec: 60.02 - lr: 0.000004
2021-07-15 21:50:01,502 ----------------------------------------------------------------------------------------------------
2021-07-15 21:50:01,502 EPOCH 33 done: loss 0.1634 - lr 0.0000038
2021-07-15 21:50:06,221 DEV : loss 0.26635703444480896 - score 0.9589
2021-07-15 21:50:06,285 BAD EPOCHS (no improvement): 2
2021-07-15 21:50:06,285 ----------------------------------------------------------------------------------------------------
2021-07-15 21:50:12,724 epoch 34 - iter 12/128 - loss 0.14830662 - samples/sec: 59.65 - lr: 0.000004
2021-07-15 21:50:19,152 epoch 34 - iter 24/128 - loss 0.16268781 - samples/sec: 59.75 - lr: 0.000004
2021-07-15 21:50:25,559 epoch 34 - iter 36/128 - loss 0.15349383 - samples/sec: 59.94 - lr: 0.000004
2021-07-15 21:50:31,936 epoch 34 - iter 48/128 - loss 0.14842695 - samples/sec: 60.23 - lr: 0.000004
2021-07-15 21:50:38,321 epoch 34 - iter 60/128 - loss 0.15324937 - samples/sec: 60.15 - lr: 0.000004
2021-07-15 21:50:44,682 epoch 34 - iter 72/128 - loss 0.15159873 - samples/sec: 60.37 - lr: 0.000004
2021-07-15 21:50:51,034 epoch 34 - iter 84/128 - loss 0.14903040 - samples/sec: 60.47 - lr: 0.000004
2021-07-15 21:50:57,441 epoch 34 - iter 96/128 - loss 0.15098563 - samples/sec: 59.95 - lr: 0.000004
2021-07-15 21:51:03,895 epoch 34 - iter 108/128 - loss 0.15203176 - samples/sec: 59.50 - lr: 0.000004
2021-07-15 21:51:10,337 epoch 34 - iter 120/128 - loss 0.15324268 - samples/sec: 59.62 - lr: 0.000004
2021-07-15 21:51:14,290 ----------------------------------------------------------------------------------------------------
2021-07-15 21:51:14,290 EPOCH 34 done: loss 0.1541 - lr 0.0000038
2021-07-15 21:51:18,990 DEV : loss 0.27077245712280273 - score 0.96
2021-07-15 21:51:19,054 BAD EPOCHS (no improvement): 3
2021-07-15 21:51:19,054 ----------------------------------------------------------------------------------------------------
2021-07-15 21:51:25,467 epoch 35 - iter 12/128 - loss 0.19282830 - samples/sec: 59.89 - lr: 0.000004
2021-07-15 21:51:31,910 epoch 35 - iter 24/128 - loss 0.18495469 - samples/sec: 59.61 - lr: 0.000004
2021-07-15 21:51:38,335 epoch 35 - iter 36/128 - loss 0.17987618 - samples/sec: 59.78 - lr: 0.000004
2021-07-15 21:51:44,786 epoch 35 - iter 48/128 - loss 0.18524743 - samples/sec: 59.53 - lr: 0.000004
2021-07-15 21:51:51,227 epoch 35 - iter 60/128 - loss 0.17354116 - samples/sec: 59.62 - lr: 0.000004
2021-07-15 21:51:57,683 epoch 35 - iter 72/128 - loss 0.17454228 - samples/sec: 59.49 - lr: 0.000004
2021-07-15 21:52:04,077 epoch 35 - iter 84/128 - loss 0.17153145 - samples/sec: 60.07 - lr: 0.000004
2021-07-15 21:52:10,512 epoch 35 - iter 96/128 - loss 0.16897836 - samples/sec: 59.68 - lr: 0.000004
2021-07-15 21:52:16,934 epoch 35 - iter 108/128 - loss 0.17426043 - samples/sec: 59.81 - lr: 0.000004
2021-07-15 21:52:23,371 epoch 35 - iter 120/128 - loss 0.17236493 - samples/sec: 59.66 - lr: 0.000004
2021-07-15 21:52:27,396 ----------------------------------------------------------------------------------------------------
2021-07-15 21:52:27,396 EPOCH 35 done: loss 0.1693 - lr 0.0000038
2021-07-15 21:52:32,101 DEV : loss 0.26928311586380005 - score 0.9584
Epoch    35: reducing learning rate of group 0 to 1.8750e-06.
2021-07-15 21:52:32,164 BAD EPOCHS (no improvement): 4
2021-07-15 21:52:32,164 ----------------------------------------------------------------------------------------------------
2021-07-15 21:52:32,164 ----------------------------------------------------------------------------------------------------
2021-07-15 21:52:32,164 learning rate too small - quitting training!
2021-07-15 21:52:32,164 ----------------------------------------------------------------------------------------------------
2021-07-15 21:52:33,250 ----------------------------------------------------------------------------------------------------
2021-07-15 21:52:33,250 Testing using best model ...
2021-07-15 21:52:33,250 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.gum/best-model.pt
2021-07-15 21:52:57,888 0.9388	0.9403	0.9395
2021-07-15 21:52:57,888 
Results:
- F1-score (micro) 0.9395
- F1-score (macro) 0.9395

By class:
SENT       tp: 1794 - fp: 117 - fn: 114 - precision: 0.9388 - recall: 0.9403 - f1-score: 0.9395
2021-07-15 21:52:57,888 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/nld.rst.nldt/
2021-07-15 21:52:57,898 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/nld.rst.nldt
2021-07-15 21:52:57,899 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/nld.rst.nldt/sent_train.txt
2021-07-15 21:52:57,901 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/nld.rst.nldt/sent_dev.txt
2021-07-15 21:52:57,902 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/nld.rst.nldt/sent_test.txt
Corpus: 618 train + 186 dev + 247 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 21:53:00,323 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:00,325 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30073, 768, padding_idx=3)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 21:53:00,325 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:00,325 Corpus: "Corpus: 618 train + 186 dev + 247 test sentences"
2021-07-15 21:53:00,325 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:00,325 Parameters:
2021-07-15 21:53:00,325  - learning_rate: "3e-05"
2021-07-15 21:53:00,325  - mini_batch_size: "32"
2021-07-15 21:53:00,325  - patience: "3"
2021-07-15 21:53:00,325  - anneal_factor: "0.5"
2021-07-15 21:53:00,325  - max_epochs: "40"
2021-07-15 21:53:00,325  - shuffle: "True"
2021-07-15 21:53:00,325  - train_with_dev: "False"
2021-07-15 21:53:00,325  - batch_growth_annealing: "False"
2021-07-15 21:53:00,325 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:00,325 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/nld.rst.nldt"
2021-07-15 21:53:00,326 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:00,326 Device: cuda:0
2021-07-15 21:53:00,326 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:00,326 Embeddings storage mode: cpu
2021-07-15 21:53:00,328 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:02,440 epoch 1 - iter 2/20 - loss 27.76361847 - samples/sec: 30.32 - lr: 0.000030
2021-07-15 21:53:04,528 epoch 1 - iter 4/20 - loss 24.55949497 - samples/sec: 30.66 - lr: 0.000030
2021-07-15 21:53:06,628 epoch 1 - iter 6/20 - loss 21.97758516 - samples/sec: 30.48 - lr: 0.000030
2021-07-15 21:53:08,742 epoch 1 - iter 8/20 - loss 19.89117002 - samples/sec: 30.27 - lr: 0.000030
2021-07-15 21:53:10,883 epoch 1 - iter 10/20 - loss 18.17879543 - samples/sec: 29.90 - lr: 0.000030
2021-07-15 21:53:12,998 epoch 1 - iter 12/20 - loss 16.64622498 - samples/sec: 30.27 - lr: 0.000030
2021-07-15 21:53:15,087 epoch 1 - iter 14/20 - loss 15.36801379 - samples/sec: 30.63 - lr: 0.000030
2021-07-15 21:53:17,203 epoch 1 - iter 16/20 - loss 14.26325655 - samples/sec: 30.26 - lr: 0.000030
2021-07-15 21:53:19,319 epoch 1 - iter 18/20 - loss 13.32103533 - samples/sec: 30.25 - lr: 0.000030
2021-07-15 21:53:20,718 epoch 1 - iter 20/20 - loss 12.52667093 - samples/sec: 45.75 - lr: 0.000030
2021-07-15 21:53:20,718 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:20,718 EPOCH 1 done: loss 12.5267 - lr 0.0000300
2021-07-15 21:53:25,267 DEV : loss 5.089298248291016 - score 0.0
2021-07-15 21:53:25,280 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:53:25,997 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:27,056 epoch 2 - iter 2/20 - loss 5.38821626 - samples/sec: 60.49 - lr: 0.000030
2021-07-15 21:53:28,127 epoch 2 - iter 4/20 - loss 5.45147979 - samples/sec: 59.78 - lr: 0.000030
2021-07-15 21:53:29,225 epoch 2 - iter 6/20 - loss 5.31721330 - samples/sec: 58.31 - lr: 0.000030
2021-07-15 21:53:30,311 epoch 2 - iter 8/20 - loss 5.13063627 - samples/sec: 58.94 - lr: 0.000030
2021-07-15 21:53:31,360 epoch 2 - iter 10/20 - loss 5.03534956 - samples/sec: 61.08 - lr: 0.000030
2021-07-15 21:53:32,441 epoch 2 - iter 12/20 - loss 4.88199892 - samples/sec: 59.25 - lr: 0.000030
2021-07-15 21:53:33,500 epoch 2 - iter 14/20 - loss 4.75017263 - samples/sec: 60.45 - lr: 0.000030
2021-07-15 21:53:34,569 epoch 2 - iter 16/20 - loss 4.64431584 - samples/sec: 59.89 - lr: 0.000030
2021-07-15 21:53:35,628 epoch 2 - iter 18/20 - loss 4.51042275 - samples/sec: 60.45 - lr: 0.000030
2021-07-15 21:53:36,354 epoch 2 - iter 20/20 - loss 4.37339830 - samples/sec: 88.28 - lr: 0.000030
2021-07-15 21:53:36,354 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:36,354 EPOCH 2 done: loss 4.3734 - lr 0.0000300
2021-07-15 21:53:37,379 DEV : loss 2.6025876998901367 - score 0.0755
2021-07-15 21:53:37,393 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:53:41,229 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:42,301 epoch 3 - iter 2/20 - loss 3.29680419 - samples/sec: 59.76 - lr: 0.000030
2021-07-15 21:53:43,377 epoch 3 - iter 4/20 - loss 3.08741641 - samples/sec: 59.52 - lr: 0.000030
2021-07-15 21:53:44,439 epoch 3 - iter 6/20 - loss 2.92207114 - samples/sec: 60.27 - lr: 0.000030
2021-07-15 21:53:45,495 epoch 3 - iter 8/20 - loss 2.84332666 - samples/sec: 60.64 - lr: 0.000030
2021-07-15 21:53:46,566 epoch 3 - iter 10/20 - loss 2.76384370 - samples/sec: 59.77 - lr: 0.000030
2021-07-15 21:53:47,635 epoch 3 - iter 12/20 - loss 2.69252477 - samples/sec: 59.93 - lr: 0.000030
2021-07-15 21:53:48,691 epoch 3 - iter 14/20 - loss 2.59850672 - samples/sec: 60.63 - lr: 0.000030
2021-07-15 21:53:49,740 epoch 3 - iter 16/20 - loss 2.49537227 - samples/sec: 61.03 - lr: 0.000030
2021-07-15 21:53:50,803 epoch 3 - iter 18/20 - loss 2.45474519 - samples/sec: 60.25 - lr: 0.000030
2021-07-15 21:53:51,554 epoch 3 - iter 20/20 - loss 2.42595434 - samples/sec: 85.29 - lr: 0.000030
2021-07-15 21:53:51,554 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:51,554 EPOCH 3 done: loss 2.4260 - lr 0.0000300
2021-07-15 21:53:52,571 DEV : loss 1.2190202474594116 - score 0.8288
2021-07-15 21:53:52,584 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:53:56,308 ----------------------------------------------------------------------------------------------------
2021-07-15 21:53:57,375 epoch 4 - iter 2/20 - loss 2.03904533 - samples/sec: 60.03 - lr: 0.000030
2021-07-15 21:53:58,421 epoch 4 - iter 4/20 - loss 1.77484846 - samples/sec: 61.23 - lr: 0.000030
2021-07-15 21:53:59,467 epoch 4 - iter 6/20 - loss 1.65524348 - samples/sec: 61.18 - lr: 0.000030
2021-07-15 21:54:00,530 epoch 4 - iter 8/20 - loss 1.65073849 - samples/sec: 60.24 - lr: 0.000030
2021-07-15 21:54:01,595 epoch 4 - iter 10/20 - loss 1.59427621 - samples/sec: 60.13 - lr: 0.000030
2021-07-15 21:54:02,668 epoch 4 - iter 12/20 - loss 1.53035624 - samples/sec: 59.69 - lr: 0.000030
2021-07-15 21:54:03,733 epoch 4 - iter 14/20 - loss 1.48924324 - samples/sec: 60.10 - lr: 0.000030
2021-07-15 21:54:04,794 epoch 4 - iter 16/20 - loss 1.44943281 - samples/sec: 60.35 - lr: 0.000030
2021-07-15 21:54:05,872 epoch 4 - iter 18/20 - loss 1.40927832 - samples/sec: 59.38 - lr: 0.000030
2021-07-15 21:54:06,617 epoch 4 - iter 20/20 - loss 1.37370672 - samples/sec: 86.01 - lr: 0.000030
2021-07-15 21:54:06,617 ----------------------------------------------------------------------------------------------------
2021-07-15 21:54:06,617 EPOCH 4 done: loss 1.3737 - lr 0.0000300
2021-07-15 21:54:07,750 DEV : loss 0.8324763774871826 - score 0.8963
2021-07-15 21:54:07,764 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:54:11,394 ----------------------------------------------------------------------------------------------------
2021-07-15 21:54:12,475 epoch 5 - iter 2/20 - loss 1.01309478 - samples/sec: 59.25 - lr: 0.000030
2021-07-15 21:54:13,538 epoch 5 - iter 4/20 - loss 0.98345535 - samples/sec: 60.26 - lr: 0.000030
2021-07-15 21:54:14,575 epoch 5 - iter 6/20 - loss 0.98310861 - samples/sec: 61.73 - lr: 0.000030
2021-07-15 21:54:15,660 epoch 5 - iter 8/20 - loss 1.05307686 - samples/sec: 58.99 - lr: 0.000030
2021-07-15 21:54:16,724 epoch 5 - iter 10/20 - loss 1.03629875 - samples/sec: 60.21 - lr: 0.000030
2021-07-15 21:54:17,794 epoch 5 - iter 12/20 - loss 1.00988833 - samples/sec: 59.82 - lr: 0.000030
2021-07-15 21:54:18,834 epoch 5 - iter 14/20 - loss 0.97261577 - samples/sec: 61.57 - lr: 0.000030
2021-07-15 21:54:19,906 epoch 5 - iter 16/20 - loss 1.00939492 - samples/sec: 59.74 - lr: 0.000030
2021-07-15 21:54:20,974 epoch 5 - iter 18/20 - loss 0.98912177 - samples/sec: 59.93 - lr: 0.000030
2021-07-15 21:54:21,742 epoch 5 - iter 20/20 - loss 1.00932161 - samples/sec: 83.40 - lr: 0.000030
2021-07-15 21:54:21,742 ----------------------------------------------------------------------------------------------------
2021-07-15 21:54:21,742 EPOCH 5 done: loss 1.0093 - lr 0.0000300
2021-07-15 21:54:22,763 DEV : loss 0.6813353300094604 - score 0.9105
2021-07-15 21:54:22,776 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:54:26,428 ----------------------------------------------------------------------------------------------------
2021-07-15 21:54:27,487 epoch 6 - iter 2/20 - loss 0.95216084 - samples/sec: 60.49 - lr: 0.000030
2021-07-15 21:54:28,559 epoch 6 - iter 4/20 - loss 0.91630051 - samples/sec: 59.74 - lr: 0.000030
2021-07-15 21:54:29,631 epoch 6 - iter 6/20 - loss 0.95672019 - samples/sec: 59.71 - lr: 0.000030
2021-07-15 21:54:30,692 epoch 6 - iter 8/20 - loss 0.96235284 - samples/sec: 60.38 - lr: 0.000030
2021-07-15 21:54:31,753 epoch 6 - iter 10/20 - loss 0.92264220 - samples/sec: 60.33 - lr: 0.000030
2021-07-15 21:54:32,828 epoch 6 - iter 12/20 - loss 0.88666982 - samples/sec: 59.56 - lr: 0.000030
2021-07-15 21:54:33,908 epoch 6 - iter 14/20 - loss 0.89409366 - samples/sec: 59.26 - lr: 0.000030
2021-07-15 21:54:34,955 epoch 6 - iter 16/20 - loss 0.88801880 - samples/sec: 61.20 - lr: 0.000030
2021-07-15 21:54:36,006 epoch 6 - iter 18/20 - loss 0.86780757 - samples/sec: 60.93 - lr: 0.000030
2021-07-15 21:54:36,767 epoch 6 - iter 20/20 - loss 0.87499321 - samples/sec: 84.10 - lr: 0.000030
2021-07-15 21:54:36,767 ----------------------------------------------------------------------------------------------------
2021-07-15 21:54:36,768 EPOCH 6 done: loss 0.8750 - lr 0.0000300
2021-07-15 21:54:37,791 DEV : loss 0.6108084321022034 - score 0.9312
2021-07-15 21:54:37,805 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:54:41,438 ----------------------------------------------------------------------------------------------------
2021-07-15 21:54:42,479 epoch 7 - iter 2/20 - loss 0.70498985 - samples/sec: 61.57 - lr: 0.000030
2021-07-15 21:54:43,556 epoch 7 - iter 4/20 - loss 0.75872108 - samples/sec: 59.44 - lr: 0.000030
2021-07-15 21:54:44,610 epoch 7 - iter 6/20 - loss 0.67276567 - samples/sec: 60.74 - lr: 0.000030
2021-07-15 21:54:45,664 epoch 7 - iter 8/20 - loss 0.66307335 - samples/sec: 60.79 - lr: 0.000030
2021-07-15 21:54:46,743 epoch 7 - iter 10/20 - loss 0.67580404 - samples/sec: 59.31 - lr: 0.000030
2021-07-15 21:54:47,819 epoch 7 - iter 12/20 - loss 0.67414439 - samples/sec: 59.52 - lr: 0.000030
2021-07-15 21:54:48,888 epoch 7 - iter 14/20 - loss 0.70982226 - samples/sec: 59.92 - lr: 0.000030
2021-07-15 21:54:49,954 epoch 7 - iter 16/20 - loss 0.74582044 - samples/sec: 60.03 - lr: 0.000030
2021-07-15 21:54:51,047 epoch 7 - iter 18/20 - loss 0.76489719 - samples/sec: 58.63 - lr: 0.000030
2021-07-15 21:54:51,806 epoch 7 - iter 20/20 - loss 0.73518194 - samples/sec: 84.38 - lr: 0.000030
2021-07-15 21:54:51,806 ----------------------------------------------------------------------------------------------------
2021-07-15 21:54:51,806 EPOCH 7 done: loss 0.7352 - lr 0.0000300
2021-07-15 21:54:52,826 DEV : loss 0.5732970237731934 - score 0.9354
2021-07-15 21:54:52,840 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:54:56,634 ----------------------------------------------------------------------------------------------------
2021-07-15 21:54:57,710 epoch 8 - iter 2/20 - loss 0.50593615 - samples/sec: 59.55 - lr: 0.000030
2021-07-15 21:54:58,791 epoch 8 - iter 4/20 - loss 0.66825330 - samples/sec: 59.26 - lr: 0.000030
2021-07-15 21:54:59,836 epoch 8 - iter 6/20 - loss 0.62844378 - samples/sec: 61.23 - lr: 0.000030
2021-07-15 21:55:00,916 epoch 8 - iter 8/20 - loss 0.68413401 - samples/sec: 59.30 - lr: 0.000030
2021-07-15 21:55:02,012 epoch 8 - iter 10/20 - loss 0.69444914 - samples/sec: 58.41 - lr: 0.000030
2021-07-15 21:55:03,080 epoch 8 - iter 12/20 - loss 0.68239269 - samples/sec: 59.99 - lr: 0.000030
2021-07-15 21:55:04,135 epoch 8 - iter 14/20 - loss 0.67875248 - samples/sec: 60.69 - lr: 0.000030
2021-07-15 21:55:05,184 epoch 8 - iter 16/20 - loss 0.71674781 - samples/sec: 61.03 - lr: 0.000030
2021-07-15 21:55:06,239 epoch 8 - iter 18/20 - loss 0.70437903 - samples/sec: 60.68 - lr: 0.000030
2021-07-15 21:55:07,006 epoch 8 - iter 20/20 - loss 0.70945552 - samples/sec: 83.53 - lr: 0.000030
2021-07-15 21:55:07,006 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:07,006 EPOCH 8 done: loss 0.7095 - lr 0.0000300
2021-07-15 21:55:08,133 DEV : loss 0.5484155416488647 - score 0.9365
2021-07-15 21:55:08,147 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:55:11,811 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:12,894 epoch 9 - iter 2/20 - loss 0.85200274 - samples/sec: 59.14 - lr: 0.000030
2021-07-15 21:55:13,982 epoch 9 - iter 4/20 - loss 0.72764820 - samples/sec: 58.85 - lr: 0.000030
2021-07-15 21:55:15,027 epoch 9 - iter 6/20 - loss 0.76396513 - samples/sec: 61.28 - lr: 0.000030
2021-07-15 21:55:16,088 epoch 9 - iter 8/20 - loss 0.72582744 - samples/sec: 60.32 - lr: 0.000030
2021-07-15 21:55:17,155 epoch 9 - iter 10/20 - loss 0.72057340 - samples/sec: 60.04 - lr: 0.000030
2021-07-15 21:55:18,197 epoch 9 - iter 12/20 - loss 0.67094359 - samples/sec: 61.43 - lr: 0.000030
2021-07-15 21:55:19,252 epoch 9 - iter 14/20 - loss 0.66408776 - samples/sec: 60.68 - lr: 0.000030
2021-07-15 21:55:20,318 epoch 9 - iter 16/20 - loss 0.65124859 - samples/sec: 60.08 - lr: 0.000030
2021-07-15 21:55:21,380 epoch 9 - iter 18/20 - loss 0.64485033 - samples/sec: 60.32 - lr: 0.000030
2021-07-15 21:55:22,139 epoch 9 - iter 20/20 - loss 0.63427748 - samples/sec: 84.28 - lr: 0.000030
2021-07-15 21:55:22,140 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:22,140 EPOCH 9 done: loss 0.6343 - lr 0.0000300
2021-07-15 21:55:23,166 DEV : loss 0.5142443180084229 - score 0.9407
2021-07-15 21:55:23,180 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:55:27,010 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:28,078 epoch 10 - iter 2/20 - loss 0.55180299 - samples/sec: 59.95 - lr: 0.000030
2021-07-15 21:55:29,135 epoch 10 - iter 4/20 - loss 0.60079888 - samples/sec: 60.58 - lr: 0.000030
2021-07-15 21:55:30,213 epoch 10 - iter 6/20 - loss 0.62262244 - samples/sec: 59.42 - lr: 0.000030
2021-07-15 21:55:31,284 epoch 10 - iter 8/20 - loss 0.66420898 - samples/sec: 59.75 - lr: 0.000030
2021-07-15 21:55:32,339 epoch 10 - iter 10/20 - loss 0.64350391 - samples/sec: 60.68 - lr: 0.000030
2021-07-15 21:55:33,409 epoch 10 - iter 12/20 - loss 0.63813406 - samples/sec: 59.88 - lr: 0.000030
2021-07-15 21:55:34,467 epoch 10 - iter 14/20 - loss 0.62726800 - samples/sec: 60.50 - lr: 0.000030
2021-07-15 21:55:35,535 epoch 10 - iter 16/20 - loss 0.61782018 - samples/sec: 59.95 - lr: 0.000030
2021-07-15 21:55:36,575 epoch 10 - iter 18/20 - loss 0.60108918 - samples/sec: 61.55 - lr: 0.000030
2021-07-15 21:55:37,324 epoch 10 - iter 20/20 - loss 0.58289452 - samples/sec: 85.50 - lr: 0.000030
2021-07-15 21:55:37,325 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:37,325 EPOCH 10 done: loss 0.5829 - lr 0.0000300
2021-07-15 21:55:38,347 DEV : loss 0.5087730884552002 - score 0.94
2021-07-15 21:55:38,360 BAD EPOCHS (no improvement): 1
2021-07-15 21:55:38,361 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:39,394 epoch 11 - iter 2/20 - loss 0.73601770 - samples/sec: 61.94 - lr: 0.000030
2021-07-15 21:55:40,455 epoch 11 - iter 4/20 - loss 0.55653119 - samples/sec: 60.35 - lr: 0.000030
2021-07-15 21:55:41,527 epoch 11 - iter 6/20 - loss 0.52575779 - samples/sec: 59.74 - lr: 0.000030
2021-07-15 21:55:42,591 epoch 11 - iter 8/20 - loss 0.56981394 - samples/sec: 60.19 - lr: 0.000030
2021-07-15 21:55:43,664 epoch 11 - iter 10/20 - loss 0.54960102 - samples/sec: 59.66 - lr: 0.000030
2021-07-15 21:55:44,744 epoch 11 - iter 12/20 - loss 0.56903693 - samples/sec: 59.29 - lr: 0.000030
2021-07-15 21:55:45,814 epoch 11 - iter 14/20 - loss 0.57201699 - samples/sec: 59.83 - lr: 0.000030
2021-07-15 21:55:46,870 epoch 11 - iter 16/20 - loss 0.56782049 - samples/sec: 60.65 - lr: 0.000030
2021-07-15 21:55:47,900 epoch 11 - iter 18/20 - loss 0.55669827 - samples/sec: 62.18 - lr: 0.000030
2021-07-15 21:55:48,654 epoch 11 - iter 20/20 - loss 0.55222696 - samples/sec: 84.98 - lr: 0.000030
2021-07-15 21:55:48,654 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:48,654 EPOCH 11 done: loss 0.5522 - lr 0.0000300
2021-07-15 21:55:49,675 DEV : loss 0.47787660360336304 - score 0.9391
2021-07-15 21:55:49,689 BAD EPOCHS (no improvement): 2
2021-07-15 21:55:49,689 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:50,727 epoch 12 - iter 2/20 - loss 0.38203616 - samples/sec: 61.67 - lr: 0.000030
2021-07-15 21:55:51,775 epoch 12 - iter 4/20 - loss 0.51799712 - samples/sec: 61.13 - lr: 0.000030
2021-07-15 21:55:52,803 epoch 12 - iter 6/20 - loss 0.46724451 - samples/sec: 62.26 - lr: 0.000030
2021-07-15 21:55:53,882 epoch 12 - iter 8/20 - loss 0.48222789 - samples/sec: 59.34 - lr: 0.000030
2021-07-15 21:55:54,943 epoch 12 - iter 10/20 - loss 0.45194102 - samples/sec: 60.36 - lr: 0.000030
2021-07-15 21:55:56,026 epoch 12 - iter 12/20 - loss 0.47538080 - samples/sec: 59.11 - lr: 0.000030
2021-07-15 21:55:57,080 epoch 12 - iter 14/20 - loss 0.48166611 - samples/sec: 60.74 - lr: 0.000030
2021-07-15 21:55:58,152 epoch 12 - iter 16/20 - loss 0.49626779 - samples/sec: 59.73 - lr: 0.000030
2021-07-15 21:55:59,233 epoch 12 - iter 18/20 - loss 0.50863478 - samples/sec: 59.24 - lr: 0.000030
2021-07-15 21:55:59,991 epoch 12 - iter 20/20 - loss 0.50758245 - samples/sec: 84.49 - lr: 0.000030
2021-07-15 21:55:59,992 ----------------------------------------------------------------------------------------------------
2021-07-15 21:55:59,992 EPOCH 12 done: loss 0.5076 - lr 0.0000300
2021-07-15 21:56:01,011 DEV : loss 0.46810251474380493 - score 0.9407
2021-07-15 21:56:01,025 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:56:04,702 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:05,759 epoch 13 - iter 2/20 - loss 0.40135819 - samples/sec: 60.61 - lr: 0.000030
2021-07-15 21:56:06,838 epoch 13 - iter 4/20 - loss 0.42343539 - samples/sec: 59.32 - lr: 0.000030
2021-07-15 21:56:07,895 epoch 13 - iter 6/20 - loss 0.44067573 - samples/sec: 60.61 - lr: 0.000030
2021-07-15 21:56:08,948 epoch 13 - iter 8/20 - loss 0.43916741 - samples/sec: 60.83 - lr: 0.000030
2021-07-15 21:56:09,993 epoch 13 - iter 10/20 - loss 0.44320897 - samples/sec: 61.23 - lr: 0.000030
2021-07-15 21:56:11,068 epoch 13 - iter 12/20 - loss 0.43880856 - samples/sec: 59.56 - lr: 0.000030
2021-07-15 21:56:12,134 epoch 13 - iter 14/20 - loss 0.44244107 - samples/sec: 60.06 - lr: 0.000030
2021-07-15 21:56:13,208 epoch 13 - iter 16/20 - loss 0.45872486 - samples/sec: 59.64 - lr: 0.000030
2021-07-15 21:56:14,267 epoch 13 - iter 18/20 - loss 0.46084426 - samples/sec: 60.45 - lr: 0.000030
2021-07-15 21:56:15,006 epoch 13 - iter 20/20 - loss 0.48109374 - samples/sec: 86.69 - lr: 0.000030
2021-07-15 21:56:15,006 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:15,006 EPOCH 13 done: loss 0.4811 - lr 0.0000300
2021-07-15 21:56:16,139 DEV : loss 0.4534188210964203 - score 0.944
2021-07-15 21:56:16,153 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:56:19,782 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:20,819 epoch 14 - iter 2/20 - loss 0.40305063 - samples/sec: 61.79 - lr: 0.000030
2021-07-15 21:56:21,871 epoch 14 - iter 4/20 - loss 0.39205130 - samples/sec: 60.83 - lr: 0.000030
2021-07-15 21:56:22,959 epoch 14 - iter 6/20 - loss 0.42522567 - samples/sec: 58.85 - lr: 0.000030
2021-07-15 21:56:24,026 epoch 14 - iter 8/20 - loss 0.43799554 - samples/sec: 60.04 - lr: 0.000030
2021-07-15 21:56:25,092 epoch 14 - iter 10/20 - loss 0.42287963 - samples/sec: 60.06 - lr: 0.000030
2021-07-15 21:56:26,166 epoch 14 - iter 12/20 - loss 0.41581598 - samples/sec: 59.62 - lr: 0.000030
2021-07-15 21:56:27,223 epoch 14 - iter 14/20 - loss 0.42143493 - samples/sec: 60.56 - lr: 0.000030
2021-07-15 21:56:28,288 epoch 14 - iter 16/20 - loss 0.41312318 - samples/sec: 60.11 - lr: 0.000030
2021-07-15 21:56:29,374 epoch 14 - iter 18/20 - loss 0.42831840 - samples/sec: 59.00 - lr: 0.000030
2021-07-15 21:56:30,100 epoch 14 - iter 20/20 - loss 0.42277071 - samples/sec: 88.17 - lr: 0.000030
2021-07-15 21:56:30,100 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:30,100 EPOCH 14 done: loss 0.4228 - lr 0.0000300
2021-07-15 21:56:31,122 DEV : loss 0.46500906348228455 - score 0.9336
2021-07-15 21:56:31,135 BAD EPOCHS (no improvement): 1
2021-07-15 21:56:31,136 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:32,152 epoch 15 - iter 2/20 - loss 0.46898812 - samples/sec: 63.00 - lr: 0.000030
2021-07-15 21:56:33,221 epoch 15 - iter 4/20 - loss 0.43515722 - samples/sec: 59.90 - lr: 0.000030
2021-07-15 21:56:34,281 epoch 15 - iter 6/20 - loss 0.44123542 - samples/sec: 60.42 - lr: 0.000030
2021-07-15 21:56:35,385 epoch 15 - iter 8/20 - loss 0.42287040 - samples/sec: 58.00 - lr: 0.000030
2021-07-15 21:56:36,446 epoch 15 - iter 10/20 - loss 0.43431295 - samples/sec: 60.30 - lr: 0.000030
2021-07-15 21:56:37,513 epoch 15 - iter 12/20 - loss 0.44433823 - samples/sec: 60.03 - lr: 0.000030
2021-07-15 21:56:38,574 epoch 15 - iter 14/20 - loss 0.43870843 - samples/sec: 60.33 - lr: 0.000030
2021-07-15 21:56:39,631 epoch 15 - iter 16/20 - loss 0.43775605 - samples/sec: 60.60 - lr: 0.000030
2021-07-15 21:56:40,703 epoch 15 - iter 18/20 - loss 0.43032840 - samples/sec: 59.75 - lr: 0.000030
2021-07-15 21:56:41,450 epoch 15 - iter 20/20 - loss 0.43972522 - samples/sec: 85.72 - lr: 0.000030
2021-07-15 21:56:41,450 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:41,450 EPOCH 15 done: loss 0.4397 - lr 0.0000300
2021-07-15 21:56:42,471 DEV : loss 0.43734312057495117 - score 0.9421
2021-07-15 21:56:42,485 BAD EPOCHS (no improvement): 2
2021-07-15 21:56:42,485 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:43,544 epoch 16 - iter 2/20 - loss 0.33139931 - samples/sec: 60.48 - lr: 0.000030
2021-07-15 21:56:44,615 epoch 16 - iter 4/20 - loss 0.40693512 - samples/sec: 59.80 - lr: 0.000030
2021-07-15 21:56:45,667 epoch 16 - iter 6/20 - loss 0.41816317 - samples/sec: 60.86 - lr: 0.000030
2021-07-15 21:56:46,742 epoch 16 - iter 8/20 - loss 0.38970309 - samples/sec: 59.55 - lr: 0.000030
2021-07-15 21:56:47,805 epoch 16 - iter 10/20 - loss 0.36377773 - samples/sec: 60.23 - lr: 0.000030
2021-07-15 21:56:48,862 epoch 16 - iter 12/20 - loss 0.38935780 - samples/sec: 60.56 - lr: 0.000030
2021-07-15 21:56:49,919 epoch 16 - iter 14/20 - loss 0.38843317 - samples/sec: 60.59 - lr: 0.000030
2021-07-15 21:56:50,983 epoch 16 - iter 16/20 - loss 0.37469959 - samples/sec: 60.20 - lr: 0.000030
2021-07-15 21:56:52,040 epoch 16 - iter 18/20 - loss 0.38169271 - samples/sec: 60.58 - lr: 0.000030
2021-07-15 21:56:52,790 epoch 16 - iter 20/20 - loss 0.39117112 - samples/sec: 85.36 - lr: 0.000030
2021-07-15 21:56:52,791 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:52,791 EPOCH 16 done: loss 0.3912 - lr 0.0000300
2021-07-15 21:56:53,812 DEV : loss 0.4496069848537445 - score 0.9333
2021-07-15 21:56:53,826 BAD EPOCHS (no improvement): 3
2021-07-15 21:56:53,826 ----------------------------------------------------------------------------------------------------
2021-07-15 21:56:54,871 epoch 17 - iter 2/20 - loss 0.37676528 - samples/sec: 61.31 - lr: 0.000030
2021-07-15 21:56:55,918 epoch 17 - iter 4/20 - loss 0.39598780 - samples/sec: 61.12 - lr: 0.000030
2021-07-15 21:56:56,984 epoch 17 - iter 6/20 - loss 0.34240791 - samples/sec: 60.09 - lr: 0.000030
2021-07-15 21:56:58,049 epoch 17 - iter 8/20 - loss 0.33289275 - samples/sec: 60.13 - lr: 0.000030
2021-07-15 21:56:59,131 epoch 17 - iter 10/20 - loss 0.35405708 - samples/sec: 59.14 - lr: 0.000030
2021-07-15 21:57:00,195 epoch 17 - iter 12/20 - loss 0.35702674 - samples/sec: 60.17 - lr: 0.000030
2021-07-15 21:57:01,257 epoch 17 - iter 14/20 - loss 0.34325163 - samples/sec: 60.34 - lr: 0.000030
2021-07-15 21:57:02,328 epoch 17 - iter 16/20 - loss 0.35460960 - samples/sec: 59.76 - lr: 0.000030
2021-07-15 21:57:03,395 epoch 17 - iter 18/20 - loss 0.35310223 - samples/sec: 60.02 - lr: 0.000030
2021-07-15 21:57:04,125 epoch 17 - iter 20/20 - loss 0.34546566 - samples/sec: 87.71 - lr: 0.000030
2021-07-15 21:57:04,125 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:04,125 EPOCH 17 done: loss 0.3455 - lr 0.0000300
2021-07-15 21:57:05,257 DEV : loss 0.41117438673973083 - score 0.9402
Epoch    17: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 21:57:05,271 BAD EPOCHS (no improvement): 4
2021-07-15 21:57:05,271 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:06,322 epoch 18 - iter 2/20 - loss 0.45726177 - samples/sec: 60.91 - lr: 0.000015
2021-07-15 21:57:07,362 epoch 18 - iter 4/20 - loss 0.36164381 - samples/sec: 61.59 - lr: 0.000015
2021-07-15 21:57:08,420 epoch 18 - iter 6/20 - loss 0.37755248 - samples/sec: 60.52 - lr: 0.000015
2021-07-15 21:57:09,478 epoch 18 - iter 8/20 - loss 0.37878945 - samples/sec: 60.53 - lr: 0.000015
2021-07-15 21:57:10,547 epoch 18 - iter 10/20 - loss 0.36342252 - samples/sec: 59.87 - lr: 0.000015
2021-07-15 21:57:11,628 epoch 18 - iter 12/20 - loss 0.36700061 - samples/sec: 59.24 - lr: 0.000015
2021-07-15 21:57:12,679 epoch 18 - iter 14/20 - loss 0.37732734 - samples/sec: 60.95 - lr: 0.000015
2021-07-15 21:57:13,748 epoch 18 - iter 16/20 - loss 0.37052498 - samples/sec: 59.89 - lr: 0.000015
2021-07-15 21:57:14,838 epoch 18 - iter 18/20 - loss 0.37236580 - samples/sec: 58.72 - lr: 0.000015
2021-07-15 21:57:15,569 epoch 18 - iter 20/20 - loss 0.35217638 - samples/sec: 87.62 - lr: 0.000015
2021-07-15 21:57:15,570 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:15,570 EPOCH 18 done: loss 0.3522 - lr 0.0000150
2021-07-15 21:57:16,588 DEV : loss 0.4099969267845154 - score 0.9421
2021-07-15 21:57:16,602 BAD EPOCHS (no improvement): 1
2021-07-15 21:57:16,602 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:17,663 epoch 19 - iter 2/20 - loss 0.41926396 - samples/sec: 60.36 - lr: 0.000015
2021-07-15 21:57:18,727 epoch 19 - iter 4/20 - loss 0.39621022 - samples/sec: 60.17 - lr: 0.000015
2021-07-15 21:57:19,816 epoch 19 - iter 6/20 - loss 0.37526979 - samples/sec: 58.81 - lr: 0.000015
2021-07-15 21:57:20,888 epoch 19 - iter 8/20 - loss 0.36364669 - samples/sec: 59.75 - lr: 0.000015
2021-07-15 21:57:21,968 epoch 19 - iter 10/20 - loss 0.35045553 - samples/sec: 59.25 - lr: 0.000015
2021-07-15 21:57:23,026 epoch 19 - iter 12/20 - loss 0.33854579 - samples/sec: 60.53 - lr: 0.000015
2021-07-15 21:57:24,074 epoch 19 - iter 14/20 - loss 0.33607575 - samples/sec: 61.10 - lr: 0.000015
2021-07-15 21:57:25,138 epoch 19 - iter 16/20 - loss 0.33881496 - samples/sec: 60.20 - lr: 0.000015
2021-07-15 21:57:26,188 epoch 19 - iter 18/20 - loss 0.33508886 - samples/sec: 60.98 - lr: 0.000015
2021-07-15 21:57:26,923 epoch 19 - iter 20/20 - loss 0.33606305 - samples/sec: 87.14 - lr: 0.000015
2021-07-15 21:57:26,923 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:26,923 EPOCH 19 done: loss 0.3361 - lr 0.0000150
2021-07-15 21:57:27,946 DEV : loss 0.41728895902633667 - score 0.9398
2021-07-15 21:57:27,960 BAD EPOCHS (no improvement): 2
2021-07-15 21:57:27,960 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:29,027 epoch 20 - iter 2/20 - loss 0.34862185 - samples/sec: 59.99 - lr: 0.000015
2021-07-15 21:57:30,085 epoch 20 - iter 4/20 - loss 0.34916604 - samples/sec: 60.53 - lr: 0.000015
2021-07-15 21:57:31,140 epoch 20 - iter 6/20 - loss 0.32437846 - samples/sec: 60.71 - lr: 0.000015
2021-07-15 21:57:32,204 epoch 20 - iter 8/20 - loss 0.30117632 - samples/sec: 60.18 - lr: 0.000015
2021-07-15 21:57:33,267 epoch 20 - iter 10/20 - loss 0.31321967 - samples/sec: 60.21 - lr: 0.000015
2021-07-15 21:57:34,309 epoch 20 - iter 12/20 - loss 0.32470341 - samples/sec: 61.48 - lr: 0.000015
2021-07-15 21:57:35,372 epoch 20 - iter 14/20 - loss 0.31870896 - samples/sec: 60.23 - lr: 0.000015
2021-07-15 21:57:36,458 epoch 20 - iter 16/20 - loss 0.30713178 - samples/sec: 58.92 - lr: 0.000015
2021-07-15 21:57:37,544 epoch 20 - iter 18/20 - loss 0.31151135 - samples/sec: 59.00 - lr: 0.000015
2021-07-15 21:57:38,288 epoch 20 - iter 20/20 - loss 0.30388736 - samples/sec: 86.04 - lr: 0.000015
2021-07-15 21:57:38,288 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:38,288 EPOCH 20 done: loss 0.3039 - lr 0.0000150
2021-07-15 21:57:39,311 DEV : loss 0.40600156784057617 - score 0.94
2021-07-15 21:57:39,324 BAD EPOCHS (no improvement): 3
2021-07-15 21:57:39,325 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:40,360 epoch 21 - iter 2/20 - loss 0.35386556 - samples/sec: 61.84 - lr: 0.000015
2021-07-15 21:57:41,462 epoch 21 - iter 4/20 - loss 0.33531824 - samples/sec: 58.10 - lr: 0.000015
2021-07-15 21:57:42,526 epoch 21 - iter 6/20 - loss 0.35411510 - samples/sec: 60.16 - lr: 0.000015
2021-07-15 21:57:43,572 epoch 21 - iter 8/20 - loss 0.33983891 - samples/sec: 61.26 - lr: 0.000015
2021-07-15 21:57:44,638 epoch 21 - iter 10/20 - loss 0.33060344 - samples/sec: 60.03 - lr: 0.000015
2021-07-15 21:57:45,705 epoch 21 - iter 12/20 - loss 0.31650113 - samples/sec: 60.01 - lr: 0.000015
2021-07-15 21:57:46,775 epoch 21 - iter 14/20 - loss 0.30446458 - samples/sec: 59.84 - lr: 0.000015
2021-07-15 21:57:47,834 epoch 21 - iter 16/20 - loss 0.29895836 - samples/sec: 60.51 - lr: 0.000015
2021-07-15 21:57:48,895 epoch 21 - iter 18/20 - loss 0.29521687 - samples/sec: 60.35 - lr: 0.000015
2021-07-15 21:57:49,628 epoch 21 - iter 20/20 - loss 0.31292644 - samples/sec: 87.37 - lr: 0.000015
2021-07-15 21:57:49,628 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:49,628 EPOCH 21 done: loss 0.3129 - lr 0.0000150
2021-07-15 21:57:50,646 DEV : loss 0.40210574865341187 - score 0.9379
Epoch    21: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 21:57:50,660 BAD EPOCHS (no improvement): 4
2021-07-15 21:57:50,660 ----------------------------------------------------------------------------------------------------
2021-07-15 21:57:51,809 epoch 22 - iter 2/20 - loss 0.27401236 - samples/sec: 55.72 - lr: 0.000008
2021-07-15 21:57:52,883 epoch 22 - iter 4/20 - loss 0.29048988 - samples/sec: 59.62 - lr: 0.000008
2021-07-15 21:57:53,968 epoch 22 - iter 6/20 - loss 0.25754716 - samples/sec: 59.04 - lr: 0.000008
2021-07-15 21:57:55,024 epoch 22 - iter 8/20 - loss 0.27208880 - samples/sec: 60.62 - lr: 0.000008
2021-07-15 21:57:56,097 epoch 22 - iter 10/20 - loss 0.27256764 - samples/sec: 59.71 - lr: 0.000008
2021-07-15 21:57:57,139 epoch 22 - iter 12/20 - loss 0.27103629 - samples/sec: 61.43 - lr: 0.000008
2021-07-15 21:57:58,188 epoch 22 - iter 14/20 - loss 0.27500661 - samples/sec: 61.06 - lr: 0.000008
2021-07-15 21:57:59,233 epoch 22 - iter 16/20 - loss 0.26569921 - samples/sec: 61.28 - lr: 0.000008
2021-07-15 21:58:00,283 epoch 22 - iter 18/20 - loss 0.27244445 - samples/sec: 60.96 - lr: 0.000008
2021-07-15 21:58:01,038 epoch 22 - iter 20/20 - loss 0.28611154 - samples/sec: 84.79 - lr: 0.000008
2021-07-15 21:58:01,039 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:01,039 EPOCH 22 done: loss 0.2861 - lr 0.0000075
2021-07-15 21:58:02,060 DEV : loss 0.40321943163871765 - score 0.94
2021-07-15 21:58:02,074 BAD EPOCHS (no improvement): 1
2021-07-15 21:58:02,074 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:03,099 epoch 23 - iter 2/20 - loss 0.27573377 - samples/sec: 62.45 - lr: 0.000008
2021-07-15 21:58:04,164 epoch 23 - iter 4/20 - loss 0.36616880 - samples/sec: 60.12 - lr: 0.000008
2021-07-15 21:58:05,212 epoch 23 - iter 6/20 - loss 0.31755355 - samples/sec: 61.13 - lr: 0.000008
2021-07-15 21:58:06,290 epoch 23 - iter 8/20 - loss 0.32528098 - samples/sec: 59.37 - lr: 0.000008
2021-07-15 21:58:07,345 epoch 23 - iter 10/20 - loss 0.30804788 - samples/sec: 60.72 - lr: 0.000008
2021-07-15 21:58:08,400 epoch 23 - iter 12/20 - loss 0.31326111 - samples/sec: 60.66 - lr: 0.000008
2021-07-15 21:58:09,458 epoch 23 - iter 14/20 - loss 0.30865748 - samples/sec: 60.57 - lr: 0.000008
2021-07-15 21:58:10,521 epoch 23 - iter 16/20 - loss 0.29549511 - samples/sec: 60.20 - lr: 0.000008
2021-07-15 21:58:11,588 epoch 23 - iter 18/20 - loss 0.30954911 - samples/sec: 60.04 - lr: 0.000008
2021-07-15 21:58:12,318 epoch 23 - iter 20/20 - loss 0.31972879 - samples/sec: 87.73 - lr: 0.000008
2021-07-15 21:58:12,318 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:12,318 EPOCH 23 done: loss 0.3197 - lr 0.0000075
2021-07-15 21:58:13,338 DEV : loss 0.4061267375946045 - score 0.9398
2021-07-15 21:58:13,352 BAD EPOCHS (no improvement): 2
2021-07-15 21:58:13,352 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:14,392 epoch 24 - iter 2/20 - loss 0.22860311 - samples/sec: 61.59 - lr: 0.000008
2021-07-15 21:58:15,483 epoch 24 - iter 4/20 - loss 0.24479013 - samples/sec: 58.68 - lr: 0.000008
2021-07-15 21:58:16,524 epoch 24 - iter 6/20 - loss 0.24699509 - samples/sec: 61.54 - lr: 0.000008
2021-07-15 21:58:17,593 epoch 24 - iter 8/20 - loss 0.27505853 - samples/sec: 59.87 - lr: 0.000008
2021-07-15 21:58:18,660 epoch 24 - iter 10/20 - loss 0.28104689 - samples/sec: 59.99 - lr: 0.000008
2021-07-15 21:58:19,697 epoch 24 - iter 12/20 - loss 0.29078417 - samples/sec: 61.77 - lr: 0.000008
2021-07-15 21:58:20,736 epoch 24 - iter 14/20 - loss 0.29054270 - samples/sec: 61.62 - lr: 0.000008
2021-07-15 21:58:21,808 epoch 24 - iter 16/20 - loss 0.29240986 - samples/sec: 59.73 - lr: 0.000008
2021-07-15 21:58:22,894 epoch 24 - iter 18/20 - loss 0.29516711 - samples/sec: 58.96 - lr: 0.000008
2021-07-15 21:58:23,629 epoch 24 - iter 20/20 - loss 0.28521386 - samples/sec: 87.11 - lr: 0.000008
2021-07-15 21:58:23,630 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:23,630 EPOCH 24 done: loss 0.2852 - lr 0.0000075
2021-07-15 21:58:24,648 DEV : loss 0.3970533013343811 - score 0.9421
2021-07-15 21:58:24,662 BAD EPOCHS (no improvement): 3
2021-07-15 21:58:24,662 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:25,729 epoch 25 - iter 2/20 - loss 0.28954118 - samples/sec: 60.05 - lr: 0.000008
2021-07-15 21:58:26,785 epoch 25 - iter 4/20 - loss 0.31375547 - samples/sec: 60.61 - lr: 0.000008
2021-07-15 21:58:27,856 epoch 25 - iter 6/20 - loss 0.29858376 - samples/sec: 59.77 - lr: 0.000008
2021-07-15 21:58:28,909 epoch 25 - iter 8/20 - loss 0.31507517 - samples/sec: 60.84 - lr: 0.000008
2021-07-15 21:58:29,970 epoch 25 - iter 10/20 - loss 0.29697543 - samples/sec: 60.36 - lr: 0.000008
2021-07-15 21:58:31,026 epoch 25 - iter 12/20 - loss 0.27462196 - samples/sec: 60.60 - lr: 0.000008
2021-07-15 21:58:32,046 epoch 25 - iter 14/20 - loss 0.27278902 - samples/sec: 62.78 - lr: 0.000008
2021-07-15 21:58:33,109 epoch 25 - iter 16/20 - loss 0.27493674 - samples/sec: 60.24 - lr: 0.000008
2021-07-15 21:58:34,152 epoch 25 - iter 18/20 - loss 0.27585628 - samples/sec: 61.39 - lr: 0.000008
2021-07-15 21:58:34,885 epoch 25 - iter 20/20 - loss 0.27482216 - samples/sec: 87.36 - lr: 0.000008
2021-07-15 21:58:34,886 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:34,886 EPOCH 25 done: loss 0.2748 - lr 0.0000075
2021-07-15 21:58:35,905 DEV : loss 0.3949671685695648 - score 0.944
2021-07-15 21:58:35,918 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:58:39,547 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:40,612 epoch 26 - iter 2/20 - loss 0.27317977 - samples/sec: 60.12 - lr: 0.000008
2021-07-15 21:58:41,692 epoch 26 - iter 4/20 - loss 0.27405667 - samples/sec: 59.30 - lr: 0.000008
2021-07-15 21:58:42,772 epoch 26 - iter 6/20 - loss 0.27815836 - samples/sec: 59.29 - lr: 0.000008
2021-07-15 21:58:43,852 epoch 26 - iter 8/20 - loss 0.27322394 - samples/sec: 59.29 - lr: 0.000008
2021-07-15 21:58:44,936 epoch 26 - iter 10/20 - loss 0.26345255 - samples/sec: 59.06 - lr: 0.000008
2021-07-15 21:58:45,991 epoch 26 - iter 12/20 - loss 0.26055968 - samples/sec: 60.74 - lr: 0.000008
2021-07-15 21:58:47,044 epoch 26 - iter 14/20 - loss 0.24889649 - samples/sec: 60.78 - lr: 0.000008
2021-07-15 21:58:48,103 epoch 26 - iter 16/20 - loss 0.25451912 - samples/sec: 60.49 - lr: 0.000008
2021-07-15 21:58:49,161 epoch 26 - iter 18/20 - loss 0.26090794 - samples/sec: 60.48 - lr: 0.000008
2021-07-15 21:58:49,904 epoch 26 - iter 20/20 - loss 0.26540657 - samples/sec: 86.19 - lr: 0.000008
2021-07-15 21:58:49,905 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:49,905 EPOCH 26 done: loss 0.2654 - lr 0.0000075
2021-07-15 21:58:50,921 DEV : loss 0.4028330445289612 - score 0.9438
2021-07-15 21:58:50,935 BAD EPOCHS (no improvement): 1
2021-07-15 21:58:50,935 ----------------------------------------------------------------------------------------------------
2021-07-15 21:58:52,119 epoch 27 - iter 2/20 - loss 0.25808549 - samples/sec: 54.06 - lr: 0.000008
2021-07-15 21:58:53,202 epoch 27 - iter 4/20 - loss 0.23120654 - samples/sec: 59.13 - lr: 0.000008
2021-07-15 21:58:54,260 epoch 27 - iter 6/20 - loss 0.28502115 - samples/sec: 60.53 - lr: 0.000008
2021-07-15 21:58:55,356 epoch 27 - iter 8/20 - loss 0.29560181 - samples/sec: 58.45 - lr: 0.000008
2021-07-15 21:58:56,399 epoch 27 - iter 10/20 - loss 0.28103577 - samples/sec: 61.35 - lr: 0.000008
2021-07-15 21:58:57,494 epoch 27 - iter 12/20 - loss 0.26856556 - samples/sec: 58.49 - lr: 0.000008
2021-07-15 21:58:58,558 epoch 27 - iter 14/20 - loss 0.27941298 - samples/sec: 60.20 - lr: 0.000008
2021-07-15 21:58:59,598 epoch 27 - iter 16/20 - loss 0.27331455 - samples/sec: 61.57 - lr: 0.000008
2021-07-15 21:59:00,641 epoch 27 - iter 18/20 - loss 0.26179198 - samples/sec: 61.36 - lr: 0.000008
2021-07-15 21:59:01,384 epoch 27 - iter 20/20 - loss 0.26125098 - samples/sec: 86.18 - lr: 0.000008
2021-07-15 21:59:01,385 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:01,385 EPOCH 27 done: loss 0.2613 - lr 0.0000075
2021-07-15 21:59:02,411 DEV : loss 0.4003276824951172 - score 0.9459
2021-07-15 21:59:02,424 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 21:59:05,742 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:06,819 epoch 28 - iter 2/20 - loss 0.33318865 - samples/sec: 59.51 - lr: 0.000008
2021-07-15 21:59:07,879 epoch 28 - iter 4/20 - loss 0.30353653 - samples/sec: 60.39 - lr: 0.000008
2021-07-15 21:59:08,963 epoch 28 - iter 6/20 - loss 0.30472415 - samples/sec: 59.04 - lr: 0.000008
2021-07-15 21:59:10,043 epoch 28 - iter 8/20 - loss 0.28257814 - samples/sec: 59.29 - lr: 0.000008
2021-07-15 21:59:11,087 epoch 28 - iter 10/20 - loss 0.27011520 - samples/sec: 61.36 - lr: 0.000008
2021-07-15 21:59:12,147 epoch 28 - iter 12/20 - loss 0.26132532 - samples/sec: 60.39 - lr: 0.000008
2021-07-15 21:59:13,235 epoch 28 - iter 14/20 - loss 0.26152542 - samples/sec: 58.89 - lr: 0.000008
2021-07-15 21:59:14,303 epoch 28 - iter 16/20 - loss 0.25936674 - samples/sec: 59.91 - lr: 0.000008
2021-07-15 21:59:15,363 epoch 28 - iter 18/20 - loss 0.26582439 - samples/sec: 60.44 - lr: 0.000008
2021-07-15 21:59:16,106 epoch 28 - iter 20/20 - loss 0.26351245 - samples/sec: 86.14 - lr: 0.000008
2021-07-15 21:59:16,107 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:16,107 EPOCH 28 done: loss 0.2635 - lr 0.0000075
2021-07-15 21:59:17,128 DEV : loss 0.3968862295150757 - score 0.944
2021-07-15 21:59:17,142 BAD EPOCHS (no improvement): 1
2021-07-15 21:59:17,142 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:18,216 epoch 29 - iter 2/20 - loss 0.23518932 - samples/sec: 59.62 - lr: 0.000008
2021-07-15 21:59:19,287 epoch 29 - iter 4/20 - loss 0.21440186 - samples/sec: 59.79 - lr: 0.000008
2021-07-15 21:59:20,375 epoch 29 - iter 6/20 - loss 0.24696306 - samples/sec: 58.85 - lr: 0.000008
2021-07-15 21:59:21,416 epoch 29 - iter 8/20 - loss 0.21855654 - samples/sec: 61.52 - lr: 0.000008
2021-07-15 21:59:22,504 epoch 29 - iter 10/20 - loss 0.23510381 - samples/sec: 58.87 - lr: 0.000008
2021-07-15 21:59:23,578 epoch 29 - iter 12/20 - loss 0.23457985 - samples/sec: 59.59 - lr: 0.000008
2021-07-15 21:59:24,666 epoch 29 - iter 14/20 - loss 0.23298122 - samples/sec: 58.85 - lr: 0.000008
2021-07-15 21:59:25,695 epoch 29 - iter 16/20 - loss 0.23397021 - samples/sec: 62.26 - lr: 0.000008
2021-07-15 21:59:26,764 epoch 29 - iter 18/20 - loss 0.24478578 - samples/sec: 59.90 - lr: 0.000008
2021-07-15 21:59:27,483 epoch 29 - iter 20/20 - loss 0.27585540 - samples/sec: 89.06 - lr: 0.000008
2021-07-15 21:59:27,483 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:27,483 EPOCH 29 done: loss 0.2759 - lr 0.0000075
2021-07-15 21:59:28,501 DEV : loss 0.41017040610313416 - score 0.9395
2021-07-15 21:59:28,515 BAD EPOCHS (no improvement): 2
2021-07-15 21:59:28,515 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:29,564 epoch 30 - iter 2/20 - loss 0.33534946 - samples/sec: 61.06 - lr: 0.000008
2021-07-15 21:59:30,589 epoch 30 - iter 4/20 - loss 0.34069439 - samples/sec: 62.48 - lr: 0.000008
2021-07-15 21:59:31,669 epoch 30 - iter 6/20 - loss 0.33048123 - samples/sec: 59.28 - lr: 0.000008
2021-07-15 21:59:32,740 epoch 30 - iter 8/20 - loss 0.29305955 - samples/sec: 59.79 - lr: 0.000008
2021-07-15 21:59:33,797 epoch 30 - iter 10/20 - loss 0.31090964 - samples/sec: 60.57 - lr: 0.000008
2021-07-15 21:59:34,857 epoch 30 - iter 12/20 - loss 0.32452953 - samples/sec: 60.39 - lr: 0.000008
2021-07-15 21:59:35,921 epoch 30 - iter 14/20 - loss 0.31539239 - samples/sec: 60.21 - lr: 0.000008
2021-07-15 21:59:36,974 epoch 30 - iter 16/20 - loss 0.30262176 - samples/sec: 60.80 - lr: 0.000008
2021-07-15 21:59:38,033 epoch 30 - iter 18/20 - loss 0.29797659 - samples/sec: 60.46 - lr: 0.000008
2021-07-15 21:59:38,765 epoch 30 - iter 20/20 - loss 0.29554176 - samples/sec: 87.45 - lr: 0.000008
2021-07-15 21:59:38,766 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:38,766 EPOCH 30 done: loss 0.2955 - lr 0.0000075
2021-07-15 21:59:39,785 DEV : loss 0.39447352290153503 - score 0.944
2021-07-15 21:59:39,799 BAD EPOCHS (no improvement): 3
2021-07-15 21:59:39,799 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:40,826 epoch 31 - iter 2/20 - loss 0.30711770 - samples/sec: 62.32 - lr: 0.000008
2021-07-15 21:59:41,876 epoch 31 - iter 4/20 - loss 0.28548601 - samples/sec: 61.02 - lr: 0.000008
2021-07-15 21:59:42,931 epoch 31 - iter 6/20 - loss 0.30087083 - samples/sec: 60.65 - lr: 0.000008
2021-07-15 21:59:43,989 epoch 31 - iter 8/20 - loss 0.31230611 - samples/sec: 60.57 - lr: 0.000008
2021-07-15 21:59:45,173 epoch 31 - iter 10/20 - loss 0.29943655 - samples/sec: 54.04 - lr: 0.000008
2021-07-15 21:59:46,221 epoch 31 - iter 12/20 - loss 0.29306286 - samples/sec: 61.13 - lr: 0.000008
2021-07-15 21:59:47,292 epoch 31 - iter 14/20 - loss 0.28335791 - samples/sec: 59.80 - lr: 0.000008
2021-07-15 21:59:48,354 epoch 31 - iter 16/20 - loss 0.26675496 - samples/sec: 60.27 - lr: 0.000008
2021-07-15 21:59:49,420 epoch 31 - iter 18/20 - loss 0.26181854 - samples/sec: 60.07 - lr: 0.000008
2021-07-15 21:59:50,162 epoch 31 - iter 20/20 - loss 0.27700503 - samples/sec: 86.31 - lr: 0.000008
2021-07-15 21:59:50,162 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:50,162 EPOCH 31 done: loss 0.2770 - lr 0.0000075
2021-07-15 21:59:51,180 DEV : loss 0.3941749930381775 - score 0.944
Epoch    31: reducing learning rate of group 0 to 3.7500e-06.
2021-07-15 21:59:51,193 BAD EPOCHS (no improvement): 4
2021-07-15 21:59:51,194 ----------------------------------------------------------------------------------------------------
2021-07-15 21:59:52,236 epoch 32 - iter 2/20 - loss 0.21646580 - samples/sec: 61.46 - lr: 0.000004
2021-07-15 21:59:53,267 epoch 32 - iter 4/20 - loss 0.28706326 - samples/sec: 62.06 - lr: 0.000004
2021-07-15 21:59:54,335 epoch 32 - iter 6/20 - loss 0.29431491 - samples/sec: 59.95 - lr: 0.000004
2021-07-15 21:59:55,384 epoch 32 - iter 8/20 - loss 0.27803399 - samples/sec: 61.05 - lr: 0.000004
2021-07-15 21:59:56,398 epoch 32 - iter 10/20 - loss 0.24679063 - samples/sec: 63.17 - lr: 0.000004
2021-07-15 21:59:57,469 epoch 32 - iter 12/20 - loss 0.26272411 - samples/sec: 59.76 - lr: 0.000004
2021-07-15 21:59:58,524 epoch 32 - iter 14/20 - loss 0.26229453 - samples/sec: 60.72 - lr: 0.000004
2021-07-15 21:59:59,609 epoch 32 - iter 16/20 - loss 0.25441237 - samples/sec: 59.00 - lr: 0.000004
2021-07-15 22:00:00,681 epoch 32 - iter 18/20 - loss 0.25958426 - samples/sec: 59.75 - lr: 0.000004
2021-07-15 22:00:01,441 epoch 32 - iter 20/20 - loss 0.25481802 - samples/sec: 84.24 - lr: 0.000004
2021-07-15 22:00:01,441 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:01,441 EPOCH 32 done: loss 0.2548 - lr 0.0000038
2021-07-15 22:00:02,461 DEV : loss 0.38860341906547546 - score 0.944
2021-07-15 22:00:02,474 BAD EPOCHS (no improvement): 1
2021-07-15 22:00:02,474 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:03,519 epoch 33 - iter 2/20 - loss 0.32133666 - samples/sec: 61.30 - lr: 0.000004
2021-07-15 22:00:04,576 epoch 33 - iter 4/20 - loss 0.29697999 - samples/sec: 60.59 - lr: 0.000004
2021-07-15 22:00:05,644 epoch 33 - iter 6/20 - loss 0.27502613 - samples/sec: 59.92 - lr: 0.000004
2021-07-15 22:00:06,707 epoch 33 - iter 8/20 - loss 0.29254869 - samples/sec: 60.24 - lr: 0.000004
2021-07-15 22:00:07,792 epoch 33 - iter 10/20 - loss 0.27775912 - samples/sec: 59.01 - lr: 0.000004
2021-07-15 22:00:08,844 epoch 33 - iter 12/20 - loss 0.26132482 - samples/sec: 60.87 - lr: 0.000004
2021-07-15 22:00:09,935 epoch 33 - iter 14/20 - loss 0.26274051 - samples/sec: 58.72 - lr: 0.000004
2021-07-15 22:00:10,991 epoch 33 - iter 16/20 - loss 0.26628704 - samples/sec: 60.62 - lr: 0.000004
2021-07-15 22:00:12,026 epoch 33 - iter 18/20 - loss 0.26095084 - samples/sec: 61.87 - lr: 0.000004
2021-07-15 22:00:12,785 epoch 33 - iter 20/20 - loss 0.26139044 - samples/sec: 84.43 - lr: 0.000004
2021-07-15 22:00:12,785 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:12,785 EPOCH 33 done: loss 0.2614 - lr 0.0000038
2021-07-15 22:00:13,810 DEV : loss 0.391331285238266 - score 0.944
2021-07-15 22:00:13,823 BAD EPOCHS (no improvement): 2
2021-07-15 22:00:13,824 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:14,899 epoch 34 - iter 2/20 - loss 0.22193420 - samples/sec: 59.55 - lr: 0.000004
2021-07-15 22:00:15,964 epoch 34 - iter 4/20 - loss 0.23524539 - samples/sec: 60.12 - lr: 0.000004
2021-07-15 22:00:17,011 epoch 34 - iter 6/20 - loss 0.24703257 - samples/sec: 61.13 - lr: 0.000004
2021-07-15 22:00:18,085 epoch 34 - iter 8/20 - loss 0.25014851 - samples/sec: 59.60 - lr: 0.000004
2021-07-15 22:00:19,152 epoch 34 - iter 10/20 - loss 0.25154571 - samples/sec: 60.05 - lr: 0.000004
2021-07-15 22:00:20,239 epoch 34 - iter 12/20 - loss 0.26300908 - samples/sec: 58.88 - lr: 0.000004
2021-07-15 22:00:21,315 epoch 34 - iter 14/20 - loss 0.25859099 - samples/sec: 59.53 - lr: 0.000004
2021-07-15 22:00:22,360 epoch 34 - iter 16/20 - loss 0.25056431 - samples/sec: 61.26 - lr: 0.000004
2021-07-15 22:00:23,408 epoch 34 - iter 18/20 - loss 0.25819171 - samples/sec: 61.11 - lr: 0.000004
2021-07-15 22:00:24,149 epoch 34 - iter 20/20 - loss 0.25507330 - samples/sec: 86.37 - lr: 0.000004
2021-07-15 22:00:24,150 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:24,150 EPOCH 34 done: loss 0.2551 - lr 0.0000038
2021-07-15 22:00:25,169 DEV : loss 0.3879716396331787 - score 0.9461
2021-07-15 22:00:25,183 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:00:28,315 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:29,359 epoch 35 - iter 2/20 - loss 0.21674033 - samples/sec: 61.39 - lr: 0.000004
2021-07-15 22:00:30,439 epoch 35 - iter 4/20 - loss 0.26678953 - samples/sec: 59.27 - lr: 0.000004
2021-07-15 22:00:31,520 epoch 35 - iter 6/20 - loss 0.27251564 - samples/sec: 59.24 - lr: 0.000004
2021-07-15 22:00:32,595 epoch 35 - iter 8/20 - loss 0.28477290 - samples/sec: 59.54 - lr: 0.000004
2021-07-15 22:00:33,654 epoch 35 - iter 10/20 - loss 0.28061414 - samples/sec: 60.47 - lr: 0.000004
2021-07-15 22:00:34,708 epoch 35 - iter 12/20 - loss 0.26623050 - samples/sec: 60.79 - lr: 0.000004
2021-07-15 22:00:35,735 epoch 35 - iter 14/20 - loss 0.25444753 - samples/sec: 62.30 - lr: 0.000004
2021-07-15 22:00:36,811 epoch 35 - iter 16/20 - loss 0.24147305 - samples/sec: 59.53 - lr: 0.000004
2021-07-15 22:00:37,855 epoch 35 - iter 18/20 - loss 0.24496237 - samples/sec: 61.35 - lr: 0.000004
2021-07-15 22:00:38,601 epoch 35 - iter 20/20 - loss 0.24723713 - samples/sec: 85.79 - lr: 0.000004
2021-07-15 22:00:38,602 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:38,602 EPOCH 35 done: loss 0.2472 - lr 0.0000038
2021-07-15 22:00:39,622 DEV : loss 0.3902064263820648 - score 0.944
2021-07-15 22:00:39,635 BAD EPOCHS (no improvement): 1
2021-07-15 22:00:39,635 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:40,786 epoch 36 - iter 2/20 - loss 0.28607330 - samples/sec: 55.67 - lr: 0.000004
2021-07-15 22:00:41,860 epoch 36 - iter 4/20 - loss 0.23888125 - samples/sec: 59.62 - lr: 0.000004
2021-07-15 22:00:42,915 epoch 36 - iter 6/20 - loss 0.22323674 - samples/sec: 60.70 - lr: 0.000004
2021-07-15 22:00:43,967 epoch 36 - iter 8/20 - loss 0.22110288 - samples/sec: 60.83 - lr: 0.000004
2021-07-15 22:00:45,036 epoch 36 - iter 10/20 - loss 0.25522798 - samples/sec: 59.93 - lr: 0.000004
2021-07-15 22:00:46,093 epoch 36 - iter 12/20 - loss 0.24501264 - samples/sec: 60.54 - lr: 0.000004
2021-07-15 22:00:47,168 epoch 36 - iter 14/20 - loss 0.24714877 - samples/sec: 59.61 - lr: 0.000004
2021-07-15 22:00:48,237 epoch 36 - iter 16/20 - loss 0.23492409 - samples/sec: 59.85 - lr: 0.000004
2021-07-15 22:00:49,306 epoch 36 - iter 18/20 - loss 0.23489243 - samples/sec: 59.90 - lr: 0.000004
2021-07-15 22:00:50,042 epoch 36 - iter 20/20 - loss 0.24881814 - samples/sec: 87.09 - lr: 0.000004
2021-07-15 22:00:50,042 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:50,042 EPOCH 36 done: loss 0.2488 - lr 0.0000038
2021-07-15 22:00:51,063 DEV : loss 0.387400358915329 - score 0.9461
2021-07-15 22:00:51,077 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:00:55,051 ----------------------------------------------------------------------------------------------------
2021-07-15 22:00:56,094 epoch 37 - iter 2/20 - loss 0.19541837 - samples/sec: 61.44 - lr: 0.000004
2021-07-15 22:00:57,148 epoch 37 - iter 4/20 - loss 0.27797430 - samples/sec: 60.77 - lr: 0.000004
2021-07-15 22:00:58,224 epoch 37 - iter 6/20 - loss 0.25917657 - samples/sec: 59.46 - lr: 0.000004
2021-07-15 22:00:59,270 epoch 37 - iter 8/20 - loss 0.25933065 - samples/sec: 61.22 - lr: 0.000004
2021-07-15 22:01:00,306 epoch 37 - iter 10/20 - loss 0.25835485 - samples/sec: 61.81 - lr: 0.000004
2021-07-15 22:01:01,359 epoch 37 - iter 12/20 - loss 0.24829173 - samples/sec: 60.81 - lr: 0.000004
2021-07-15 22:01:02,464 epoch 37 - iter 14/20 - loss 0.24963539 - samples/sec: 57.94 - lr: 0.000004
2021-07-15 22:01:03,546 epoch 37 - iter 16/20 - loss 0.26510785 - samples/sec: 59.18 - lr: 0.000004
2021-07-15 22:01:04,626 epoch 37 - iter 18/20 - loss 0.26343923 - samples/sec: 59.30 - lr: 0.000004
2021-07-15 22:01:05,367 epoch 37 - iter 20/20 - loss 0.25302372 - samples/sec: 86.45 - lr: 0.000004
2021-07-15 22:01:05,367 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:05,368 EPOCH 37 done: loss 0.2530 - lr 0.0000038
2021-07-15 22:01:06,389 DEV : loss 0.3839609622955322 - score 0.9461
2021-07-15 22:01:06,402 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:01:10,107 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:11,159 epoch 38 - iter 2/20 - loss 0.23431707 - samples/sec: 60.86 - lr: 0.000004
2021-07-15 22:01:12,239 epoch 38 - iter 4/20 - loss 0.23547918 - samples/sec: 59.29 - lr: 0.000004
2021-07-15 22:01:13,299 epoch 38 - iter 6/20 - loss 0.28044130 - samples/sec: 60.41 - lr: 0.000004
2021-07-15 22:01:14,376 epoch 38 - iter 8/20 - loss 0.26207654 - samples/sec: 59.48 - lr: 0.000004
2021-07-15 22:01:15,422 epoch 38 - iter 10/20 - loss 0.24776954 - samples/sec: 61.18 - lr: 0.000004
2021-07-15 22:01:16,471 epoch 38 - iter 12/20 - loss 0.26490164 - samples/sec: 61.06 - lr: 0.000004
2021-07-15 22:01:17,538 epoch 38 - iter 14/20 - loss 0.26360068 - samples/sec: 60.00 - lr: 0.000004
2021-07-15 22:01:18,612 epoch 38 - iter 16/20 - loss 0.25816246 - samples/sec: 59.63 - lr: 0.000004
2021-07-15 22:01:19,692 epoch 38 - iter 18/20 - loss 0.26686526 - samples/sec: 59.30 - lr: 0.000004
2021-07-15 22:01:20,421 epoch 38 - iter 20/20 - loss 0.26815185 - samples/sec: 87.84 - lr: 0.000004
2021-07-15 22:01:20,421 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:20,421 EPOCH 38 done: loss 0.2682 - lr 0.0000038
2021-07-15 22:01:21,445 DEV : loss 0.37920552492141724 - score 0.9461
2021-07-15 22:01:21,458 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:01:25,174 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:26,236 epoch 39 - iter 2/20 - loss 0.15752828 - samples/sec: 60.30 - lr: 0.000004
2021-07-15 22:01:27,318 epoch 39 - iter 4/20 - loss 0.16452372 - samples/sec: 59.20 - lr: 0.000004
2021-07-15 22:01:28,399 epoch 39 - iter 6/20 - loss 0.20373268 - samples/sec: 59.24 - lr: 0.000004
2021-07-15 22:01:29,451 epoch 39 - iter 8/20 - loss 0.20316619 - samples/sec: 60.85 - lr: 0.000004
2021-07-15 22:01:30,507 epoch 39 - iter 10/20 - loss 0.21891138 - samples/sec: 60.61 - lr: 0.000004
2021-07-15 22:01:31,569 epoch 39 - iter 12/20 - loss 0.21056080 - samples/sec: 60.33 - lr: 0.000004
2021-07-15 22:01:32,624 epoch 39 - iter 14/20 - loss 0.20111632 - samples/sec: 60.70 - lr: 0.000004
2021-07-15 22:01:33,676 epoch 39 - iter 16/20 - loss 0.21274196 - samples/sec: 60.87 - lr: 0.000004
2021-07-15 22:01:34,730 epoch 39 - iter 18/20 - loss 0.21186955 - samples/sec: 60.75 - lr: 0.000004
2021-07-15 22:01:35,473 epoch 39 - iter 20/20 - loss 0.23202805 - samples/sec: 86.18 - lr: 0.000004
2021-07-15 22:01:35,473 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:35,473 EPOCH 39 done: loss 0.2320 - lr 0.0000038
2021-07-15 22:01:36,496 DEV : loss 0.3881104588508606 - score 0.944
2021-07-15 22:01:36,510 BAD EPOCHS (no improvement): 1
2021-07-15 22:01:36,510 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:37,566 epoch 40 - iter 2/20 - loss 0.21892202 - samples/sec: 60.63 - lr: 0.000004
2021-07-15 22:01:38,588 epoch 40 - iter 4/20 - loss 0.24618228 - samples/sec: 62.64 - lr: 0.000004
2021-07-15 22:01:39,658 epoch 40 - iter 6/20 - loss 0.23066132 - samples/sec: 59.87 - lr: 0.000004
2021-07-15 22:01:40,726 epoch 40 - iter 8/20 - loss 0.22260619 - samples/sec: 59.95 - lr: 0.000004
2021-07-15 22:01:41,770 epoch 40 - iter 10/20 - loss 0.23381346 - samples/sec: 61.34 - lr: 0.000004
2021-07-15 22:01:42,859 epoch 40 - iter 12/20 - loss 0.23877125 - samples/sec: 58.79 - lr: 0.000004
2021-07-15 22:01:43,909 epoch 40 - iter 14/20 - loss 0.24064096 - samples/sec: 60.99 - lr: 0.000004
2021-07-15 22:01:44,989 epoch 40 - iter 16/20 - loss 0.23334454 - samples/sec: 59.29 - lr: 0.000004
2021-07-15 22:01:46,055 epoch 40 - iter 18/20 - loss 0.22128768 - samples/sec: 60.06 - lr: 0.000004
2021-07-15 22:01:46,909 epoch 40 - iter 20/20 - loss 0.22259164 - samples/sec: 75.01 - lr: 0.000004
2021-07-15 22:01:46,909 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:46,909 EPOCH 40 done: loss 0.2226 - lr 0.0000038
2021-07-15 22:01:47,927 DEV : loss 0.3869723677635193 - score 0.944
2021-07-15 22:01:47,941 BAD EPOCHS (no improvement): 2
2021-07-15 22:01:48,657 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:48,657 Testing using best model ...
2021-07-15 22:01:48,657 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/nld.rst.nldt/best-model.pt
2021-07-15 22:01:53,670 0.9636	0.9532	0.9584
2021-07-15 22:01:53,670 
Results:
- F1-score (micro) 0.9584
- F1-score (macro) 0.9584

By class:
SENT       tp: 265 - fp: 10 - fn: 13 - precision: 0.9636 - recall: 0.9532 - f1-score: 0.9584
2021-07-15 22:01:53,670 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/por.rst.cstn/
2021-07-15 22:01:53,680 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/por.rst.cstn
2021-07-15 22:01:53,681 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/por.rst.cstn/sent_train.txt
2021-07-15 22:01:53,683 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/por.rst.cstn/sent_dev.txt
2021-07-15 22:01:53,683 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/por.rst.cstn/sent_test.txt
Corpus: 1767 train + 316 dev + 592 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 22:01:57,057 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:57,058 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(29794, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 22:01:57,058 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:57,059 Corpus: "Corpus: 1767 train + 316 dev + 592 test sentences"
2021-07-15 22:01:57,059 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:57,059 Parameters:
2021-07-15 22:01:57,059  - learning_rate: "3e-05"
2021-07-15 22:01:57,059  - mini_batch_size: "32"
2021-07-15 22:01:57,059  - patience: "3"
2021-07-15 22:01:57,059  - anneal_factor: "0.5"
2021-07-15 22:01:57,059  - max_epochs: "40"
2021-07-15 22:01:57,059  - shuffle: "True"
2021-07-15 22:01:57,059  - train_with_dev: "False"
2021-07-15 22:01:57,059  - batch_growth_annealing: "False"
2021-07-15 22:01:57,059 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:57,059 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/por.rst.cstn"
2021-07-15 22:01:57,059 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:57,059 Device: cuda:0
2021-07-15 22:01:57,059 ----------------------------------------------------------------------------------------------------
2021-07-15 22:01:57,059 Embeddings storage mode: cpu
2021-07-15 22:01:57,062 ----------------------------------------------------------------------------------------------------
2021-07-15 22:02:02,172 epoch 1 - iter 5/56 - loss 46.64054642 - samples/sec: 31.32 - lr: 0.000030
2021-07-15 22:02:07,337 epoch 1 - iter 10/56 - loss 36.98440342 - samples/sec: 30.98 - lr: 0.000030
2021-07-15 22:02:12,480 epoch 1 - iter 15/56 - loss 29.62699680 - samples/sec: 31.11 - lr: 0.000030
2021-07-15 22:02:17,852 epoch 1 - iter 20/56 - loss 24.51193421 - samples/sec: 29.79 - lr: 0.000030
2021-07-15 22:02:23,036 epoch 1 - iter 25/56 - loss 20.87596975 - samples/sec: 30.87 - lr: 0.000030
2021-07-15 22:02:28,173 epoch 1 - iter 30/56 - loss 18.17837009 - samples/sec: 31.15 - lr: 0.000030
2021-07-15 22:02:33,339 epoch 1 - iter 35/56 - loss 16.16618151 - samples/sec: 30.98 - lr: 0.000030
2021-07-15 22:02:38,478 epoch 1 - iter 40/56 - loss 14.60474666 - samples/sec: 31.13 - lr: 0.000030
2021-07-15 22:02:43,633 epoch 1 - iter 45/56 - loss 13.32225847 - samples/sec: 31.04 - lr: 0.000030
2021-07-15 22:02:48,790 epoch 1 - iter 50/56 - loss 12.26306257 - samples/sec: 31.02 - lr: 0.000030
2021-07-15 22:02:53,974 epoch 1 - iter 55/56 - loss 11.36022969 - samples/sec: 30.87 - lr: 0.000030
2021-07-15 22:02:54,245 ----------------------------------------------------------------------------------------------------
2021-07-15 22:02:54,245 EPOCH 1 done: loss 11.1945 - lr 0.0000300
2021-07-15 22:02:59,917 DEV : loss 1.688058853149414 - score 0.0
2021-07-15 22:02:59,940 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:03:00,689 ----------------------------------------------------------------------------------------------------
2021-07-15 22:03:03,333 epoch 2 - iter 5/56 - loss 1.89360087 - samples/sec: 60.52 - lr: 0.000030
2021-07-15 22:03:05,991 epoch 2 - iter 10/56 - loss 1.83078493 - samples/sec: 60.22 - lr: 0.000030
2021-07-15 22:03:08,679 epoch 2 - iter 15/56 - loss 1.69712667 - samples/sec: 59.53 - lr: 0.000030
2021-07-15 22:03:11,320 epoch 2 - iter 20/56 - loss 1.58240901 - samples/sec: 60.61 - lr: 0.000030
2021-07-15 22:03:13,974 epoch 2 - iter 25/56 - loss 1.50501078 - samples/sec: 60.30 - lr: 0.000030
2021-07-15 22:03:16,667 epoch 2 - iter 30/56 - loss 1.43869117 - samples/sec: 59.43 - lr: 0.000030
2021-07-15 22:03:19,342 epoch 2 - iter 35/56 - loss 1.37672286 - samples/sec: 59.83 - lr: 0.000030
2021-07-15 22:03:22,186 epoch 2 - iter 40/56 - loss 1.32042317 - samples/sec: 56.27 - lr: 0.000030
2021-07-15 22:03:24,874 epoch 2 - iter 45/56 - loss 1.26785140 - samples/sec: 59.54 - lr: 0.000030
2021-07-15 22:03:27,521 epoch 2 - iter 50/56 - loss 1.22114571 - samples/sec: 60.46 - lr: 0.000030
2021-07-15 22:03:30,206 epoch 2 - iter 55/56 - loss 1.18301536 - samples/sec: 59.61 - lr: 0.000030
2021-07-15 22:03:30,377 ----------------------------------------------------------------------------------------------------
2021-07-15 22:03:30,377 EPOCH 2 done: loss 1.1740 - lr 0.0000300
2021-07-15 22:03:32,113 DEV : loss 0.39675411581993103 - score 0.9109
2021-07-15 22:03:32,137 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:03:35,711 ----------------------------------------------------------------------------------------------------
2021-07-15 22:03:38,362 epoch 3 - iter 5/56 - loss 0.86720879 - samples/sec: 60.39 - lr: 0.000030
2021-07-15 22:03:41,011 epoch 3 - iter 10/56 - loss 0.76738974 - samples/sec: 60.40 - lr: 0.000030
2021-07-15 22:03:43,692 epoch 3 - iter 15/56 - loss 0.80436378 - samples/sec: 59.68 - lr: 0.000030
2021-07-15 22:03:46,348 epoch 3 - iter 20/56 - loss 0.77876411 - samples/sec: 60.27 - lr: 0.000030
2021-07-15 22:03:49,028 epoch 3 - iter 25/56 - loss 0.73755417 - samples/sec: 59.72 - lr: 0.000030
2021-07-15 22:03:51,696 epoch 3 - iter 30/56 - loss 0.72716268 - samples/sec: 59.98 - lr: 0.000030
2021-07-15 22:03:54,376 epoch 3 - iter 35/56 - loss 0.71402573 - samples/sec: 59.72 - lr: 0.000030
2021-07-15 22:03:57,048 epoch 3 - iter 40/56 - loss 0.71977684 - samples/sec: 59.90 - lr: 0.000030
2021-07-15 22:03:59,707 epoch 3 - iter 45/56 - loss 0.70466485 - samples/sec: 60.17 - lr: 0.000030
2021-07-15 22:04:02,376 epoch 3 - iter 50/56 - loss 0.69212389 - samples/sec: 59.97 - lr: 0.000030
2021-07-15 22:04:05,039 epoch 3 - iter 55/56 - loss 0.68603613 - samples/sec: 60.10 - lr: 0.000030
2021-07-15 22:04:05,212 ----------------------------------------------------------------------------------------------------
2021-07-15 22:04:05,212 EPOCH 3 done: loss 0.6813 - lr 0.0000300
2021-07-15 22:04:06,936 DEV : loss 0.2627827823162079 - score 0.9476
2021-07-15 22:04:06,960 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:04:10,603 ----------------------------------------------------------------------------------------------------
2021-07-15 22:04:13,266 epoch 4 - iter 5/56 - loss 0.52860327 - samples/sec: 60.10 - lr: 0.000030
2021-07-15 22:04:15,967 epoch 4 - iter 10/56 - loss 0.53207765 - samples/sec: 59.27 - lr: 0.000030
2021-07-15 22:04:18,615 epoch 4 - iter 15/56 - loss 0.53047239 - samples/sec: 60.44 - lr: 0.000030
2021-07-15 22:04:21,267 epoch 4 - iter 20/56 - loss 0.53572563 - samples/sec: 60.33 - lr: 0.000030
2021-07-15 22:04:23,958 epoch 4 - iter 25/56 - loss 0.53458812 - samples/sec: 59.48 - lr: 0.000030
2021-07-15 22:04:26,596 epoch 4 - iter 30/56 - loss 0.51888140 - samples/sec: 60.66 - lr: 0.000030
2021-07-15 22:04:29,280 epoch 4 - iter 35/56 - loss 0.53372654 - samples/sec: 59.63 - lr: 0.000030
2021-07-15 22:04:31,967 epoch 4 - iter 40/56 - loss 0.52956310 - samples/sec: 59.58 - lr: 0.000030
2021-07-15 22:04:34,640 epoch 4 - iter 45/56 - loss 0.52722214 - samples/sec: 59.87 - lr: 0.000030
2021-07-15 22:04:37,290 epoch 4 - iter 50/56 - loss 0.53609939 - samples/sec: 60.38 - lr: 0.000030
2021-07-15 22:04:39,948 epoch 4 - iter 55/56 - loss 0.53178339 - samples/sec: 60.22 - lr: 0.000030
2021-07-15 22:04:40,116 ----------------------------------------------------------------------------------------------------
2021-07-15 22:04:40,117 EPOCH 4 done: loss 0.5257 - lr 0.0000300
2021-07-15 22:04:41,840 DEV : loss 0.20892594754695892 - score 0.9672
2021-07-15 22:04:41,863 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:04:45,479 ----------------------------------------------------------------------------------------------------
2021-07-15 22:04:48,141 epoch 5 - iter 5/56 - loss 0.52225561 - samples/sec: 60.13 - lr: 0.000030
2021-07-15 22:04:50,830 epoch 5 - iter 10/56 - loss 0.51073904 - samples/sec: 59.51 - lr: 0.000030
2021-07-15 22:04:53,500 epoch 5 - iter 15/56 - loss 0.45425834 - samples/sec: 59.94 - lr: 0.000030
2021-07-15 22:04:56,180 epoch 5 - iter 20/56 - loss 0.45993346 - samples/sec: 59.72 - lr: 0.000030
2021-07-15 22:04:58,845 epoch 5 - iter 25/56 - loss 0.45280838 - samples/sec: 60.06 - lr: 0.000030
2021-07-15 22:05:01,551 epoch 5 - iter 30/56 - loss 0.46547065 - samples/sec: 59.12 - lr: 0.000030
2021-07-15 22:05:04,194 epoch 5 - iter 35/56 - loss 0.45273165 - samples/sec: 60.56 - lr: 0.000030
2021-07-15 22:05:06,852 epoch 5 - iter 40/56 - loss 0.44604542 - samples/sec: 60.21 - lr: 0.000030
2021-07-15 22:05:09,507 epoch 5 - iter 45/56 - loss 0.45067339 - samples/sec: 60.27 - lr: 0.000030
2021-07-15 22:05:12,155 epoch 5 - iter 50/56 - loss 0.43540839 - samples/sec: 60.44 - lr: 0.000030
2021-07-15 22:05:14,815 epoch 5 - iter 55/56 - loss 0.43592759 - samples/sec: 60.18 - lr: 0.000030
2021-07-15 22:05:14,983 ----------------------------------------------------------------------------------------------------
2021-07-15 22:05:14,983 EPOCH 5 done: loss 0.4439 - lr 0.0000300
2021-07-15 22:05:16,714 DEV : loss 0.16670501232147217 - score 0.969
2021-07-15 22:05:16,738 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:05:20,371 ----------------------------------------------------------------------------------------------------
2021-07-15 22:05:23,048 epoch 6 - iter 5/56 - loss 0.34259524 - samples/sec: 59.81 - lr: 0.000030
2021-07-15 22:05:25,716 epoch 6 - iter 10/56 - loss 0.37202221 - samples/sec: 59.97 - lr: 0.000030
2021-07-15 22:05:28,386 epoch 6 - iter 15/56 - loss 0.36371590 - samples/sec: 59.95 - lr: 0.000030
2021-07-15 22:05:31,051 epoch 6 - iter 20/56 - loss 0.38231887 - samples/sec: 60.04 - lr: 0.000030
2021-07-15 22:05:33,726 epoch 6 - iter 25/56 - loss 0.37325367 - samples/sec: 59.84 - lr: 0.000030
2021-07-15 22:05:36,387 epoch 6 - iter 30/56 - loss 0.37131048 - samples/sec: 60.14 - lr: 0.000030
2021-07-15 22:05:39,001 epoch 6 - iter 35/56 - loss 0.36167709 - samples/sec: 61.21 - lr: 0.000030
2021-07-15 22:05:41,658 epoch 6 - iter 40/56 - loss 0.37351039 - samples/sec: 60.24 - lr: 0.000030
2021-07-15 22:05:44,306 epoch 6 - iter 45/56 - loss 0.36676395 - samples/sec: 60.43 - lr: 0.000030
2021-07-15 22:05:47,157 epoch 6 - iter 50/56 - loss 0.36386451 - samples/sec: 56.13 - lr: 0.000030
2021-07-15 22:05:49,823 epoch 6 - iter 55/56 - loss 0.36078121 - samples/sec: 60.03 - lr: 0.000030
2021-07-15 22:05:49,991 ----------------------------------------------------------------------------------------------------
2021-07-15 22:05:49,991 EPOCH 6 done: loss 0.3555 - lr 0.0000300
2021-07-15 22:05:51,715 DEV : loss 0.1390417069196701 - score 0.971
2021-07-15 22:05:51,738 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:05:55,415 ----------------------------------------------------------------------------------------------------
2021-07-15 22:05:58,063 epoch 7 - iter 5/56 - loss 0.33731205 - samples/sec: 60.44 - lr: 0.000030
2021-07-15 22:06:00,693 epoch 7 - iter 10/56 - loss 0.33540322 - samples/sec: 60.86 - lr: 0.000030
2021-07-15 22:06:03,345 epoch 7 - iter 15/56 - loss 0.32701096 - samples/sec: 60.36 - lr: 0.000030
2021-07-15 22:06:06,002 epoch 7 - iter 20/56 - loss 0.33029988 - samples/sec: 60.24 - lr: 0.000030
2021-07-15 22:06:08,621 epoch 7 - iter 25/56 - loss 0.33245641 - samples/sec: 61.09 - lr: 0.000030
2021-07-15 22:06:11,252 epoch 7 - iter 30/56 - loss 0.32997262 - samples/sec: 60.84 - lr: 0.000030
2021-07-15 22:06:13,884 epoch 7 - iter 35/56 - loss 0.32826885 - samples/sec: 60.80 - lr: 0.000030
2021-07-15 22:06:16,538 epoch 7 - iter 40/56 - loss 0.32419318 - samples/sec: 60.31 - lr: 0.000030
2021-07-15 22:06:19,193 epoch 7 - iter 45/56 - loss 0.32870572 - samples/sec: 60.29 - lr: 0.000030
2021-07-15 22:06:21,832 epoch 7 - iter 50/56 - loss 0.31892571 - samples/sec: 60.62 - lr: 0.000030
2021-07-15 22:06:24,477 epoch 7 - iter 55/56 - loss 0.31466975 - samples/sec: 60.53 - lr: 0.000030
2021-07-15 22:06:24,644 ----------------------------------------------------------------------------------------------------
2021-07-15 22:06:24,645 EPOCH 7 done: loss 0.3120 - lr 0.0000300
2021-07-15 22:06:26,367 DEV : loss 0.11644253879785538 - score 0.9786
2021-07-15 22:06:26,390 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:06:29,835 ----------------------------------------------------------------------------------------------------
2021-07-15 22:06:32,497 epoch 8 - iter 5/56 - loss 0.33079133 - samples/sec: 60.15 - lr: 0.000030
2021-07-15 22:06:35,137 epoch 8 - iter 10/56 - loss 0.29251323 - samples/sec: 60.62 - lr: 0.000030
2021-07-15 22:06:37,766 epoch 8 - iter 15/56 - loss 0.28715297 - samples/sec: 60.87 - lr: 0.000030
2021-07-15 22:06:40,365 epoch 8 - iter 20/56 - loss 0.31163711 - samples/sec: 61.58 - lr: 0.000030
2021-07-15 22:06:43,025 epoch 8 - iter 25/56 - loss 0.30473862 - samples/sec: 60.15 - lr: 0.000030
2021-07-15 22:06:45,655 epoch 8 - iter 30/56 - loss 0.29689765 - samples/sec: 60.85 - lr: 0.000030
2021-07-15 22:06:48,328 epoch 8 - iter 35/56 - loss 0.29344093 - samples/sec: 59.88 - lr: 0.000030
2021-07-15 22:06:50,977 epoch 8 - iter 40/56 - loss 0.28854935 - samples/sec: 60.42 - lr: 0.000030
2021-07-15 22:06:53,607 epoch 8 - iter 45/56 - loss 0.28217328 - samples/sec: 60.83 - lr: 0.000030
2021-07-15 22:06:56,275 epoch 8 - iter 50/56 - loss 0.27723899 - samples/sec: 59.99 - lr: 0.000030
2021-07-15 22:06:58,931 epoch 8 - iter 55/56 - loss 0.26889046 - samples/sec: 60.26 - lr: 0.000030
2021-07-15 22:06:59,102 ----------------------------------------------------------------------------------------------------
2021-07-15 22:06:59,102 EPOCH 8 done: loss 0.2659 - lr 0.0000300
2021-07-15 22:07:00,823 DEV : loss 0.10528624057769775 - score 0.9786
2021-07-15 22:07:00,847 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:07:04,575 ----------------------------------------------------------------------------------------------------
2021-07-15 22:07:07,238 epoch 9 - iter 5/56 - loss 0.21801996 - samples/sec: 60.11 - lr: 0.000030
2021-07-15 22:07:09,878 epoch 9 - iter 10/56 - loss 0.22530918 - samples/sec: 60.62 - lr: 0.000030
2021-07-15 22:07:12,589 epoch 9 - iter 15/56 - loss 0.24765934 - samples/sec: 59.03 - lr: 0.000030
2021-07-15 22:07:15,255 epoch 9 - iter 20/56 - loss 0.24470044 - samples/sec: 60.04 - lr: 0.000030
2021-07-15 22:07:17,920 epoch 9 - iter 25/56 - loss 0.23791501 - samples/sec: 60.06 - lr: 0.000030
2021-07-15 22:07:20,568 epoch 9 - iter 30/56 - loss 0.24207918 - samples/sec: 60.43 - lr: 0.000030
2021-07-15 22:07:23,243 epoch 9 - iter 35/56 - loss 0.23876122 - samples/sec: 59.84 - lr: 0.000030
2021-07-15 22:07:25,896 epoch 9 - iter 40/56 - loss 0.23450856 - samples/sec: 60.32 - lr: 0.000030
2021-07-15 22:07:28,572 epoch 9 - iter 45/56 - loss 0.23100658 - samples/sec: 59.81 - lr: 0.000030
2021-07-15 22:07:31,255 epoch 9 - iter 50/56 - loss 0.23482306 - samples/sec: 59.65 - lr: 0.000030
2021-07-15 22:07:33,939 epoch 9 - iter 55/56 - loss 0.23840238 - samples/sec: 59.62 - lr: 0.000030
2021-07-15 22:07:34,112 ----------------------------------------------------------------------------------------------------
2021-07-15 22:07:34,113 EPOCH 9 done: loss 0.2442 - lr 0.0000300
2021-07-15 22:07:35,834 DEV : loss 0.09672478586435318 - score 0.9805
2021-07-15 22:07:35,858 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:07:39,174 ----------------------------------------------------------------------------------------------------
2021-07-15 22:07:41,838 epoch 10 - iter 5/56 - loss 0.24979000 - samples/sec: 60.09 - lr: 0.000030
2021-07-15 22:07:44,520 epoch 10 - iter 10/56 - loss 0.28355088 - samples/sec: 59.67 - lr: 0.000030
2021-07-15 22:07:47,164 epoch 10 - iter 15/56 - loss 0.26396197 - samples/sec: 60.53 - lr: 0.000030
2021-07-15 22:07:49,840 epoch 10 - iter 20/56 - loss 0.24958075 - samples/sec: 59.82 - lr: 0.000030
2021-07-15 22:07:52,520 epoch 10 - iter 25/56 - loss 0.22911093 - samples/sec: 59.70 - lr: 0.000030
2021-07-15 22:07:55,219 epoch 10 - iter 30/56 - loss 0.24413852 - samples/sec: 59.31 - lr: 0.000030
2021-07-15 22:07:57,888 epoch 10 - iter 35/56 - loss 0.24376105 - samples/sec: 59.96 - lr: 0.000030
2021-07-15 22:08:00,558 epoch 10 - iter 40/56 - loss 0.23002072 - samples/sec: 59.94 - lr: 0.000030
2021-07-15 22:08:03,427 epoch 10 - iter 45/56 - loss 0.22845568 - samples/sec: 55.78 - lr: 0.000030
2021-07-15 22:08:06,067 epoch 10 - iter 50/56 - loss 0.22678999 - samples/sec: 60.63 - lr: 0.000030
2021-07-15 22:08:08,730 epoch 10 - iter 55/56 - loss 0.22045200 - samples/sec: 60.08 - lr: 0.000030
2021-07-15 22:08:08,900 ----------------------------------------------------------------------------------------------------
2021-07-15 22:08:08,900 EPOCH 10 done: loss 0.2286 - lr 0.0000300
2021-07-15 22:08:10,619 DEV : loss 0.08687106519937515 - score 0.9825
2021-07-15 22:08:10,643 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:08:14,270 ----------------------------------------------------------------------------------------------------
2021-07-15 22:08:16,942 epoch 11 - iter 5/56 - loss 0.21752641 - samples/sec: 59.90 - lr: 0.000030
2021-07-15 22:08:19,620 epoch 11 - iter 10/56 - loss 0.22289495 - samples/sec: 59.76 - lr: 0.000030
2021-07-15 22:08:22,299 epoch 11 - iter 15/56 - loss 0.19716954 - samples/sec: 59.75 - lr: 0.000030
2021-07-15 22:08:24,987 epoch 11 - iter 20/56 - loss 0.19841670 - samples/sec: 59.53 - lr: 0.000030
2021-07-15 22:08:27,642 epoch 11 - iter 25/56 - loss 0.20042123 - samples/sec: 60.29 - lr: 0.000030
2021-07-15 22:08:30,312 epoch 11 - iter 30/56 - loss 0.19004976 - samples/sec: 59.94 - lr: 0.000030
2021-07-15 22:08:32,983 epoch 11 - iter 35/56 - loss 0.19894269 - samples/sec: 59.91 - lr: 0.000030
2021-07-15 22:08:35,628 epoch 11 - iter 40/56 - loss 0.19381183 - samples/sec: 60.50 - lr: 0.000030
2021-07-15 22:08:38,311 epoch 11 - iter 45/56 - loss 0.19233898 - samples/sec: 59.67 - lr: 0.000030
2021-07-15 22:08:40,973 epoch 11 - iter 50/56 - loss 0.18714327 - samples/sec: 60.12 - lr: 0.000030
2021-07-15 22:08:43,625 epoch 11 - iter 55/56 - loss 0.18346267 - samples/sec: 60.34 - lr: 0.000030
2021-07-15 22:08:43,796 ----------------------------------------------------------------------------------------------------
2021-07-15 22:08:43,796 EPOCH 11 done: loss 0.1813 - lr 0.0000300
2021-07-15 22:08:45,518 DEV : loss 0.08487675338983536 - score 0.9863
2021-07-15 22:08:45,542 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:08:49,069 ----------------------------------------------------------------------------------------------------
2021-07-15 22:08:51,763 epoch 12 - iter 5/56 - loss 0.12747278 - samples/sec: 59.42 - lr: 0.000030
2021-07-15 22:08:54,460 epoch 12 - iter 10/56 - loss 0.13748521 - samples/sec: 59.34 - lr: 0.000030
2021-07-15 22:08:57,100 epoch 12 - iter 15/56 - loss 0.13538737 - samples/sec: 60.62 - lr: 0.000030
2021-07-15 22:08:59,800 epoch 12 - iter 20/56 - loss 0.14966184 - samples/sec: 59.27 - lr: 0.000030
2021-07-15 22:09:02,497 epoch 12 - iter 25/56 - loss 0.15825629 - samples/sec: 59.34 - lr: 0.000030
2021-07-15 22:09:05,192 epoch 12 - iter 30/56 - loss 0.16954674 - samples/sec: 59.39 - lr: 0.000030
2021-07-15 22:09:07,828 epoch 12 - iter 35/56 - loss 0.17518271 - samples/sec: 60.70 - lr: 0.000030
2021-07-15 22:09:10,467 epoch 12 - iter 40/56 - loss 0.17067805 - samples/sec: 60.66 - lr: 0.000030
2021-07-15 22:09:13,143 epoch 12 - iter 45/56 - loss 0.17513044 - samples/sec: 59.79 - lr: 0.000030
2021-07-15 22:09:15,778 epoch 12 - iter 50/56 - loss 0.17713462 - samples/sec: 60.73 - lr: 0.000030
2021-07-15 22:09:18,427 epoch 12 - iter 55/56 - loss 0.17839662 - samples/sec: 60.41 - lr: 0.000030
2021-07-15 22:09:18,599 ----------------------------------------------------------------------------------------------------
2021-07-15 22:09:18,599 EPOCH 12 done: loss 0.1759 - lr 0.0000300
2021-07-15 22:09:20,321 DEV : loss 0.08308180421590805 - score 0.9823
2021-07-15 22:09:20,345 BAD EPOCHS (no improvement): 1
2021-07-15 22:09:20,345 ----------------------------------------------------------------------------------------------------
2021-07-15 22:09:23,013 epoch 13 - iter 5/56 - loss 0.16874806 - samples/sec: 59.97 - lr: 0.000030
2021-07-15 22:09:25,698 epoch 13 - iter 10/56 - loss 0.18271617 - samples/sec: 59.61 - lr: 0.000030
2021-07-15 22:09:28,360 epoch 13 - iter 15/56 - loss 0.17861075 - samples/sec: 60.13 - lr: 0.000030
2021-07-15 22:09:31,046 epoch 13 - iter 20/56 - loss 0.18760516 - samples/sec: 59.57 - lr: 0.000030
2021-07-15 22:09:33,724 epoch 13 - iter 25/56 - loss 0.18386058 - samples/sec: 59.77 - lr: 0.000030
2021-07-15 22:09:36,383 epoch 13 - iter 30/56 - loss 0.17410601 - samples/sec: 60.18 - lr: 0.000030
2021-07-15 22:09:39,067 epoch 13 - iter 35/56 - loss 0.16430374 - samples/sec: 59.64 - lr: 0.000030
2021-07-15 22:09:41,727 epoch 13 - iter 40/56 - loss 0.15894737 - samples/sec: 60.17 - lr: 0.000030
2021-07-15 22:09:44,419 epoch 13 - iter 45/56 - loss 0.15869701 - samples/sec: 59.45 - lr: 0.000030
2021-07-15 22:09:47,058 epoch 13 - iter 50/56 - loss 0.15444406 - samples/sec: 60.64 - lr: 0.000030
2021-07-15 22:09:49,731 epoch 13 - iter 55/56 - loss 0.14820894 - samples/sec: 59.87 - lr: 0.000030
2021-07-15 22:09:49,894 ----------------------------------------------------------------------------------------------------
2021-07-15 22:09:49,894 EPOCH 13 done: loss 0.1466 - lr 0.0000300
2021-07-15 22:09:51,615 DEV : loss 0.07778987288475037 - score 0.9862
2021-07-15 22:09:51,639 BAD EPOCHS (no improvement): 2
2021-07-15 22:09:51,640 ----------------------------------------------------------------------------------------------------
2021-07-15 22:09:54,279 epoch 14 - iter 5/56 - loss 0.16295481 - samples/sec: 60.65 - lr: 0.000030
2021-07-15 22:09:56,963 epoch 14 - iter 10/56 - loss 0.13734085 - samples/sec: 59.61 - lr: 0.000030
2021-07-15 22:09:59,625 epoch 14 - iter 15/56 - loss 0.12913475 - samples/sec: 60.13 - lr: 0.000030
2021-07-15 22:10:02,318 epoch 14 - iter 20/56 - loss 0.15624657 - samples/sec: 59.41 - lr: 0.000030
2021-07-15 22:10:04,964 epoch 14 - iter 25/56 - loss 0.15997812 - samples/sec: 60.49 - lr: 0.000030
2021-07-15 22:10:07,669 epoch 14 - iter 30/56 - loss 0.16213680 - samples/sec: 59.17 - lr: 0.000030
2021-07-15 22:10:10,530 epoch 14 - iter 35/56 - loss 0.16101578 - samples/sec: 55.93 - lr: 0.000030
2021-07-15 22:10:13,200 epoch 14 - iter 40/56 - loss 0.15977579 - samples/sec: 59.95 - lr: 0.000030
2021-07-15 22:10:15,829 epoch 14 - iter 45/56 - loss 0.15951181 - samples/sec: 60.87 - lr: 0.000030
2021-07-15 22:10:18,503 epoch 14 - iter 50/56 - loss 0.15708753 - samples/sec: 59.85 - lr: 0.000030
2021-07-15 22:10:21,176 epoch 14 - iter 55/56 - loss 0.15870363 - samples/sec: 59.86 - lr: 0.000030
2021-07-15 22:10:21,348 ----------------------------------------------------------------------------------------------------
2021-07-15 22:10:21,348 EPOCH 14 done: loss 0.1570 - lr 0.0000300
2021-07-15 22:10:23,070 DEV : loss 0.07337833940982819 - score 0.9882
2021-07-15 22:10:23,094 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:10:26,731 ----------------------------------------------------------------------------------------------------
2021-07-15 22:10:29,384 epoch 15 - iter 5/56 - loss 0.17345080 - samples/sec: 60.35 - lr: 0.000030
2021-07-15 22:10:32,014 epoch 15 - iter 10/56 - loss 0.16501064 - samples/sec: 60.84 - lr: 0.000030
2021-07-15 22:10:34,664 epoch 15 - iter 15/56 - loss 0.14330301 - samples/sec: 60.39 - lr: 0.000030
2021-07-15 22:10:37,305 epoch 15 - iter 20/56 - loss 0.14035457 - samples/sec: 60.60 - lr: 0.000030
2021-07-15 22:10:39,939 epoch 15 - iter 25/56 - loss 0.14159742 - samples/sec: 60.76 - lr: 0.000030
2021-07-15 22:10:42,593 epoch 15 - iter 30/56 - loss 0.14579350 - samples/sec: 60.30 - lr: 0.000030
2021-07-15 22:10:45,262 epoch 15 - iter 35/56 - loss 0.14921840 - samples/sec: 59.95 - lr: 0.000030
2021-07-15 22:10:47,919 epoch 15 - iter 40/56 - loss 0.14217107 - samples/sec: 60.24 - lr: 0.000030
2021-07-15 22:10:50,580 epoch 15 - iter 45/56 - loss 0.13879160 - samples/sec: 60.15 - lr: 0.000030
2021-07-15 22:10:53,188 epoch 15 - iter 50/56 - loss 0.13454366 - samples/sec: 61.37 - lr: 0.000030
2021-07-15 22:10:55,801 epoch 15 - iter 55/56 - loss 0.13299797 - samples/sec: 61.24 - lr: 0.000030
2021-07-15 22:10:55,975 ----------------------------------------------------------------------------------------------------
2021-07-15 22:10:55,976 EPOCH 15 done: loss 0.1359 - lr 0.0000300
2021-07-15 22:10:57,699 DEV : loss 0.07131969928741455 - score 0.9863
2021-07-15 22:10:57,722 BAD EPOCHS (no improvement): 1
2021-07-15 22:10:57,723 ----------------------------------------------------------------------------------------------------
2021-07-15 22:11:00,352 epoch 16 - iter 5/56 - loss 0.06474493 - samples/sec: 60.88 - lr: 0.000030
2021-07-15 22:11:02,987 epoch 16 - iter 10/56 - loss 0.07498698 - samples/sec: 60.72 - lr: 0.000030
2021-07-15 22:11:05,643 epoch 16 - iter 15/56 - loss 0.10089613 - samples/sec: 60.26 - lr: 0.000030
2021-07-15 22:11:08,276 epoch 16 - iter 20/56 - loss 0.11723295 - samples/sec: 60.77 - lr: 0.000030
2021-07-15 22:11:10,922 epoch 16 - iter 25/56 - loss 0.13613677 - samples/sec: 60.50 - lr: 0.000030
2021-07-15 22:11:13,579 epoch 16 - iter 30/56 - loss 0.12801966 - samples/sec: 60.23 - lr: 0.000030
2021-07-15 22:11:16,231 epoch 16 - iter 35/56 - loss 0.12589469 - samples/sec: 60.34 - lr: 0.000030
2021-07-15 22:11:18,895 epoch 16 - iter 40/56 - loss 0.12722558 - samples/sec: 60.09 - lr: 0.000030
2021-07-15 22:11:21,596 epoch 16 - iter 45/56 - loss 0.13337399 - samples/sec: 59.25 - lr: 0.000030
2021-07-15 22:11:24,272 epoch 16 - iter 50/56 - loss 0.13344745 - samples/sec: 59.79 - lr: 0.000030
2021-07-15 22:11:26,935 epoch 16 - iter 55/56 - loss 0.13465627 - samples/sec: 60.11 - lr: 0.000030
2021-07-15 22:11:27,102 ----------------------------------------------------------------------------------------------------
2021-07-15 22:11:27,103 EPOCH 16 done: loss 0.1344 - lr 0.0000300
2021-07-15 22:11:28,828 DEV : loss 0.07422608137130737 - score 0.9862
2021-07-15 22:11:28,852 BAD EPOCHS (no improvement): 2
2021-07-15 22:11:28,852 ----------------------------------------------------------------------------------------------------
2021-07-15 22:11:31,495 epoch 17 - iter 5/56 - loss 0.13981878 - samples/sec: 60.56 - lr: 0.000030
2021-07-15 22:11:34,173 epoch 17 - iter 10/56 - loss 0.12089963 - samples/sec: 59.76 - lr: 0.000030
2021-07-15 22:11:36,834 epoch 17 - iter 15/56 - loss 0.11317763 - samples/sec: 60.14 - lr: 0.000030
2021-07-15 22:11:39,498 epoch 17 - iter 20/56 - loss 0.12105820 - samples/sec: 60.07 - lr: 0.000030
2021-07-15 22:11:42,182 epoch 17 - iter 25/56 - loss 0.12090098 - samples/sec: 59.62 - lr: 0.000030
2021-07-15 22:11:44,838 epoch 17 - iter 30/56 - loss 0.13131729 - samples/sec: 60.27 - lr: 0.000030
2021-07-15 22:11:47,499 epoch 17 - iter 35/56 - loss 0.13725665 - samples/sec: 60.14 - lr: 0.000030
2021-07-15 22:11:50,183 epoch 17 - iter 40/56 - loss 0.13593412 - samples/sec: 59.62 - lr: 0.000030
2021-07-15 22:11:52,842 epoch 17 - iter 45/56 - loss 0.13819878 - samples/sec: 60.20 - lr: 0.000030
2021-07-15 22:11:55,532 epoch 17 - iter 50/56 - loss 0.13511342 - samples/sec: 59.49 - lr: 0.000030
2021-07-15 22:11:58,196 epoch 17 - iter 55/56 - loss 0.13192504 - samples/sec: 60.08 - lr: 0.000030
2021-07-15 22:11:58,367 ----------------------------------------------------------------------------------------------------
2021-07-15 22:11:58,368 EPOCH 17 done: loss 0.1321 - lr 0.0000300
2021-07-15 22:12:00,092 DEV : loss 0.07152663916349411 - score 0.9862
2021-07-15 22:12:00,115 BAD EPOCHS (no improvement): 3
2021-07-15 22:12:00,116 ----------------------------------------------------------------------------------------------------
2021-07-15 22:12:02,779 epoch 18 - iter 5/56 - loss 0.14312582 - samples/sec: 60.08 - lr: 0.000030
2021-07-15 22:12:05,444 epoch 18 - iter 10/56 - loss 0.12406176 - samples/sec: 60.06 - lr: 0.000030
2021-07-15 22:12:08,095 epoch 18 - iter 15/56 - loss 0.14924964 - samples/sec: 60.37 - lr: 0.000030
2021-07-15 22:12:10,717 epoch 18 - iter 20/56 - loss 0.13933730 - samples/sec: 61.04 - lr: 0.000030
2021-07-15 22:12:13,376 epoch 18 - iter 25/56 - loss 0.13191201 - samples/sec: 60.20 - lr: 0.000030
2021-07-15 22:12:15,991 epoch 18 - iter 30/56 - loss 0.12606080 - samples/sec: 61.19 - lr: 0.000030
2021-07-15 22:12:18,664 epoch 18 - iter 35/56 - loss 0.12650161 - samples/sec: 59.87 - lr: 0.000030
2021-07-15 22:12:21,295 epoch 18 - iter 40/56 - loss 0.12525963 - samples/sec: 60.84 - lr: 0.000030
2021-07-15 22:12:23,918 epoch 18 - iter 45/56 - loss 0.12934545 - samples/sec: 61.01 - lr: 0.000030
2021-07-15 22:12:26,559 epoch 18 - iter 50/56 - loss 0.12931074 - samples/sec: 60.60 - lr: 0.000030
2021-07-15 22:12:29,200 epoch 18 - iter 55/56 - loss 0.13057956 - samples/sec: 60.59 - lr: 0.000030
2021-07-15 22:12:29,371 ----------------------------------------------------------------------------------------------------
2021-07-15 22:12:29,372 EPOCH 18 done: loss 0.1285 - lr 0.0000300
2021-07-15 22:12:31,292 DEV : loss 0.06464339792728424 - score 0.9883
2021-07-15 22:12:31,316 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:12:35,004 ----------------------------------------------------------------------------------------------------
2021-07-15 22:12:37,620 epoch 19 - iter 5/56 - loss 0.10356254 - samples/sec: 61.19 - lr: 0.000030
2021-07-15 22:12:40,279 epoch 19 - iter 10/56 - loss 0.10177974 - samples/sec: 60.17 - lr: 0.000030
2021-07-15 22:12:42,958 epoch 19 - iter 15/56 - loss 0.10613239 - samples/sec: 59.75 - lr: 0.000030
2021-07-15 22:12:45,624 epoch 19 - iter 20/56 - loss 0.09554635 - samples/sec: 60.01 - lr: 0.000030
2021-07-15 22:12:48,316 epoch 19 - iter 25/56 - loss 0.09899944 - samples/sec: 59.47 - lr: 0.000030
2021-07-15 22:12:50,980 epoch 19 - iter 30/56 - loss 0.10262363 - samples/sec: 60.07 - lr: 0.000030
2021-07-15 22:12:53,662 epoch 19 - iter 35/56 - loss 0.09827102 - samples/sec: 59.67 - lr: 0.000030
2021-07-15 22:12:56,324 epoch 19 - iter 40/56 - loss 0.10171046 - samples/sec: 60.12 - lr: 0.000030
2021-07-15 22:12:58,999 epoch 19 - iter 45/56 - loss 0.10562104 - samples/sec: 59.83 - lr: 0.000030
2021-07-15 22:13:01,657 epoch 19 - iter 50/56 - loss 0.10548153 - samples/sec: 60.22 - lr: 0.000030
2021-07-15 22:13:04,342 epoch 19 - iter 55/56 - loss 0.10298573 - samples/sec: 59.61 - lr: 0.000030
2021-07-15 22:13:04,513 ----------------------------------------------------------------------------------------------------
2021-07-15 22:13:04,513 EPOCH 19 done: loss 0.1094 - lr 0.0000300
2021-07-15 22:13:06,241 DEV : loss 0.06833948940038681 - score 0.9863
2021-07-15 22:13:06,265 BAD EPOCHS (no improvement): 1
2021-07-15 22:13:06,265 ----------------------------------------------------------------------------------------------------
2021-07-15 22:13:08,890 epoch 20 - iter 5/56 - loss 0.10688596 - samples/sec: 60.98 - lr: 0.000030
2021-07-15 22:13:11,567 epoch 20 - iter 10/56 - loss 0.11906129 - samples/sec: 59.78 - lr: 0.000030
2021-07-15 22:13:14,208 epoch 20 - iter 15/56 - loss 0.10628173 - samples/sec: 60.61 - lr: 0.000030
2021-07-15 22:13:16,888 epoch 20 - iter 20/56 - loss 0.10212366 - samples/sec: 59.70 - lr: 0.000030
2021-07-15 22:13:19,562 epoch 20 - iter 25/56 - loss 0.10054770 - samples/sec: 59.86 - lr: 0.000030
2021-07-15 22:13:22,243 epoch 20 - iter 30/56 - loss 0.10164866 - samples/sec: 59.69 - lr: 0.000030
2021-07-15 22:13:24,915 epoch 20 - iter 35/56 - loss 0.10228669 - samples/sec: 59.89 - lr: 0.000030
2021-07-15 22:13:27,615 epoch 20 - iter 40/56 - loss 0.10249316 - samples/sec: 59.28 - lr: 0.000030
2021-07-15 22:13:30,304 epoch 20 - iter 45/56 - loss 0.10222963 - samples/sec: 59.51 - lr: 0.000030
2021-07-15 22:13:32,951 epoch 20 - iter 50/56 - loss 0.10381096 - samples/sec: 60.45 - lr: 0.000030
2021-07-15 22:13:35,603 epoch 20 - iter 55/56 - loss 0.10405833 - samples/sec: 60.36 - lr: 0.000030
2021-07-15 22:13:35,767 ----------------------------------------------------------------------------------------------------
2021-07-15 22:13:35,768 EPOCH 20 done: loss 0.1025 - lr 0.0000300
2021-07-15 22:13:37,494 DEV : loss 0.0641256794333458 - score 0.9862
2021-07-15 22:13:37,518 BAD EPOCHS (no improvement): 2
2021-07-15 22:13:37,518 ----------------------------------------------------------------------------------------------------
2021-07-15 22:13:40,182 epoch 21 - iter 5/56 - loss 0.08462352 - samples/sec: 60.07 - lr: 0.000030
2021-07-15 22:13:42,855 epoch 21 - iter 10/56 - loss 0.08162363 - samples/sec: 59.88 - lr: 0.000030
2021-07-15 22:13:45,503 epoch 21 - iter 15/56 - loss 0.08976888 - samples/sec: 60.44 - lr: 0.000030
2021-07-15 22:13:48,119 epoch 21 - iter 20/56 - loss 0.09798175 - samples/sec: 61.17 - lr: 0.000030
2021-07-15 22:13:50,795 epoch 21 - iter 25/56 - loss 0.10149622 - samples/sec: 59.81 - lr: 0.000030
2021-07-15 22:13:53,466 epoch 21 - iter 30/56 - loss 0.10486433 - samples/sec: 59.91 - lr: 0.000030
2021-07-15 22:13:56,163 epoch 21 - iter 35/56 - loss 0.10359430 - samples/sec: 59.34 - lr: 0.000030
2021-07-15 22:13:58,835 epoch 21 - iter 40/56 - loss 0.10573653 - samples/sec: 59.91 - lr: 0.000030
2021-07-15 22:14:01,503 epoch 21 - iter 45/56 - loss 0.10732052 - samples/sec: 59.98 - lr: 0.000030
2021-07-15 22:14:04,171 epoch 21 - iter 50/56 - loss 0.10842112 - samples/sec: 59.99 - lr: 0.000030
2021-07-15 22:14:06,827 epoch 21 - iter 55/56 - loss 0.11096669 - samples/sec: 60.25 - lr: 0.000030
2021-07-15 22:14:06,997 ----------------------------------------------------------------------------------------------------
2021-07-15 22:14:06,997 EPOCH 21 done: loss 0.1096 - lr 0.0000300
2021-07-15 22:14:08,723 DEV : loss 0.060924239456653595 - score 0.9882
2021-07-15 22:14:08,747 BAD EPOCHS (no improvement): 3
2021-07-15 22:14:08,747 ----------------------------------------------------------------------------------------------------
2021-07-15 22:14:11,401 epoch 22 - iter 5/56 - loss 0.06519524 - samples/sec: 60.31 - lr: 0.000030
2021-07-15 22:14:14,088 epoch 22 - iter 10/56 - loss 0.08359169 - samples/sec: 59.55 - lr: 0.000030
2021-07-15 22:14:16,754 epoch 22 - iter 15/56 - loss 0.08955071 - samples/sec: 60.03 - lr: 0.000030
2021-07-15 22:14:19,436 epoch 22 - iter 20/56 - loss 0.09298285 - samples/sec: 59.68 - lr: 0.000030
2021-07-15 22:14:22,128 epoch 22 - iter 25/56 - loss 0.10188788 - samples/sec: 59.45 - lr: 0.000030
2021-07-15 22:14:24,784 epoch 22 - iter 30/56 - loss 0.09465167 - samples/sec: 60.25 - lr: 0.000030
2021-07-15 22:14:27,442 epoch 22 - iter 35/56 - loss 0.09183870 - samples/sec: 60.21 - lr: 0.000030
2021-07-15 22:14:30,100 epoch 22 - iter 40/56 - loss 0.09187878 - samples/sec: 60.20 - lr: 0.000030
2021-07-15 22:14:32,775 epoch 22 - iter 45/56 - loss 0.09602737 - samples/sec: 59.84 - lr: 0.000030
2021-07-15 22:14:35,423 epoch 22 - iter 50/56 - loss 0.09669995 - samples/sec: 60.43 - lr: 0.000030
2021-07-15 22:14:38,103 epoch 22 - iter 55/56 - loss 0.09862193 - samples/sec: 59.73 - lr: 0.000030
2021-07-15 22:14:38,269 ----------------------------------------------------------------------------------------------------
2021-07-15 22:14:38,269 EPOCH 22 done: loss 0.0974 - lr 0.0000300
2021-07-15 22:14:40,198 DEV : loss 0.06229499727487564 - score 0.9902
2021-07-15 22:14:40,222 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:14:43,899 ----------------------------------------------------------------------------------------------------
2021-07-15 22:14:46,583 epoch 23 - iter 5/56 - loss 0.14183799 - samples/sec: 59.64 - lr: 0.000030
2021-07-15 22:14:49,262 epoch 23 - iter 10/56 - loss 0.11994886 - samples/sec: 59.74 - lr: 0.000030
2021-07-15 22:14:51,918 epoch 23 - iter 15/56 - loss 0.12121990 - samples/sec: 60.25 - lr: 0.000030
2021-07-15 22:14:54,565 epoch 23 - iter 20/56 - loss 0.11072001 - samples/sec: 60.47 - lr: 0.000030
2021-07-15 22:14:57,234 epoch 23 - iter 25/56 - loss 0.11043813 - samples/sec: 59.95 - lr: 0.000030
2021-07-15 22:14:59,915 epoch 23 - iter 30/56 - loss 0.10713434 - samples/sec: 59.70 - lr: 0.000030
2021-07-15 22:15:02,582 epoch 23 - iter 35/56 - loss 0.10038958 - samples/sec: 60.00 - lr: 0.000030
2021-07-15 22:15:05,222 epoch 23 - iter 40/56 - loss 0.10143784 - samples/sec: 60.64 - lr: 0.000030
2021-07-15 22:15:07,923 epoch 23 - iter 45/56 - loss 0.10097031 - samples/sec: 59.24 - lr: 0.000030
2021-07-15 22:15:10,586 epoch 23 - iter 50/56 - loss 0.10008260 - samples/sec: 60.10 - lr: 0.000030
2021-07-15 22:15:13,280 epoch 23 - iter 55/56 - loss 0.10257772 - samples/sec: 59.42 - lr: 0.000030
2021-07-15 22:15:13,451 ----------------------------------------------------------------------------------------------------
2021-07-15 22:15:13,451 EPOCH 23 done: loss 0.1012 - lr 0.0000300
2021-07-15 22:15:15,179 DEV : loss 0.06108502671122551 - score 0.9922
2021-07-15 22:15:15,203 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:15:18,915 ----------------------------------------------------------------------------------------------------
2021-07-15 22:15:21,567 epoch 24 - iter 5/56 - loss 0.07284022 - samples/sec: 60.35 - lr: 0.000030
2021-07-15 22:15:24,252 epoch 24 - iter 10/56 - loss 0.06630352 - samples/sec: 59.60 - lr: 0.000030
2021-07-15 22:15:26,890 epoch 24 - iter 15/56 - loss 0.08538285 - samples/sec: 60.67 - lr: 0.000030
2021-07-15 22:15:29,554 epoch 24 - iter 20/56 - loss 0.09167064 - samples/sec: 60.08 - lr: 0.000030
2021-07-15 22:15:32,224 epoch 24 - iter 25/56 - loss 0.09071151 - samples/sec: 59.94 - lr: 0.000030
2021-07-15 22:15:34,890 epoch 24 - iter 30/56 - loss 0.08286284 - samples/sec: 60.03 - lr: 0.000030
2021-07-15 22:15:37,571 epoch 24 - iter 35/56 - loss 0.08089918 - samples/sec: 59.70 - lr: 0.000030
2021-07-15 22:15:40,239 epoch 24 - iter 40/56 - loss 0.08469722 - samples/sec: 59.98 - lr: 0.000030
2021-07-15 22:15:42,883 epoch 24 - iter 45/56 - loss 0.08895937 - samples/sec: 60.53 - lr: 0.000030
2021-07-15 22:15:45,551 epoch 24 - iter 50/56 - loss 0.08804789 - samples/sec: 59.99 - lr: 0.000030
2021-07-15 22:15:48,226 epoch 24 - iter 55/56 - loss 0.08775476 - samples/sec: 59.82 - lr: 0.000030
2021-07-15 22:15:48,396 ----------------------------------------------------------------------------------------------------
2021-07-15 22:15:48,397 EPOCH 24 done: loss 0.0869 - lr 0.0000300
2021-07-15 22:15:50,119 DEV : loss 0.060970958322286606 - score 0.9902
2021-07-15 22:15:50,143 BAD EPOCHS (no improvement): 1
2021-07-15 22:15:50,143 ----------------------------------------------------------------------------------------------------
2021-07-15 22:15:52,830 epoch 25 - iter 5/56 - loss 0.10844612 - samples/sec: 59.56 - lr: 0.000030
2021-07-15 22:15:55,515 epoch 25 - iter 10/56 - loss 0.08908009 - samples/sec: 59.60 - lr: 0.000030
2021-07-15 22:15:58,214 epoch 25 - iter 15/56 - loss 0.07792129 - samples/sec: 59.30 - lr: 0.000030
2021-07-15 22:16:00,842 epoch 25 - iter 20/56 - loss 0.08103497 - samples/sec: 60.91 - lr: 0.000030
2021-07-15 22:16:03,515 epoch 25 - iter 25/56 - loss 0.07661696 - samples/sec: 59.87 - lr: 0.000030
2021-07-15 22:16:06,159 epoch 25 - iter 30/56 - loss 0.08092758 - samples/sec: 60.52 - lr: 0.000030
2021-07-15 22:16:08,842 epoch 25 - iter 35/56 - loss 0.08363012 - samples/sec: 59.65 - lr: 0.000030
2021-07-15 22:16:11,527 epoch 25 - iter 40/56 - loss 0.08532063 - samples/sec: 59.61 - lr: 0.000030
2021-07-15 22:16:14,183 epoch 25 - iter 45/56 - loss 0.08715917 - samples/sec: 60.25 - lr: 0.000030
2021-07-15 22:16:16,859 epoch 25 - iter 50/56 - loss 0.08604806 - samples/sec: 59.82 - lr: 0.000030
2021-07-15 22:16:19,525 epoch 25 - iter 55/56 - loss 0.08294369 - samples/sec: 60.02 - lr: 0.000030
2021-07-15 22:16:19,697 ----------------------------------------------------------------------------------------------------
2021-07-15 22:16:19,697 EPOCH 25 done: loss 0.0820 - lr 0.0000300
2021-07-15 22:16:21,422 DEV : loss 0.06162640452384949 - score 0.9902
2021-07-15 22:16:21,445 BAD EPOCHS (no improvement): 2
2021-07-15 22:16:21,446 ----------------------------------------------------------------------------------------------------
2021-07-15 22:16:24,126 epoch 26 - iter 5/56 - loss 0.13280892 - samples/sec: 59.71 - lr: 0.000030
2021-07-15 22:16:26,817 epoch 26 - iter 10/56 - loss 0.10061150 - samples/sec: 59.48 - lr: 0.000030
2021-07-15 22:16:29,464 epoch 26 - iter 15/56 - loss 0.08819545 - samples/sec: 60.45 - lr: 0.000030
2021-07-15 22:16:32,132 epoch 26 - iter 20/56 - loss 0.07308838 - samples/sec: 59.99 - lr: 0.000030
2021-07-15 22:16:34,800 epoch 26 - iter 25/56 - loss 0.08419996 - samples/sec: 59.99 - lr: 0.000030
2021-07-15 22:16:37,510 epoch 26 - iter 30/56 - loss 0.08271330 - samples/sec: 59.04 - lr: 0.000030
2021-07-15 22:16:40,192 epoch 26 - iter 35/56 - loss 0.08161352 - samples/sec: 59.69 - lr: 0.000030
2021-07-15 22:16:42,831 epoch 26 - iter 40/56 - loss 0.08234416 - samples/sec: 60.63 - lr: 0.000030
2021-07-15 22:16:45,478 epoch 26 - iter 45/56 - loss 0.08136065 - samples/sec: 60.46 - lr: 0.000030
2021-07-15 22:16:48,150 epoch 26 - iter 50/56 - loss 0.08473028 - samples/sec: 59.89 - lr: 0.000030
2021-07-15 22:16:50,822 epoch 26 - iter 55/56 - loss 0.08180942 - samples/sec: 59.90 - lr: 0.000030
2021-07-15 22:16:50,993 ----------------------------------------------------------------------------------------------------
2021-07-15 22:16:50,994 EPOCH 26 done: loss 0.0837 - lr 0.0000300
2021-07-15 22:16:52,923 DEV : loss 0.06207726150751114 - score 0.9902
2021-07-15 22:16:52,947 BAD EPOCHS (no improvement): 3
2021-07-15 22:16:52,948 ----------------------------------------------------------------------------------------------------
2021-07-15 22:16:55,614 epoch 27 - iter 5/56 - loss 0.07503236 - samples/sec: 60.02 - lr: 0.000030
2021-07-15 22:16:58,270 epoch 27 - iter 10/56 - loss 0.08895525 - samples/sec: 60.26 - lr: 0.000030
2021-07-15 22:17:00,928 epoch 27 - iter 15/56 - loss 0.07985693 - samples/sec: 60.21 - lr: 0.000030
2021-07-15 22:17:03,618 epoch 27 - iter 20/56 - loss 0.09915712 - samples/sec: 59.50 - lr: 0.000030
2021-07-15 22:17:06,304 epoch 27 - iter 25/56 - loss 0.09110672 - samples/sec: 59.58 - lr: 0.000030
2021-07-15 22:17:08,999 epoch 27 - iter 30/56 - loss 0.08326845 - samples/sec: 59.38 - lr: 0.000030
2021-07-15 22:17:11,661 epoch 27 - iter 35/56 - loss 0.08209476 - samples/sec: 60.11 - lr: 0.000030
2021-07-15 22:17:14,315 epoch 27 - iter 40/56 - loss 0.08054654 - samples/sec: 60.31 - lr: 0.000030
2021-07-15 22:17:16,982 epoch 27 - iter 45/56 - loss 0.08076179 - samples/sec: 59.99 - lr: 0.000030
2021-07-15 22:17:19,624 epoch 27 - iter 50/56 - loss 0.07880807 - samples/sec: 60.58 - lr: 0.000030
2021-07-15 22:17:22,287 epoch 27 - iter 55/56 - loss 0.07959066 - samples/sec: 60.09 - lr: 0.000030
2021-07-15 22:17:22,459 ----------------------------------------------------------------------------------------------------
2021-07-15 22:17:22,459 EPOCH 27 done: loss 0.0786 - lr 0.0000300
2021-07-15 22:17:24,183 DEV : loss 0.06100313737988472 - score 0.9882
Epoch    27: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 22:17:24,206 BAD EPOCHS (no improvement): 4
2021-07-15 22:17:24,207 ----------------------------------------------------------------------------------------------------
2021-07-15 22:17:26,876 epoch 28 - iter 5/56 - loss 0.06753612 - samples/sec: 59.97 - lr: 0.000015
2021-07-15 22:17:29,535 epoch 28 - iter 10/56 - loss 0.07778627 - samples/sec: 60.19 - lr: 0.000015
2021-07-15 22:17:32,216 epoch 28 - iter 15/56 - loss 0.07902866 - samples/sec: 59.69 - lr: 0.000015
2021-07-15 22:17:34,902 epoch 28 - iter 20/56 - loss 0.08816634 - samples/sec: 59.57 - lr: 0.000015
2021-07-15 22:17:37,535 epoch 28 - iter 25/56 - loss 0.07945212 - samples/sec: 60.78 - lr: 0.000015
2021-07-15 22:17:40,188 epoch 28 - iter 30/56 - loss 0.07556699 - samples/sec: 60.32 - lr: 0.000015
2021-07-15 22:17:42,852 epoch 28 - iter 35/56 - loss 0.07087369 - samples/sec: 60.08 - lr: 0.000015
2021-07-15 22:17:45,527 epoch 28 - iter 40/56 - loss 0.07174008 - samples/sec: 59.83 - lr: 0.000015
2021-07-15 22:17:48,204 epoch 28 - iter 45/56 - loss 0.07396313 - samples/sec: 59.78 - lr: 0.000015
2021-07-15 22:17:50,894 epoch 28 - iter 50/56 - loss 0.07377294 - samples/sec: 59.50 - lr: 0.000015
2021-07-15 22:17:53,567 epoch 28 - iter 55/56 - loss 0.07352892 - samples/sec: 59.86 - lr: 0.000015
2021-07-15 22:17:53,732 ----------------------------------------------------------------------------------------------------
2021-07-15 22:17:53,732 EPOCH 28 done: loss 0.0723 - lr 0.0000150
2021-07-15 22:17:55,462 DEV : loss 0.06225454807281494 - score 0.9882
2021-07-15 22:17:55,485 BAD EPOCHS (no improvement): 1
2021-07-15 22:17:55,486 ----------------------------------------------------------------------------------------------------
2021-07-15 22:17:58,139 epoch 29 - iter 5/56 - loss 0.02693425 - samples/sec: 60.31 - lr: 0.000015
2021-07-15 22:18:00,788 epoch 29 - iter 10/56 - loss 0.04692245 - samples/sec: 60.42 - lr: 0.000015
2021-07-15 22:18:03,447 epoch 29 - iter 15/56 - loss 0.04916673 - samples/sec: 60.19 - lr: 0.000015
2021-07-15 22:18:06,092 epoch 29 - iter 20/56 - loss 0.04785478 - samples/sec: 60.51 - lr: 0.000015
2021-07-15 22:18:08,770 epoch 29 - iter 25/56 - loss 0.04720867 - samples/sec: 59.75 - lr: 0.000015
2021-07-15 22:18:11,477 epoch 29 - iter 30/56 - loss 0.05797912 - samples/sec: 59.14 - lr: 0.000015
2021-07-15 22:18:14,162 epoch 29 - iter 35/56 - loss 0.05797238 - samples/sec: 59.60 - lr: 0.000015
2021-07-15 22:18:16,812 epoch 29 - iter 40/56 - loss 0.06027927 - samples/sec: 60.40 - lr: 0.000015
2021-07-15 22:18:19,467 epoch 29 - iter 45/56 - loss 0.06002529 - samples/sec: 60.27 - lr: 0.000015
2021-07-15 22:18:22,152 epoch 29 - iter 50/56 - loss 0.05988194 - samples/sec: 59.60 - lr: 0.000015
2021-07-15 22:18:24,831 epoch 29 - iter 55/56 - loss 0.06184121 - samples/sec: 59.75 - lr: 0.000015
2021-07-15 22:18:24,994 ----------------------------------------------------------------------------------------------------
2021-07-15 22:18:24,995 EPOCH 29 done: loss 0.0619 - lr 0.0000150
2021-07-15 22:18:26,721 DEV : loss 0.06180921941995621 - score 0.9882
2021-07-15 22:18:26,744 BAD EPOCHS (no improvement): 2
2021-07-15 22:18:26,745 ----------------------------------------------------------------------------------------------------
2021-07-15 22:18:29,401 epoch 30 - iter 5/56 - loss 0.08359204 - samples/sec: 60.25 - lr: 0.000015
2021-07-15 22:18:32,068 epoch 30 - iter 10/56 - loss 0.07561054 - samples/sec: 60.00 - lr: 0.000015
2021-07-15 22:18:34,739 epoch 30 - iter 15/56 - loss 0.06806299 - samples/sec: 59.91 - lr: 0.000015
2021-07-15 22:18:37,408 epoch 30 - iter 20/56 - loss 0.06733567 - samples/sec: 59.97 - lr: 0.000015
2021-07-15 22:18:40,083 epoch 30 - iter 25/56 - loss 0.08112729 - samples/sec: 59.81 - lr: 0.000015
2021-07-15 22:18:42,768 epoch 30 - iter 30/56 - loss 0.08068570 - samples/sec: 59.62 - lr: 0.000015
2021-07-15 22:18:45,415 epoch 30 - iter 35/56 - loss 0.07725323 - samples/sec: 60.47 - lr: 0.000015
2021-07-15 22:18:48,066 epoch 30 - iter 40/56 - loss 0.07402410 - samples/sec: 60.36 - lr: 0.000015
2021-07-15 22:18:50,724 epoch 30 - iter 45/56 - loss 0.06997648 - samples/sec: 60.23 - lr: 0.000015
2021-07-15 22:18:53,416 epoch 30 - iter 50/56 - loss 0.06943799 - samples/sec: 59.45 - lr: 0.000015
2021-07-15 22:18:56,066 epoch 30 - iter 55/56 - loss 0.06960833 - samples/sec: 60.39 - lr: 0.000015
2021-07-15 22:18:56,236 ----------------------------------------------------------------------------------------------------
2021-07-15 22:18:56,236 EPOCH 30 done: loss 0.0689 - lr 0.0000150
2021-07-15 22:18:57,963 DEV : loss 0.062180567532777786 - score 0.9882
2021-07-15 22:18:57,987 BAD EPOCHS (no improvement): 3
2021-07-15 22:18:57,987 ----------------------------------------------------------------------------------------------------
2021-07-15 22:19:00,651 epoch 31 - iter 5/56 - loss 0.09984809 - samples/sec: 60.07 - lr: 0.000015
2021-07-15 22:19:03,344 epoch 31 - iter 10/56 - loss 0.08581896 - samples/sec: 59.42 - lr: 0.000015
2021-07-15 22:19:06,044 epoch 31 - iter 15/56 - loss 0.07821870 - samples/sec: 59.28 - lr: 0.000015
2021-07-15 22:19:08,695 epoch 31 - iter 20/56 - loss 0.07650049 - samples/sec: 60.38 - lr: 0.000015
2021-07-15 22:19:11,384 epoch 31 - iter 25/56 - loss 0.07680508 - samples/sec: 59.51 - lr: 0.000015
2021-07-15 22:19:14,059 epoch 31 - iter 30/56 - loss 0.07686128 - samples/sec: 59.82 - lr: 0.000015
2021-07-15 22:19:16,704 epoch 31 - iter 35/56 - loss 0.07996497 - samples/sec: 60.51 - lr: 0.000015
2021-07-15 22:19:19,362 epoch 31 - iter 40/56 - loss 0.07911540 - samples/sec: 60.22 - lr: 0.000015
2021-07-15 22:19:22,032 epoch 31 - iter 45/56 - loss 0.07855705 - samples/sec: 59.93 - lr: 0.000015
2021-07-15 22:19:24,677 epoch 31 - iter 50/56 - loss 0.07516278 - samples/sec: 60.51 - lr: 0.000015
2021-07-15 22:19:27,330 epoch 31 - iter 55/56 - loss 0.07281352 - samples/sec: 60.33 - lr: 0.000015
2021-07-15 22:19:27,496 ----------------------------------------------------------------------------------------------------
2021-07-15 22:19:27,496 EPOCH 31 done: loss 0.0723 - lr 0.0000150
2021-07-15 22:19:29,425 DEV : loss 0.06368488073348999 - score 0.9882
Epoch    31: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 22:19:29,449 BAD EPOCHS (no improvement): 4
2021-07-15 22:19:29,450 ----------------------------------------------------------------------------------------------------
2021-07-15 22:19:32,117 epoch 32 - iter 5/56 - loss 0.05470275 - samples/sec: 59.99 - lr: 0.000008
2021-07-15 22:19:34,757 epoch 32 - iter 10/56 - loss 0.05570971 - samples/sec: 60.62 - lr: 0.000008
2021-07-15 22:19:37,432 epoch 32 - iter 15/56 - loss 0.05125135 - samples/sec: 59.85 - lr: 0.000008
2021-07-15 22:19:40,110 epoch 32 - iter 20/56 - loss 0.06225398 - samples/sec: 59.75 - lr: 0.000008
2021-07-15 22:19:42,800 epoch 32 - iter 25/56 - loss 0.05528036 - samples/sec: 59.50 - lr: 0.000008
2021-07-15 22:19:45,439 epoch 32 - iter 30/56 - loss 0.05992664 - samples/sec: 60.65 - lr: 0.000008
2021-07-15 22:19:48,118 epoch 32 - iter 35/56 - loss 0.05825068 - samples/sec: 59.74 - lr: 0.000008
2021-07-15 22:19:50,787 epoch 32 - iter 40/56 - loss 0.05939039 - samples/sec: 59.96 - lr: 0.000008
2021-07-15 22:19:53,475 epoch 32 - iter 45/56 - loss 0.05680986 - samples/sec: 59.55 - lr: 0.000008
2021-07-15 22:19:56,164 epoch 32 - iter 50/56 - loss 0.05488272 - samples/sec: 59.52 - lr: 0.000008
2021-07-15 22:19:58,827 epoch 32 - iter 55/56 - loss 0.05794459 - samples/sec: 60.08 - lr: 0.000008
2021-07-15 22:19:58,997 ----------------------------------------------------------------------------------------------------
2021-07-15 22:19:58,997 EPOCH 32 done: loss 0.0586 - lr 0.0000075
2021-07-15 22:20:00,724 DEV : loss 0.060607850551605225 - score 0.9902
2021-07-15 22:20:00,748 BAD EPOCHS (no improvement): 1
2021-07-15 22:20:00,749 ----------------------------------------------------------------------------------------------------
2021-07-15 22:20:03,411 epoch 33 - iter 5/56 - loss 0.06206148 - samples/sec: 60.11 - lr: 0.000008
2021-07-15 22:20:06,079 epoch 33 - iter 10/56 - loss 0.05543710 - samples/sec: 59.99 - lr: 0.000008
2021-07-15 22:20:08,759 epoch 33 - iter 15/56 - loss 0.06974789 - samples/sec: 59.71 - lr: 0.000008
2021-07-15 22:20:11,430 epoch 33 - iter 20/56 - loss 0.06346759 - samples/sec: 59.92 - lr: 0.000008
2021-07-15 22:20:14,116 epoch 33 - iter 25/56 - loss 0.07111755 - samples/sec: 59.60 - lr: 0.000008
2021-07-15 22:20:16,774 epoch 33 - iter 30/56 - loss 0.06946694 - samples/sec: 60.21 - lr: 0.000008
2021-07-15 22:20:19,472 epoch 33 - iter 35/56 - loss 0.07215620 - samples/sec: 59.31 - lr: 0.000008
2021-07-15 22:20:22,122 epoch 33 - iter 40/56 - loss 0.07547732 - samples/sec: 60.40 - lr: 0.000008
2021-07-15 22:20:24,772 epoch 33 - iter 45/56 - loss 0.07373780 - samples/sec: 60.39 - lr: 0.000008
2021-07-15 22:20:27,471 epoch 33 - iter 50/56 - loss 0.07444492 - samples/sec: 59.30 - lr: 0.000008
2021-07-15 22:20:30,137 epoch 33 - iter 55/56 - loss 0.07318174 - samples/sec: 60.03 - lr: 0.000008
2021-07-15 22:20:30,308 ----------------------------------------------------------------------------------------------------
2021-07-15 22:20:30,308 EPOCH 33 done: loss 0.0778 - lr 0.0000075
2021-07-15 22:20:32,038 DEV : loss 0.06084349378943443 - score 0.9902
2021-07-15 22:20:32,062 BAD EPOCHS (no improvement): 2
2021-07-15 22:20:32,062 ----------------------------------------------------------------------------------------------------
2021-07-15 22:20:34,708 epoch 34 - iter 5/56 - loss 0.04858166 - samples/sec: 60.49 - lr: 0.000008
2021-07-15 22:20:37,388 epoch 34 - iter 10/56 - loss 0.04728860 - samples/sec: 59.73 - lr: 0.000008
2021-07-15 22:20:40,072 epoch 34 - iter 15/56 - loss 0.05283462 - samples/sec: 59.61 - lr: 0.000008
2021-07-15 22:20:42,765 epoch 34 - iter 20/56 - loss 0.05331321 - samples/sec: 59.45 - lr: 0.000008
2021-07-15 22:20:45,435 epoch 34 - iter 25/56 - loss 0.05576574 - samples/sec: 59.94 - lr: 0.000008
2021-07-15 22:20:48,075 epoch 34 - iter 30/56 - loss 0.05771129 - samples/sec: 60.62 - lr: 0.000008
2021-07-15 22:20:50,728 epoch 34 - iter 35/56 - loss 0.05988000 - samples/sec: 60.31 - lr: 0.000008
2021-07-15 22:20:53,391 epoch 34 - iter 40/56 - loss 0.05799359 - samples/sec: 60.11 - lr: 0.000008
2021-07-15 22:20:56,062 epoch 34 - iter 45/56 - loss 0.05659470 - samples/sec: 59.91 - lr: 0.000008
2021-07-15 22:20:58,723 epoch 34 - iter 50/56 - loss 0.05516212 - samples/sec: 60.15 - lr: 0.000008
2021-07-15 22:21:01,396 epoch 34 - iter 55/56 - loss 0.05767243 - samples/sec: 59.87 - lr: 0.000008
2021-07-15 22:21:01,569 ----------------------------------------------------------------------------------------------------
2021-07-15 22:21:01,569 EPOCH 34 done: loss 0.0569 - lr 0.0000075
2021-07-15 22:21:03,297 DEV : loss 0.06059498339891434 - score 0.9902
2021-07-15 22:21:03,321 BAD EPOCHS (no improvement): 3
2021-07-15 22:21:03,321 ----------------------------------------------------------------------------------------------------
2021-07-15 22:21:05,976 epoch 35 - iter 5/56 - loss 0.09500832 - samples/sec: 60.29 - lr: 0.000008
2021-07-15 22:21:08,616 epoch 35 - iter 10/56 - loss 0.10318448 - samples/sec: 60.63 - lr: 0.000008
2021-07-15 22:21:11,315 epoch 35 - iter 15/56 - loss 0.08344945 - samples/sec: 59.29 - lr: 0.000008
2021-07-15 22:21:13,971 epoch 35 - iter 20/56 - loss 0.08354841 - samples/sec: 60.26 - lr: 0.000008
2021-07-15 22:21:16,618 epoch 35 - iter 25/56 - loss 0.07795676 - samples/sec: 60.45 - lr: 0.000008
2021-07-15 22:21:19,298 epoch 35 - iter 30/56 - loss 0.07458844 - samples/sec: 59.72 - lr: 0.000008
2021-07-15 22:21:21,980 epoch 35 - iter 35/56 - loss 0.07369816 - samples/sec: 59.67 - lr: 0.000008
2021-07-15 22:21:24,631 epoch 35 - iter 40/56 - loss 0.06948914 - samples/sec: 60.38 - lr: 0.000008
2021-07-15 22:21:27,266 epoch 35 - iter 45/56 - loss 0.06666921 - samples/sec: 60.72 - lr: 0.000008
2021-07-15 22:21:30,144 epoch 35 - iter 50/56 - loss 0.06469539 - samples/sec: 55.61 - lr: 0.000008
2021-07-15 22:21:32,849 epoch 35 - iter 55/56 - loss 0.06833274 - samples/sec: 59.18 - lr: 0.000008
2021-07-15 22:21:33,023 ----------------------------------------------------------------------------------------------------
2021-07-15 22:21:33,023 EPOCH 35 done: loss 0.0674 - lr 0.0000075
2021-07-15 22:21:34,748 DEV : loss 0.06154879555106163 - score 0.9882
Epoch    35: reducing learning rate of group 0 to 3.7500e-06.
2021-07-15 22:21:34,773 BAD EPOCHS (no improvement): 4
2021-07-15 22:21:34,773 ----------------------------------------------------------------------------------------------------
2021-07-15 22:21:37,425 epoch 36 - iter 5/56 - loss 0.10083644 - samples/sec: 60.36 - lr: 0.000004
2021-07-15 22:21:40,099 epoch 36 - iter 10/56 - loss 0.06964818 - samples/sec: 59.85 - lr: 0.000004
2021-07-15 22:21:42,763 epoch 36 - iter 15/56 - loss 0.05980025 - samples/sec: 60.07 - lr: 0.000004
2021-07-15 22:21:45,433 epoch 36 - iter 20/56 - loss 0.05392464 - samples/sec: 59.93 - lr: 0.000004
2021-07-15 22:21:48,131 epoch 36 - iter 25/56 - loss 0.05616761 - samples/sec: 59.32 - lr: 0.000004
2021-07-15 22:21:50,771 epoch 36 - iter 30/56 - loss 0.06321747 - samples/sec: 60.63 - lr: 0.000004
2021-07-15 22:21:53,436 epoch 36 - iter 35/56 - loss 0.06156002 - samples/sec: 60.05 - lr: 0.000004
2021-07-15 22:21:56,099 epoch 36 - iter 40/56 - loss 0.06225660 - samples/sec: 60.09 - lr: 0.000004
2021-07-15 22:21:58,766 epoch 36 - iter 45/56 - loss 0.06221758 - samples/sec: 60.00 - lr: 0.000004
2021-07-15 22:22:01,457 epoch 36 - iter 50/56 - loss 0.06636870 - samples/sec: 59.47 - lr: 0.000004
2021-07-15 22:22:04,127 epoch 36 - iter 55/56 - loss 0.06485524 - samples/sec: 59.95 - lr: 0.000004
2021-07-15 22:22:04,299 ----------------------------------------------------------------------------------------------------
2021-07-15 22:22:04,299 EPOCH 36 done: loss 0.0669 - lr 0.0000038
2021-07-15 22:22:06,025 DEV : loss 0.0608668215572834 - score 0.9882
2021-07-15 22:22:06,049 BAD EPOCHS (no improvement): 1
2021-07-15 22:22:06,049 ----------------------------------------------------------------------------------------------------
2021-07-15 22:22:08,744 epoch 37 - iter 5/56 - loss 0.04252582 - samples/sec: 59.39 - lr: 0.000004
2021-07-15 22:22:11,464 epoch 37 - iter 10/56 - loss 0.04123546 - samples/sec: 58.84 - lr: 0.000004
2021-07-15 22:22:14,159 epoch 37 - iter 15/56 - loss 0.04724087 - samples/sec: 59.39 - lr: 0.000004
2021-07-15 22:22:16,795 epoch 37 - iter 20/56 - loss 0.04904667 - samples/sec: 60.71 - lr: 0.000004
2021-07-15 22:22:19,468 epoch 37 - iter 25/56 - loss 0.04848074 - samples/sec: 59.87 - lr: 0.000004
2021-07-15 22:22:22,116 epoch 37 - iter 30/56 - loss 0.05003222 - samples/sec: 60.45 - lr: 0.000004
2021-07-15 22:22:24,762 epoch 37 - iter 35/56 - loss 0.05244451 - samples/sec: 60.46 - lr: 0.000004
2021-07-15 22:22:27,443 epoch 37 - iter 40/56 - loss 0.05617395 - samples/sec: 59.71 - lr: 0.000004
2021-07-15 22:22:30,074 epoch 37 - iter 45/56 - loss 0.05608538 - samples/sec: 60.83 - lr: 0.000004
2021-07-15 22:22:32,750 epoch 37 - iter 50/56 - loss 0.05692169 - samples/sec: 59.80 - lr: 0.000004
2021-07-15 22:22:35,430 epoch 37 - iter 55/56 - loss 0.05805270 - samples/sec: 59.73 - lr: 0.000004
2021-07-15 22:22:35,591 ----------------------------------------------------------------------------------------------------
2021-07-15 22:22:35,591 EPOCH 37 done: loss 0.0616 - lr 0.0000038
2021-07-15 22:22:37,316 DEV : loss 0.0615408681333065 - score 0.9882
2021-07-15 22:22:37,340 BAD EPOCHS (no improvement): 2
2021-07-15 22:22:37,340 ----------------------------------------------------------------------------------------------------
2021-07-15 22:22:40,019 epoch 38 - iter 5/56 - loss 0.05023250 - samples/sec: 59.73 - lr: 0.000004
2021-07-15 22:22:42,711 epoch 38 - iter 10/56 - loss 0.04083781 - samples/sec: 59.45 - lr: 0.000004
2021-07-15 22:22:45,411 epoch 38 - iter 15/56 - loss 0.04808405 - samples/sec: 59.29 - lr: 0.000004
2021-07-15 22:22:48,062 epoch 38 - iter 20/56 - loss 0.04812386 - samples/sec: 60.36 - lr: 0.000004
2021-07-15 22:22:50,706 epoch 38 - iter 25/56 - loss 0.05326377 - samples/sec: 60.53 - lr: 0.000004
2021-07-15 22:22:53,416 epoch 38 - iter 30/56 - loss 0.06567518 - samples/sec: 59.07 - lr: 0.000004
2021-07-15 22:22:56,069 epoch 38 - iter 35/56 - loss 0.06278045 - samples/sec: 60.31 - lr: 0.000004
2021-07-15 22:22:58,731 epoch 38 - iter 40/56 - loss 0.06489666 - samples/sec: 60.14 - lr: 0.000004
2021-07-15 22:23:01,407 epoch 38 - iter 45/56 - loss 0.06870558 - samples/sec: 59.80 - lr: 0.000004
2021-07-15 22:23:04,125 epoch 38 - iter 50/56 - loss 0.06478385 - samples/sec: 58.89 - lr: 0.000004
2021-07-15 22:23:06,799 epoch 38 - iter 55/56 - loss 0.06405925 - samples/sec: 59.86 - lr: 0.000004
2021-07-15 22:23:06,970 ----------------------------------------------------------------------------------------------------
2021-07-15 22:23:06,971 EPOCH 38 done: loss 0.0633 - lr 0.0000038
2021-07-15 22:23:08,702 DEV : loss 0.060339540243148804 - score 0.9882
2021-07-15 22:23:08,726 BAD EPOCHS (no improvement): 3
2021-07-15 22:23:08,726 ----------------------------------------------------------------------------------------------------
2021-07-15 22:23:11,392 epoch 39 - iter 5/56 - loss 0.04934531 - samples/sec: 60.05 - lr: 0.000004
2021-07-15 22:23:16,745 epoch 39 - iter 10/56 - loss 0.04718553 - samples/sec: 29.89 - lr: 0.000004
2021-07-15 22:23:21,652 epoch 39 - iter 15/56 - loss 0.05420487 - samples/sec: 32.61 - lr: 0.000004
2021-07-15 22:23:25,616 epoch 39 - iter 20/56 - loss 0.05572491 - samples/sec: 40.37 - lr: 0.000004
2021-07-15 22:23:29,403 epoch 39 - iter 25/56 - loss 0.06339255 - samples/sec: 42.26 - lr: 0.000004
2021-07-15 22:23:33,414 epoch 39 - iter 30/56 - loss 0.05879275 - samples/sec: 39.90 - lr: 0.000004
2021-07-15 22:23:37,045 epoch 39 - iter 35/56 - loss 0.06066807 - samples/sec: 44.07 - lr: 0.000004
2021-07-15 22:23:40,840 epoch 39 - iter 40/56 - loss 0.06033350 - samples/sec: 42.17 - lr: 0.000004
2021-07-15 22:23:44,548 epoch 39 - iter 45/56 - loss 0.05998653 - samples/sec: 43.15 - lr: 0.000004
2021-07-15 22:23:48,486 epoch 39 - iter 50/56 - loss 0.06120316 - samples/sec: 40.64 - lr: 0.000004
2021-07-15 22:23:52,189 epoch 39 - iter 55/56 - loss 0.06029573 - samples/sec: 43.21 - lr: 0.000004
2021-07-15 22:23:52,422 ----------------------------------------------------------------------------------------------------
2021-07-15 22:23:52,422 EPOCH 39 done: loss 0.0597 - lr 0.0000038
2021-07-15 22:23:55,671 DEV : loss 0.05976327881217003 - score 0.9902
Epoch    39: reducing learning rate of group 0 to 1.8750e-06.
2021-07-15 22:23:55,695 BAD EPOCHS (no improvement): 4
2021-07-15 22:23:55,695 ----------------------------------------------------------------------------------------------------
2021-07-15 22:23:55,695 ----------------------------------------------------------------------------------------------------
2021-07-15 22:23:55,695 learning rate too small - quitting training!
2021-07-15 22:23:55,695 ----------------------------------------------------------------------------------------------------
2021-07-15 22:23:56,646 ----------------------------------------------------------------------------------------------------
2021-07-15 22:23:56,646 Testing using best model ...
2021-07-15 22:23:56,647 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/por.rst.cstn/best-model.pt
2021-07-15 22:24:08,802 0.9761	0.9846	0.9803
2021-07-15 22:24:08,802 
Results:
- F1-score (micro) 0.9803
- F1-score (macro) 0.9803

By class:
SENT       tp: 449 - fp: 11 - fn: 7 - precision: 0.9761 - recall: 0.9846 - f1-score: 0.9803
2021-07-15 22:24:08,802 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/fas.rst.prstc/
2021-07-15 22:24:08,810 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/fas.rst.prstc
2021-07-15 22:24:08,811 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/fas.rst.prstc/sent_train.txt
2021-07-15 22:24:08,813 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/fas.rst.prstc/sent_dev.txt
2021-07-15 22:24:08,813 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/fas.rst.prstc/sent_test.txt
Corpus: 1940 train + 341 dev + 610 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 22:24:13,932 ----------------------------------------------------------------------------------------------------
2021-07-15 22:24:13,933 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(100000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 22:24:13,933 ----------------------------------------------------------------------------------------------------
2021-07-15 22:24:13,933 Corpus: "Corpus: 1940 train + 341 dev + 610 test sentences"
2021-07-15 22:24:13,933 ----------------------------------------------------------------------------------------------------
2021-07-15 22:24:13,933 Parameters:
2021-07-15 22:24:13,933  - learning_rate: "3e-05"
2021-07-15 22:24:13,933  - mini_batch_size: "32"
2021-07-15 22:24:13,933  - patience: "3"
2021-07-15 22:24:13,934  - anneal_factor: "0.5"
2021-07-15 22:24:13,934  - max_epochs: "40"
2021-07-15 22:24:13,934  - shuffle: "True"
2021-07-15 22:24:13,934  - train_with_dev: "False"
2021-07-15 22:24:13,934  - batch_growth_annealing: "False"
2021-07-15 22:24:13,934 ----------------------------------------------------------------------------------------------------
2021-07-15 22:24:13,934 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/fas.rst.prstc"
2021-07-15 22:24:13,934 ----------------------------------------------------------------------------------------------------
2021-07-15 22:24:13,934 Device: cuda:0
2021-07-15 22:24:13,934 ----------------------------------------------------------------------------------------------------
2021-07-15 22:24:13,934 Embeddings storage mode: cpu
2021-07-15 22:24:13,936 ----------------------------------------------------------------------------------------------------
2021-07-15 22:24:20,640 epoch 1 - iter 6/61 - loss 14.58211438 - samples/sec: 28.64 - lr: 0.000030
2021-07-15 22:24:27,425 epoch 1 - iter 12/61 - loss 10.34195220 - samples/sec: 28.30 - lr: 0.000030
2021-07-15 22:24:34,519 epoch 1 - iter 18/61 - loss 8.20581248 - samples/sec: 27.07 - lr: 0.000030
2021-07-15 22:24:42,544 epoch 1 - iter 24/61 - loss 6.98120784 - samples/sec: 23.93 - lr: 0.000030
2021-07-15 22:24:51,328 epoch 1 - iter 30/61 - loss 6.16274661 - samples/sec: 21.86 - lr: 0.000030
2021-07-15 22:24:58,087 epoch 1 - iter 36/61 - loss 5.54283404 - samples/sec: 28.41 - lr: 0.000030
2021-07-15 22:25:04,779 epoch 1 - iter 42/61 - loss 5.06203516 - samples/sec: 28.69 - lr: 0.000030
2021-07-15 22:25:11,517 epoch 1 - iter 48/61 - loss 4.68716795 - samples/sec: 28.50 - lr: 0.000030
2021-07-15 22:25:18,235 epoch 1 - iter 54/61 - loss 4.41333137 - samples/sec: 28.58 - lr: 0.000030
2021-07-15 22:25:25,016 epoch 1 - iter 60/61 - loss 4.14321273 - samples/sec: 28.32 - lr: 0.000030
2021-07-15 22:25:25,816 ----------------------------------------------------------------------------------------------------
2021-07-15 22:25:25,816 EPOCH 1 done: loss 4.1060 - lr 0.0000300
2021-07-15 22:25:35,203 DEV : loss 1.2264394760131836 - score 0.1485
2021-07-15 22:25:35,228 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:25:36,599 ----------------------------------------------------------------------------------------------------
2021-07-15 22:25:39,647 epoch 2 - iter 6/61 - loss 1.66581635 - samples/sec: 63.02 - lr: 0.000030
2021-07-15 22:25:42,739 epoch 2 - iter 12/61 - loss 1.60903188 - samples/sec: 62.11 - lr: 0.000030
2021-07-15 22:25:45,837 epoch 2 - iter 18/61 - loss 1.51460513 - samples/sec: 62.00 - lr: 0.000030
2021-07-15 22:25:48,964 epoch 2 - iter 24/61 - loss 1.47625181 - samples/sec: 61.41 - lr: 0.000030
2021-07-15 22:25:52,064 epoch 2 - iter 30/61 - loss 1.41485232 - samples/sec: 61.95 - lr: 0.000030
2021-07-15 22:25:55,128 epoch 2 - iter 36/61 - loss 1.35241038 - samples/sec: 62.68 - lr: 0.000030
2021-07-15 22:25:58,183 epoch 2 - iter 42/61 - loss 1.29955227 - samples/sec: 62.85 - lr: 0.000030
2021-07-15 22:26:01,264 epoch 2 - iter 48/61 - loss 1.26638243 - samples/sec: 62.33 - lr: 0.000030
2021-07-15 22:26:04,320 epoch 2 - iter 54/61 - loss 1.23637639 - samples/sec: 62.84 - lr: 0.000030
2021-07-15 22:26:07,362 epoch 2 - iter 60/61 - loss 1.19860851 - samples/sec: 63.12 - lr: 0.000030
2021-07-15 22:26:07,712 ----------------------------------------------------------------------------------------------------
2021-07-15 22:26:07,712 EPOCH 2 done: loss 1.1916 - lr 0.0000300
2021-07-15 22:26:09,531 DEV : loss 0.5423141717910767 - score 0.8861
2021-07-15 22:26:09,557 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:26:15,515 ----------------------------------------------------------------------------------------------------
2021-07-15 22:26:18,594 epoch 3 - iter 6/61 - loss 0.82932281 - samples/sec: 62.39 - lr: 0.000030
2021-07-15 22:26:21,651 epoch 3 - iter 12/61 - loss 0.84748721 - samples/sec: 62.82 - lr: 0.000030
2021-07-15 22:26:24,725 epoch 3 - iter 18/61 - loss 0.87386077 - samples/sec: 62.47 - lr: 0.000030
2021-07-15 22:26:27,778 epoch 3 - iter 24/61 - loss 0.84286810 - samples/sec: 62.90 - lr: 0.000030
2021-07-15 22:26:30,860 epoch 3 - iter 30/61 - loss 0.81444824 - samples/sec: 62.31 - lr: 0.000030
2021-07-15 22:26:33,925 epoch 3 - iter 36/61 - loss 0.78644987 - samples/sec: 62.66 - lr: 0.000030
2021-07-15 22:26:36,997 epoch 3 - iter 42/61 - loss 0.76074057 - samples/sec: 62.52 - lr: 0.000030
2021-07-15 22:26:40,079 epoch 3 - iter 48/61 - loss 0.74568496 - samples/sec: 62.30 - lr: 0.000030
2021-07-15 22:26:43,164 epoch 3 - iter 54/61 - loss 0.73831124 - samples/sec: 62.26 - lr: 0.000030
2021-07-15 22:26:46,221 epoch 3 - iter 60/61 - loss 0.72750184 - samples/sec: 62.83 - lr: 0.000030
2021-07-15 22:26:46,559 ----------------------------------------------------------------------------------------------------
2021-07-15 22:26:46,560 EPOCH 3 done: loss 0.7235 - lr 0.0000300
2021-07-15 22:26:48,362 DEV : loss 0.37221041321754456 - score 0.91
2021-07-15 22:26:48,387 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:26:53,997 ----------------------------------------------------------------------------------------------------
2021-07-15 22:26:57,077 epoch 4 - iter 6/61 - loss 0.59247475 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 22:27:00,177 epoch 4 - iter 12/61 - loss 0.58620244 - samples/sec: 61.96 - lr: 0.000030
2021-07-15 22:27:03,240 epoch 4 - iter 18/61 - loss 0.59767469 - samples/sec: 62.70 - lr: 0.000030
2021-07-15 22:27:06,335 epoch 4 - iter 24/61 - loss 0.57286552 - samples/sec: 62.03 - lr: 0.000030
2021-07-15 22:27:09,431 epoch 4 - iter 30/61 - loss 0.56272025 - samples/sec: 62.03 - lr: 0.000030
2021-07-15 22:27:12,521 epoch 4 - iter 36/61 - loss 0.55948725 - samples/sec: 62.16 - lr: 0.000030
2021-07-15 22:27:15,610 epoch 4 - iter 42/61 - loss 0.56060683 - samples/sec: 62.16 - lr: 0.000030
2021-07-15 22:27:18,669 epoch 4 - iter 48/61 - loss 0.56061791 - samples/sec: 62.79 - lr: 0.000030
2021-07-15 22:27:21,704 epoch 4 - iter 54/61 - loss 0.55047387 - samples/sec: 63.27 - lr: 0.000030
2021-07-15 22:27:24,763 epoch 4 - iter 60/61 - loss 0.54518084 - samples/sec: 62.79 - lr: 0.000030
2021-07-15 22:27:25,101 ----------------------------------------------------------------------------------------------------
2021-07-15 22:27:25,101 EPOCH 4 done: loss 0.5427 - lr 0.0000300
2021-07-15 22:27:26,906 DEV : loss 0.28940847516059875 - score 0.9212
2021-07-15 22:27:26,932 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:27:32,159 ----------------------------------------------------------------------------------------------------
2021-07-15 22:27:35,439 epoch 5 - iter 6/61 - loss 0.49295916 - samples/sec: 58.55 - lr: 0.000030
2021-07-15 22:27:38,507 epoch 5 - iter 12/61 - loss 0.48732403 - samples/sec: 62.61 - lr: 0.000030
2021-07-15 22:27:41,576 epoch 5 - iter 18/61 - loss 0.47971664 - samples/sec: 62.57 - lr: 0.000030
2021-07-15 22:27:44,652 epoch 5 - iter 24/61 - loss 0.50135355 - samples/sec: 62.44 - lr: 0.000030
2021-07-15 22:27:47,738 epoch 5 - iter 30/61 - loss 0.48669950 - samples/sec: 62.22 - lr: 0.000030
2021-07-15 22:27:50,773 epoch 5 - iter 36/61 - loss 0.46785001 - samples/sec: 63.29 - lr: 0.000030
2021-07-15 22:27:53,866 epoch 5 - iter 42/61 - loss 0.46251997 - samples/sec: 62.08 - lr: 0.000030
2021-07-15 22:27:56,914 epoch 5 - iter 48/61 - loss 0.46212913 - samples/sec: 63.02 - lr: 0.000030
2021-07-15 22:28:00,026 epoch 5 - iter 54/61 - loss 0.45953546 - samples/sec: 61.71 - lr: 0.000030
2021-07-15 22:28:03,105 epoch 5 - iter 60/61 - loss 0.45452971 - samples/sec: 62.37 - lr: 0.000030
2021-07-15 22:28:03,455 ----------------------------------------------------------------------------------------------------
2021-07-15 22:28:03,456 EPOCH 5 done: loss 0.4528 - lr 0.0000300
2021-07-15 22:28:05,260 DEV : loss 0.24550440907478333 - score 0.9287
2021-07-15 22:28:05,286 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:28:10,853 ----------------------------------------------------------------------------------------------------
2021-07-15 22:28:13,934 epoch 6 - iter 6/61 - loss 0.42765995 - samples/sec: 62.34 - lr: 0.000030
2021-07-15 22:28:17,011 epoch 6 - iter 12/61 - loss 0.38946718 - samples/sec: 62.41 - lr: 0.000030
2021-07-15 22:28:20,107 epoch 6 - iter 18/61 - loss 0.37368594 - samples/sec: 62.03 - lr: 0.000030
2021-07-15 22:28:23,227 epoch 6 - iter 24/61 - loss 0.37827058 - samples/sec: 61.56 - lr: 0.000030
2021-07-15 22:28:26,348 epoch 6 - iter 30/61 - loss 0.37001366 - samples/sec: 61.53 - lr: 0.000030
2021-07-15 22:28:29,459 epoch 6 - iter 36/61 - loss 0.38051972 - samples/sec: 61.73 - lr: 0.000030
2021-07-15 22:28:32,567 epoch 6 - iter 42/61 - loss 0.38639567 - samples/sec: 61.78 - lr: 0.000030
2021-07-15 22:28:35,688 epoch 6 - iter 48/61 - loss 0.38655850 - samples/sec: 61.55 - lr: 0.000030
2021-07-15 22:28:38,796 epoch 6 - iter 54/61 - loss 0.37862353 - samples/sec: 61.78 - lr: 0.000030
2021-07-15 22:28:41,901 epoch 6 - iter 60/61 - loss 0.37385531 - samples/sec: 61.84 - lr: 0.000030
2021-07-15 22:28:42,247 ----------------------------------------------------------------------------------------------------
2021-07-15 22:28:42,247 EPOCH 6 done: loss 0.3727 - lr 0.0000300
2021-07-15 22:28:44,052 DEV : loss 0.21519939601421356 - score 0.931
2021-07-15 22:28:44,077 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:28:49,654 ----------------------------------------------------------------------------------------------------
2021-07-15 22:28:52,739 epoch 7 - iter 6/61 - loss 0.27273313 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 22:28:55,818 epoch 7 - iter 12/61 - loss 0.30035054 - samples/sec: 62.36 - lr: 0.000030
2021-07-15 22:28:58,944 epoch 7 - iter 18/61 - loss 0.33398483 - samples/sec: 61.43 - lr: 0.000030
2021-07-15 22:29:02,056 epoch 7 - iter 24/61 - loss 0.34522922 - samples/sec: 61.72 - lr: 0.000030
2021-07-15 22:29:05,131 epoch 7 - iter 30/61 - loss 0.33954671 - samples/sec: 62.46 - lr: 0.000030
2021-07-15 22:29:08,239 epoch 7 - iter 36/61 - loss 0.33431466 - samples/sec: 61.78 - lr: 0.000030
2021-07-15 22:29:11,366 epoch 7 - iter 42/61 - loss 0.33357042 - samples/sec: 61.42 - lr: 0.000030
2021-07-15 22:29:14,482 epoch 7 - iter 48/61 - loss 0.33768190 - samples/sec: 61.62 - lr: 0.000030
2021-07-15 22:29:17,618 epoch 7 - iter 54/61 - loss 0.33053942 - samples/sec: 61.24 - lr: 0.000030
2021-07-15 22:29:20,742 epoch 7 - iter 60/61 - loss 0.33650529 - samples/sec: 61.48 - lr: 0.000030
2021-07-15 22:29:21,087 ----------------------------------------------------------------------------------------------------
2021-07-15 22:29:21,087 EPOCH 7 done: loss 0.3397 - lr 0.0000300
2021-07-15 22:29:22,895 DEV : loss 0.21827010810375214 - score 0.9275
2021-07-15 22:29:22,920 BAD EPOCHS (no improvement): 1
2021-07-15 22:29:22,921 ----------------------------------------------------------------------------------------------------
2021-07-15 22:29:26,015 epoch 8 - iter 6/61 - loss 0.31693316 - samples/sec: 62.06 - lr: 0.000030
2021-07-15 22:29:29,160 epoch 8 - iter 12/61 - loss 0.31081601 - samples/sec: 61.07 - lr: 0.000030
2021-07-15 22:29:32,267 epoch 8 - iter 18/61 - loss 0.32088378 - samples/sec: 61.82 - lr: 0.000030
2021-07-15 22:29:35,362 epoch 8 - iter 24/61 - loss 0.30499616 - samples/sec: 62.04 - lr: 0.000030
2021-07-15 22:29:38,459 epoch 8 - iter 30/61 - loss 0.30878990 - samples/sec: 62.01 - lr: 0.000030
2021-07-15 22:29:41,553 epoch 8 - iter 36/61 - loss 0.32102864 - samples/sec: 62.07 - lr: 0.000030
2021-07-15 22:29:44,589 epoch 8 - iter 42/61 - loss 0.32194273 - samples/sec: 63.26 - lr: 0.000030
2021-07-15 22:29:47,680 epoch 8 - iter 48/61 - loss 0.32380085 - samples/sec: 62.12 - lr: 0.000030
2021-07-15 22:29:50,730 epoch 8 - iter 54/61 - loss 0.32642667 - samples/sec: 62.97 - lr: 0.000030
2021-07-15 22:29:53,811 epoch 8 - iter 60/61 - loss 0.32396440 - samples/sec: 62.33 - lr: 0.000030
2021-07-15 22:29:54,163 ----------------------------------------------------------------------------------------------------
2021-07-15 22:29:54,163 EPOCH 8 done: loss 0.3250 - lr 0.0000300
2021-07-15 22:29:55,965 DEV : loss 0.19857387244701385 - score 0.9343
2021-07-15 22:29:55,991 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:30:01,752 ----------------------------------------------------------------------------------------------------
2021-07-15 22:30:05,079 epoch 9 - iter 6/61 - loss 0.23185253 - samples/sec: 57.72 - lr: 0.000030
2021-07-15 22:30:08,148 epoch 9 - iter 12/61 - loss 0.22840574 - samples/sec: 62.58 - lr: 0.000030
2021-07-15 22:30:11,234 epoch 9 - iter 18/61 - loss 0.24738440 - samples/sec: 62.23 - lr: 0.000030
2021-07-15 22:30:14,331 epoch 9 - iter 24/61 - loss 0.24787197 - samples/sec: 62.01 - lr: 0.000030
2021-07-15 22:30:17,447 epoch 9 - iter 30/61 - loss 0.27043613 - samples/sec: 61.64 - lr: 0.000030
2021-07-15 22:30:20,570 epoch 9 - iter 36/61 - loss 0.27609128 - samples/sec: 61.49 - lr: 0.000030
2021-07-15 22:30:23,676 epoch 9 - iter 42/61 - loss 0.27352261 - samples/sec: 61.84 - lr: 0.000030
2021-07-15 22:30:26,788 epoch 9 - iter 48/61 - loss 0.28749089 - samples/sec: 61.71 - lr: 0.000030
2021-07-15 22:30:29,910 epoch 9 - iter 54/61 - loss 0.28528174 - samples/sec: 61.50 - lr: 0.000030
2021-07-15 22:30:33,018 epoch 9 - iter 60/61 - loss 0.28394010 - samples/sec: 61.80 - lr: 0.000030
2021-07-15 22:30:33,368 ----------------------------------------------------------------------------------------------------
2021-07-15 22:30:33,369 EPOCH 9 done: loss 0.2840 - lr 0.0000300
2021-07-15 22:30:35,176 DEV : loss 0.22381776571273804 - score 0.9333
2021-07-15 22:30:35,202 BAD EPOCHS (no improvement): 1
2021-07-15 22:30:35,202 ----------------------------------------------------------------------------------------------------
2021-07-15 22:30:38,343 epoch 10 - iter 6/61 - loss 0.25532347 - samples/sec: 61.13 - lr: 0.000030
2021-07-15 22:30:41,431 epoch 10 - iter 12/61 - loss 0.26930396 - samples/sec: 62.20 - lr: 0.000030
2021-07-15 22:30:44,535 epoch 10 - iter 18/61 - loss 0.25235125 - samples/sec: 61.86 - lr: 0.000030
2021-07-15 22:30:47,643 epoch 10 - iter 24/61 - loss 0.24307987 - samples/sec: 61.80 - lr: 0.000030
2021-07-15 22:30:50,675 epoch 10 - iter 30/61 - loss 0.24024536 - samples/sec: 63.35 - lr: 0.000030
2021-07-15 22:30:53,788 epoch 10 - iter 36/61 - loss 0.23530671 - samples/sec: 61.69 - lr: 0.000030
2021-07-15 22:30:56,878 epoch 10 - iter 42/61 - loss 0.23281941 - samples/sec: 62.14 - lr: 0.000030
2021-07-15 22:30:59,986 epoch 10 - iter 48/61 - loss 0.24876903 - samples/sec: 61.79 - lr: 0.000030
2021-07-15 22:31:03,112 epoch 10 - iter 54/61 - loss 0.25346557 - samples/sec: 61.43 - lr: 0.000030
2021-07-15 22:31:06,242 epoch 10 - iter 60/61 - loss 0.24840505 - samples/sec: 61.35 - lr: 0.000030
2021-07-15 22:31:06,588 ----------------------------------------------------------------------------------------------------
2021-07-15 22:31:06,588 EPOCH 10 done: loss 0.2466 - lr 0.0000300
2021-07-15 22:31:08,391 DEV : loss 0.1944497972726822 - score 0.9372
2021-07-15 22:31:08,417 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:31:14,013 ----------------------------------------------------------------------------------------------------
2021-07-15 22:31:17,108 epoch 11 - iter 6/61 - loss 0.17431992 - samples/sec: 62.04 - lr: 0.000030
2021-07-15 22:31:20,211 epoch 11 - iter 12/61 - loss 0.19996120 - samples/sec: 61.89 - lr: 0.000030
2021-07-15 22:31:23,302 epoch 11 - iter 18/61 - loss 0.22451763 - samples/sec: 62.14 - lr: 0.000030
2021-07-15 22:31:26,416 epoch 11 - iter 24/61 - loss 0.22217222 - samples/sec: 61.67 - lr: 0.000030
2021-07-15 22:31:29,546 epoch 11 - iter 30/61 - loss 0.22252334 - samples/sec: 61.35 - lr: 0.000030
2021-07-15 22:31:32,670 epoch 11 - iter 36/61 - loss 0.22578545 - samples/sec: 61.48 - lr: 0.000030
2021-07-15 22:31:35,794 epoch 11 - iter 42/61 - loss 0.23191449 - samples/sec: 61.46 - lr: 0.000030
2021-07-15 22:31:38,904 epoch 11 - iter 48/61 - loss 0.23188408 - samples/sec: 61.75 - lr: 0.000030
2021-07-15 22:31:42,023 epoch 11 - iter 54/61 - loss 0.23512786 - samples/sec: 61.58 - lr: 0.000030
2021-07-15 22:31:45,102 epoch 11 - iter 60/61 - loss 0.24019130 - samples/sec: 62.37 - lr: 0.000030
2021-07-15 22:31:45,452 ----------------------------------------------------------------------------------------------------
2021-07-15 22:31:45,452 EPOCH 11 done: loss 0.2418 - lr 0.0000300
2021-07-15 22:31:47,254 DEV : loss 0.19845741987228394 - score 0.9403
2021-07-15 22:31:47,280 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:31:52,891 ----------------------------------------------------------------------------------------------------
2021-07-15 22:31:56,010 epoch 12 - iter 6/61 - loss 0.25072817 - samples/sec: 61.58 - lr: 0.000030
2021-07-15 22:31:59,122 epoch 12 - iter 12/61 - loss 0.25789259 - samples/sec: 61.72 - lr: 0.000030
2021-07-15 22:32:02,227 epoch 12 - iter 18/61 - loss 0.23416812 - samples/sec: 61.85 - lr: 0.000030
2021-07-15 22:32:05,346 epoch 12 - iter 24/61 - loss 0.22872645 - samples/sec: 61.57 - lr: 0.000030
2021-07-15 22:32:08,463 epoch 12 - iter 30/61 - loss 0.23215854 - samples/sec: 61.61 - lr: 0.000030
2021-07-15 22:32:11,595 epoch 12 - iter 36/61 - loss 0.22993497 - samples/sec: 61.32 - lr: 0.000030
2021-07-15 22:32:14,682 epoch 12 - iter 42/61 - loss 0.22410522 - samples/sec: 62.21 - lr: 0.000030
2021-07-15 22:32:17,766 epoch 12 - iter 48/61 - loss 0.23082741 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 22:32:20,878 epoch 12 - iter 54/61 - loss 0.22521000 - samples/sec: 61.70 - lr: 0.000030
2021-07-15 22:32:23,955 epoch 12 - iter 60/61 - loss 0.22305973 - samples/sec: 62.42 - lr: 0.000030
2021-07-15 22:32:24,308 ----------------------------------------------------------------------------------------------------
2021-07-15 22:32:24,308 EPOCH 12 done: loss 0.2220 - lr 0.0000300
2021-07-15 22:32:26,316 DEV : loss 0.20221999287605286 - score 0.9378
2021-07-15 22:32:26,342 BAD EPOCHS (no improvement): 1
2021-07-15 22:32:26,342 ----------------------------------------------------------------------------------------------------
2021-07-15 22:32:29,439 epoch 13 - iter 6/61 - loss 0.17460723 - samples/sec: 62.01 - lr: 0.000030
2021-07-15 22:32:32,550 epoch 13 - iter 12/61 - loss 0.20892651 - samples/sec: 61.73 - lr: 0.000030
2021-07-15 22:32:35,654 epoch 13 - iter 18/61 - loss 0.22752301 - samples/sec: 61.87 - lr: 0.000030
2021-07-15 22:32:38,762 epoch 13 - iter 24/61 - loss 0.21755001 - samples/sec: 61.80 - lr: 0.000030
2021-07-15 22:32:41,891 epoch 13 - iter 30/61 - loss 0.21311484 - samples/sec: 61.37 - lr: 0.000030
2021-07-15 22:32:44,971 epoch 13 - iter 36/61 - loss 0.21907653 - samples/sec: 62.34 - lr: 0.000030
2021-07-15 22:32:48,067 epoch 13 - iter 42/61 - loss 0.21582260 - samples/sec: 62.03 - lr: 0.000030
2021-07-15 22:32:51,152 epoch 13 - iter 48/61 - loss 0.20939236 - samples/sec: 62.26 - lr: 0.000030
2021-07-15 22:32:54,272 epoch 13 - iter 54/61 - loss 0.21294496 - samples/sec: 61.55 - lr: 0.000030
2021-07-15 22:32:57,390 epoch 13 - iter 60/61 - loss 0.21520199 - samples/sec: 61.58 - lr: 0.000030
2021-07-15 22:32:57,732 ----------------------------------------------------------------------------------------------------
2021-07-15 22:32:57,733 EPOCH 13 done: loss 0.2157 - lr 0.0000300
2021-07-15 22:32:59,537 DEV : loss 0.19002240896224976 - score 0.9372
2021-07-15 22:32:59,563 BAD EPOCHS (no improvement): 2
2021-07-15 22:32:59,563 ----------------------------------------------------------------------------------------------------
2021-07-15 22:33:02,690 epoch 14 - iter 6/61 - loss 0.21698742 - samples/sec: 61.41 - lr: 0.000030
2021-07-15 22:33:05,729 epoch 14 - iter 12/61 - loss 0.23699561 - samples/sec: 63.20 - lr: 0.000030
2021-07-15 22:33:08,806 epoch 14 - iter 18/61 - loss 0.21918541 - samples/sec: 62.42 - lr: 0.000030
2021-07-15 22:33:11,899 epoch 14 - iter 24/61 - loss 0.21376842 - samples/sec: 62.09 - lr: 0.000030
2021-07-15 22:33:14,980 epoch 14 - iter 30/61 - loss 0.20720765 - samples/sec: 62.32 - lr: 0.000030
2021-07-15 22:33:18,075 epoch 14 - iter 36/61 - loss 0.19830222 - samples/sec: 62.06 - lr: 0.000030
2021-07-15 22:33:21,170 epoch 14 - iter 42/61 - loss 0.19097067 - samples/sec: 62.05 - lr: 0.000030
2021-07-15 22:33:24,251 epoch 14 - iter 48/61 - loss 0.18950352 - samples/sec: 62.31 - lr: 0.000030
2021-07-15 22:33:27,338 epoch 14 - iter 54/61 - loss 0.18919189 - samples/sec: 62.23 - lr: 0.000030
2021-07-15 22:33:30,447 epoch 14 - iter 60/61 - loss 0.18681825 - samples/sec: 61.77 - lr: 0.000030
2021-07-15 22:33:30,788 ----------------------------------------------------------------------------------------------------
2021-07-15 22:33:30,789 EPOCH 14 done: loss 0.1863 - lr 0.0000300
2021-07-15 22:33:32,596 DEV : loss 0.19684681296348572 - score 0.9423
2021-07-15 22:33:32,622 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:33:38,359 ----------------------------------------------------------------------------------------------------
2021-07-15 22:33:41,427 epoch 15 - iter 6/61 - loss 0.17552799 - samples/sec: 62.60 - lr: 0.000030
2021-07-15 22:33:44,510 epoch 15 - iter 12/61 - loss 0.17837995 - samples/sec: 62.29 - lr: 0.000030
2021-07-15 22:33:47,591 epoch 15 - iter 18/61 - loss 0.19114037 - samples/sec: 62.32 - lr: 0.000030
2021-07-15 22:33:50,686 epoch 15 - iter 24/61 - loss 0.19234689 - samples/sec: 62.06 - lr: 0.000030
2021-07-15 22:33:53,793 epoch 15 - iter 30/61 - loss 0.19007208 - samples/sec: 61.81 - lr: 0.000030
2021-07-15 22:33:56,883 epoch 15 - iter 36/61 - loss 0.18728765 - samples/sec: 62.14 - lr: 0.000030
2021-07-15 22:33:59,959 epoch 15 - iter 42/61 - loss 0.18379034 - samples/sec: 62.43 - lr: 0.000030
2021-07-15 22:34:03,084 epoch 15 - iter 48/61 - loss 0.18584532 - samples/sec: 61.46 - lr: 0.000030
2021-07-15 22:34:06,154 epoch 15 - iter 54/61 - loss 0.18235855 - samples/sec: 62.55 - lr: 0.000030
2021-07-15 22:34:09,232 epoch 15 - iter 60/61 - loss 0.18048476 - samples/sec: 62.40 - lr: 0.000030
2021-07-15 22:34:09,572 ----------------------------------------------------------------------------------------------------
2021-07-15 22:34:09,572 EPOCH 15 done: loss 0.1809 - lr 0.0000300
2021-07-15 22:34:11,379 DEV : loss 0.16912807524204254 - score 0.9366
2021-07-15 22:34:11,405 BAD EPOCHS (no improvement): 1
2021-07-15 22:34:11,405 ----------------------------------------------------------------------------------------------------
2021-07-15 22:34:14,481 epoch 16 - iter 6/61 - loss 0.15680817 - samples/sec: 62.45 - lr: 0.000030
2021-07-15 22:34:17,578 epoch 16 - iter 12/61 - loss 0.18435776 - samples/sec: 62.00 - lr: 0.000030
2021-07-15 22:34:20,635 epoch 16 - iter 18/61 - loss 0.18716808 - samples/sec: 62.83 - lr: 0.000030
2021-07-15 22:34:23,722 epoch 16 - iter 24/61 - loss 0.18594338 - samples/sec: 62.19 - lr: 0.000030
2021-07-15 22:34:26,810 epoch 16 - iter 30/61 - loss 0.18185149 - samples/sec: 62.20 - lr: 0.000030
2021-07-15 22:34:29,902 epoch 16 - iter 36/61 - loss 0.17986476 - samples/sec: 62.10 - lr: 0.000030
2021-07-15 22:34:32,968 epoch 16 - iter 42/61 - loss 0.17688348 - samples/sec: 62.65 - lr: 0.000030
2021-07-15 22:34:36,059 epoch 16 - iter 48/61 - loss 0.17280843 - samples/sec: 62.13 - lr: 0.000030
2021-07-15 22:34:39,176 epoch 16 - iter 54/61 - loss 0.17421025 - samples/sec: 61.61 - lr: 0.000030
2021-07-15 22:34:42,259 epoch 16 - iter 60/61 - loss 0.17469493 - samples/sec: 62.29 - lr: 0.000030
2021-07-15 22:34:42,600 ----------------------------------------------------------------------------------------------------
2021-07-15 22:34:42,600 EPOCH 16 done: loss 0.1732 - lr 0.0000300
2021-07-15 22:34:44,406 DEV : loss 0.18699845671653748 - score 0.9474
2021-07-15 22:34:44,431 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:34:50,089 ----------------------------------------------------------------------------------------------------
2021-07-15 22:34:53,181 epoch 17 - iter 6/61 - loss 0.14287530 - samples/sec: 62.10 - lr: 0.000030
2021-07-15 22:34:56,270 epoch 17 - iter 12/61 - loss 0.18597795 - samples/sec: 62.19 - lr: 0.000030
2021-07-15 22:34:59,355 epoch 17 - iter 18/61 - loss 0.17977235 - samples/sec: 62.24 - lr: 0.000030
2021-07-15 22:35:02,662 epoch 17 - iter 24/61 - loss 0.17567967 - samples/sec: 58.08 - lr: 0.000030
2021-07-15 22:35:05,782 epoch 17 - iter 30/61 - loss 0.17574911 - samples/sec: 61.54 - lr: 0.000030
2021-07-15 22:35:08,878 epoch 17 - iter 36/61 - loss 0.17725402 - samples/sec: 62.03 - lr: 0.000030
2021-07-15 22:35:11,994 epoch 17 - iter 42/61 - loss 0.17755118 - samples/sec: 61.64 - lr: 0.000030
2021-07-15 22:35:15,094 epoch 17 - iter 48/61 - loss 0.17309989 - samples/sec: 61.94 - lr: 0.000030
2021-07-15 22:35:18,202 epoch 17 - iter 54/61 - loss 0.17392943 - samples/sec: 61.79 - lr: 0.000030
2021-07-15 22:35:21,292 epoch 17 - iter 60/61 - loss 0.17699006 - samples/sec: 62.15 - lr: 0.000030
2021-07-15 22:35:21,640 ----------------------------------------------------------------------------------------------------
2021-07-15 22:35:21,640 EPOCH 17 done: loss 0.1751 - lr 0.0000300
2021-07-15 22:35:23,446 DEV : loss 0.20112662017345428 - score 0.9384
2021-07-15 22:35:23,472 BAD EPOCHS (no improvement): 1
2021-07-15 22:35:23,472 ----------------------------------------------------------------------------------------------------
2021-07-15 22:35:26,551 epoch 18 - iter 6/61 - loss 0.13477755 - samples/sec: 62.38 - lr: 0.000030
2021-07-15 22:35:29,695 epoch 18 - iter 12/61 - loss 0.16701486 - samples/sec: 61.08 - lr: 0.000030
2021-07-15 22:35:32,783 epoch 18 - iter 18/61 - loss 0.15675286 - samples/sec: 62.19 - lr: 0.000030
2021-07-15 22:35:35,926 epoch 18 - iter 24/61 - loss 0.16381105 - samples/sec: 61.11 - lr: 0.000030
2021-07-15 22:35:39,050 epoch 18 - iter 30/61 - loss 0.18295357 - samples/sec: 61.47 - lr: 0.000030
2021-07-15 22:35:42,125 epoch 18 - iter 36/61 - loss 0.17984433 - samples/sec: 62.45 - lr: 0.000030
2021-07-15 22:35:45,259 epoch 18 - iter 42/61 - loss 0.17223121 - samples/sec: 61.28 - lr: 0.000030
2021-07-15 22:35:48,354 epoch 18 - iter 48/61 - loss 0.17506920 - samples/sec: 62.06 - lr: 0.000030
2021-07-15 22:35:51,437 epoch 18 - iter 54/61 - loss 0.17557205 - samples/sec: 62.27 - lr: 0.000030
2021-07-15 22:35:54,526 epoch 18 - iter 60/61 - loss 0.16907997 - samples/sec: 62.18 - lr: 0.000030
2021-07-15 22:35:54,881 ----------------------------------------------------------------------------------------------------
2021-07-15 22:35:54,881 EPOCH 18 done: loss 0.1693 - lr 0.0000300
2021-07-15 22:35:56,688 DEV : loss 0.1726306676864624 - score 0.9417
2021-07-15 22:35:56,713 BAD EPOCHS (no improvement): 2
2021-07-15 22:35:56,713 ----------------------------------------------------------------------------------------------------
2021-07-15 22:35:59,839 epoch 19 - iter 6/61 - loss 0.19444758 - samples/sec: 61.45 - lr: 0.000030
2021-07-15 22:36:02,955 epoch 19 - iter 12/61 - loss 0.14761300 - samples/sec: 61.64 - lr: 0.000030
2021-07-15 22:36:06,085 epoch 19 - iter 18/61 - loss 0.17946372 - samples/sec: 61.36 - lr: 0.000030
2021-07-15 22:36:09,186 epoch 19 - iter 24/61 - loss 0.17332627 - samples/sec: 61.91 - lr: 0.000030
2021-07-15 22:36:12,290 epoch 19 - iter 30/61 - loss 0.16669409 - samples/sec: 61.87 - lr: 0.000030
2021-07-15 22:36:15,401 epoch 19 - iter 36/61 - loss 0.17040392 - samples/sec: 61.74 - lr: 0.000030
2021-07-15 22:36:18,467 epoch 19 - iter 42/61 - loss 0.16394156 - samples/sec: 62.65 - lr: 0.000030
2021-07-15 22:36:21,522 epoch 19 - iter 48/61 - loss 0.16079647 - samples/sec: 62.84 - lr: 0.000030
2021-07-15 22:36:24,579 epoch 19 - iter 54/61 - loss 0.16371785 - samples/sec: 62.84 - lr: 0.000030
2021-07-15 22:36:27,624 epoch 19 - iter 60/61 - loss 0.15780873 - samples/sec: 63.05 - lr: 0.000030
2021-07-15 22:36:27,973 ----------------------------------------------------------------------------------------------------
2021-07-15 22:36:27,973 EPOCH 19 done: loss 0.1604 - lr 0.0000300
2021-07-15 22:36:29,780 DEV : loss 0.18988001346588135 - score 0.933
2021-07-15 22:36:29,805 BAD EPOCHS (no improvement): 3
2021-07-15 22:36:29,806 ----------------------------------------------------------------------------------------------------
2021-07-15 22:36:32,887 epoch 20 - iter 6/61 - loss 0.11061571 - samples/sec: 62.33 - lr: 0.000030
2021-07-15 22:36:35,959 epoch 20 - iter 12/61 - loss 0.14389894 - samples/sec: 62.51 - lr: 0.000030
2021-07-15 22:36:39,052 epoch 20 - iter 18/61 - loss 0.13451640 - samples/sec: 62.10 - lr: 0.000030
2021-07-15 22:36:42,203 epoch 20 - iter 24/61 - loss 0.14398903 - samples/sec: 60.94 - lr: 0.000030
2021-07-15 22:36:45,323 epoch 20 - iter 30/61 - loss 0.14621805 - samples/sec: 61.57 - lr: 0.000030
2021-07-15 22:36:48,451 epoch 20 - iter 36/61 - loss 0.14578348 - samples/sec: 61.39 - lr: 0.000030
2021-07-15 22:36:51,567 epoch 20 - iter 42/61 - loss 0.15351053 - samples/sec: 61.64 - lr: 0.000030
2021-07-15 22:36:54,647 epoch 20 - iter 48/61 - loss 0.14777410 - samples/sec: 62.35 - lr: 0.000030
2021-07-15 22:36:57,831 epoch 20 - iter 54/61 - loss 0.14776468 - samples/sec: 60.31 - lr: 0.000030
2021-07-15 22:37:02,088 epoch 20 - iter 60/61 - loss 0.14379854 - samples/sec: 45.11 - lr: 0.000030
2021-07-15 22:37:02,566 ----------------------------------------------------------------------------------------------------
2021-07-15 22:37:02,566 EPOCH 20 done: loss 0.1440 - lr 0.0000300
2021-07-15 22:37:06,350 DEV : loss 0.18937630951404572 - score 0.9378
Epoch    20: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 22:37:06,376 BAD EPOCHS (no improvement): 4
2021-07-15 22:37:06,376 ----------------------------------------------------------------------------------------------------
2021-07-15 22:37:10,937 epoch 21 - iter 6/61 - loss 0.08290428 - samples/sec: 42.10 - lr: 0.000015
2021-07-15 22:37:15,460 epoch 21 - iter 12/61 - loss 0.12337140 - samples/sec: 42.46 - lr: 0.000015
2021-07-15 22:37:19,994 epoch 21 - iter 18/61 - loss 0.12005113 - samples/sec: 42.35 - lr: 0.000015
2021-07-15 22:37:24,569 epoch 21 - iter 24/61 - loss 0.13263226 - samples/sec: 41.98 - lr: 0.000015
2021-07-15 22:37:29,081 epoch 21 - iter 30/61 - loss 0.13319509 - samples/sec: 42.55 - lr: 0.000015
2021-07-15 22:37:33,603 epoch 21 - iter 36/61 - loss 0.13321789 - samples/sec: 42.47 - lr: 0.000015
2021-07-15 22:37:38,113 epoch 21 - iter 42/61 - loss 0.13436479 - samples/sec: 42.58 - lr: 0.000015
2021-07-15 22:37:42,673 epoch 21 - iter 48/61 - loss 0.13884082 - samples/sec: 42.11 - lr: 0.000015
2021-07-15 22:37:47,283 epoch 21 - iter 54/61 - loss 0.14040146 - samples/sec: 41.65 - lr: 0.000015
2021-07-15 22:37:51,788 epoch 21 - iter 60/61 - loss 0.13938091 - samples/sec: 42.63 - lr: 0.000015
2021-07-15 22:37:52,255 ----------------------------------------------------------------------------------------------------
2021-07-15 22:37:52,255 EPOCH 21 done: loss 0.1391 - lr 0.0000150
2021-07-15 22:37:56,037 DEV : loss 0.1681959331035614 - score 0.942
2021-07-15 22:37:56,063 BAD EPOCHS (no improvement): 1
2021-07-15 22:37:56,063 ----------------------------------------------------------------------------------------------------
2021-07-15 22:38:00,630 epoch 22 - iter 6/61 - loss 0.12180916 - samples/sec: 42.05 - lr: 0.000015
2021-07-15 22:38:05,061 epoch 22 - iter 12/61 - loss 0.14958797 - samples/sec: 43.34 - lr: 0.000015
2021-07-15 22:38:09,739 epoch 22 - iter 18/61 - loss 0.13416185 - samples/sec: 41.05 - lr: 0.000015
2021-07-15 22:38:14,298 epoch 22 - iter 24/61 - loss 0.14768090 - samples/sec: 42.12 - lr: 0.000015
2021-07-15 22:38:19,007 epoch 22 - iter 30/61 - loss 0.14090442 - samples/sec: 40.79 - lr: 0.000015
2021-07-15 22:38:23,510 epoch 22 - iter 36/61 - loss 0.14241502 - samples/sec: 42.64 - lr: 0.000015
2021-07-15 22:38:28,013 epoch 22 - iter 42/61 - loss 0.13732899 - samples/sec: 42.64 - lr: 0.000015
2021-07-15 22:38:32,504 epoch 22 - iter 48/61 - loss 0.13923054 - samples/sec: 42.75 - lr: 0.000015
2021-07-15 22:38:37,716 epoch 22 - iter 54/61 - loss 0.14433533 - samples/sec: 36.85 - lr: 0.000015
2021-07-15 22:38:44,705 epoch 22 - iter 60/61 - loss 0.13954518 - samples/sec: 27.47 - lr: 0.000015
2021-07-15 22:38:45,173 ----------------------------------------------------------------------------------------------------
2021-07-15 22:38:45,173 EPOCH 22 done: loss 0.1390 - lr 0.0000150
2021-07-15 22:38:48,844 DEV : loss 0.188155397772789 - score 0.9403
2021-07-15 22:38:48,869 BAD EPOCHS (no improvement): 2
2021-07-15 22:38:48,870 ----------------------------------------------------------------------------------------------------
2021-07-15 22:38:53,302 epoch 23 - iter 6/61 - loss 0.11469478 - samples/sec: 43.33 - lr: 0.000015
2021-07-15 22:38:57,889 epoch 23 - iter 12/61 - loss 0.13322253 - samples/sec: 41.86 - lr: 0.000015
2021-07-15 22:39:03,040 epoch 23 - iter 18/61 - loss 0.13335882 - samples/sec: 37.28 - lr: 0.000015
2021-07-15 22:39:07,206 epoch 23 - iter 24/61 - loss 0.12547739 - samples/sec: 46.10 - lr: 0.000015
2021-07-15 22:39:10,347 epoch 23 - iter 30/61 - loss 0.13318493 - samples/sec: 61.15 - lr: 0.000015
2021-07-15 22:39:13,466 epoch 23 - iter 36/61 - loss 0.13342827 - samples/sec: 61.56 - lr: 0.000015
2021-07-15 22:39:16,727 epoch 23 - iter 42/61 - loss 0.12633106 - samples/sec: 58.90 - lr: 0.000015
2021-07-15 22:39:19,880 epoch 23 - iter 48/61 - loss 0.13014972 - samples/sec: 60.90 - lr: 0.000015
2021-07-15 22:39:24,508 epoch 23 - iter 54/61 - loss 0.13104447 - samples/sec: 41.49 - lr: 0.000015
2021-07-15 22:39:29,092 epoch 23 - iter 60/61 - loss 0.13233662 - samples/sec: 41.90 - lr: 0.000015
2021-07-15 22:39:29,570 ----------------------------------------------------------------------------------------------------
2021-07-15 22:39:29,570 EPOCH 23 done: loss 0.1309 - lr 0.0000150
2021-07-15 22:39:33,203 DEV : loss 0.18477530777454376 - score 0.9333
2021-07-15 22:39:33,228 BAD EPOCHS (no improvement): 3
2021-07-15 22:39:33,229 ----------------------------------------------------------------------------------------------------
2021-07-15 22:39:37,811 epoch 24 - iter 6/61 - loss 0.10034881 - samples/sec: 41.91 - lr: 0.000015
2021-07-15 22:39:42,205 epoch 24 - iter 12/61 - loss 0.12708031 - samples/sec: 43.71 - lr: 0.000015
2021-07-15 22:39:46,604 epoch 24 - iter 18/61 - loss 0.11855908 - samples/sec: 43.65 - lr: 0.000015
2021-07-15 22:39:50,998 epoch 24 - iter 24/61 - loss 0.11332516 - samples/sec: 43.70 - lr: 0.000015
2021-07-15 22:39:55,539 epoch 24 - iter 30/61 - loss 0.11615093 - samples/sec: 42.29 - lr: 0.000015
2021-07-15 22:39:59,962 epoch 24 - iter 36/61 - loss 0.11792367 - samples/sec: 43.41 - lr: 0.000015
2021-07-15 22:40:04,557 epoch 24 - iter 42/61 - loss 0.12004760 - samples/sec: 41.79 - lr: 0.000015
2021-07-15 22:40:08,975 epoch 24 - iter 48/61 - loss 0.11781908 - samples/sec: 43.47 - lr: 0.000015
2021-07-15 22:40:13,270 epoch 24 - iter 54/61 - loss 0.11707751 - samples/sec: 44.71 - lr: 0.000015
2021-07-15 22:40:17,732 epoch 24 - iter 60/61 - loss 0.11609365 - samples/sec: 43.04 - lr: 0.000015
2021-07-15 22:40:18,227 ----------------------------------------------------------------------------------------------------
2021-07-15 22:40:18,227 EPOCH 24 done: loss 0.1164 - lr 0.0000150
2021-07-15 22:40:21,853 DEV : loss 0.17213666439056396 - score 0.944
Epoch    24: reducing learning rate of group 0 to 7.5000e-06.
2021-07-15 22:40:21,879 BAD EPOCHS (no improvement): 4
2021-07-15 22:40:21,879 ----------------------------------------------------------------------------------------------------
2021-07-15 22:40:26,455 epoch 25 - iter 6/61 - loss 0.10846782 - samples/sec: 41.97 - lr: 0.000008
2021-07-15 22:40:31,367 epoch 25 - iter 12/61 - loss 0.10496124 - samples/sec: 39.09 - lr: 0.000008
2021-07-15 22:40:39,602 epoch 25 - iter 18/61 - loss 0.10491601 - samples/sec: 23.32 - lr: 0.000008
2021-07-15 22:40:44,123 epoch 25 - iter 24/61 - loss 0.10965853 - samples/sec: 42.47 - lr: 0.000008
2021-07-15 22:40:48,763 epoch 25 - iter 30/61 - loss 0.10733293 - samples/sec: 41.39 - lr: 0.000008
2021-07-15 22:40:53,643 epoch 25 - iter 36/61 - loss 0.11362767 - samples/sec: 39.34 - lr: 0.000008
2021-07-15 22:40:59,980 epoch 25 - iter 42/61 - loss 0.12168547 - samples/sec: 30.31 - lr: 0.000008
2021-07-15 22:41:04,991 epoch 25 - iter 48/61 - loss 0.12100504 - samples/sec: 38.32 - lr: 0.000008
2021-07-15 22:41:12,688 epoch 25 - iter 54/61 - loss 0.11993188 - samples/sec: 24.95 - lr: 0.000008
2021-07-15 22:41:17,229 epoch 25 - iter 60/61 - loss 0.11917833 - samples/sec: 42.29 - lr: 0.000008
2021-07-15 22:41:17,774 ----------------------------------------------------------------------------------------------------
2021-07-15 22:41:17,774 EPOCH 25 done: loss 0.1212 - lr 0.0000075
2021-07-15 22:41:21,575 DEV : loss 0.1860816329717636 - score 0.9378
2021-07-15 22:41:21,601 BAD EPOCHS (no improvement): 1
2021-07-15 22:41:21,601 ----------------------------------------------------------------------------------------------------
2021-07-15 22:41:26,732 epoch 26 - iter 6/61 - loss 0.11681885 - samples/sec: 37.43 - lr: 0.000008
2021-07-15 22:41:31,995 epoch 26 - iter 12/61 - loss 0.09857767 - samples/sec: 36.49 - lr: 0.000008
2021-07-15 22:41:35,126 epoch 26 - iter 18/61 - loss 0.12444888 - samples/sec: 61.32 - lr: 0.000008
2021-07-15 22:41:38,215 epoch 26 - iter 24/61 - loss 0.12529790 - samples/sec: 62.19 - lr: 0.000008
2021-07-15 22:41:41,332 epoch 26 - iter 30/61 - loss 0.12311432 - samples/sec: 61.61 - lr: 0.000008
2021-07-15 22:41:44,445 epoch 26 - iter 36/61 - loss 0.11675422 - samples/sec: 61.68 - lr: 0.000008
2021-07-15 22:41:47,554 epoch 26 - iter 42/61 - loss 0.11924419 - samples/sec: 61.78 - lr: 0.000008
2021-07-15 22:41:50,634 epoch 26 - iter 48/61 - loss 0.12128877 - samples/sec: 62.34 - lr: 0.000008
2021-07-15 22:41:53,751 epoch 26 - iter 54/61 - loss 0.12022119 - samples/sec: 61.63 - lr: 0.000008
2021-07-15 22:41:56,830 epoch 26 - iter 60/61 - loss 0.11786901 - samples/sec: 62.37 - lr: 0.000008
2021-07-15 22:41:57,178 ----------------------------------------------------------------------------------------------------
2021-07-15 22:41:57,178 EPOCH 26 done: loss 0.1176 - lr 0.0000075
2021-07-15 22:41:58,979 DEV : loss 0.18789704144001007 - score 0.9381
2021-07-15 22:41:59,005 BAD EPOCHS (no improvement): 2
2021-07-15 22:41:59,005 ----------------------------------------------------------------------------------------------------
2021-07-15 22:42:02,100 epoch 27 - iter 6/61 - loss 0.09044388 - samples/sec: 62.05 - lr: 0.000008
2021-07-15 22:42:05,199 epoch 27 - iter 12/61 - loss 0.09620010 - samples/sec: 61.96 - lr: 0.000008
2021-07-15 22:42:08,274 epoch 27 - iter 18/61 - loss 0.11212310 - samples/sec: 62.46 - lr: 0.000008
2021-07-15 22:42:11,378 epoch 27 - iter 24/61 - loss 0.11386473 - samples/sec: 61.86 - lr: 0.000008
2021-07-15 22:42:14,442 epoch 27 - iter 30/61 - loss 0.10809978 - samples/sec: 62.68 - lr: 0.000008
2021-07-15 22:42:17,540 epoch 27 - iter 36/61 - loss 0.11370606 - samples/sec: 62.00 - lr: 0.000008
2021-07-15 22:42:20,656 epoch 27 - iter 42/61 - loss 0.11135069 - samples/sec: 61.63 - lr: 0.000008
2021-07-15 22:42:23,735 epoch 27 - iter 48/61 - loss 0.10897132 - samples/sec: 62.37 - lr: 0.000008
2021-07-15 22:42:26,827 epoch 27 - iter 54/61 - loss 0.11090125 - samples/sec: 62.11 - lr: 0.000008
2021-07-15 22:42:29,958 epoch 27 - iter 60/61 - loss 0.11553621 - samples/sec: 61.33 - lr: 0.000008
2021-07-15 22:42:30,304 ----------------------------------------------------------------------------------------------------
2021-07-15 22:42:30,305 EPOCH 27 done: loss 0.1159 - lr 0.0000075
2021-07-15 22:42:32,115 DEV : loss 0.1755298376083374 - score 0.9398
2021-07-15 22:42:32,141 BAD EPOCHS (no improvement): 3
2021-07-15 22:42:32,141 ----------------------------------------------------------------------------------------------------
2021-07-15 22:42:35,270 epoch 28 - iter 6/61 - loss 0.09402299 - samples/sec: 61.39 - lr: 0.000008
2021-07-15 22:42:38,374 epoch 28 - iter 12/61 - loss 0.07978594 - samples/sec: 61.86 - lr: 0.000008
2021-07-15 22:42:41,461 epoch 28 - iter 18/61 - loss 0.09402115 - samples/sec: 62.21 - lr: 0.000008
2021-07-15 22:42:44,562 epoch 28 - iter 24/61 - loss 0.09540946 - samples/sec: 61.94 - lr: 0.000008
2021-07-15 22:42:47,678 epoch 28 - iter 30/61 - loss 0.09655922 - samples/sec: 61.62 - lr: 0.000008
2021-07-15 22:42:50,747 epoch 28 - iter 36/61 - loss 0.10120521 - samples/sec: 62.58 - lr: 0.000008
2021-07-15 22:42:53,839 epoch 28 - iter 42/61 - loss 0.09911461 - samples/sec: 62.11 - lr: 0.000008
2021-07-15 22:42:56,935 epoch 28 - iter 48/61 - loss 0.10190997 - samples/sec: 62.03 - lr: 0.000008
2021-07-15 22:43:00,057 epoch 28 - iter 54/61 - loss 0.10919930 - samples/sec: 61.51 - lr: 0.000008
2021-07-15 22:43:03,191 epoch 28 - iter 60/61 - loss 0.10964201 - samples/sec: 61.27 - lr: 0.000008
2021-07-15 22:43:03,531 ----------------------------------------------------------------------------------------------------
2021-07-15 22:43:03,531 EPOCH 28 done: loss 0.1086 - lr 0.0000075
2021-07-15 22:43:05,340 DEV : loss 0.19153951108455658 - score 0.9378
Epoch    28: reducing learning rate of group 0 to 3.7500e-06.
2021-07-15 22:43:05,366 BAD EPOCHS (no improvement): 4
2021-07-15 22:43:05,367 ----------------------------------------------------------------------------------------------------
2021-07-15 22:43:08,473 epoch 29 - iter 6/61 - loss 0.13609607 - samples/sec: 61.82 - lr: 0.000004
2021-07-15 22:43:11,563 epoch 29 - iter 12/61 - loss 0.14422497 - samples/sec: 62.15 - lr: 0.000004
2021-07-15 22:43:14,656 epoch 29 - iter 18/61 - loss 0.14689015 - samples/sec: 62.10 - lr: 0.000004
2021-07-15 22:43:17,971 epoch 29 - iter 24/61 - loss 0.13363473 - samples/sec: 57.93 - lr: 0.000004
2021-07-15 22:43:21,096 epoch 29 - iter 30/61 - loss 0.14134876 - samples/sec: 61.45 - lr: 0.000004
2021-07-15 22:43:24,186 epoch 29 - iter 36/61 - loss 0.13416008 - samples/sec: 62.16 - lr: 0.000004
2021-07-15 22:43:27,264 epoch 29 - iter 42/61 - loss 0.12936156 - samples/sec: 62.40 - lr: 0.000004
2021-07-15 22:43:30,362 epoch 29 - iter 48/61 - loss 0.12466946 - samples/sec: 61.99 - lr: 0.000004
2021-07-15 22:43:33,492 epoch 29 - iter 54/61 - loss 0.12142956 - samples/sec: 61.36 - lr: 0.000004
2021-07-15 22:43:36,614 epoch 29 - iter 60/61 - loss 0.12189340 - samples/sec: 61.50 - lr: 0.000004
2021-07-15 22:43:36,965 ----------------------------------------------------------------------------------------------------
2021-07-15 22:43:36,965 EPOCH 29 done: loss 0.1247 - lr 0.0000038
2021-07-15 22:43:38,777 DEV : loss 0.1842080056667328 - score 0.9423
2021-07-15 22:43:38,803 BAD EPOCHS (no improvement): 1
2021-07-15 22:43:38,804 ----------------------------------------------------------------------------------------------------
2021-07-15 22:43:41,938 epoch 30 - iter 6/61 - loss 0.12110035 - samples/sec: 61.27 - lr: 0.000004
2021-07-15 22:43:45,026 epoch 30 - iter 12/61 - loss 0.11328504 - samples/sec: 62.18 - lr: 0.000004
2021-07-15 22:43:48,139 epoch 30 - iter 18/61 - loss 0.11468496 - samples/sec: 61.70 - lr: 0.000004
2021-07-15 22:43:51,247 epoch 30 - iter 24/61 - loss 0.12123998 - samples/sec: 61.79 - lr: 0.000004
2021-07-15 22:43:54,330 epoch 30 - iter 30/61 - loss 0.11391636 - samples/sec: 62.29 - lr: 0.000004
2021-07-15 22:43:57,427 epoch 30 - iter 36/61 - loss 0.11187529 - samples/sec: 62.02 - lr: 0.000004
2021-07-15 22:44:00,547 epoch 30 - iter 42/61 - loss 0.11283075 - samples/sec: 61.55 - lr: 0.000004
2021-07-15 22:44:03,654 epoch 30 - iter 48/61 - loss 0.11247552 - samples/sec: 61.81 - lr: 0.000004
2021-07-15 22:44:06,758 epoch 30 - iter 54/61 - loss 0.11106921 - samples/sec: 61.86 - lr: 0.000004
2021-07-15 22:44:10,007 epoch 30 - iter 60/61 - loss 0.10953697 - samples/sec: 59.11 - lr: 0.000004
2021-07-15 22:44:10,344 ----------------------------------------------------------------------------------------------------
2021-07-15 22:44:10,344 EPOCH 30 done: loss 0.1093 - lr 0.0000038
2021-07-15 22:44:12,406 DEV : loss 0.1872379183769226 - score 0.9426
2021-07-15 22:44:12,431 BAD EPOCHS (no improvement): 2
2021-07-15 22:44:12,431 ----------------------------------------------------------------------------------------------------
2021-07-15 22:44:16,545 epoch 31 - iter 6/61 - loss 0.11389442 - samples/sec: 46.69 - lr: 0.000004
2021-07-15 22:44:20,888 epoch 31 - iter 12/61 - loss 0.10699356 - samples/sec: 44.22 - lr: 0.000004
2021-07-15 22:44:25,899 epoch 31 - iter 18/61 - loss 0.11297121 - samples/sec: 38.32 - lr: 0.000004
2021-07-15 22:44:30,791 epoch 31 - iter 24/61 - loss 0.12180077 - samples/sec: 39.26 - lr: 0.000004
2021-07-15 22:44:34,598 epoch 31 - iter 30/61 - loss 0.12232369 - samples/sec: 50.45 - lr: 0.000004
2021-07-15 22:44:38,162 epoch 31 - iter 36/61 - loss 0.12329708 - samples/sec: 53.88 - lr: 0.000004
2021-07-15 22:44:42,257 epoch 31 - iter 42/61 - loss 0.11699829 - samples/sec: 46.90 - lr: 0.000004
2021-07-15 22:44:46,218 epoch 31 - iter 48/61 - loss 0.12009789 - samples/sec: 48.48 - lr: 0.000004
2021-07-15 22:44:49,515 epoch 31 - iter 54/61 - loss 0.12066331 - samples/sec: 58.24 - lr: 0.000004
2021-07-15 22:44:52,845 epoch 31 - iter 60/61 - loss 0.11942930 - samples/sec: 57.68 - lr: 0.000004
2021-07-15 22:44:53,205 ----------------------------------------------------------------------------------------------------
2021-07-15 22:44:53,205 EPOCH 31 done: loss 0.1186 - lr 0.0000038
2021-07-15 22:44:55,535 DEV : loss 0.18413560092449188 - score 0.9448
2021-07-15 22:44:55,576 BAD EPOCHS (no improvement): 3
2021-07-15 22:44:55,576 ----------------------------------------------------------------------------------------------------
2021-07-15 22:44:59,862 epoch 32 - iter 6/61 - loss 0.09024978 - samples/sec: 44.81 - lr: 0.000004
2021-07-15 22:45:03,551 epoch 32 - iter 12/61 - loss 0.09643622 - samples/sec: 52.05 - lr: 0.000004
2021-07-15 22:45:06,743 epoch 32 - iter 18/61 - loss 0.09067635 - samples/sec: 60.17 - lr: 0.000004
2021-07-15 22:45:10,319 epoch 32 - iter 24/61 - loss 0.09466463 - samples/sec: 53.70 - lr: 0.000004
2021-07-15 22:45:14,453 epoch 32 - iter 30/61 - loss 0.09097607 - samples/sec: 46.45 - lr: 0.000004
2021-07-15 22:45:18,163 epoch 32 - iter 36/61 - loss 0.09722649 - samples/sec: 51.77 - lr: 0.000004
2021-07-15 22:45:22,299 epoch 32 - iter 42/61 - loss 0.09897272 - samples/sec: 46.43 - lr: 0.000004
2021-07-15 22:45:26,265 epoch 32 - iter 48/61 - loss 0.10161320 - samples/sec: 48.42 - lr: 0.000004
2021-07-15 22:45:29,952 epoch 32 - iter 54/61 - loss 0.10957010 - samples/sec: 52.09 - lr: 0.000004
2021-07-15 22:45:34,156 epoch 32 - iter 60/61 - loss 0.10850572 - samples/sec: 45.68 - lr: 0.000004
2021-07-15 22:45:34,626 ----------------------------------------------------------------------------------------------------
2021-07-15 22:45:34,627 EPOCH 32 done: loss 0.1069 - lr 0.0000038
2021-07-15 22:45:37,117 DEV : loss 0.1911100596189499 - score 0.9381
Epoch    32: reducing learning rate of group 0 to 1.8750e-06.
2021-07-15 22:45:37,154 BAD EPOCHS (no improvement): 4
2021-07-15 22:45:37,155 ----------------------------------------------------------------------------------------------------
2021-07-15 22:45:37,155 ----------------------------------------------------------------------------------------------------
2021-07-15 22:45:37,155 learning rate too small - quitting training!
2021-07-15 22:45:37,155 ----------------------------------------------------------------------------------------------------
2021-07-15 22:45:39,079 ----------------------------------------------------------------------------------------------------
2021-07-15 22:45:39,079 Testing using best model ...
2021-07-15 22:45:39,080 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/fas.rst.prstc/best-model.pt
2021-07-15 22:45:55,778 0.9091	0.9499	0.9290
2021-07-15 22:45:55,778 
Results:
- F1-score (micro) 0.9290
- F1-score (macro) 0.9290

By class:
SENT       tp: 360 - fp: 36 - fn: 19 - precision: 0.9091 - recall: 0.9499 - f1-score: 0.9290
2021-07-15 22:45:55,778 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/tur.pdtb.tdb/
2021-07-15 22:45:55,798 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/tur.pdtb.tdb
2021-07-15 22:45:55,799 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/tur.pdtb.tdb/sent_train.txt
2021-07-15 22:45:55,801 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/tur.pdtb.tdb/sent_dev.txt
2021-07-15 22:45:55,803 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/tur.pdtb.tdb/sent_test.txt
Corpus: 13984 train + 2347 dev + 4731 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-15 22:46:12,755 ----------------------------------------------------------------------------------------------------
2021-07-15 22:46:12,757 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(32000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-15 22:46:12,757 ----------------------------------------------------------------------------------------------------
2021-07-15 22:46:12,757 Corpus: "Corpus: 13984 train + 2347 dev + 4731 test sentences"
2021-07-15 22:46:12,757 ----------------------------------------------------------------------------------------------------
2021-07-15 22:46:12,757 Parameters:
2021-07-15 22:46:12,757  - learning_rate: "3e-05"
2021-07-15 22:46:12,758  - mini_batch_size: "32"
2021-07-15 22:46:12,758  - patience: "3"
2021-07-15 22:46:12,758  - anneal_factor: "0.5"
2021-07-15 22:46:12,758  - max_epochs: "40"
2021-07-15 22:46:12,758  - shuffle: "True"
2021-07-15 22:46:12,758  - train_with_dev: "False"
2021-07-15 22:46:12,758  - batch_growth_annealing: "False"
2021-07-15 22:46:12,758 ----------------------------------------------------------------------------------------------------
2021-07-15 22:46:12,758 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/tur.pdtb.tdb"
2021-07-15 22:46:12,758 ----------------------------------------------------------------------------------------------------
2021-07-15 22:46:12,758 Device: cuda:0
2021-07-15 22:46:12,758 ----------------------------------------------------------------------------------------------------
2021-07-15 22:46:12,758 Embeddings storage mode: cpu
2021-07-15 22:46:12,762 ----------------------------------------------------------------------------------------------------
2021-07-15 22:47:13,617 epoch 1 - iter 43/437 - loss 9.21814853 - samples/sec: 22.61 - lr: 0.000030
2021-07-15 22:48:21,052 epoch 1 - iter 86/437 - loss 5.61787484 - samples/sec: 20.41 - lr: 0.000030
2021-07-15 22:49:31,181 epoch 1 - iter 129/437 - loss 4.16332539 - samples/sec: 19.62 - lr: 0.000030
2021-07-15 22:50:24,319 epoch 1 - iter 172/437 - loss 3.36837662 - samples/sec: 25.90 - lr: 0.000030
2021-07-15 22:51:11,490 epoch 1 - iter 215/437 - loss 2.85422425 - samples/sec: 29.17 - lr: 0.000030
2021-07-15 22:51:59,121 epoch 1 - iter 258/437 - loss 2.50921005 - samples/sec: 28.89 - lr: 0.000030
2021-07-15 22:52:49,133 epoch 1 - iter 301/437 - loss 2.25443318 - samples/sec: 27.52 - lr: 0.000030
2021-07-15 22:53:39,323 epoch 1 - iter 344/437 - loss 2.05374352 - samples/sec: 27.42 - lr: 0.000030
2021-07-15 22:54:33,486 epoch 1 - iter 387/437 - loss 1.90372953 - samples/sec: 25.41 - lr: 0.000030
2021-07-15 22:55:23,445 epoch 1 - iter 430/437 - loss 1.77177866 - samples/sec: 27.54 - lr: 0.000030
2021-07-15 22:55:31,662 ----------------------------------------------------------------------------------------------------
2021-07-15 22:55:31,662 EPOCH 1 done: loss 1.7533 - lr 0.0000300
2021-07-15 22:56:23,736 DEV : loss 0.7266349196434021 - score 0.9301
2021-07-15 22:56:23,914 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 22:56:24,667 ----------------------------------------------------------------------------------------------------
2021-07-15 22:56:48,095 epoch 2 - iter 43/437 - loss 0.62059817 - samples/sec: 58.74 - lr: 0.000030
2021-07-15 22:57:11,576 epoch 2 - iter 86/437 - loss 0.58702049 - samples/sec: 58.61 - lr: 0.000030
2021-07-15 22:57:37,114 epoch 2 - iter 129/437 - loss 0.58403677 - samples/sec: 53.89 - lr: 0.000030
2021-07-15 22:58:07,220 epoch 2 - iter 172/437 - loss 0.57065392 - samples/sec: 45.71 - lr: 0.000030
2021-07-15 22:58:37,466 epoch 2 - iter 215/437 - loss 0.55605999 - samples/sec: 45.50 - lr: 0.000030
2021-07-15 22:59:18,161 epoch 2 - iter 258/437 - loss 0.54802628 - samples/sec: 33.82 - lr: 0.000030
2021-07-15 22:59:58,497 epoch 2 - iter 301/437 - loss 0.53340768 - samples/sec: 34.12 - lr: 0.000030
2021-07-15 23:00:39,362 epoch 2 - iter 344/437 - loss 0.52577845 - samples/sec: 33.67 - lr: 0.000030
2021-07-15 23:01:24,834 epoch 2 - iter 387/437 - loss 0.52044247 - samples/sec: 30.26 - lr: 0.000030
2021-07-15 23:02:07,874 epoch 2 - iter 430/437 - loss 0.51347164 - samples/sec: 31.97 - lr: 0.000030
2021-07-15 23:02:15,911 ----------------------------------------------------------------------------------------------------
2021-07-15 23:02:15,911 EPOCH 2 done: loss 0.5130 - lr 0.0000300
2021-07-15 23:02:47,640 DEV : loss 0.6609184741973877 - score 0.938
2021-07-15 23:02:47,894 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 23:02:51,866 ----------------------------------------------------------------------------------------------------
2021-07-15 23:03:33,696 epoch 3 - iter 43/437 - loss 0.42846907 - samples/sec: 32.90 - lr: 0.000030
2021-07-15 23:04:03,716 epoch 3 - iter 86/437 - loss 0.42027901 - samples/sec: 45.84 - lr: 0.000030
2021-07-15 23:04:27,084 epoch 3 - iter 129/437 - loss 0.41982787 - samples/sec: 58.89 - lr: 0.000030
2021-07-15 23:04:50,364 epoch 3 - iter 172/437 - loss 0.41691280 - samples/sec: 59.11 - lr: 0.000030
2021-07-15 23:05:21,929 epoch 3 - iter 215/437 - loss 0.41841806 - samples/sec: 43.60 - lr: 0.000030
2021-07-15 23:05:47,850 epoch 3 - iter 258/437 - loss 0.41636309 - samples/sec: 53.09 - lr: 0.000030
2021-07-15 23:06:12,148 epoch 3 - iter 301/437 - loss 0.41449003 - samples/sec: 56.64 - lr: 0.000030
2021-07-15 23:06:44,307 epoch 3 - iter 344/437 - loss 0.41487949 - samples/sec: 42.79 - lr: 0.000030
2021-07-15 23:07:16,218 epoch 3 - iter 387/437 - loss 0.41470875 - samples/sec: 43.12 - lr: 0.000030
2021-07-15 23:07:48,509 epoch 3 - iter 430/437 - loss 0.41421262 - samples/sec: 42.62 - lr: 0.000030
2021-07-15 23:07:55,018 ----------------------------------------------------------------------------------------------------
2021-07-15 23:07:55,018 EPOCH 3 done: loss 0.4128 - lr 0.0000300
2021-07-15 23:08:18,072 DEV : loss 0.6464072465896606 - score 0.9403
2021-07-15 23:08:18,249 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 23:08:21,921 ----------------------------------------------------------------------------------------------------
2021-07-15 23:08:53,661 epoch 4 - iter 43/437 - loss 0.37279028 - samples/sec: 43.36 - lr: 0.000030
2021-07-15 23:09:25,852 epoch 4 - iter 86/437 - loss 0.36486424 - samples/sec: 42.75 - lr: 0.000030
2021-07-15 23:09:59,208 epoch 4 - iter 129/437 - loss 0.36898955 - samples/sec: 41.25 - lr: 0.000030
2021-07-15 23:10:22,749 epoch 4 - iter 172/437 - loss 0.35840055 - samples/sec: 58.46 - lr: 0.000030
2021-07-15 23:10:46,297 epoch 4 - iter 215/437 - loss 0.37194657 - samples/sec: 58.44 - lr: 0.000030
2021-07-15 23:11:15,345 epoch 4 - iter 258/437 - loss 0.37171033 - samples/sec: 47.37 - lr: 0.000030
2021-07-15 23:11:54,840 epoch 4 - iter 301/437 - loss 0.37133480 - samples/sec: 34.84 - lr: 0.000030
2021-07-15 23:12:38,342 epoch 4 - iter 344/437 - loss 0.36797779 - samples/sec: 31.63 - lr: 0.000030
2021-07-15 23:13:19,637 epoch 4 - iter 387/437 - loss 0.36571319 - samples/sec: 33.32 - lr: 0.000030
2021-07-15 23:14:08,801 epoch 4 - iter 430/437 - loss 0.36406374 - samples/sec: 27.99 - lr: 0.000030
2021-07-15 23:14:17,220 ----------------------------------------------------------------------------------------------------
2021-07-15 23:14:17,221 EPOCH 4 done: loss 0.3638 - lr 0.0000300
2021-07-15 23:14:47,358 DEV : loss 0.6327165961265564 - score 0.9428
2021-07-15 23:14:47,534 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 23:14:51,352 ----------------------------------------------------------------------------------------------------
2021-07-15 23:15:24,884 epoch 5 - iter 43/437 - loss 0.32469488 - samples/sec: 41.04 - lr: 0.000030
2021-07-15 23:15:58,681 epoch 5 - iter 86/437 - loss 0.31494774 - samples/sec: 40.72 - lr: 0.000030
2021-07-15 23:16:25,201 epoch 5 - iter 129/437 - loss 0.33057131 - samples/sec: 51.89 - lr: 0.000030
2021-07-15 23:16:49,089 epoch 5 - iter 172/437 - loss 0.33760449 - samples/sec: 57.61 - lr: 0.000030
2021-07-15 23:17:20,923 epoch 5 - iter 215/437 - loss 0.33513152 - samples/sec: 43.23 - lr: 0.000030
2021-07-15 23:17:49,448 epoch 5 - iter 258/437 - loss 0.33491723 - samples/sec: 48.24 - lr: 0.000030
2021-07-15 23:18:23,078 epoch 5 - iter 301/437 - loss 0.33253630 - samples/sec: 40.92 - lr: 0.000030
2021-07-15 23:18:57,091 epoch 5 - iter 344/437 - loss 0.33328191 - samples/sec: 40.46 - lr: 0.000030
2021-07-15 23:19:27,915 epoch 5 - iter 387/437 - loss 0.32892086 - samples/sec: 44.65 - lr: 0.000030
2021-07-15 23:20:02,482 epoch 5 - iter 430/437 - loss 0.32796921 - samples/sec: 39.81 - lr: 0.000030
2021-07-15 23:20:07,032 ----------------------------------------------------------------------------------------------------
2021-07-15 23:20:07,032 EPOCH 5 done: loss 0.3279 - lr 0.0000300
2021-07-15 23:20:23,821 DEV : loss 0.6300196647644043 - score 0.9435
2021-07-15 23:20:24,069 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 23:20:27,979 ----------------------------------------------------------------------------------------------------
2021-07-15 23:21:05,971 epoch 6 - iter 43/437 - loss 0.30106328 - samples/sec: 36.22 - lr: 0.000030
2021-07-15 23:21:42,287 epoch 6 - iter 86/437 - loss 0.30063424 - samples/sec: 37.89 - lr: 0.000030
2021-07-15 23:22:20,219 epoch 6 - iter 129/437 - loss 0.29340671 - samples/sec: 36.28 - lr: 0.000030
2021-07-15 23:22:49,619 epoch 6 - iter 172/437 - loss 0.29372780 - samples/sec: 46.81 - lr: 0.000030
2021-07-15 23:23:13,615 epoch 6 - iter 215/437 - loss 0.29796663 - samples/sec: 57.35 - lr: 0.000030
2021-07-15 23:23:46,149 epoch 6 - iter 258/437 - loss 0.28989599 - samples/sec: 42.30 - lr: 0.000030
2021-07-15 23:24:21,372 epoch 6 - iter 301/437 - loss 0.29242279 - samples/sec: 39.07 - lr: 0.000030
2021-07-15 23:24:56,440 epoch 6 - iter 344/437 - loss 0.29310955 - samples/sec: 39.24 - lr: 0.000030
2021-07-15 23:25:30,803 epoch 6 - iter 387/437 - loss 0.29347835 - samples/sec: 40.05 - lr: 0.000030
2021-07-15 23:25:54,861 epoch 6 - iter 430/437 - loss 0.29795659 - samples/sec: 57.20 - lr: 0.000030
2021-07-15 23:25:59,008 ----------------------------------------------------------------------------------------------------
2021-07-15 23:25:59,008 EPOCH 6 done: loss 0.2985 - lr 0.0000300
2021-07-15 23:26:26,254 DEV : loss 0.6258965134620667 - score 0.9464
2021-07-15 23:26:26,430 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 23:26:30,399 ----------------------------------------------------------------------------------------------------
2021-07-15 23:27:04,196 epoch 7 - iter 43/437 - loss 0.30725190 - samples/sec: 40.72 - lr: 0.000030
2021-07-15 23:27:37,034 epoch 7 - iter 86/437 - loss 0.30816698 - samples/sec: 41.91 - lr: 0.000030
2021-07-15 23:28:00,657 epoch 7 - iter 129/437 - loss 0.30226165 - samples/sec: 58.25 - lr: 0.000030
2021-07-15 23:28:24,296 epoch 7 - iter 172/437 - loss 0.29633914 - samples/sec: 58.21 - lr: 0.000030
2021-07-15 23:28:58,911 epoch 7 - iter 215/437 - loss 0.30030486 - samples/sec: 39.75 - lr: 0.000030
2021-07-15 23:29:32,888 epoch 7 - iter 258/437 - loss 0.29171146 - samples/sec: 40.50 - lr: 0.000030
2021-07-15 23:30:07,100 epoch 7 - iter 301/437 - loss 0.28962683 - samples/sec: 40.22 - lr: 0.000030
2021-07-15 23:30:36,637 epoch 7 - iter 344/437 - loss 0.28751584 - samples/sec: 46.59 - lr: 0.000030
2021-07-15 23:31:10,426 epoch 7 - iter 387/437 - loss 0.28549545 - samples/sec: 40.73 - lr: 0.000030
2021-07-15 23:31:43,997 epoch 7 - iter 430/437 - loss 0.28433041 - samples/sec: 40.99 - lr: 0.000030
2021-07-15 23:31:49,403 ----------------------------------------------------------------------------------------------------
2021-07-15 23:31:49,404 EPOCH 7 done: loss 0.2846 - lr 0.0000300
2021-07-15 23:32:20,542 DEV : loss 0.633706271648407 - score 0.9447
2021-07-15 23:32:20,721 BAD EPOCHS (no improvement): 1
2021-07-15 23:32:20,722 ----------------------------------------------------------------------------------------------------
2021-07-15 23:32:47,576 epoch 8 - iter 43/437 - loss 0.26053489 - samples/sec: 51.24 - lr: 0.000030
2021-07-15 23:33:11,171 epoch 8 - iter 86/437 - loss 0.26178249 - samples/sec: 58.32 - lr: 0.000030
2021-07-15 23:33:34,862 epoch 8 - iter 129/437 - loss 0.26546909 - samples/sec: 58.09 - lr: 0.000030
2021-07-15 23:34:06,688 epoch 8 - iter 172/437 - loss 0.25517212 - samples/sec: 43.24 - lr: 0.000030
2021-07-15 23:34:39,878 epoch 8 - iter 215/437 - loss 0.25479000 - samples/sec: 41.46 - lr: 0.000030
2021-07-15 23:35:16,240 epoch 8 - iter 258/437 - loss 0.25763176 - samples/sec: 37.84 - lr: 0.000030
2021-07-15 23:35:46,937 epoch 8 - iter 301/437 - loss 0.25941675 - samples/sec: 44.83 - lr: 0.000030
2021-07-15 23:36:20,353 epoch 8 - iter 344/437 - loss 0.25875996 - samples/sec: 41.18 - lr: 0.000030
2021-07-15 23:36:53,938 epoch 8 - iter 387/437 - loss 0.25881803 - samples/sec: 40.97 - lr: 0.000030
2021-07-15 23:37:31,397 epoch 8 - iter 430/437 - loss 0.26008046 - samples/sec: 36.74 - lr: 0.000030
2021-07-15 23:37:36,768 ----------------------------------------------------------------------------------------------------
2021-07-15 23:37:36,768 EPOCH 8 done: loss 0.2606 - lr 0.0000300
2021-07-15 23:37:54,187 DEV : loss 0.6540747880935669 - score 0.9456
2021-07-15 23:37:54,362 BAD EPOCHS (no improvement): 2
2021-07-15 23:37:54,362 ----------------------------------------------------------------------------------------------------
2021-07-15 23:38:17,977 epoch 9 - iter 43/437 - loss 0.24203174 - samples/sec: 58.28 - lr: 0.000030
2021-07-15 23:38:41,589 epoch 9 - iter 86/437 - loss 0.24406537 - samples/sec: 58.28 - lr: 0.000030
2021-07-15 23:39:05,281 epoch 9 - iter 129/437 - loss 0.24398314 - samples/sec: 58.08 - lr: 0.000030
2021-07-15 23:39:28,936 epoch 9 - iter 172/437 - loss 0.24251910 - samples/sec: 58.17 - lr: 0.000030
2021-07-15 23:39:52,543 epoch 9 - iter 215/437 - loss 0.24349402 - samples/sec: 58.29 - lr: 0.000030
2021-07-15 23:40:16,177 epoch 9 - iter 258/437 - loss 0.24223921 - samples/sec: 58.23 - lr: 0.000030
2021-07-15 23:40:39,804 epoch 9 - iter 301/437 - loss 0.24552845 - samples/sec: 58.24 - lr: 0.000030
2021-07-15 23:41:03,408 epoch 9 - iter 344/437 - loss 0.24627751 - samples/sec: 58.30 - lr: 0.000030
2021-07-15 23:41:27,066 epoch 9 - iter 387/437 - loss 0.24737404 - samples/sec: 58.17 - lr: 0.000030
2021-07-15 23:41:50,734 epoch 9 - iter 430/437 - loss 0.24845320 - samples/sec: 58.15 - lr: 0.000030
2021-07-15 23:41:54,573 ----------------------------------------------------------------------------------------------------
2021-07-15 23:41:54,573 EPOCH 9 done: loss 0.2489 - lr 0.0000300
2021-07-15 23:42:07,824 DEV : loss 0.6633967161178589 - score 0.947
2021-07-15 23:42:08,002 BAD EPOCHS (no improvement): 0
saving best model
2021-07-15 23:42:11,841 ----------------------------------------------------------------------------------------------------
2021-07-15 23:42:35,580 epoch 10 - iter 43/437 - loss 0.24419803 - samples/sec: 57.97 - lr: 0.000030
2021-07-15 23:42:59,191 epoch 10 - iter 86/437 - loss 0.23863816 - samples/sec: 58.28 - lr: 0.000030
2021-07-15 23:43:22,859 epoch 10 - iter 129/437 - loss 0.23839910 - samples/sec: 58.14 - lr: 0.000030
2021-07-15 23:43:46,508 epoch 10 - iter 172/437 - loss 0.23486748 - samples/sec: 58.19 - lr: 0.000030
2021-07-15 23:44:10,154 epoch 10 - iter 215/437 - loss 0.23025771 - samples/sec: 58.20 - lr: 0.000030
2021-07-15 23:44:33,780 epoch 10 - iter 258/437 - loss 0.23045241 - samples/sec: 58.25 - lr: 0.000030
2021-07-15 23:44:57,398 epoch 10 - iter 301/437 - loss 0.23195532 - samples/sec: 58.27 - lr: 0.000030
2021-07-15 23:45:21,013 epoch 10 - iter 344/437 - loss 0.23395359 - samples/sec: 58.27 - lr: 0.000030
2021-07-15 23:45:44,658 epoch 10 - iter 387/437 - loss 0.23499348 - samples/sec: 58.20 - lr: 0.000030
2021-07-15 23:46:08,334 epoch 10 - iter 430/437 - loss 0.23364588 - samples/sec: 58.12 - lr: 0.000030
2021-07-15 23:46:12,182 ----------------------------------------------------------------------------------------------------
2021-07-15 23:46:12,183 EPOCH 10 done: loss 0.2330 - lr 0.0000300
2021-07-15 23:46:25,433 DEV : loss 0.6688311696052551 - score 0.9468
2021-07-15 23:46:25,611 BAD EPOCHS (no improvement): 1
2021-07-15 23:46:25,611 ----------------------------------------------------------------------------------------------------
2021-07-15 23:46:49,250 epoch 11 - iter 43/437 - loss 0.19166479 - samples/sec: 58.22 - lr: 0.000030
2021-07-15 23:47:12,872 epoch 11 - iter 86/437 - loss 0.21686087 - samples/sec: 58.26 - lr: 0.000030
2021-07-15 23:47:36,486 epoch 11 - iter 129/437 - loss 0.21737128 - samples/sec: 58.28 - lr: 0.000030
2021-07-15 23:48:01,219 epoch 11 - iter 172/437 - loss 0.22036827 - samples/sec: 55.64 - lr: 0.000030
2021-07-15 23:48:24,715 epoch 11 - iter 215/437 - loss 0.22364091 - samples/sec: 58.57 - lr: 0.000030
2021-07-15 23:48:48,317 epoch 11 - iter 258/437 - loss 0.22170622 - samples/sec: 58.31 - lr: 0.000030
2021-07-15 23:49:11,970 epoch 11 - iter 301/437 - loss 0.22429620 - samples/sec: 58.18 - lr: 0.000030
2021-07-15 23:49:35,582 epoch 11 - iter 344/437 - loss 0.22353289 - samples/sec: 58.28 - lr: 0.000030
2021-07-15 23:49:59,161 epoch 11 - iter 387/437 - loss 0.22123105 - samples/sec: 58.36 - lr: 0.000030
2021-07-15 23:50:22,824 epoch 11 - iter 430/437 - loss 0.22071246 - samples/sec: 58.16 - lr: 0.000030
2021-07-15 23:50:26,659 ----------------------------------------------------------------------------------------------------
2021-07-15 23:50:26,660 EPOCH 11 done: loss 0.2214 - lr 0.0000300
2021-07-15 23:50:39,897 DEV : loss 0.6986470222473145 - score 0.9468
2021-07-15 23:50:40,076 BAD EPOCHS (no improvement): 2
2021-07-15 23:50:40,077 ----------------------------------------------------------------------------------------------------
2021-07-15 23:51:03,638 epoch 12 - iter 43/437 - loss 0.19429847 - samples/sec: 58.41 - lr: 0.000030
2021-07-15 23:51:27,164 epoch 12 - iter 86/437 - loss 0.21098332 - samples/sec: 58.49 - lr: 0.000030
2021-07-15 23:51:50,626 epoch 12 - iter 129/437 - loss 0.21075191 - samples/sec: 58.65 - lr: 0.000030
2021-07-15 23:52:14,150 epoch 12 - iter 172/437 - loss 0.21086014 - samples/sec: 58.50 - lr: 0.000030
2021-07-15 23:52:37,706 epoch 12 - iter 215/437 - loss 0.21467134 - samples/sec: 58.42 - lr: 0.000030
2021-07-15 23:53:01,237 epoch 12 - iter 258/437 - loss 0.21182758 - samples/sec: 58.48 - lr: 0.000030
2021-07-15 23:53:24,772 epoch 12 - iter 301/437 - loss 0.21257435 - samples/sec: 58.47 - lr: 0.000030
2021-07-15 23:53:48,352 epoch 12 - iter 344/437 - loss 0.21285047 - samples/sec: 58.36 - lr: 0.000030
2021-07-15 23:54:11,934 epoch 12 - iter 387/437 - loss 0.21682218 - samples/sec: 58.35 - lr: 0.000030
2021-07-15 23:54:35,499 epoch 12 - iter 430/437 - loss 0.21348643 - samples/sec: 58.40 - lr: 0.000030
2021-07-15 23:54:39,337 ----------------------------------------------------------------------------------------------------
2021-07-15 23:54:39,337 EPOCH 12 done: loss 0.2141 - lr 0.0000300
2021-07-15 23:54:52,608 DEV : loss 0.7000285387039185 - score 0.9451
2021-07-15 23:54:52,785 BAD EPOCHS (no improvement): 3
2021-07-15 23:54:52,785 ----------------------------------------------------------------------------------------------------
2021-07-15 23:55:16,387 epoch 13 - iter 43/437 - loss 0.19186116 - samples/sec: 58.31 - lr: 0.000030
2021-07-15 23:55:39,871 epoch 13 - iter 86/437 - loss 0.19497623 - samples/sec: 58.60 - lr: 0.000030
2021-07-15 23:56:03,535 epoch 13 - iter 129/437 - loss 0.20131247 - samples/sec: 58.15 - lr: 0.000030
2021-07-15 23:56:27,166 epoch 13 - iter 172/437 - loss 0.20882075 - samples/sec: 58.23 - lr: 0.000030
2021-07-15 23:56:50,802 epoch 13 - iter 215/437 - loss 0.20794604 - samples/sec: 58.22 - lr: 0.000030
2021-07-15 23:57:14,526 epoch 13 - iter 258/437 - loss 0.21098707 - samples/sec: 58.01 - lr: 0.000030
2021-07-15 23:57:38,238 epoch 13 - iter 301/437 - loss 0.21037655 - samples/sec: 58.04 - lr: 0.000030
2021-07-15 23:58:01,944 epoch 13 - iter 344/437 - loss 0.20823783 - samples/sec: 58.05 - lr: 0.000030
2021-07-15 23:58:25,595 epoch 13 - iter 387/437 - loss 0.20550780 - samples/sec: 58.18 - lr: 0.000030
2021-07-15 23:58:49,227 epoch 13 - iter 430/437 - loss 0.20734258 - samples/sec: 58.23 - lr: 0.000030
2021-07-15 23:58:53,084 ----------------------------------------------------------------------------------------------------
2021-07-15 23:58:53,084 EPOCH 13 done: loss 0.2067 - lr 0.0000300
2021-07-15 23:59:06,402 DEV : loss 0.7065809369087219 - score 0.9465
Epoch    13: reducing learning rate of group 0 to 1.5000e-05.
2021-07-15 23:59:06,577 BAD EPOCHS (no improvement): 4
2021-07-15 23:59:06,577 ----------------------------------------------------------------------------------------------------
2021-07-15 23:59:30,206 epoch 14 - iter 43/437 - loss 0.16831268 - samples/sec: 58.24 - lr: 0.000015
2021-07-15 23:59:53,855 epoch 14 - iter 86/437 - loss 0.17489923 - samples/sec: 58.19 - lr: 0.000015
2021-07-16 00:00:17,488 epoch 14 - iter 129/437 - loss 0.17690039 - samples/sec: 58.23 - lr: 0.000015
2021-07-16 00:00:41,178 epoch 14 - iter 172/437 - loss 0.18007758 - samples/sec: 58.09 - lr: 0.000015
2021-07-16 00:01:04,855 epoch 14 - iter 215/437 - loss 0.18325408 - samples/sec: 58.12 - lr: 0.000015
2021-07-16 00:01:28,436 epoch 14 - iter 258/437 - loss 0.18514354 - samples/sec: 58.36 - lr: 0.000015
2021-07-16 00:01:52,099 epoch 14 - iter 301/437 - loss 0.18408937 - samples/sec: 58.16 - lr: 0.000015
2021-07-16 00:02:15,776 epoch 14 - iter 344/437 - loss 0.18465127 - samples/sec: 58.12 - lr: 0.000015
2021-07-16 00:02:39,446 epoch 14 - iter 387/437 - loss 0.18503064 - samples/sec: 58.14 - lr: 0.000015
2021-07-16 00:03:03,062 epoch 14 - iter 430/437 - loss 0.18824136 - samples/sec: 58.27 - lr: 0.000015
2021-07-16 00:03:06,883 ----------------------------------------------------------------------------------------------------
2021-07-16 00:03:06,883 EPOCH 14 done: loss 0.1879 - lr 0.0000150
2021-07-16 00:03:21,354 DEV : loss 0.7043650150299072 - score 0.9456
2021-07-16 00:03:21,529 BAD EPOCHS (no improvement): 1
2021-07-16 00:03:21,529 ----------------------------------------------------------------------------------------------------
2021-07-16 00:03:45,151 epoch 15 - iter 43/437 - loss 0.17613872 - samples/sec: 58.26 - lr: 0.000015
2021-07-16 00:04:08,807 epoch 15 - iter 86/437 - loss 0.17770396 - samples/sec: 58.17 - lr: 0.000015
2021-07-16 00:04:32,475 epoch 15 - iter 129/437 - loss 0.17604416 - samples/sec: 58.14 - lr: 0.000015
2021-07-16 00:04:56,091 epoch 15 - iter 172/437 - loss 0.17871908 - samples/sec: 58.27 - lr: 0.000015
2021-07-16 00:05:19,707 epoch 15 - iter 215/437 - loss 0.17759828 - samples/sec: 58.27 - lr: 0.000015
2021-07-16 00:05:43,340 epoch 15 - iter 258/437 - loss 0.17659604 - samples/sec: 58.23 - lr: 0.000015
2021-07-16 00:06:06,927 epoch 15 - iter 301/437 - loss 0.17860923 - samples/sec: 58.34 - lr: 0.000015
2021-07-16 00:06:30,582 epoch 15 - iter 344/437 - loss 0.18188712 - samples/sec: 58.17 - lr: 0.000015
2021-07-16 00:06:54,231 epoch 15 - iter 387/437 - loss 0.18127670 - samples/sec: 58.19 - lr: 0.000015
2021-07-16 00:07:17,930 epoch 15 - iter 430/437 - loss 0.18160327 - samples/sec: 58.07 - lr: 0.000015
2021-07-16 00:07:21,795 ----------------------------------------------------------------------------------------------------
2021-07-16 00:07:21,795 EPOCH 15 done: loss 0.1811 - lr 0.0000150
2021-07-16 00:07:35,006 DEV : loss 0.7132378220558167 - score 0.9466
2021-07-16 00:07:35,183 BAD EPOCHS (no improvement): 2
2021-07-16 00:07:35,183 ----------------------------------------------------------------------------------------------------
2021-07-16 00:07:58,811 epoch 16 - iter 43/437 - loss 0.17419640 - samples/sec: 58.24 - lr: 0.000015
2021-07-16 00:08:22,478 epoch 16 - iter 86/437 - loss 0.17541487 - samples/sec: 58.15 - lr: 0.000015
2021-07-16 00:08:46,170 epoch 16 - iter 129/437 - loss 0.17902864 - samples/sec: 58.09 - lr: 0.000015
2021-07-16 00:09:09,750 epoch 16 - iter 172/437 - loss 0.18120560 - samples/sec: 58.36 - lr: 0.000015
2021-07-16 00:09:33,395 epoch 16 - iter 215/437 - loss 0.18041207 - samples/sec: 58.20 - lr: 0.000015
2021-07-16 00:09:57,019 epoch 16 - iter 258/437 - loss 0.17925109 - samples/sec: 58.25 - lr: 0.000015
2021-07-16 00:10:20,690 epoch 16 - iter 301/437 - loss 0.17878865 - samples/sec: 58.14 - lr: 0.000015
2021-07-16 00:10:44,359 epoch 16 - iter 344/437 - loss 0.18079584 - samples/sec: 58.14 - lr: 0.000015
2021-07-16 00:11:07,782 epoch 16 - iter 387/437 - loss 0.18044498 - samples/sec: 58.75 - lr: 0.000015
2021-07-16 00:11:31,371 epoch 16 - iter 430/437 - loss 0.17973519 - samples/sec: 58.34 - lr: 0.000015
2021-07-16 00:11:35,209 ----------------------------------------------------------------------------------------------------
2021-07-16 00:11:35,209 EPOCH 16 done: loss 0.1799 - lr 0.0000150
2021-07-16 00:11:48,453 DEV : loss 0.7243148684501648 - score 0.9468
2021-07-16 00:11:48,632 BAD EPOCHS (no improvement): 3
2021-07-16 00:11:48,632 ----------------------------------------------------------------------------------------------------
2021-07-16 00:12:12,338 epoch 17 - iter 43/437 - loss 0.16960330 - samples/sec: 58.05 - lr: 0.000015
2021-07-16 00:12:35,904 epoch 17 - iter 86/437 - loss 0.17139440 - samples/sec: 58.40 - lr: 0.000015
2021-07-16 00:12:59,475 epoch 17 - iter 129/437 - loss 0.16078068 - samples/sec: 58.38 - lr: 0.000015
2021-07-16 00:13:23,102 epoch 17 - iter 172/437 - loss 0.16017876 - samples/sec: 58.24 - lr: 0.000015
2021-07-16 00:13:46,644 epoch 17 - iter 215/437 - loss 0.16266905 - samples/sec: 58.46 - lr: 0.000015
2021-07-16 00:14:10,335 epoch 17 - iter 258/437 - loss 0.16343315 - samples/sec: 58.09 - lr: 0.000015
2021-07-16 00:14:33,852 epoch 17 - iter 301/437 - loss 0.16198077 - samples/sec: 58.52 - lr: 0.000015
2021-07-16 00:14:57,350 epoch 17 - iter 344/437 - loss 0.16466289 - samples/sec: 58.56 - lr: 0.000015
2021-07-16 00:15:21,040 epoch 17 - iter 387/437 - loss 0.16758710 - samples/sec: 58.09 - lr: 0.000015
2021-07-16 00:15:44,703 epoch 17 - iter 430/437 - loss 0.17005601 - samples/sec: 58.16 - lr: 0.000015
2021-07-16 00:15:48,553 ----------------------------------------------------------------------------------------------------
2021-07-16 00:15:48,553 EPOCH 17 done: loss 0.1709 - lr 0.0000150
2021-07-16 00:16:02,997 DEV : loss 0.7258497476577759 - score 0.9473
2021-07-16 00:16:03,175 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 00:16:06,989 ----------------------------------------------------------------------------------------------------
2021-07-16 00:16:30,518 epoch 18 - iter 43/437 - loss 0.15034929 - samples/sec: 58.49 - lr: 0.000015
2021-07-16 00:16:53,995 epoch 18 - iter 86/437 - loss 0.15212462 - samples/sec: 58.62 - lr: 0.000015
2021-07-16 00:17:17,451 epoch 18 - iter 129/437 - loss 0.14443002 - samples/sec: 58.67 - lr: 0.000015
2021-07-16 00:17:41,064 epoch 18 - iter 172/437 - loss 0.14830480 - samples/sec: 58.28 - lr: 0.000015
2021-07-16 00:18:04,719 epoch 18 - iter 215/437 - loss 0.15587658 - samples/sec: 58.17 - lr: 0.000015
2021-07-16 00:18:28,400 epoch 18 - iter 258/437 - loss 0.15940964 - samples/sec: 58.11 - lr: 0.000015
2021-07-16 00:18:52,042 epoch 18 - iter 301/437 - loss 0.16220281 - samples/sec: 58.21 - lr: 0.000015
2021-07-16 00:19:15,795 epoch 18 - iter 344/437 - loss 0.16576803 - samples/sec: 57.94 - lr: 0.000015
2021-07-16 00:19:39,508 epoch 18 - iter 387/437 - loss 0.16573839 - samples/sec: 58.03 - lr: 0.000015
2021-07-16 00:20:03,204 epoch 18 - iter 430/437 - loss 0.16808510 - samples/sec: 58.08 - lr: 0.000015
2021-07-16 00:20:07,067 ----------------------------------------------------------------------------------------------------
2021-07-16 00:20:07,068 EPOCH 18 done: loss 0.1681 - lr 0.0000150
2021-07-16 00:20:20,305 DEV : loss 0.7329831719398499 - score 0.946
2021-07-16 00:20:20,483 BAD EPOCHS (no improvement): 1
2021-07-16 00:20:20,483 ----------------------------------------------------------------------------------------------------
2021-07-16 00:20:44,141 epoch 19 - iter 43/437 - loss 0.14373942 - samples/sec: 58.17 - lr: 0.000015
2021-07-16 00:21:07,860 epoch 19 - iter 86/437 - loss 0.15083689 - samples/sec: 58.02 - lr: 0.000015
2021-07-16 00:21:31,575 epoch 19 - iter 129/437 - loss 0.15829306 - samples/sec: 58.03 - lr: 0.000015
2021-07-16 00:21:55,111 epoch 19 - iter 172/437 - loss 0.16306237 - samples/sec: 58.47 - lr: 0.000015
2021-07-16 00:22:18,560 epoch 19 - iter 215/437 - loss 0.16039744 - samples/sec: 58.69 - lr: 0.000015
2021-07-16 00:22:42,122 epoch 19 - iter 258/437 - loss 0.15962807 - samples/sec: 58.41 - lr: 0.000015
2021-07-16 00:23:05,838 epoch 19 - iter 301/437 - loss 0.15571986 - samples/sec: 58.03 - lr: 0.000015
2021-07-16 00:23:29,503 epoch 19 - iter 344/437 - loss 0.15550059 - samples/sec: 58.15 - lr: 0.000015
2021-07-16 00:23:53,171 epoch 19 - iter 387/437 - loss 0.15794172 - samples/sec: 58.14 - lr: 0.000015
2021-07-16 00:24:16,764 epoch 19 - iter 430/437 - loss 0.15720872 - samples/sec: 58.33 - lr: 0.000015
2021-07-16 00:24:20,569 ----------------------------------------------------------------------------------------------------
2021-07-16 00:24:20,569 EPOCH 19 done: loss 0.1583 - lr 0.0000150
2021-07-16 00:24:33,787 DEV : loss 0.7333964705467224 - score 0.9476
2021-07-16 00:24:33,965 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 00:24:37,770 ----------------------------------------------------------------------------------------------------
2021-07-16 00:25:01,310 epoch 20 - iter 43/437 - loss 0.14119831 - samples/sec: 58.46 - lr: 0.000015
2021-07-16 00:25:24,892 epoch 20 - iter 86/437 - loss 0.15979196 - samples/sec: 58.36 - lr: 0.000015
2021-07-16 00:25:48,396 epoch 20 - iter 129/437 - loss 0.15664788 - samples/sec: 58.55 - lr: 0.000015
2021-07-16 00:26:11,926 epoch 20 - iter 172/437 - loss 0.15914873 - samples/sec: 58.48 - lr: 0.000015
2021-07-16 00:26:35,527 epoch 20 - iter 215/437 - loss 0.15982173 - samples/sec: 58.31 - lr: 0.000015
2021-07-16 00:26:59,088 epoch 20 - iter 258/437 - loss 0.16371954 - samples/sec: 58.41 - lr: 0.000015
2021-07-16 00:27:22,726 epoch 20 - iter 301/437 - loss 0.16168095 - samples/sec: 58.22 - lr: 0.000015
2021-07-16 00:27:46,350 epoch 20 - iter 344/437 - loss 0.16170934 - samples/sec: 58.25 - lr: 0.000015
2021-07-16 00:28:09,873 epoch 20 - iter 387/437 - loss 0.16122410 - samples/sec: 58.50 - lr: 0.000015
2021-07-16 00:28:33,400 epoch 20 - iter 430/437 - loss 0.16054251 - samples/sec: 58.49 - lr: 0.000015
2021-07-16 00:28:37,234 ----------------------------------------------------------------------------------------------------
2021-07-16 00:28:37,234 EPOCH 20 done: loss 0.1600 - lr 0.0000150
2021-07-16 00:28:51,713 DEV : loss 0.7381328344345093 - score 0.9457
2021-07-16 00:28:51,891 BAD EPOCHS (no improvement): 1
2021-07-16 00:28:51,891 ----------------------------------------------------------------------------------------------------
2021-07-16 00:29:15,428 epoch 21 - iter 43/437 - loss 0.17209877 - samples/sec: 58.47 - lr: 0.000015
2021-07-16 00:29:38,908 epoch 21 - iter 86/437 - loss 0.16443673 - samples/sec: 58.61 - lr: 0.000015
2021-07-16 00:30:02,416 epoch 21 - iter 129/437 - loss 0.16570641 - samples/sec: 58.54 - lr: 0.000015
2021-07-16 00:30:26,062 epoch 21 - iter 172/437 - loss 0.16767666 - samples/sec: 58.20 - lr: 0.000015
2021-07-16 00:30:49,523 epoch 21 - iter 215/437 - loss 0.16656945 - samples/sec: 58.66 - lr: 0.000015
2021-07-16 00:31:13,044 epoch 21 - iter 258/437 - loss 0.16540545 - samples/sec: 58.51 - lr: 0.000015
2021-07-16 00:31:36,629 epoch 21 - iter 301/437 - loss 0.15936789 - samples/sec: 58.35 - lr: 0.000015
2021-07-16 00:32:00,178 epoch 21 - iter 344/437 - loss 0.16039312 - samples/sec: 58.44 - lr: 0.000015
2021-07-16 00:32:23,918 epoch 21 - iter 387/437 - loss 0.15955231 - samples/sec: 57.97 - lr: 0.000015
2021-07-16 00:32:47,620 epoch 21 - iter 430/437 - loss 0.15884043 - samples/sec: 58.06 - lr: 0.000015
2021-07-16 00:32:51,466 ----------------------------------------------------------------------------------------------------
2021-07-16 00:32:51,467 EPOCH 21 done: loss 0.1589 - lr 0.0000150
2021-07-16 00:33:04,679 DEV : loss 0.7535942792892456 - score 0.9463
2021-07-16 00:33:04,858 BAD EPOCHS (no improvement): 2
2021-07-16 00:33:04,859 ----------------------------------------------------------------------------------------------------
2021-07-16 00:33:28,548 epoch 22 - iter 43/437 - loss 0.15211615 - samples/sec: 58.09 - lr: 0.000015
2021-07-16 00:33:52,211 epoch 22 - iter 86/437 - loss 0.16377007 - samples/sec: 58.16 - lr: 0.000015
2021-07-16 00:34:15,959 epoch 22 - iter 129/437 - loss 0.16315247 - samples/sec: 57.95 - lr: 0.000015
2021-07-16 00:34:39,685 epoch 22 - iter 172/437 - loss 0.15710573 - samples/sec: 58.00 - lr: 0.000015
2021-07-16 00:35:03,370 epoch 22 - iter 215/437 - loss 0.15611931 - samples/sec: 58.10 - lr: 0.000015
2021-07-16 00:35:27,038 epoch 22 - iter 258/437 - loss 0.15350961 - samples/sec: 58.14 - lr: 0.000015
2021-07-16 00:35:50,489 epoch 22 - iter 301/437 - loss 0.15187466 - samples/sec: 58.68 - lr: 0.000015
2021-07-16 00:36:13,958 epoch 22 - iter 344/437 - loss 0.15033073 - samples/sec: 58.64 - lr: 0.000015
2021-07-16 00:36:37,704 epoch 22 - iter 387/437 - loss 0.14998073 - samples/sec: 57.95 - lr: 0.000015
2021-07-16 00:37:01,452 epoch 22 - iter 430/437 - loss 0.14865447 - samples/sec: 57.95 - lr: 0.000015
2021-07-16 00:37:05,315 ----------------------------------------------------------------------------------------------------
2021-07-16 00:37:05,315 EPOCH 22 done: loss 0.1490 - lr 0.0000150
2021-07-16 00:37:18,543 DEV : loss 0.7565162181854248 - score 0.9454
2021-07-16 00:37:18,720 BAD EPOCHS (no improvement): 3
2021-07-16 00:37:18,721 ----------------------------------------------------------------------------------------------------
2021-07-16 00:37:42,498 epoch 23 - iter 43/437 - loss 0.16518240 - samples/sec: 57.88 - lr: 0.000015
2021-07-16 00:38:06,252 epoch 23 - iter 86/437 - loss 0.17406931 - samples/sec: 57.93 - lr: 0.000015
2021-07-16 00:38:30,019 epoch 23 - iter 129/437 - loss 0.16541998 - samples/sec: 57.90 - lr: 0.000015
2021-07-16 00:38:53,783 epoch 23 - iter 172/437 - loss 0.16830340 - samples/sec: 57.91 - lr: 0.000015
2021-07-16 00:39:17,519 epoch 23 - iter 215/437 - loss 0.16334757 - samples/sec: 57.97 - lr: 0.000015
2021-07-16 00:39:41,308 epoch 23 - iter 258/437 - loss 0.16029674 - samples/sec: 57.85 - lr: 0.000015
2021-07-16 00:40:04,947 epoch 23 - iter 301/437 - loss 0.15746176 - samples/sec: 58.22 - lr: 0.000015
2021-07-16 00:40:28,703 epoch 23 - iter 344/437 - loss 0.15565499 - samples/sec: 57.93 - lr: 0.000015
2021-07-16 00:40:52,487 epoch 23 - iter 387/437 - loss 0.15342911 - samples/sec: 57.86 - lr: 0.000015
2021-07-16 00:41:16,288 epoch 23 - iter 430/437 - loss 0.15303059 - samples/sec: 57.82 - lr: 0.000015
2021-07-16 00:41:20,151 ----------------------------------------------------------------------------------------------------
2021-07-16 00:41:20,151 EPOCH 23 done: loss 0.1535 - lr 0.0000150
2021-07-16 00:41:33,451 DEV : loss 0.7540342211723328 - score 0.9472
Epoch    23: reducing learning rate of group 0 to 7.5000e-06.
2021-07-16 00:41:33,625 BAD EPOCHS (no improvement): 4
2021-07-16 00:41:33,625 ----------------------------------------------------------------------------------------------------
2021-07-16 00:41:57,175 epoch 24 - iter 43/437 - loss 0.14431949 - samples/sec: 58.44 - lr: 0.000008
2021-07-16 00:42:20,748 epoch 24 - iter 86/437 - loss 0.14295970 - samples/sec: 58.38 - lr: 0.000008
2021-07-16 00:42:44,295 epoch 24 - iter 129/437 - loss 0.14308619 - samples/sec: 58.44 - lr: 0.000008
2021-07-16 00:43:07,911 epoch 24 - iter 172/437 - loss 0.14345193 - samples/sec: 58.27 - lr: 0.000008
2021-07-16 00:43:31,650 epoch 24 - iter 215/437 - loss 0.14552767 - samples/sec: 57.97 - lr: 0.000008
2021-07-16 00:43:55,487 epoch 24 - iter 258/437 - loss 0.14436654 - samples/sec: 57.73 - lr: 0.000008
2021-07-16 00:44:19,264 epoch 24 - iter 301/437 - loss 0.14118844 - samples/sec: 57.88 - lr: 0.000008
2021-07-16 00:44:42,974 epoch 24 - iter 344/437 - loss 0.14071996 - samples/sec: 58.04 - lr: 0.000008
2021-07-16 00:45:07,867 epoch 24 - iter 387/437 - loss 0.14207008 - samples/sec: 55.28 - lr: 0.000008
2021-07-16 00:45:31,499 epoch 24 - iter 430/437 - loss 0.14244904 - samples/sec: 58.23 - lr: 0.000008
2021-07-16 00:45:35,358 ----------------------------------------------------------------------------------------------------
2021-07-16 00:45:35,359 EPOCH 24 done: loss 0.1428 - lr 0.0000075
2021-07-16 00:45:48,602 DEV : loss 0.76596599817276 - score 0.9466
2021-07-16 00:45:48,780 BAD EPOCHS (no improvement): 1
2021-07-16 00:45:48,780 ----------------------------------------------------------------------------------------------------
2021-07-16 00:46:12,453 epoch 25 - iter 43/437 - loss 0.15114684 - samples/sec: 58.13 - lr: 0.000008
2021-07-16 00:46:36,110 epoch 25 - iter 86/437 - loss 0.14868608 - samples/sec: 58.17 - lr: 0.000008
2021-07-16 00:46:59,779 epoch 25 - iter 129/437 - loss 0.14614671 - samples/sec: 58.14 - lr: 0.000008
2021-07-16 00:47:23,420 epoch 25 - iter 172/437 - loss 0.14478040 - samples/sec: 58.21 - lr: 0.000008
2021-07-16 00:47:47,135 epoch 25 - iter 215/437 - loss 0.14452150 - samples/sec: 58.03 - lr: 0.000008
2021-07-16 00:48:10,767 epoch 25 - iter 258/437 - loss 0.14315118 - samples/sec: 58.23 - lr: 0.000008
2021-07-16 00:48:34,438 epoch 25 - iter 301/437 - loss 0.14250025 - samples/sec: 58.14 - lr: 0.000008
2021-07-16 00:48:58,096 epoch 25 - iter 344/437 - loss 0.14405702 - samples/sec: 58.17 - lr: 0.000008
2021-07-16 00:49:21,886 epoch 25 - iter 387/437 - loss 0.14093977 - samples/sec: 57.84 - lr: 0.000008
2021-07-16 00:49:45,701 epoch 25 - iter 430/437 - loss 0.14223162 - samples/sec: 57.79 - lr: 0.000008
2021-07-16 00:49:49,555 ----------------------------------------------------------------------------------------------------
2021-07-16 00:49:49,555 EPOCH 25 done: loss 0.1424 - lr 0.0000075
2021-07-16 00:50:02,749 DEV : loss 0.7718750238418579 - score 0.9463
2021-07-16 00:50:02,928 BAD EPOCHS (no improvement): 2
2021-07-16 00:50:02,929 ----------------------------------------------------------------------------------------------------
2021-07-16 00:50:26,734 epoch 26 - iter 43/437 - loss 0.12964074 - samples/sec: 57.81 - lr: 0.000008
2021-07-16 00:50:50,461 epoch 26 - iter 86/437 - loss 0.13470295 - samples/sec: 58.00 - lr: 0.000008
2021-07-16 00:51:14,324 epoch 26 - iter 129/437 - loss 0.13698050 - samples/sec: 57.67 - lr: 0.000008
2021-07-16 00:51:38,044 epoch 26 - iter 172/437 - loss 0.13513985 - samples/sec: 58.02 - lr: 0.000008
2021-07-16 00:52:01,592 epoch 26 - iter 215/437 - loss 0.13874798 - samples/sec: 58.44 - lr: 0.000008
2021-07-16 00:52:25,251 epoch 26 - iter 258/437 - loss 0.14006257 - samples/sec: 58.17 - lr: 0.000008
2021-07-16 00:52:49,016 epoch 26 - iter 301/437 - loss 0.13793640 - samples/sec: 57.91 - lr: 0.000008
2021-07-16 00:53:12,659 epoch 26 - iter 344/437 - loss 0.13651586 - samples/sec: 58.21 - lr: 0.000008
2021-07-16 00:53:36,293 epoch 26 - iter 387/437 - loss 0.13632818 - samples/sec: 58.23 - lr: 0.000008
2021-07-16 00:53:59,925 epoch 26 - iter 430/437 - loss 0.13844337 - samples/sec: 58.23 - lr: 0.000008
2021-07-16 00:54:03,759 ----------------------------------------------------------------------------------------------------
2021-07-16 00:54:03,759 EPOCH 26 done: loss 0.1379 - lr 0.0000075
2021-07-16 00:54:16,959 DEV : loss 0.7709866762161255 - score 0.9459
2021-07-16 00:54:17,137 BAD EPOCHS (no improvement): 3
2021-07-16 00:54:17,137 ----------------------------------------------------------------------------------------------------
2021-07-16 00:54:40,764 epoch 27 - iter 43/437 - loss 0.13526459 - samples/sec: 58.25 - lr: 0.000008
2021-07-16 00:55:04,422 epoch 27 - iter 86/437 - loss 0.13049643 - samples/sec: 58.17 - lr: 0.000008
2021-07-16 00:55:28,094 epoch 27 - iter 129/437 - loss 0.13795481 - samples/sec: 58.13 - lr: 0.000008
2021-07-16 00:55:51,716 epoch 27 - iter 172/437 - loss 0.13459740 - samples/sec: 58.26 - lr: 0.000008
2021-07-16 00:56:15,368 epoch 27 - iter 215/437 - loss 0.13234400 - samples/sec: 58.18 - lr: 0.000008
2021-07-16 00:56:39,012 epoch 27 - iter 258/437 - loss 0.13299647 - samples/sec: 58.20 - lr: 0.000008
2021-07-16 00:57:02,670 epoch 27 - iter 301/437 - loss 0.13231714 - samples/sec: 58.17 - lr: 0.000008
2021-07-16 00:57:26,368 epoch 27 - iter 344/437 - loss 0.13134366 - samples/sec: 58.07 - lr: 0.000008
2021-07-16 00:57:50,181 epoch 27 - iter 387/437 - loss 0.13024920 - samples/sec: 57.79 - lr: 0.000008
2021-07-16 00:58:13,947 epoch 27 - iter 430/437 - loss 0.13249173 - samples/sec: 57.90 - lr: 0.000008
2021-07-16 00:58:17,814 ----------------------------------------------------------------------------------------------------
2021-07-16 00:58:17,814 EPOCH 27 done: loss 0.1331 - lr 0.0000075
2021-07-16 00:58:32,341 DEV : loss 0.7809068560600281 - score 0.9454
Epoch    27: reducing learning rate of group 0 to 3.7500e-06.
2021-07-16 00:58:32,520 BAD EPOCHS (no improvement): 4
2021-07-16 00:58:32,520 ----------------------------------------------------------------------------------------------------
2021-07-16 00:58:56,326 epoch 28 - iter 43/437 - loss 0.11206312 - samples/sec: 57.81 - lr: 0.000004
2021-07-16 00:59:20,058 epoch 28 - iter 86/437 - loss 0.12431672 - samples/sec: 57.99 - lr: 0.000004
2021-07-16 00:59:43,777 epoch 28 - iter 129/437 - loss 0.12792560 - samples/sec: 58.02 - lr: 0.000004
2021-07-16 01:00:07,416 epoch 28 - iter 172/437 - loss 0.12888128 - samples/sec: 58.22 - lr: 0.000004
2021-07-16 01:00:31,111 epoch 28 - iter 215/437 - loss 0.12959407 - samples/sec: 58.08 - lr: 0.000004
2021-07-16 01:00:54,708 epoch 28 - iter 258/437 - loss 0.13117653 - samples/sec: 58.32 - lr: 0.000004
2021-07-16 01:01:18,415 epoch 28 - iter 301/437 - loss 0.12922439 - samples/sec: 58.05 - lr: 0.000004
2021-07-16 01:01:42,167 epoch 28 - iter 344/437 - loss 0.12974222 - samples/sec: 57.94 - lr: 0.000004
2021-07-16 01:02:05,938 epoch 28 - iter 387/437 - loss 0.12867449 - samples/sec: 57.89 - lr: 0.000004
2021-07-16 01:02:29,501 epoch 28 - iter 430/437 - loss 0.12852571 - samples/sec: 58.40 - lr: 0.000004
2021-07-16 01:02:33,346 ----------------------------------------------------------------------------------------------------
2021-07-16 01:02:33,347 EPOCH 28 done: loss 0.1283 - lr 0.0000038
2021-07-16 01:02:46,528 DEV : loss 0.785426676273346 - score 0.9466
2021-07-16 01:02:46,707 BAD EPOCHS (no improvement): 1
2021-07-16 01:02:46,708 ----------------------------------------------------------------------------------------------------
2021-07-16 01:03:10,166 epoch 29 - iter 43/437 - loss 0.12374784 - samples/sec: 58.67 - lr: 0.000004
2021-07-16 01:03:33,689 epoch 29 - iter 86/437 - loss 0.13288850 - samples/sec: 58.50 - lr: 0.000004
2021-07-16 01:03:57,293 epoch 29 - iter 129/437 - loss 0.13257707 - samples/sec: 58.30 - lr: 0.000004
2021-07-16 01:04:21,081 epoch 29 - iter 172/437 - loss 0.13139982 - samples/sec: 57.85 - lr: 0.000004
2021-07-16 01:04:44,830 epoch 29 - iter 215/437 - loss 0.12974348 - samples/sec: 57.94 - lr: 0.000004
2021-07-16 01:05:08,592 epoch 29 - iter 258/437 - loss 0.12857398 - samples/sec: 57.92 - lr: 0.000004
2021-07-16 01:05:32,219 epoch 29 - iter 301/437 - loss 0.13016651 - samples/sec: 58.24 - lr: 0.000004
2021-07-16 01:05:55,875 epoch 29 - iter 344/437 - loss 0.12954633 - samples/sec: 58.17 - lr: 0.000004
2021-07-16 01:06:19,554 epoch 29 - iter 387/437 - loss 0.12994548 - samples/sec: 58.11 - lr: 0.000004
2021-07-16 01:06:43,180 epoch 29 - iter 430/437 - loss 0.13010321 - samples/sec: 58.25 - lr: 0.000004
2021-07-16 01:06:47,024 ----------------------------------------------------------------------------------------------------
2021-07-16 01:06:47,024 EPOCH 29 done: loss 0.1302 - lr 0.0000038
2021-07-16 01:07:00,206 DEV : loss 0.7785341143608093 - score 0.9449
2021-07-16 01:07:00,384 BAD EPOCHS (no improvement): 2
2021-07-16 01:07:00,384 ----------------------------------------------------------------------------------------------------
2021-07-16 01:07:23,959 epoch 30 - iter 43/437 - loss 0.11910630 - samples/sec: 58.38 - lr: 0.000004
2021-07-16 01:07:47,567 epoch 30 - iter 86/437 - loss 0.11337094 - samples/sec: 58.29 - lr: 0.000004
2021-07-16 01:08:11,157 epoch 30 - iter 129/437 - loss 0.11907853 - samples/sec: 58.33 - lr: 0.000004
2021-07-16 01:08:34,700 epoch 30 - iter 172/437 - loss 0.12003767 - samples/sec: 58.45 - lr: 0.000004
2021-07-16 01:08:58,452 epoch 30 - iter 215/437 - loss 0.11994599 - samples/sec: 57.94 - lr: 0.000004
2021-07-16 01:09:22,271 epoch 30 - iter 258/437 - loss 0.12086526 - samples/sec: 57.77 - lr: 0.000004
2021-07-16 01:09:46,051 epoch 30 - iter 301/437 - loss 0.12088198 - samples/sec: 57.87 - lr: 0.000004
2021-07-16 01:10:09,771 epoch 30 - iter 344/437 - loss 0.11978740 - samples/sec: 58.02 - lr: 0.000004
2021-07-16 01:10:33,586 epoch 30 - iter 387/437 - loss 0.12082750 - samples/sec: 57.78 - lr: 0.000004
2021-07-16 01:10:57,399 epoch 30 - iter 430/437 - loss 0.12095634 - samples/sec: 57.79 - lr: 0.000004
2021-07-16 01:11:01,272 ----------------------------------------------------------------------------------------------------
2021-07-16 01:11:01,273 EPOCH 30 done: loss 0.1204 - lr 0.0000038
2021-07-16 01:11:15,679 DEV : loss 0.7937438488006592 - score 0.9468
2021-07-16 01:11:15,856 BAD EPOCHS (no improvement): 3
2021-07-16 01:11:15,856 ----------------------------------------------------------------------------------------------------
2021-07-16 01:11:39,519 epoch 31 - iter 43/437 - loss 0.14651492 - samples/sec: 58.16 - lr: 0.000004
2021-07-16 01:12:03,190 epoch 31 - iter 86/437 - loss 0.12467193 - samples/sec: 58.14 - lr: 0.000004
2021-07-16 01:12:26,990 epoch 31 - iter 129/437 - loss 0.12502162 - samples/sec: 57.82 - lr: 0.000004
2021-07-16 01:12:50,751 epoch 31 - iter 172/437 - loss 0.12766631 - samples/sec: 57.92 - lr: 0.000004
2021-07-16 01:13:14,530 epoch 31 - iter 215/437 - loss 0.12633107 - samples/sec: 57.87 - lr: 0.000004
2021-07-16 01:13:38,329 epoch 31 - iter 258/437 - loss 0.12599817 - samples/sec: 57.82 - lr: 0.000004
2021-07-16 01:14:02,016 epoch 31 - iter 301/437 - loss 0.12573441 - samples/sec: 58.09 - lr: 0.000004
2021-07-16 01:14:25,691 epoch 31 - iter 344/437 - loss 0.12561450 - samples/sec: 58.13 - lr: 0.000004
2021-07-16 01:14:49,315 epoch 31 - iter 387/437 - loss 0.12602467 - samples/sec: 58.25 - lr: 0.000004
2021-07-16 01:15:12,998 epoch 31 - iter 430/437 - loss 0.12561077 - samples/sec: 58.11 - lr: 0.000004
2021-07-16 01:15:16,856 ----------------------------------------------------------------------------------------------------
2021-07-16 01:15:16,856 EPOCH 31 done: loss 0.1251 - lr 0.0000038
2021-07-16 01:15:30,026 DEV : loss 0.7953630089759827 - score 0.9471
Epoch    31: reducing learning rate of group 0 to 1.8750e-06.
2021-07-16 01:15:30,207 BAD EPOCHS (no improvement): 4
2021-07-16 01:15:30,208 ----------------------------------------------------------------------------------------------------
2021-07-16 01:15:30,208 ----------------------------------------------------------------------------------------------------
2021-07-16 01:15:30,208 learning rate too small - quitting training!
2021-07-16 01:15:30,208 ----------------------------------------------------------------------------------------------------
2021-07-16 01:15:30,937 ----------------------------------------------------------------------------------------------------
2021-07-16 01:15:30,938 Testing using best model ...
2021-07-16 01:15:30,938 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/tur.pdtb.tdb/best-model.pt
2021-07-16 01:16:53,035 0.9766	0.9695	0.9730
2021-07-16 01:16:53,035 
Results:
- F1-score (micro) 0.9730
- F1-score (macro) 0.9730

By class:
SENT       tp: 7216 - fp: 173 - fn: 227 - precision: 0.9766 - recall: 0.9695 - f1-score: 0.9730
2021-07-16 01:16:53,035 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.sdrt.stac/
2021-07-16 01:16:53,068 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.sdrt.stac
2021-07-16 01:16:53,070 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.sdrt.stac/sent_train.txt
2021-07-16 01:16:53,072 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.sdrt.stac/sent_dev.txt
2021-07-16 01:16:53,074 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.sdrt.stac/sent_test.txt
Corpus: 1546 train + 228 dev + 426 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-16 01:17:00,033 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:00,035 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-16 01:17:00,035 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:00,035 Corpus: "Corpus: 1546 train + 228 dev + 426 test sentences"
2021-07-16 01:17:00,035 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:00,035 Parameters:
2021-07-16 01:17:00,035  - learning_rate: "3e-05"
2021-07-16 01:17:00,035  - mini_batch_size: "32"
2021-07-16 01:17:00,035  - patience: "3"
2021-07-16 01:17:00,035  - anneal_factor: "0.5"
2021-07-16 01:17:00,035  - max_epochs: "40"
2021-07-16 01:17:00,035  - shuffle: "True"
2021-07-16 01:17:00,035  - train_with_dev: "False"
2021-07-16 01:17:00,035  - batch_growth_annealing: "False"
2021-07-16 01:17:00,035 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:00,035 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.sdrt.stac"
2021-07-16 01:17:00,035 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:00,035 Device: cuda:0
2021-07-16 01:17:00,035 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:00,035 Embeddings storage mode: cpu
2021-07-16 01:17:00,038 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:04,086 epoch 1 - iter 4/49 - loss 20.27929974 - samples/sec: 31.62 - lr: 0.000030
2021-07-16 01:17:08,175 epoch 1 - iter 8/49 - loss 17.77514994 - samples/sec: 31.31 - lr: 0.000030
2021-07-16 01:17:12,244 epoch 1 - iter 12/49 - loss 16.15126721 - samples/sec: 31.46 - lr: 0.000030
2021-07-16 01:17:16,319 epoch 1 - iter 16/49 - loss 14.89611501 - samples/sec: 31.42 - lr: 0.000030
2021-07-16 01:17:20,396 epoch 1 - iter 20/49 - loss 13.95692973 - samples/sec: 31.40 - lr: 0.000030
2021-07-16 01:17:24,501 epoch 1 - iter 24/49 - loss 13.22533039 - samples/sec: 31.18 - lr: 0.000030
2021-07-16 01:17:28,585 epoch 1 - iter 28/49 - loss 12.62881572 - samples/sec: 31.35 - lr: 0.000030
2021-07-16 01:17:32,682 epoch 1 - iter 32/49 - loss 12.08733079 - samples/sec: 31.25 - lr: 0.000030
2021-07-16 01:17:36,725 epoch 1 - iter 36/49 - loss 11.60482159 - samples/sec: 31.66 - lr: 0.000030
2021-07-16 01:17:41,001 epoch 1 - iter 40/49 - loss 11.19441339 - samples/sec: 29.93 - lr: 0.000030
2021-07-16 01:17:45,075 epoch 1 - iter 44/49 - loss 10.81473552 - samples/sec: 31.43 - lr: 0.000030
2021-07-16 01:17:49,140 epoch 1 - iter 48/49 - loss 10.50024188 - samples/sec: 31.49 - lr: 0.000030
2021-07-16 01:17:49,500 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:49,500 EPOCH 1 done: loss 10.4168 - lr 0.0000300
2021-07-16 01:17:53,577 DEV : loss 6.289424896240234 - score 0.6961
2021-07-16 01:17:53,594 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:17:54,336 ----------------------------------------------------------------------------------------------------
2021-07-16 01:17:56,377 epoch 2 - iter 4/49 - loss 6.60360551 - samples/sec: 62.75 - lr: 0.000030
2021-07-16 01:17:58,420 epoch 2 - iter 8/49 - loss 6.53308970 - samples/sec: 62.67 - lr: 0.000030
2021-07-16 01:18:00,480 epoch 2 - iter 12/49 - loss 6.47380149 - samples/sec: 62.14 - lr: 0.000030
2021-07-16 01:18:02,525 epoch 2 - iter 16/49 - loss 6.43640172 - samples/sec: 62.62 - lr: 0.000030
2021-07-16 01:18:04,580 epoch 2 - iter 20/49 - loss 6.36839650 - samples/sec: 62.28 - lr: 0.000030
2021-07-16 01:18:06,664 epoch 2 - iter 24/49 - loss 6.28749160 - samples/sec: 61.46 - lr: 0.000030
2021-07-16 01:18:08,754 epoch 2 - iter 28/49 - loss 6.28536384 - samples/sec: 61.27 - lr: 0.000030
2021-07-16 01:18:10,826 epoch 2 - iter 32/49 - loss 6.24455778 - samples/sec: 61.78 - lr: 0.000030
2021-07-16 01:18:12,890 epoch 2 - iter 36/49 - loss 6.20368477 - samples/sec: 62.03 - lr: 0.000030
2021-07-16 01:18:14,972 epoch 2 - iter 40/49 - loss 6.19081597 - samples/sec: 61.50 - lr: 0.000030
2021-07-16 01:18:17,059 epoch 2 - iter 44/49 - loss 6.13791525 - samples/sec: 61.36 - lr: 0.000030
2021-07-16 01:18:19,127 epoch 2 - iter 48/49 - loss 6.10020638 - samples/sec: 61.89 - lr: 0.000030
2021-07-16 01:18:19,337 ----------------------------------------------------------------------------------------------------
2021-07-16 01:18:19,337 EPOCH 2 done: loss 6.0888 - lr 0.0000300
2021-07-16 01:18:20,587 DEV : loss 5.082155704498291 - score 0.7516
2021-07-16 01:18:20,604 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:18:24,623 ----------------------------------------------------------------------------------------------------
2021-07-16 01:18:26,705 epoch 3 - iter 4/49 - loss 5.46133232 - samples/sec: 61.53 - lr: 0.000030
2021-07-16 01:18:28,781 epoch 3 - iter 8/49 - loss 5.58884615 - samples/sec: 61.66 - lr: 0.000030
2021-07-16 01:18:30,860 epoch 3 - iter 12/49 - loss 5.58888984 - samples/sec: 61.59 - lr: 0.000030
2021-07-16 01:18:32,924 epoch 3 - iter 16/49 - loss 5.74997628 - samples/sec: 62.02 - lr: 0.000030
2021-07-16 01:18:34,976 epoch 3 - iter 20/49 - loss 5.71862922 - samples/sec: 62.39 - lr: 0.000030
2021-07-16 01:18:37,031 epoch 3 - iter 24/49 - loss 5.67666974 - samples/sec: 62.32 - lr: 0.000030
2021-07-16 01:18:39,090 epoch 3 - iter 28/49 - loss 5.65790798 - samples/sec: 62.20 - lr: 0.000030
2021-07-16 01:18:41,145 epoch 3 - iter 32/49 - loss 5.66965126 - samples/sec: 62.30 - lr: 0.000030
2021-07-16 01:18:43,182 epoch 3 - iter 36/49 - loss 5.60457587 - samples/sec: 62.84 - lr: 0.000030
2021-07-16 01:18:45,236 epoch 3 - iter 40/49 - loss 5.58385490 - samples/sec: 62.34 - lr: 0.000030
2021-07-16 01:18:47,301 epoch 3 - iter 44/49 - loss 5.56186286 - samples/sec: 62.02 - lr: 0.000030
2021-07-16 01:18:49,353 epoch 3 - iter 48/49 - loss 5.53853454 - samples/sec: 62.39 - lr: 0.000030
2021-07-16 01:18:49,561 ----------------------------------------------------------------------------------------------------
2021-07-16 01:18:49,561 EPOCH 3 done: loss 5.5222 - lr 0.0000300
2021-07-16 01:18:50,802 DEV : loss 4.63674259185791 - score 0.7821
2021-07-16 01:18:50,820 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:18:54,594 ----------------------------------------------------------------------------------------------------
2021-07-16 01:18:56,657 epoch 4 - iter 4/49 - loss 5.58178842 - samples/sec: 62.06 - lr: 0.000030
2021-07-16 01:18:58,683 epoch 4 - iter 8/49 - loss 5.42423224 - samples/sec: 63.20 - lr: 0.000030
2021-07-16 01:19:00,744 epoch 4 - iter 12/49 - loss 5.42920097 - samples/sec: 62.13 - lr: 0.000030
2021-07-16 01:19:02,816 epoch 4 - iter 16/49 - loss 5.41253838 - samples/sec: 61.80 - lr: 0.000030
2021-07-16 01:19:04,866 epoch 4 - iter 20/49 - loss 5.41418145 - samples/sec: 62.46 - lr: 0.000030
2021-07-16 01:19:06,919 epoch 4 - iter 24/49 - loss 5.40266409 - samples/sec: 62.38 - lr: 0.000030
2021-07-16 01:19:08,982 epoch 4 - iter 28/49 - loss 5.35859151 - samples/sec: 62.05 - lr: 0.000030
2021-07-16 01:19:11,029 epoch 4 - iter 32/49 - loss 5.33000645 - samples/sec: 62.54 - lr: 0.000030
2021-07-16 01:19:13,089 epoch 4 - iter 36/49 - loss 5.34370385 - samples/sec: 62.15 - lr: 0.000030
2021-07-16 01:19:15,133 epoch 4 - iter 40/49 - loss 5.32519890 - samples/sec: 62.64 - lr: 0.000030
2021-07-16 01:19:17,187 epoch 4 - iter 44/49 - loss 5.31141324 - samples/sec: 62.35 - lr: 0.000030
2021-07-16 01:19:19,236 epoch 4 - iter 48/49 - loss 5.26816756 - samples/sec: 62.49 - lr: 0.000030
2021-07-16 01:19:19,446 ----------------------------------------------------------------------------------------------------
2021-07-16 01:19:19,446 EPOCH 4 done: loss 5.2601 - lr 0.0000300
2021-07-16 01:19:20,868 DEV : loss 4.419760227203369 - score 0.7937
2021-07-16 01:19:20,886 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:19:24,621 ----------------------------------------------------------------------------------------------------
2021-07-16 01:19:26,683 epoch 5 - iter 4/49 - loss 5.39938462 - samples/sec: 62.11 - lr: 0.000030
2021-07-16 01:19:28,751 epoch 5 - iter 8/49 - loss 5.06430781 - samples/sec: 61.93 - lr: 0.000030
2021-07-16 01:19:30,801 epoch 5 - iter 12/49 - loss 4.98924573 - samples/sec: 62.43 - lr: 0.000030
2021-07-16 01:19:32,858 epoch 5 - iter 16/49 - loss 5.04190820 - samples/sec: 62.24 - lr: 0.000030
2021-07-16 01:19:34,895 epoch 5 - iter 20/49 - loss 5.06669757 - samples/sec: 62.87 - lr: 0.000030
2021-07-16 01:19:36,957 epoch 5 - iter 24/49 - loss 5.06385303 - samples/sec: 62.09 - lr: 0.000030
2021-07-16 01:19:39,021 epoch 5 - iter 28/49 - loss 5.08084714 - samples/sec: 62.05 - lr: 0.000030
2021-07-16 01:19:41,076 epoch 5 - iter 32/49 - loss 5.03561017 - samples/sec: 62.30 - lr: 0.000030
2021-07-16 01:19:43,119 epoch 5 - iter 36/49 - loss 5.01686625 - samples/sec: 62.66 - lr: 0.000030
2021-07-16 01:19:45,184 epoch 5 - iter 40/49 - loss 5.02756133 - samples/sec: 62.01 - lr: 0.000030
2021-07-16 01:19:47,224 epoch 5 - iter 44/49 - loss 5.01347353 - samples/sec: 62.75 - lr: 0.000030
2021-07-16 01:19:49,282 epoch 5 - iter 48/49 - loss 5.01312622 - samples/sec: 62.21 - lr: 0.000030
2021-07-16 01:19:49,492 ----------------------------------------------------------------------------------------------------
2021-07-16 01:19:49,492 EPOCH 5 done: loss 5.0178 - lr 0.0000300
2021-07-16 01:19:50,735 DEV : loss 4.446070194244385 - score 0.8023
2021-07-16 01:19:50,753 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:19:54,451 ----------------------------------------------------------------------------------------------------
2021-07-16 01:19:56,528 epoch 6 - iter 4/49 - loss 4.73647594 - samples/sec: 61.66 - lr: 0.000030
2021-07-16 01:19:58,597 epoch 6 - iter 8/49 - loss 5.00342464 - samples/sec: 61.90 - lr: 0.000030
2021-07-16 01:20:00,672 epoch 6 - iter 12/49 - loss 4.97045100 - samples/sec: 61.70 - lr: 0.000030
2021-07-16 01:20:02,751 epoch 6 - iter 16/49 - loss 4.95987472 - samples/sec: 61.59 - lr: 0.000030
2021-07-16 01:20:04,828 epoch 6 - iter 20/49 - loss 5.00371609 - samples/sec: 61.62 - lr: 0.000030
2021-07-16 01:20:06,907 epoch 6 - iter 24/49 - loss 4.95179447 - samples/sec: 61.61 - lr: 0.000030
2021-07-16 01:20:08,971 epoch 6 - iter 28/49 - loss 4.91178204 - samples/sec: 62.02 - lr: 0.000030
2021-07-16 01:20:11,061 epoch 6 - iter 32/49 - loss 4.91101871 - samples/sec: 61.27 - lr: 0.000030
2021-07-16 01:20:13,152 epoch 6 - iter 36/49 - loss 4.91496656 - samples/sec: 61.23 - lr: 0.000030
2021-07-16 01:20:15,200 epoch 6 - iter 40/49 - loss 4.88693793 - samples/sec: 62.50 - lr: 0.000030
2021-07-16 01:20:17,283 epoch 6 - iter 44/49 - loss 4.90075038 - samples/sec: 61.48 - lr: 0.000030
2021-07-16 01:20:19,364 epoch 6 - iter 48/49 - loss 4.90809669 - samples/sec: 61.53 - lr: 0.000030
2021-07-16 01:20:19,574 ----------------------------------------------------------------------------------------------------
2021-07-16 01:20:19,574 EPOCH 6 done: loss 4.8945 - lr 0.0000300
2021-07-16 01:20:20,817 DEV : loss 4.114877700805664 - score 0.8072
2021-07-16 01:20:20,834 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:20:24,590 ----------------------------------------------------------------------------------------------------
2021-07-16 01:20:26,672 epoch 7 - iter 4/49 - loss 4.69129539 - samples/sec: 61.52 - lr: 0.000030
2021-07-16 01:20:28,743 epoch 7 - iter 8/49 - loss 4.78682923 - samples/sec: 61.82 - lr: 0.000030
2021-07-16 01:20:30,818 epoch 7 - iter 12/49 - loss 4.80255091 - samples/sec: 61.69 - lr: 0.000030
2021-07-16 01:20:32,900 epoch 7 - iter 16/49 - loss 4.82708684 - samples/sec: 61.52 - lr: 0.000030
2021-07-16 01:20:34,984 epoch 7 - iter 20/49 - loss 4.75420077 - samples/sec: 61.43 - lr: 0.000030
2021-07-16 01:20:37,068 epoch 7 - iter 24/49 - loss 4.74056943 - samples/sec: 61.43 - lr: 0.000030
2021-07-16 01:20:39,144 epoch 7 - iter 28/49 - loss 4.82642926 - samples/sec: 61.69 - lr: 0.000030
2021-07-16 01:20:41,193 epoch 7 - iter 32/49 - loss 4.84409401 - samples/sec: 62.48 - lr: 0.000030
2021-07-16 01:20:43,267 epoch 7 - iter 36/49 - loss 4.82959424 - samples/sec: 61.73 - lr: 0.000030
2021-07-16 01:20:45,351 epoch 7 - iter 40/49 - loss 4.78346519 - samples/sec: 61.43 - lr: 0.000030
2021-07-16 01:20:47,417 epoch 7 - iter 44/49 - loss 4.78696126 - samples/sec: 61.99 - lr: 0.000030
2021-07-16 01:20:49,504 epoch 7 - iter 48/49 - loss 4.78212409 - samples/sec: 61.34 - lr: 0.000030
2021-07-16 01:20:49,714 ----------------------------------------------------------------------------------------------------
2021-07-16 01:20:49,715 EPOCH 7 done: loss 4.7864 - lr 0.0000300
2021-07-16 01:20:50,955 DEV : loss 4.10544490814209 - score 0.8148
2021-07-16 01:20:50,972 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:20:54,652 ----------------------------------------------------------------------------------------------------
2021-07-16 01:20:56,717 epoch 8 - iter 4/49 - loss 4.92018974 - samples/sec: 62.01 - lr: 0.000030
2021-07-16 01:20:58,778 epoch 8 - iter 8/49 - loss 4.80012143 - samples/sec: 62.11 - lr: 0.000030
2021-07-16 01:21:00,868 epoch 8 - iter 12/49 - loss 4.64088817 - samples/sec: 61.27 - lr: 0.000030
2021-07-16 01:21:02,948 epoch 8 - iter 16/49 - loss 4.60560524 - samples/sec: 61.57 - lr: 0.000030
2021-07-16 01:21:05,016 epoch 8 - iter 20/49 - loss 4.59316442 - samples/sec: 61.91 - lr: 0.000030
2021-07-16 01:21:07,104 epoch 8 - iter 24/49 - loss 4.63216712 - samples/sec: 61.33 - lr: 0.000030
2021-07-16 01:21:09,177 epoch 8 - iter 28/49 - loss 4.67966831 - samples/sec: 61.76 - lr: 0.000030
2021-07-16 01:21:11,263 epoch 8 - iter 32/49 - loss 4.67745326 - samples/sec: 61.36 - lr: 0.000030
2021-07-16 01:21:13,347 epoch 8 - iter 36/49 - loss 4.67156457 - samples/sec: 61.46 - lr: 0.000030
2021-07-16 01:21:15,421 epoch 8 - iter 40/49 - loss 4.64507390 - samples/sec: 61.73 - lr: 0.000030
2021-07-16 01:21:17,496 epoch 8 - iter 44/49 - loss 4.66526029 - samples/sec: 61.70 - lr: 0.000030
2021-07-16 01:21:19,566 epoch 8 - iter 48/49 - loss 4.68657195 - samples/sec: 61.85 - lr: 0.000030
2021-07-16 01:21:19,775 ----------------------------------------------------------------------------------------------------
2021-07-16 01:21:19,776 EPOCH 8 done: loss 4.6979 - lr 0.0000300
2021-07-16 01:21:21,016 DEV : loss 4.053144454956055 - score 0.8186
2021-07-16 01:21:21,033 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:21:24,698 ----------------------------------------------------------------------------------------------------
2021-07-16 01:21:26,775 epoch 9 - iter 4/49 - loss 4.67949653 - samples/sec: 61.66 - lr: 0.000030
2021-07-16 01:21:28,848 epoch 9 - iter 8/49 - loss 4.64307749 - samples/sec: 61.75 - lr: 0.000030
2021-07-16 01:21:30,907 epoch 9 - iter 12/49 - loss 4.56474078 - samples/sec: 62.18 - lr: 0.000030
2021-07-16 01:21:33,003 epoch 9 - iter 16/49 - loss 4.55919772 - samples/sec: 61.09 - lr: 0.000030
2021-07-16 01:21:35,068 epoch 9 - iter 20/49 - loss 4.59730074 - samples/sec: 62.00 - lr: 0.000030
2021-07-16 01:21:37,151 epoch 9 - iter 24/49 - loss 4.63706309 - samples/sec: 61.47 - lr: 0.000030
2021-07-16 01:21:39,394 epoch 9 - iter 28/49 - loss 4.66179935 - samples/sec: 57.10 - lr: 0.000030
2021-07-16 01:21:41,471 epoch 9 - iter 32/49 - loss 4.64383557 - samples/sec: 61.63 - lr: 0.000030
2021-07-16 01:21:43,547 epoch 9 - iter 36/49 - loss 4.60464415 - samples/sec: 61.68 - lr: 0.000030
2021-07-16 01:21:45,628 epoch 9 - iter 40/49 - loss 4.59134648 - samples/sec: 61.52 - lr: 0.000030
2021-07-16 01:21:47,707 epoch 9 - iter 44/49 - loss 4.60154681 - samples/sec: 61.61 - lr: 0.000030
2021-07-16 01:21:49,767 epoch 9 - iter 48/49 - loss 4.60038876 - samples/sec: 62.15 - lr: 0.000030
2021-07-16 01:21:49,974 ----------------------------------------------------------------------------------------------------
2021-07-16 01:21:49,975 EPOCH 9 done: loss 4.6023 - lr 0.0000300
2021-07-16 01:21:51,216 DEV : loss 3.991147518157959 - score 0.8201
2021-07-16 01:21:51,234 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:21:54,898 ----------------------------------------------------------------------------------------------------
2021-07-16 01:21:56,965 epoch 10 - iter 4/49 - loss 4.38369501 - samples/sec: 61.95 - lr: 0.000030
2021-07-16 01:21:59,052 epoch 10 - iter 8/49 - loss 4.36737284 - samples/sec: 61.36 - lr: 0.000030
2021-07-16 01:22:01,120 epoch 10 - iter 12/49 - loss 4.44576758 - samples/sec: 61.93 - lr: 0.000030
2021-07-16 01:22:03,176 epoch 10 - iter 16/49 - loss 4.51026513 - samples/sec: 62.27 - lr: 0.000030
2021-07-16 01:22:05,219 epoch 10 - iter 20/49 - loss 4.56571587 - samples/sec: 62.68 - lr: 0.000030
2021-07-16 01:22:07,292 epoch 10 - iter 24/49 - loss 4.55297211 - samples/sec: 61.75 - lr: 0.000030
2021-07-16 01:22:09,366 epoch 10 - iter 28/49 - loss 4.46672294 - samples/sec: 61.74 - lr: 0.000030
2021-07-16 01:22:11,432 epoch 10 - iter 32/49 - loss 4.48521205 - samples/sec: 61.97 - lr: 0.000030
2021-07-16 01:22:13,488 epoch 10 - iter 36/49 - loss 4.46294841 - samples/sec: 62.28 - lr: 0.000030
2021-07-16 01:22:15,556 epoch 10 - iter 40/49 - loss 4.45239608 - samples/sec: 61.90 - lr: 0.000030
2021-07-16 01:22:17,625 epoch 10 - iter 44/49 - loss 4.47975869 - samples/sec: 61.91 - lr: 0.000030
2021-07-16 01:22:19,690 epoch 10 - iter 48/49 - loss 4.51201076 - samples/sec: 61.99 - lr: 0.000030
2021-07-16 01:22:19,899 ----------------------------------------------------------------------------------------------------
2021-07-16 01:22:19,899 EPOCH 10 done: loss 4.5185 - lr 0.0000300
2021-07-16 01:22:21,141 DEV : loss 3.907500743865967 - score 0.8238
2021-07-16 01:22:21,158 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:22:24,905 ----------------------------------------------------------------------------------------------------
2021-07-16 01:22:26,968 epoch 11 - iter 4/49 - loss 4.44335896 - samples/sec: 62.09 - lr: 0.000030
2021-07-16 01:22:29,051 epoch 11 - iter 8/49 - loss 4.52402791 - samples/sec: 61.46 - lr: 0.000030
2021-07-16 01:22:31,124 epoch 11 - iter 12/49 - loss 4.41366182 - samples/sec: 61.77 - lr: 0.000030
2021-07-16 01:22:33,196 epoch 11 - iter 16/49 - loss 4.47061753 - samples/sec: 61.80 - lr: 0.000030
2021-07-16 01:22:35,269 epoch 11 - iter 20/49 - loss 4.41486541 - samples/sec: 61.77 - lr: 0.000030
2021-07-16 01:22:37,308 epoch 11 - iter 24/49 - loss 4.41465430 - samples/sec: 62.79 - lr: 0.000030
2021-07-16 01:22:39,376 epoch 11 - iter 28/49 - loss 4.45012802 - samples/sec: 61.92 - lr: 0.000030
2021-07-16 01:22:41,436 epoch 11 - iter 32/49 - loss 4.45734366 - samples/sec: 62.16 - lr: 0.000030
2021-07-16 01:22:43,499 epoch 11 - iter 36/49 - loss 4.45535240 - samples/sec: 62.05 - lr: 0.000030
2021-07-16 01:22:45,559 epoch 11 - iter 40/49 - loss 4.44787512 - samples/sec: 62.16 - lr: 0.000030
2021-07-16 01:22:47,624 epoch 11 - iter 44/49 - loss 4.42691308 - samples/sec: 62.02 - lr: 0.000030
2021-07-16 01:22:49,677 epoch 11 - iter 48/49 - loss 4.42205824 - samples/sec: 62.35 - lr: 0.000030
2021-07-16 01:22:49,886 ----------------------------------------------------------------------------------------------------
2021-07-16 01:22:49,886 EPOCH 11 done: loss 4.4286 - lr 0.0000300
2021-07-16 01:22:51,124 DEV : loss 3.830369472503662 - score 0.8183
2021-07-16 01:22:51,142 BAD EPOCHS (no improvement): 1
2021-07-16 01:22:51,142 ----------------------------------------------------------------------------------------------------
2021-07-16 01:22:53,200 epoch 12 - iter 4/49 - loss 4.15922761 - samples/sec: 62.24 - lr: 0.000030
2021-07-16 01:22:55,251 epoch 12 - iter 8/49 - loss 4.23045677 - samples/sec: 62.42 - lr: 0.000030
2021-07-16 01:22:57,336 epoch 12 - iter 12/49 - loss 4.21304011 - samples/sec: 61.41 - lr: 0.000030
2021-07-16 01:22:59,424 epoch 12 - iter 16/49 - loss 4.19733603 - samples/sec: 61.32 - lr: 0.000030
2021-07-16 01:23:01,484 epoch 12 - iter 20/49 - loss 4.23894521 - samples/sec: 62.16 - lr: 0.000030
2021-07-16 01:23:03,548 epoch 12 - iter 24/49 - loss 4.23016911 - samples/sec: 62.04 - lr: 0.000030
2021-07-16 01:23:05,620 epoch 12 - iter 28/49 - loss 4.23888241 - samples/sec: 61.79 - lr: 0.000030
2021-07-16 01:23:07,691 epoch 12 - iter 32/49 - loss 4.25976116 - samples/sec: 61.82 - lr: 0.000030
2021-07-16 01:23:09,756 epoch 12 - iter 36/49 - loss 4.28882459 - samples/sec: 62.00 - lr: 0.000030
2021-07-16 01:23:11,804 epoch 12 - iter 40/49 - loss 4.27120735 - samples/sec: 62.51 - lr: 0.000030
2021-07-16 01:23:13,862 epoch 12 - iter 44/49 - loss 4.27120363 - samples/sec: 62.21 - lr: 0.000030
2021-07-16 01:23:15,938 epoch 12 - iter 48/49 - loss 4.29352377 - samples/sec: 61.67 - lr: 0.000030
2021-07-16 01:23:16,146 ----------------------------------------------------------------------------------------------------
2021-07-16 01:23:16,146 EPOCH 12 done: loss 4.3359 - lr 0.0000300
2021-07-16 01:23:17,387 DEV : loss 3.8411498069763184 - score 0.8312
2021-07-16 01:23:17,405 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:23:21,176 ----------------------------------------------------------------------------------------------------
2021-07-16 01:23:23,247 epoch 13 - iter 4/49 - loss 3.93696398 - samples/sec: 61.84 - lr: 0.000030
2021-07-16 01:23:25,327 epoch 13 - iter 8/49 - loss 4.00208533 - samples/sec: 61.55 - lr: 0.000030
2021-07-16 01:23:27,400 epoch 13 - iter 12/49 - loss 4.19645015 - samples/sec: 61.77 - lr: 0.000030
2021-07-16 01:23:29,468 epoch 13 - iter 16/49 - loss 4.14789481 - samples/sec: 61.92 - lr: 0.000030
2021-07-16 01:23:31,526 epoch 13 - iter 20/49 - loss 4.21382455 - samples/sec: 62.21 - lr: 0.000030
2021-07-16 01:23:33,584 epoch 13 - iter 24/49 - loss 4.26711555 - samples/sec: 62.22 - lr: 0.000030
2021-07-16 01:23:35,646 epoch 13 - iter 28/49 - loss 4.29211434 - samples/sec: 62.08 - lr: 0.000030
2021-07-16 01:23:37,705 epoch 13 - iter 32/49 - loss 4.29110298 - samples/sec: 62.21 - lr: 0.000030
2021-07-16 01:23:39,773 epoch 13 - iter 36/49 - loss 4.30301948 - samples/sec: 61.91 - lr: 0.000030
2021-07-16 01:23:41,853 epoch 13 - iter 40/49 - loss 4.27826716 - samples/sec: 61.56 - lr: 0.000030
2021-07-16 01:23:43,940 epoch 13 - iter 44/49 - loss 4.25773391 - samples/sec: 61.33 - lr: 0.000030
2021-07-16 01:23:46,014 epoch 13 - iter 48/49 - loss 4.24404461 - samples/sec: 61.74 - lr: 0.000030
2021-07-16 01:23:46,222 ----------------------------------------------------------------------------------------------------
2021-07-16 01:23:46,222 EPOCH 13 done: loss 4.2319 - lr 0.0000300
2021-07-16 01:23:47,465 DEV : loss 3.8590095043182373 - score 0.8354
2021-07-16 01:23:47,483 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:23:51,184 ----------------------------------------------------------------------------------------------------
2021-07-16 01:23:53,426 epoch 14 - iter 4/49 - loss 4.32770717 - samples/sec: 57.10 - lr: 0.000030
2021-07-16 01:23:55,512 epoch 14 - iter 8/49 - loss 4.11094067 - samples/sec: 61.39 - lr: 0.000030
2021-07-16 01:23:57,624 epoch 14 - iter 12/49 - loss 4.07259607 - samples/sec: 60.64 - lr: 0.000030
2021-07-16 01:23:59,704 epoch 14 - iter 16/49 - loss 4.13829526 - samples/sec: 61.54 - lr: 0.000030
2021-07-16 01:24:01,776 epoch 14 - iter 20/49 - loss 4.18046201 - samples/sec: 61.78 - lr: 0.000030
2021-07-16 01:24:03,869 epoch 14 - iter 24/49 - loss 4.21383952 - samples/sec: 61.18 - lr: 0.000030
2021-07-16 01:24:05,963 epoch 14 - iter 28/49 - loss 4.18924809 - samples/sec: 61.14 - lr: 0.000030
2021-07-16 01:24:08,037 epoch 14 - iter 32/49 - loss 4.21684782 - samples/sec: 61.75 - lr: 0.000030
2021-07-16 01:24:10,103 epoch 14 - iter 36/49 - loss 4.20447916 - samples/sec: 61.96 - lr: 0.000030
2021-07-16 01:24:12,173 epoch 14 - iter 40/49 - loss 4.20857866 - samples/sec: 61.87 - lr: 0.000030
2021-07-16 01:24:14,215 epoch 14 - iter 44/49 - loss 4.20023869 - samples/sec: 62.69 - lr: 0.000030
2021-07-16 01:24:16,297 epoch 14 - iter 48/49 - loss 4.19215764 - samples/sec: 61.51 - lr: 0.000030
2021-07-16 01:24:16,506 ----------------------------------------------------------------------------------------------------
2021-07-16 01:24:16,506 EPOCH 14 done: loss 4.2117 - lr 0.0000300
2021-07-16 01:24:17,747 DEV : loss 3.8107237815856934 - score 0.8351
2021-07-16 01:24:17,764 BAD EPOCHS (no improvement): 1
2021-07-16 01:24:17,765 ----------------------------------------------------------------------------------------------------
2021-07-16 01:24:19,820 epoch 15 - iter 4/49 - loss 4.09357285 - samples/sec: 62.31 - lr: 0.000030
2021-07-16 01:24:21,888 epoch 15 - iter 8/49 - loss 4.15061226 - samples/sec: 61.89 - lr: 0.000030
2021-07-16 01:24:23,960 epoch 15 - iter 12/49 - loss 4.11961029 - samples/sec: 61.81 - lr: 0.000030
2021-07-16 01:24:26,023 epoch 15 - iter 16/49 - loss 4.12876509 - samples/sec: 62.06 - lr: 0.000030
2021-07-16 01:24:28,105 epoch 15 - iter 20/49 - loss 4.10689871 - samples/sec: 61.50 - lr: 0.000030
2021-07-16 01:24:30,196 epoch 15 - iter 24/49 - loss 4.11257698 - samples/sec: 61.23 - lr: 0.000030
2021-07-16 01:24:32,281 epoch 15 - iter 28/49 - loss 4.12966497 - samples/sec: 61.42 - lr: 0.000030
2021-07-16 01:24:34,344 epoch 15 - iter 32/49 - loss 4.12999495 - samples/sec: 62.07 - lr: 0.000030
2021-07-16 01:24:36,419 epoch 15 - iter 36/49 - loss 4.08389617 - samples/sec: 61.69 - lr: 0.000030
2021-07-16 01:24:38,478 epoch 15 - iter 40/49 - loss 4.09652500 - samples/sec: 62.18 - lr: 0.000030
2021-07-16 01:24:40,560 epoch 15 - iter 44/49 - loss 4.10510737 - samples/sec: 61.50 - lr: 0.000030
2021-07-16 01:24:42,644 epoch 15 - iter 48/49 - loss 4.13943932 - samples/sec: 61.46 - lr: 0.000030
2021-07-16 01:24:42,854 ----------------------------------------------------------------------------------------------------
2021-07-16 01:24:42,855 EPOCH 15 done: loss 4.1682 - lr 0.0000300
2021-07-16 01:24:44,097 DEV : loss 3.8045201301574707 - score 0.8307
2021-07-16 01:24:44,115 BAD EPOCHS (no improvement): 2
2021-07-16 01:24:44,115 ----------------------------------------------------------------------------------------------------
2021-07-16 01:24:46,190 epoch 16 - iter 4/49 - loss 3.92394817 - samples/sec: 61.70 - lr: 0.000030
2021-07-16 01:24:48,280 epoch 16 - iter 8/49 - loss 4.17335606 - samples/sec: 61.29 - lr: 0.000030
2021-07-16 01:24:50,329 epoch 16 - iter 12/49 - loss 4.13114554 - samples/sec: 62.47 - lr: 0.000030
2021-07-16 01:24:52,400 epoch 16 - iter 16/49 - loss 4.09460774 - samples/sec: 61.84 - lr: 0.000030
2021-07-16 01:24:54,476 epoch 16 - iter 20/49 - loss 4.09016268 - samples/sec: 61.67 - lr: 0.000030
2021-07-16 01:24:56,553 epoch 16 - iter 24/49 - loss 4.02501369 - samples/sec: 61.65 - lr: 0.000030
2021-07-16 01:24:58,626 epoch 16 - iter 28/49 - loss 3.99293338 - samples/sec: 61.74 - lr: 0.000030
2021-07-16 01:25:00,695 epoch 16 - iter 32/49 - loss 4.01174141 - samples/sec: 61.90 - lr: 0.000030
2021-07-16 01:25:02,777 epoch 16 - iter 36/49 - loss 4.01911690 - samples/sec: 61.48 - lr: 0.000030
2021-07-16 01:25:04,871 epoch 16 - iter 40/49 - loss 4.01587976 - samples/sec: 61.16 - lr: 0.000030
2021-07-16 01:25:06,943 epoch 16 - iter 44/49 - loss 4.05950464 - samples/sec: 61.80 - lr: 0.000030
2021-07-16 01:25:09,034 epoch 16 - iter 48/49 - loss 4.08950485 - samples/sec: 61.22 - lr: 0.000030
2021-07-16 01:25:09,240 ----------------------------------------------------------------------------------------------------
2021-07-16 01:25:09,241 EPOCH 16 done: loss 4.0913 - lr 0.0000300
2021-07-16 01:25:10,480 DEV : loss 3.6944854259490967 - score 0.8323
2021-07-16 01:25:10,498 BAD EPOCHS (no improvement): 3
2021-07-16 01:25:10,498 ----------------------------------------------------------------------------------------------------
2021-07-16 01:25:12,558 epoch 17 - iter 4/49 - loss 4.00565249 - samples/sec: 62.16 - lr: 0.000030
2021-07-16 01:25:14,632 epoch 17 - iter 8/49 - loss 4.12422103 - samples/sec: 61.74 - lr: 0.000030
2021-07-16 01:25:16,708 epoch 17 - iter 12/49 - loss 4.03550647 - samples/sec: 61.67 - lr: 0.000030
2021-07-16 01:25:18,772 epoch 17 - iter 16/49 - loss 4.06312193 - samples/sec: 62.04 - lr: 0.000030
2021-07-16 01:25:20,844 epoch 17 - iter 20/49 - loss 4.06619955 - samples/sec: 61.79 - lr: 0.000030
2021-07-16 01:25:22,924 epoch 17 - iter 24/49 - loss 4.02422799 - samples/sec: 61.56 - lr: 0.000030
2021-07-16 01:25:24,995 epoch 17 - iter 28/49 - loss 4.00388097 - samples/sec: 61.82 - lr: 0.000030
2021-07-16 01:25:27,079 epoch 17 - iter 32/49 - loss 4.00543864 - samples/sec: 61.43 - lr: 0.000030
2021-07-16 01:25:29,151 epoch 17 - iter 36/49 - loss 4.00341449 - samples/sec: 61.80 - lr: 0.000030
2021-07-16 01:25:31,223 epoch 17 - iter 40/49 - loss 4.00574394 - samples/sec: 61.82 - lr: 0.000030
2021-07-16 01:25:33,306 epoch 17 - iter 44/49 - loss 3.98669625 - samples/sec: 61.44 - lr: 0.000030
2021-07-16 01:25:35,378 epoch 17 - iter 48/49 - loss 4.00865252 - samples/sec: 61.81 - lr: 0.000030
2021-07-16 01:25:35,588 ----------------------------------------------------------------------------------------------------
2021-07-16 01:25:35,589 EPOCH 17 done: loss 4.0091 - lr 0.0000300
2021-07-16 01:25:36,828 DEV : loss 3.718153715133667 - score 0.8315
Epoch    17: reducing learning rate of group 0 to 1.5000e-05.
2021-07-16 01:25:36,846 BAD EPOCHS (no improvement): 4
2021-07-16 01:25:36,846 ----------------------------------------------------------------------------------------------------
2021-07-16 01:25:38,914 epoch 18 - iter 4/49 - loss 3.93784457 - samples/sec: 61.91 - lr: 0.000015
2021-07-16 01:25:40,975 epoch 18 - iter 8/49 - loss 3.91591960 - samples/sec: 62.12 - lr: 0.000015
2021-07-16 01:25:43,056 epoch 18 - iter 12/49 - loss 3.84494948 - samples/sec: 61.54 - lr: 0.000015
2021-07-16 01:25:45,132 epoch 18 - iter 16/49 - loss 3.95346791 - samples/sec: 61.67 - lr: 0.000015
2021-07-16 01:25:47,222 epoch 18 - iter 20/49 - loss 3.93247048 - samples/sec: 61.26 - lr: 0.000015
2021-07-16 01:25:49,305 epoch 18 - iter 24/49 - loss 3.97497143 - samples/sec: 61.47 - lr: 0.000015
2021-07-16 01:25:51,375 epoch 18 - iter 28/49 - loss 4.02292735 - samples/sec: 61.86 - lr: 0.000015
2021-07-16 01:25:53,463 epoch 18 - iter 32/49 - loss 3.95855891 - samples/sec: 61.32 - lr: 0.000015
2021-07-16 01:25:55,535 epoch 18 - iter 36/49 - loss 3.95534029 - samples/sec: 61.78 - lr: 0.000015
2021-07-16 01:25:57,599 epoch 18 - iter 40/49 - loss 3.96889925 - samples/sec: 62.05 - lr: 0.000015
2021-07-16 01:25:59,680 epoch 18 - iter 44/49 - loss 3.97781461 - samples/sec: 61.50 - lr: 0.000015
2021-07-16 01:26:01,755 epoch 18 - iter 48/49 - loss 3.98838776 - samples/sec: 61.72 - lr: 0.000015
2021-07-16 01:26:01,962 ----------------------------------------------------------------------------------------------------
2021-07-16 01:26:01,962 EPOCH 18 done: loss 4.0192 - lr 0.0000150
2021-07-16 01:26:03,377 DEV : loss 3.657712936401367 - score 0.8341
2021-07-16 01:26:03,394 BAD EPOCHS (no improvement): 1
2021-07-16 01:26:03,394 ----------------------------------------------------------------------------------------------------
2021-07-16 01:26:05,450 epoch 19 - iter 4/49 - loss 3.88931614 - samples/sec: 62.29 - lr: 0.000015
2021-07-16 01:26:07,527 epoch 19 - iter 8/49 - loss 3.90836254 - samples/sec: 61.63 - lr: 0.000015
2021-07-16 01:26:09,612 epoch 19 - iter 12/49 - loss 3.87041964 - samples/sec: 61.42 - lr: 0.000015
2021-07-16 01:26:11,684 epoch 19 - iter 16/49 - loss 3.93500401 - samples/sec: 61.78 - lr: 0.000015
2021-07-16 01:26:13,752 epoch 19 - iter 20/49 - loss 3.88694583 - samples/sec: 61.93 - lr: 0.000015
2021-07-16 01:26:15,835 epoch 19 - iter 24/49 - loss 3.86385302 - samples/sec: 61.45 - lr: 0.000015
2021-07-16 01:26:17,908 epoch 19 - iter 28/49 - loss 3.87143217 - samples/sec: 61.77 - lr: 0.000015
2021-07-16 01:26:19,999 epoch 19 - iter 32/49 - loss 3.92344706 - samples/sec: 61.24 - lr: 0.000015
2021-07-16 01:26:22,075 epoch 19 - iter 36/49 - loss 3.93557490 - samples/sec: 61.69 - lr: 0.000015
2021-07-16 01:26:24,153 epoch 19 - iter 40/49 - loss 3.94886184 - samples/sec: 61.60 - lr: 0.000015
2021-07-16 01:26:26,231 epoch 19 - iter 44/49 - loss 3.92411522 - samples/sec: 61.63 - lr: 0.000015
2021-07-16 01:26:28,317 epoch 19 - iter 48/49 - loss 3.94252396 - samples/sec: 61.36 - lr: 0.000015
2021-07-16 01:26:28,526 ----------------------------------------------------------------------------------------------------
2021-07-16 01:26:28,526 EPOCH 19 done: loss 3.9361 - lr 0.0000150
2021-07-16 01:26:29,766 DEV : loss 3.6563680171966553 - score 0.8308
2021-07-16 01:26:29,784 BAD EPOCHS (no improvement): 2
2021-07-16 01:26:29,784 ----------------------------------------------------------------------------------------------------
2021-07-16 01:26:31,843 epoch 20 - iter 4/49 - loss 3.85328335 - samples/sec: 62.20 - lr: 0.000015
2021-07-16 01:26:33,915 epoch 20 - iter 8/49 - loss 3.89232463 - samples/sec: 61.79 - lr: 0.000015
2021-07-16 01:26:35,981 epoch 20 - iter 12/49 - loss 3.81409434 - samples/sec: 61.98 - lr: 0.000015
2021-07-16 01:26:38,062 epoch 20 - iter 16/49 - loss 3.87152083 - samples/sec: 61.51 - lr: 0.000015
2021-07-16 01:26:40,132 epoch 20 - iter 20/49 - loss 3.92149153 - samples/sec: 61.87 - lr: 0.000015
2021-07-16 01:26:42,203 epoch 20 - iter 24/49 - loss 3.94856393 - samples/sec: 61.80 - lr: 0.000015
2021-07-16 01:26:44,292 epoch 20 - iter 28/49 - loss 3.90154185 - samples/sec: 61.32 - lr: 0.000015
2021-07-16 01:26:46,363 epoch 20 - iter 32/49 - loss 3.92781565 - samples/sec: 61.80 - lr: 0.000015
2021-07-16 01:26:48,444 epoch 20 - iter 36/49 - loss 3.94301367 - samples/sec: 61.54 - lr: 0.000015
2021-07-16 01:26:50,527 epoch 20 - iter 40/49 - loss 3.92076609 - samples/sec: 61.47 - lr: 0.000015
2021-07-16 01:26:52,609 epoch 20 - iter 44/49 - loss 3.90325440 - samples/sec: 61.51 - lr: 0.000015
2021-07-16 01:26:54,659 epoch 20 - iter 48/49 - loss 3.88538378 - samples/sec: 62.46 - lr: 0.000015
2021-07-16 01:26:54,865 ----------------------------------------------------------------------------------------------------
2021-07-16 01:26:54,865 EPOCH 20 done: loss 3.8753 - lr 0.0000150
2021-07-16 01:26:56,106 DEV : loss 3.6309099197387695 - score 0.8328
2021-07-16 01:26:56,124 BAD EPOCHS (no improvement): 3
2021-07-16 01:26:56,124 ----------------------------------------------------------------------------------------------------
2021-07-16 01:26:58,175 epoch 21 - iter 4/49 - loss 3.90391016 - samples/sec: 62.41 - lr: 0.000015
2021-07-16 01:27:00,240 epoch 21 - iter 8/49 - loss 3.92148778 - samples/sec: 62.03 - lr: 0.000015
2021-07-16 01:27:02,316 epoch 21 - iter 12/49 - loss 3.93233677 - samples/sec: 61.66 - lr: 0.000015
2021-07-16 01:27:04,370 epoch 21 - iter 16/49 - loss 3.87929790 - samples/sec: 62.35 - lr: 0.000015
2021-07-16 01:27:06,444 epoch 21 - iter 20/49 - loss 3.91530068 - samples/sec: 61.74 - lr: 0.000015
2021-07-16 01:27:08,519 epoch 21 - iter 24/49 - loss 3.90136658 - samples/sec: 61.68 - lr: 0.000015
2021-07-16 01:27:10,585 epoch 21 - iter 28/49 - loss 3.85326418 - samples/sec: 62.00 - lr: 0.000015
2021-07-16 01:27:12,653 epoch 21 - iter 32/49 - loss 3.83318324 - samples/sec: 61.91 - lr: 0.000015
2021-07-16 01:27:14,711 epoch 21 - iter 36/49 - loss 3.85536812 - samples/sec: 62.22 - lr: 0.000015
2021-07-16 01:27:16,762 epoch 21 - iter 40/49 - loss 3.87110495 - samples/sec: 62.40 - lr: 0.000015
2021-07-16 01:27:18,840 epoch 21 - iter 44/49 - loss 3.84848739 - samples/sec: 61.62 - lr: 0.000015
2021-07-16 01:27:20,895 epoch 21 - iter 48/49 - loss 3.84356768 - samples/sec: 62.31 - lr: 0.000015
2021-07-16 01:27:21,102 ----------------------------------------------------------------------------------------------------
2021-07-16 01:27:21,102 EPOCH 21 done: loss 3.8395 - lr 0.0000150
2021-07-16 01:27:22,351 DEV : loss 3.6397311687469482 - score 0.8309
Epoch    21: reducing learning rate of group 0 to 7.5000e-06.
2021-07-16 01:27:22,369 BAD EPOCHS (no improvement): 4
2021-07-16 01:27:22,369 ----------------------------------------------------------------------------------------------------
2021-07-16 01:27:24,423 epoch 22 - iter 4/49 - loss 3.46819538 - samples/sec: 62.33 - lr: 0.000008
2021-07-16 01:27:26,502 epoch 22 - iter 8/49 - loss 3.63912365 - samples/sec: 61.57 - lr: 0.000008
2021-07-16 01:27:28,569 epoch 22 - iter 12/49 - loss 3.78957623 - samples/sec: 61.97 - lr: 0.000008
2021-07-16 01:27:30,641 epoch 22 - iter 16/49 - loss 3.82593526 - samples/sec: 61.77 - lr: 0.000008
2021-07-16 01:27:32,721 epoch 22 - iter 20/49 - loss 3.77319402 - samples/sec: 61.56 - lr: 0.000008
2021-07-16 01:27:34,785 epoch 22 - iter 24/49 - loss 3.75452173 - samples/sec: 62.05 - lr: 0.000008
2021-07-16 01:27:36,836 epoch 22 - iter 28/49 - loss 3.73829817 - samples/sec: 62.43 - lr: 0.000008
2021-07-16 01:27:38,915 epoch 22 - iter 32/49 - loss 3.76525640 - samples/sec: 61.58 - lr: 0.000008
2021-07-16 01:27:40,973 epoch 22 - iter 36/49 - loss 3.75542969 - samples/sec: 62.23 - lr: 0.000008
2021-07-16 01:27:43,048 epoch 22 - iter 40/49 - loss 3.80405065 - samples/sec: 61.71 - lr: 0.000008
2021-07-16 01:27:45,120 epoch 22 - iter 44/49 - loss 3.79325431 - samples/sec: 61.78 - lr: 0.000008
2021-07-16 01:27:47,170 epoch 22 - iter 48/49 - loss 3.79864166 - samples/sec: 62.45 - lr: 0.000008
2021-07-16 01:27:47,378 ----------------------------------------------------------------------------------------------------
2021-07-16 01:27:47,378 EPOCH 22 done: loss 3.7980 - lr 0.0000075
2021-07-16 01:27:48,620 DEV : loss 3.6480910778045654 - score 0.8337
2021-07-16 01:27:48,638 BAD EPOCHS (no improvement): 1
2021-07-16 01:27:48,638 ----------------------------------------------------------------------------------------------------
2021-07-16 01:27:50,705 epoch 23 - iter 4/49 - loss 3.79789180 - samples/sec: 61.94 - lr: 0.000008
2021-07-16 01:27:52,774 epoch 23 - iter 8/49 - loss 3.75912014 - samples/sec: 61.89 - lr: 0.000008
2021-07-16 01:27:54,841 epoch 23 - iter 12/49 - loss 3.71060077 - samples/sec: 61.94 - lr: 0.000008
2021-07-16 01:27:56,905 epoch 23 - iter 16/49 - loss 3.68826479 - samples/sec: 62.04 - lr: 0.000008
2021-07-16 01:27:58,963 epoch 23 - iter 20/49 - loss 3.67848967 - samples/sec: 62.21 - lr: 0.000008
2021-07-16 01:28:01,035 epoch 23 - iter 24/49 - loss 3.75134993 - samples/sec: 61.78 - lr: 0.000008
2021-07-16 01:28:03,101 epoch 23 - iter 28/49 - loss 3.75230791 - samples/sec: 61.99 - lr: 0.000008
2021-07-16 01:28:05,188 epoch 23 - iter 32/49 - loss 3.74550875 - samples/sec: 61.33 - lr: 0.000008
2021-07-16 01:28:07,255 epoch 23 - iter 36/49 - loss 3.76098420 - samples/sec: 61.94 - lr: 0.000008
2021-07-16 01:28:09,511 epoch 23 - iter 40/49 - loss 3.80923620 - samples/sec: 56.77 - lr: 0.000008
2021-07-16 01:28:11,582 epoch 23 - iter 44/49 - loss 3.83822380 - samples/sec: 61.81 - lr: 0.000008
2021-07-16 01:28:13,654 epoch 23 - iter 48/49 - loss 3.82293217 - samples/sec: 61.79 - lr: 0.000008
2021-07-16 01:28:13,858 ----------------------------------------------------------------------------------------------------
2021-07-16 01:28:13,858 EPOCH 23 done: loss 3.8477 - lr 0.0000075
2021-07-16 01:28:15,109 DEV : loss 3.6291284561157227 - score 0.834
2021-07-16 01:28:15,127 BAD EPOCHS (no improvement): 2
2021-07-16 01:28:15,127 ----------------------------------------------------------------------------------------------------
2021-07-16 01:28:17,163 epoch 24 - iter 4/49 - loss 3.82487810 - samples/sec: 62.89 - lr: 0.000008
2021-07-16 01:28:19,192 epoch 24 - iter 8/49 - loss 3.78373805 - samples/sec: 63.09 - lr: 0.000008
2021-07-16 01:28:21,261 epoch 24 - iter 12/49 - loss 3.74072788 - samples/sec: 61.89 - lr: 0.000008
2021-07-16 01:28:23,324 epoch 24 - iter 16/49 - loss 3.73641281 - samples/sec: 62.05 - lr: 0.000008
2021-07-16 01:28:25,377 epoch 24 - iter 20/49 - loss 3.76515257 - samples/sec: 62.37 - lr: 0.000008
2021-07-16 01:28:27,434 epoch 24 - iter 24/49 - loss 3.76842469 - samples/sec: 62.25 - lr: 0.000008
2021-07-16 01:28:29,475 epoch 24 - iter 28/49 - loss 3.73703990 - samples/sec: 62.72 - lr: 0.000008
2021-07-16 01:28:31,516 epoch 24 - iter 32/49 - loss 3.72896793 - samples/sec: 62.74 - lr: 0.000008
2021-07-16 01:28:33,572 epoch 24 - iter 36/49 - loss 3.73784752 - samples/sec: 62.27 - lr: 0.000008
2021-07-16 01:28:35,631 epoch 24 - iter 40/49 - loss 3.75406404 - samples/sec: 62.19 - lr: 0.000008
2021-07-16 01:28:37,681 epoch 24 - iter 44/49 - loss 3.77583914 - samples/sec: 62.47 - lr: 0.000008
2021-07-16 01:28:39,725 epoch 24 - iter 48/49 - loss 3.80033647 - samples/sec: 62.64 - lr: 0.000008
2021-07-16 01:28:39,931 ----------------------------------------------------------------------------------------------------
2021-07-16 01:28:39,931 EPOCH 24 done: loss 3.8104 - lr 0.0000075
2021-07-16 01:28:41,175 DEV : loss 3.652421474456787 - score 0.8357
2021-07-16 01:28:41,193 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:28:44,995 ----------------------------------------------------------------------------------------------------
2021-07-16 01:28:47,048 epoch 25 - iter 4/49 - loss 3.88838816 - samples/sec: 62.38 - lr: 0.000008
2021-07-16 01:28:49,112 epoch 25 - iter 8/49 - loss 3.69208768 - samples/sec: 62.05 - lr: 0.000008
2021-07-16 01:28:51,161 epoch 25 - iter 12/49 - loss 3.83331134 - samples/sec: 62.49 - lr: 0.000008
2021-07-16 01:28:53,219 epoch 25 - iter 16/49 - loss 3.88168971 - samples/sec: 62.20 - lr: 0.000008
2021-07-16 01:28:55,276 epoch 25 - iter 20/49 - loss 3.85664178 - samples/sec: 62.24 - lr: 0.000008
2021-07-16 01:28:57,323 epoch 25 - iter 24/49 - loss 3.92028220 - samples/sec: 62.56 - lr: 0.000008
2021-07-16 01:28:59,373 epoch 25 - iter 28/49 - loss 3.87407846 - samples/sec: 62.45 - lr: 0.000008
2021-07-16 01:29:01,417 epoch 25 - iter 32/49 - loss 3.86646499 - samples/sec: 62.64 - lr: 0.000008
2021-07-16 01:29:03,486 epoch 25 - iter 36/49 - loss 3.84827979 - samples/sec: 61.88 - lr: 0.000008
2021-07-16 01:29:05,527 epoch 25 - iter 40/49 - loss 3.81015869 - samples/sec: 62.76 - lr: 0.000008
2021-07-16 01:29:07,577 epoch 25 - iter 44/49 - loss 3.80583232 - samples/sec: 62.44 - lr: 0.000008
2021-07-16 01:29:09,644 epoch 25 - iter 48/49 - loss 3.79136835 - samples/sec: 61.96 - lr: 0.000008
2021-07-16 01:29:09,850 ----------------------------------------------------------------------------------------------------
2021-07-16 01:29:09,850 EPOCH 25 done: loss 3.7877 - lr 0.0000075
2021-07-16 01:29:11,094 DEV : loss 3.6274361610412598 - score 0.837
2021-07-16 01:29:11,112 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:29:14,844 ----------------------------------------------------------------------------------------------------
2021-07-16 01:29:16,907 epoch 26 - iter 4/49 - loss 3.77081716 - samples/sec: 62.08 - lr: 0.000008
2021-07-16 01:29:18,964 epoch 26 - iter 8/49 - loss 3.74435884 - samples/sec: 62.26 - lr: 0.000008
2021-07-16 01:29:21,036 epoch 26 - iter 12/49 - loss 3.79385181 - samples/sec: 61.78 - lr: 0.000008
2021-07-16 01:29:23,088 epoch 26 - iter 16/49 - loss 3.74154821 - samples/sec: 62.40 - lr: 0.000008
2021-07-16 01:29:25,133 epoch 26 - iter 20/49 - loss 3.81261499 - samples/sec: 62.61 - lr: 0.000008
2021-07-16 01:29:27,193 epoch 26 - iter 24/49 - loss 3.78762835 - samples/sec: 62.15 - lr: 0.000008
2021-07-16 01:29:29,253 epoch 26 - iter 28/49 - loss 3.82744834 - samples/sec: 62.17 - lr: 0.000008
2021-07-16 01:29:31,301 epoch 26 - iter 32/49 - loss 3.81624430 - samples/sec: 62.50 - lr: 0.000008
2021-07-16 01:29:33,354 epoch 26 - iter 36/49 - loss 3.82603322 - samples/sec: 62.38 - lr: 0.000008
2021-07-16 01:29:35,390 epoch 26 - iter 40/49 - loss 3.81229831 - samples/sec: 62.89 - lr: 0.000008
2021-07-16 01:29:37,440 epoch 26 - iter 44/49 - loss 3.80658621 - samples/sec: 62.44 - lr: 0.000008
2021-07-16 01:29:39,476 epoch 26 - iter 48/49 - loss 3.79068268 - samples/sec: 62.89 - lr: 0.000008
2021-07-16 01:29:39,684 ----------------------------------------------------------------------------------------------------
2021-07-16 01:29:39,684 EPOCH 26 done: loss 3.7824 - lr 0.0000075
2021-07-16 01:29:40,928 DEV : loss 3.6225953102111816 - score 0.8361
2021-07-16 01:29:40,946 BAD EPOCHS (no improvement): 1
2021-07-16 01:29:40,946 ----------------------------------------------------------------------------------------------------
2021-07-16 01:29:42,994 epoch 27 - iter 4/49 - loss 3.83102286 - samples/sec: 62.52 - lr: 0.000008
2021-07-16 01:29:45,045 epoch 27 - iter 8/49 - loss 3.96249759 - samples/sec: 62.42 - lr: 0.000008
2021-07-16 01:29:47,098 epoch 27 - iter 12/49 - loss 3.86496566 - samples/sec: 62.38 - lr: 0.000008
2021-07-16 01:29:49,164 epoch 27 - iter 16/49 - loss 3.87655950 - samples/sec: 61.96 - lr: 0.000008
2021-07-16 01:29:51,190 epoch 27 - iter 20/49 - loss 3.79005741 - samples/sec: 63.19 - lr: 0.000008
2021-07-16 01:29:53,252 epoch 27 - iter 24/49 - loss 3.76549111 - samples/sec: 62.10 - lr: 0.000008
2021-07-16 01:29:55,298 epoch 27 - iter 28/49 - loss 3.76168859 - samples/sec: 62.59 - lr: 0.000008
2021-07-16 01:29:57,345 epoch 27 - iter 32/49 - loss 3.74716172 - samples/sec: 62.54 - lr: 0.000008
2021-07-16 01:29:59,397 epoch 27 - iter 36/49 - loss 3.74789890 - samples/sec: 62.41 - lr: 0.000008
2021-07-16 01:30:01,459 epoch 27 - iter 40/49 - loss 3.76110708 - samples/sec: 62.10 - lr: 0.000008
2021-07-16 01:30:03,514 epoch 27 - iter 44/49 - loss 3.75710620 - samples/sec: 62.30 - lr: 0.000008
2021-07-16 01:30:05,575 epoch 27 - iter 48/49 - loss 3.75194754 - samples/sec: 62.12 - lr: 0.000008
2021-07-16 01:30:05,782 ----------------------------------------------------------------------------------------------------
2021-07-16 01:30:05,783 EPOCH 27 done: loss 3.7378 - lr 0.0000075
2021-07-16 01:30:07,028 DEV : loss 3.649453639984131 - score 0.8355
2021-07-16 01:30:07,046 BAD EPOCHS (no improvement): 2
2021-07-16 01:30:07,046 ----------------------------------------------------------------------------------------------------
2021-07-16 01:30:09,279 epoch 28 - iter 4/49 - loss 3.67711067 - samples/sec: 57.33 - lr: 0.000008
2021-07-16 01:30:11,321 epoch 28 - iter 8/49 - loss 3.95738265 - samples/sec: 62.71 - lr: 0.000008
2021-07-16 01:30:13,380 epoch 28 - iter 12/49 - loss 4.01709596 - samples/sec: 62.16 - lr: 0.000008
2021-07-16 01:30:15,417 epoch 28 - iter 16/49 - loss 4.02254289 - samples/sec: 62.86 - lr: 0.000008
2021-07-16 01:30:17,476 epoch 28 - iter 20/49 - loss 3.96400459 - samples/sec: 62.19 - lr: 0.000008
2021-07-16 01:30:19,535 epoch 28 - iter 24/49 - loss 3.91888650 - samples/sec: 62.18 - lr: 0.000008
2021-07-16 01:30:21,589 epoch 28 - iter 28/49 - loss 3.89525159 - samples/sec: 62.35 - lr: 0.000008
2021-07-16 01:30:23,648 epoch 28 - iter 32/49 - loss 3.87797380 - samples/sec: 62.17 - lr: 0.000008
2021-07-16 01:30:25,719 epoch 28 - iter 36/49 - loss 3.87245313 - samples/sec: 61.82 - lr: 0.000008
2021-07-16 01:30:27,772 epoch 28 - iter 40/49 - loss 3.84084684 - samples/sec: 62.38 - lr: 0.000008
2021-07-16 01:30:29,834 epoch 28 - iter 44/49 - loss 3.80525261 - samples/sec: 62.09 - lr: 0.000008
2021-07-16 01:30:31,877 epoch 28 - iter 48/49 - loss 3.82637149 - samples/sec: 62.69 - lr: 0.000008
2021-07-16 01:30:32,085 ----------------------------------------------------------------------------------------------------
2021-07-16 01:30:32,085 EPOCH 28 done: loss 3.8027 - lr 0.0000075
2021-07-16 01:30:33,330 DEV : loss 3.6029863357543945 - score 0.8321
2021-07-16 01:30:33,348 BAD EPOCHS (no improvement): 3
2021-07-16 01:30:33,348 ----------------------------------------------------------------------------------------------------
2021-07-16 01:30:35,392 epoch 29 - iter 4/49 - loss 3.62643802 - samples/sec: 62.65 - lr: 0.000008
2021-07-16 01:30:37,439 epoch 29 - iter 8/49 - loss 3.62983105 - samples/sec: 62.55 - lr: 0.000008
2021-07-16 01:30:39,519 epoch 29 - iter 12/49 - loss 3.64204872 - samples/sec: 61.54 - lr: 0.000008
2021-07-16 01:30:41,589 epoch 29 - iter 16/49 - loss 3.74035598 - samples/sec: 61.86 - lr: 0.000008
2021-07-16 01:30:43,673 epoch 29 - iter 20/49 - loss 3.76239334 - samples/sec: 61.44 - lr: 0.000008
2021-07-16 01:30:45,755 epoch 29 - iter 24/49 - loss 3.75947553 - samples/sec: 61.49 - lr: 0.000008
2021-07-16 01:30:47,831 epoch 29 - iter 28/49 - loss 3.74560231 - samples/sec: 61.68 - lr: 0.000008
2021-07-16 01:30:49,921 epoch 29 - iter 32/49 - loss 3.72535712 - samples/sec: 61.26 - lr: 0.000008
2021-07-16 01:30:52,000 epoch 29 - iter 36/49 - loss 3.72972272 - samples/sec: 61.59 - lr: 0.000008
2021-07-16 01:30:54,063 epoch 29 - iter 40/49 - loss 3.71647139 - samples/sec: 62.07 - lr: 0.000008
2021-07-16 01:30:56,155 epoch 29 - iter 44/49 - loss 3.72684264 - samples/sec: 61.20 - lr: 0.000008
2021-07-16 01:30:58,248 epoch 29 - iter 48/49 - loss 3.73462125 - samples/sec: 61.16 - lr: 0.000008
2021-07-16 01:30:58,458 ----------------------------------------------------------------------------------------------------
2021-07-16 01:30:58,459 EPOCH 29 done: loss 3.7323 - lr 0.0000075
2021-07-16 01:30:59,697 DEV : loss 3.621145009994507 - score 0.8342
Epoch    29: reducing learning rate of group 0 to 3.7500e-06.
2021-07-16 01:30:59,715 BAD EPOCHS (no improvement): 4
2021-07-16 01:30:59,715 ----------------------------------------------------------------------------------------------------
2021-07-16 01:31:01,788 epoch 30 - iter 4/49 - loss 3.94223112 - samples/sec: 61.78 - lr: 0.000004
2021-07-16 01:31:03,858 epoch 30 - iter 8/49 - loss 3.71092486 - samples/sec: 61.84 - lr: 0.000004
2021-07-16 01:31:05,915 epoch 30 - iter 12/49 - loss 3.67183610 - samples/sec: 62.26 - lr: 0.000004
2021-07-16 01:31:08,008 epoch 30 - iter 16/49 - loss 3.65858622 - samples/sec: 61.18 - lr: 0.000004
2021-07-16 01:31:10,088 epoch 30 - iter 20/49 - loss 3.70064039 - samples/sec: 61.56 - lr: 0.000004
2021-07-16 01:31:12,169 epoch 30 - iter 24/49 - loss 3.70092791 - samples/sec: 61.52 - lr: 0.000004
2021-07-16 01:31:14,253 epoch 30 - iter 28/49 - loss 3.70793722 - samples/sec: 61.44 - lr: 0.000004
2021-07-16 01:31:16,317 epoch 30 - iter 32/49 - loss 3.69396302 - samples/sec: 62.03 - lr: 0.000004
2021-07-16 01:31:18,387 epoch 30 - iter 36/49 - loss 3.70264151 - samples/sec: 61.84 - lr: 0.000004
2021-07-16 01:31:20,469 epoch 30 - iter 40/49 - loss 3.72819160 - samples/sec: 61.52 - lr: 0.000004
2021-07-16 01:31:22,556 epoch 30 - iter 44/49 - loss 3.74651446 - samples/sec: 61.34 - lr: 0.000004
2021-07-16 01:31:24,627 epoch 30 - iter 48/49 - loss 3.75757023 - samples/sec: 61.84 - lr: 0.000004
2021-07-16 01:31:24,838 ----------------------------------------------------------------------------------------------------
2021-07-16 01:31:24,838 EPOCH 30 done: loss 3.7554 - lr 0.0000038
2021-07-16 01:31:26,081 DEV : loss 3.611910104751587 - score 0.8336
2021-07-16 01:31:26,098 BAD EPOCHS (no improvement): 1
2021-07-16 01:31:26,098 ----------------------------------------------------------------------------------------------------
2021-07-16 01:31:28,161 epoch 31 - iter 4/49 - loss 3.74308771 - samples/sec: 62.09 - lr: 0.000004
2021-07-16 01:31:30,232 epoch 31 - iter 8/49 - loss 3.64734486 - samples/sec: 61.83 - lr: 0.000004
2021-07-16 01:31:32,297 epoch 31 - iter 12/49 - loss 3.65161995 - samples/sec: 61.99 - lr: 0.000004
2021-07-16 01:31:34,367 epoch 31 - iter 16/49 - loss 3.70167342 - samples/sec: 61.85 - lr: 0.000004
2021-07-16 01:31:36,420 epoch 31 - iter 20/49 - loss 3.71927382 - samples/sec: 62.37 - lr: 0.000004
2021-07-16 01:31:38,515 epoch 31 - iter 24/49 - loss 3.72883564 - samples/sec: 61.13 - lr: 0.000004
2021-07-16 01:31:40,591 epoch 31 - iter 28/49 - loss 3.75804016 - samples/sec: 61.66 - lr: 0.000004
2021-07-16 01:31:42,666 epoch 31 - iter 32/49 - loss 3.72957155 - samples/sec: 61.72 - lr: 0.000004
2021-07-16 01:31:44,746 epoch 31 - iter 36/49 - loss 3.73639462 - samples/sec: 61.54 - lr: 0.000004
2021-07-16 01:31:46,827 epoch 31 - iter 40/49 - loss 3.73587833 - samples/sec: 61.54 - lr: 0.000004
2021-07-16 01:31:48,883 epoch 31 - iter 44/49 - loss 3.72498833 - samples/sec: 62.27 - lr: 0.000004
2021-07-16 01:31:50,963 epoch 31 - iter 48/49 - loss 3.73341962 - samples/sec: 61.55 - lr: 0.000004
2021-07-16 01:31:51,169 ----------------------------------------------------------------------------------------------------
2021-07-16 01:31:51,169 EPOCH 31 done: loss 3.7322 - lr 0.0000038
2021-07-16 01:31:52,409 DEV : loss 3.592318534851074 - score 0.8324
2021-07-16 01:31:52,427 BAD EPOCHS (no improvement): 2
2021-07-16 01:31:52,427 ----------------------------------------------------------------------------------------------------
2021-07-16 01:31:54,481 epoch 32 - iter 4/49 - loss 3.61433905 - samples/sec: 62.35 - lr: 0.000004
2021-07-16 01:31:56,555 epoch 32 - iter 8/49 - loss 3.64880297 - samples/sec: 61.73 - lr: 0.000004
2021-07-16 01:31:58,609 epoch 32 - iter 12/49 - loss 3.71594427 - samples/sec: 62.34 - lr: 0.000004
2021-07-16 01:32:00,690 epoch 32 - iter 16/49 - loss 3.67175326 - samples/sec: 61.50 - lr: 0.000004
2021-07-16 01:32:02,764 epoch 32 - iter 20/49 - loss 3.73232332 - samples/sec: 61.76 - lr: 0.000004
2021-07-16 01:32:04,828 epoch 32 - iter 24/49 - loss 3.73958349 - samples/sec: 62.03 - lr: 0.000004
2021-07-16 01:32:06,923 epoch 32 - iter 28/49 - loss 3.75816745 - samples/sec: 61.09 - lr: 0.000004
2021-07-16 01:32:09,005 epoch 32 - iter 32/49 - loss 3.74862218 - samples/sec: 61.52 - lr: 0.000004
2021-07-16 01:32:11,086 epoch 32 - iter 36/49 - loss 3.75070783 - samples/sec: 61.52 - lr: 0.000004
2021-07-16 01:32:13,164 epoch 32 - iter 40/49 - loss 3.74443567 - samples/sec: 61.62 - lr: 0.000004
2021-07-16 01:32:15,224 epoch 32 - iter 44/49 - loss 3.72608026 - samples/sec: 62.14 - lr: 0.000004
2021-07-16 01:32:17,296 epoch 32 - iter 48/49 - loss 3.73328866 - samples/sec: 61.81 - lr: 0.000004
2021-07-16 01:32:17,506 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:17,506 EPOCH 32 done: loss 3.7331 - lr 0.0000038
2021-07-16 01:32:18,924 DEV : loss 3.604625940322876 - score 0.8349
2021-07-16 01:32:18,942 BAD EPOCHS (no improvement): 3
2021-07-16 01:32:18,942 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:21,003 epoch 33 - iter 4/49 - loss 3.86638016 - samples/sec: 62.11 - lr: 0.000004
2021-07-16 01:32:23,075 epoch 33 - iter 8/49 - loss 3.79392552 - samples/sec: 61.81 - lr: 0.000004
2021-07-16 01:32:25,154 epoch 33 - iter 12/49 - loss 3.69079820 - samples/sec: 61.57 - lr: 0.000004
2021-07-16 01:32:27,249 epoch 33 - iter 16/49 - loss 3.68321013 - samples/sec: 61.13 - lr: 0.000004
2021-07-16 01:32:29,299 epoch 33 - iter 20/49 - loss 3.69737437 - samples/sec: 62.44 - lr: 0.000004
2021-07-16 01:32:31,380 epoch 33 - iter 24/49 - loss 3.72237376 - samples/sec: 61.55 - lr: 0.000004
2021-07-16 01:32:33,451 epoch 33 - iter 28/49 - loss 3.74432744 - samples/sec: 61.81 - lr: 0.000004
2021-07-16 01:32:35,528 epoch 33 - iter 32/49 - loss 3.73350427 - samples/sec: 61.66 - lr: 0.000004
2021-07-16 01:32:37,616 epoch 33 - iter 36/49 - loss 3.72931900 - samples/sec: 61.31 - lr: 0.000004
2021-07-16 01:32:39,698 epoch 33 - iter 40/49 - loss 3.71432744 - samples/sec: 61.48 - lr: 0.000004
2021-07-16 01:32:41,785 epoch 33 - iter 44/49 - loss 3.72033148 - samples/sec: 61.37 - lr: 0.000004
2021-07-16 01:32:43,856 epoch 33 - iter 48/49 - loss 3.70705504 - samples/sec: 61.82 - lr: 0.000004
2021-07-16 01:32:44,064 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:44,064 EPOCH 33 done: loss 3.6945 - lr 0.0000038
2021-07-16 01:32:45,304 DEV : loss 3.626972198486328 - score 0.8365
Epoch    33: reducing learning rate of group 0 to 1.8750e-06.
2021-07-16 01:32:45,322 BAD EPOCHS (no improvement): 4
2021-07-16 01:32:45,322 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:45,322 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:45,322 learning rate too small - quitting training!
2021-07-16 01:32:45,322 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:46,043 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:46,043 Testing using best model ...
2021-07-16 01:32:46,043 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.sdrt.stac/best-model.pt
2021-07-16 01:32:53,684 0.8181	0.8232	0.8206
2021-07-16 01:32:53,684 
Results:
- F1-score (micro) 0.8206
- F1-score (macro) 0.8206

By class:
SENT       tp: 1606 - fp: 357 - fn: 345 - precision: 0.8181 - recall: 0.8232 - f1-score: 0.8206
2021-07-16 01:32:53,684 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.sctb/
2021-07-16 01:32:53,694 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.sctb
2021-07-16 01:32:53,694 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.sctb/sent_train.txt
2021-07-16 01:32:53,697 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.sctb/sent_dev.txt
2021-07-16 01:32:53,697 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.sctb/sent_test.txt
Corpus: 407 train + 120 dev + 94 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-16 01:32:56,495 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:56,497 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-16 01:32:56,497 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:56,497 Corpus: "Corpus: 407 train + 120 dev + 94 test sentences"
2021-07-16 01:32:56,497 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:56,497 Parameters:
2021-07-16 01:32:56,497  - learning_rate: "3e-05"
2021-07-16 01:32:56,497  - mini_batch_size: "32"
2021-07-16 01:32:56,497  - patience: "3"
2021-07-16 01:32:56,497  - anneal_factor: "0.5"
2021-07-16 01:32:56,497  - max_epochs: "40"
2021-07-16 01:32:56,497  - shuffle: "True"
2021-07-16 01:32:56,497  - train_with_dev: "False"
2021-07-16 01:32:56,497  - batch_growth_annealing: "False"
2021-07-16 01:32:56,497 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:56,497 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.sctb"
2021-07-16 01:32:56,497 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:56,497 Device: cuda:0
2021-07-16 01:32:56,497 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:56,497 Embeddings storage mode: cpu
2021-07-16 01:32:56,500 ----------------------------------------------------------------------------------------------------
2021-07-16 01:32:57,532 epoch 1 - iter 1/13 - loss 14.71633339 - samples/sec: 31.04 - lr: 0.000030
2021-07-16 01:32:58,569 epoch 1 - iter 2/13 - loss 12.63309908 - samples/sec: 30.86 - lr: 0.000030
2021-07-16 01:32:59,610 epoch 1 - iter 3/13 - loss 11.25997321 - samples/sec: 30.75 - lr: 0.000030
2021-07-16 01:33:00,651 epoch 1 - iter 4/13 - loss 10.10806668 - samples/sec: 30.73 - lr: 0.000030
2021-07-16 01:33:01,699 epoch 1 - iter 5/13 - loss 9.37594233 - samples/sec: 30.54 - lr: 0.000030
2021-07-16 01:33:02,752 epoch 1 - iter 6/13 - loss 8.47919134 - samples/sec: 30.39 - lr: 0.000030
2021-07-16 01:33:03,770 epoch 1 - iter 7/13 - loss 7.89913249 - samples/sec: 31.46 - lr: 0.000030
2021-07-16 01:33:04,821 epoch 1 - iter 8/13 - loss 7.46614197 - samples/sec: 30.45 - lr: 0.000030
2021-07-16 01:33:05,860 epoch 1 - iter 9/13 - loss 7.04709898 - samples/sec: 30.81 - lr: 0.000030
2021-07-16 01:33:06,896 epoch 1 - iter 10/13 - loss 6.78453205 - samples/sec: 30.90 - lr: 0.000030
2021-07-16 01:33:07,947 epoch 1 - iter 11/13 - loss 6.63780440 - samples/sec: 30.46 - lr: 0.000030
2021-07-16 01:33:08,976 epoch 1 - iter 12/13 - loss 6.48384959 - samples/sec: 31.10 - lr: 0.000030
2021-07-16 01:33:09,738 epoch 1 - iter 13/13 - loss 6.30685867 - samples/sec: 41.98 - lr: 0.000030
2021-07-16 01:33:09,739 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:09,739 EPOCH 1 done: loss 6.3069 - lr 0.0000300
2021-07-16 01:33:11,895 DEV : loss 3.4692912101745605 - score 0.0
2021-07-16 01:33:11,904 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:33:12,762 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:13,307 epoch 2 - iter 1/13 - loss 5.03748369 - samples/sec: 58.74 - lr: 0.000030
2021-07-16 01:33:13,849 epoch 2 - iter 2/13 - loss 4.40846133 - samples/sec: 59.16 - lr: 0.000030
2021-07-16 01:33:14,393 epoch 2 - iter 3/13 - loss 4.08311089 - samples/sec: 58.86 - lr: 0.000030
2021-07-16 01:33:14,920 epoch 2 - iter 4/13 - loss 3.99976856 - samples/sec: 60.68 - lr: 0.000030
2021-07-16 01:33:15,459 epoch 2 - iter 5/13 - loss 3.79970918 - samples/sec: 59.51 - lr: 0.000030
2021-07-16 01:33:15,991 epoch 2 - iter 6/13 - loss 3.69308341 - samples/sec: 60.19 - lr: 0.000030
2021-07-16 01:33:16,516 epoch 2 - iter 7/13 - loss 3.58576458 - samples/sec: 60.96 - lr: 0.000030
2021-07-16 01:33:17,055 epoch 2 - iter 8/13 - loss 3.47440311 - samples/sec: 59.38 - lr: 0.000030
2021-07-16 01:33:17,580 epoch 2 - iter 9/13 - loss 3.38190325 - samples/sec: 61.06 - lr: 0.000030
2021-07-16 01:33:18,128 epoch 2 - iter 10/13 - loss 3.35528891 - samples/sec: 58.40 - lr: 0.000030
2021-07-16 01:33:18,672 epoch 2 - iter 11/13 - loss 3.28022989 - samples/sec: 58.89 - lr: 0.000030
2021-07-16 01:33:19,219 epoch 2 - iter 12/13 - loss 3.30284250 - samples/sec: 58.61 - lr: 0.000030
2021-07-16 01:33:19,626 epoch 2 - iter 13/13 - loss 3.26438979 - samples/sec: 78.75 - lr: 0.000030
2021-07-16 01:33:19,626 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:19,626 EPOCH 2 done: loss 3.2644 - lr 0.0000300
2021-07-16 01:33:20,288 DEV : loss 2.2480697631835938 - score 0.0
2021-07-16 01:33:20,297 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:33:24,220 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:24,756 epoch 3 - iter 1/13 - loss 2.84190750 - samples/sec: 59.79 - lr: 0.000030
2021-07-16 01:33:25,294 epoch 3 - iter 2/13 - loss 2.74866867 - samples/sec: 59.50 - lr: 0.000030
2021-07-16 01:33:25,840 epoch 3 - iter 3/13 - loss 2.58785701 - samples/sec: 58.70 - lr: 0.000030
2021-07-16 01:33:26,385 epoch 3 - iter 4/13 - loss 2.70689803 - samples/sec: 58.76 - lr: 0.000030
2021-07-16 01:33:26,921 epoch 3 - iter 5/13 - loss 2.63883266 - samples/sec: 59.71 - lr: 0.000030
2021-07-16 01:33:27,445 epoch 3 - iter 6/13 - loss 2.54719043 - samples/sec: 61.14 - lr: 0.000030
2021-07-16 01:33:27,993 epoch 3 - iter 7/13 - loss 2.51332072 - samples/sec: 58.49 - lr: 0.000030
2021-07-16 01:33:28,528 epoch 3 - iter 8/13 - loss 2.46535602 - samples/sec: 59.81 - lr: 0.000030
2021-07-16 01:33:29,060 epoch 3 - iter 9/13 - loss 2.45971364 - samples/sec: 60.19 - lr: 0.000030
2021-07-16 01:33:29,596 epoch 3 - iter 10/13 - loss 2.43446736 - samples/sec: 59.81 - lr: 0.000030
2021-07-16 01:33:30,136 epoch 3 - iter 11/13 - loss 2.42670874 - samples/sec: 59.32 - lr: 0.000030
2021-07-16 01:33:30,684 epoch 3 - iter 12/13 - loss 2.41243877 - samples/sec: 58.37 - lr: 0.000030
2021-07-16 01:33:31,094 epoch 3 - iter 13/13 - loss 2.39515559 - samples/sec: 78.29 - lr: 0.000030
2021-07-16 01:33:31,094 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:31,094 EPOCH 3 done: loss 2.3952 - lr 0.0000300
2021-07-16 01:33:31,754 DEV : loss 1.516801357269287 - score 0.0506
2021-07-16 01:33:31,763 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:33:35,763 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:36,308 epoch 4 - iter 1/13 - loss 1.71586168 - samples/sec: 58.84 - lr: 0.000030
2021-07-16 01:33:36,844 epoch 4 - iter 2/13 - loss 1.69856018 - samples/sec: 59.76 - lr: 0.000030
2021-07-16 01:33:37,379 epoch 4 - iter 3/13 - loss 1.71145058 - samples/sec: 59.81 - lr: 0.000030
2021-07-16 01:33:37,925 epoch 4 - iter 4/13 - loss 1.78493762 - samples/sec: 58.71 - lr: 0.000030
2021-07-16 01:33:38,460 epoch 4 - iter 5/13 - loss 1.82618504 - samples/sec: 59.81 - lr: 0.000030
2021-07-16 01:33:38,989 epoch 4 - iter 6/13 - loss 1.83909694 - samples/sec: 60.63 - lr: 0.000030
2021-07-16 01:33:39,523 epoch 4 - iter 7/13 - loss 1.82578393 - samples/sec: 59.98 - lr: 0.000030
2021-07-16 01:33:40,064 epoch 4 - iter 8/13 - loss 1.80055691 - samples/sec: 59.20 - lr: 0.000030
2021-07-16 01:33:40,599 epoch 4 - iter 9/13 - loss 1.78643268 - samples/sec: 59.80 - lr: 0.000030
2021-07-16 01:33:41,134 epoch 4 - iter 10/13 - loss 1.77895154 - samples/sec: 59.84 - lr: 0.000030
2021-07-16 01:33:41,674 epoch 4 - iter 11/13 - loss 1.76148263 - samples/sec: 59.33 - lr: 0.000030
2021-07-16 01:33:42,219 epoch 4 - iter 12/13 - loss 1.73497654 - samples/sec: 58.78 - lr: 0.000030
2021-07-16 01:33:42,632 epoch 4 - iter 13/13 - loss 1.69533768 - samples/sec: 77.50 - lr: 0.000030
2021-07-16 01:33:42,633 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:42,633 EPOCH 4 done: loss 1.6953 - lr 0.0000300
2021-07-16 01:33:43,295 DEV : loss 0.9987587928771973 - score 0.5357
2021-07-16 01:33:43,304 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:33:47,097 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:47,635 epoch 5 - iter 1/13 - loss 1.82014036 - samples/sec: 59.56 - lr: 0.000030
2021-07-16 01:33:48,164 epoch 5 - iter 2/13 - loss 1.37398148 - samples/sec: 60.54 - lr: 0.000030
2021-07-16 01:33:48,707 epoch 5 - iter 3/13 - loss 1.33767442 - samples/sec: 58.93 - lr: 0.000030
2021-07-16 01:33:49,248 epoch 5 - iter 4/13 - loss 1.28213155 - samples/sec: 59.23 - lr: 0.000030
2021-07-16 01:33:49,788 epoch 5 - iter 5/13 - loss 1.29835608 - samples/sec: 59.26 - lr: 0.000030
2021-07-16 01:33:50,303 epoch 5 - iter 6/13 - loss 1.35817824 - samples/sec: 62.17 - lr: 0.000030
2021-07-16 01:33:50,848 epoch 5 - iter 7/13 - loss 1.36757202 - samples/sec: 58.80 - lr: 0.000030
2021-07-16 01:33:51,395 epoch 5 - iter 8/13 - loss 1.30204074 - samples/sec: 58.57 - lr: 0.000030
2021-07-16 01:33:51,943 epoch 5 - iter 9/13 - loss 1.31358887 - samples/sec: 58.40 - lr: 0.000030
2021-07-16 01:33:52,473 epoch 5 - iter 10/13 - loss 1.27835948 - samples/sec: 60.52 - lr: 0.000030
2021-07-16 01:33:53,019 epoch 5 - iter 11/13 - loss 1.26870206 - samples/sec: 58.57 - lr: 0.000030
2021-07-16 01:33:53,563 epoch 5 - iter 12/13 - loss 1.28523342 - samples/sec: 58.93 - lr: 0.000030
2021-07-16 01:33:53,965 epoch 5 - iter 13/13 - loss 1.25410817 - samples/sec: 79.66 - lr: 0.000030
2021-07-16 01:33:53,965 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:53,966 EPOCH 5 done: loss 1.2541 - lr 0.0000300
2021-07-16 01:33:54,626 DEV : loss 0.6252055168151855 - score 0.8811
2021-07-16 01:33:54,636 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:33:58,538 ----------------------------------------------------------------------------------------------------
2021-07-16 01:33:59,076 epoch 6 - iter 1/13 - loss 0.89084017 - samples/sec: 59.57 - lr: 0.000030
2021-07-16 01:33:59,606 epoch 6 - iter 2/13 - loss 0.81128326 - samples/sec: 60.36 - lr: 0.000030
2021-07-16 01:34:00,148 epoch 6 - iter 3/13 - loss 0.84478158 - samples/sec: 59.06 - lr: 0.000030
2021-07-16 01:34:00,697 epoch 6 - iter 4/13 - loss 0.89540835 - samples/sec: 58.39 - lr: 0.000030
2021-07-16 01:34:01,244 epoch 6 - iter 5/13 - loss 0.91268460 - samples/sec: 58.57 - lr: 0.000030
2021-07-16 01:34:01,786 epoch 6 - iter 6/13 - loss 0.90447595 - samples/sec: 59.02 - lr: 0.000030
2021-07-16 01:34:02,336 epoch 6 - iter 7/13 - loss 0.91148090 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 01:34:02,876 epoch 6 - iter 8/13 - loss 0.90256159 - samples/sec: 59.30 - lr: 0.000030
2021-07-16 01:34:03,406 epoch 6 - iter 9/13 - loss 0.90205483 - samples/sec: 60.47 - lr: 0.000030
2021-07-16 01:34:03,923 epoch 6 - iter 10/13 - loss 0.88158928 - samples/sec: 61.87 - lr: 0.000030
2021-07-16 01:34:04,459 epoch 6 - iter 11/13 - loss 0.89650469 - samples/sec: 59.78 - lr: 0.000030
2021-07-16 01:34:05,005 epoch 6 - iter 12/13 - loss 0.89087412 - samples/sec: 58.72 - lr: 0.000030
2021-07-16 01:34:05,417 epoch 6 - iter 13/13 - loss 0.91038506 - samples/sec: 77.66 - lr: 0.000030
2021-07-16 01:34:05,418 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:05,418 EPOCH 6 done: loss 0.9104 - lr 0.0000300
2021-07-16 01:34:06,077 DEV : loss 0.505408763885498 - score 0.8765
2021-07-16 01:34:06,086 BAD EPOCHS (no improvement): 1
2021-07-16 01:34:06,087 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:06,607 epoch 7 - iter 1/13 - loss 0.74716961 - samples/sec: 61.51 - lr: 0.000030
2021-07-16 01:34:07,141 epoch 7 - iter 2/13 - loss 0.75154242 - samples/sec: 60.02 - lr: 0.000030
2021-07-16 01:34:07,679 epoch 7 - iter 3/13 - loss 0.69410803 - samples/sec: 59.48 - lr: 0.000030
2021-07-16 01:34:08,219 epoch 7 - iter 4/13 - loss 0.75475578 - samples/sec: 59.37 - lr: 0.000030
2021-07-16 01:34:08,765 epoch 7 - iter 5/13 - loss 0.71442951 - samples/sec: 58.67 - lr: 0.000030
2021-07-16 01:34:09,311 epoch 7 - iter 6/13 - loss 0.72785865 - samples/sec: 58.61 - lr: 0.000030
2021-07-16 01:34:09,847 epoch 7 - iter 7/13 - loss 0.69702833 - samples/sec: 59.76 - lr: 0.000030
2021-07-16 01:34:10,393 epoch 7 - iter 8/13 - loss 0.67875147 - samples/sec: 58.67 - lr: 0.000030
2021-07-16 01:34:10,933 epoch 7 - iter 9/13 - loss 0.65941177 - samples/sec: 59.32 - lr: 0.000030
2021-07-16 01:34:11,472 epoch 7 - iter 10/13 - loss 0.65416057 - samples/sec: 59.41 - lr: 0.000030
2021-07-16 01:34:12,000 epoch 7 - iter 11/13 - loss 0.65981529 - samples/sec: 60.67 - lr: 0.000030
2021-07-16 01:34:12,539 epoch 7 - iter 12/13 - loss 0.66803304 - samples/sec: 59.35 - lr: 0.000030
2021-07-16 01:34:12,952 epoch 7 - iter 13/13 - loss 0.70196186 - samples/sec: 77.62 - lr: 0.000030
2021-07-16 01:34:12,952 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:12,953 EPOCH 7 done: loss 0.7020 - lr 0.0000300
2021-07-16 01:34:13,611 DEV : loss 0.361420214176178 - score 0.879
2021-07-16 01:34:13,620 BAD EPOCHS (no improvement): 2
2021-07-16 01:34:13,620 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:14,218 epoch 8 - iter 1/13 - loss 0.54923075 - samples/sec: 53.60 - lr: 0.000030
2021-07-16 01:34:14,763 epoch 8 - iter 2/13 - loss 0.57258531 - samples/sec: 58.74 - lr: 0.000030
2021-07-16 01:34:15,300 epoch 8 - iter 3/13 - loss 0.58107235 - samples/sec: 59.58 - lr: 0.000030
2021-07-16 01:34:15,843 epoch 8 - iter 4/13 - loss 0.57904054 - samples/sec: 59.02 - lr: 0.000030
2021-07-16 01:34:16,380 epoch 8 - iter 5/13 - loss 0.59179419 - samples/sec: 59.60 - lr: 0.000030
2021-07-16 01:34:16,918 epoch 8 - iter 6/13 - loss 0.62512619 - samples/sec: 59.52 - lr: 0.000030
2021-07-16 01:34:17,460 epoch 8 - iter 7/13 - loss 0.61647700 - samples/sec: 59.09 - lr: 0.000030
2021-07-16 01:34:17,994 epoch 8 - iter 8/13 - loss 0.56775206 - samples/sec: 59.98 - lr: 0.000030
2021-07-16 01:34:18,540 epoch 8 - iter 9/13 - loss 0.56217545 - samples/sec: 58.76 - lr: 0.000030
2021-07-16 01:34:19,082 epoch 8 - iter 10/13 - loss 0.57320725 - samples/sec: 59.00 - lr: 0.000030
2021-07-16 01:34:19,621 epoch 8 - iter 11/13 - loss 0.57098986 - samples/sec: 59.42 - lr: 0.000030
2021-07-16 01:34:20,143 epoch 8 - iter 12/13 - loss 0.58294416 - samples/sec: 61.38 - lr: 0.000030
2021-07-16 01:34:20,550 epoch 8 - iter 13/13 - loss 0.55779143 - samples/sec: 78.79 - lr: 0.000030
2021-07-16 01:34:20,550 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:20,550 EPOCH 8 done: loss 0.5578 - lr 0.0000300
2021-07-16 01:34:21,209 DEV : loss 0.3800738751888275 - score 0.8712
2021-07-16 01:34:21,219 BAD EPOCHS (no improvement): 3
2021-07-16 01:34:21,219 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:21,751 epoch 9 - iter 1/13 - loss 0.40117413 - samples/sec: 60.14 - lr: 0.000030
2021-07-16 01:34:22,288 epoch 9 - iter 2/13 - loss 0.56131795 - samples/sec: 59.66 - lr: 0.000030
2021-07-16 01:34:22,832 epoch 9 - iter 3/13 - loss 0.62402171 - samples/sec: 58.89 - lr: 0.000030
2021-07-16 01:34:23,371 epoch 9 - iter 4/13 - loss 0.53717698 - samples/sec: 59.41 - lr: 0.000030
2021-07-16 01:34:23,903 epoch 9 - iter 5/13 - loss 0.54866461 - samples/sec: 60.19 - lr: 0.000030
2021-07-16 01:34:24,451 epoch 9 - iter 6/13 - loss 0.52518756 - samples/sec: 58.48 - lr: 0.000030
2021-07-16 01:34:24,983 epoch 9 - iter 7/13 - loss 0.51101108 - samples/sec: 60.21 - lr: 0.000030
2021-07-16 01:34:25,537 epoch 9 - iter 8/13 - loss 0.49382486 - samples/sec: 57.80 - lr: 0.000030
2021-07-16 01:34:26,073 epoch 9 - iter 9/13 - loss 0.51837602 - samples/sec: 59.78 - lr: 0.000030
2021-07-16 01:34:26,610 epoch 9 - iter 10/13 - loss 0.49713939 - samples/sec: 59.58 - lr: 0.000030
2021-07-16 01:34:27,154 epoch 9 - iter 11/13 - loss 0.47596375 - samples/sec: 58.87 - lr: 0.000030
2021-07-16 01:34:27,674 epoch 9 - iter 12/13 - loss 0.50036287 - samples/sec: 61.56 - lr: 0.000030
2021-07-16 01:34:28,084 epoch 9 - iter 13/13 - loss 0.49758835 - samples/sec: 78.20 - lr: 0.000030
2021-07-16 01:34:28,084 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:28,084 EPOCH 9 done: loss 0.4976 - lr 0.0000300
2021-07-16 01:34:28,743 DEV : loss 0.3328339457511902 - score 0.8805
Epoch     9: reducing learning rate of group 0 to 1.5000e-05.
2021-07-16 01:34:28,752 BAD EPOCHS (no improvement): 4
2021-07-16 01:34:28,753 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:29,275 epoch 10 - iter 1/13 - loss 0.75288224 - samples/sec: 61.25 - lr: 0.000015
2021-07-16 01:34:29,821 epoch 10 - iter 2/13 - loss 0.56036901 - samples/sec: 58.72 - lr: 0.000015
2021-07-16 01:34:30,355 epoch 10 - iter 3/13 - loss 0.55923961 - samples/sec: 60.00 - lr: 0.000015
2021-07-16 01:34:30,878 epoch 10 - iter 4/13 - loss 0.50191801 - samples/sec: 61.24 - lr: 0.000015
2021-07-16 01:34:31,419 epoch 10 - iter 5/13 - loss 0.47145421 - samples/sec: 59.15 - lr: 0.000015
2021-07-16 01:34:31,953 epoch 10 - iter 6/13 - loss 0.45121075 - samples/sec: 60.03 - lr: 0.000015
2021-07-16 01:34:32,496 epoch 10 - iter 7/13 - loss 0.48292614 - samples/sec: 58.89 - lr: 0.000015
2021-07-16 01:34:33,039 epoch 10 - iter 8/13 - loss 0.47598947 - samples/sec: 59.08 - lr: 0.000015
2021-07-16 01:34:33,567 epoch 10 - iter 9/13 - loss 0.45635024 - samples/sec: 60.66 - lr: 0.000015
2021-07-16 01:34:34,114 epoch 10 - iter 10/13 - loss 0.45086944 - samples/sec: 58.52 - lr: 0.000015
2021-07-16 01:34:34,667 epoch 10 - iter 11/13 - loss 0.46512020 - samples/sec: 57.91 - lr: 0.000015
2021-07-16 01:34:35,218 epoch 10 - iter 12/13 - loss 0.44937978 - samples/sec: 58.12 - lr: 0.000015
2021-07-16 01:34:35,621 epoch 10 - iter 13/13 - loss 0.47234058 - samples/sec: 79.47 - lr: 0.000015
2021-07-16 01:34:35,622 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:35,622 EPOCH 10 done: loss 0.4723 - lr 0.0000150
2021-07-16 01:34:36,282 DEV : loss 0.34296512603759766 - score 0.8696
2021-07-16 01:34:36,291 BAD EPOCHS (no improvement): 1
2021-07-16 01:34:36,291 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:36,830 epoch 11 - iter 1/13 - loss 0.47339654 - samples/sec: 59.40 - lr: 0.000015
2021-07-16 01:34:37,378 epoch 11 - iter 2/13 - loss 0.42117250 - samples/sec: 58.47 - lr: 0.000015
2021-07-16 01:34:37,918 epoch 11 - iter 3/13 - loss 0.46330031 - samples/sec: 59.33 - lr: 0.000015
2021-07-16 01:34:38,455 epoch 11 - iter 4/13 - loss 0.46707046 - samples/sec: 59.66 - lr: 0.000015
2021-07-16 01:34:39,000 epoch 11 - iter 5/13 - loss 0.42719936 - samples/sec: 58.80 - lr: 0.000015
2021-07-16 01:34:39,533 epoch 11 - iter 6/13 - loss 0.42445640 - samples/sec: 60.06 - lr: 0.000015
2021-07-16 01:34:40,051 epoch 11 - iter 7/13 - loss 0.40671309 - samples/sec: 61.86 - lr: 0.000015
2021-07-16 01:34:40,599 epoch 11 - iter 8/13 - loss 0.40990696 - samples/sec: 58.40 - lr: 0.000015
2021-07-16 01:34:41,149 epoch 11 - iter 9/13 - loss 0.41209908 - samples/sec: 58.25 - lr: 0.000015
2021-07-16 01:34:41,688 epoch 11 - iter 10/13 - loss 0.42093089 - samples/sec: 59.43 - lr: 0.000015
2021-07-16 01:34:42,213 epoch 11 - iter 11/13 - loss 0.41296725 - samples/sec: 60.96 - lr: 0.000015
2021-07-16 01:34:42,749 epoch 11 - iter 12/13 - loss 0.40372685 - samples/sec: 59.81 - lr: 0.000015
2021-07-16 01:34:43,157 epoch 11 - iter 13/13 - loss 0.39172763 - samples/sec: 78.52 - lr: 0.000015
2021-07-16 01:34:43,157 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:43,157 EPOCH 11 done: loss 0.3917 - lr 0.0000150
2021-07-16 01:34:43,816 DEV : loss 0.35679149627685547 - score 0.8765
2021-07-16 01:34:43,825 BAD EPOCHS (no improvement): 2
2021-07-16 01:34:43,826 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:44,342 epoch 12 - iter 1/13 - loss 0.35517097 - samples/sec: 61.96 - lr: 0.000015
2021-07-16 01:34:44,880 epoch 12 - iter 2/13 - loss 0.38046056 - samples/sec: 59.61 - lr: 0.000015
2021-07-16 01:34:45,430 epoch 12 - iter 3/13 - loss 0.40014247 - samples/sec: 58.24 - lr: 0.000015
2021-07-16 01:34:45,959 epoch 12 - iter 4/13 - loss 0.35252696 - samples/sec: 60.55 - lr: 0.000015
2021-07-16 01:34:46,499 epoch 12 - iter 5/13 - loss 0.37527037 - samples/sec: 59.29 - lr: 0.000015
2021-07-16 01:34:47,040 epoch 12 - iter 6/13 - loss 0.40685672 - samples/sec: 59.20 - lr: 0.000015
2021-07-16 01:34:47,577 epoch 12 - iter 7/13 - loss 0.40339128 - samples/sec: 59.66 - lr: 0.000015
2021-07-16 01:34:48,123 epoch 12 - iter 8/13 - loss 0.42454519 - samples/sec: 58.66 - lr: 0.000015
2021-07-16 01:34:48,654 epoch 12 - iter 9/13 - loss 0.43277065 - samples/sec: 60.27 - lr: 0.000015
2021-07-16 01:34:49,192 epoch 12 - iter 10/13 - loss 0.42458592 - samples/sec: 59.58 - lr: 0.000015
2021-07-16 01:34:49,739 epoch 12 - iter 11/13 - loss 0.42642813 - samples/sec: 58.57 - lr: 0.000015
2021-07-16 01:34:50,280 epoch 12 - iter 12/13 - loss 0.40284058 - samples/sec: 59.12 - lr: 0.000015
2021-07-16 01:34:50,692 epoch 12 - iter 13/13 - loss 0.38321138 - samples/sec: 77.89 - lr: 0.000015
2021-07-16 01:34:50,692 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:50,692 EPOCH 12 done: loss 0.3832 - lr 0.0000150
2021-07-16 01:34:51,351 DEV : loss 0.3211763799190521 - score 0.875
2021-07-16 01:34:51,360 BAD EPOCHS (no improvement): 3
2021-07-16 01:34:51,360 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:51,895 epoch 13 - iter 1/13 - loss 0.54271877 - samples/sec: 59.90 - lr: 0.000015
2021-07-16 01:34:52,442 epoch 13 - iter 2/13 - loss 0.49764448 - samples/sec: 58.50 - lr: 0.000015
2021-07-16 01:34:52,987 epoch 13 - iter 3/13 - loss 0.45514770 - samples/sec: 58.83 - lr: 0.000015
2021-07-16 01:34:53,531 epoch 13 - iter 4/13 - loss 0.54548439 - samples/sec: 58.87 - lr: 0.000015
2021-07-16 01:34:54,067 epoch 13 - iter 5/13 - loss 0.50722608 - samples/sec: 59.75 - lr: 0.000015
2021-07-16 01:34:54,608 epoch 13 - iter 6/13 - loss 0.51535236 - samples/sec: 59.26 - lr: 0.000015
2021-07-16 01:34:55,155 epoch 13 - iter 7/13 - loss 0.46944182 - samples/sec: 58.45 - lr: 0.000015
2021-07-16 01:34:55,675 epoch 13 - iter 8/13 - loss 0.44140872 - samples/sec: 61.64 - lr: 0.000015
2021-07-16 01:34:56,218 epoch 13 - iter 9/13 - loss 0.45832714 - samples/sec: 59.03 - lr: 0.000015
2021-07-16 01:34:56,760 epoch 13 - iter 10/13 - loss 0.45200027 - samples/sec: 58.99 - lr: 0.000015
2021-07-16 01:34:57,303 epoch 13 - iter 11/13 - loss 0.45182944 - samples/sec: 59.01 - lr: 0.000015
2021-07-16 01:34:57,835 epoch 13 - iter 12/13 - loss 0.44115274 - samples/sec: 60.22 - lr: 0.000015
2021-07-16 01:34:58,236 epoch 13 - iter 13/13 - loss 0.41869373 - samples/sec: 79.88 - lr: 0.000015
2021-07-16 01:34:58,237 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:58,237 EPOCH 13 done: loss 0.4187 - lr 0.0000150
2021-07-16 01:34:58,976 DEV : loss 0.3454468250274658 - score 0.8696
Epoch    13: reducing learning rate of group 0 to 7.5000e-06.
2021-07-16 01:34:58,985 BAD EPOCHS (no improvement): 4
2021-07-16 01:34:58,985 ----------------------------------------------------------------------------------------------------
2021-07-16 01:34:59,499 epoch 14 - iter 1/13 - loss 0.25125813 - samples/sec: 62.34 - lr: 0.000008
2021-07-16 01:35:00,036 epoch 14 - iter 2/13 - loss 0.36083642 - samples/sec: 59.61 - lr: 0.000008
2021-07-16 01:35:00,586 epoch 14 - iter 3/13 - loss 0.33525127 - samples/sec: 58.29 - lr: 0.000008
2021-07-16 01:35:01,132 epoch 14 - iter 4/13 - loss 0.32813503 - samples/sec: 58.63 - lr: 0.000008
2021-07-16 01:35:01,663 epoch 14 - iter 5/13 - loss 0.33505646 - samples/sec: 60.35 - lr: 0.000008
2021-07-16 01:35:02,204 epoch 14 - iter 6/13 - loss 0.37259977 - samples/sec: 59.17 - lr: 0.000008
2021-07-16 01:35:02,741 epoch 14 - iter 7/13 - loss 0.37303324 - samples/sec: 59.61 - lr: 0.000008
2021-07-16 01:35:03,276 epoch 14 - iter 8/13 - loss 0.36999580 - samples/sec: 59.90 - lr: 0.000008
2021-07-16 01:35:03,820 epoch 14 - iter 9/13 - loss 0.35770220 - samples/sec: 58.85 - lr: 0.000008
2021-07-16 01:35:04,364 epoch 14 - iter 10/13 - loss 0.36309845 - samples/sec: 58.97 - lr: 0.000008
2021-07-16 01:35:04,906 epoch 14 - iter 11/13 - loss 0.37507529 - samples/sec: 59.00 - lr: 0.000008
2021-07-16 01:35:05,446 epoch 14 - iter 12/13 - loss 0.36771942 - samples/sec: 59.31 - lr: 0.000008
2021-07-16 01:35:05,853 epoch 14 - iter 13/13 - loss 0.38252602 - samples/sec: 78.86 - lr: 0.000008
2021-07-16 01:35:05,853 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:05,853 EPOCH 14 done: loss 0.3825 - lr 0.0000075
2021-07-16 01:35:06,516 DEV : loss 0.36041224002838135 - score 0.8712
2021-07-16 01:35:06,526 BAD EPOCHS (no improvement): 1
2021-07-16 01:35:06,526 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:07,054 epoch 15 - iter 1/13 - loss 0.23999208 - samples/sec: 60.68 - lr: 0.000008
2021-07-16 01:35:07,588 epoch 15 - iter 2/13 - loss 0.23889741 - samples/sec: 59.94 - lr: 0.000008
2021-07-16 01:35:08,120 epoch 15 - iter 3/13 - loss 0.27926075 - samples/sec: 60.25 - lr: 0.000008
2021-07-16 01:35:08,659 epoch 15 - iter 4/13 - loss 0.33201115 - samples/sec: 59.42 - lr: 0.000008
2021-07-16 01:35:09,200 epoch 15 - iter 5/13 - loss 0.34268092 - samples/sec: 59.12 - lr: 0.000008
2021-07-16 01:35:09,733 epoch 15 - iter 6/13 - loss 0.35410075 - samples/sec: 60.18 - lr: 0.000008
2021-07-16 01:35:10,263 epoch 15 - iter 7/13 - loss 0.38498638 - samples/sec: 60.34 - lr: 0.000008
2021-07-16 01:35:10,804 epoch 15 - iter 8/13 - loss 0.39984844 - samples/sec: 59.23 - lr: 0.000008
2021-07-16 01:35:11,344 epoch 15 - iter 9/13 - loss 0.42596271 - samples/sec: 59.38 - lr: 0.000008
2021-07-16 01:35:11,878 epoch 15 - iter 10/13 - loss 0.41449977 - samples/sec: 59.96 - lr: 0.000008
2021-07-16 01:35:12,430 epoch 15 - iter 11/13 - loss 0.40433243 - samples/sec: 58.00 - lr: 0.000008
2021-07-16 01:35:12,960 epoch 15 - iter 12/13 - loss 0.39588315 - samples/sec: 60.44 - lr: 0.000008
2021-07-16 01:35:13,368 epoch 15 - iter 13/13 - loss 0.38198287 - samples/sec: 78.51 - lr: 0.000008
2021-07-16 01:35:13,368 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:13,368 EPOCH 15 done: loss 0.3820 - lr 0.0000075
2021-07-16 01:35:14,029 DEV : loss 0.3481607139110565 - score 0.8765
2021-07-16 01:35:14,038 BAD EPOCHS (no improvement): 2
2021-07-16 01:35:14,038 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:14,570 epoch 16 - iter 1/13 - loss 0.40785187 - samples/sec: 60.24 - lr: 0.000008
2021-07-16 01:35:15,118 epoch 16 - iter 2/13 - loss 0.32539496 - samples/sec: 58.39 - lr: 0.000008
2021-07-16 01:35:15,639 epoch 16 - iter 3/13 - loss 0.33810349 - samples/sec: 61.47 - lr: 0.000008
2021-07-16 01:35:16,188 epoch 16 - iter 4/13 - loss 0.31280884 - samples/sec: 58.40 - lr: 0.000008
2021-07-16 01:35:16,719 epoch 16 - iter 5/13 - loss 0.27242382 - samples/sec: 60.29 - lr: 0.000008
2021-07-16 01:35:17,254 epoch 16 - iter 6/13 - loss 0.36158659 - samples/sec: 59.82 - lr: 0.000008
2021-07-16 01:35:17,787 epoch 16 - iter 7/13 - loss 0.35732567 - samples/sec: 60.09 - lr: 0.000008
2021-07-16 01:35:18,319 epoch 16 - iter 8/13 - loss 0.36373319 - samples/sec: 60.18 - lr: 0.000008
2021-07-16 01:35:18,844 epoch 16 - iter 9/13 - loss 0.36400946 - samples/sec: 61.06 - lr: 0.000008
2021-07-16 01:35:19,383 epoch 16 - iter 10/13 - loss 0.36195750 - samples/sec: 59.46 - lr: 0.000008
2021-07-16 01:35:19,912 epoch 16 - iter 11/13 - loss 0.37972961 - samples/sec: 60.49 - lr: 0.000008
2021-07-16 01:35:20,456 epoch 16 - iter 12/13 - loss 0.39535472 - samples/sec: 58.87 - lr: 0.000008
2021-07-16 01:35:20,864 epoch 16 - iter 13/13 - loss 0.39162620 - samples/sec: 78.47 - lr: 0.000008
2021-07-16 01:35:20,865 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:20,865 EPOCH 16 done: loss 0.3916 - lr 0.0000075
2021-07-16 01:35:21,525 DEV : loss 0.3323993384838104 - score 0.875
2021-07-16 01:35:21,534 BAD EPOCHS (no improvement): 3
2021-07-16 01:35:21,534 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:22,070 epoch 17 - iter 1/13 - loss 0.20293283 - samples/sec: 59.73 - lr: 0.000008
2021-07-16 01:35:22,618 epoch 17 - iter 2/13 - loss 0.26231670 - samples/sec: 58.41 - lr: 0.000008
2021-07-16 01:35:23,162 epoch 17 - iter 3/13 - loss 0.25252938 - samples/sec: 58.95 - lr: 0.000008
2021-07-16 01:35:23,686 epoch 17 - iter 4/13 - loss 0.27157858 - samples/sec: 61.14 - lr: 0.000008
2021-07-16 01:35:24,209 epoch 17 - iter 5/13 - loss 0.34333398 - samples/sec: 61.14 - lr: 0.000008
2021-07-16 01:35:24,755 epoch 17 - iter 6/13 - loss 0.32849628 - samples/sec: 58.65 - lr: 0.000008
2021-07-16 01:35:25,302 epoch 17 - iter 7/13 - loss 0.36351989 - samples/sec: 58.57 - lr: 0.000008
2021-07-16 01:35:25,826 epoch 17 - iter 8/13 - loss 0.36875821 - samples/sec: 61.20 - lr: 0.000008
2021-07-16 01:35:26,367 epoch 17 - iter 9/13 - loss 0.36167036 - samples/sec: 59.14 - lr: 0.000008
2021-07-16 01:35:26,904 epoch 17 - iter 10/13 - loss 0.37322085 - samples/sec: 59.68 - lr: 0.000008
2021-07-16 01:35:27,441 epoch 17 - iter 11/13 - loss 0.35475031 - samples/sec: 59.59 - lr: 0.000008
2021-07-16 01:35:27,967 epoch 17 - iter 12/13 - loss 0.34138714 - samples/sec: 60.98 - lr: 0.000008
2021-07-16 01:35:28,366 epoch 17 - iter 13/13 - loss 0.34870432 - samples/sec: 80.28 - lr: 0.000008
2021-07-16 01:35:28,366 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:28,366 EPOCH 17 done: loss 0.3487 - lr 0.0000075
2021-07-16 01:35:29,027 DEV : loss 0.33335697650909424 - score 0.875
Epoch    17: reducing learning rate of group 0 to 3.7500e-06.
2021-07-16 01:35:29,036 BAD EPOCHS (no improvement): 4
2021-07-16 01:35:29,036 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:29,563 epoch 18 - iter 1/13 - loss 0.55989355 - samples/sec: 60.73 - lr: 0.000004
2021-07-16 01:35:30,095 epoch 18 - iter 2/13 - loss 0.37744442 - samples/sec: 60.19 - lr: 0.000004
2021-07-16 01:35:30,639 epoch 18 - iter 3/13 - loss 0.38878896 - samples/sec: 58.93 - lr: 0.000004
2021-07-16 01:35:31,176 epoch 18 - iter 4/13 - loss 0.37727372 - samples/sec: 59.57 - lr: 0.000004
2021-07-16 01:35:31,708 epoch 18 - iter 5/13 - loss 0.40124320 - samples/sec: 60.23 - lr: 0.000004
2021-07-16 01:35:32,240 epoch 18 - iter 6/13 - loss 0.44898650 - samples/sec: 60.25 - lr: 0.000004
2021-07-16 01:35:32,773 epoch 18 - iter 7/13 - loss 0.42392475 - samples/sec: 60.03 - lr: 0.000004
2021-07-16 01:35:33,319 epoch 18 - iter 8/13 - loss 0.40668651 - samples/sec: 58.64 - lr: 0.000004
2021-07-16 01:35:33,846 epoch 18 - iter 9/13 - loss 0.40263985 - samples/sec: 60.84 - lr: 0.000004
2021-07-16 01:35:34,390 epoch 18 - iter 10/13 - loss 0.40755934 - samples/sec: 58.84 - lr: 0.000004
2021-07-16 01:35:34,932 epoch 18 - iter 11/13 - loss 0.41084057 - samples/sec: 59.07 - lr: 0.000004
2021-07-16 01:35:35,470 epoch 18 - iter 12/13 - loss 0.39672360 - samples/sec: 59.52 - lr: 0.000004
2021-07-16 01:35:35,870 epoch 18 - iter 13/13 - loss 0.39897460 - samples/sec: 80.13 - lr: 0.000004
2021-07-16 01:35:35,871 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:35,871 EPOCH 18 done: loss 0.3990 - lr 0.0000038
2021-07-16 01:35:36,534 DEV : loss 0.3360293209552765 - score 0.882
2021-07-16 01:35:36,543 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:35:40,393 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:40,935 epoch 19 - iter 1/13 - loss 0.47068977 - samples/sec: 59.19 - lr: 0.000004
2021-07-16 01:35:41,470 epoch 19 - iter 2/13 - loss 0.35132429 - samples/sec: 59.80 - lr: 0.000004
2021-07-16 01:35:42,007 epoch 19 - iter 3/13 - loss 0.34131976 - samples/sec: 59.65 - lr: 0.000004
2021-07-16 01:35:42,539 epoch 19 - iter 4/13 - loss 0.35584468 - samples/sec: 60.24 - lr: 0.000004
2021-07-16 01:35:43,169 epoch 19 - iter 5/13 - loss 0.38300138 - samples/sec: 50.83 - lr: 0.000004
2021-07-16 01:35:43,704 epoch 19 - iter 6/13 - loss 0.38393835 - samples/sec: 59.85 - lr: 0.000004
2021-07-16 01:35:44,235 epoch 19 - iter 7/13 - loss 0.37671280 - samples/sec: 60.26 - lr: 0.000004
2021-07-16 01:35:44,779 epoch 19 - iter 8/13 - loss 0.37812957 - samples/sec: 58.91 - lr: 0.000004
2021-07-16 01:35:45,308 epoch 19 - iter 9/13 - loss 0.36664093 - samples/sec: 60.53 - lr: 0.000004
2021-07-16 01:35:45,854 epoch 19 - iter 10/13 - loss 0.34267772 - samples/sec: 58.68 - lr: 0.000004
2021-07-16 01:35:46,387 epoch 19 - iter 11/13 - loss 0.36206869 - samples/sec: 60.13 - lr: 0.000004
2021-07-16 01:35:46,916 epoch 19 - iter 12/13 - loss 0.34863734 - samples/sec: 60.51 - lr: 0.000004
2021-07-16 01:35:47,325 epoch 19 - iter 13/13 - loss 0.35583095 - samples/sec: 78.25 - lr: 0.000004
2021-07-16 01:35:47,326 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:47,326 EPOCH 19 done: loss 0.3558 - lr 0.0000038
2021-07-16 01:35:47,987 DEV : loss 0.33418452739715576 - score 0.882
2021-07-16 01:35:47,996 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:35:51,696 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:52,231 epoch 20 - iter 1/13 - loss 0.49916726 - samples/sec: 59.83 - lr: 0.000004
2021-07-16 01:35:52,764 epoch 20 - iter 2/13 - loss 0.50948071 - samples/sec: 60.09 - lr: 0.000004
2021-07-16 01:35:53,311 epoch 20 - iter 3/13 - loss 0.48927967 - samples/sec: 58.58 - lr: 0.000004
2021-07-16 01:35:53,845 epoch 20 - iter 4/13 - loss 0.42415321 - samples/sec: 60.02 - lr: 0.000004
2021-07-16 01:35:54,383 epoch 20 - iter 5/13 - loss 0.41490099 - samples/sec: 59.54 - lr: 0.000004
2021-07-16 01:35:54,926 epoch 20 - iter 6/13 - loss 0.39582958 - samples/sec: 58.90 - lr: 0.000004
2021-07-16 01:35:55,464 epoch 20 - iter 7/13 - loss 0.36496808 - samples/sec: 59.58 - lr: 0.000004
2021-07-16 01:35:55,995 epoch 20 - iter 8/13 - loss 0.39993487 - samples/sec: 60.26 - lr: 0.000004
2021-07-16 01:35:56,538 epoch 20 - iter 9/13 - loss 0.41888768 - samples/sec: 59.08 - lr: 0.000004
2021-07-16 01:35:57,078 epoch 20 - iter 10/13 - loss 0.42262157 - samples/sec: 59.22 - lr: 0.000004
2021-07-16 01:35:57,598 epoch 20 - iter 11/13 - loss 0.40298184 - samples/sec: 61.66 - lr: 0.000004
2021-07-16 01:35:58,131 epoch 20 - iter 12/13 - loss 0.38026271 - samples/sec: 60.03 - lr: 0.000004
2021-07-16 01:35:58,543 epoch 20 - iter 13/13 - loss 0.37073382 - samples/sec: 77.76 - lr: 0.000004
2021-07-16 01:35:58,544 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:58,544 EPOCH 20 done: loss 0.3707 - lr 0.0000038
2021-07-16 01:35:59,204 DEV : loss 0.3315942883491516 - score 0.875
2021-07-16 01:35:59,213 BAD EPOCHS (no improvement): 1
2021-07-16 01:35:59,213 ----------------------------------------------------------------------------------------------------
2021-07-16 01:35:59,744 epoch 21 - iter 1/13 - loss 0.37319717 - samples/sec: 60.31 - lr: 0.000004
2021-07-16 01:36:00,259 epoch 21 - iter 2/13 - loss 0.33263315 - samples/sec: 62.24 - lr: 0.000004
2021-07-16 01:36:00,784 epoch 21 - iter 3/13 - loss 0.27863575 - samples/sec: 60.98 - lr: 0.000004
2021-07-16 01:36:01,327 epoch 21 - iter 4/13 - loss 0.28272779 - samples/sec: 58.94 - lr: 0.000004
2021-07-16 01:36:01,881 epoch 21 - iter 5/13 - loss 0.31188055 - samples/sec: 57.80 - lr: 0.000004
2021-07-16 01:36:02,414 epoch 21 - iter 6/13 - loss 0.30487720 - samples/sec: 60.19 - lr: 0.000004
2021-07-16 01:36:02,949 epoch 21 - iter 7/13 - loss 0.32436564 - samples/sec: 59.84 - lr: 0.000004
2021-07-16 01:36:03,491 epoch 21 - iter 8/13 - loss 0.32747291 - samples/sec: 59.03 - lr: 0.000004
2021-07-16 01:36:04,035 epoch 21 - iter 9/13 - loss 0.33444226 - samples/sec: 58.93 - lr: 0.000004
2021-07-16 01:36:04,573 epoch 21 - iter 10/13 - loss 0.36151632 - samples/sec: 59.49 - lr: 0.000004
2021-07-16 01:36:05,107 epoch 21 - iter 11/13 - loss 0.35559979 - samples/sec: 60.02 - lr: 0.000004
2021-07-16 01:36:05,646 epoch 21 - iter 12/13 - loss 0.36940051 - samples/sec: 59.38 - lr: 0.000004
2021-07-16 01:36:06,056 epoch 21 - iter 13/13 - loss 0.35220545 - samples/sec: 78.17 - lr: 0.000004
2021-07-16 01:36:06,056 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:06,056 EPOCH 21 done: loss 0.3522 - lr 0.0000038
2021-07-16 01:36:06,719 DEV : loss 0.3339042067527771 - score 0.882
2021-07-16 01:36:06,729 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:36:10,622 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:11,167 epoch 22 - iter 1/13 - loss 0.55683613 - samples/sec: 58.82 - lr: 0.000004
2021-07-16 01:36:11,690 epoch 22 - iter 2/13 - loss 0.40945962 - samples/sec: 61.24 - lr: 0.000004
2021-07-16 01:36:12,231 epoch 22 - iter 3/13 - loss 0.34713342 - samples/sec: 59.18 - lr: 0.000004
2021-07-16 01:36:12,767 epoch 22 - iter 4/13 - loss 0.30571053 - samples/sec: 59.79 - lr: 0.000004
2021-07-16 01:36:13,316 epoch 22 - iter 5/13 - loss 0.31615322 - samples/sec: 58.31 - lr: 0.000004
2021-07-16 01:36:13,860 epoch 22 - iter 6/13 - loss 0.29752070 - samples/sec: 58.88 - lr: 0.000004
2021-07-16 01:36:14,404 epoch 22 - iter 7/13 - loss 0.29495701 - samples/sec: 58.83 - lr: 0.000004
2021-07-16 01:36:14,949 epoch 22 - iter 8/13 - loss 0.31219535 - samples/sec: 58.77 - lr: 0.000004
2021-07-16 01:36:15,479 epoch 22 - iter 9/13 - loss 0.31562611 - samples/sec: 60.49 - lr: 0.000004
2021-07-16 01:36:16,003 epoch 22 - iter 10/13 - loss 0.30789986 - samples/sec: 61.13 - lr: 0.000004
2021-07-16 01:36:16,535 epoch 22 - iter 11/13 - loss 0.32280130 - samples/sec: 60.17 - lr: 0.000004
2021-07-16 01:36:17,076 epoch 22 - iter 12/13 - loss 0.33162842 - samples/sec: 59.18 - lr: 0.000004
2021-07-16 01:36:17,467 epoch 22 - iter 13/13 - loss 0.33644672 - samples/sec: 82.03 - lr: 0.000004
2021-07-16 01:36:17,467 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:17,467 EPOCH 22 done: loss 0.3364 - lr 0.0000038
2021-07-16 01:36:18,129 DEV : loss 0.3390278220176697 - score 0.882
2021-07-16 01:36:18,139 BAD EPOCHS (no improvement): 1
2021-07-16 01:36:18,139 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:18,664 epoch 23 - iter 1/13 - loss 0.37087017 - samples/sec: 61.02 - lr: 0.000004
2021-07-16 01:36:19,219 epoch 23 - iter 2/13 - loss 0.34817639 - samples/sec: 57.62 - lr: 0.000004
2021-07-16 01:36:19,754 epoch 23 - iter 3/13 - loss 0.40645546 - samples/sec: 59.92 - lr: 0.000004
2021-07-16 01:36:20,291 epoch 23 - iter 4/13 - loss 0.36115004 - samples/sec: 59.63 - lr: 0.000004
2021-07-16 01:36:20,824 epoch 23 - iter 5/13 - loss 0.36113471 - samples/sec: 60.09 - lr: 0.000004
2021-07-16 01:36:21,370 epoch 23 - iter 6/13 - loss 0.34703795 - samples/sec: 58.68 - lr: 0.000004
2021-07-16 01:36:21,896 epoch 23 - iter 7/13 - loss 0.33911354 - samples/sec: 60.87 - lr: 0.000004
2021-07-16 01:36:22,430 epoch 23 - iter 8/13 - loss 0.31949247 - samples/sec: 60.02 - lr: 0.000004
2021-07-16 01:36:22,963 epoch 23 - iter 9/13 - loss 0.34198709 - samples/sec: 60.09 - lr: 0.000004
2021-07-16 01:36:23,501 epoch 23 - iter 10/13 - loss 0.34906369 - samples/sec: 59.48 - lr: 0.000004
2021-07-16 01:36:24,048 epoch 23 - iter 11/13 - loss 0.34565996 - samples/sec: 58.59 - lr: 0.000004
2021-07-16 01:36:24,595 epoch 23 - iter 12/13 - loss 0.35074187 - samples/sec: 58.50 - lr: 0.000004
2021-07-16 01:36:24,997 epoch 23 - iter 13/13 - loss 0.34670288 - samples/sec: 79.65 - lr: 0.000004
2021-07-16 01:36:24,998 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:24,998 EPOCH 23 done: loss 0.3467 - lr 0.0000038
2021-07-16 01:36:25,663 DEV : loss 0.33541616797447205 - score 0.882
2021-07-16 01:36:25,672 BAD EPOCHS (no improvement): 2
2021-07-16 01:36:25,672 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:26,218 epoch 24 - iter 1/13 - loss 0.19145823 - samples/sec: 58.66 - lr: 0.000004
2021-07-16 01:36:26,762 epoch 24 - iter 2/13 - loss 0.22443938 - samples/sec: 58.88 - lr: 0.000004
2021-07-16 01:36:27,302 epoch 24 - iter 3/13 - loss 0.35567633 - samples/sec: 59.33 - lr: 0.000004
2021-07-16 01:36:27,841 epoch 24 - iter 4/13 - loss 0.35123035 - samples/sec: 59.48 - lr: 0.000004
2021-07-16 01:36:28,385 epoch 24 - iter 5/13 - loss 0.34023144 - samples/sec: 58.85 - lr: 0.000004
2021-07-16 01:36:28,916 epoch 24 - iter 6/13 - loss 0.36489073 - samples/sec: 60.32 - lr: 0.000004
2021-07-16 01:36:29,442 epoch 24 - iter 7/13 - loss 0.35179686 - samples/sec: 60.85 - lr: 0.000004
2021-07-16 01:36:29,989 epoch 24 - iter 8/13 - loss 0.36179557 - samples/sec: 58.62 - lr: 0.000004
2021-07-16 01:36:30,529 epoch 24 - iter 9/13 - loss 0.34863988 - samples/sec: 59.23 - lr: 0.000004
2021-07-16 01:36:31,045 epoch 24 - iter 10/13 - loss 0.34233183 - samples/sec: 62.09 - lr: 0.000004
2021-07-16 01:36:31,577 epoch 24 - iter 11/13 - loss 0.34835279 - samples/sec: 60.26 - lr: 0.000004
2021-07-16 01:36:32,110 epoch 24 - iter 12/13 - loss 0.33807631 - samples/sec: 60.00 - lr: 0.000004
2021-07-16 01:36:32,520 epoch 24 - iter 13/13 - loss 0.34288002 - samples/sec: 78.25 - lr: 0.000004
2021-07-16 01:36:32,520 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:32,520 EPOCH 24 done: loss 0.3429 - lr 0.0000038
2021-07-16 01:36:33,265 DEV : loss 0.33217546343803406 - score 0.882
2021-07-16 01:36:33,274 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:36:37,061 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:37,570 epoch 25 - iter 1/13 - loss 0.42972389 - samples/sec: 63.07 - lr: 0.000004
2021-07-16 01:36:38,103 epoch 25 - iter 2/13 - loss 0.44394557 - samples/sec: 60.06 - lr: 0.000004
2021-07-16 01:36:38,652 epoch 25 - iter 3/13 - loss 0.46361783 - samples/sec: 58.33 - lr: 0.000004
2021-07-16 01:36:39,201 epoch 25 - iter 4/13 - loss 0.45399847 - samples/sec: 58.38 - lr: 0.000004
2021-07-16 01:36:39,741 epoch 25 - iter 5/13 - loss 0.44423901 - samples/sec: 59.27 - lr: 0.000004
2021-07-16 01:36:40,276 epoch 25 - iter 6/13 - loss 0.40388486 - samples/sec: 59.88 - lr: 0.000004
2021-07-16 01:36:40,820 epoch 25 - iter 7/13 - loss 0.41566945 - samples/sec: 58.80 - lr: 0.000004
2021-07-16 01:36:41,364 epoch 25 - iter 8/13 - loss 0.40707294 - samples/sec: 58.89 - lr: 0.000004
2021-07-16 01:36:41,892 epoch 25 - iter 9/13 - loss 0.40059570 - samples/sec: 60.71 - lr: 0.000004
2021-07-16 01:36:42,436 epoch 25 - iter 10/13 - loss 0.38780738 - samples/sec: 58.88 - lr: 0.000004
2021-07-16 01:36:42,969 epoch 25 - iter 11/13 - loss 0.39433922 - samples/sec: 60.10 - lr: 0.000004
2021-07-16 01:36:43,492 epoch 25 - iter 12/13 - loss 0.38319902 - samples/sec: 61.19 - lr: 0.000004
2021-07-16 01:36:43,897 epoch 25 - iter 13/13 - loss 0.37336590 - samples/sec: 79.18 - lr: 0.000004
2021-07-16 01:36:43,897 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:43,897 EPOCH 25 done: loss 0.3734 - lr 0.0000038
2021-07-16 01:36:44,556 DEV : loss 0.33476921916007996 - score 0.882
2021-07-16 01:36:44,565 BAD EPOCHS (no improvement): 1
2021-07-16 01:36:44,566 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:45,086 epoch 26 - iter 1/13 - loss 0.20581585 - samples/sec: 61.53 - lr: 0.000004
2021-07-16 01:36:45,630 epoch 26 - iter 2/13 - loss 0.29814425 - samples/sec: 58.85 - lr: 0.000004
2021-07-16 01:36:46,167 epoch 26 - iter 3/13 - loss 0.29321530 - samples/sec: 59.65 - lr: 0.000004
2021-07-16 01:36:46,709 epoch 26 - iter 4/13 - loss 0.29286446 - samples/sec: 59.08 - lr: 0.000004
2021-07-16 01:36:47,242 epoch 26 - iter 5/13 - loss 0.27399055 - samples/sec: 60.16 - lr: 0.000004
2021-07-16 01:36:47,780 epoch 26 - iter 6/13 - loss 0.26993050 - samples/sec: 59.50 - lr: 0.000004
2021-07-16 01:36:48,310 epoch 26 - iter 7/13 - loss 0.26778813 - samples/sec: 60.40 - lr: 0.000004
2021-07-16 01:36:48,826 epoch 26 - iter 8/13 - loss 0.28059256 - samples/sec: 62.13 - lr: 0.000004
2021-07-16 01:36:49,365 epoch 26 - iter 9/13 - loss 0.27377179 - samples/sec: 59.40 - lr: 0.000004
2021-07-16 01:36:49,902 epoch 26 - iter 10/13 - loss 0.28992672 - samples/sec: 59.63 - lr: 0.000004
2021-07-16 01:36:50,448 epoch 26 - iter 11/13 - loss 0.27489318 - samples/sec: 58.68 - lr: 0.000004
2021-07-16 01:36:50,990 epoch 26 - iter 12/13 - loss 0.27930528 - samples/sec: 59.05 - lr: 0.000004
2021-07-16 01:36:51,401 epoch 26 - iter 13/13 - loss 0.28365214 - samples/sec: 78.02 - lr: 0.000004
2021-07-16 01:36:51,401 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:51,401 EPOCH 26 done: loss 0.2837 - lr 0.0000038
2021-07-16 01:36:52,061 DEV : loss 0.33427873253822327 - score 0.882
2021-07-16 01:36:52,070 BAD EPOCHS (no improvement): 2
2021-07-16 01:36:52,070 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:52,593 epoch 27 - iter 1/13 - loss 0.20540863 - samples/sec: 61.28 - lr: 0.000004
2021-07-16 01:36:53,128 epoch 27 - iter 2/13 - loss 0.24596232 - samples/sec: 59.89 - lr: 0.000004
2021-07-16 01:36:53,668 epoch 27 - iter 3/13 - loss 0.25107006 - samples/sec: 59.28 - lr: 0.000004
2021-07-16 01:36:54,202 epoch 27 - iter 4/13 - loss 0.24778506 - samples/sec: 59.95 - lr: 0.000004
2021-07-16 01:36:54,744 epoch 27 - iter 5/13 - loss 0.30833385 - samples/sec: 59.08 - lr: 0.000004
2021-07-16 01:36:55,258 epoch 27 - iter 6/13 - loss 0.31958196 - samples/sec: 62.31 - lr: 0.000004
2021-07-16 01:36:55,800 epoch 27 - iter 7/13 - loss 0.33252928 - samples/sec: 59.16 - lr: 0.000004
2021-07-16 01:36:56,346 epoch 27 - iter 8/13 - loss 0.33598910 - samples/sec: 58.60 - lr: 0.000004
2021-07-16 01:36:56,872 epoch 27 - iter 9/13 - loss 0.32363876 - samples/sec: 60.89 - lr: 0.000004
2021-07-16 01:36:57,412 epoch 27 - iter 10/13 - loss 0.31657849 - samples/sec: 59.36 - lr: 0.000004
2021-07-16 01:36:57,942 epoch 27 - iter 11/13 - loss 0.30210016 - samples/sec: 60.39 - lr: 0.000004
2021-07-16 01:36:58,486 epoch 27 - iter 12/13 - loss 0.29162614 - samples/sec: 58.83 - lr: 0.000004
2021-07-16 01:36:58,893 epoch 27 - iter 13/13 - loss 0.30174964 - samples/sec: 78.84 - lr: 0.000004
2021-07-16 01:36:58,893 ----------------------------------------------------------------------------------------------------
2021-07-16 01:36:58,893 EPOCH 27 done: loss 0.3017 - lr 0.0000038
2021-07-16 01:36:59,552 DEV : loss 0.3332981765270233 - score 0.882
2021-07-16 01:36:59,562 BAD EPOCHS (no improvement): 3
2021-07-16 01:36:59,562 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:00,088 epoch 28 - iter 1/13 - loss 0.45682442 - samples/sec: 60.90 - lr: 0.000004
2021-07-16 01:37:00,616 epoch 28 - iter 2/13 - loss 0.43695955 - samples/sec: 60.66 - lr: 0.000004
2021-07-16 01:37:01,160 epoch 28 - iter 3/13 - loss 0.42327439 - samples/sec: 58.87 - lr: 0.000004
2021-07-16 01:37:01,686 epoch 28 - iter 4/13 - loss 0.39446767 - samples/sec: 60.79 - lr: 0.000004
2021-07-16 01:37:02,224 epoch 28 - iter 5/13 - loss 0.41466367 - samples/sec: 59.54 - lr: 0.000004
2021-07-16 01:37:02,763 epoch 28 - iter 6/13 - loss 0.39697422 - samples/sec: 59.49 - lr: 0.000004
2021-07-16 01:37:03,302 epoch 28 - iter 7/13 - loss 0.39646320 - samples/sec: 59.35 - lr: 0.000004
2021-07-16 01:37:03,849 epoch 28 - iter 8/13 - loss 0.38825570 - samples/sec: 58.64 - lr: 0.000004
2021-07-16 01:37:04,378 epoch 28 - iter 9/13 - loss 0.36729469 - samples/sec: 60.53 - lr: 0.000004
2021-07-16 01:37:04,915 epoch 28 - iter 10/13 - loss 0.35146201 - samples/sec: 59.66 - lr: 0.000004
2021-07-16 01:37:05,462 epoch 28 - iter 11/13 - loss 0.35126329 - samples/sec: 58.52 - lr: 0.000004
2021-07-16 01:37:05,996 epoch 28 - iter 12/13 - loss 0.33949060 - samples/sec: 60.02 - lr: 0.000004
2021-07-16 01:37:06,393 epoch 28 - iter 13/13 - loss 0.35770111 - samples/sec: 80.52 - lr: 0.000004
2021-07-16 01:37:06,394 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:06,394 EPOCH 28 done: loss 0.3577 - lr 0.0000038
2021-07-16 01:37:07,053 DEV : loss 0.3320091962814331 - score 0.882
2021-07-16 01:37:07,063 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:37:10,941 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:11,479 epoch 29 - iter 1/13 - loss 0.35347793 - samples/sec: 59.53 - lr: 0.000004
2021-07-16 01:37:12,016 epoch 29 - iter 2/13 - loss 0.39218436 - samples/sec: 59.68 - lr: 0.000004
2021-07-16 01:37:12,559 epoch 29 - iter 3/13 - loss 0.39071726 - samples/sec: 59.02 - lr: 0.000004
2021-07-16 01:37:13,092 epoch 29 - iter 4/13 - loss 0.35690821 - samples/sec: 60.10 - lr: 0.000004
2021-07-16 01:37:13,626 epoch 29 - iter 5/13 - loss 0.33780800 - samples/sec: 59.93 - lr: 0.000004
2021-07-16 01:37:14,166 epoch 29 - iter 6/13 - loss 0.32807593 - samples/sec: 59.28 - lr: 0.000004
2021-07-16 01:37:14,704 epoch 29 - iter 7/13 - loss 0.32995173 - samples/sec: 59.59 - lr: 0.000004
2021-07-16 01:37:15,228 epoch 29 - iter 8/13 - loss 0.35934757 - samples/sec: 61.13 - lr: 0.000004
2021-07-16 01:37:15,759 epoch 29 - iter 9/13 - loss 0.34340384 - samples/sec: 60.33 - lr: 0.000004
2021-07-16 01:37:16,292 epoch 29 - iter 10/13 - loss 0.32718910 - samples/sec: 60.04 - lr: 0.000004
2021-07-16 01:37:16,828 epoch 29 - iter 11/13 - loss 0.32955017 - samples/sec: 59.74 - lr: 0.000004
2021-07-16 01:37:17,371 epoch 29 - iter 12/13 - loss 0.33558934 - samples/sec: 59.00 - lr: 0.000004
2021-07-16 01:37:17,777 epoch 29 - iter 13/13 - loss 0.32215703 - samples/sec: 78.93 - lr: 0.000004
2021-07-16 01:37:17,777 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:17,777 EPOCH 29 done: loss 0.3222 - lr 0.0000038
2021-07-16 01:37:18,436 DEV : loss 0.3314163088798523 - score 0.882
2021-07-16 01:37:18,445 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:37:22,292 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:22,903 epoch 30 - iter 1/13 - loss 0.31077832 - samples/sec: 52.43 - lr: 0.000004
2021-07-16 01:37:23,438 epoch 30 - iter 2/13 - loss 0.28002904 - samples/sec: 59.87 - lr: 0.000004
2021-07-16 01:37:23,963 epoch 30 - iter 3/13 - loss 0.31805741 - samples/sec: 60.93 - lr: 0.000004
2021-07-16 01:37:24,504 epoch 30 - iter 4/13 - loss 0.31402376 - samples/sec: 59.20 - lr: 0.000004
2021-07-16 01:37:25,052 epoch 30 - iter 5/13 - loss 0.28691329 - samples/sec: 58.50 - lr: 0.000004
2021-07-16 01:37:25,589 epoch 30 - iter 6/13 - loss 0.30919755 - samples/sec: 59.67 - lr: 0.000004
2021-07-16 01:37:26,136 epoch 30 - iter 7/13 - loss 0.33913878 - samples/sec: 58.54 - lr: 0.000004
2021-07-16 01:37:26,676 epoch 30 - iter 8/13 - loss 0.30871249 - samples/sec: 59.31 - lr: 0.000004
2021-07-16 01:37:27,219 epoch 30 - iter 9/13 - loss 0.29959435 - samples/sec: 59.00 - lr: 0.000004
2021-07-16 01:37:27,759 epoch 30 - iter 10/13 - loss 0.30226021 - samples/sec: 59.31 - lr: 0.000004
2021-07-16 01:37:28,312 epoch 30 - iter 11/13 - loss 0.29584014 - samples/sec: 57.89 - lr: 0.000004
2021-07-16 01:37:28,840 epoch 30 - iter 12/13 - loss 0.28548080 - samples/sec: 60.62 - lr: 0.000004
2021-07-16 01:37:29,245 epoch 30 - iter 13/13 - loss 0.28077703 - samples/sec: 79.21 - lr: 0.000004
2021-07-16 01:37:29,245 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:29,245 EPOCH 30 done: loss 0.2808 - lr 0.0000038
2021-07-16 01:37:29,905 DEV : loss 0.32908111810684204 - score 0.882
2021-07-16 01:37:29,915 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:37:33,647 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:34,180 epoch 31 - iter 1/13 - loss 0.46376234 - samples/sec: 60.13 - lr: 0.000004
2021-07-16 01:37:34,715 epoch 31 - iter 2/13 - loss 0.45473886 - samples/sec: 59.85 - lr: 0.000004
2021-07-16 01:37:35,261 epoch 31 - iter 3/13 - loss 0.35741440 - samples/sec: 58.68 - lr: 0.000004
2021-07-16 01:37:35,788 epoch 31 - iter 4/13 - loss 0.34286175 - samples/sec: 60.71 - lr: 0.000004
2021-07-16 01:37:36,327 epoch 31 - iter 5/13 - loss 0.35982187 - samples/sec: 59.46 - lr: 0.000004
2021-07-16 01:37:36,876 epoch 31 - iter 6/13 - loss 0.35085359 - samples/sec: 58.28 - lr: 0.000004
2021-07-16 01:37:37,422 epoch 31 - iter 7/13 - loss 0.39740374 - samples/sec: 58.67 - lr: 0.000004
2021-07-16 01:37:37,968 epoch 31 - iter 8/13 - loss 0.38989737 - samples/sec: 58.73 - lr: 0.000004
2021-07-16 01:37:38,515 epoch 31 - iter 9/13 - loss 0.40486904 - samples/sec: 58.49 - lr: 0.000004
2021-07-16 01:37:39,034 epoch 31 - iter 10/13 - loss 0.37326237 - samples/sec: 61.73 - lr: 0.000004
2021-07-16 01:37:39,562 epoch 31 - iter 11/13 - loss 0.38601843 - samples/sec: 60.69 - lr: 0.000004
2021-07-16 01:37:40,100 epoch 31 - iter 12/13 - loss 0.38073685 - samples/sec: 59.51 - lr: 0.000004
2021-07-16 01:37:40,510 epoch 31 - iter 13/13 - loss 0.36571836 - samples/sec: 78.22 - lr: 0.000004
2021-07-16 01:37:40,510 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:40,510 EPOCH 31 done: loss 0.3657 - lr 0.0000038
2021-07-16 01:37:41,171 DEV : loss 0.33708930015563965 - score 0.882
2021-07-16 01:37:41,180 BAD EPOCHS (no improvement): 1
2021-07-16 01:37:41,180 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:41,703 epoch 32 - iter 1/13 - loss 0.39364615 - samples/sec: 61.26 - lr: 0.000004
2021-07-16 01:37:42,228 epoch 32 - iter 2/13 - loss 0.26757337 - samples/sec: 61.06 - lr: 0.000004
2021-07-16 01:37:42,776 epoch 32 - iter 3/13 - loss 0.25208220 - samples/sec: 58.37 - lr: 0.000004
2021-07-16 01:37:43,311 epoch 32 - iter 4/13 - loss 0.23646805 - samples/sec: 59.92 - lr: 0.000004
2021-07-16 01:37:43,838 epoch 32 - iter 5/13 - loss 0.29797478 - samples/sec: 60.76 - lr: 0.000004
2021-07-16 01:37:44,382 epoch 32 - iter 6/13 - loss 0.29619288 - samples/sec: 58.88 - lr: 0.000004
2021-07-16 01:37:44,927 epoch 32 - iter 7/13 - loss 0.29964614 - samples/sec: 58.74 - lr: 0.000004
2021-07-16 01:37:45,467 epoch 32 - iter 8/13 - loss 0.30740115 - samples/sec: 59.29 - lr: 0.000004
2021-07-16 01:37:46,012 epoch 32 - iter 9/13 - loss 0.31538881 - samples/sec: 58.77 - lr: 0.000004
2021-07-16 01:37:46,564 epoch 32 - iter 10/13 - loss 0.30338013 - samples/sec: 58.09 - lr: 0.000004
2021-07-16 01:37:47,103 epoch 32 - iter 11/13 - loss 0.31651399 - samples/sec: 59.35 - lr: 0.000004
2021-07-16 01:37:47,641 epoch 32 - iter 12/13 - loss 0.31990653 - samples/sec: 59.62 - lr: 0.000004
2021-07-16 01:37:48,053 epoch 32 - iter 13/13 - loss 0.32735190 - samples/sec: 77.77 - lr: 0.000004
2021-07-16 01:37:48,053 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:48,053 EPOCH 32 done: loss 0.3274 - lr 0.0000038
2021-07-16 01:37:48,713 DEV : loss 0.33908611536026 - score 0.882
2021-07-16 01:37:48,722 BAD EPOCHS (no improvement): 2
2021-07-16 01:37:48,722 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:49,258 epoch 33 - iter 1/13 - loss 0.48770279 - samples/sec: 59.77 - lr: 0.000004
2021-07-16 01:37:49,802 epoch 33 - iter 2/13 - loss 0.36992869 - samples/sec: 58.88 - lr: 0.000004
2021-07-16 01:37:50,339 epoch 33 - iter 3/13 - loss 0.32290989 - samples/sec: 59.70 - lr: 0.000004
2021-07-16 01:37:50,854 epoch 33 - iter 4/13 - loss 0.33426998 - samples/sec: 62.12 - lr: 0.000004
2021-07-16 01:37:51,386 epoch 33 - iter 5/13 - loss 0.36197076 - samples/sec: 60.21 - lr: 0.000004
2021-07-16 01:37:51,932 epoch 33 - iter 6/13 - loss 0.38931597 - samples/sec: 58.71 - lr: 0.000004
2021-07-16 01:37:52,478 epoch 33 - iter 7/13 - loss 0.38073802 - samples/sec: 58.61 - lr: 0.000004
2021-07-16 01:37:53,016 epoch 33 - iter 8/13 - loss 0.39454290 - samples/sec: 59.49 - lr: 0.000004
2021-07-16 01:37:53,556 epoch 33 - iter 9/13 - loss 0.37609428 - samples/sec: 59.40 - lr: 0.000004
2021-07-16 01:37:54,090 epoch 33 - iter 10/13 - loss 0.36136218 - samples/sec: 59.97 - lr: 0.000004
2021-07-16 01:37:54,626 epoch 33 - iter 11/13 - loss 0.34683801 - samples/sec: 59.71 - lr: 0.000004
2021-07-16 01:37:55,171 epoch 33 - iter 12/13 - loss 0.34553654 - samples/sec: 58.82 - lr: 0.000004
2021-07-16 01:37:55,585 epoch 33 - iter 13/13 - loss 0.35129947 - samples/sec: 77.28 - lr: 0.000004
2021-07-16 01:37:55,586 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:55,586 EPOCH 33 done: loss 0.3513 - lr 0.0000038
2021-07-16 01:37:56,246 DEV : loss 0.34044164419174194 - score 0.882
2021-07-16 01:37:56,255 BAD EPOCHS (no improvement): 3
2021-07-16 01:37:56,255 ----------------------------------------------------------------------------------------------------
2021-07-16 01:37:56,788 epoch 34 - iter 1/13 - loss 0.31381989 - samples/sec: 60.09 - lr: 0.000004
2021-07-16 01:37:57,324 epoch 34 - iter 2/13 - loss 0.27659583 - samples/sec: 59.77 - lr: 0.000004
2021-07-16 01:37:57,863 epoch 34 - iter 3/13 - loss 0.28310645 - samples/sec: 59.43 - lr: 0.000004
2021-07-16 01:37:58,416 epoch 34 - iter 4/13 - loss 0.28284046 - samples/sec: 57.90 - lr: 0.000004
2021-07-16 01:37:58,951 epoch 34 - iter 5/13 - loss 0.28408816 - samples/sec: 59.91 - lr: 0.000004
2021-07-16 01:37:59,479 epoch 34 - iter 6/13 - loss 0.29234825 - samples/sec: 60.58 - lr: 0.000004
2021-07-16 01:38:00,020 epoch 34 - iter 7/13 - loss 0.28194760 - samples/sec: 59.19 - lr: 0.000004
2021-07-16 01:38:00,562 epoch 34 - iter 8/13 - loss 0.27696143 - samples/sec: 59.09 - lr: 0.000004
2021-07-16 01:38:01,107 epoch 34 - iter 9/13 - loss 0.31536528 - samples/sec: 58.84 - lr: 0.000004
2021-07-16 01:38:01,655 epoch 34 - iter 10/13 - loss 0.31549198 - samples/sec: 58.45 - lr: 0.000004
2021-07-16 01:38:02,211 epoch 34 - iter 11/13 - loss 0.29912360 - samples/sec: 57.54 - lr: 0.000004
2021-07-16 01:38:02,743 epoch 34 - iter 12/13 - loss 0.30587689 - samples/sec: 60.28 - lr: 0.000004
2021-07-16 01:38:03,144 epoch 34 - iter 13/13 - loss 0.31716975 - samples/sec: 79.90 - lr: 0.000004
2021-07-16 01:38:03,144 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:03,144 EPOCH 34 done: loss 0.3172 - lr 0.0000038
2021-07-16 01:38:03,804 DEV : loss 0.34318554401397705 - score 0.8765
Epoch    34: reducing learning rate of group 0 to 1.8750e-06.
2021-07-16 01:38:03,813 BAD EPOCHS (no improvement): 4
2021-07-16 01:38:03,813 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:03,813 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:03,813 learning rate too small - quitting training!
2021-07-16 01:38:03,813 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:04,586 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:04,586 Testing using best model ...
2021-07-16 01:38:04,586 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/spa.rst.sctb/best-model.pt
2021-07-16 01:38:07,086 0.8833	0.9464	0.9138
2021-07-16 01:38:07,086 
Results:
- F1-score (micro) 0.9138
- F1-score (macro) 0.9138

By class:
SENT       tp: 53 - fp: 7 - fn: 3 - precision: 0.8833 - recall: 0.9464 - f1-score: 0.9138
2021-07-16 01:38:07,086 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.rstdt/
2021-07-16 01:38:07,099 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.rstdt
2021-07-16 01:38:07,099 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.rstdt/sent_train.txt
2021-07-16 01:38:07,101 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.rstdt/sent_dev.txt
2021-07-16 01:38:07,104 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.rstdt/sent_test.txt
Corpus: 6143 train + 840 dev + 1956 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-16 01:38:12,548 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:12,549 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-16 01:38:12,549 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:12,550 Corpus: "Corpus: 6143 train + 840 dev + 1956 test sentences"
2021-07-16 01:38:12,550 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:12,550 Parameters:
2021-07-16 01:38:12,550  - learning_rate: "3e-05"
2021-07-16 01:38:12,550  - mini_batch_size: "32"
2021-07-16 01:38:12,550  - patience: "3"
2021-07-16 01:38:12,550  - anneal_factor: "0.5"
2021-07-16 01:38:12,550  - max_epochs: "40"
2021-07-16 01:38:12,550  - shuffle: "True"
2021-07-16 01:38:12,550  - train_with_dev: "False"
2021-07-16 01:38:12,550  - batch_growth_annealing: "False"
2021-07-16 01:38:12,550 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:12,550 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.rstdt"
2021-07-16 01:38:12,550 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:12,550 Device: cuda:0
2021-07-16 01:38:12,550 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:12,550 Embeddings storage mode: cpu
2021-07-16 01:38:12,553 ----------------------------------------------------------------------------------------------------
2021-07-16 01:38:32,212 epoch 1 - iter 19/192 - loss 6.20576157 - samples/sec: 30.93 - lr: 0.000030
2021-07-16 01:38:52,339 epoch 1 - iter 38/192 - loss 4.58314584 - samples/sec: 30.21 - lr: 0.000030
2021-07-16 01:39:11,974 epoch 1 - iter 57/192 - loss 3.65351604 - samples/sec: 30.97 - lr: 0.000030
2021-07-16 01:39:31,677 epoch 1 - iter 76/192 - loss 3.05257230 - samples/sec: 30.86 - lr: 0.000030
2021-07-16 01:39:51,279 epoch 1 - iter 95/192 - loss 2.61715643 - samples/sec: 31.02 - lr: 0.000030
2021-07-16 01:40:10,818 epoch 1 - iter 114/192 - loss 2.31472865 - samples/sec: 31.12 - lr: 0.000030
2021-07-16 01:40:30,366 epoch 1 - iter 133/192 - loss 2.07976319 - samples/sec: 31.10 - lr: 0.000030
2021-07-16 01:40:49,996 epoch 1 - iter 152/192 - loss 1.89833770 - samples/sec: 30.98 - lr: 0.000030
2021-07-16 01:41:09,675 epoch 1 - iter 171/192 - loss 1.74551032 - samples/sec: 30.90 - lr: 0.000030
2021-07-16 01:41:29,351 epoch 1 - iter 190/192 - loss 1.63150968 - samples/sec: 30.90 - lr: 0.000030
2021-07-16 01:41:31,406 ----------------------------------------------------------------------------------------------------
2021-07-16 01:41:31,407 EPOCH 1 done: loss 1.6182 - lr 0.0000300
2021-07-16 01:41:47,035 DEV : loss 0.3829819858074188 - score 0.9141
2021-07-16 01:41:47,097 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:41:47,801 ----------------------------------------------------------------------------------------------------
2021-07-16 01:41:57,755 epoch 2 - iter 19/192 - loss 0.53280415 - samples/sec: 61.09 - lr: 0.000030
2021-07-16 01:42:07,855 epoch 2 - iter 38/192 - loss 0.51861126 - samples/sec: 60.21 - lr: 0.000030
2021-07-16 01:42:17,934 epoch 2 - iter 57/192 - loss 0.51264001 - samples/sec: 60.33 - lr: 0.000030
2021-07-16 01:42:27,961 epoch 2 - iter 76/192 - loss 0.49857915 - samples/sec: 60.64 - lr: 0.000030
2021-07-16 01:42:38,001 epoch 2 - iter 95/192 - loss 0.48692274 - samples/sec: 60.57 - lr: 0.000030
2021-07-16 01:42:48,052 epoch 2 - iter 114/192 - loss 0.46358162 - samples/sec: 60.50 - lr: 0.000030
2021-07-16 01:42:58,093 epoch 2 - iter 133/192 - loss 0.45585212 - samples/sec: 60.56 - lr: 0.000030
2021-07-16 01:43:08,128 epoch 2 - iter 152/192 - loss 0.44436630 - samples/sec: 60.59 - lr: 0.000030
2021-07-16 01:43:18,178 epoch 2 - iter 171/192 - loss 0.43836231 - samples/sec: 60.51 - lr: 0.000030
2021-07-16 01:43:28,310 epoch 2 - iter 190/192 - loss 0.42932691 - samples/sec: 60.02 - lr: 0.000030
2021-07-16 01:43:29,359 ----------------------------------------------------------------------------------------------------
2021-07-16 01:43:29,360 EPOCH 2 done: loss 0.4273 - lr 0.0000300
2021-07-16 01:43:33,960 DEV : loss 0.2492658644914627 - score 0.9384
2021-07-16 01:43:34,021 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:43:37,679 ----------------------------------------------------------------------------------------------------
2021-07-16 01:43:47,744 epoch 3 - iter 19/192 - loss 0.31557054 - samples/sec: 60.42 - lr: 0.000030
2021-07-16 01:43:57,876 epoch 3 - iter 38/192 - loss 0.34282548 - samples/sec: 60.01 - lr: 0.000030
2021-07-16 01:44:08,036 epoch 3 - iter 57/192 - loss 0.33476543 - samples/sec: 59.85 - lr: 0.000030
2021-07-16 01:44:18,106 epoch 3 - iter 76/192 - loss 0.34079007 - samples/sec: 60.38 - lr: 0.000030
2021-07-16 01:44:28,191 epoch 3 - iter 95/192 - loss 0.34492002 - samples/sec: 60.30 - lr: 0.000030
2021-07-16 01:44:38,391 epoch 3 - iter 114/192 - loss 0.34340381 - samples/sec: 59.62 - lr: 0.000030
2021-07-16 01:44:48,592 epoch 3 - iter 133/192 - loss 0.33216338 - samples/sec: 59.61 - lr: 0.000030
2021-07-16 01:44:58,731 epoch 3 - iter 152/192 - loss 0.32181241 - samples/sec: 59.97 - lr: 0.000030
2021-07-16 01:45:08,858 epoch 3 - iter 171/192 - loss 0.32405106 - samples/sec: 60.04 - lr: 0.000030
2021-07-16 01:45:18,976 epoch 3 - iter 190/192 - loss 0.32252536 - samples/sec: 60.10 - lr: 0.000030
2021-07-16 01:45:20,040 ----------------------------------------------------------------------------------------------------
2021-07-16 01:45:20,041 EPOCH 3 done: loss 0.3231 - lr 0.0000300
2021-07-16 01:45:24,618 DEV : loss 0.20674210786819458 - score 0.9485
2021-07-16 01:45:24,680 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:45:28,443 ----------------------------------------------------------------------------------------------------
2021-07-16 01:45:38,560 epoch 4 - iter 19/192 - loss 0.34628180 - samples/sec: 60.11 - lr: 0.000030
2021-07-16 01:45:48,616 epoch 4 - iter 38/192 - loss 0.32028995 - samples/sec: 60.47 - lr: 0.000030
2021-07-16 01:45:58,704 epoch 4 - iter 57/192 - loss 0.30897732 - samples/sec: 60.28 - lr: 0.000030
2021-07-16 01:46:08,729 epoch 4 - iter 76/192 - loss 0.30649966 - samples/sec: 60.66 - lr: 0.000030
2021-07-16 01:46:18,761 epoch 4 - iter 95/192 - loss 0.29223184 - samples/sec: 60.61 - lr: 0.000030
2021-07-16 01:46:28,797 epoch 4 - iter 114/192 - loss 0.29194505 - samples/sec: 60.59 - lr: 0.000030
2021-07-16 01:46:38,799 epoch 4 - iter 133/192 - loss 0.28736800 - samples/sec: 60.80 - lr: 0.000030
2021-07-16 01:46:48,840 epoch 4 - iter 152/192 - loss 0.28109128 - samples/sec: 60.56 - lr: 0.000030
2021-07-16 01:46:58,858 epoch 4 - iter 171/192 - loss 0.28125468 - samples/sec: 60.70 - lr: 0.000030
2021-07-16 01:47:08,911 epoch 4 - iter 190/192 - loss 0.27872002 - samples/sec: 60.48 - lr: 0.000030
2021-07-16 01:47:09,955 ----------------------------------------------------------------------------------------------------
2021-07-16 01:47:09,956 EPOCH 4 done: loss 0.2779 - lr 0.0000300
2021-07-16 01:47:14,535 DEV : loss 0.184612438082695 - score 0.9538
2021-07-16 01:47:14,598 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:47:18,187 ----------------------------------------------------------------------------------------------------
2021-07-16 01:47:28,256 epoch 5 - iter 19/192 - loss 0.23081358 - samples/sec: 60.40 - lr: 0.000030
2021-07-16 01:47:38,347 epoch 5 - iter 38/192 - loss 0.21919710 - samples/sec: 60.26 - lr: 0.000030
2021-07-16 01:47:48,502 epoch 5 - iter 57/192 - loss 0.22232203 - samples/sec: 59.88 - lr: 0.000030
2021-07-16 01:47:58,663 epoch 5 - iter 76/192 - loss 0.23706088 - samples/sec: 59.84 - lr: 0.000030
2021-07-16 01:48:08,809 epoch 5 - iter 95/192 - loss 0.23824524 - samples/sec: 59.93 - lr: 0.000030
2021-07-16 01:48:18,879 epoch 5 - iter 114/192 - loss 0.24628072 - samples/sec: 60.39 - lr: 0.000030
2021-07-16 01:48:28,975 epoch 5 - iter 133/192 - loss 0.24037293 - samples/sec: 60.23 - lr: 0.000030
2021-07-16 01:48:39,139 epoch 5 - iter 152/192 - loss 0.23941586 - samples/sec: 59.83 - lr: 0.000030
2021-07-16 01:48:49,293 epoch 5 - iter 171/192 - loss 0.24069082 - samples/sec: 59.89 - lr: 0.000030
2021-07-16 01:48:59,407 epoch 5 - iter 190/192 - loss 0.24306089 - samples/sec: 60.12 - lr: 0.000030
2021-07-16 01:49:00,464 ----------------------------------------------------------------------------------------------------
2021-07-16 01:49:00,465 EPOCH 5 done: loss 0.2431 - lr 0.0000300
2021-07-16 01:49:05,586 DEV : loss 0.17682673037052155 - score 0.9582
2021-07-16 01:49:05,647 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:49:09,261 ----------------------------------------------------------------------------------------------------
2021-07-16 01:49:19,444 epoch 6 - iter 19/192 - loss 0.21121054 - samples/sec: 59.72 - lr: 0.000030
2021-07-16 01:49:29,536 epoch 6 - iter 38/192 - loss 0.23423860 - samples/sec: 60.25 - lr: 0.000030
2021-07-16 01:49:39,688 epoch 6 - iter 57/192 - loss 0.22269679 - samples/sec: 59.90 - lr: 0.000030
2021-07-16 01:49:49,787 epoch 6 - iter 76/192 - loss 0.21825942 - samples/sec: 60.21 - lr: 0.000030
2021-07-16 01:49:59,966 epoch 6 - iter 95/192 - loss 0.22280875 - samples/sec: 59.74 - lr: 0.000030
2021-07-16 01:50:10,103 epoch 6 - iter 114/192 - loss 0.22151196 - samples/sec: 59.99 - lr: 0.000030
2021-07-16 01:50:20,211 epoch 6 - iter 133/192 - loss 0.22140283 - samples/sec: 60.16 - lr: 0.000030
2021-07-16 01:50:30,308 epoch 6 - iter 152/192 - loss 0.22669585 - samples/sec: 60.22 - lr: 0.000030
2021-07-16 01:50:40,392 epoch 6 - iter 171/192 - loss 0.22919199 - samples/sec: 60.30 - lr: 0.000030
2021-07-16 01:50:50,490 epoch 6 - iter 190/192 - loss 0.22832009 - samples/sec: 60.22 - lr: 0.000030
2021-07-16 01:50:51,532 ----------------------------------------------------------------------------------------------------
2021-07-16 01:50:51,533 EPOCH 6 done: loss 0.2277 - lr 0.0000300
2021-07-16 01:50:56,112 DEV : loss 0.1659041941165924 - score 0.9585
2021-07-16 01:50:56,174 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:50:59,458 ----------------------------------------------------------------------------------------------------
2021-07-16 01:51:09,595 epoch 7 - iter 19/192 - loss 0.22576267 - samples/sec: 59.99 - lr: 0.000030
2021-07-16 01:51:19,671 epoch 7 - iter 38/192 - loss 0.22321466 - samples/sec: 60.35 - lr: 0.000030
2021-07-16 01:51:29,814 epoch 7 - iter 57/192 - loss 0.22083466 - samples/sec: 59.95 - lr: 0.000030
2021-07-16 01:51:39,904 epoch 7 - iter 76/192 - loss 0.21504585 - samples/sec: 60.27 - lr: 0.000030
2021-07-16 01:51:50,071 epoch 7 - iter 95/192 - loss 0.21231363 - samples/sec: 59.81 - lr: 0.000030
2021-07-16 01:52:00,130 epoch 7 - iter 114/192 - loss 0.21087657 - samples/sec: 60.45 - lr: 0.000030
2021-07-16 01:52:10,273 epoch 7 - iter 133/192 - loss 0.20810689 - samples/sec: 59.95 - lr: 0.000030
2021-07-16 01:52:20,416 epoch 7 - iter 152/192 - loss 0.20410548 - samples/sec: 59.95 - lr: 0.000030
2021-07-16 01:52:30,547 epoch 7 - iter 171/192 - loss 0.20669108 - samples/sec: 60.03 - lr: 0.000030
2021-07-16 01:52:40,654 epoch 7 - iter 190/192 - loss 0.20456931 - samples/sec: 60.16 - lr: 0.000030
2021-07-16 01:52:41,687 ----------------------------------------------------------------------------------------------------
2021-07-16 01:52:41,688 EPOCH 7 done: loss 0.2055 - lr 0.0000300
2021-07-16 01:52:46,277 DEV : loss 0.1559908539056778 - score 0.9667
2021-07-16 01:52:46,339 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 01:52:50,027 ----------------------------------------------------------------------------------------------------
2021-07-16 01:53:00,172 epoch 8 - iter 19/192 - loss 0.17155813 - samples/sec: 59.94 - lr: 0.000030
2021-07-16 01:53:10,283 epoch 8 - iter 38/192 - loss 0.19319217 - samples/sec: 60.14 - lr: 0.000030
2021-07-16 01:53:20,420 epoch 8 - iter 57/192 - loss 0.19099752 - samples/sec: 59.99 - lr: 0.000030
2021-07-16 01:53:30,461 epoch 8 - iter 76/192 - loss 0.20321275 - samples/sec: 60.56 - lr: 0.000030
2021-07-16 01:53:40,579 epoch 8 - iter 95/192 - loss 0.20327993 - samples/sec: 60.10 - lr: 0.000030
2021-07-16 01:53:50,752 epoch 8 - iter 114/192 - loss 0.20276158 - samples/sec: 59.78 - lr: 0.000030
2021-07-16 01:54:00,903 epoch 8 - iter 133/192 - loss 0.20381672 - samples/sec: 59.90 - lr: 0.000030
2021-07-16 01:54:10,979 epoch 8 - iter 152/192 - loss 0.19919816 - samples/sec: 60.35 - lr: 0.000030
2021-07-16 01:54:21,031 epoch 8 - iter 171/192 - loss 0.20092323 - samples/sec: 60.49 - lr: 0.000030
2021-07-16 01:54:31,075 epoch 8 - iter 190/192 - loss 0.20056111 - samples/sec: 60.55 - lr: 0.000030
2021-07-16 01:54:32,126 ----------------------------------------------------------------------------------------------------
2021-07-16 01:54:32,127 EPOCH 8 done: loss 0.1998 - lr 0.0000300
2021-07-16 01:54:36,701 DEV : loss 0.1477004885673523 - score 0.9645
2021-07-16 01:54:36,763 BAD EPOCHS (no improvement): 1
2021-07-16 01:54:36,763 ----------------------------------------------------------------------------------------------------
2021-07-16 01:54:46,835 epoch 9 - iter 19/192 - loss 0.22200350 - samples/sec: 60.37 - lr: 0.000030
2021-07-16 01:54:56,894 epoch 9 - iter 38/192 - loss 0.20680419 - samples/sec: 60.45 - lr: 0.000030
2021-07-16 01:55:06,951 epoch 9 - iter 57/192 - loss 0.20208296 - samples/sec: 60.47 - lr: 0.000030
2021-07-16 01:55:17,056 epoch 9 - iter 76/192 - loss 0.19810898 - samples/sec: 60.18 - lr: 0.000030
2021-07-16 01:55:27,158 epoch 9 - iter 95/192 - loss 0.18844849 - samples/sec: 60.20 - lr: 0.000030
2021-07-16 01:55:37,275 epoch 9 - iter 114/192 - loss 0.18431091 - samples/sec: 60.10 - lr: 0.000030
2021-07-16 01:55:47,456 epoch 9 - iter 133/192 - loss 0.17912292 - samples/sec: 59.73 - lr: 0.000030
2021-07-16 01:55:57,587 epoch 9 - iter 152/192 - loss 0.18426002 - samples/sec: 60.02 - lr: 0.000030
2021-07-16 01:56:07,787 epoch 9 - iter 171/192 - loss 0.18579255 - samples/sec: 59.61 - lr: 0.000030
2021-07-16 01:56:17,963 epoch 9 - iter 190/192 - loss 0.18490520 - samples/sec: 59.76 - lr: 0.000030
2021-07-16 01:56:19,016 ----------------------------------------------------------------------------------------------------
2021-07-16 01:56:19,016 EPOCH 9 done: loss 0.1848 - lr 0.0000300
2021-07-16 01:56:24,104 DEV : loss 0.14480406045913696 - score 0.9641
2021-07-16 01:56:24,166 BAD EPOCHS (no improvement): 2
2021-07-16 01:56:24,166 ----------------------------------------------------------------------------------------------------
2021-07-16 01:56:34,272 epoch 10 - iter 19/192 - loss 0.14816581 - samples/sec: 60.17 - lr: 0.000030
2021-07-16 01:56:44,416 epoch 10 - iter 38/192 - loss 0.13763811 - samples/sec: 59.94 - lr: 0.000030
2021-07-16 01:56:54,540 epoch 10 - iter 57/192 - loss 0.14866831 - samples/sec: 60.06 - lr: 0.000030
2021-07-16 01:57:04,626 epoch 10 - iter 76/192 - loss 0.15447972 - samples/sec: 60.29 - lr: 0.000030
2021-07-16 01:57:14,755 epoch 10 - iter 95/192 - loss 0.16440067 - samples/sec: 60.03 - lr: 0.000030
2021-07-16 01:57:24,883 epoch 10 - iter 114/192 - loss 0.16890298 - samples/sec: 60.04 - lr: 0.000030
2021-07-16 01:57:35,002 epoch 10 - iter 133/192 - loss 0.16991989 - samples/sec: 60.09 - lr: 0.000030
2021-07-16 01:57:45,163 epoch 10 - iter 152/192 - loss 0.17018254 - samples/sec: 59.85 - lr: 0.000030
2021-07-16 01:57:55,248 epoch 10 - iter 171/192 - loss 0.16982837 - samples/sec: 60.30 - lr: 0.000030
2021-07-16 01:58:05,376 epoch 10 - iter 190/192 - loss 0.16823157 - samples/sec: 60.03 - lr: 0.000030
2021-07-16 01:58:06,414 ----------------------------------------------------------------------------------------------------
2021-07-16 01:58:06,415 EPOCH 10 done: loss 0.1676 - lr 0.0000300
2021-07-16 01:58:10,988 DEV : loss 0.14074942469596863 - score 0.9654
2021-07-16 01:58:11,049 BAD EPOCHS (no improvement): 3
2021-07-16 01:58:11,049 ----------------------------------------------------------------------------------------------------
2021-07-16 01:58:21,172 epoch 11 - iter 19/192 - loss 0.14005681 - samples/sec: 60.07 - lr: 0.000030
2021-07-16 01:58:31,296 epoch 11 - iter 38/192 - loss 0.14582791 - samples/sec: 60.07 - lr: 0.000030
2021-07-16 01:58:41,425 epoch 11 - iter 57/192 - loss 0.12858304 - samples/sec: 60.03 - lr: 0.000030
2021-07-16 01:58:51,543 epoch 11 - iter 76/192 - loss 0.13963798 - samples/sec: 60.10 - lr: 0.000030
2021-07-16 01:59:01,643 epoch 11 - iter 95/192 - loss 0.13974812 - samples/sec: 60.21 - lr: 0.000030
2021-07-16 01:59:11,754 epoch 11 - iter 114/192 - loss 0.14777026 - samples/sec: 60.14 - lr: 0.000030
2021-07-16 01:59:21,885 epoch 11 - iter 133/192 - loss 0.14980312 - samples/sec: 60.03 - lr: 0.000030
2021-07-16 01:59:32,017 epoch 11 - iter 152/192 - loss 0.14855270 - samples/sec: 60.02 - lr: 0.000030
2021-07-16 01:59:42,146 epoch 11 - iter 171/192 - loss 0.14600972 - samples/sec: 60.03 - lr: 0.000030
2021-07-16 01:59:52,301 epoch 11 - iter 190/192 - loss 0.14940335 - samples/sec: 59.88 - lr: 0.000030
2021-07-16 01:59:53,346 ----------------------------------------------------------------------------------------------------
2021-07-16 01:59:53,346 EPOCH 11 done: loss 0.1490 - lr 0.0000300
2021-07-16 01:59:57,918 DEV : loss 0.14815643429756165 - score 0.965
Epoch    11: reducing learning rate of group 0 to 1.5000e-05.
2021-07-16 01:59:57,981 BAD EPOCHS (no improvement): 4
2021-07-16 01:59:57,981 ----------------------------------------------------------------------------------------------------
2021-07-16 02:00:08,034 epoch 12 - iter 19/192 - loss 0.16411408 - samples/sec: 60.49 - lr: 0.000015
2021-07-16 02:00:18,152 epoch 12 - iter 38/192 - loss 0.15950124 - samples/sec: 60.10 - lr: 0.000015
2021-07-16 02:00:28,292 epoch 12 - iter 57/192 - loss 0.15082884 - samples/sec: 59.97 - lr: 0.000015
2021-07-16 02:00:38,452 epoch 12 - iter 76/192 - loss 0.14355875 - samples/sec: 59.85 - lr: 0.000015
2021-07-16 02:00:48,557 epoch 12 - iter 95/192 - loss 0.14176090 - samples/sec: 60.18 - lr: 0.000015
2021-07-16 02:00:58,714 epoch 12 - iter 114/192 - loss 0.14165479 - samples/sec: 59.87 - lr: 0.000015
2021-07-16 02:01:08,864 epoch 12 - iter 133/192 - loss 0.13808505 - samples/sec: 59.91 - lr: 0.000015
2021-07-16 02:01:19,030 epoch 12 - iter 152/192 - loss 0.14377058 - samples/sec: 59.81 - lr: 0.000015
2021-07-16 02:01:29,124 epoch 12 - iter 171/192 - loss 0.14624751 - samples/sec: 60.24 - lr: 0.000015
2021-07-16 02:01:39,232 epoch 12 - iter 190/192 - loss 0.14412136 - samples/sec: 60.16 - lr: 0.000015
2021-07-16 02:01:40,287 ----------------------------------------------------------------------------------------------------
2021-07-16 02:01:40,287 EPOCH 12 done: loss 0.1440 - lr 0.0000150
2021-07-16 02:01:44,859 DEV : loss 0.13426952064037323 - score 0.9669
2021-07-16 02:01:44,921 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:01:48,735 ----------------------------------------------------------------------------------------------------
2021-07-16 02:01:58,804 epoch 13 - iter 19/192 - loss 0.12488742 - samples/sec: 60.40 - lr: 0.000015
2021-07-16 02:02:08,906 epoch 13 - iter 38/192 - loss 0.12987375 - samples/sec: 60.19 - lr: 0.000015
2021-07-16 02:02:19,051 epoch 13 - iter 57/192 - loss 0.14322452 - samples/sec: 59.94 - lr: 0.000015
2021-07-16 02:02:29,218 epoch 13 - iter 76/192 - loss 0.14441105 - samples/sec: 59.81 - lr: 0.000015
2021-07-16 02:02:39,369 epoch 13 - iter 95/192 - loss 0.13764047 - samples/sec: 59.91 - lr: 0.000015
2021-07-16 02:02:49,499 epoch 13 - iter 114/192 - loss 0.13987298 - samples/sec: 60.02 - lr: 0.000015
2021-07-16 02:02:59,623 epoch 13 - iter 133/192 - loss 0.14952046 - samples/sec: 60.06 - lr: 0.000015
2021-07-16 02:03:09,790 epoch 13 - iter 152/192 - loss 0.14611161 - samples/sec: 59.81 - lr: 0.000015
2021-07-16 02:03:19,835 epoch 13 - iter 171/192 - loss 0.14456608 - samples/sec: 60.54 - lr: 0.000015
2021-07-16 02:03:30,039 epoch 13 - iter 190/192 - loss 0.14200829 - samples/sec: 59.59 - lr: 0.000015
2021-07-16 02:03:31,096 ----------------------------------------------------------------------------------------------------
2021-07-16 02:03:31,096 EPOCH 13 done: loss 0.1422 - lr 0.0000150
2021-07-16 02:03:36,179 DEV : loss 0.14580142498016357 - score 0.9642
2021-07-16 02:03:36,241 BAD EPOCHS (no improvement): 1
2021-07-16 02:03:36,241 ----------------------------------------------------------------------------------------------------
2021-07-16 02:03:46,290 epoch 14 - iter 19/192 - loss 0.18087991 - samples/sec: 60.51 - lr: 0.000015
2021-07-16 02:03:56,446 epoch 14 - iter 38/192 - loss 0.16667224 - samples/sec: 59.87 - lr: 0.000015
2021-07-16 02:04:06,586 epoch 14 - iter 57/192 - loss 0.15543200 - samples/sec: 59.97 - lr: 0.000015
2021-07-16 02:04:16,786 epoch 14 - iter 76/192 - loss 0.14632887 - samples/sec: 59.61 - lr: 0.000015
2021-07-16 02:04:26,904 epoch 14 - iter 95/192 - loss 0.14630110 - samples/sec: 60.10 - lr: 0.000015
2021-07-16 02:04:37,048 epoch 14 - iter 114/192 - loss 0.13908800 - samples/sec: 59.94 - lr: 0.000015
2021-07-16 02:04:47,209 epoch 14 - iter 133/192 - loss 0.13993084 - samples/sec: 59.85 - lr: 0.000015
2021-07-16 02:04:57,339 epoch 14 - iter 152/192 - loss 0.14058634 - samples/sec: 60.02 - lr: 0.000015
2021-07-16 02:05:07,414 epoch 14 - iter 171/192 - loss 0.13606135 - samples/sec: 60.36 - lr: 0.000015
2021-07-16 02:05:17,524 epoch 14 - iter 190/192 - loss 0.13658900 - samples/sec: 60.15 - lr: 0.000015
2021-07-16 02:05:18,594 ----------------------------------------------------------------------------------------------------
2021-07-16 02:05:18,595 EPOCH 14 done: loss 0.1358 - lr 0.0000150
2021-07-16 02:05:23,149 DEV : loss 0.13805978000164032 - score 0.9682
2021-07-16 02:05:23,212 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:05:26,562 ----------------------------------------------------------------------------------------------------
2021-07-16 02:05:36,672 epoch 15 - iter 19/192 - loss 0.11489688 - samples/sec: 60.15 - lr: 0.000015
2021-07-16 02:05:46,768 epoch 15 - iter 38/192 - loss 0.12728858 - samples/sec: 60.23 - lr: 0.000015
2021-07-16 02:05:56,901 epoch 15 - iter 57/192 - loss 0.13206658 - samples/sec: 60.01 - lr: 0.000015
2021-07-16 02:06:07,015 epoch 15 - iter 76/192 - loss 0.12496102 - samples/sec: 60.12 - lr: 0.000015
2021-07-16 02:06:17,087 epoch 15 - iter 95/192 - loss 0.12194117 - samples/sec: 60.37 - lr: 0.000015
2021-07-16 02:06:27,103 epoch 15 - iter 114/192 - loss 0.13292397 - samples/sec: 60.71 - lr: 0.000015
2021-07-16 02:06:37,203 epoch 15 - iter 133/192 - loss 0.13399828 - samples/sec: 60.21 - lr: 0.000015
2021-07-16 02:06:47,363 epoch 15 - iter 152/192 - loss 0.13531911 - samples/sec: 59.85 - lr: 0.000015
2021-07-16 02:06:57,490 epoch 15 - iter 171/192 - loss 0.13430446 - samples/sec: 60.04 - lr: 0.000015
2021-07-16 02:07:07,536 epoch 15 - iter 190/192 - loss 0.13223994 - samples/sec: 60.53 - lr: 0.000015
2021-07-16 02:07:08,541 ----------------------------------------------------------------------------------------------------
2021-07-16 02:07:08,541 EPOCH 15 done: loss 0.1318 - lr 0.0000150
2021-07-16 02:07:13,107 DEV : loss 0.1296660155057907 - score 0.9659
2021-07-16 02:07:13,170 BAD EPOCHS (no improvement): 1
2021-07-16 02:07:13,170 ----------------------------------------------------------------------------------------------------
2021-07-16 02:07:23,144 epoch 16 - iter 19/192 - loss 0.12503024 - samples/sec: 60.97 - lr: 0.000015
2021-07-16 02:07:33,144 epoch 16 - iter 38/192 - loss 0.14158771 - samples/sec: 60.81 - lr: 0.000015
2021-07-16 02:07:43,190 epoch 16 - iter 57/192 - loss 0.12925197 - samples/sec: 60.53 - lr: 0.000015
2021-07-16 02:07:53,218 epoch 16 - iter 76/192 - loss 0.12995188 - samples/sec: 60.63 - lr: 0.000015
2021-07-16 02:08:03,259 epoch 16 - iter 95/192 - loss 0.13050634 - samples/sec: 60.56 - lr: 0.000015
2021-07-16 02:08:13,328 epoch 16 - iter 114/192 - loss 0.12658857 - samples/sec: 60.39 - lr: 0.000015
2021-07-16 02:08:23,338 epoch 16 - iter 133/192 - loss 0.12714220 - samples/sec: 60.75 - lr: 0.000015
2021-07-16 02:08:33,372 epoch 16 - iter 152/192 - loss 0.12661329 - samples/sec: 60.60 - lr: 0.000015
2021-07-16 02:08:43,354 epoch 16 - iter 171/192 - loss 0.12862089 - samples/sec: 60.92 - lr: 0.000015
2021-07-16 02:08:53,384 epoch 16 - iter 190/192 - loss 0.12860908 - samples/sec: 60.63 - lr: 0.000015
2021-07-16 02:08:54,407 ----------------------------------------------------------------------------------------------------
2021-07-16 02:08:54,408 EPOCH 16 done: loss 0.1281 - lr 0.0000150
2021-07-16 02:08:58,984 DEV : loss 0.13130377233028412 - score 0.9676
2021-07-16 02:08:59,047 BAD EPOCHS (no improvement): 2
2021-07-16 02:08:59,047 ----------------------------------------------------------------------------------------------------
2021-07-16 02:09:09,073 epoch 17 - iter 19/192 - loss 0.13547532 - samples/sec: 60.66 - lr: 0.000015
2021-07-16 02:09:19,172 epoch 17 - iter 38/192 - loss 0.14257751 - samples/sec: 60.21 - lr: 0.000015
2021-07-16 02:09:29,189 epoch 17 - iter 57/192 - loss 0.13427380 - samples/sec: 60.70 - lr: 0.000015
2021-07-16 02:09:39,287 epoch 17 - iter 76/192 - loss 0.12689179 - samples/sec: 60.21 - lr: 0.000015
2021-07-16 02:09:49,364 epoch 17 - iter 95/192 - loss 0.12740691 - samples/sec: 60.35 - lr: 0.000015
2021-07-16 02:09:59,491 epoch 17 - iter 114/192 - loss 0.13048505 - samples/sec: 60.04 - lr: 0.000015
2021-07-16 02:10:09,606 epoch 17 - iter 133/192 - loss 0.13112413 - samples/sec: 60.12 - lr: 0.000015
2021-07-16 02:10:19,700 epoch 17 - iter 152/192 - loss 0.12881606 - samples/sec: 60.24 - lr: 0.000015
2021-07-16 02:10:29,842 epoch 17 - iter 171/192 - loss 0.12693896 - samples/sec: 59.95 - lr: 0.000015
2021-07-16 02:10:39,986 epoch 17 - iter 190/192 - loss 0.12753275 - samples/sec: 59.95 - lr: 0.000015
2021-07-16 02:10:41,039 ----------------------------------------------------------------------------------------------------
2021-07-16 02:10:41,040 EPOCH 17 done: loss 0.1275 - lr 0.0000150
2021-07-16 02:10:46,141 DEV : loss 0.1257561296224594 - score 0.9675
2021-07-16 02:10:46,203 BAD EPOCHS (no improvement): 3
2021-07-16 02:10:46,204 ----------------------------------------------------------------------------------------------------
2021-07-16 02:10:56,284 epoch 18 - iter 19/192 - loss 0.10476257 - samples/sec: 60.32 - lr: 0.000015
2021-07-16 02:11:06,448 epoch 18 - iter 38/192 - loss 0.11662997 - samples/sec: 59.83 - lr: 0.000015
2021-07-16 02:11:16,582 epoch 18 - iter 57/192 - loss 0.11721382 - samples/sec: 60.00 - lr: 0.000015
2021-07-16 02:11:26,676 epoch 18 - iter 76/192 - loss 0.11254728 - samples/sec: 60.24 - lr: 0.000015
2021-07-16 02:11:36,840 epoch 18 - iter 95/192 - loss 0.11124962 - samples/sec: 59.83 - lr: 0.000015
2021-07-16 02:11:46,953 epoch 18 - iter 114/192 - loss 0.11528173 - samples/sec: 60.12 - lr: 0.000015
2021-07-16 02:11:57,080 epoch 18 - iter 133/192 - loss 0.11371998 - samples/sec: 60.05 - lr: 0.000015
2021-07-16 02:12:07,174 epoch 18 - iter 152/192 - loss 0.11604783 - samples/sec: 60.24 - lr: 0.000015
2021-07-16 02:12:17,275 epoch 18 - iter 171/192 - loss 0.11721534 - samples/sec: 60.20 - lr: 0.000015
2021-07-16 02:12:27,439 epoch 18 - iter 190/192 - loss 0.11662542 - samples/sec: 59.82 - lr: 0.000015
2021-07-16 02:12:28,479 ----------------------------------------------------------------------------------------------------
2021-07-16 02:12:28,479 EPOCH 18 done: loss 0.1163 - lr 0.0000150
2021-07-16 02:12:33,053 DEV : loss 0.1310112327337265 - score 0.9676
Epoch    18: reducing learning rate of group 0 to 7.5000e-06.
2021-07-16 02:12:33,115 BAD EPOCHS (no improvement): 4
2021-07-16 02:12:33,116 ----------------------------------------------------------------------------------------------------
2021-07-16 02:12:43,246 epoch 19 - iter 19/192 - loss 0.12527670 - samples/sec: 60.02 - lr: 0.000008
2021-07-16 02:12:53,352 epoch 19 - iter 38/192 - loss 0.11548488 - samples/sec: 60.17 - lr: 0.000008
2021-07-16 02:13:03,482 epoch 19 - iter 57/192 - loss 0.11996011 - samples/sec: 60.03 - lr: 0.000008
2021-07-16 02:13:13,607 epoch 19 - iter 76/192 - loss 0.12012226 - samples/sec: 60.06 - lr: 0.000008
2021-07-16 02:13:23,782 epoch 19 - iter 95/192 - loss 0.12049150 - samples/sec: 59.76 - lr: 0.000008
2021-07-16 02:13:33,936 epoch 19 - iter 114/192 - loss 0.11582808 - samples/sec: 59.89 - lr: 0.000008
2021-07-16 02:13:44,091 epoch 19 - iter 133/192 - loss 0.11662125 - samples/sec: 59.88 - lr: 0.000008
2021-07-16 02:13:54,218 epoch 19 - iter 152/192 - loss 0.11363107 - samples/sec: 60.04 - lr: 0.000008
2021-07-16 02:14:04,297 epoch 19 - iter 171/192 - loss 0.11200173 - samples/sec: 60.33 - lr: 0.000008
2021-07-16 02:14:14,407 epoch 19 - iter 190/192 - loss 0.11339491 - samples/sec: 60.15 - lr: 0.000008
2021-07-16 02:14:15,459 ----------------------------------------------------------------------------------------------------
2021-07-16 02:14:15,460 EPOCH 19 done: loss 0.1139 - lr 0.0000075
2021-07-16 02:14:20,022 DEV : loss 0.12746401131153107 - score 0.9682
2021-07-16 02:14:20,084 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:14:23,531 ----------------------------------------------------------------------------------------------------
2021-07-16 02:14:33,685 epoch 20 - iter 19/192 - loss 0.09538759 - samples/sec: 59.89 - lr: 0.000008
2021-07-16 02:14:43,764 epoch 20 - iter 38/192 - loss 0.10546703 - samples/sec: 60.33 - lr: 0.000008
2021-07-16 02:14:53,915 epoch 20 - iter 57/192 - loss 0.10901153 - samples/sec: 59.90 - lr: 0.000008
2021-07-16 02:15:04,119 epoch 20 - iter 76/192 - loss 0.11059554 - samples/sec: 59.59 - lr: 0.000008
2021-07-16 02:15:14,252 epoch 20 - iter 95/192 - loss 0.10784357 - samples/sec: 60.01 - lr: 0.000008
2021-07-16 02:15:24,298 epoch 20 - iter 114/192 - loss 0.11154650 - samples/sec: 60.53 - lr: 0.000008
2021-07-16 02:15:34,396 epoch 20 - iter 133/192 - loss 0.10998616 - samples/sec: 60.22 - lr: 0.000008
2021-07-16 02:15:44,497 epoch 20 - iter 152/192 - loss 0.11101081 - samples/sec: 60.20 - lr: 0.000008
2021-07-16 02:15:54,608 epoch 20 - iter 171/192 - loss 0.10878638 - samples/sec: 60.14 - lr: 0.000008
2021-07-16 02:16:04,730 epoch 20 - iter 190/192 - loss 0.10725899 - samples/sec: 60.08 - lr: 0.000008
2021-07-16 02:16:05,768 ----------------------------------------------------------------------------------------------------
2021-07-16 02:16:05,768 EPOCH 20 done: loss 0.1073 - lr 0.0000075
2021-07-16 02:16:10,326 DEV : loss 0.12638813257217407 - score 0.9675
2021-07-16 02:16:10,388 BAD EPOCHS (no improvement): 1
2021-07-16 02:16:10,388 ----------------------------------------------------------------------------------------------------
2021-07-16 02:16:20,531 epoch 21 - iter 19/192 - loss 0.11217485 - samples/sec: 59.96 - lr: 0.000008
2021-07-16 02:16:30,647 epoch 21 - iter 38/192 - loss 0.11404813 - samples/sec: 60.11 - lr: 0.000008
2021-07-16 02:16:40,708 epoch 21 - iter 57/192 - loss 0.10558342 - samples/sec: 60.44 - lr: 0.000008
2021-07-16 02:16:50,808 epoch 21 - iter 76/192 - loss 0.10065225 - samples/sec: 60.21 - lr: 0.000008
2021-07-16 02:17:00,914 epoch 21 - iter 95/192 - loss 0.10014531 - samples/sec: 60.17 - lr: 0.000008
2021-07-16 02:17:11,052 epoch 21 - iter 114/192 - loss 0.10575145 - samples/sec: 59.98 - lr: 0.000008
2021-07-16 02:17:21,208 epoch 21 - iter 133/192 - loss 0.10744367 - samples/sec: 59.88 - lr: 0.000008
2021-07-16 02:17:31,867 epoch 21 - iter 152/192 - loss 0.10544329 - samples/sec: 57.04 - lr: 0.000008
2021-07-16 02:17:42,065 epoch 21 - iter 171/192 - loss 0.10777215 - samples/sec: 59.63 - lr: 0.000008
2021-07-16 02:17:52,183 epoch 21 - iter 190/192 - loss 0.10776038 - samples/sec: 60.10 - lr: 0.000008
2021-07-16 02:17:53,236 ----------------------------------------------------------------------------------------------------
2021-07-16 02:17:53,236 EPOCH 21 done: loss 0.1078 - lr 0.0000075
2021-07-16 02:17:57,818 DEV : loss 0.12673217058181763 - score 0.9669
2021-07-16 02:17:57,882 BAD EPOCHS (no improvement): 2
2021-07-16 02:17:57,882 ----------------------------------------------------------------------------------------------------
2021-07-16 02:18:07,977 epoch 22 - iter 19/192 - loss 0.10161968 - samples/sec: 60.24 - lr: 0.000008
2021-07-16 02:18:18,115 epoch 22 - iter 38/192 - loss 0.10260564 - samples/sec: 59.98 - lr: 0.000008
2021-07-16 02:18:28,278 epoch 22 - iter 57/192 - loss 0.09773155 - samples/sec: 59.84 - lr: 0.000008
2021-07-16 02:18:38,356 epoch 22 - iter 76/192 - loss 0.10174626 - samples/sec: 60.33 - lr: 0.000008
2021-07-16 02:18:48,476 epoch 22 - iter 95/192 - loss 0.09821875 - samples/sec: 60.09 - lr: 0.000008
2021-07-16 02:18:58,643 epoch 22 - iter 114/192 - loss 0.09648120 - samples/sec: 59.81 - lr: 0.000008
2021-07-16 02:19:08,736 epoch 22 - iter 133/192 - loss 0.09648847 - samples/sec: 60.25 - lr: 0.000008
2021-07-16 02:19:18,892 epoch 22 - iter 152/192 - loss 0.09806531 - samples/sec: 59.88 - lr: 0.000008
2021-07-16 02:19:28,969 epoch 22 - iter 171/192 - loss 0.10037895 - samples/sec: 60.34 - lr: 0.000008
2021-07-16 02:19:39,092 epoch 22 - iter 190/192 - loss 0.10318928 - samples/sec: 60.07 - lr: 0.000008
2021-07-16 02:19:40,137 ----------------------------------------------------------------------------------------------------
2021-07-16 02:19:40,137 EPOCH 22 done: loss 0.1032 - lr 0.0000075
2021-07-16 02:19:44,704 DEV : loss 0.12619653344154358 - score 0.9689
2021-07-16 02:19:44,766 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:19:48,492 ----------------------------------------------------------------------------------------------------
2021-07-16 02:19:58,642 epoch 23 - iter 19/192 - loss 0.11782076 - samples/sec: 59.91 - lr: 0.000008
2021-07-16 02:20:08,786 epoch 23 - iter 38/192 - loss 0.11296596 - samples/sec: 59.95 - lr: 0.000008
2021-07-16 02:20:18,888 epoch 23 - iter 57/192 - loss 0.11018337 - samples/sec: 60.19 - lr: 0.000008
2021-07-16 02:20:28,915 epoch 23 - iter 76/192 - loss 0.11434545 - samples/sec: 60.64 - lr: 0.000008
2021-07-16 02:20:38,982 epoch 23 - iter 95/192 - loss 0.10826863 - samples/sec: 60.40 - lr: 0.000008
2021-07-16 02:20:49,158 epoch 23 - iter 114/192 - loss 0.10725249 - samples/sec: 59.76 - lr: 0.000008
2021-07-16 02:20:59,300 epoch 23 - iter 133/192 - loss 0.10700195 - samples/sec: 59.96 - lr: 0.000008
2021-07-16 02:21:09,404 epoch 23 - iter 152/192 - loss 0.10399990 - samples/sec: 60.18 - lr: 0.000008
2021-07-16 02:21:19,500 epoch 23 - iter 171/192 - loss 0.10864302 - samples/sec: 60.23 - lr: 0.000008
2021-07-16 02:21:29,661 epoch 23 - iter 190/192 - loss 0.10785742 - samples/sec: 59.85 - lr: 0.000008
2021-07-16 02:21:30,725 ----------------------------------------------------------------------------------------------------
2021-07-16 02:21:30,725 EPOCH 23 done: loss 0.1080 - lr 0.0000075
2021-07-16 02:21:35,302 DEV : loss 0.13045640289783478 - score 0.9668
2021-07-16 02:21:35,365 BAD EPOCHS (no improvement): 1
2021-07-16 02:21:35,365 ----------------------------------------------------------------------------------------------------
2021-07-16 02:21:45,523 epoch 24 - iter 19/192 - loss 0.10341611 - samples/sec: 59.87 - lr: 0.000008
2021-07-16 02:21:55,623 epoch 24 - iter 38/192 - loss 0.10179846 - samples/sec: 60.20 - lr: 0.000008
2021-07-16 02:22:05,770 epoch 24 - iter 57/192 - loss 0.09901788 - samples/sec: 59.93 - lr: 0.000008
2021-07-16 02:22:15,924 epoch 24 - iter 76/192 - loss 0.09778277 - samples/sec: 59.89 - lr: 0.000008
2021-07-16 02:22:25,916 epoch 24 - iter 95/192 - loss 0.10302807 - samples/sec: 60.85 - lr: 0.000008
2021-07-16 02:22:36,015 epoch 24 - iter 114/192 - loss 0.10323223 - samples/sec: 60.21 - lr: 0.000008
2021-07-16 02:22:46,130 epoch 24 - iter 133/192 - loss 0.10088402 - samples/sec: 60.12 - lr: 0.000008
2021-07-16 02:22:56,329 epoch 24 - iter 152/192 - loss 0.10141266 - samples/sec: 59.62 - lr: 0.000008
2021-07-16 02:23:06,485 epoch 24 - iter 171/192 - loss 0.10090895 - samples/sec: 59.88 - lr: 0.000008
2021-07-16 02:23:16,607 epoch 24 - iter 190/192 - loss 0.10114217 - samples/sec: 60.07 - lr: 0.000008
2021-07-16 02:23:17,671 ----------------------------------------------------------------------------------------------------
2021-07-16 02:23:17,671 EPOCH 24 done: loss 0.1011 - lr 0.0000075
2021-07-16 02:23:22,244 DEV : loss 0.12591874599456787 - score 0.9691
2021-07-16 02:23:22,307 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:23:25,707 ----------------------------------------------------------------------------------------------------
2021-07-16 02:23:35,800 epoch 25 - iter 19/192 - loss 0.10740236 - samples/sec: 60.25 - lr: 0.000008
2021-07-16 02:23:45,972 epoch 25 - iter 38/192 - loss 0.11552602 - samples/sec: 59.78 - lr: 0.000008
2021-07-16 02:23:56,124 epoch 25 - iter 57/192 - loss 0.10896354 - samples/sec: 59.90 - lr: 0.000008
2021-07-16 02:24:06,307 epoch 25 - iter 76/192 - loss 0.10700552 - samples/sec: 59.72 - lr: 0.000008
2021-07-16 02:24:16,446 epoch 25 - iter 95/192 - loss 0.10230394 - samples/sec: 59.97 - lr: 0.000008
2021-07-16 02:24:26,542 epoch 25 - iter 114/192 - loss 0.10326362 - samples/sec: 60.23 - lr: 0.000008
2021-07-16 02:24:37,229 epoch 25 - iter 133/192 - loss 0.09895578 - samples/sec: 56.90 - lr: 0.000008
2021-07-16 02:24:47,300 epoch 25 - iter 152/192 - loss 0.09936854 - samples/sec: 60.38 - lr: 0.000008
2021-07-16 02:24:57,403 epoch 25 - iter 171/192 - loss 0.09980674 - samples/sec: 60.19 - lr: 0.000008
2021-07-16 02:25:07,470 epoch 25 - iter 190/192 - loss 0.09864321 - samples/sec: 60.40 - lr: 0.000008
2021-07-16 02:25:08,522 ----------------------------------------------------------------------------------------------------
2021-07-16 02:25:08,523 EPOCH 25 done: loss 0.0992 - lr 0.0000075
2021-07-16 02:25:13,081 DEV : loss 0.12294867634773254 - score 0.971
2021-07-16 02:25:13,144 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:25:16,851 ----------------------------------------------------------------------------------------------------
2021-07-16 02:25:26,979 epoch 26 - iter 19/192 - loss 0.09407434 - samples/sec: 60.04 - lr: 0.000008
2021-07-16 02:25:37,175 epoch 26 - iter 38/192 - loss 0.09232780 - samples/sec: 59.64 - lr: 0.000008
2021-07-16 02:25:47,284 epoch 26 - iter 57/192 - loss 0.09383110 - samples/sec: 60.15 - lr: 0.000008
2021-07-16 02:25:57,447 epoch 26 - iter 76/192 - loss 0.09318275 - samples/sec: 59.84 - lr: 0.000008
2021-07-16 02:26:07,542 epoch 26 - iter 95/192 - loss 0.09711159 - samples/sec: 60.23 - lr: 0.000008
2021-07-16 02:26:17,612 epoch 26 - iter 114/192 - loss 0.09982789 - samples/sec: 60.38 - lr: 0.000008
2021-07-16 02:26:27,714 epoch 26 - iter 133/192 - loss 0.09919651 - samples/sec: 60.20 - lr: 0.000008
2021-07-16 02:26:37,775 epoch 26 - iter 152/192 - loss 0.09697806 - samples/sec: 60.44 - lr: 0.000008
2021-07-16 02:26:47,828 epoch 26 - iter 171/192 - loss 0.09845305 - samples/sec: 60.49 - lr: 0.000008
2021-07-16 02:26:57,972 epoch 26 - iter 190/192 - loss 0.09685909 - samples/sec: 59.95 - lr: 0.000008
2021-07-16 02:26:59,019 ----------------------------------------------------------------------------------------------------
2021-07-16 02:26:59,019 EPOCH 26 done: loss 0.0974 - lr 0.0000075
2021-07-16 02:27:03,585 DEV : loss 0.12421845644712448 - score 0.9689
2021-07-16 02:27:03,648 BAD EPOCHS (no improvement): 1
2021-07-16 02:27:03,648 ----------------------------------------------------------------------------------------------------
2021-07-16 02:27:13,728 epoch 27 - iter 19/192 - loss 0.10715961 - samples/sec: 60.32 - lr: 0.000008
2021-07-16 02:27:23,840 epoch 27 - iter 38/192 - loss 0.11320819 - samples/sec: 60.13 - lr: 0.000008
2021-07-16 02:27:33,952 epoch 27 - iter 57/192 - loss 0.10899207 - samples/sec: 60.13 - lr: 0.000008
2021-07-16 02:27:44,068 epoch 27 - iter 76/192 - loss 0.10060114 - samples/sec: 60.11 - lr: 0.000008
2021-07-16 02:27:54,125 epoch 27 - iter 95/192 - loss 0.09963248 - samples/sec: 60.46 - lr: 0.000008
2021-07-16 02:28:04,260 epoch 27 - iter 114/192 - loss 0.09692359 - samples/sec: 60.00 - lr: 0.000008
2021-07-16 02:28:14,388 epoch 27 - iter 133/192 - loss 0.09770018 - samples/sec: 60.04 - lr: 0.000008
2021-07-16 02:28:24,458 epoch 27 - iter 152/192 - loss 0.09656737 - samples/sec: 60.38 - lr: 0.000008
2021-07-16 02:28:34,538 epoch 27 - iter 171/192 - loss 0.09548323 - samples/sec: 60.33 - lr: 0.000008
2021-07-16 02:28:44,606 epoch 27 - iter 190/192 - loss 0.09769362 - samples/sec: 60.40 - lr: 0.000008
2021-07-16 02:28:45,633 ----------------------------------------------------------------------------------------------------
2021-07-16 02:28:45,634 EPOCH 27 done: loss 0.0988 - lr 0.0000075
2021-07-16 02:28:50,202 DEV : loss 0.11762737482786179 - score 0.9715
2021-07-16 02:28:50,265 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:28:53,914 ----------------------------------------------------------------------------------------------------
2021-07-16 02:29:03,966 epoch 28 - iter 19/192 - loss 0.07304202 - samples/sec: 60.50 - lr: 0.000008
2021-07-16 02:29:14,018 epoch 28 - iter 38/192 - loss 0.08640531 - samples/sec: 60.49 - lr: 0.000008
2021-07-16 02:29:24,055 epoch 28 - iter 57/192 - loss 0.09236911 - samples/sec: 60.58 - lr: 0.000008
2021-07-16 02:29:34,103 epoch 28 - iter 76/192 - loss 0.08936083 - samples/sec: 60.52 - lr: 0.000008
2021-07-16 02:29:44,255 epoch 28 - iter 95/192 - loss 0.08960237 - samples/sec: 59.90 - lr: 0.000008
2021-07-16 02:29:54,398 epoch 28 - iter 114/192 - loss 0.09356179 - samples/sec: 59.95 - lr: 0.000008
2021-07-16 02:30:04,492 epoch 28 - iter 133/192 - loss 0.09353773 - samples/sec: 60.24 - lr: 0.000008
2021-07-16 02:30:14,565 epoch 28 - iter 152/192 - loss 0.09405495 - samples/sec: 60.36 - lr: 0.000008
2021-07-16 02:30:24,599 epoch 28 - iter 171/192 - loss 0.09523009 - samples/sec: 60.60 - lr: 0.000008
2021-07-16 02:30:34,697 epoch 28 - iter 190/192 - loss 0.09770198 - samples/sec: 60.22 - lr: 0.000008
2021-07-16 02:30:35,750 ----------------------------------------------------------------------------------------------------
2021-07-16 02:30:35,750 EPOCH 28 done: loss 0.0981 - lr 0.0000075
2021-07-16 02:30:40,856 DEV : loss 0.1213650330901146 - score 0.9689
2021-07-16 02:30:40,918 BAD EPOCHS (no improvement): 1
2021-07-16 02:30:40,918 ----------------------------------------------------------------------------------------------------
2021-07-16 02:30:50,995 epoch 29 - iter 19/192 - loss 0.10574838 - samples/sec: 60.35 - lr: 0.000008
2021-07-16 02:31:01,128 epoch 29 - iter 38/192 - loss 0.09834978 - samples/sec: 60.01 - lr: 0.000008
2021-07-16 02:31:11,226 epoch 29 - iter 57/192 - loss 0.09556366 - samples/sec: 60.21 - lr: 0.000008
2021-07-16 02:31:21,342 epoch 29 - iter 76/192 - loss 0.09187840 - samples/sec: 60.11 - lr: 0.000008
2021-07-16 02:31:31,374 epoch 29 - iter 95/192 - loss 0.09148239 - samples/sec: 60.61 - lr: 0.000008
2021-07-16 02:31:41,491 epoch 29 - iter 114/192 - loss 0.09339267 - samples/sec: 60.11 - lr: 0.000008
2021-07-16 02:31:51,531 epoch 29 - iter 133/192 - loss 0.09348016 - samples/sec: 60.57 - lr: 0.000008
2021-07-16 02:32:01,623 epoch 29 - iter 152/192 - loss 0.09396936 - samples/sec: 60.25 - lr: 0.000008
2021-07-16 02:32:11,684 epoch 29 - iter 171/192 - loss 0.09474557 - samples/sec: 60.44 - lr: 0.000008
2021-07-16 02:32:21,763 epoch 29 - iter 190/192 - loss 0.09318028 - samples/sec: 60.33 - lr: 0.000008
2021-07-16 02:32:22,823 ----------------------------------------------------------------------------------------------------
2021-07-16 02:32:22,823 EPOCH 29 done: loss 0.0925 - lr 0.0000075
2021-07-16 02:32:27,401 DEV : loss 0.11910191178321838 - score 0.9696
2021-07-16 02:32:27,463 BAD EPOCHS (no improvement): 2
2021-07-16 02:32:27,464 ----------------------------------------------------------------------------------------------------
2021-07-16 02:32:37,552 epoch 30 - iter 19/192 - loss 0.07379389 - samples/sec: 60.27 - lr: 0.000008
2021-07-16 02:32:47,697 epoch 30 - iter 38/192 - loss 0.08663014 - samples/sec: 59.94 - lr: 0.000008
2021-07-16 02:32:57,762 epoch 30 - iter 57/192 - loss 0.08601325 - samples/sec: 60.41 - lr: 0.000008
2021-07-16 02:33:07,857 epoch 30 - iter 76/192 - loss 0.08744350 - samples/sec: 60.23 - lr: 0.000008
2021-07-16 02:33:17,915 epoch 30 - iter 95/192 - loss 0.08713462 - samples/sec: 60.46 - lr: 0.000008
2021-07-16 02:33:27,983 epoch 30 - iter 114/192 - loss 0.08653098 - samples/sec: 60.40 - lr: 0.000008
2021-07-16 02:33:38,031 epoch 30 - iter 133/192 - loss 0.08999959 - samples/sec: 60.52 - lr: 0.000008
2021-07-16 02:33:48,181 epoch 30 - iter 152/192 - loss 0.08877499 - samples/sec: 59.91 - lr: 0.000008
2021-07-16 02:33:58,265 epoch 30 - iter 171/192 - loss 0.08815002 - samples/sec: 60.30 - lr: 0.000008
2021-07-16 02:34:08,224 epoch 30 - iter 190/192 - loss 0.08865421 - samples/sec: 61.06 - lr: 0.000008
2021-07-16 02:34:09,267 ----------------------------------------------------------------------------------------------------
2021-07-16 02:34:09,267 EPOCH 30 done: loss 0.0887 - lr 0.0000075
2021-07-16 02:34:13,836 DEV : loss 0.1287999004125595 - score 0.9676
2021-07-16 02:34:13,899 BAD EPOCHS (no improvement): 3
2021-07-16 02:34:13,899 ----------------------------------------------------------------------------------------------------
2021-07-16 02:34:23,942 epoch 31 - iter 19/192 - loss 0.10438964 - samples/sec: 60.55 - lr: 0.000008
2021-07-16 02:34:33,952 epoch 31 - iter 38/192 - loss 0.11018688 - samples/sec: 60.75 - lr: 0.000008
2021-07-16 02:34:44,036 epoch 31 - iter 57/192 - loss 0.10386341 - samples/sec: 60.30 - lr: 0.000008
2021-07-16 02:34:54,153 epoch 31 - iter 76/192 - loss 0.10361485 - samples/sec: 60.11 - lr: 0.000008
2021-07-16 02:35:04,271 epoch 31 - iter 95/192 - loss 0.10187851 - samples/sec: 60.10 - lr: 0.000008
2021-07-16 02:35:14,410 epoch 31 - iter 114/192 - loss 0.10340725 - samples/sec: 59.97 - lr: 0.000008
2021-07-16 02:35:24,523 epoch 31 - iter 133/192 - loss 0.10120561 - samples/sec: 60.13 - lr: 0.000008
2021-07-16 02:35:34,607 epoch 31 - iter 152/192 - loss 0.10053427 - samples/sec: 60.31 - lr: 0.000008
2021-07-16 02:35:44,638 epoch 31 - iter 171/192 - loss 0.09743613 - samples/sec: 60.62 - lr: 0.000008
2021-07-16 02:35:54,679 epoch 31 - iter 190/192 - loss 0.09570009 - samples/sec: 60.56 - lr: 0.000008
2021-07-16 02:35:55,742 ----------------------------------------------------------------------------------------------------
2021-07-16 02:35:55,743 EPOCH 31 done: loss 0.0951 - lr 0.0000075
2021-07-16 02:36:00,314 DEV : loss 0.12236826866865158 - score 0.9689
Epoch    31: reducing learning rate of group 0 to 3.7500e-06.
2021-07-16 02:36:00,376 BAD EPOCHS (no improvement): 4
2021-07-16 02:36:00,377 ----------------------------------------------------------------------------------------------------
2021-07-16 02:36:10,472 epoch 32 - iter 19/192 - loss 0.09223851 - samples/sec: 60.24 - lr: 0.000004
2021-07-16 02:36:20,628 epoch 32 - iter 38/192 - loss 0.07851715 - samples/sec: 59.87 - lr: 0.000004
2021-07-16 02:36:30,760 epoch 32 - iter 57/192 - loss 0.07846097 - samples/sec: 60.01 - lr: 0.000004
2021-07-16 02:36:40,867 epoch 32 - iter 76/192 - loss 0.07580800 - samples/sec: 60.16 - lr: 0.000004
2021-07-16 02:36:50,939 epoch 32 - iter 95/192 - loss 0.08309145 - samples/sec: 60.38 - lr: 0.000004
2021-07-16 02:37:01,014 epoch 32 - iter 114/192 - loss 0.08392031 - samples/sec: 60.36 - lr: 0.000004
2021-07-16 02:37:11,150 epoch 32 - iter 133/192 - loss 0.08159076 - samples/sec: 59.99 - lr: 0.000004
2021-07-16 02:37:21,187 epoch 32 - iter 152/192 - loss 0.08265411 - samples/sec: 60.58 - lr: 0.000004
2021-07-16 02:37:31,251 epoch 32 - iter 171/192 - loss 0.08267282 - samples/sec: 60.42 - lr: 0.000004
2021-07-16 02:37:41,330 epoch 32 - iter 190/192 - loss 0.08212067 - samples/sec: 60.33 - lr: 0.000004
2021-07-16 02:37:42,326 ----------------------------------------------------------------------------------------------------
2021-07-16 02:37:42,326 EPOCH 32 done: loss 0.0818 - lr 0.0000038
2021-07-16 02:37:47,416 DEV : loss 0.12348230928182602 - score 0.9682
2021-07-16 02:37:47,479 BAD EPOCHS (no improvement): 1
2021-07-16 02:37:47,479 ----------------------------------------------------------------------------------------------------
2021-07-16 02:37:57,534 epoch 33 - iter 19/192 - loss 0.09187839 - samples/sec: 60.48 - lr: 0.000004
2021-07-16 02:38:07,616 epoch 33 - iter 38/192 - loss 0.08356438 - samples/sec: 60.32 - lr: 0.000004
2021-07-16 02:38:17,775 epoch 33 - iter 57/192 - loss 0.07599412 - samples/sec: 59.85 - lr: 0.000004
2021-07-16 02:38:27,903 epoch 33 - iter 76/192 - loss 0.07638373 - samples/sec: 60.04 - lr: 0.000004
2021-07-16 02:38:38,063 epoch 33 - iter 95/192 - loss 0.07913776 - samples/sec: 59.85 - lr: 0.000004
2021-07-16 02:38:48,199 epoch 33 - iter 114/192 - loss 0.08012551 - samples/sec: 59.99 - lr: 0.000004
2021-07-16 02:38:58,338 epoch 33 - iter 133/192 - loss 0.08230698 - samples/sec: 59.97 - lr: 0.000004
2021-07-16 02:39:08,496 epoch 33 - iter 152/192 - loss 0.08468939 - samples/sec: 59.86 - lr: 0.000004
2021-07-16 02:39:18,628 epoch 33 - iter 171/192 - loss 0.08348640 - samples/sec: 60.02 - lr: 0.000004
2021-07-16 02:39:28,662 epoch 33 - iter 190/192 - loss 0.08266355 - samples/sec: 60.60 - lr: 0.000004
2021-07-16 02:39:29,712 ----------------------------------------------------------------------------------------------------
2021-07-16 02:39:29,712 EPOCH 33 done: loss 0.0830 - lr 0.0000038
2021-07-16 02:39:34,286 DEV : loss 0.12554803490638733 - score 0.9703
2021-07-16 02:39:34,348 BAD EPOCHS (no improvement): 2
2021-07-16 02:39:34,348 ----------------------------------------------------------------------------------------------------
2021-07-16 02:39:44,420 epoch 34 - iter 19/192 - loss 0.06188335 - samples/sec: 60.38 - lr: 0.000004
2021-07-16 02:39:54,543 epoch 34 - iter 38/192 - loss 0.07202520 - samples/sec: 60.07 - lr: 0.000004
2021-07-16 02:40:04,684 epoch 34 - iter 57/192 - loss 0.07487309 - samples/sec: 59.96 - lr: 0.000004
2021-07-16 02:40:14,843 epoch 34 - iter 76/192 - loss 0.08150745 - samples/sec: 59.85 - lr: 0.000004
2021-07-16 02:40:24,980 epoch 34 - iter 95/192 - loss 0.08024928 - samples/sec: 59.99 - lr: 0.000004
2021-07-16 02:40:35,111 epoch 34 - iter 114/192 - loss 0.07896488 - samples/sec: 60.02 - lr: 0.000004
2021-07-16 02:40:45,248 epoch 34 - iter 133/192 - loss 0.07935188 - samples/sec: 59.99 - lr: 0.000004
2021-07-16 02:40:55,400 epoch 34 - iter 152/192 - loss 0.07937982 - samples/sec: 59.90 - lr: 0.000004
2021-07-16 02:41:05,523 epoch 34 - iter 171/192 - loss 0.07730202 - samples/sec: 60.07 - lr: 0.000004
2021-07-16 02:41:15,629 epoch 34 - iter 190/192 - loss 0.08010134 - samples/sec: 60.17 - lr: 0.000004
2021-07-16 02:41:16,697 ----------------------------------------------------------------------------------------------------
2021-07-16 02:41:16,697 EPOCH 34 done: loss 0.0800 - lr 0.0000038
2021-07-16 02:41:21,274 DEV : loss 0.12226337939500809 - score 0.9681
2021-07-16 02:41:21,336 BAD EPOCHS (no improvement): 3
2021-07-16 02:41:21,337 ----------------------------------------------------------------------------------------------------
2021-07-16 02:41:31,466 epoch 35 - iter 19/192 - loss 0.10243657 - samples/sec: 60.03 - lr: 0.000004
2021-07-16 02:41:41,650 epoch 35 - iter 38/192 - loss 0.09488693 - samples/sec: 59.71 - lr: 0.000004
2021-07-16 02:41:51,800 epoch 35 - iter 57/192 - loss 0.09207106 - samples/sec: 59.91 - lr: 0.000004
2021-07-16 02:42:01,957 epoch 35 - iter 76/192 - loss 0.09586298 - samples/sec: 59.87 - lr: 0.000004
2021-07-16 02:42:12,042 epoch 35 - iter 95/192 - loss 0.09077181 - samples/sec: 60.29 - lr: 0.000004
2021-07-16 02:42:22,135 epoch 35 - iter 114/192 - loss 0.08863412 - samples/sec: 60.25 - lr: 0.000004
2021-07-16 02:42:32,222 epoch 35 - iter 133/192 - loss 0.08732556 - samples/sec: 60.29 - lr: 0.000004
2021-07-16 02:42:42,360 epoch 35 - iter 152/192 - loss 0.08704994 - samples/sec: 59.98 - lr: 0.000004
2021-07-16 02:42:52,507 epoch 35 - iter 171/192 - loss 0.08584717 - samples/sec: 59.93 - lr: 0.000004
2021-07-16 02:43:02,673 epoch 35 - iter 190/192 - loss 0.08505342 - samples/sec: 59.81 - lr: 0.000004
2021-07-16 02:43:03,711 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:03,711 EPOCH 35 done: loss 0.0859 - lr 0.0000038
2021-07-16 02:43:08,290 DEV : loss 0.122381791472435 - score 0.9675
Epoch    35: reducing learning rate of group 0 to 1.8750e-06.
2021-07-16 02:43:08,354 BAD EPOCHS (no improvement): 4
2021-07-16 02:43:08,354 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:08,354 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:08,354 learning rate too small - quitting training!
2021-07-16 02:43:08,354 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:09,056 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:09,056 Testing using best model ...
2021-07-16 02:43:09,056 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/eng.rst.rstdt/best-model.pt
2021-07-16 02:43:42,654 0.9647	0.9780	0.9713
2021-07-16 02:43:42,655 
Results:
- F1-score (micro) 0.9713
- F1-score (macro) 0.9713

By class:
SENT       tp: 1558 - fp: 57 - fn: 35 - precision: 0.9647 - recall: 0.9780 - f1-score: 0.9713
2021-07-16 02:43:42,655 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/rus.rst.rrt/
2021-07-16 02:43:42,671 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/rus.rst.rrt
2021-07-16 02:43:42,673 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/rus.rst.rrt/sent_train.txt
2021-07-16 02:43:42,675 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/rus.rst.rrt/sent_dev.txt
2021-07-16 02:43:42,677 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/rus.rst.rrt/sent_test.txt
Corpus: 15406 train + 1956 dev + 3315 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-16 02:43:54,829 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:54,831 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50021, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-16 02:43:54,831 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:54,831 Corpus: "Corpus: 15406 train + 1956 dev + 3315 test sentences"
2021-07-16 02:43:54,831 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:54,831 Parameters:
2021-07-16 02:43:54,831  - learning_rate: "3e-05"
2021-07-16 02:43:54,831  - mini_batch_size: "32"
2021-07-16 02:43:54,831  - patience: "3"
2021-07-16 02:43:54,831  - anneal_factor: "0.5"
2021-07-16 02:43:54,831  - max_epochs: "40"
2021-07-16 02:43:54,831  - shuffle: "True"
2021-07-16 02:43:54,831  - train_with_dev: "False"
2021-07-16 02:43:54,832  - batch_growth_annealing: "False"
2021-07-16 02:43:54,832 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:54,832 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/rus.rst.rrt"
2021-07-16 02:43:54,832 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:54,832 Device: cuda:0
2021-07-16 02:43:54,832 ----------------------------------------------------------------------------------------------------
2021-07-16 02:43:54,832 Embeddings storage mode: cpu
2021-07-16 02:43:54,834 ----------------------------------------------------------------------------------------------------
2021-07-16 02:44:49,644 epoch 1 - iter 48/482 - loss 5.90080102 - samples/sec: 28.03 - lr: 0.000030
2021-07-16 02:45:42,512 epoch 1 - iter 96/482 - loss 3.38926943 - samples/sec: 29.06 - lr: 0.000030
2021-07-16 02:46:34,823 epoch 1 - iter 144/482 - loss 2.50810204 - samples/sec: 29.36 - lr: 0.000030
2021-07-16 02:47:27,054 epoch 1 - iter 192/482 - loss 2.04105636 - samples/sec: 29.41 - lr: 0.000030
2021-07-16 02:48:19,179 epoch 1 - iter 240/482 - loss 1.73681692 - samples/sec: 29.47 - lr: 0.000030
2021-07-16 02:49:11,214 epoch 1 - iter 288/482 - loss 1.52653950 - samples/sec: 29.52 - lr: 0.000030
2021-07-16 02:50:03,199 epoch 1 - iter 336/482 - loss 1.37864414 - samples/sec: 29.55 - lr: 0.000030
2021-07-16 02:50:56,030 epoch 1 - iter 384/482 - loss 1.25865449 - samples/sec: 29.08 - lr: 0.000030
2021-07-16 02:51:48,397 epoch 1 - iter 432/482 - loss 1.16542776 - samples/sec: 29.33 - lr: 0.000030
2021-07-16 02:52:41,336 epoch 1 - iter 480/482 - loss 1.08915992 - samples/sec: 29.02 - lr: 0.000030
2021-07-16 02:52:42,935 ----------------------------------------------------------------------------------------------------
2021-07-16 02:52:42,935 EPOCH 1 done: loss 1.0861 - lr 0.0000300
2021-07-16 02:53:20,445 DEV : loss 0.32409825921058655 - score 0.9512
2021-07-16 02:53:20,591 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:53:21,531 ----------------------------------------------------------------------------------------------------
2021-07-16 02:53:47,829 epoch 2 - iter 48/482 - loss 0.35558201 - samples/sec: 58.42 - lr: 0.000030
2021-07-16 02:54:14,107 epoch 2 - iter 96/482 - loss 0.35694722 - samples/sec: 58.46 - lr: 0.000030
2021-07-16 02:54:40,337 epoch 2 - iter 144/482 - loss 0.36004174 - samples/sec: 58.57 - lr: 0.000030
2021-07-16 02:55:06,599 epoch 2 - iter 192/482 - loss 0.35552643 - samples/sec: 58.49 - lr: 0.000030
2021-07-16 02:55:32,978 epoch 2 - iter 240/482 - loss 0.34864199 - samples/sec: 58.23 - lr: 0.000030
2021-07-16 02:55:59,330 epoch 2 - iter 288/482 - loss 0.34020106 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 02:56:25,730 epoch 2 - iter 336/482 - loss 0.33692208 - samples/sec: 58.19 - lr: 0.000030
2021-07-16 02:56:51,932 epoch 2 - iter 384/482 - loss 0.33368087 - samples/sec: 58.63 - lr: 0.000030
2021-07-16 02:57:17,980 epoch 2 - iter 432/482 - loss 0.32725856 - samples/sec: 58.98 - lr: 0.000030
2021-07-16 02:57:44,124 epoch 2 - iter 480/482 - loss 0.32238441 - samples/sec: 58.76 - lr: 0.000030
2021-07-16 02:57:44,941 ----------------------------------------------------------------------------------------------------
2021-07-16 02:57:44,941 EPOCH 2 done: loss 0.3229 - lr 0.0000300
2021-07-16 02:57:56,037 DEV : loss 0.26564544439315796 - score 0.9606
2021-07-16 02:57:56,181 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 02:58:00,542 ----------------------------------------------------------------------------------------------------
2021-07-16 02:58:26,612 epoch 3 - iter 48/482 - loss 0.26227273 - samples/sec: 58.93 - lr: 0.000030
2021-07-16 02:58:52,751 epoch 3 - iter 96/482 - loss 0.27037159 - samples/sec: 58.77 - lr: 0.000030
2021-07-16 02:59:19,042 epoch 3 - iter 144/482 - loss 0.26950990 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 02:59:45,362 epoch 3 - iter 192/482 - loss 0.26541930 - samples/sec: 58.36 - lr: 0.000030
2021-07-16 03:00:11,660 epoch 3 - iter 240/482 - loss 0.26204778 - samples/sec: 58.41 - lr: 0.000030
2021-07-16 03:00:37,956 epoch 3 - iter 288/482 - loss 0.26328586 - samples/sec: 58.42 - lr: 0.000030
2021-07-16 03:01:04,056 epoch 3 - iter 336/482 - loss 0.26425996 - samples/sec: 58.86 - lr: 0.000030
2021-07-16 03:01:31,305 epoch 3 - iter 384/482 - loss 0.26025768 - samples/sec: 56.37 - lr: 0.000030
2021-07-16 03:01:57,394 epoch 3 - iter 432/482 - loss 0.26285445 - samples/sec: 58.88 - lr: 0.000030
2021-07-16 03:02:23,691 epoch 3 - iter 480/482 - loss 0.25890144 - samples/sec: 58.42 - lr: 0.000030
2021-07-16 03:02:24,522 ----------------------------------------------------------------------------------------------------
2021-07-16 03:02:24,523 EPOCH 3 done: loss 0.2588 - lr 0.0000300
2021-07-16 03:02:35,546 DEV : loss 0.23663775622844696 - score 0.9642
2021-07-16 03:02:35,690 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 03:02:39,923 ----------------------------------------------------------------------------------------------------
2021-07-16 03:03:06,211 epoch 4 - iter 48/482 - loss 0.24084601 - samples/sec: 58.44 - lr: 0.000030
2021-07-16 03:03:32,435 epoch 4 - iter 96/482 - loss 0.24951158 - samples/sec: 58.58 - lr: 0.000030
2021-07-16 03:03:58,760 epoch 4 - iter 144/482 - loss 0.24566323 - samples/sec: 58.36 - lr: 0.000030
2021-07-16 03:04:25,104 epoch 4 - iter 192/482 - loss 0.24422755 - samples/sec: 58.31 - lr: 0.000030
2021-07-16 03:04:51,435 epoch 4 - iter 240/482 - loss 0.23797570 - samples/sec: 58.34 - lr: 0.000030
2021-07-16 03:05:17,789 epoch 4 - iter 288/482 - loss 0.23928582 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 03:05:44,094 epoch 4 - iter 336/482 - loss 0.23992185 - samples/sec: 58.40 - lr: 0.000030
2021-07-16 03:06:10,408 epoch 4 - iter 384/482 - loss 0.23485610 - samples/sec: 58.38 - lr: 0.000030
2021-07-16 03:06:36,632 epoch 4 - iter 432/482 - loss 0.23734216 - samples/sec: 58.58 - lr: 0.000030
2021-07-16 03:07:02,897 epoch 4 - iter 480/482 - loss 0.23445182 - samples/sec: 58.49 - lr: 0.000030
2021-07-16 03:07:03,723 ----------------------------------------------------------------------------------------------------
2021-07-16 03:07:03,723 EPOCH 4 done: loss 0.2340 - lr 0.0000300
2021-07-16 03:07:14,807 DEV : loss 0.22378185391426086 - score 0.9662
2021-07-16 03:07:14,950 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 03:07:19,138 ----------------------------------------------------------------------------------------------------
2021-07-16 03:07:45,424 epoch 5 - iter 48/482 - loss 0.20374994 - samples/sec: 58.44 - lr: 0.000030
2021-07-16 03:08:11,763 epoch 5 - iter 96/482 - loss 0.20696811 - samples/sec: 58.32 - lr: 0.000030
2021-07-16 03:08:38,155 epoch 5 - iter 144/482 - loss 0.20515713 - samples/sec: 58.21 - lr: 0.000030
2021-07-16 03:09:04,568 epoch 5 - iter 192/482 - loss 0.20958715 - samples/sec: 58.16 - lr: 0.000030
2021-07-16 03:09:30,863 epoch 5 - iter 240/482 - loss 0.20975470 - samples/sec: 58.42 - lr: 0.000030
2021-07-16 03:09:57,209 epoch 5 - iter 288/482 - loss 0.21370085 - samples/sec: 58.31 - lr: 0.000030
2021-07-16 03:10:23,577 epoch 5 - iter 336/482 - loss 0.21860850 - samples/sec: 58.26 - lr: 0.000030
2021-07-16 03:10:49,914 epoch 5 - iter 384/482 - loss 0.21257555 - samples/sec: 58.33 - lr: 0.000030
2021-07-16 03:11:16,330 epoch 5 - iter 432/482 - loss 0.21260479 - samples/sec: 58.15 - lr: 0.000030
2021-07-16 03:11:42,640 epoch 5 - iter 480/482 - loss 0.21023001 - samples/sec: 58.39 - lr: 0.000030
2021-07-16 03:11:43,467 ----------------------------------------------------------------------------------------------------
2021-07-16 03:11:43,468 EPOCH 5 done: loss 0.2105 - lr 0.0000300
2021-07-16 03:11:54,585 DEV : loss 0.20980903506278992 - score 0.9685
2021-07-16 03:11:54,731 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 03:11:59,122 ----------------------------------------------------------------------------------------------------
2021-07-16 03:12:25,474 epoch 6 - iter 48/482 - loss 0.19486155 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 03:12:51,739 epoch 6 - iter 96/482 - loss 0.19579403 - samples/sec: 58.49 - lr: 0.000030
2021-07-16 03:13:18,058 epoch 6 - iter 144/482 - loss 0.19212364 - samples/sec: 58.37 - lr: 0.000030
2021-07-16 03:13:44,434 epoch 6 - iter 192/482 - loss 0.19394445 - samples/sec: 58.24 - lr: 0.000030
2021-07-16 03:14:10,752 epoch 6 - iter 240/482 - loss 0.19780662 - samples/sec: 58.37 - lr: 0.000030
2021-07-16 03:14:37,128 epoch 6 - iter 288/482 - loss 0.19427678 - samples/sec: 58.24 - lr: 0.000030
2021-07-16 03:15:03,540 epoch 6 - iter 336/482 - loss 0.19259801 - samples/sec: 58.16 - lr: 0.000030
2021-07-16 03:15:29,929 epoch 6 - iter 384/482 - loss 0.19359361 - samples/sec: 58.21 - lr: 0.000030
2021-07-16 03:15:56,374 epoch 6 - iter 432/482 - loss 0.19327040 - samples/sec: 58.09 - lr: 0.000030
2021-07-16 03:16:22,648 epoch 6 - iter 480/482 - loss 0.19209953 - samples/sec: 58.47 - lr: 0.000030
2021-07-16 03:16:23,472 ----------------------------------------------------------------------------------------------------
2021-07-16 03:16:23,473 EPOCH 6 done: loss 0.1924 - lr 0.0000300
2021-07-16 03:16:35,746 DEV : loss 0.200583815574646 - score 0.9698
2021-07-16 03:16:35,892 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 03:16:40,128 ----------------------------------------------------------------------------------------------------
2021-07-16 03:17:06,294 epoch 7 - iter 48/482 - loss 0.17857912 - samples/sec: 58.71 - lr: 0.000030
2021-07-16 03:17:32,686 epoch 7 - iter 96/482 - loss 0.17120215 - samples/sec: 58.21 - lr: 0.000030
2021-07-16 03:17:58,960 epoch 7 - iter 144/482 - loss 0.17965243 - samples/sec: 58.47 - lr: 0.000030
2021-07-16 03:18:25,136 epoch 7 - iter 192/482 - loss 0.17894356 - samples/sec: 58.69 - lr: 0.000030
2021-07-16 03:18:51,318 epoch 7 - iter 240/482 - loss 0.18105076 - samples/sec: 58.67 - lr: 0.000030
2021-07-16 03:19:17,474 epoch 7 - iter 288/482 - loss 0.18353567 - samples/sec: 58.73 - lr: 0.000030
2021-07-16 03:19:43,751 epoch 7 - iter 336/482 - loss 0.18399425 - samples/sec: 58.46 - lr: 0.000030
2021-07-16 03:20:09,858 epoch 7 - iter 384/482 - loss 0.18359487 - samples/sec: 58.84 - lr: 0.000030
2021-07-16 03:20:35,965 epoch 7 - iter 432/482 - loss 0.18758336 - samples/sec: 58.84 - lr: 0.000030
2021-07-16 03:21:02,278 epoch 7 - iter 480/482 - loss 0.18807113 - samples/sec: 58.38 - lr: 0.000030
2021-07-16 03:21:03,110 ----------------------------------------------------------------------------------------------------
2021-07-16 03:21:03,110 EPOCH 7 done: loss 0.1876 - lr 0.0000300
2021-07-16 03:21:14,184 DEV : loss 0.1933988630771637 - score 0.9713
2021-07-16 03:21:14,330 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 03:21:18,871 ----------------------------------------------------------------------------------------------------
2021-07-16 03:21:45,166 epoch 8 - iter 48/482 - loss 0.18017616 - samples/sec: 58.42 - lr: 0.000030
2021-07-16 03:22:11,320 epoch 8 - iter 96/482 - loss 0.18662753 - samples/sec: 58.74 - lr: 0.000030
2021-07-16 03:22:37,508 epoch 8 - iter 144/482 - loss 0.17956157 - samples/sec: 58.66 - lr: 0.000030
2021-07-16 03:23:03,724 epoch 8 - iter 192/482 - loss 0.17289005 - samples/sec: 58.59 - lr: 0.000030
2021-07-16 03:23:29,946 epoch 8 - iter 240/482 - loss 0.17079119 - samples/sec: 58.58 - lr: 0.000030
2021-07-16 03:23:56,158 epoch 8 - iter 288/482 - loss 0.17400417 - samples/sec: 58.61 - lr: 0.000030
2021-07-16 03:24:22,434 epoch 8 - iter 336/482 - loss 0.17344778 - samples/sec: 58.46 - lr: 0.000030
2021-07-16 03:24:48,589 epoch 8 - iter 384/482 - loss 0.17630256 - samples/sec: 58.73 - lr: 0.000030
2021-07-16 03:25:14,887 epoch 8 - iter 432/482 - loss 0.17652795 - samples/sec: 58.41 - lr: 0.000030
2021-07-16 03:25:41,169 epoch 8 - iter 480/482 - loss 0.17781380 - samples/sec: 58.45 - lr: 0.000030
2021-07-16 03:25:41,987 ----------------------------------------------------------------------------------------------------
2021-07-16 03:25:41,987 EPOCH 8 done: loss 0.1782 - lr 0.0000300
2021-07-16 03:25:53,055 DEV : loss 0.19904541969299316 - score 0.9705
2021-07-16 03:25:53,202 BAD EPOCHS (no improvement): 1
2021-07-16 03:25:53,202 ----------------------------------------------------------------------------------------------------
2021-07-16 03:26:19,495 epoch 9 - iter 48/482 - loss 0.16798537 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 03:26:45,867 epoch 9 - iter 96/482 - loss 0.16446720 - samples/sec: 58.25 - lr: 0.000030
2021-07-16 03:27:12,158 epoch 9 - iter 144/482 - loss 0.16773188 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 03:27:38,458 epoch 9 - iter 192/482 - loss 0.16480067 - samples/sec: 58.41 - lr: 0.000030
2021-07-16 03:28:04,763 epoch 9 - iter 240/482 - loss 0.16523774 - samples/sec: 58.40 - lr: 0.000030
2021-07-16 03:28:30,897 epoch 9 - iter 288/482 - loss 0.16838720 - samples/sec: 58.78 - lr: 0.000030
2021-07-16 03:28:56,961 epoch 9 - iter 336/482 - loss 0.16150376 - samples/sec: 58.94 - lr: 0.000030
2021-07-16 03:29:23,109 epoch 9 - iter 384/482 - loss 0.16262587 - samples/sec: 58.75 - lr: 0.000030
2021-07-16 03:29:49,225 epoch 9 - iter 432/482 - loss 0.16322946 - samples/sec: 58.82 - lr: 0.000030
2021-07-16 03:30:15,331 epoch 9 - iter 480/482 - loss 0.16490259 - samples/sec: 58.84 - lr: 0.000030
2021-07-16 03:30:16,157 ----------------------------------------------------------------------------------------------------
2021-07-16 03:30:16,158 EPOCH 9 done: loss 0.1646 - lr 0.0000300
2021-07-16 03:30:27,215 DEV : loss 0.17549960315227509 - score 0.9724
2021-07-16 03:30:27,360 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 03:30:31,594 ----------------------------------------------------------------------------------------------------
2021-07-16 03:30:57,815 epoch 10 - iter 48/482 - loss 0.16356420 - samples/sec: 58.59 - lr: 0.000030
2021-07-16 03:31:24,163 epoch 10 - iter 96/482 - loss 0.15726663 - samples/sec: 58.30 - lr: 0.000030
2021-07-16 03:31:50,492 epoch 10 - iter 144/482 - loss 0.16481138 - samples/sec: 58.35 - lr: 0.000030
2021-07-16 03:32:16,695 epoch 10 - iter 192/482 - loss 0.16517353 - samples/sec: 58.63 - lr: 0.000030
2021-07-16 03:32:42,987 epoch 10 - iter 240/482 - loss 0.16453273 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 03:33:09,361 epoch 10 - iter 288/482 - loss 0.16547607 - samples/sec: 58.25 - lr: 0.000030
2021-07-16 03:33:35,715 epoch 10 - iter 336/482 - loss 0.16329276 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 03:34:01,717 epoch 10 - iter 384/482 - loss 0.16283367 - samples/sec: 59.08 - lr: 0.000030
2021-07-16 03:34:27,827 epoch 10 - iter 432/482 - loss 0.16355744 - samples/sec: 58.83 - lr: 0.000030
2021-07-16 03:34:53,904 epoch 10 - iter 480/482 - loss 0.16342150 - samples/sec: 58.91 - lr: 0.000030
2021-07-16 03:34:54,717 ----------------------------------------------------------------------------------------------------
2021-07-16 03:34:54,718 EPOCH 10 done: loss 0.1631 - lr 0.0000300
2021-07-16 03:35:06,907 DEV : loss 0.17728851735591888 - score 0.9718
2021-07-16 03:35:07,052 BAD EPOCHS (no improvement): 1
2021-07-16 03:35:07,053 ----------------------------------------------------------------------------------------------------
2021-07-16 03:35:33,242 epoch 11 - iter 48/482 - loss 0.15677328 - samples/sec: 58.66 - lr: 0.000030
2021-07-16 03:35:59,378 epoch 11 - iter 96/482 - loss 0.14788953 - samples/sec: 58.78 - lr: 0.000030
2021-07-16 03:36:25,623 epoch 11 - iter 144/482 - loss 0.15534761 - samples/sec: 58.53 - lr: 0.000030
2021-07-16 03:36:51,946 epoch 11 - iter 192/482 - loss 0.15377688 - samples/sec: 58.36 - lr: 0.000030
2021-07-16 03:37:18,144 epoch 11 - iter 240/482 - loss 0.15405464 - samples/sec: 58.64 - lr: 0.000030
2021-07-16 03:37:44,330 epoch 11 - iter 288/482 - loss 0.15719702 - samples/sec: 58.66 - lr: 0.000030
2021-07-16 03:38:10,524 epoch 11 - iter 336/482 - loss 0.15499864 - samples/sec: 58.65 - lr: 0.000030
2021-07-16 03:38:36,792 epoch 11 - iter 384/482 - loss 0.15524672 - samples/sec: 58.48 - lr: 0.000030
2021-07-16 03:39:02,995 epoch 11 - iter 432/482 - loss 0.15575806 - samples/sec: 58.63 - lr: 0.000030
2021-07-16 03:39:29,250 epoch 11 - iter 480/482 - loss 0.15602636 - samples/sec: 58.51 - lr: 0.000030
2021-07-16 03:39:30,074 ----------------------------------------------------------------------------------------------------
2021-07-16 03:39:30,074 EPOCH 11 done: loss 0.1566 - lr 0.0000300
2021-07-16 03:39:41,141 DEV : loss 0.18279510736465454 - score 0.9738
2021-07-16 03:39:41,287 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 03:39:45,572 ----------------------------------------------------------------------------------------------------
2021-07-16 03:40:11,886 epoch 12 - iter 48/482 - loss 0.17341263 - samples/sec: 58.38 - lr: 0.000030
2021-07-16 03:40:38,235 epoch 12 - iter 96/482 - loss 0.16486445 - samples/sec: 58.30 - lr: 0.000030
2021-07-16 03:41:04,628 epoch 12 - iter 144/482 - loss 0.16560551 - samples/sec: 58.20 - lr: 0.000030
2021-07-16 03:41:31,005 epoch 12 - iter 192/482 - loss 0.16553508 - samples/sec: 58.24 - lr: 0.000030
2021-07-16 03:41:57,359 epoch 12 - iter 240/482 - loss 0.16126031 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 03:42:23,737 epoch 12 - iter 288/482 - loss 0.15840394 - samples/sec: 58.24 - lr: 0.000030
2021-07-16 03:42:50,022 epoch 12 - iter 336/482 - loss 0.15633852 - samples/sec: 58.44 - lr: 0.000030
2021-07-16 03:43:16,404 epoch 12 - iter 384/482 - loss 0.15472999 - samples/sec: 58.23 - lr: 0.000030
2021-07-16 03:43:42,705 epoch 12 - iter 432/482 - loss 0.15479790 - samples/sec: 58.41 - lr: 0.000030
2021-07-16 03:44:09,011 epoch 12 - iter 480/482 - loss 0.15142136 - samples/sec: 58.40 - lr: 0.000030
2021-07-16 03:44:09,843 ----------------------------------------------------------------------------------------------------
2021-07-16 03:44:09,843 EPOCH 12 done: loss 0.1510 - lr 0.0000300
2021-07-16 03:44:20,904 DEV : loss 0.19891609251499176 - score 0.9716
2021-07-16 03:44:21,050 BAD EPOCHS (no improvement): 1
2021-07-16 03:44:21,050 ----------------------------------------------------------------------------------------------------
2021-07-16 03:44:47,380 epoch 13 - iter 48/482 - loss 0.12790487 - samples/sec: 58.34 - lr: 0.000030
2021-07-16 03:45:13,613 epoch 13 - iter 96/482 - loss 0.13562732 - samples/sec: 58.56 - lr: 0.000030
2021-07-16 03:45:39,798 epoch 13 - iter 144/482 - loss 0.13714147 - samples/sec: 58.67 - lr: 0.000030
2021-07-16 03:46:05,972 epoch 13 - iter 192/482 - loss 0.14010169 - samples/sec: 58.69 - lr: 0.000030
2021-07-16 03:46:32,195 epoch 13 - iter 240/482 - loss 0.14966319 - samples/sec: 58.58 - lr: 0.000030
2021-07-16 03:46:58,394 epoch 13 - iter 288/482 - loss 0.14747113 - samples/sec: 58.63 - lr: 0.000030
2021-07-16 03:47:24,629 epoch 13 - iter 336/482 - loss 0.14694392 - samples/sec: 58.55 - lr: 0.000030
2021-07-16 03:47:50,880 epoch 13 - iter 384/482 - loss 0.14698623 - samples/sec: 58.52 - lr: 0.000030
2021-07-16 03:48:17,098 epoch 13 - iter 432/482 - loss 0.14597573 - samples/sec: 58.59 - lr: 0.000030
2021-07-16 03:48:43,301 epoch 13 - iter 480/482 - loss 0.14496933 - samples/sec: 58.63 - lr: 0.000030
2021-07-16 03:48:44,122 ----------------------------------------------------------------------------------------------------
2021-07-16 03:48:44,123 EPOCH 13 done: loss 0.1447 - lr 0.0000300
2021-07-16 03:48:55,173 DEV : loss 0.18982115387916565 - score 0.9729
2021-07-16 03:48:55,318 BAD EPOCHS (no improvement): 2
2021-07-16 03:48:55,319 ----------------------------------------------------------------------------------------------------
2021-07-16 03:49:21,596 epoch 14 - iter 48/482 - loss 0.13674393 - samples/sec: 58.46 - lr: 0.000030
2021-07-16 03:49:47,807 epoch 14 - iter 96/482 - loss 0.13622813 - samples/sec: 58.61 - lr: 0.000030
2021-07-16 03:50:13,992 epoch 14 - iter 144/482 - loss 0.12960070 - samples/sec: 58.67 - lr: 0.000030
2021-07-16 03:50:40,184 epoch 14 - iter 192/482 - loss 0.12958702 - samples/sec: 58.65 - lr: 0.000030
2021-07-16 03:51:06,411 epoch 14 - iter 240/482 - loss 0.13092299 - samples/sec: 58.57 - lr: 0.000030
2021-07-16 03:51:32,623 epoch 14 - iter 288/482 - loss 0.13611557 - samples/sec: 58.61 - lr: 0.000030
2021-07-16 03:51:58,758 epoch 14 - iter 336/482 - loss 0.13444415 - samples/sec: 58.78 - lr: 0.000030
2021-07-16 03:52:25,039 epoch 14 - iter 384/482 - loss 0.13461919 - samples/sec: 58.45 - lr: 0.000030
2021-07-16 03:52:51,218 epoch 14 - iter 432/482 - loss 0.13771955 - samples/sec: 58.68 - lr: 0.000030
2021-07-16 03:53:17,504 epoch 14 - iter 480/482 - loss 0.13687164 - samples/sec: 58.44 - lr: 0.000030
2021-07-16 03:53:18,333 ----------------------------------------------------------------------------------------------------
2021-07-16 03:53:18,333 EPOCH 14 done: loss 0.1370 - lr 0.0000300
2021-07-16 03:53:30,586 DEV : loss 0.18281647562980652 - score 0.9736
2021-07-16 03:53:30,733 BAD EPOCHS (no improvement): 3
2021-07-16 03:53:30,733 ----------------------------------------------------------------------------------------------------
2021-07-16 03:53:57,065 epoch 15 - iter 48/482 - loss 0.15273065 - samples/sec: 58.34 - lr: 0.000030
2021-07-16 03:54:23,393 epoch 15 - iter 96/482 - loss 0.13712791 - samples/sec: 58.35 - lr: 0.000030
2021-07-16 03:54:49,746 epoch 15 - iter 144/482 - loss 0.12867405 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 03:55:16,030 epoch 15 - iter 192/482 - loss 0.13383330 - samples/sec: 58.45 - lr: 0.000030
2021-07-16 03:55:42,375 epoch 15 - iter 240/482 - loss 0.13090706 - samples/sec: 58.31 - lr: 0.000030
2021-07-16 03:56:08,700 epoch 15 - iter 288/482 - loss 0.12996971 - samples/sec: 58.35 - lr: 0.000030
2021-07-16 03:56:35,052 epoch 15 - iter 336/482 - loss 0.13321960 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 03:57:01,409 epoch 15 - iter 384/482 - loss 0.13541374 - samples/sec: 58.28 - lr: 0.000030
2021-07-16 03:57:27,712 epoch 15 - iter 432/482 - loss 0.13401099 - samples/sec: 58.40 - lr: 0.000030
2021-07-16 03:57:54,037 epoch 15 - iter 480/482 - loss 0.13481453 - samples/sec: 58.35 - lr: 0.000030
2021-07-16 03:57:54,870 ----------------------------------------------------------------------------------------------------
2021-07-16 03:57:54,870 EPOCH 15 done: loss 0.1349 - lr 0.0000300
2021-07-16 03:58:05,931 DEV : loss 0.1809552013874054 - score 0.974
2021-07-16 03:58:06,078 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 03:58:09,975 ----------------------------------------------------------------------------------------------------
2021-07-16 03:58:36,332 epoch 16 - iter 48/482 - loss 0.12407941 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 03:59:02,719 epoch 16 - iter 96/482 - loss 0.12829175 - samples/sec: 58.22 - lr: 0.000030
2021-07-16 03:59:29,011 epoch 16 - iter 144/482 - loss 0.13442244 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 03:59:55,374 epoch 16 - iter 192/482 - loss 0.13351030 - samples/sec: 58.27 - lr: 0.000030
2021-07-16 04:00:21,730 epoch 16 - iter 240/482 - loss 0.13058770 - samples/sec: 58.28 - lr: 0.000030
2021-07-16 04:00:48,076 epoch 16 - iter 288/482 - loss 0.13044612 - samples/sec: 58.31 - lr: 0.000030
2021-07-16 04:01:14,415 epoch 16 - iter 336/482 - loss 0.13139089 - samples/sec: 58.32 - lr: 0.000030
2021-07-16 04:01:40,779 epoch 16 - iter 384/482 - loss 0.12887955 - samples/sec: 58.27 - lr: 0.000030
2021-07-16 04:02:07,092 epoch 16 - iter 432/482 - loss 0.12940069 - samples/sec: 58.38 - lr: 0.000030
2021-07-16 04:02:33,427 epoch 16 - iter 480/482 - loss 0.13044339 - samples/sec: 58.33 - lr: 0.000030
2021-07-16 04:02:34,225 ----------------------------------------------------------------------------------------------------
2021-07-16 04:02:34,225 EPOCH 16 done: loss 0.1305 - lr 0.0000300
2021-07-16 04:02:45,297 DEV : loss 0.17366360127925873 - score 0.9754
2021-07-16 04:02:45,445 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 04:02:49,326 ----------------------------------------------------------------------------------------------------
2021-07-16 04:03:15,615 epoch 17 - iter 48/482 - loss 0.11939733 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 04:03:41,925 epoch 17 - iter 96/482 - loss 0.12399630 - samples/sec: 58.39 - lr: 0.000030
2021-07-16 04:04:08,224 epoch 17 - iter 144/482 - loss 0.13082462 - samples/sec: 58.41 - lr: 0.000030
2021-07-16 04:04:34,514 epoch 17 - iter 192/482 - loss 0.13036090 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 04:05:00,939 epoch 17 - iter 240/482 - loss 0.13168377 - samples/sec: 58.13 - lr: 0.000030
2021-07-16 04:05:27,331 epoch 17 - iter 288/482 - loss 0.13059423 - samples/sec: 58.20 - lr: 0.000030
2021-07-16 04:05:53,658 epoch 17 - iter 336/482 - loss 0.13017229 - samples/sec: 58.35 - lr: 0.000030
2021-07-16 04:06:19,947 epoch 17 - iter 384/482 - loss 0.12803345 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 04:06:46,288 epoch 17 - iter 432/482 - loss 0.12837247 - samples/sec: 58.32 - lr: 0.000030
2021-07-16 04:07:12,599 epoch 17 - iter 480/482 - loss 0.12790472 - samples/sec: 58.39 - lr: 0.000030
2021-07-16 04:07:13,430 ----------------------------------------------------------------------------------------------------
2021-07-16 04:07:13,430 EPOCH 17 done: loss 0.1277 - lr 0.0000300
2021-07-16 04:07:24,510 DEV : loss 0.20069536566734314 - score 0.9731
2021-07-16 04:07:24,657 BAD EPOCHS (no improvement): 1
2021-07-16 04:07:24,657 ----------------------------------------------------------------------------------------------------
2021-07-16 04:07:50,975 epoch 18 - iter 48/482 - loss 0.13135115 - samples/sec: 58.37 - lr: 0.000030
2021-07-16 04:08:17,118 epoch 18 - iter 96/482 - loss 0.13431995 - samples/sec: 58.76 - lr: 0.000030
2021-07-16 04:08:44,591 epoch 18 - iter 144/482 - loss 0.12900586 - samples/sec: 55.91 - lr: 0.000030
2021-07-16 04:09:10,917 epoch 18 - iter 192/482 - loss 0.12251939 - samples/sec: 58.35 - lr: 0.000030
2021-07-16 04:09:37,274 epoch 18 - iter 240/482 - loss 0.12133637 - samples/sec: 58.28 - lr: 0.000030
2021-07-16 04:10:03,654 epoch 18 - iter 288/482 - loss 0.12204850 - samples/sec: 58.23 - lr: 0.000030
2021-07-16 04:10:30,008 epoch 18 - iter 336/482 - loss 0.11986806 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 04:10:56,340 epoch 18 - iter 384/482 - loss 0.11955953 - samples/sec: 58.34 - lr: 0.000030
2021-07-16 04:11:22,616 epoch 18 - iter 432/482 - loss 0.12071238 - samples/sec: 58.46 - lr: 0.000030
2021-07-16 04:11:48,889 epoch 18 - iter 480/482 - loss 0.12166016 - samples/sec: 58.47 - lr: 0.000030
2021-07-16 04:11:49,706 ----------------------------------------------------------------------------------------------------
2021-07-16 04:11:49,706 EPOCH 18 done: loss 0.1216 - lr 0.0000300
2021-07-16 04:12:00,754 DEV : loss 0.1805371791124344 - score 0.9745
2021-07-16 04:12:00,900 BAD EPOCHS (no improvement): 2
2021-07-16 04:12:00,900 ----------------------------------------------------------------------------------------------------
2021-07-16 04:12:27,267 epoch 19 - iter 48/482 - loss 0.12038199 - samples/sec: 58.26 - lr: 0.000030
2021-07-16 04:12:53,658 epoch 19 - iter 96/482 - loss 0.11787569 - samples/sec: 58.21 - lr: 0.000030
2021-07-16 04:13:19,999 epoch 19 - iter 144/482 - loss 0.11014960 - samples/sec: 58.32 - lr: 0.000030
2021-07-16 04:13:46,316 epoch 19 - iter 192/482 - loss 0.11596801 - samples/sec: 58.37 - lr: 0.000030
2021-07-16 04:14:12,639 epoch 19 - iter 240/482 - loss 0.11556991 - samples/sec: 58.36 - lr: 0.000030
2021-07-16 04:14:39,043 epoch 19 - iter 288/482 - loss 0.11729476 - samples/sec: 58.18 - lr: 0.000030
2021-07-16 04:15:05,371 epoch 19 - iter 336/482 - loss 0.11710825 - samples/sec: 58.35 - lr: 0.000030
2021-07-16 04:15:31,622 epoch 19 - iter 384/482 - loss 0.11704847 - samples/sec: 58.52 - lr: 0.000030
2021-07-16 04:15:57,790 epoch 19 - iter 432/482 - loss 0.11874229 - samples/sec: 58.70 - lr: 0.000030
2021-07-16 04:16:23,911 epoch 19 - iter 480/482 - loss 0.11891351 - samples/sec: 58.81 - lr: 0.000030
2021-07-16 04:16:24,712 ----------------------------------------------------------------------------------------------------
2021-07-16 04:16:24,712 EPOCH 19 done: loss 0.1185 - lr 0.0000300
2021-07-16 04:16:35,769 DEV : loss 0.18989630043506622 - score 0.9747
2021-07-16 04:16:35,916 BAD EPOCHS (no improvement): 3
2021-07-16 04:16:35,917 ----------------------------------------------------------------------------------------------------
2021-07-16 04:17:02,058 epoch 20 - iter 48/482 - loss 0.11114558 - samples/sec: 58.76 - lr: 0.000030
2021-07-16 04:17:28,376 epoch 20 - iter 96/482 - loss 0.11717559 - samples/sec: 58.37 - lr: 0.000030
2021-07-16 04:17:54,732 epoch 20 - iter 144/482 - loss 0.11908233 - samples/sec: 58.29 - lr: 0.000030
2021-07-16 04:18:21,023 epoch 20 - iter 192/482 - loss 0.11867148 - samples/sec: 58.43 - lr: 0.000030
2021-07-16 04:18:47,318 epoch 20 - iter 240/482 - loss 0.12018191 - samples/sec: 58.42 - lr: 0.000030
2021-07-16 04:19:13,620 epoch 20 - iter 288/482 - loss 0.11791135 - samples/sec: 58.41 - lr: 0.000030
2021-07-16 04:19:39,965 epoch 20 - iter 336/482 - loss 0.11788072 - samples/sec: 58.31 - lr: 0.000030
2021-07-16 04:20:06,272 epoch 20 - iter 384/482 - loss 0.11917125 - samples/sec: 58.39 - lr: 0.000030
2021-07-16 04:20:32,512 epoch 20 - iter 432/482 - loss 0.11875278 - samples/sec: 58.54 - lr: 0.000030
2021-07-16 04:20:58,843 epoch 20 - iter 480/482 - loss 0.11890652 - samples/sec: 58.34 - lr: 0.000030
2021-07-16 04:20:59,655 ----------------------------------------------------------------------------------------------------
2021-07-16 04:20:59,655 EPOCH 20 done: loss 0.1191 - lr 0.0000300
2021-07-16 04:21:10,724 DEV : loss 0.1825714409351349 - score 0.9731
Epoch    20: reducing learning rate of group 0 to 1.5000e-05.
2021-07-16 04:21:10,870 BAD EPOCHS (no improvement): 4
2021-07-16 04:21:10,871 ----------------------------------------------------------------------------------------------------
2021-07-16 04:21:37,191 epoch 21 - iter 48/482 - loss 0.09839812 - samples/sec: 58.36 - lr: 0.000015
2021-07-16 04:22:03,576 epoch 21 - iter 96/482 - loss 0.10172529 - samples/sec: 58.22 - lr: 0.000015
2021-07-16 04:22:29,805 epoch 21 - iter 144/482 - loss 0.10333239 - samples/sec: 58.57 - lr: 0.000015
2021-07-16 04:22:56,217 epoch 21 - iter 192/482 - loss 0.10402329 - samples/sec: 58.16 - lr: 0.000015
2021-07-16 04:23:22,551 epoch 21 - iter 240/482 - loss 0.10912845 - samples/sec: 58.33 - lr: 0.000015
2021-07-16 04:23:48,692 epoch 21 - iter 288/482 - loss 0.10777377 - samples/sec: 58.76 - lr: 0.000015
2021-07-16 04:24:16,135 epoch 21 - iter 336/482 - loss 0.10969283 - samples/sec: 55.98 - lr: 0.000015
2021-07-16 04:24:42,290 epoch 21 - iter 384/482 - loss 0.10680151 - samples/sec: 58.73 - lr: 0.000015
2021-07-16 04:25:08,398 epoch 21 - iter 432/482 - loss 0.10689972 - samples/sec: 58.84 - lr: 0.000015
2021-07-16 04:25:34,644 epoch 21 - iter 480/482 - loss 0.10735322 - samples/sec: 58.53 - lr: 0.000015
2021-07-16 04:25:35,479 ----------------------------------------------------------------------------------------------------
2021-07-16 04:25:35,480 EPOCH 21 done: loss 0.1075 - lr 0.0000150
2021-07-16 04:25:46,548 DEV : loss 0.18478922545909882 - score 0.9762
2021-07-16 04:25:46,693 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 04:25:51,041 ----------------------------------------------------------------------------------------------------
2021-07-16 04:26:17,288 epoch 22 - iter 48/482 - loss 0.11542609 - samples/sec: 58.53 - lr: 0.000015
2021-07-16 04:26:43,444 epoch 22 - iter 96/482 - loss 0.10931700 - samples/sec: 58.73 - lr: 0.000015
2021-07-16 04:27:09,713 epoch 22 - iter 144/482 - loss 0.10945573 - samples/sec: 58.48 - lr: 0.000015
2021-07-16 04:27:35,931 epoch 22 - iter 192/482 - loss 0.10936263 - samples/sec: 58.59 - lr: 0.000015
2021-07-16 04:28:02,285 epoch 22 - iter 240/482 - loss 0.10544089 - samples/sec: 58.29 - lr: 0.000015
2021-07-16 04:28:28,624 epoch 22 - iter 288/482 - loss 0.10366770 - samples/sec: 58.32 - lr: 0.000015
2021-07-16 04:28:55,030 epoch 22 - iter 336/482 - loss 0.10467965 - samples/sec: 58.17 - lr: 0.000015
2021-07-16 04:29:21,197 epoch 22 - iter 384/482 - loss 0.10608455 - samples/sec: 58.71 - lr: 0.000015
2021-07-16 04:29:47,528 epoch 22 - iter 432/482 - loss 0.10644070 - samples/sec: 58.34 - lr: 0.000015
2021-07-16 04:30:13,897 epoch 22 - iter 480/482 - loss 0.10515546 - samples/sec: 58.26 - lr: 0.000015
2021-07-16 04:30:14,726 ----------------------------------------------------------------------------------------------------
2021-07-16 04:30:14,727 EPOCH 22 done: loss 0.1049 - lr 0.0000150
2021-07-16 04:30:25,792 DEV : loss 0.1924079805612564 - score 0.9749
2021-07-16 04:30:25,938 BAD EPOCHS (no improvement): 1
2021-07-16 04:30:25,938 ----------------------------------------------------------------------------------------------------
2021-07-16 04:30:52,364 epoch 23 - iter 48/482 - loss 0.10876229 - samples/sec: 58.13 - lr: 0.000015
2021-07-16 04:31:18,774 epoch 23 - iter 96/482 - loss 0.10782388 - samples/sec: 58.17 - lr: 0.000015
2021-07-16 04:31:45,096 epoch 23 - iter 144/482 - loss 0.10412014 - samples/sec: 58.36 - lr: 0.000015
2021-07-16 04:32:11,459 epoch 23 - iter 192/482 - loss 0.10603245 - samples/sec: 58.27 - lr: 0.000015
2021-07-16 04:32:37,827 epoch 23 - iter 240/482 - loss 0.10751169 - samples/sec: 58.26 - lr: 0.000015
2021-07-16 04:33:04,156 epoch 23 - iter 288/482 - loss 0.10520788 - samples/sec: 58.34 - lr: 0.000015
2021-07-16 04:33:30,466 epoch 23 - iter 336/482 - loss 0.10411057 - samples/sec: 58.39 - lr: 0.000015
2021-07-16 04:33:56,782 epoch 23 - iter 384/482 - loss 0.10410541 - samples/sec: 58.37 - lr: 0.000015
2021-07-16 04:34:23,152 epoch 23 - iter 432/482 - loss 0.10402836 - samples/sec: 58.26 - lr: 0.000015
2021-07-16 04:34:49,483 epoch 23 - iter 480/482 - loss 0.10348147 - samples/sec: 58.34 - lr: 0.000015
2021-07-16 04:34:50,322 ----------------------------------------------------------------------------------------------------
2021-07-16 04:34:50,322 EPOCH 23 done: loss 0.1038 - lr 0.0000150
2021-07-16 04:35:01,426 DEV : loss 0.18079274892807007 - score 0.9752
2021-07-16 04:35:01,575 BAD EPOCHS (no improvement): 2
2021-07-16 04:35:01,575 ----------------------------------------------------------------------------------------------------
2021-07-16 04:35:27,924 epoch 24 - iter 48/482 - loss 0.11987737 - samples/sec: 58.30 - lr: 0.000015
2021-07-16 04:35:54,327 epoch 24 - iter 96/482 - loss 0.10222840 - samples/sec: 58.18 - lr: 0.000015
2021-07-16 04:36:20,596 epoch 24 - iter 144/482 - loss 0.10185100 - samples/sec: 58.48 - lr: 0.000015
2021-07-16 04:36:46,920 epoch 24 - iter 192/482 - loss 0.10273184 - samples/sec: 58.36 - lr: 0.000015
2021-07-16 04:37:13,296 epoch 24 - iter 240/482 - loss 0.10038904 - samples/sec: 58.24 - lr: 0.000015
2021-07-16 04:37:39,476 epoch 24 - iter 288/482 - loss 0.10149740 - samples/sec: 58.68 - lr: 0.000015
2021-07-16 04:38:05,783 epoch 24 - iter 336/482 - loss 0.10360413 - samples/sec: 58.39 - lr: 0.000015
2021-07-16 04:38:32,101 epoch 24 - iter 384/482 - loss 0.10339996 - samples/sec: 58.37 - lr: 0.000015
2021-07-16 04:38:58,306 epoch 24 - iter 432/482 - loss 0.10211833 - samples/sec: 58.62 - lr: 0.000015
2021-07-16 04:39:24,655 epoch 24 - iter 480/482 - loss 0.10269891 - samples/sec: 58.30 - lr: 0.000015
2021-07-16 04:39:25,486 ----------------------------------------------------------------------------------------------------
2021-07-16 04:39:25,486 EPOCH 24 done: loss 0.1026 - lr 0.0000150
2021-07-16 04:39:36,578 DEV : loss 0.18847408890724182 - score 0.9758
2021-07-16 04:39:36,725 BAD EPOCHS (no improvement): 3
2021-07-16 04:39:36,725 ----------------------------------------------------------------------------------------------------
2021-07-16 04:40:03,111 epoch 25 - iter 48/482 - loss 0.10314005 - samples/sec: 58.22 - lr: 0.000015
2021-07-16 04:40:29,442 epoch 25 - iter 96/482 - loss 0.09878057 - samples/sec: 58.34 - lr: 0.000015
2021-07-16 04:40:55,745 epoch 25 - iter 144/482 - loss 0.09626620 - samples/sec: 58.40 - lr: 0.000015
2021-07-16 04:41:22,152 epoch 25 - iter 192/482 - loss 0.09495535 - samples/sec: 58.17 - lr: 0.000015
2021-07-16 04:41:48,529 epoch 25 - iter 240/482 - loss 0.09339860 - samples/sec: 58.24 - lr: 0.000015
2021-07-16 04:42:14,898 epoch 25 - iter 288/482 - loss 0.09280435 - samples/sec: 58.25 - lr: 0.000015
2021-07-16 04:42:41,199 epoch 25 - iter 336/482 - loss 0.09467414 - samples/sec: 58.41 - lr: 0.000015
2021-07-16 04:43:07,531 epoch 25 - iter 384/482 - loss 0.09660032 - samples/sec: 58.34 - lr: 0.000015
2021-07-16 04:43:34,928 epoch 25 - iter 432/482 - loss 0.09584114 - samples/sec: 56.07 - lr: 0.000015
2021-07-16 04:44:01,129 epoch 25 - iter 480/482 - loss 0.09543925 - samples/sec: 58.63 - lr: 0.000015
2021-07-16 04:44:01,931 ----------------------------------------------------------------------------------------------------
2021-07-16 04:44:01,931 EPOCH 25 done: loss 0.0955 - lr 0.0000150
2021-07-16 04:44:12,991 DEV : loss 0.18769744038581848 - score 0.9754
Epoch    25: reducing learning rate of group 0 to 7.5000e-06.
2021-07-16 04:44:13,138 BAD EPOCHS (no improvement): 4
2021-07-16 04:44:13,139 ----------------------------------------------------------------------------------------------------
2021-07-16 04:44:39,439 epoch 26 - iter 48/482 - loss 0.09578178 - samples/sec: 58.41 - lr: 0.000008
2021-07-16 04:45:05,823 epoch 26 - iter 96/482 - loss 0.09222127 - samples/sec: 58.22 - lr: 0.000008
2021-07-16 04:45:32,106 epoch 26 - iter 144/482 - loss 0.09426816 - samples/sec: 58.45 - lr: 0.000008
2021-07-16 04:45:58,396 epoch 26 - iter 192/482 - loss 0.09302133 - samples/sec: 58.43 - lr: 0.000008
2021-07-16 04:46:24,710 epoch 26 - iter 240/482 - loss 0.09113856 - samples/sec: 58.38 - lr: 0.000008
2021-07-16 04:46:50,979 epoch 26 - iter 288/482 - loss 0.09203344 - samples/sec: 58.48 - lr: 0.000008
2021-07-16 04:47:17,076 epoch 26 - iter 336/482 - loss 0.09059843 - samples/sec: 58.86 - lr: 0.000008
2021-07-16 04:47:43,168 epoch 26 - iter 384/482 - loss 0.09256913 - samples/sec: 58.87 - lr: 0.000008
2021-07-16 04:48:09,487 epoch 26 - iter 432/482 - loss 0.09220154 - samples/sec: 58.37 - lr: 0.000008
2021-07-16 04:48:35,827 epoch 26 - iter 480/482 - loss 0.09453088 - samples/sec: 58.32 - lr: 0.000008
2021-07-16 04:48:36,659 ----------------------------------------------------------------------------------------------------
2021-07-16 04:48:36,659 EPOCH 26 done: loss 0.0946 - lr 0.0000075
2021-07-16 04:48:47,744 DEV : loss 0.18194927275180817 - score 0.9765
2021-07-16 04:48:47,892 BAD EPOCHS (no improvement): 0
saving best model
2021-07-16 04:48:52,154 ----------------------------------------------------------------------------------------------------
2021-07-16 04:49:18,548 epoch 27 - iter 48/482 - loss 0.10395975 - samples/sec: 58.20 - lr: 0.000008
2021-07-16 04:49:44,802 epoch 27 - iter 96/482 - loss 0.10099570 - samples/sec: 58.51 - lr: 0.000008
2021-07-16 04:50:11,081 epoch 27 - iter 144/482 - loss 0.09286683 - samples/sec: 58.45 - lr: 0.000008
2021-07-16 04:50:37,463 epoch 27 - iter 192/482 - loss 0.09045301 - samples/sec: 58.23 - lr: 0.000008
2021-07-16 04:51:03,832 epoch 27 - iter 240/482 - loss 0.09117473 - samples/sec: 58.26 - lr: 0.000008
2021-07-16 04:51:30,270 epoch 27 - iter 288/482 - loss 0.09014459 - samples/sec: 58.10 - lr: 0.000008
2021-07-16 04:51:56,627 epoch 27 - iter 336/482 - loss 0.08987777 - samples/sec: 58.28 - lr: 0.000008
2021-07-16 04:52:23,100 epoch 27 - iter 384/482 - loss 0.09133709 - samples/sec: 58.03 - lr: 0.000008
2021-07-16 04:52:49,483 epoch 27 - iter 432/482 - loss 0.09126394 - samples/sec: 58.23 - lr: 0.000008
2021-07-16 04:53:15,823 epoch 27 - iter 480/482 - loss 0.09284701 - samples/sec: 58.32 - lr: 0.000008
2021-07-16 04:53:16,640 ----------------------------------------------------------------------------------------------------
2021-07-16 04:53:16,640 EPOCH 27 done: loss 0.0928 - lr 0.0000075
2021-07-16 04:53:27,720 DEV : loss 0.18703046441078186 - score 0.976
2021-07-16 04:53:27,868 BAD EPOCHS (no improvement): 1
2021-07-16 04:53:27,868 ----------------------------------------------------------------------------------------------------
2021-07-16 04:53:54,178 epoch 28 - iter 48/482 - loss 0.07522838 - samples/sec: 58.39 - lr: 0.000008
2021-07-16 04:54:20,559 epoch 28 - iter 96/482 - loss 0.08506770 - samples/sec: 58.23 - lr: 0.000008
2021-07-16 04:54:47,004 epoch 28 - iter 144/482 - loss 0.08403755 - samples/sec: 58.09 - lr: 0.000008
2021-07-16 04:55:13,423 epoch 28 - iter 192/482 - loss 0.08543267 - samples/sec: 58.15 - lr: 0.000008
2021-07-16 04:55:39,792 epoch 28 - iter 240/482 - loss 0.08923889 - samples/sec: 58.26 - lr: 0.000008
2021-07-16 04:56:06,191 epoch 28 - iter 288/482 - loss 0.08851946 - samples/sec: 58.19 - lr: 0.000008
2021-07-16 04:56:32,523 epoch 28 - iter 336/482 - loss 0.08885986 - samples/sec: 58.34 - lr: 0.000008
2021-07-16 04:56:58,616 epoch 28 - iter 384/482 - loss 0.09063213 - samples/sec: 58.87 - lr: 0.000008
2021-07-16 04:57:24,721 epoch 28 - iter 432/482 - loss 0.09160056 - samples/sec: 58.84 - lr: 0.000008
2021-07-16 04:57:50,910 epoch 28 - iter 480/482 - loss 0.09063819 - samples/sec: 58.66 - lr: 0.000008
2021-07-16 04:57:51,751 ----------------------------------------------------------------------------------------------------
2021-07-16 04:57:51,751 EPOCH 28 done: loss 0.0904 - lr 0.0000075
2021-07-16 04:58:04,039 DEV : loss 0.18403813242912292 - score 0.976
2021-07-16 04:58:04,187 BAD EPOCHS (no improvement): 2
2021-07-16 04:58:04,188 ----------------------------------------------------------------------------------------------------
2021-07-16 04:58:30,544 epoch 29 - iter 48/482 - loss 0.08339140 - samples/sec: 58.28 - lr: 0.000008
2021-07-16 04:58:57,007 epoch 29 - iter 96/482 - loss 0.08314893 - samples/sec: 58.05 - lr: 0.000008
2021-07-16 04:59:23,434 epoch 29 - iter 144/482 - loss 0.08531742 - samples/sec: 58.13 - lr: 0.000008
2021-07-16 04:59:49,803 epoch 29 - iter 192/482 - loss 0.08430528 - samples/sec: 58.26 - lr: 0.000008
2021-07-16 05:00:16,142 epoch 29 - iter 240/482 - loss 0.08702347 - samples/sec: 58.32 - lr: 0.000008
2021-07-16 05:00:42,562 epoch 29 - iter 288/482 - loss 0.08932111 - samples/sec: 58.14 - lr: 0.000008
2021-07-16 05:01:08,987 epoch 29 - iter 336/482 - loss 0.08844602 - samples/sec: 58.13 - lr: 0.000008
2021-07-16 05:01:35,414 epoch 29 - iter 384/482 - loss 0.08788795 - samples/sec: 58.13 - lr: 0.000008
2021-07-16 05:02:01,804 epoch 29 - iter 432/482 - loss 0.08604675 - samples/sec: 58.21 - lr: 0.000008
2021-07-16 05:02:28,288 epoch 29 - iter 480/482 - loss 0.08508027 - samples/sec: 58.00 - lr: 0.000008
2021-07-16 05:02:29,115 ----------------------------------------------------------------------------------------------------
2021-07-16 05:02:29,115 EPOCH 29 done: loss 0.0849 - lr 0.0000075
2021-07-16 05:02:40,202 DEV : loss 0.18575339019298553 - score 0.976
2021-07-16 05:02:40,348 BAD EPOCHS (no improvement): 3
2021-07-16 05:02:40,348 ----------------------------------------------------------------------------------------------------
2021-07-16 05:03:06,783 epoch 30 - iter 48/482 - loss 0.07477631 - samples/sec: 58.11 - lr: 0.000008
2021-07-16 05:03:33,118 epoch 30 - iter 96/482 - loss 0.07171180 - samples/sec: 58.33 - lr: 0.000008
2021-07-16 05:03:59,372 epoch 30 - iter 144/482 - loss 0.07653203 - samples/sec: 58.51 - lr: 0.000008
2021-07-16 05:04:25,873 epoch 30 - iter 192/482 - loss 0.07682583 - samples/sec: 57.97 - lr: 0.000008
2021-07-16 05:04:52,255 epoch 30 - iter 240/482 - loss 0.07751463 - samples/sec: 58.23 - lr: 0.000008
2021-07-16 05:05:18,743 epoch 30 - iter 288/482 - loss 0.07841462 - samples/sec: 58.00 - lr: 0.000008
2021-07-16 05:05:45,197 epoch 30 - iter 336/482 - loss 0.08067008 - samples/sec: 58.07 - lr: 0.000008
2021-07-16 05:06:11,634 epoch 30 - iter 384/482 - loss 0.08062714 - samples/sec: 58.11 - lr: 0.000008
2021-07-16 05:06:37,976 epoch 30 - iter 432/482 - loss 0.08186000 - samples/sec: 58.32 - lr: 0.000008
2021-07-16 05:07:04,432 epoch 30 - iter 480/482 - loss 0.08400511 - samples/sec: 58.07 - lr: 0.000008
2021-07-16 05:07:05,266 ----------------------------------------------------------------------------------------------------
2021-07-16 05:07:05,266 EPOCH 30 done: loss 0.0838 - lr 0.0000075
2021-07-16 05:07:16,361 DEV : loss 0.19327273964881897 - score 0.9741
Epoch    30: reducing learning rate of group 0 to 3.7500e-06.
2021-07-16 05:07:16,509 BAD EPOCHS (no improvement): 4
2021-07-16 05:07:16,509 ----------------------------------------------------------------------------------------------------
2021-07-16 05:07:42,979 epoch 31 - iter 48/482 - loss 0.09117967 - samples/sec: 58.04 - lr: 0.000004
2021-07-16 05:08:09,337 epoch 31 - iter 96/482 - loss 0.08956351 - samples/sec: 58.28 - lr: 0.000004
2021-07-16 05:08:35,656 epoch 31 - iter 144/482 - loss 0.08761129 - samples/sec: 58.37 - lr: 0.000004
2021-07-16 05:09:01,997 epoch 31 - iter 192/482 - loss 0.08639201 - samples/sec: 58.32 - lr: 0.000004
2021-07-16 05:09:28,283 epoch 31 - iter 240/482 - loss 0.08451477 - samples/sec: 58.44 - lr: 0.000004
2021-07-16 05:09:54,620 epoch 31 - iter 288/482 - loss 0.08643996 - samples/sec: 58.33 - lr: 0.000004
2021-07-16 05:10:20,979 epoch 31 - iter 336/482 - loss 0.08554470 - samples/sec: 58.28 - lr: 0.000004
2021-07-16 05:10:47,495 epoch 31 - iter 384/482 - loss 0.08392154 - samples/sec: 57.93 - lr: 0.000004
2021-07-16 05:11:13,910 epoch 31 - iter 432/482 - loss 0.08406267 - samples/sec: 58.15 - lr: 0.000004
2021-07-16 05:11:40,260 epoch 31 - iter 480/482 - loss 0.08323184 - samples/sec: 58.30 - lr: 0.000004
2021-07-16 05:11:41,090 ----------------------------------------------------------------------------------------------------
2021-07-16 05:11:41,090 EPOCH 31 done: loss 0.0835 - lr 0.0000038
2021-07-16 05:11:52,205 DEV : loss 0.19335758686065674 - score 0.9755
2021-07-16 05:11:52,351 BAD EPOCHS (no improvement): 1
2021-07-16 05:11:52,351 ----------------------------------------------------------------------------------------------------
2021-07-16 05:12:18,883 epoch 32 - iter 48/482 - loss 0.07794572 - samples/sec: 57.90 - lr: 0.000004
2021-07-16 05:12:45,323 epoch 32 - iter 96/482 - loss 0.08394300 - samples/sec: 58.10 - lr: 0.000004
2021-07-16 05:13:11,786 epoch 32 - iter 144/482 - loss 0.08060759 - samples/sec: 58.05 - lr: 0.000004
2021-07-16 05:13:38,258 epoch 32 - iter 192/482 - loss 0.07937487 - samples/sec: 58.03 - lr: 0.000004
2021-07-16 05:14:04,739 epoch 32 - iter 240/482 - loss 0.07825172 - samples/sec: 58.01 - lr: 0.000004
2021-07-16 05:14:31,183 epoch 32 - iter 288/482 - loss 0.08016153 - samples/sec: 58.09 - lr: 0.000004
2021-07-16 05:14:57,454 epoch 32 - iter 336/482 - loss 0.08155621 - samples/sec: 58.47 - lr: 0.000004
2021-07-16 05:15:23,921 epoch 32 - iter 384/482 - loss 0.08336897 - samples/sec: 58.04 - lr: 0.000004
2021-07-16 05:15:50,396 epoch 32 - iter 432/482 - loss 0.08431515 - samples/sec: 58.02 - lr: 0.000004
2021-07-16 05:16:16,864 epoch 32 - iter 480/482 - loss 0.08387807 - samples/sec: 58.04 - lr: 0.000004
2021-07-16 05:16:17,686 ----------------------------------------------------------------------------------------------------
2021-07-16 05:16:17,687 EPOCH 32 done: loss 0.0838 - lr 0.0000038
2021-07-16 05:16:29,986 DEV : loss 0.19316187500953674 - score 0.9753
2021-07-16 05:16:30,134 BAD EPOCHS (no improvement): 2
2021-07-16 05:16:30,134 ----------------------------------------------------------------------------------------------------
2021-07-16 05:16:56,422 epoch 33 - iter 48/482 - loss 0.08760992 - samples/sec: 58.44 - lr: 0.000004
2021-07-16 05:17:22,859 epoch 33 - iter 96/482 - loss 0.08581838 - samples/sec: 58.10 - lr: 0.000004
2021-07-16 05:17:49,221 epoch 33 - iter 144/482 - loss 0.08859232 - samples/sec: 58.27 - lr: 0.000004
2021-07-16 05:18:15,544 epoch 33 - iter 192/482 - loss 0.08386755 - samples/sec: 58.36 - lr: 0.000004
2021-07-16 05:18:41,836 epoch 33 - iter 240/482 - loss 0.08237360 - samples/sec: 58.43 - lr: 0.000004
2021-07-16 05:19:08,133 epoch 33 - iter 288/482 - loss 0.08086062 - samples/sec: 58.42 - lr: 0.000004
2021-07-16 05:19:34,512 epoch 33 - iter 336/482 - loss 0.07953481 - samples/sec: 58.23 - lr: 0.000004
2021-07-16 05:20:00,974 epoch 33 - iter 384/482 - loss 0.08066974 - samples/sec: 58.05 - lr: 0.000004
2021-07-16 05:20:27,139 epoch 33 - iter 432/482 - loss 0.08114631 - samples/sec: 58.71 - lr: 0.000004
2021-07-16 05:20:53,363 epoch 33 - iter 480/482 - loss 0.08213143 - samples/sec: 58.58 - lr: 0.000004
2021-07-16 05:20:54,173 ----------------------------------------------------------------------------------------------------
2021-07-16 05:20:54,174 EPOCH 33 done: loss 0.0819 - lr 0.0000038
2021-07-16 05:21:05,280 DEV : loss 0.19206354022026062 - score 0.9753
2021-07-16 05:21:05,427 BAD EPOCHS (no improvement): 3
2021-07-16 05:21:05,427 ----------------------------------------------------------------------------------------------------
2021-07-16 05:21:31,725 epoch 34 - iter 48/482 - loss 0.07695439 - samples/sec: 58.42 - lr: 0.000004
2021-07-16 05:21:58,098 epoch 34 - iter 96/482 - loss 0.07926669 - samples/sec: 58.25 - lr: 0.000004
2021-07-16 05:22:24,474 epoch 34 - iter 144/482 - loss 0.08035011 - samples/sec: 58.24 - lr: 0.000004
2021-07-16 05:22:50,818 epoch 34 - iter 192/482 - loss 0.07943328 - samples/sec: 58.31 - lr: 0.000004
2021-07-16 05:23:17,103 epoch 34 - iter 240/482 - loss 0.08123067 - samples/sec: 58.44 - lr: 0.000004
2021-07-16 05:23:43,463 epoch 34 - iter 288/482 - loss 0.08039590 - samples/sec: 58.28 - lr: 0.000004
2021-07-16 05:24:09,795 epoch 34 - iter 336/482 - loss 0.07996429 - samples/sec: 58.34 - lr: 0.000004
2021-07-16 05:24:36,122 epoch 34 - iter 384/482 - loss 0.08241229 - samples/sec: 58.35 - lr: 0.000004
2021-07-16 05:25:02,464 epoch 34 - iter 432/482 - loss 0.08087124 - samples/sec: 58.32 - lr: 0.000004
2021-07-16 05:25:28,783 epoch 34 - iter 480/482 - loss 0.08108853 - samples/sec: 58.37 - lr: 0.000004
2021-07-16 05:25:29,613 ----------------------------------------------------------------------------------------------------
2021-07-16 05:25:29,613 EPOCH 34 done: loss 0.0811 - lr 0.0000038
2021-07-16 05:25:40,725 DEV : loss 0.19280552864074707 - score 0.9741
Epoch    34: reducing learning rate of group 0 to 1.8750e-06.
2021-07-16 05:25:40,873 BAD EPOCHS (no improvement): 4
2021-07-16 05:25:40,873 ----------------------------------------------------------------------------------------------------
2021-07-16 05:25:40,874 ----------------------------------------------------------------------------------------------------
2021-07-16 05:25:40,874 learning rate too small - quitting training!
2021-07-16 05:25:40,874 ----------------------------------------------------------------------------------------------------
2021-07-16 05:25:41,780 ----------------------------------------------------------------------------------------------------
2021-07-16 05:25:41,780 Testing using best model ...
2021-07-16 05:25:41,780 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-1/rus.rst.rrt/best-model.pt
2021-07-16 05:26:45,501 0.9802	0.9850	0.9826
2021-07-16 05:26:45,501 
Results:
- F1-score (micro) 0.9826
- F1-score (macro) 0.9826

By class:
SENT       tp: 3613 - fp: 73 - fn: 55 - precision: 0.9802 - recall: 0.9850 - f1-score: 0.9826
2021-07-16 05:26:45,501 ----------------------------------------------------------------------------------------------------
