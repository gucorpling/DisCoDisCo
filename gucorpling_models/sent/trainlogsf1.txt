/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.rstdt/
2021-07-22 12:42:01,120 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.rstdt
2021-07-22 12:42:01,120 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.rstdt/sent_train.txt
2021-07-22 12:42:01,120 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.rstdt/sent_dev.txt
2021-07-22 12:42:01,120 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.rstdt/sent_test.txt
Corpus: 16907 train + 2332 dev + 5368 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 12:42:08,264 ----------------------------------------------------------------------------------------------------
2021-07-22 12:42:08,265 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 12:42:08,265 ----------------------------------------------------------------------------------------------------
2021-07-22 12:42:08,265 Corpus: "Corpus: 16907 train + 2332 dev + 5368 test sentences"
2021-07-22 12:42:08,265 ----------------------------------------------------------------------------------------------------
2021-07-22 12:42:08,265 Parameters:
2021-07-22 12:42:08,266  - learning_rate: "3e-05"
2021-07-22 12:42:08,266  - mini_batch_size: "32"
2021-07-22 12:42:08,266  - patience: "3"
2021-07-22 12:42:08,266  - anneal_factor: "0.5"
2021-07-22 12:42:08,266  - max_epochs: "40"
2021-07-22 12:42:08,266  - shuffle: "True"
2021-07-22 12:42:08,266  - train_with_dev: "False"
2021-07-22 12:42:08,266  - batch_growth_annealing: "False"
2021-07-22 12:42:08,266 ----------------------------------------------------------------------------------------------------
2021-07-22 12:42:08,266 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.rstdt"
2021-07-22 12:42:08,266 ----------------------------------------------------------------------------------------------------
2021-07-22 12:42:08,266 Device: cuda:0
2021-07-22 12:42:08,266 ----------------------------------------------------------------------------------------------------
2021-07-22 12:42:08,266 Embeddings storage mode: cpu
2021-07-22 12:42:08,269 ----------------------------------------------------------------------------------------------------
2021-07-22 12:42:37,404 epoch 1 - iter 52/529 - loss 7.02509479 - samples/sec: 57.12 - lr: 0.000030
2021-07-22 12:43:07,413 epoch 1 - iter 104/529 - loss 4.88095571 - samples/sec: 55.45 - lr: 0.000030
2021-07-22 12:43:37,278 epoch 1 - iter 156/529 - loss 3.65024051 - samples/sec: 55.72 - lr: 0.000030
2021-07-22 12:44:07,017 epoch 1 - iter 208/529 - loss 2.93493636 - samples/sec: 55.96 - lr: 0.000030
2021-07-22 12:44:36,669 epoch 1 - iter 260/529 - loss 2.46448703 - samples/sec: 56.12 - lr: 0.000030
2021-07-22 12:45:06,597 epoch 1 - iter 312/529 - loss 2.12417916 - samples/sec: 55.61 - lr: 0.000030
2021-07-22 12:45:36,410 epoch 1 - iter 364/529 - loss 1.86713289 - samples/sec: 55.82 - lr: 0.000030
2021-07-22 12:46:06,591 epoch 1 - iter 416/529 - loss 1.66897697 - samples/sec: 55.14 - lr: 0.000030
2021-07-22 12:46:36,760 epoch 1 - iter 468/529 - loss 1.50810317 - samples/sec: 55.16 - lr: 0.000030
2021-07-22 12:47:06,819 epoch 1 - iter 520/529 - loss 1.37988889 - samples/sec: 55.36 - lr: 0.000030
2021-07-22 12:47:11,697 ----------------------------------------------------------------------------------------------------
2021-07-22 12:47:11,697 EPOCH 1 done: loss 1.3601 - lr 0.0000300
2021-07-22 12:47:42,615 DEV : loss 0.11829023063182831 - score 0.9685
2021-07-22 12:47:42,680 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:47:43,324 ----------------------------------------------------------------------------------------------------
2021-07-22 12:47:55,083 epoch 2 - iter 52/529 - loss 0.20272174 - samples/sec: 141.57 - lr: 0.000030
2021-07-22 12:48:07,032 epoch 2 - iter 104/529 - loss 0.18644456 - samples/sec: 139.29 - lr: 0.000030
2021-07-22 12:48:19,299 epoch 2 - iter 156/529 - loss 0.18458291 - samples/sec: 135.68 - lr: 0.000030
2021-07-22 12:48:31,548 epoch 2 - iter 208/529 - loss 0.18323475 - samples/sec: 135.88 - lr: 0.000030
2021-07-22 12:48:43,676 epoch 2 - iter 260/529 - loss 0.17977423 - samples/sec: 137.23 - lr: 0.000030
2021-07-22 12:48:55,610 epoch 2 - iter 312/529 - loss 0.17373107 - samples/sec: 139.47 - lr: 0.000030
2021-07-22 12:49:07,644 epoch 2 - iter 364/529 - loss 0.17211404 - samples/sec: 138.30 - lr: 0.000030
2021-07-22 12:49:19,963 epoch 2 - iter 416/529 - loss 0.17107951 - samples/sec: 135.10 - lr: 0.000030
2021-07-22 12:49:32,203 epoch 2 - iter 468/529 - loss 0.17075758 - samples/sec: 135.98 - lr: 0.000030
2021-07-22 12:49:44,460 epoch 2 - iter 520/529 - loss 0.16978925 - samples/sec: 135.79 - lr: 0.000030
2021-07-22 12:49:46,470 ----------------------------------------------------------------------------------------------------
2021-07-22 12:49:46,471 EPOCH 2 done: loss 0.1687 - lr 0.0000300
2021-07-22 12:49:52,016 DEV : loss 0.0828787162899971 - score 0.9769
2021-07-22 12:49:52,080 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:49:54,266 ----------------------------------------------------------------------------------------------------
2021-07-22 12:50:06,244 epoch 3 - iter 52/529 - loss 0.14478815 - samples/sec: 138.98 - lr: 0.000030
2021-07-22 12:50:18,484 epoch 3 - iter 104/529 - loss 0.15542907 - samples/sec: 135.99 - lr: 0.000030
2021-07-22 12:50:30,871 epoch 3 - iter 156/529 - loss 0.15045340 - samples/sec: 134.36 - lr: 0.000030
2021-07-22 12:50:42,762 epoch 3 - iter 208/529 - loss 0.14384469 - samples/sec: 139.98 - lr: 0.000030
2021-07-22 12:50:54,968 epoch 3 - iter 260/529 - loss 0.14634114 - samples/sec: 136.36 - lr: 0.000030
2021-07-22 12:51:07,242 epoch 3 - iter 312/529 - loss 0.14846975 - samples/sec: 135.60 - lr: 0.000030
2021-07-22 12:51:19,320 epoch 3 - iter 364/529 - loss 0.14831982 - samples/sec: 137.81 - lr: 0.000030
2021-07-22 12:51:31,823 epoch 3 - iter 416/529 - loss 0.14640006 - samples/sec: 133.12 - lr: 0.000030
2021-07-22 12:51:43,952 epoch 3 - iter 468/529 - loss 0.14332922 - samples/sec: 137.22 - lr: 0.000030
2021-07-22 12:51:56,150 epoch 3 - iter 520/529 - loss 0.14403830 - samples/sec: 136.44 - lr: 0.000030
2021-07-22 12:51:58,136 ----------------------------------------------------------------------------------------------------
2021-07-22 12:51:58,136 EPOCH 3 done: loss 0.1445 - lr 0.0000300
2021-07-22 12:52:03,713 DEV : loss 0.07566235959529877 - score 0.979
2021-07-22 12:52:03,778 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:52:05,612 ----------------------------------------------------------------------------------------------------
2021-07-22 12:52:18,243 epoch 4 - iter 52/529 - loss 0.14156824 - samples/sec: 131.80 - lr: 0.000030
2021-07-22 12:52:30,443 epoch 4 - iter 104/529 - loss 0.13015063 - samples/sec: 136.43 - lr: 0.000030
2021-07-22 12:52:42,752 epoch 4 - iter 156/529 - loss 0.12704648 - samples/sec: 135.22 - lr: 0.000030
2021-07-22 12:52:54,895 epoch 4 - iter 208/529 - loss 0.12421180 - samples/sec: 137.07 - lr: 0.000030
2021-07-22 12:53:07,006 epoch 4 - iter 260/529 - loss 0.12387102 - samples/sec: 137.43 - lr: 0.000030
2021-07-22 12:53:19,364 epoch 4 - iter 312/529 - loss 0.12309609 - samples/sec: 134.68 - lr: 0.000030
2021-07-22 12:53:31,736 epoch 4 - iter 364/529 - loss 0.12564008 - samples/sec: 134.53 - lr: 0.000030
2021-07-22 12:53:44,036 epoch 4 - iter 416/529 - loss 0.12576713 - samples/sec: 135.31 - lr: 0.000030
2021-07-22 12:53:56,363 epoch 4 - iter 468/529 - loss 0.12585028 - samples/sec: 135.02 - lr: 0.000030
2021-07-22 12:54:08,713 epoch 4 - iter 520/529 - loss 0.12759437 - samples/sec: 134.77 - lr: 0.000030
2021-07-22 12:54:10,672 ----------------------------------------------------------------------------------------------------
2021-07-22 12:54:10,672 EPOCH 4 done: loss 0.1278 - lr 0.0000300
2021-07-22 12:54:16,277 DEV : loss 0.07572389394044876 - score 0.9792
2021-07-22 12:54:16,342 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:54:18,435 ----------------------------------------------------------------------------------------------------
2021-07-22 12:54:30,958 epoch 5 - iter 52/529 - loss 0.13235541 - samples/sec: 132.93 - lr: 0.000030
2021-07-22 12:54:43,320 epoch 5 - iter 104/529 - loss 0.13094523 - samples/sec: 134.64 - lr: 0.000030
2021-07-22 12:54:55,599 epoch 5 - iter 156/529 - loss 0.13032999 - samples/sec: 135.54 - lr: 0.000030
2021-07-22 12:55:08,031 epoch 5 - iter 208/529 - loss 0.12608428 - samples/sec: 133.87 - lr: 0.000030
2021-07-22 12:55:20,388 epoch 5 - iter 260/529 - loss 0.12753630 - samples/sec: 134.70 - lr: 0.000030
2021-07-22 12:55:33,059 epoch 5 - iter 312/529 - loss 0.12353786 - samples/sec: 131.35 - lr: 0.000030
2021-07-22 12:55:45,168 epoch 5 - iter 364/529 - loss 0.12305586 - samples/sec: 137.45 - lr: 0.000030
2021-07-22 12:55:57,650 epoch 5 - iter 416/529 - loss 0.12265918 - samples/sec: 133.34 - lr: 0.000030
2021-07-22 12:56:09,772 epoch 5 - iter 468/529 - loss 0.12191286 - samples/sec: 137.31 - lr: 0.000030
2021-07-22 12:56:21,744 epoch 5 - iter 520/529 - loss 0.12131799 - samples/sec: 139.02 - lr: 0.000030
2021-07-22 12:56:23,750 ----------------------------------------------------------------------------------------------------
2021-07-22 12:56:23,750 EPOCH 5 done: loss 0.1216 - lr 0.0000300
2021-07-22 12:56:29,311 DEV : loss 0.06779134273529053 - score 0.9804
2021-07-22 12:56:29,375 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:56:31,336 ----------------------------------------------------------------------------------------------------
2021-07-22 12:56:43,272 epoch 6 - iter 52/529 - loss 0.10630963 - samples/sec: 139.47 - lr: 0.000030
2021-07-22 12:56:55,304 epoch 6 - iter 104/529 - loss 0.11072300 - samples/sec: 138.33 - lr: 0.000030
2021-07-22 12:57:07,428 epoch 6 - iter 156/529 - loss 0.11159474 - samples/sec: 137.28 - lr: 0.000030
2021-07-22 12:57:19,709 epoch 6 - iter 208/529 - loss 0.10997014 - samples/sec: 135.52 - lr: 0.000030
2021-07-22 12:57:32,036 epoch 6 - iter 260/529 - loss 0.10856970 - samples/sec: 135.01 - lr: 0.000030
2021-07-22 12:57:44,514 epoch 6 - iter 312/529 - loss 0.11324074 - samples/sec: 133.39 - lr: 0.000030
2021-07-22 12:57:57,444 epoch 6 - iter 364/529 - loss 0.11302869 - samples/sec: 128.72 - lr: 0.000030
2021-07-22 12:58:09,851 epoch 6 - iter 416/529 - loss 0.11036563 - samples/sec: 134.15 - lr: 0.000030
2021-07-22 12:58:22,247 epoch 6 - iter 468/529 - loss 0.11108778 - samples/sec: 134.27 - lr: 0.000030
2021-07-22 12:58:34,844 epoch 6 - iter 520/529 - loss 0.11201751 - samples/sec: 132.12 - lr: 0.000030
2021-07-22 12:58:36,820 ----------------------------------------------------------------------------------------------------
2021-07-22 12:58:36,820 EPOCH 6 done: loss 0.1122 - lr 0.0000300
2021-07-22 12:58:42,386 DEV : loss 0.06527942419052124 - score 0.9816
2021-07-22 12:58:42,451 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 12:58:44,633 ----------------------------------------------------------------------------------------------------
2021-07-22 12:58:57,115 epoch 7 - iter 52/529 - loss 0.10292786 - samples/sec: 133.37 - lr: 0.000030
2021-07-22 12:59:09,396 epoch 7 - iter 104/529 - loss 0.09668873 - samples/sec: 135.52 - lr: 0.000030
2021-07-22 12:59:21,747 epoch 7 - iter 156/529 - loss 0.10395671 - samples/sec: 134.76 - lr: 0.000030
2021-07-22 12:59:34,177 epoch 7 - iter 208/529 - loss 0.11076062 - samples/sec: 133.90 - lr: 0.000030
2021-07-22 12:59:46,905 epoch 7 - iter 260/529 - loss 0.11513619 - samples/sec: 130.76 - lr: 0.000030
2021-07-22 12:59:59,178 epoch 7 - iter 312/529 - loss 0.11385431 - samples/sec: 135.61 - lr: 0.000030
2021-07-22 13:00:11,319 epoch 7 - iter 364/529 - loss 0.11270868 - samples/sec: 137.09 - lr: 0.000030
2021-07-22 13:00:23,404 epoch 7 - iter 416/529 - loss 0.11075555 - samples/sec: 137.72 - lr: 0.000030
2021-07-22 13:00:36,088 epoch 7 - iter 468/529 - loss 0.11040216 - samples/sec: 131.22 - lr: 0.000030
2021-07-22 13:00:48,105 epoch 7 - iter 520/529 - loss 0.10904260 - samples/sec: 138.51 - lr: 0.000030
2021-07-22 13:00:50,136 ----------------------------------------------------------------------------------------------------
2021-07-22 13:00:50,136 EPOCH 7 done: loss 0.1088 - lr 0.0000300
2021-07-22 13:00:55,705 DEV : loss 0.058569587767124176 - score 0.9831
2021-07-22 13:00:55,770 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:00:57,880 ----------------------------------------------------------------------------------------------------
2021-07-22 13:01:10,227 epoch 8 - iter 52/529 - loss 0.11754028 - samples/sec: 134.83 - lr: 0.000030
2021-07-22 13:01:22,709 epoch 8 - iter 104/529 - loss 0.11113204 - samples/sec: 133.35 - lr: 0.000030
2021-07-22 13:01:34,928 epoch 8 - iter 156/529 - loss 0.10548186 - samples/sec: 136.21 - lr: 0.000030
2021-07-22 13:01:47,263 epoch 8 - iter 208/529 - loss 0.10856810 - samples/sec: 134.92 - lr: 0.000030
2021-07-22 13:01:59,508 epoch 8 - iter 260/529 - loss 0.10863818 - samples/sec: 135.93 - lr: 0.000030
2021-07-22 13:02:11,851 epoch 8 - iter 312/529 - loss 0.10578988 - samples/sec: 134.84 - lr: 0.000030
2021-07-22 13:02:24,332 epoch 8 - iter 364/529 - loss 0.10194832 - samples/sec: 133.35 - lr: 0.000030
2021-07-22 13:02:36,749 epoch 8 - iter 416/529 - loss 0.10083640 - samples/sec: 134.04 - lr: 0.000030
2021-07-22 13:02:49,105 epoch 8 - iter 468/529 - loss 0.10107906 - samples/sec: 134.70 - lr: 0.000030
2021-07-22 13:03:01,468 epoch 8 - iter 520/529 - loss 0.10112995 - samples/sec: 134.62 - lr: 0.000030
2021-07-22 13:03:03,487 ----------------------------------------------------------------------------------------------------
2021-07-22 13:03:03,487 EPOCH 8 done: loss 0.1009 - lr 0.0000300
2021-07-22 13:03:09,090 DEV : loss 0.06740760058164597 - score 0.9817
2021-07-22 13:03:09,156 BAD EPOCHS (no improvement): 1
2021-07-22 13:03:09,156 ----------------------------------------------------------------------------------------------------
2021-07-22 13:03:21,515 epoch 9 - iter 52/529 - loss 0.09647688 - samples/sec: 134.68 - lr: 0.000030
2021-07-22 13:03:33,947 epoch 9 - iter 104/529 - loss 0.10480891 - samples/sec: 133.87 - lr: 0.000030
2021-07-22 13:03:46,226 epoch 9 - iter 156/529 - loss 0.10203365 - samples/sec: 135.55 - lr: 0.000030
2021-07-22 13:03:58,631 epoch 9 - iter 208/529 - loss 0.10190044 - samples/sec: 134.16 - lr: 0.000030
2021-07-22 13:04:11,103 epoch 9 - iter 260/529 - loss 0.10132367 - samples/sec: 133.45 - lr: 0.000030
2021-07-22 13:04:23,648 epoch 9 - iter 312/529 - loss 0.10186031 - samples/sec: 132.67 - lr: 0.000030
2021-07-22 13:04:35,908 epoch 9 - iter 364/529 - loss 0.10063070 - samples/sec: 135.76 - lr: 0.000030
2021-07-22 13:04:48,395 epoch 9 - iter 416/529 - loss 0.09950977 - samples/sec: 133.28 - lr: 0.000030
2021-07-22 13:05:00,364 epoch 9 - iter 468/529 - loss 0.09865541 - samples/sec: 139.06 - lr: 0.000030
2021-07-22 13:05:12,619 epoch 9 - iter 520/529 - loss 0.09631034 - samples/sec: 135.81 - lr: 0.000030
2021-07-22 13:05:14,600 ----------------------------------------------------------------------------------------------------
2021-07-22 13:05:14,600 EPOCH 9 done: loss 0.0959 - lr 0.0000300
2021-07-22 13:05:20,207 DEV : loss 0.0524936281144619 - score 0.9844
2021-07-22 13:05:20,273 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:05:22,469 ----------------------------------------------------------------------------------------------------
2021-07-22 13:05:35,130 epoch 10 - iter 52/529 - loss 0.08747226 - samples/sec: 131.48 - lr: 0.000030
2021-07-22 13:05:47,275 epoch 10 - iter 104/529 - loss 0.08858107 - samples/sec: 137.04 - lr: 0.000030
2021-07-22 13:05:59,632 epoch 10 - iter 156/529 - loss 0.09525527 - samples/sec: 134.69 - lr: 0.000030
2021-07-22 13:06:11,978 epoch 10 - iter 208/529 - loss 0.09495894 - samples/sec: 134.81 - lr: 0.000030
2021-07-22 13:06:24,290 epoch 10 - iter 260/529 - loss 0.09404059 - samples/sec: 135.18 - lr: 0.000030
2021-07-22 13:06:36,621 epoch 10 - iter 312/529 - loss 0.09333577 - samples/sec: 134.98 - lr: 0.000030
2021-07-22 13:06:49,136 epoch 10 - iter 364/529 - loss 0.09212488 - samples/sec: 132.99 - lr: 0.000030
2021-07-22 13:07:01,208 epoch 10 - iter 416/529 - loss 0.09149553 - samples/sec: 137.86 - lr: 0.000030
2021-07-22 13:07:13,605 epoch 10 - iter 468/529 - loss 0.08952821 - samples/sec: 134.26 - lr: 0.000030
2021-07-22 13:07:25,766 epoch 10 - iter 520/529 - loss 0.08912280 - samples/sec: 136.86 - lr: 0.000030
2021-07-22 13:07:27,790 ----------------------------------------------------------------------------------------------------
2021-07-22 13:07:27,790 EPOCH 10 done: loss 0.0892 - lr 0.0000300
2021-07-22 13:07:33,973 DEV : loss 0.06724278628826141 - score 0.9829
2021-07-22 13:07:34,038 BAD EPOCHS (no improvement): 1
2021-07-22 13:07:34,039 ----------------------------------------------------------------------------------------------------
2021-07-22 13:07:46,156 epoch 11 - iter 52/529 - loss 0.08669437 - samples/sec: 137.38 - lr: 0.000030
2021-07-22 13:07:58,214 epoch 11 - iter 104/529 - loss 0.08094623 - samples/sec: 138.02 - lr: 0.000030
2021-07-22 13:08:10,568 epoch 11 - iter 156/529 - loss 0.08417833 - samples/sec: 134.73 - lr: 0.000030
2021-07-22 13:08:23,031 epoch 11 - iter 208/529 - loss 0.08031621 - samples/sec: 133.54 - lr: 0.000030
2021-07-22 13:08:35,452 epoch 11 - iter 260/529 - loss 0.08417463 - samples/sec: 134.00 - lr: 0.000030
2021-07-22 13:08:47,929 epoch 11 - iter 312/529 - loss 0.08421709 - samples/sec: 133.39 - lr: 0.000030
2021-07-22 13:09:00,176 epoch 11 - iter 364/529 - loss 0.08318087 - samples/sec: 135.90 - lr: 0.000030
2021-07-22 13:09:12,660 epoch 11 - iter 416/529 - loss 0.08406585 - samples/sec: 133.32 - lr: 0.000030
2021-07-22 13:09:24,916 epoch 11 - iter 468/529 - loss 0.08406339 - samples/sec: 135.80 - lr: 0.000030
2021-07-22 13:09:37,431 epoch 11 - iter 520/529 - loss 0.08460113 - samples/sec: 132.99 - lr: 0.000030
2021-07-22 13:09:39,483 ----------------------------------------------------------------------------------------------------
2021-07-22 13:09:39,483 EPOCH 11 done: loss 0.0848 - lr 0.0000300
2021-07-22 13:09:45,077 DEV : loss 0.053131382912397385 - score 0.9848
2021-07-22 13:09:45,143 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:09:47,305 ----------------------------------------------------------------------------------------------------
2021-07-22 13:09:59,532 epoch 12 - iter 52/529 - loss 0.07865803 - samples/sec: 136.15 - lr: 0.000030
2021-07-22 13:10:11,956 epoch 12 - iter 104/529 - loss 0.07790349 - samples/sec: 133.97 - lr: 0.000030
2021-07-22 13:10:24,308 epoch 12 - iter 156/529 - loss 0.08162048 - samples/sec: 134.74 - lr: 0.000030
2021-07-22 13:10:36,600 epoch 12 - iter 208/529 - loss 0.08052391 - samples/sec: 135.40 - lr: 0.000030
2021-07-22 13:10:49,279 epoch 12 - iter 260/529 - loss 0.08278012 - samples/sec: 131.27 - lr: 0.000030
2021-07-22 13:11:01,372 epoch 12 - iter 312/529 - loss 0.08318323 - samples/sec: 137.64 - lr: 0.000030
2021-07-22 13:11:13,871 epoch 12 - iter 364/529 - loss 0.08393000 - samples/sec: 133.16 - lr: 0.000030
2021-07-22 13:11:26,079 epoch 12 - iter 416/529 - loss 0.08223721 - samples/sec: 136.34 - lr: 0.000030
2021-07-22 13:11:38,609 epoch 12 - iter 468/529 - loss 0.08123535 - samples/sec: 132.83 - lr: 0.000030
2021-07-22 13:11:50,804 epoch 12 - iter 520/529 - loss 0.08025185 - samples/sec: 136.48 - lr: 0.000030
2021-07-22 13:11:52,902 ----------------------------------------------------------------------------------------------------
2021-07-22 13:11:52,902 EPOCH 12 done: loss 0.0798 - lr 0.0000300
2021-07-22 13:11:58,545 DEV : loss 0.059284090995788574 - score 0.9845
2021-07-22 13:11:58,610 BAD EPOCHS (no improvement): 1
2021-07-22 13:11:58,610 ----------------------------------------------------------------------------------------------------
2021-07-22 13:12:10,859 epoch 13 - iter 52/529 - loss 0.07915894 - samples/sec: 135.89 - lr: 0.000030
2021-07-22 13:12:22,883 epoch 13 - iter 104/529 - loss 0.07372156 - samples/sec: 138.42 - lr: 0.000030
2021-07-22 13:12:35,170 epoch 13 - iter 156/529 - loss 0.08118173 - samples/sec: 135.46 - lr: 0.000030
2021-07-22 13:12:47,493 epoch 13 - iter 208/529 - loss 0.08258600 - samples/sec: 135.07 - lr: 0.000030
2021-07-22 13:12:59,684 epoch 13 - iter 260/529 - loss 0.07883855 - samples/sec: 136.52 - lr: 0.000030
2021-07-22 13:13:11,848 epoch 13 - iter 312/529 - loss 0.07812124 - samples/sec: 136.84 - lr: 0.000030
2021-07-22 13:13:24,064 epoch 13 - iter 364/529 - loss 0.07736162 - samples/sec: 136.25 - lr: 0.000030
2021-07-22 13:13:36,808 epoch 13 - iter 416/529 - loss 0.07588463 - samples/sec: 130.60 - lr: 0.000030
2021-07-22 13:13:49,015 epoch 13 - iter 468/529 - loss 0.07611755 - samples/sec: 136.34 - lr: 0.000030
2021-07-22 13:14:01,308 epoch 13 - iter 520/529 - loss 0.07490045 - samples/sec: 135.39 - lr: 0.000030
2021-07-22 13:14:03,314 ----------------------------------------------------------------------------------------------------
2021-07-22 13:14:03,315 EPOCH 13 done: loss 0.0747 - lr 0.0000300
2021-07-22 13:14:08,956 DEV : loss 0.052421338856220245 - score 0.9851
2021-07-22 13:14:09,021 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:14:11,143 ----------------------------------------------------------------------------------------------------
2021-07-22 13:14:23,396 epoch 14 - iter 52/529 - loss 0.07585383 - samples/sec: 135.86 - lr: 0.000030
2021-07-22 13:14:35,718 epoch 14 - iter 104/529 - loss 0.07871598 - samples/sec: 135.07 - lr: 0.000030
2021-07-22 13:14:48,090 epoch 14 - iter 156/529 - loss 0.07664860 - samples/sec: 134.53 - lr: 0.000030
2021-07-22 13:15:00,671 epoch 14 - iter 208/529 - loss 0.08102829 - samples/sec: 132.29 - lr: 0.000030
2021-07-22 13:15:12,795 epoch 14 - iter 260/529 - loss 0.07975998 - samples/sec: 137.28 - lr: 0.000030
2021-07-22 13:15:25,340 epoch 14 - iter 312/529 - loss 0.07964570 - samples/sec: 132.67 - lr: 0.000030
2021-07-22 13:15:37,781 epoch 14 - iter 364/529 - loss 0.07997491 - samples/sec: 133.78 - lr: 0.000030
2021-07-22 13:15:50,002 epoch 14 - iter 416/529 - loss 0.07920208 - samples/sec: 136.19 - lr: 0.000030
2021-07-22 13:16:02,608 epoch 14 - iter 468/529 - loss 0.07858622 - samples/sec: 132.02 - lr: 0.000030
2021-07-22 13:16:14,784 epoch 14 - iter 520/529 - loss 0.07861781 - samples/sec: 136.70 - lr: 0.000030
2021-07-22 13:16:16,843 ----------------------------------------------------------------------------------------------------
2021-07-22 13:16:16,844 EPOCH 14 done: loss 0.0784 - lr 0.0000300
2021-07-22 13:16:22,473 DEV : loss 0.04725232347846031 - score 0.9854
2021-07-22 13:16:22,539 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:16:24,665 ----------------------------------------------------------------------------------------------------
2021-07-22 13:16:36,919 epoch 15 - iter 52/529 - loss 0.08288322 - samples/sec: 135.85 - lr: 0.000030
2021-07-22 13:16:49,424 epoch 15 - iter 104/529 - loss 0.07734599 - samples/sec: 133.10 - lr: 0.000030
2021-07-22 13:17:01,880 epoch 15 - iter 156/529 - loss 0.07689826 - samples/sec: 133.62 - lr: 0.000030
2021-07-22 13:17:13,962 epoch 15 - iter 208/529 - loss 0.07101278 - samples/sec: 137.75 - lr: 0.000030
2021-07-22 13:17:26,207 epoch 15 - iter 260/529 - loss 0.07203253 - samples/sec: 135.92 - lr: 0.000030
2021-07-22 13:17:38,477 epoch 15 - iter 312/529 - loss 0.06916915 - samples/sec: 135.65 - lr: 0.000030
2021-07-22 13:17:50,900 epoch 15 - iter 364/529 - loss 0.06902660 - samples/sec: 133.97 - lr: 0.000030
2021-07-22 13:18:03,353 epoch 15 - iter 416/529 - loss 0.06842527 - samples/sec: 133.66 - lr: 0.000030
2021-07-22 13:18:15,891 epoch 15 - iter 468/529 - loss 0.06825726 - samples/sec: 132.74 - lr: 0.000030
2021-07-22 13:18:28,183 epoch 15 - iter 520/529 - loss 0.06978724 - samples/sec: 135.40 - lr: 0.000030
2021-07-22 13:18:30,057 ----------------------------------------------------------------------------------------------------
2021-07-22 13:18:30,058 EPOCH 15 done: loss 0.0700 - lr 0.0000300
2021-07-22 13:18:36,254 DEV : loss 0.0478588230907917 - score 0.9848
2021-07-22 13:18:36,319 BAD EPOCHS (no improvement): 1
2021-07-22 13:18:36,319 ----------------------------------------------------------------------------------------------------
2021-07-22 13:18:48,515 epoch 16 - iter 52/529 - loss 0.07105733 - samples/sec: 136.49 - lr: 0.000030
2021-07-22 13:19:00,712 epoch 16 - iter 104/529 - loss 0.06333877 - samples/sec: 136.46 - lr: 0.000030
2021-07-22 13:19:12,775 epoch 16 - iter 156/529 - loss 0.06799072 - samples/sec: 137.97 - lr: 0.000030
2021-07-22 13:19:24,947 epoch 16 - iter 208/529 - loss 0.06709481 - samples/sec: 136.75 - lr: 0.000030
2021-07-22 13:19:37,345 epoch 16 - iter 260/529 - loss 0.06654256 - samples/sec: 134.24 - lr: 0.000030
2021-07-22 13:19:49,806 epoch 16 - iter 312/529 - loss 0.06512501 - samples/sec: 133.56 - lr: 0.000030
2021-07-22 13:20:02,264 epoch 16 - iter 364/529 - loss 0.06518125 - samples/sec: 133.60 - lr: 0.000030
2021-07-22 13:20:14,672 epoch 16 - iter 416/529 - loss 0.06493563 - samples/sec: 134.14 - lr: 0.000030
2021-07-22 13:20:27,148 epoch 16 - iter 468/529 - loss 0.06486052 - samples/sec: 133.40 - lr: 0.000030
2021-07-22 13:20:39,763 epoch 16 - iter 520/529 - loss 0.06513097 - samples/sec: 131.93 - lr: 0.000030
2021-07-22 13:20:41,723 ----------------------------------------------------------------------------------------------------
2021-07-22 13:20:41,723 EPOCH 16 done: loss 0.0647 - lr 0.0000300
2021-07-22 13:20:47,322 DEV : loss 0.048280175775289536 - score 0.9848
2021-07-22 13:20:47,387 BAD EPOCHS (no improvement): 2
2021-07-22 13:20:47,388 ----------------------------------------------------------------------------------------------------
2021-07-22 13:20:59,792 epoch 17 - iter 52/529 - loss 0.05426717 - samples/sec: 134.19 - lr: 0.000030
2021-07-22 13:21:12,188 epoch 17 - iter 104/529 - loss 0.05469601 - samples/sec: 134.27 - lr: 0.000030
2021-07-22 13:21:24,475 epoch 17 - iter 156/529 - loss 0.05465986 - samples/sec: 135.46 - lr: 0.000030
2021-07-22 13:21:36,915 epoch 17 - iter 208/529 - loss 0.05564619 - samples/sec: 133.78 - lr: 0.000030
2021-07-22 13:21:49,135 epoch 17 - iter 260/529 - loss 0.05419285 - samples/sec: 136.21 - lr: 0.000030
2021-07-22 13:22:01,529 epoch 17 - iter 312/529 - loss 0.05446787 - samples/sec: 134.29 - lr: 0.000030
2021-07-22 13:22:14,224 epoch 17 - iter 364/529 - loss 0.05632214 - samples/sec: 131.10 - lr: 0.000030
2021-07-22 13:22:26,469 epoch 17 - iter 416/529 - loss 0.05948885 - samples/sec: 135.92 - lr: 0.000030
2021-07-22 13:22:38,731 epoch 17 - iter 468/529 - loss 0.06055014 - samples/sec: 135.73 - lr: 0.000030
2021-07-22 13:22:50,991 epoch 17 - iter 520/529 - loss 0.06254667 - samples/sec: 135.76 - lr: 0.000030
2021-07-22 13:22:52,990 ----------------------------------------------------------------------------------------------------
2021-07-22 13:22:52,991 EPOCH 17 done: loss 0.0622 - lr 0.0000300
2021-07-22 13:22:58,636 DEV : loss 0.051892515271902084 - score 0.9857
2021-07-22 13:22:58,701 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:23:00,892 ----------------------------------------------------------------------------------------------------
2021-07-22 13:23:13,208 epoch 18 - iter 52/529 - loss 0.06656467 - samples/sec: 135.16 - lr: 0.000030
2021-07-22 13:23:25,362 epoch 18 - iter 104/529 - loss 0.06227714 - samples/sec: 136.95 - lr: 0.000030
2021-07-22 13:23:37,453 epoch 18 - iter 156/529 - loss 0.05915628 - samples/sec: 137.66 - lr: 0.000030
2021-07-22 13:23:49,746 epoch 18 - iter 208/529 - loss 0.06066766 - samples/sec: 135.38 - lr: 0.000030
2021-07-22 13:24:02,022 epoch 18 - iter 260/529 - loss 0.06043490 - samples/sec: 135.58 - lr: 0.000030
2021-07-22 13:24:14,578 epoch 18 - iter 312/529 - loss 0.06047311 - samples/sec: 132.56 - lr: 0.000030
2021-07-22 13:24:26,811 epoch 18 - iter 364/529 - loss 0.06191535 - samples/sec: 136.05 - lr: 0.000030
2021-07-22 13:24:39,199 epoch 18 - iter 416/529 - loss 0.06233013 - samples/sec: 134.36 - lr: 0.000030
2021-07-22 13:24:51,620 epoch 18 - iter 468/529 - loss 0.06105237 - samples/sec: 134.00 - lr: 0.000030
2021-07-22 13:25:03,983 epoch 18 - iter 520/529 - loss 0.06102106 - samples/sec: 134.63 - lr: 0.000030
2021-07-22 13:25:06,012 ----------------------------------------------------------------------------------------------------
2021-07-22 13:25:06,013 EPOCH 18 done: loss 0.0609 - lr 0.0000300
2021-07-22 13:25:11,644 DEV : loss 0.046039238572120667 - score 0.986
2021-07-22 13:25:11,708 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:25:13,859 ----------------------------------------------------------------------------------------------------
2021-07-22 13:25:26,374 epoch 19 - iter 52/529 - loss 0.05520547 - samples/sec: 133.03 - lr: 0.000030
2021-07-22 13:25:38,408 epoch 19 - iter 104/529 - loss 0.05585948 - samples/sec: 138.31 - lr: 0.000030
2021-07-22 13:25:50,442 epoch 19 - iter 156/529 - loss 0.05589610 - samples/sec: 138.31 - lr: 0.000030
2021-07-22 13:26:02,844 epoch 19 - iter 208/529 - loss 0.05658274 - samples/sec: 134.20 - lr: 0.000030
2021-07-22 13:26:15,171 epoch 19 - iter 260/529 - loss 0.05737530 - samples/sec: 135.02 - lr: 0.000030
2021-07-22 13:26:27,379 epoch 19 - iter 312/529 - loss 0.05631906 - samples/sec: 136.34 - lr: 0.000030
2021-07-22 13:26:39,643 epoch 19 - iter 364/529 - loss 0.05563168 - samples/sec: 135.71 - lr: 0.000030
2021-07-22 13:26:51,625 epoch 19 - iter 416/529 - loss 0.05632112 - samples/sec: 138.91 - lr: 0.000030
2021-07-22 13:27:04,191 epoch 19 - iter 468/529 - loss 0.05666308 - samples/sec: 132.45 - lr: 0.000030
2021-07-22 13:27:16,488 epoch 19 - iter 520/529 - loss 0.05695164 - samples/sec: 135.35 - lr: 0.000030
2021-07-22 13:27:18,453 ----------------------------------------------------------------------------------------------------
2021-07-22 13:27:18,454 EPOCH 19 done: loss 0.0570 - lr 0.0000300
2021-07-22 13:27:24,079 DEV : loss 0.04506751894950867 - score 0.9888
2021-07-22 13:27:24,144 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:27:26,274 ----------------------------------------------------------------------------------------------------
2021-07-22 13:27:38,511 epoch 20 - iter 52/529 - loss 0.04965714 - samples/sec: 136.03 - lr: 0.000030
2021-07-22 13:27:51,017 epoch 20 - iter 104/529 - loss 0.04761647 - samples/sec: 133.09 - lr: 0.000030
2021-07-22 13:28:04,058 epoch 20 - iter 156/529 - loss 0.05667938 - samples/sec: 127.63 - lr: 0.000030
2021-07-22 13:28:16,387 epoch 20 - iter 208/529 - loss 0.05589645 - samples/sec: 135.00 - lr: 0.000030
2021-07-22 13:28:28,719 epoch 20 - iter 260/529 - loss 0.05511329 - samples/sec: 134.97 - lr: 0.000030
2021-07-22 13:28:41,084 epoch 20 - iter 312/529 - loss 0.05601580 - samples/sec: 134.60 - lr: 0.000030
2021-07-22 13:28:53,346 epoch 20 - iter 364/529 - loss 0.05545340 - samples/sec: 135.73 - lr: 0.000030
2021-07-22 13:29:05,776 epoch 20 - iter 416/529 - loss 0.05649407 - samples/sec: 133.90 - lr: 0.000030
2021-07-22 13:29:18,310 epoch 20 - iter 468/529 - loss 0.05581043 - samples/sec: 132.78 - lr: 0.000030
2021-07-22 13:29:30,619 epoch 20 - iter 520/529 - loss 0.05626703 - samples/sec: 135.22 - lr: 0.000030
2021-07-22 13:29:32,671 ----------------------------------------------------------------------------------------------------
2021-07-22 13:29:32,671 EPOCH 20 done: loss 0.0565 - lr 0.0000300
2021-07-22 13:29:38,273 DEV : loss 0.04547882825136185 - score 0.9879
2021-07-22 13:29:38,338 BAD EPOCHS (no improvement): 1
2021-07-22 13:29:38,339 ----------------------------------------------------------------------------------------------------
2021-07-22 13:29:50,740 epoch 21 - iter 52/529 - loss 0.05811930 - samples/sec: 134.23 - lr: 0.000030
2021-07-22 13:30:03,229 epoch 21 - iter 104/529 - loss 0.05977701 - samples/sec: 133.26 - lr: 0.000030
2021-07-22 13:30:15,756 epoch 21 - iter 156/529 - loss 0.05724023 - samples/sec: 132.87 - lr: 0.000030
2021-07-22 13:30:28,047 epoch 21 - iter 208/529 - loss 0.06000609 - samples/sec: 135.42 - lr: 0.000030
2021-07-22 13:30:40,412 epoch 21 - iter 260/529 - loss 0.06004034 - samples/sec: 134.60 - lr: 0.000030
2021-07-22 13:30:52,764 epoch 21 - iter 312/529 - loss 0.05858347 - samples/sec: 134.75 - lr: 0.000030
2021-07-22 13:31:04,922 epoch 21 - iter 364/529 - loss 0.05940381 - samples/sec: 136.89 - lr: 0.000030
2021-07-22 13:31:17,488 epoch 21 - iter 416/529 - loss 0.06076490 - samples/sec: 132.44 - lr: 0.000030
2021-07-22 13:31:29,872 epoch 21 - iter 468/529 - loss 0.06060192 - samples/sec: 134.40 - lr: 0.000030
2021-07-22 13:31:42,169 epoch 21 - iter 520/529 - loss 0.06038852 - samples/sec: 135.36 - lr: 0.000030
2021-07-22 13:31:44,135 ----------------------------------------------------------------------------------------------------
2021-07-22 13:31:44,135 EPOCH 21 done: loss 0.0600 - lr 0.0000300
2021-07-22 13:31:49,729 DEV : loss 0.044220034033060074 - score 0.9882
2021-07-22 13:31:49,794 BAD EPOCHS (no improvement): 2
2021-07-22 13:31:49,795 ----------------------------------------------------------------------------------------------------
2021-07-22 13:32:02,343 epoch 22 - iter 52/529 - loss 0.05991412 - samples/sec: 132.65 - lr: 0.000030
2021-07-22 13:32:14,972 epoch 22 - iter 104/529 - loss 0.06106086 - samples/sec: 131.79 - lr: 0.000030
2021-07-22 13:32:27,137 epoch 22 - iter 156/529 - loss 0.05649990 - samples/sec: 136.82 - lr: 0.000030
2021-07-22 13:32:39,672 epoch 22 - iter 208/529 - loss 0.05906557 - samples/sec: 132.77 - lr: 0.000030
2021-07-22 13:32:51,839 epoch 22 - iter 260/529 - loss 0.05755096 - samples/sec: 136.80 - lr: 0.000030
2021-07-22 13:33:03,871 epoch 22 - iter 312/529 - loss 0.05676783 - samples/sec: 138.32 - lr: 0.000030
2021-07-22 13:33:16,151 epoch 22 - iter 364/529 - loss 0.05651775 - samples/sec: 135.54 - lr: 0.000030
2021-07-22 13:33:28,463 epoch 22 - iter 416/529 - loss 0.05578581 - samples/sec: 135.18 - lr: 0.000030
2021-07-22 13:33:40,875 epoch 22 - iter 468/529 - loss 0.05443859 - samples/sec: 134.09 - lr: 0.000030
2021-07-22 13:33:53,240 epoch 22 - iter 520/529 - loss 0.05420902 - samples/sec: 134.61 - lr: 0.000030
2021-07-22 13:33:55,357 ----------------------------------------------------------------------------------------------------
2021-07-22 13:33:55,357 EPOCH 22 done: loss 0.0541 - lr 0.0000300
2021-07-22 13:34:00,996 DEV : loss 0.04501386359333992 - score 0.9882
2021-07-22 13:34:01,062 BAD EPOCHS (no improvement): 3
2021-07-22 13:34:01,062 ----------------------------------------------------------------------------------------------------
2021-07-22 13:34:13,252 epoch 23 - iter 52/529 - loss 0.04280151 - samples/sec: 136.56 - lr: 0.000030
2021-07-22 13:34:25,463 epoch 23 - iter 104/529 - loss 0.04935926 - samples/sec: 136.30 - lr: 0.000030
2021-07-22 13:34:38,016 epoch 23 - iter 156/529 - loss 0.04976441 - samples/sec: 132.58 - lr: 0.000030
2021-07-22 13:34:50,168 epoch 23 - iter 208/529 - loss 0.04956618 - samples/sec: 136.97 - lr: 0.000030
2021-07-22 13:35:02,474 epoch 23 - iter 260/529 - loss 0.04878791 - samples/sec: 135.25 - lr: 0.000030
2021-07-22 13:35:14,435 epoch 23 - iter 312/529 - loss 0.04996634 - samples/sec: 139.15 - lr: 0.000030
2021-07-22 13:35:26,622 epoch 23 - iter 364/529 - loss 0.05032808 - samples/sec: 136.57 - lr: 0.000030
2021-07-22 13:35:38,692 epoch 23 - iter 416/529 - loss 0.05007707 - samples/sec: 137.90 - lr: 0.000030
2021-07-22 13:35:51,231 epoch 23 - iter 468/529 - loss 0.05156407 - samples/sec: 132.74 - lr: 0.000030
2021-07-22 13:36:03,623 epoch 23 - iter 520/529 - loss 0.05140437 - samples/sec: 134.31 - lr: 0.000030
2021-07-22 13:36:05,617 ----------------------------------------------------------------------------------------------------
2021-07-22 13:36:05,618 EPOCH 23 done: loss 0.0520 - lr 0.0000300
2021-07-22 13:36:11,227 DEV : loss 0.04496167600154877 - score 0.9882
Epoch    23: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 13:36:11,292 BAD EPOCHS (no improvement): 4
2021-07-22 13:36:11,293 ----------------------------------------------------------------------------------------------------
2021-07-22 13:36:23,729 epoch 24 - iter 52/529 - loss 0.05466507 - samples/sec: 133.85 - lr: 0.000015
2021-07-22 13:36:35,980 epoch 24 - iter 104/529 - loss 0.04985189 - samples/sec: 135.85 - lr: 0.000015
2021-07-22 13:36:48,384 epoch 24 - iter 156/529 - loss 0.05233680 - samples/sec: 134.18 - lr: 0.000015
2021-07-22 13:37:00,908 epoch 24 - iter 208/529 - loss 0.05364947 - samples/sec: 132.90 - lr: 0.000015
2021-07-22 13:37:13,288 epoch 24 - iter 260/529 - loss 0.05233839 - samples/sec: 134.44 - lr: 0.000015
2021-07-22 13:37:26,020 epoch 24 - iter 312/529 - loss 0.05273320 - samples/sec: 130.73 - lr: 0.000015
2021-07-22 13:37:38,259 epoch 24 - iter 364/529 - loss 0.05203285 - samples/sec: 135.98 - lr: 0.000015
2021-07-22 13:37:50,655 epoch 24 - iter 416/529 - loss 0.05182980 - samples/sec: 134.27 - lr: 0.000015
2021-07-22 13:38:02,891 epoch 24 - iter 468/529 - loss 0.05287059 - samples/sec: 136.03 - lr: 0.000015
2021-07-22 13:38:15,144 epoch 24 - iter 520/529 - loss 0.05292579 - samples/sec: 135.84 - lr: 0.000015
2021-07-22 13:38:17,139 ----------------------------------------------------------------------------------------------------
2021-07-22 13:38:17,139 EPOCH 24 done: loss 0.0529 - lr 0.0000150
2021-07-22 13:38:23,305 DEV : loss 0.04616796597838402 - score 0.9879
2021-07-22 13:38:23,371 BAD EPOCHS (no improvement): 1
2021-07-22 13:38:23,371 ----------------------------------------------------------------------------------------------------
2021-07-22 13:38:35,608 epoch 25 - iter 52/529 - loss 0.04420422 - samples/sec: 136.03 - lr: 0.000015
2021-07-22 13:38:47,770 epoch 25 - iter 104/529 - loss 0.04636883 - samples/sec: 136.85 - lr: 0.000015
2021-07-22 13:39:00,077 epoch 25 - iter 156/529 - loss 0.04856656 - samples/sec: 135.25 - lr: 0.000015
2021-07-22 13:39:12,405 epoch 25 - iter 208/529 - loss 0.04688031 - samples/sec: 135.01 - lr: 0.000015
2021-07-22 13:39:24,928 epoch 25 - iter 260/529 - loss 0.04763045 - samples/sec: 132.90 - lr: 0.000015
2021-07-22 13:39:37,207 epoch 25 - iter 312/529 - loss 0.04698038 - samples/sec: 135.55 - lr: 0.000015
2021-07-22 13:39:49,376 epoch 25 - iter 364/529 - loss 0.04580195 - samples/sec: 136.77 - lr: 0.000015
2021-07-22 13:40:01,665 epoch 25 - iter 416/529 - loss 0.04587339 - samples/sec: 135.43 - lr: 0.000015
2021-07-22 13:40:14,232 epoch 25 - iter 468/529 - loss 0.04646447 - samples/sec: 132.45 - lr: 0.000015
2021-07-22 13:40:26,558 epoch 25 - iter 520/529 - loss 0.04705184 - samples/sec: 135.02 - lr: 0.000015
2021-07-22 13:40:28,622 ----------------------------------------------------------------------------------------------------
2021-07-22 13:40:28,622 EPOCH 25 done: loss 0.0466 - lr 0.0000150
2021-07-22 13:40:34,251 DEV : loss 0.045599207282066345 - score 0.9872
2021-07-22 13:40:34,317 BAD EPOCHS (no improvement): 2
2021-07-22 13:40:34,317 ----------------------------------------------------------------------------------------------------
2021-07-22 13:40:46,652 epoch 26 - iter 52/529 - loss 0.05167658 - samples/sec: 134.95 - lr: 0.000015
2021-07-22 13:40:58,838 epoch 26 - iter 104/529 - loss 0.04751041 - samples/sec: 136.58 - lr: 0.000015
2021-07-22 13:41:11,280 epoch 26 - iter 156/529 - loss 0.04527719 - samples/sec: 133.77 - lr: 0.000015
2021-07-22 13:41:23,764 epoch 26 - iter 208/529 - loss 0.04967637 - samples/sec: 133.33 - lr: 0.000015
2021-07-22 13:41:36,265 epoch 26 - iter 260/529 - loss 0.04879931 - samples/sec: 133.15 - lr: 0.000015
2021-07-22 13:41:48,507 epoch 26 - iter 312/529 - loss 0.04685168 - samples/sec: 135.95 - lr: 0.000015
2021-07-22 13:42:00,505 epoch 26 - iter 364/529 - loss 0.04830882 - samples/sec: 138.72 - lr: 0.000015
2021-07-22 13:42:13,144 epoch 26 - iter 416/529 - loss 0.04891799 - samples/sec: 131.69 - lr: 0.000015
2021-07-22 13:42:25,348 epoch 26 - iter 468/529 - loss 0.04894906 - samples/sec: 136.39 - lr: 0.000015
2021-07-22 13:42:37,616 epoch 26 - iter 520/529 - loss 0.04882925 - samples/sec: 135.66 - lr: 0.000015
2021-07-22 13:42:39,606 ----------------------------------------------------------------------------------------------------
2021-07-22 13:42:39,606 EPOCH 26 done: loss 0.0487 - lr 0.0000150
2021-07-22 13:42:45,262 DEV : loss 0.04472828656435013 - score 0.9865
2021-07-22 13:42:45,327 BAD EPOCHS (no improvement): 3
2021-07-22 13:42:45,327 ----------------------------------------------------------------------------------------------------
2021-07-22 13:42:57,491 epoch 27 - iter 52/529 - loss 0.04658552 - samples/sec: 136.85 - lr: 0.000015
2021-07-22 13:43:10,019 epoch 27 - iter 104/529 - loss 0.04317214 - samples/sec: 132.85 - lr: 0.000015
2021-07-22 13:43:22,527 epoch 27 - iter 156/529 - loss 0.04371580 - samples/sec: 133.06 - lr: 0.000015
2021-07-22 13:43:34,716 epoch 27 - iter 208/529 - loss 0.04240288 - samples/sec: 136.54 - lr: 0.000015
2021-07-22 13:43:46,844 epoch 27 - iter 260/529 - loss 0.04370201 - samples/sec: 137.24 - lr: 0.000015
2021-07-22 13:43:59,043 epoch 27 - iter 312/529 - loss 0.04345357 - samples/sec: 136.43 - lr: 0.000015
2021-07-22 13:44:11,447 epoch 27 - iter 364/529 - loss 0.04365211 - samples/sec: 134.19 - lr: 0.000015
2021-07-22 13:44:23,581 epoch 27 - iter 416/529 - loss 0.04329289 - samples/sec: 137.17 - lr: 0.000015
2021-07-22 13:44:36,135 epoch 27 - iter 468/529 - loss 0.04493162 - samples/sec: 132.57 - lr: 0.000015
2021-07-22 13:44:48,735 epoch 27 - iter 520/529 - loss 0.04470612 - samples/sec: 132.09 - lr: 0.000015
2021-07-22 13:44:50,742 ----------------------------------------------------------------------------------------------------
2021-07-22 13:44:50,742 EPOCH 27 done: loss 0.0448 - lr 0.0000150
2021-07-22 13:44:56,350 DEV : loss 0.044316332787275314 - score 0.9885
Epoch    27: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 13:44:56,416 BAD EPOCHS (no improvement): 4
2021-07-22 13:44:56,417 ----------------------------------------------------------------------------------------------------
2021-07-22 13:45:08,540 epoch 28 - iter 52/529 - loss 0.03727971 - samples/sec: 137.31 - lr: 0.000008
2021-07-22 13:45:21,036 epoch 28 - iter 104/529 - loss 0.03926381 - samples/sec: 133.19 - lr: 0.000008
2021-07-22 13:45:33,432 epoch 28 - iter 156/529 - loss 0.04067944 - samples/sec: 134.27 - lr: 0.000008
2021-07-22 13:45:45,814 epoch 28 - iter 208/529 - loss 0.04326822 - samples/sec: 134.42 - lr: 0.000008
2021-07-22 13:45:58,171 epoch 28 - iter 260/529 - loss 0.04360138 - samples/sec: 134.69 - lr: 0.000008
2021-07-22 13:46:10,600 epoch 28 - iter 312/529 - loss 0.04276806 - samples/sec: 133.91 - lr: 0.000008
2021-07-22 13:46:23,199 epoch 28 - iter 364/529 - loss 0.04462899 - samples/sec: 132.11 - lr: 0.000008
2021-07-22 13:46:35,468 epoch 28 - iter 416/529 - loss 0.04419070 - samples/sec: 135.65 - lr: 0.000008
2021-07-22 13:46:47,512 epoch 28 - iter 468/529 - loss 0.04431102 - samples/sec: 138.19 - lr: 0.000008
2021-07-22 13:46:59,910 epoch 28 - iter 520/529 - loss 0.04444302 - samples/sec: 134.24 - lr: 0.000008
2021-07-22 13:47:01,923 ----------------------------------------------------------------------------------------------------
2021-07-22 13:47:01,924 EPOCH 28 done: loss 0.0446 - lr 0.0000075
2021-07-22 13:47:07,573 DEV : loss 0.04404013231396675 - score 0.9882
2021-07-22 13:47:07,639 BAD EPOCHS (no improvement): 1
2021-07-22 13:47:07,639 ----------------------------------------------------------------------------------------------------
2021-07-22 13:47:20,063 epoch 29 - iter 52/529 - loss 0.04904664 - samples/sec: 133.97 - lr: 0.000008
2021-07-22 13:47:32,330 epoch 29 - iter 104/529 - loss 0.04460633 - samples/sec: 135.68 - lr: 0.000008
2021-07-22 13:47:44,876 epoch 29 - iter 156/529 - loss 0.04395847 - samples/sec: 132.66 - lr: 0.000008
2021-07-22 13:47:57,093 epoch 29 - iter 208/529 - loss 0.04354500 - samples/sec: 136.23 - lr: 0.000008
2021-07-22 13:48:09,501 epoch 29 - iter 260/529 - loss 0.04412521 - samples/sec: 134.14 - lr: 0.000008
2021-07-22 13:48:22,012 epoch 29 - iter 312/529 - loss 0.04623832 - samples/sec: 133.03 - lr: 0.000008
2021-07-22 13:48:34,927 epoch 29 - iter 364/529 - loss 0.04585654 - samples/sec: 128.87 - lr: 0.000008
2021-07-22 13:48:47,375 epoch 29 - iter 416/529 - loss 0.04627881 - samples/sec: 133.71 - lr: 0.000008
2021-07-22 13:48:59,622 epoch 29 - iter 468/529 - loss 0.04631608 - samples/sec: 135.90 - lr: 0.000008
2021-07-22 13:49:11,737 epoch 29 - iter 520/529 - loss 0.04633239 - samples/sec: 137.39 - lr: 0.000008
2021-07-22 13:49:13,673 ----------------------------------------------------------------------------------------------------
2021-07-22 13:49:13,674 EPOCH 29 done: loss 0.0464 - lr 0.0000075
2021-07-22 13:49:19,287 DEV : loss 0.04361841455101967 - score 0.9882
2021-07-22 13:49:19,353 BAD EPOCHS (no improvement): 2
2021-07-22 13:49:19,353 ----------------------------------------------------------------------------------------------------
2021-07-22 13:49:31,553 epoch 30 - iter 52/529 - loss 0.04451261 - samples/sec: 136.45 - lr: 0.000008
2021-07-22 13:49:43,757 epoch 30 - iter 104/529 - loss 0.04634864 - samples/sec: 136.38 - lr: 0.000008
2021-07-22 13:49:56,164 epoch 30 - iter 156/529 - loss 0.04789752 - samples/sec: 134.15 - lr: 0.000008
2021-07-22 13:50:08,497 epoch 30 - iter 208/529 - loss 0.04737502 - samples/sec: 134.95 - lr: 0.000008
2021-07-22 13:50:20,619 epoch 30 - iter 260/529 - loss 0.04830779 - samples/sec: 137.29 - lr: 0.000008
2021-07-22 13:50:32,916 epoch 30 - iter 312/529 - loss 0.04739215 - samples/sec: 135.35 - lr: 0.000008
2021-07-22 13:50:45,256 epoch 30 - iter 364/529 - loss 0.04686067 - samples/sec: 134.88 - lr: 0.000008
2021-07-22 13:50:57,647 epoch 30 - iter 416/529 - loss 0.04711619 - samples/sec: 134.32 - lr: 0.000008
2021-07-22 13:51:10,135 epoch 30 - iter 468/529 - loss 0.04578941 - samples/sec: 133.28 - lr: 0.000008
2021-07-22 13:51:22,568 epoch 30 - iter 520/529 - loss 0.04555899 - samples/sec: 133.88 - lr: 0.000008
2021-07-22 13:51:24,660 ----------------------------------------------------------------------------------------------------
2021-07-22 13:51:24,660 EPOCH 30 done: loss 0.0453 - lr 0.0000075
2021-07-22 13:51:30,308 DEV : loss 0.044482551515102386 - score 0.9885
2021-07-22 13:51:30,373 BAD EPOCHS (no improvement): 3
2021-07-22 13:51:30,373 ----------------------------------------------------------------------------------------------------
2021-07-22 13:51:42,840 epoch 31 - iter 52/529 - loss 0.04785539 - samples/sec: 133.52 - lr: 0.000008
2021-07-22 13:51:55,077 epoch 31 - iter 104/529 - loss 0.04790623 - samples/sec: 136.01 - lr: 0.000008
2021-07-22 13:52:07,569 epoch 31 - iter 156/529 - loss 0.04603493 - samples/sec: 133.24 - lr: 0.000008
2021-07-22 13:52:19,894 epoch 31 - iter 208/529 - loss 0.04302365 - samples/sec: 135.04 - lr: 0.000008
2021-07-22 13:52:32,259 epoch 31 - iter 260/529 - loss 0.04289216 - samples/sec: 134.61 - lr: 0.000008
2021-07-22 13:52:44,395 epoch 31 - iter 312/529 - loss 0.04131565 - samples/sec: 137.15 - lr: 0.000008
2021-07-22 13:52:56,627 epoch 31 - iter 364/529 - loss 0.04082310 - samples/sec: 136.06 - lr: 0.000008
2021-07-22 13:53:09,173 epoch 31 - iter 416/529 - loss 0.04224248 - samples/sec: 132.66 - lr: 0.000008
2021-07-22 13:53:21,315 epoch 31 - iter 468/529 - loss 0.04202383 - samples/sec: 137.08 - lr: 0.000008
2021-07-22 13:53:33,415 epoch 31 - iter 520/529 - loss 0.04224734 - samples/sec: 137.55 - lr: 0.000008
2021-07-22 13:53:35,431 ----------------------------------------------------------------------------------------------------
2021-07-22 13:53:35,431 EPOCH 31 done: loss 0.0424 - lr 0.0000075
2021-07-22 13:53:41,030 DEV : loss 0.04350414127111435 - score 0.9891
2021-07-22 13:53:41,098 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 13:53:43,351 ----------------------------------------------------------------------------------------------------
2021-07-22 13:53:55,374 epoch 32 - iter 52/529 - loss 0.03632086 - samples/sec: 138.45 - lr: 0.000008
2021-07-22 13:54:07,873 epoch 32 - iter 104/529 - loss 0.04089327 - samples/sec: 133.17 - lr: 0.000008
2021-07-22 13:54:20,141 epoch 32 - iter 156/529 - loss 0.04315381 - samples/sec: 135.67 - lr: 0.000008
2021-07-22 13:54:32,576 epoch 32 - iter 208/529 - loss 0.04398253 - samples/sec: 133.85 - lr: 0.000008
2021-07-22 13:54:44,880 epoch 32 - iter 260/529 - loss 0.04558832 - samples/sec: 135.27 - lr: 0.000008
2021-07-22 13:54:57,020 epoch 32 - iter 312/529 - loss 0.04621392 - samples/sec: 137.09 - lr: 0.000008
2021-07-22 13:55:09,390 epoch 32 - iter 364/529 - loss 0.04602623 - samples/sec: 134.55 - lr: 0.000008
2021-07-22 13:55:21,912 epoch 32 - iter 416/529 - loss 0.04601353 - samples/sec: 132.91 - lr: 0.000008
2021-07-22 13:55:34,088 epoch 32 - iter 468/529 - loss 0.04610268 - samples/sec: 136.70 - lr: 0.000008
2021-07-22 13:55:46,617 epoch 32 - iter 520/529 - loss 0.04705131 - samples/sec: 132.84 - lr: 0.000008
2021-07-22 13:55:48,704 ----------------------------------------------------------------------------------------------------
2021-07-22 13:55:48,704 EPOCH 32 done: loss 0.0466 - lr 0.0000075
2021-07-22 13:55:54,315 DEV : loss 0.04508841782808304 - score 0.9876
2021-07-22 13:55:54,381 BAD EPOCHS (no improvement): 1
2021-07-22 13:55:54,381 ----------------------------------------------------------------------------------------------------
2021-07-22 13:56:07,018 epoch 33 - iter 52/529 - loss 0.04655516 - samples/sec: 131.72 - lr: 0.000008
2021-07-22 13:56:19,381 epoch 33 - iter 104/529 - loss 0.04726176 - samples/sec: 134.63 - lr: 0.000008
2021-07-22 13:56:31,891 epoch 33 - iter 156/529 - loss 0.04602531 - samples/sec: 133.04 - lr: 0.000008
2021-07-22 13:56:43,956 epoch 33 - iter 208/529 - loss 0.04546501 - samples/sec: 137.95 - lr: 0.000008
2021-07-22 13:56:56,039 epoch 33 - iter 260/529 - loss 0.04454376 - samples/sec: 137.75 - lr: 0.000008
2021-07-22 13:57:08,100 epoch 33 - iter 312/529 - loss 0.04410283 - samples/sec: 137.99 - lr: 0.000008
2021-07-22 13:57:20,545 epoch 33 - iter 364/529 - loss 0.04299795 - samples/sec: 133.74 - lr: 0.000008
2021-07-22 13:57:32,983 epoch 33 - iter 416/529 - loss 0.04302771 - samples/sec: 133.81 - lr: 0.000008
2021-07-22 13:57:45,360 epoch 33 - iter 468/529 - loss 0.04374698 - samples/sec: 134.48 - lr: 0.000008
2021-07-22 13:57:57,790 epoch 33 - iter 520/529 - loss 0.04347906 - samples/sec: 133.90 - lr: 0.000008
2021-07-22 13:57:59,832 ----------------------------------------------------------------------------------------------------
2021-07-22 13:57:59,832 EPOCH 33 done: loss 0.0437 - lr 0.0000075
2021-07-22 13:58:06,030 DEV : loss 0.04291508346796036 - score 0.9882
2021-07-22 13:58:06,096 BAD EPOCHS (no improvement): 2
2021-07-22 13:58:06,096 ----------------------------------------------------------------------------------------------------
2021-07-22 13:58:18,480 epoch 34 - iter 52/529 - loss 0.04307331 - samples/sec: 134.41 - lr: 0.000008
2021-07-22 13:58:31,031 epoch 34 - iter 104/529 - loss 0.04363968 - samples/sec: 132.61 - lr: 0.000008
2021-07-22 13:58:43,081 epoch 34 - iter 156/529 - loss 0.04404042 - samples/sec: 138.13 - lr: 0.000008
2021-07-22 13:58:55,283 epoch 34 - iter 208/529 - loss 0.04607101 - samples/sec: 136.40 - lr: 0.000008
2021-07-22 13:59:07,829 epoch 34 - iter 260/529 - loss 0.04392527 - samples/sec: 132.67 - lr: 0.000008
2021-07-22 13:59:20,276 epoch 34 - iter 312/529 - loss 0.04818570 - samples/sec: 133.71 - lr: 0.000008
2021-07-22 13:59:32,523 epoch 34 - iter 364/529 - loss 0.04653166 - samples/sec: 135.90 - lr: 0.000008
2021-07-22 13:59:44,941 epoch 34 - iter 416/529 - loss 0.04675970 - samples/sec: 134.03 - lr: 0.000008
2021-07-22 13:59:57,294 epoch 34 - iter 468/529 - loss 0.04488476 - samples/sec: 134.74 - lr: 0.000008
2021-07-22 14:00:09,592 epoch 34 - iter 520/529 - loss 0.04606063 - samples/sec: 135.34 - lr: 0.000008
2021-07-22 14:00:11,482 ----------------------------------------------------------------------------------------------------
2021-07-22 14:00:11,483 EPOCH 34 done: loss 0.0461 - lr 0.0000075
2021-07-22 14:00:17,097 DEV : loss 0.042527712881565094 - score 0.9882
2021-07-22 14:00:17,163 BAD EPOCHS (no improvement): 3
2021-07-22 14:00:17,164 ----------------------------------------------------------------------------------------------------
2021-07-22 14:00:29,759 epoch 35 - iter 52/529 - loss 0.03920009 - samples/sec: 132.16 - lr: 0.000008
2021-07-22 14:00:42,151 epoch 35 - iter 104/529 - loss 0.03916764 - samples/sec: 134.31 - lr: 0.000008
2021-07-22 14:00:54,455 epoch 35 - iter 156/529 - loss 0.03793163 - samples/sec: 135.28 - lr: 0.000008
2021-07-22 14:01:06,938 epoch 35 - iter 208/529 - loss 0.03920786 - samples/sec: 133.33 - lr: 0.000008
2021-07-22 14:01:18,636 epoch 35 - iter 260/529 - loss 0.03993847 - samples/sec: 142.28 - lr: 0.000008
2021-07-22 14:01:30,702 epoch 35 - iter 312/529 - loss 0.04372462 - samples/sec: 137.93 - lr: 0.000008
2021-07-22 14:01:42,923 epoch 35 - iter 364/529 - loss 0.04459212 - samples/sec: 136.19 - lr: 0.000008
2021-07-22 14:01:55,160 epoch 35 - iter 416/529 - loss 0.04411978 - samples/sec: 136.02 - lr: 0.000008
2021-07-22 14:02:07,379 epoch 35 - iter 468/529 - loss 0.04407912 - samples/sec: 136.21 - lr: 0.000008
2021-07-22 14:02:20,030 epoch 35 - iter 520/529 - loss 0.04443810 - samples/sec: 131.56 - lr: 0.000008
2021-07-22 14:02:21,921 ----------------------------------------------------------------------------------------------------
2021-07-22 14:02:21,922 EPOCH 35 done: loss 0.0444 - lr 0.0000075
2021-07-22 14:02:27,526 DEV : loss 0.04236394539475441 - score 0.9885
Epoch    35: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 14:02:27,593 BAD EPOCHS (no improvement): 4
2021-07-22 14:02:27,593 ----------------------------------------------------------------------------------------------------
2021-07-22 14:02:39,655 epoch 36 - iter 52/529 - loss 0.04342950 - samples/sec: 138.01 - lr: 0.000004
2021-07-22 14:02:52,032 epoch 36 - iter 104/529 - loss 0.04403330 - samples/sec: 134.47 - lr: 0.000004
2021-07-22 14:03:04,073 epoch 36 - iter 156/529 - loss 0.04288128 - samples/sec: 138.23 - lr: 0.000004
2021-07-22 14:03:16,283 epoch 36 - iter 208/529 - loss 0.04106936 - samples/sec: 136.31 - lr: 0.000004
2021-07-22 14:03:28,736 epoch 36 - iter 260/529 - loss 0.04158686 - samples/sec: 133.65 - lr: 0.000004
2021-07-22 14:03:41,037 epoch 36 - iter 312/529 - loss 0.04262711 - samples/sec: 135.31 - lr: 0.000004
2021-07-22 14:03:53,515 epoch 36 - iter 364/529 - loss 0.04228569 - samples/sec: 133.39 - lr: 0.000004
2021-07-22 14:04:06,011 epoch 36 - iter 416/529 - loss 0.04099419 - samples/sec: 133.18 - lr: 0.000004
2021-07-22 14:04:18,371 epoch 36 - iter 468/529 - loss 0.04114119 - samples/sec: 134.66 - lr: 0.000004
2021-07-22 14:04:30,879 epoch 36 - iter 520/529 - loss 0.04149227 - samples/sec: 133.07 - lr: 0.000004
2021-07-22 14:04:32,943 ----------------------------------------------------------------------------------------------------
2021-07-22 14:04:32,943 EPOCH 36 done: loss 0.0414 - lr 0.0000038
2021-07-22 14:04:38,545 DEV : loss 0.042220503091812134 - score 0.9891
2021-07-22 14:04:38,634 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:04:40,780 ----------------------------------------------------------------------------------------------------
2021-07-22 14:04:53,197 epoch 37 - iter 52/529 - loss 0.04067876 - samples/sec: 134.07 - lr: 0.000004
2021-07-22 14:05:05,628 epoch 37 - iter 104/529 - loss 0.03554715 - samples/sec: 133.88 - lr: 0.000004
2021-07-22 14:05:17,868 epoch 37 - iter 156/529 - loss 0.03958256 - samples/sec: 135.98 - lr: 0.000004
2021-07-22 14:05:30,206 epoch 37 - iter 208/529 - loss 0.04331122 - samples/sec: 134.89 - lr: 0.000004
2021-07-22 14:05:42,587 epoch 37 - iter 260/529 - loss 0.04435594 - samples/sec: 134.43 - lr: 0.000004
2021-07-22 14:05:54,896 epoch 37 - iter 312/529 - loss 0.04259548 - samples/sec: 135.22 - lr: 0.000004
2021-07-22 14:06:07,200 epoch 37 - iter 364/529 - loss 0.04283486 - samples/sec: 135.27 - lr: 0.000004
2021-07-22 14:06:19,930 epoch 37 - iter 416/529 - loss 0.04257492 - samples/sec: 130.74 - lr: 0.000004
2021-07-22 14:06:32,340 epoch 37 - iter 468/529 - loss 0.04265055 - samples/sec: 134.11 - lr: 0.000004
2021-07-22 14:06:44,501 epoch 37 - iter 520/529 - loss 0.04253485 - samples/sec: 136.87 - lr: 0.000004
2021-07-22 14:06:46,545 ----------------------------------------------------------------------------------------------------
2021-07-22 14:06:46,546 EPOCH 37 done: loss 0.0422 - lr 0.0000038
2021-07-22 14:06:52,204 DEV : loss 0.04329985752701759 - score 0.9891
2021-07-22 14:06:52,270 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:06:54,348 ----------------------------------------------------------------------------------------------------
2021-07-22 14:07:06,676 epoch 38 - iter 52/529 - loss 0.03753916 - samples/sec: 135.03 - lr: 0.000004
2021-07-22 14:07:19,192 epoch 38 - iter 104/529 - loss 0.04139654 - samples/sec: 132.98 - lr: 0.000004
2021-07-22 14:07:31,428 epoch 38 - iter 156/529 - loss 0.04169851 - samples/sec: 136.03 - lr: 0.000004
2021-07-22 14:07:43,636 epoch 38 - iter 208/529 - loss 0.03900216 - samples/sec: 136.33 - lr: 0.000004
2021-07-22 14:07:55,888 epoch 38 - iter 260/529 - loss 0.03986120 - samples/sec: 135.85 - lr: 0.000004
2021-07-22 14:08:08,066 epoch 38 - iter 312/529 - loss 0.04192647 - samples/sec: 136.66 - lr: 0.000004
2021-07-22 14:08:20,331 epoch 38 - iter 364/529 - loss 0.04228227 - samples/sec: 135.70 - lr: 0.000004
2021-07-22 14:08:32,591 epoch 38 - iter 416/529 - loss 0.04277540 - samples/sec: 135.76 - lr: 0.000004
2021-07-22 14:08:44,892 epoch 38 - iter 468/529 - loss 0.04353664 - samples/sec: 135.30 - lr: 0.000004
2021-07-22 14:08:57,314 epoch 38 - iter 520/529 - loss 0.04350292 - samples/sec: 133.99 - lr: 0.000004
2021-07-22 14:08:59,251 ----------------------------------------------------------------------------------------------------
2021-07-22 14:08:59,251 EPOCH 38 done: loss 0.0436 - lr 0.0000038
2021-07-22 14:09:05,432 DEV : loss 0.04292645677924156 - score 0.9888
2021-07-22 14:09:05,499 BAD EPOCHS (no improvement): 1
2021-07-22 14:09:05,499 ----------------------------------------------------------------------------------------------------
2021-07-22 14:09:17,699 epoch 39 - iter 52/529 - loss 0.04078393 - samples/sec: 136.45 - lr: 0.000004
2021-07-22 14:09:30,180 epoch 39 - iter 104/529 - loss 0.03835152 - samples/sec: 133.35 - lr: 0.000004
2021-07-22 14:09:42,380 epoch 39 - iter 156/529 - loss 0.03843409 - samples/sec: 136.42 - lr: 0.000004
2021-07-22 14:09:54,684 epoch 39 - iter 208/529 - loss 0.03873631 - samples/sec: 135.27 - lr: 0.000004
2021-07-22 14:10:06,860 epoch 39 - iter 260/529 - loss 0.04054549 - samples/sec: 136.69 - lr: 0.000004
2021-07-22 14:10:18,919 epoch 39 - iter 312/529 - loss 0.03932053 - samples/sec: 138.03 - lr: 0.000004
2021-07-22 14:10:31,482 epoch 39 - iter 364/529 - loss 0.04157850 - samples/sec: 132.47 - lr: 0.000004
2021-07-22 14:10:43,304 epoch 39 - iter 416/529 - loss 0.04108695 - samples/sec: 140.79 - lr: 0.000004
2021-07-22 14:10:55,703 epoch 39 - iter 468/529 - loss 0.04082032 - samples/sec: 134.23 - lr: 0.000004
2021-07-22 14:11:07,828 epoch 39 - iter 520/529 - loss 0.04182202 - samples/sec: 137.27 - lr: 0.000004
2021-07-22 14:11:09,914 ----------------------------------------------------------------------------------------------------
2021-07-22 14:11:09,915 EPOCH 39 done: loss 0.0420 - lr 0.0000038
2021-07-22 14:11:15,560 DEV : loss 0.042947907000780106 - score 0.9898
2021-07-22 14:11:15,628 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:11:17,820 ----------------------------------------------------------------------------------------------------
2021-07-22 14:11:29,957 epoch 40 - iter 52/529 - loss 0.03239955 - samples/sec: 137.17 - lr: 0.000004
2021-07-22 14:11:42,236 epoch 40 - iter 104/529 - loss 0.03588047 - samples/sec: 135.55 - lr: 0.000004
2021-07-22 14:11:54,300 epoch 40 - iter 156/529 - loss 0.03470671 - samples/sec: 137.96 - lr: 0.000004
2021-07-22 14:12:06,585 epoch 40 - iter 208/529 - loss 0.03789987 - samples/sec: 135.48 - lr: 0.000004
2021-07-22 14:12:18,849 epoch 40 - iter 260/529 - loss 0.03839757 - samples/sec: 135.71 - lr: 0.000004
2021-07-22 14:12:31,248 epoch 40 - iter 312/529 - loss 0.03851310 - samples/sec: 134.24 - lr: 0.000004
2021-07-22 14:12:43,501 epoch 40 - iter 364/529 - loss 0.03969112 - samples/sec: 135.83 - lr: 0.000004
2021-07-22 14:12:55,856 epoch 40 - iter 416/529 - loss 0.04055673 - samples/sec: 134.72 - lr: 0.000004
2021-07-22 14:13:08,520 epoch 40 - iter 468/529 - loss 0.04111070 - samples/sec: 131.42 - lr: 0.000004
2021-07-22 14:13:20,880 epoch 40 - iter 520/529 - loss 0.04185118 - samples/sec: 134.66 - lr: 0.000004
2021-07-22 14:13:22,838 ----------------------------------------------------------------------------------------------------
2021-07-22 14:13:22,839 EPOCH 40 done: loss 0.0423 - lr 0.0000038
2021-07-22 14:13:28,479 DEV : loss 0.04308035597205162 - score 0.9888
2021-07-22 14:13:28,545 BAD EPOCHS (no improvement): 1
2021-07-22 14:13:29,189 ----------------------------------------------------------------------------------------------------
2021-07-22 14:13:29,189 Testing using best model ...
2021-07-22 14:13:29,190 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.rstdt/best-model.pt
2021-07-22 14:14:41,480 0.9869	0.9935	0.9902
2021-07-22 14:14:41,481 
Results:
- F1-score (micro) 0.9902
- F1-score (macro) 0.9891

By class:
SENT       tp: 1570 - fp: 47 - fn: 23 - precision: 0.9709 - recall: 0.9856 - f1-score: 0.9782
X          tp: 1958 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 14:14:41,481 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/tur.pdtb.tdb/
2021-07-22 14:14:41,497 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/tur.pdtb.tdb
2021-07-22 14:14:41,497 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/tur.pdtb.tdb/sent_train.txt
2021-07-22 14:14:41,498 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/tur.pdtb.tdb/sent_dev.txt
2021-07-22 14:14:41,500 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/tur.pdtb.tdb/sent_test.txt
Corpus: 44496 train + 7479 dev + 16478 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 14:14:53,800 ----------------------------------------------------------------------------------------------------
2021-07-22 14:14:53,802 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(32000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 14:14:53,802 ----------------------------------------------------------------------------------------------------
2021-07-22 14:14:53,802 Corpus: "Corpus: 44496 train + 7479 dev + 16478 test sentences"
2021-07-22 14:14:53,802 ----------------------------------------------------------------------------------------------------
2021-07-22 14:14:53,802 Parameters:
2021-07-22 14:14:53,802  - learning_rate: "3e-05"
2021-07-22 14:14:53,802  - mini_batch_size: "32"
2021-07-22 14:14:53,802  - patience: "3"
2021-07-22 14:14:53,802  - anneal_factor: "0.5"
2021-07-22 14:14:53,802  - max_epochs: "40"
2021-07-22 14:14:53,802  - shuffle: "True"
2021-07-22 14:14:53,802  - train_with_dev: "False"
2021-07-22 14:14:53,802  - batch_growth_annealing: "False"
2021-07-22 14:14:53,802 ----------------------------------------------------------------------------------------------------
2021-07-22 14:14:53,802 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/tur.pdtb.tdb"
2021-07-22 14:14:53,802 ----------------------------------------------------------------------------------------------------
2021-07-22 14:14:53,802 Device: cuda:0
2021-07-22 14:14:53,802 ----------------------------------------------------------------------------------------------------
2021-07-22 14:14:53,802 Embeddings storage mode: cpu
2021-07-22 14:14:53,805 ----------------------------------------------------------------------------------------------------
2021-07-22 14:16:10,291 epoch 1 - iter 139/1391 - loss 4.34166081 - samples/sec: 58.16 - lr: 0.000030
2021-07-22 14:17:29,454 epoch 1 - iter 278/1391 - loss 2.60084738 - samples/sec: 56.19 - lr: 0.000030
2021-07-22 14:18:50,776 epoch 1 - iter 417/1391 - loss 1.88332530 - samples/sec: 54.70 - lr: 0.000030
2021-07-22 14:20:16,442 epoch 1 - iter 556/1391 - loss 1.48982606 - samples/sec: 51.93 - lr: 0.000030
2021-07-22 14:21:42,368 epoch 1 - iter 695/1391 - loss 1.24895049 - samples/sec: 51.77 - lr: 0.000030
2021-07-22 14:23:03,859 epoch 1 - iter 834/1391 - loss 1.08506739 - samples/sec: 54.59 - lr: 0.000030
2021-07-22 14:24:24,233 epoch 1 - iter 973/1391 - loss 0.96767001 - samples/sec: 55.35 - lr: 0.000030
2021-07-22 14:25:44,714 epoch 1 - iter 1112/1391 - loss 0.87752741 - samples/sec: 55.27 - lr: 0.000030
2021-07-22 14:27:04,566 epoch 1 - iter 1251/1391 - loss 0.80630959 - samples/sec: 55.71 - lr: 0.000030
2021-07-22 14:28:23,958 epoch 1 - iter 1390/1391 - loss 0.74912706 - samples/sec: 56.03 - lr: 0.000030
2021-07-22 14:28:24,259 ----------------------------------------------------------------------------------------------------
2021-07-22 14:28:24,259 EPOCH 1 done: loss 0.7488 - lr 0.0000300
2021-07-22 14:30:00,566 DEV : loss 0.16815370321273804 - score 0.9593
2021-07-22 14:30:00,747 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:30:01,316 ----------------------------------------------------------------------------------------------------
2021-07-22 14:30:32,786 epoch 2 - iter 139/1391 - loss 0.22073875 - samples/sec: 141.38 - lr: 0.000030
2021-07-22 14:31:04,447 epoch 2 - iter 278/1391 - loss 0.21742069 - samples/sec: 140.52 - lr: 0.000030
2021-07-22 14:31:36,169 epoch 2 - iter 417/1391 - loss 0.21382850 - samples/sec: 140.25 - lr: 0.000030
2021-07-22 14:32:07,879 epoch 2 - iter 556/1391 - loss 0.21444544 - samples/sec: 140.30 - lr: 0.000030
2021-07-22 14:32:39,509 epoch 2 - iter 695/1391 - loss 0.21433272 - samples/sec: 140.66 - lr: 0.000030
2021-07-22 14:33:11,162 epoch 2 - iter 834/1391 - loss 0.21291784 - samples/sec: 140.56 - lr: 0.000030
2021-07-22 14:33:42,783 epoch 2 - iter 973/1391 - loss 0.20962729 - samples/sec: 140.70 - lr: 0.000030
2021-07-22 14:34:14,209 epoch 2 - iter 1112/1391 - loss 0.20928020 - samples/sec: 141.57 - lr: 0.000030
2021-07-22 14:34:45,711 epoch 2 - iter 1251/1391 - loss 0.21009209 - samples/sec: 141.23 - lr: 0.000030
2021-07-22 14:35:16,795 epoch 2 - iter 1390/1391 - loss 0.20834028 - samples/sec: 143.13 - lr: 0.000030
2021-07-22 14:35:16,949 ----------------------------------------------------------------------------------------------------
2021-07-22 14:35:16,949 EPOCH 2 done: loss 0.2083 - lr 0.0000300
2021-07-22 14:35:34,041 DEV : loss 0.15520401298999786 - score 0.9631
2021-07-22 14:35:34,224 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:35:36,500 ----------------------------------------------------------------------------------------------------
2021-07-22 14:36:07,954 epoch 3 - iter 139/1391 - loss 0.19174654 - samples/sec: 141.46 - lr: 0.000030
2021-07-22 14:36:39,414 epoch 3 - iter 278/1391 - loss 0.18712759 - samples/sec: 141.42 - lr: 0.000030
2021-07-22 14:37:11,094 epoch 3 - iter 417/1391 - loss 0.18681517 - samples/sec: 140.43 - lr: 0.000030
2021-07-22 14:37:42,793 epoch 3 - iter 556/1391 - loss 0.18828098 - samples/sec: 140.35 - lr: 0.000030
2021-07-22 14:38:14,683 epoch 3 - iter 695/1391 - loss 0.18806485 - samples/sec: 139.51 - lr: 0.000030
2021-07-22 14:38:46,603 epoch 3 - iter 834/1391 - loss 0.18877880 - samples/sec: 139.38 - lr: 0.000030
2021-07-22 14:39:18,539 epoch 3 - iter 973/1391 - loss 0.18790738 - samples/sec: 139.31 - lr: 0.000030
2021-07-22 14:39:51,000 epoch 3 - iter 1112/1391 - loss 0.18610823 - samples/sec: 137.05 - lr: 0.000030
2021-07-22 14:40:22,855 epoch 3 - iter 1251/1391 - loss 0.18428481 - samples/sec: 139.66 - lr: 0.000030
2021-07-22 14:40:54,431 epoch 3 - iter 1390/1391 - loss 0.18385059 - samples/sec: 140.90 - lr: 0.000030
2021-07-22 14:40:54,588 ----------------------------------------------------------------------------------------------------
2021-07-22 14:40:54,588 EPOCH 3 done: loss 0.1839 - lr 0.0000300
2021-07-22 14:41:13,034 DEV : loss 0.14844654500484467 - score 0.9642
2021-07-22 14:41:13,218 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:41:15,358 ----------------------------------------------------------------------------------------------------
2021-07-22 14:41:47,440 epoch 4 - iter 139/1391 - loss 0.17291117 - samples/sec: 138.70 - lr: 0.000030
2021-07-22 14:42:19,641 epoch 4 - iter 278/1391 - loss 0.17692659 - samples/sec: 138.16 - lr: 0.000030
2021-07-22 14:42:51,528 epoch 4 - iter 417/1391 - loss 0.18033450 - samples/sec: 139.52 - lr: 0.000030
2021-07-22 14:43:23,652 epoch 4 - iter 556/1391 - loss 0.17782363 - samples/sec: 138.50 - lr: 0.000030
2021-07-22 14:43:55,704 epoch 4 - iter 695/1391 - loss 0.17957151 - samples/sec: 138.81 - lr: 0.000030
2021-07-22 14:44:27,884 epoch 4 - iter 834/1391 - loss 0.17792574 - samples/sec: 138.25 - lr: 0.000030
2021-07-22 14:44:59,738 epoch 4 - iter 973/1391 - loss 0.17513197 - samples/sec: 139.67 - lr: 0.000030
2021-07-22 14:45:31,520 epoch 4 - iter 1112/1391 - loss 0.17116289 - samples/sec: 139.98 - lr: 0.000030
2021-07-22 14:46:03,315 epoch 4 - iter 1251/1391 - loss 0.16854943 - samples/sec: 139.93 - lr: 0.000030
2021-07-22 14:46:35,183 epoch 4 - iter 1390/1391 - loss 0.16869668 - samples/sec: 139.61 - lr: 0.000030
2021-07-22 14:46:35,319 ----------------------------------------------------------------------------------------------------
2021-07-22 14:46:35,319 EPOCH 4 done: loss 0.1686 - lr 0.0000300
2021-07-22 14:46:52,664 DEV : loss 0.1357264667749405 - score 0.9649
2021-07-22 14:46:52,847 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:46:54,855 ----------------------------------------------------------------------------------------------------
2021-07-22 14:47:26,992 epoch 5 - iter 139/1391 - loss 0.16359925 - samples/sec: 138.46 - lr: 0.000030
2021-07-22 14:47:58,721 epoch 5 - iter 278/1391 - loss 0.15893291 - samples/sec: 140.22 - lr: 0.000030
2021-07-22 14:48:29,955 epoch 5 - iter 417/1391 - loss 0.15719412 - samples/sec: 142.44 - lr: 0.000030
2021-07-22 14:49:01,642 epoch 5 - iter 556/1391 - loss 0.15671507 - samples/sec: 140.40 - lr: 0.000030
2021-07-22 14:49:33,339 epoch 5 - iter 695/1391 - loss 0.15492268 - samples/sec: 140.36 - lr: 0.000030
2021-07-22 14:50:04,940 epoch 5 - iter 834/1391 - loss 0.15365568 - samples/sec: 140.79 - lr: 0.000030
2021-07-22 14:50:37,044 epoch 5 - iter 973/1391 - loss 0.15384265 - samples/sec: 138.58 - lr: 0.000030
2021-07-22 14:51:09,144 epoch 5 - iter 1112/1391 - loss 0.15388713 - samples/sec: 138.60 - lr: 0.000030
2021-07-22 14:51:41,499 epoch 5 - iter 1251/1391 - loss 0.15273298 - samples/sec: 137.50 - lr: 0.000030
2021-07-22 14:52:14,244 epoch 5 - iter 1390/1391 - loss 0.15215203 - samples/sec: 135.87 - lr: 0.000030
2021-07-22 14:52:14,412 ----------------------------------------------------------------------------------------------------
2021-07-22 14:52:14,412 EPOCH 5 done: loss 0.1521 - lr 0.0000300
2021-07-22 14:52:31,777 DEV : loss 0.13672761619091034 - score 0.9652
2021-07-22 14:52:31,964 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:52:34,157 ----------------------------------------------------------------------------------------------------
2021-07-22 14:53:06,644 epoch 6 - iter 139/1391 - loss 0.14307584 - samples/sec: 136.97 - lr: 0.000030
2021-07-22 14:53:39,124 epoch 6 - iter 278/1391 - loss 0.14502098 - samples/sec: 136.97 - lr: 0.000030
2021-07-22 14:54:11,284 epoch 6 - iter 417/1391 - loss 0.14148301 - samples/sec: 138.34 - lr: 0.000030
2021-07-22 14:54:43,455 epoch 6 - iter 556/1391 - loss 0.14210358 - samples/sec: 138.29 - lr: 0.000030
2021-07-22 14:55:15,495 epoch 6 - iter 695/1391 - loss 0.14399023 - samples/sec: 138.86 - lr: 0.000030
2021-07-22 14:55:47,356 epoch 6 - iter 834/1391 - loss 0.14314111 - samples/sec: 139.64 - lr: 0.000030
2021-07-22 14:56:19,374 epoch 6 - iter 973/1391 - loss 0.14357789 - samples/sec: 138.95 - lr: 0.000030
2021-07-22 14:56:51,558 epoch 6 - iter 1112/1391 - loss 0.14419995 - samples/sec: 138.23 - lr: 0.000030
2021-07-22 14:57:23,367 epoch 6 - iter 1251/1391 - loss 0.14419070 - samples/sec: 139.87 - lr: 0.000030
2021-07-22 14:57:55,268 epoch 6 - iter 1390/1391 - loss 0.14325898 - samples/sec: 139.46 - lr: 0.000030
2021-07-22 14:57:55,394 ----------------------------------------------------------------------------------------------------
2021-07-22 14:57:55,394 EPOCH 6 done: loss 0.1432 - lr 0.0000300
2021-07-22 14:58:12,887 DEV : loss 0.12754642963409424 - score 0.9663
2021-07-22 14:58:13,072 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 14:58:15,133 ----------------------------------------------------------------------------------------------------
2021-07-22 14:58:47,467 epoch 7 - iter 139/1391 - loss 0.13702244 - samples/sec: 137.61 - lr: 0.000030
2021-07-22 14:59:19,291 epoch 7 - iter 278/1391 - loss 0.13591203 - samples/sec: 139.80 - lr: 0.000030
2021-07-22 14:59:51,194 epoch 7 - iter 417/1391 - loss 0.13111961 - samples/sec: 139.45 - lr: 0.000030
2021-07-22 15:00:23,063 epoch 7 - iter 556/1391 - loss 0.13232448 - samples/sec: 139.60 - lr: 0.000030
2021-07-22 15:00:54,912 epoch 7 - iter 695/1391 - loss 0.13226267 - samples/sec: 139.69 - lr: 0.000030
2021-07-22 15:01:27,256 epoch 7 - iter 834/1391 - loss 0.13230770 - samples/sec: 137.55 - lr: 0.000030
2021-07-22 15:01:59,512 epoch 7 - iter 973/1391 - loss 0.13339384 - samples/sec: 137.93 - lr: 0.000030
2021-07-22 15:02:31,046 epoch 7 - iter 1112/1391 - loss 0.13383216 - samples/sec: 141.08 - lr: 0.000030
2021-07-22 15:03:02,663 epoch 7 - iter 1251/1391 - loss 0.13360905 - samples/sec: 140.71 - lr: 0.000030
2021-07-22 15:03:34,828 epoch 7 - iter 1390/1391 - loss 0.13401434 - samples/sec: 138.31 - lr: 0.000030
2021-07-22 15:03:34,975 ----------------------------------------------------------------------------------------------------
2021-07-22 15:03:34,975 EPOCH 7 done: loss 0.1340 - lr 0.0000300
2021-07-22 15:03:53,716 DEV : loss 0.1330825537443161 - score 0.9666
2021-07-22 15:03:53,902 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:03:56,063 ----------------------------------------------------------------------------------------------------
2021-07-22 15:04:27,728 epoch 8 - iter 139/1391 - loss 0.11962192 - samples/sec: 140.52 - lr: 0.000030
2021-07-22 15:04:59,839 epoch 8 - iter 278/1391 - loss 0.12337054 - samples/sec: 138.55 - lr: 0.000030
2021-07-22 15:05:32,014 epoch 8 - iter 417/1391 - loss 0.12322326 - samples/sec: 138.28 - lr: 0.000030
2021-07-22 15:06:04,238 epoch 8 - iter 556/1391 - loss 0.12548471 - samples/sec: 138.06 - lr: 0.000030
2021-07-22 15:06:36,196 epoch 8 - iter 695/1391 - loss 0.12598232 - samples/sec: 139.21 - lr: 0.000030
2021-07-22 15:07:07,863 epoch 8 - iter 834/1391 - loss 0.12662203 - samples/sec: 140.50 - lr: 0.000030
2021-07-22 15:07:40,050 epoch 8 - iter 973/1391 - loss 0.12861668 - samples/sec: 138.22 - lr: 0.000030
2021-07-22 15:08:12,164 epoch 8 - iter 1112/1391 - loss 0.12859445 - samples/sec: 138.54 - lr: 0.000030
2021-07-22 15:08:44,623 epoch 8 - iter 1251/1391 - loss 0.12976928 - samples/sec: 137.07 - lr: 0.000030
2021-07-22 15:09:16,631 epoch 8 - iter 1390/1391 - loss 0.12891631 - samples/sec: 138.99 - lr: 0.000030
2021-07-22 15:09:16,770 ----------------------------------------------------------------------------------------------------
2021-07-22 15:09:16,770 EPOCH 8 done: loss 0.1289 - lr 0.0000300
2021-07-22 15:09:34,222 DEV : loss 0.12590205669403076 - score 0.9677
2021-07-22 15:09:34,405 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:09:36,593 ----------------------------------------------------------------------------------------------------
2021-07-22 15:10:08,745 epoch 9 - iter 139/1391 - loss 0.12359367 - samples/sec: 138.39 - lr: 0.000030
2021-07-22 15:10:40,671 epoch 9 - iter 278/1391 - loss 0.12425535 - samples/sec: 139.35 - lr: 0.000030
2021-07-22 15:11:12,188 epoch 9 - iter 417/1391 - loss 0.12229834 - samples/sec: 141.16 - lr: 0.000030
2021-07-22 15:11:44,375 epoch 9 - iter 556/1391 - loss 0.12597480 - samples/sec: 138.22 - lr: 0.000030
2021-07-22 15:12:16,671 epoch 9 - iter 695/1391 - loss 0.12683538 - samples/sec: 137.75 - lr: 0.000030
2021-07-22 15:12:48,582 epoch 9 - iter 834/1391 - loss 0.12677420 - samples/sec: 139.42 - lr: 0.000030
2021-07-22 15:13:20,772 epoch 9 - iter 973/1391 - loss 0.12455032 - samples/sec: 138.21 - lr: 0.000030
2021-07-22 15:13:52,816 epoch 9 - iter 1112/1391 - loss 0.12371762 - samples/sec: 138.84 - lr: 0.000030
2021-07-22 15:14:24,999 epoch 9 - iter 1251/1391 - loss 0.12518537 - samples/sec: 138.24 - lr: 0.000030
2021-07-22 15:14:57,163 epoch 9 - iter 1390/1391 - loss 0.12477137 - samples/sec: 138.32 - lr: 0.000030
2021-07-22 15:14:57,287 ----------------------------------------------------------------------------------------------------
2021-07-22 15:14:57,288 EPOCH 9 done: loss 0.1247 - lr 0.0000300
2021-07-22 15:15:14,575 DEV : loss 0.12689806520938873 - score 0.9668
2021-07-22 15:15:14,761 BAD EPOCHS (no improvement): 1
2021-07-22 15:15:14,761 ----------------------------------------------------------------------------------------------------
2021-07-22 15:15:46,811 epoch 10 - iter 139/1391 - loss 0.11728586 - samples/sec: 138.83 - lr: 0.000030
2021-07-22 15:16:18,546 epoch 10 - iter 278/1391 - loss 0.11668497 - samples/sec: 140.19 - lr: 0.000030
2021-07-22 15:16:50,795 epoch 10 - iter 417/1391 - loss 0.11785501 - samples/sec: 137.96 - lr: 0.000030
2021-07-22 15:17:23,063 epoch 10 - iter 556/1391 - loss 0.11698244 - samples/sec: 137.88 - lr: 0.000030
2021-07-22 15:17:54,929 epoch 10 - iter 695/1391 - loss 0.11896311 - samples/sec: 139.62 - lr: 0.000030
2021-07-22 15:18:26,939 epoch 10 - iter 834/1391 - loss 0.11844684 - samples/sec: 138.98 - lr: 0.000030
2021-07-22 15:18:58,969 epoch 10 - iter 973/1391 - loss 0.11947236 - samples/sec: 138.90 - lr: 0.000030
2021-07-22 15:19:30,696 epoch 10 - iter 1112/1391 - loss 0.12063370 - samples/sec: 140.23 - lr: 0.000030
2021-07-22 15:20:02,974 epoch 10 - iter 1251/1391 - loss 0.12154397 - samples/sec: 137.83 - lr: 0.000030
2021-07-22 15:20:35,267 epoch 10 - iter 1390/1391 - loss 0.12286670 - samples/sec: 137.77 - lr: 0.000030
2021-07-22 15:20:35,383 ----------------------------------------------------------------------------------------------------
2021-07-22 15:20:35,384 EPOCH 10 done: loss 0.1228 - lr 0.0000300
2021-07-22 15:20:52,674 DEV : loss 0.12503135204315186 - score 0.9668
2021-07-22 15:20:52,860 BAD EPOCHS (no improvement): 2
2021-07-22 15:20:52,860 ----------------------------------------------------------------------------------------------------
2021-07-22 15:21:24,799 epoch 11 - iter 139/1391 - loss 0.11938264 - samples/sec: 139.31 - lr: 0.000030
2021-07-22 15:21:56,592 epoch 11 - iter 278/1391 - loss 0.11872416 - samples/sec: 139.94 - lr: 0.000030
2021-07-22 15:22:28,399 epoch 11 - iter 417/1391 - loss 0.12053699 - samples/sec: 139.87 - lr: 0.000030
2021-07-22 15:23:00,219 epoch 11 - iter 556/1391 - loss 0.12166492 - samples/sec: 139.82 - lr: 0.000030
2021-07-22 15:23:32,125 epoch 11 - iter 695/1391 - loss 0.12099481 - samples/sec: 139.44 - lr: 0.000030
2021-07-22 15:24:04,247 epoch 11 - iter 834/1391 - loss 0.12088299 - samples/sec: 138.50 - lr: 0.000030
2021-07-22 15:24:36,196 epoch 11 - iter 973/1391 - loss 0.11935301 - samples/sec: 139.25 - lr: 0.000030
2021-07-22 15:25:07,911 epoch 11 - iter 1112/1391 - loss 0.11848632 - samples/sec: 140.28 - lr: 0.000030
2021-07-22 15:25:39,920 epoch 11 - iter 1251/1391 - loss 0.11892292 - samples/sec: 138.99 - lr: 0.000030
2021-07-22 15:26:11,358 epoch 11 - iter 1390/1391 - loss 0.11909521 - samples/sec: 141.52 - lr: 0.000030
2021-07-22 15:26:11,499 ----------------------------------------------------------------------------------------------------
2021-07-22 15:26:11,500 EPOCH 11 done: loss 0.1190 - lr 0.0000300
2021-07-22 15:26:30,210 DEV : loss 0.12553244829177856 - score 0.9684
2021-07-22 15:26:30,394 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:26:32,562 ----------------------------------------------------------------------------------------------------
2021-07-22 15:27:04,586 epoch 12 - iter 139/1391 - loss 0.12496071 - samples/sec: 138.95 - lr: 0.000030
2021-07-22 15:27:36,649 epoch 12 - iter 278/1391 - loss 0.12362408 - samples/sec: 138.76 - lr: 0.000030
2021-07-22 15:28:09,052 epoch 12 - iter 417/1391 - loss 0.12204932 - samples/sec: 137.30 - lr: 0.000030
2021-07-22 15:28:41,065 epoch 12 - iter 556/1391 - loss 0.12067542 - samples/sec: 138.97 - lr: 0.000030
2021-07-22 15:29:13,557 epoch 12 - iter 695/1391 - loss 0.11943889 - samples/sec: 136.93 - lr: 0.000030
2021-07-22 15:29:45,227 epoch 12 - iter 834/1391 - loss 0.11912320 - samples/sec: 140.48 - lr: 0.000030
2021-07-22 15:30:17,501 epoch 12 - iter 973/1391 - loss 0.11918502 - samples/sec: 137.85 - lr: 0.000030
2021-07-22 15:30:49,396 epoch 12 - iter 1112/1391 - loss 0.11719158 - samples/sec: 139.49 - lr: 0.000030
2021-07-22 15:31:21,404 epoch 12 - iter 1251/1391 - loss 0.11627305 - samples/sec: 138.99 - lr: 0.000030
2021-07-22 15:31:53,432 epoch 12 - iter 1390/1391 - loss 0.11672477 - samples/sec: 138.91 - lr: 0.000030
2021-07-22 15:31:53,551 ----------------------------------------------------------------------------------------------------
2021-07-22 15:31:53,551 EPOCH 12 done: loss 0.1167 - lr 0.0000300
2021-07-22 15:32:10,912 DEV : loss 0.12170843034982681 - score 0.9694
2021-07-22 15:32:11,097 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:32:13,108 ----------------------------------------------------------------------------------------------------
2021-07-22 15:32:44,928 epoch 13 - iter 139/1391 - loss 0.10380770 - samples/sec: 139.83 - lr: 0.000030
2021-07-22 15:33:16,766 epoch 13 - iter 278/1391 - loss 0.10579083 - samples/sec: 139.74 - lr: 0.000030
2021-07-22 15:33:49,035 epoch 13 - iter 417/1391 - loss 0.10809223 - samples/sec: 137.87 - lr: 0.000030
2021-07-22 15:34:21,132 epoch 13 - iter 556/1391 - loss 0.10862307 - samples/sec: 138.61 - lr: 0.000030
2021-07-22 15:34:52,887 epoch 13 - iter 695/1391 - loss 0.10953054 - samples/sec: 140.10 - lr: 0.000030
2021-07-22 15:35:24,419 epoch 13 - iter 834/1391 - loss 0.10879047 - samples/sec: 141.10 - lr: 0.000030
2021-07-22 15:35:56,155 epoch 13 - iter 973/1391 - loss 0.10991565 - samples/sec: 140.18 - lr: 0.000030
2021-07-22 15:36:27,946 epoch 13 - iter 1112/1391 - loss 0.11127699 - samples/sec: 139.95 - lr: 0.000030
2021-07-22 15:36:59,759 epoch 13 - iter 1251/1391 - loss 0.11159209 - samples/sec: 139.85 - lr: 0.000030
2021-07-22 15:37:31,233 epoch 13 - iter 1390/1391 - loss 0.11165157 - samples/sec: 141.36 - lr: 0.000030
2021-07-22 15:37:31,380 ----------------------------------------------------------------------------------------------------
2021-07-22 15:37:31,380 EPOCH 13 done: loss 0.1117 - lr 0.0000300
2021-07-22 15:37:48,629 DEV : loss 0.11905960738658905 - score 0.9698
2021-07-22 15:37:48,815 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 15:37:50,926 ----------------------------------------------------------------------------------------------------
2021-07-22 15:38:23,103 epoch 14 - iter 139/1391 - loss 0.11398605 - samples/sec: 138.28 - lr: 0.000030
2021-07-22 15:38:54,835 epoch 14 - iter 278/1391 - loss 0.11432660 - samples/sec: 140.21 - lr: 0.000030
2021-07-22 15:39:27,051 epoch 14 - iter 417/1391 - loss 0.11347204 - samples/sec: 138.10 - lr: 0.000030
2021-07-22 15:39:58,984 epoch 14 - iter 556/1391 - loss 0.11311131 - samples/sec: 139.32 - lr: 0.000030
2021-07-22 15:40:30,722 epoch 14 - iter 695/1391 - loss 0.11161184 - samples/sec: 140.18 - lr: 0.000030
2021-07-22 15:41:02,445 epoch 14 - iter 834/1391 - loss 0.11274030 - samples/sec: 140.24 - lr: 0.000030
2021-07-22 15:41:34,463 epoch 14 - iter 973/1391 - loss 0.11344089 - samples/sec: 138.95 - lr: 0.000030
2021-07-22 15:42:06,339 epoch 14 - iter 1112/1391 - loss 0.11303329 - samples/sec: 139.57 - lr: 0.000030
2021-07-22 15:42:38,653 epoch 14 - iter 1251/1391 - loss 0.11225012 - samples/sec: 137.68 - lr: 0.000030
2021-07-22 15:43:10,624 epoch 14 - iter 1390/1391 - loss 0.11262170 - samples/sec: 139.16 - lr: 0.000030
2021-07-22 15:43:10,765 ----------------------------------------------------------------------------------------------------
2021-07-22 15:43:10,766 EPOCH 14 done: loss 0.1126 - lr 0.0000300
2021-07-22 15:43:28,177 DEV : loss 0.12041951715946198 - score 0.9688
2021-07-22 15:43:28,361 BAD EPOCHS (no improvement): 1
2021-07-22 15:43:28,362 ----------------------------------------------------------------------------------------------------
2021-07-22 15:44:00,100 epoch 15 - iter 139/1391 - loss 0.10149694 - samples/sec: 140.20 - lr: 0.000030
2021-07-22 15:44:31,736 epoch 15 - iter 278/1391 - loss 0.10041427 - samples/sec: 140.63 - lr: 0.000030
2021-07-22 15:45:04,116 epoch 15 - iter 417/1391 - loss 0.10373093 - samples/sec: 137.40 - lr: 0.000030
2021-07-22 15:45:35,843 epoch 15 - iter 556/1391 - loss 0.10657982 - samples/sec: 140.23 - lr: 0.000030
2021-07-22 15:46:07,767 epoch 15 - iter 695/1391 - loss 0.10756201 - samples/sec: 139.36 - lr: 0.000030
2021-07-22 15:46:40,028 epoch 15 - iter 834/1391 - loss 0.10817040 - samples/sec: 137.91 - lr: 0.000030
2021-07-22 15:47:12,075 epoch 15 - iter 973/1391 - loss 0.10907049 - samples/sec: 138.83 - lr: 0.000030
2021-07-22 15:47:44,220 epoch 15 - iter 1112/1391 - loss 0.10937982 - samples/sec: 138.40 - lr: 0.000030
2021-07-22 15:48:16,028 epoch 15 - iter 1251/1391 - loss 0.10914366 - samples/sec: 139.87 - lr: 0.000030
2021-07-22 15:48:47,788 epoch 15 - iter 1390/1391 - loss 0.10859907 - samples/sec: 140.08 - lr: 0.000030
2021-07-22 15:48:47,906 ----------------------------------------------------------------------------------------------------
2021-07-22 15:48:47,907 EPOCH 15 done: loss 0.1085 - lr 0.0000300
2021-07-22 15:49:05,339 DEV : loss 0.12383747845888138 - score 0.9679
2021-07-22 15:49:05,523 BAD EPOCHS (no improvement): 2
2021-07-22 15:49:05,523 ----------------------------------------------------------------------------------------------------
2021-07-22 15:49:38,247 epoch 16 - iter 139/1391 - loss 0.10428933 - samples/sec: 135.97 - lr: 0.000030
2021-07-22 15:50:10,620 epoch 16 - iter 278/1391 - loss 0.10270550 - samples/sec: 137.43 - lr: 0.000030
2021-07-22 15:50:42,788 epoch 16 - iter 417/1391 - loss 0.10112048 - samples/sec: 138.31 - lr: 0.000030
2021-07-22 15:51:15,011 epoch 16 - iter 556/1391 - loss 0.10324466 - samples/sec: 138.07 - lr: 0.000030
2021-07-22 15:51:47,206 epoch 16 - iter 695/1391 - loss 0.10421594 - samples/sec: 138.19 - lr: 0.000030
2021-07-22 15:52:19,167 epoch 16 - iter 834/1391 - loss 0.10450577 - samples/sec: 139.20 - lr: 0.000030
2021-07-22 15:52:51,032 epoch 16 - iter 973/1391 - loss 0.10366967 - samples/sec: 139.62 - lr: 0.000030
2021-07-22 15:53:22,987 epoch 16 - iter 1112/1391 - loss 0.10480897 - samples/sec: 139.23 - lr: 0.000030
2021-07-22 15:53:54,988 epoch 16 - iter 1251/1391 - loss 0.10531677 - samples/sec: 139.03 - lr: 0.000030
2021-07-22 15:54:27,092 epoch 16 - iter 1390/1391 - loss 0.10612960 - samples/sec: 138.58 - lr: 0.000030
2021-07-22 15:54:27,226 ----------------------------------------------------------------------------------------------------
2021-07-22 15:54:27,226 EPOCH 16 done: loss 0.1061 - lr 0.0000300
2021-07-22 15:54:44,521 DEV : loss 0.12088363617658615 - score 0.9679
2021-07-22 15:54:44,709 BAD EPOCHS (no improvement): 3
2021-07-22 15:54:44,709 ----------------------------------------------------------------------------------------------------
2021-07-22 15:55:16,568 epoch 17 - iter 139/1391 - loss 0.10105884 - samples/sec: 139.66 - lr: 0.000030
2021-07-22 15:55:48,618 epoch 17 - iter 278/1391 - loss 0.10826793 - samples/sec: 138.81 - lr: 0.000030
2021-07-22 15:56:20,259 epoch 17 - iter 417/1391 - loss 0.10462685 - samples/sec: 140.61 - lr: 0.000030
2021-07-22 15:56:52,361 epoch 17 - iter 556/1391 - loss 0.10322364 - samples/sec: 138.59 - lr: 0.000030
2021-07-22 15:57:24,895 epoch 17 - iter 695/1391 - loss 0.10233192 - samples/sec: 136.75 - lr: 0.000030
2021-07-22 15:57:56,868 epoch 17 - iter 834/1391 - loss 0.10134449 - samples/sec: 139.14 - lr: 0.000030
2021-07-22 15:58:29,151 epoch 17 - iter 973/1391 - loss 0.10163936 - samples/sec: 137.81 - lr: 0.000030
2021-07-22 15:59:00,995 epoch 17 - iter 1112/1391 - loss 0.10218723 - samples/sec: 139.71 - lr: 0.000030
2021-07-22 15:59:32,803 epoch 17 - iter 1251/1391 - loss 0.10221593 - samples/sec: 139.87 - lr: 0.000030
2021-07-22 16:00:05,094 epoch 17 - iter 1390/1391 - loss 0.10350271 - samples/sec: 137.78 - lr: 0.000030
2021-07-22 16:00:05,235 ----------------------------------------------------------------------------------------------------
2021-07-22 16:00:05,236 EPOCH 17 done: loss 0.1036 - lr 0.0000300
2021-07-22 16:00:22,624 DEV : loss 0.11525433510541916 - score 0.9703
2021-07-22 16:00:22,810 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 16:00:24,783 ----------------------------------------------------------------------------------------------------
2021-07-22 16:00:56,715 epoch 18 - iter 139/1391 - loss 0.09830261 - samples/sec: 139.34 - lr: 0.000030
2021-07-22 16:01:28,444 epoch 18 - iter 278/1391 - loss 0.10016752 - samples/sec: 140.22 - lr: 0.000030
2021-07-22 16:02:00,403 epoch 18 - iter 417/1391 - loss 0.10088017 - samples/sec: 139.21 - lr: 0.000030
2021-07-22 16:02:32,606 epoch 18 - iter 556/1391 - loss 0.10309572 - samples/sec: 138.16 - lr: 0.000030
2021-07-22 16:03:04,788 epoch 18 - iter 695/1391 - loss 0.10263484 - samples/sec: 138.24 - lr: 0.000030
2021-07-22 16:03:37,008 epoch 18 - iter 834/1391 - loss 0.10221856 - samples/sec: 138.08 - lr: 0.000030
2021-07-22 16:04:09,227 epoch 18 - iter 973/1391 - loss 0.10150226 - samples/sec: 138.09 - lr: 0.000030
2021-07-22 16:04:41,073 epoch 18 - iter 1112/1391 - loss 0.10122601 - samples/sec: 139.71 - lr: 0.000030
2021-07-22 16:05:12,880 epoch 18 - iter 1251/1391 - loss 0.10114459 - samples/sec: 139.87 - lr: 0.000030
2021-07-22 16:05:44,619 epoch 18 - iter 1390/1391 - loss 0.10069937 - samples/sec: 140.18 - lr: 0.000030
2021-07-22 16:05:44,762 ----------------------------------------------------------------------------------------------------
2021-07-22 16:05:44,762 EPOCH 18 done: loss 0.1007 - lr 0.0000300
2021-07-22 16:06:02,127 DEV : loss 0.11569585651159286 - score 0.9695
2021-07-22 16:06:02,311 BAD EPOCHS (no improvement): 1
2021-07-22 16:06:02,312 ----------------------------------------------------------------------------------------------------
2021-07-22 16:06:34,100 epoch 19 - iter 139/1391 - loss 0.08727143 - samples/sec: 139.97 - lr: 0.000030
2021-07-22 16:07:06,468 epoch 19 - iter 278/1391 - loss 0.09507461 - samples/sec: 137.45 - lr: 0.000030
2021-07-22 16:07:38,512 epoch 19 - iter 417/1391 - loss 0.09536309 - samples/sec: 138.84 - lr: 0.000030
2021-07-22 16:08:10,688 epoch 19 - iter 556/1391 - loss 0.09703644 - samples/sec: 138.27 - lr: 0.000030
2021-07-22 16:08:42,727 epoch 19 - iter 695/1391 - loss 0.09914800 - samples/sec: 138.86 - lr: 0.000030
2021-07-22 16:09:14,903 epoch 19 - iter 834/1391 - loss 0.10088996 - samples/sec: 138.27 - lr: 0.000030
2021-07-22 16:09:46,686 epoch 19 - iter 973/1391 - loss 0.10057663 - samples/sec: 139.98 - lr: 0.000030
2021-07-22 16:10:18,644 epoch 19 - iter 1112/1391 - loss 0.09987145 - samples/sec: 139.22 - lr: 0.000030
2021-07-22 16:10:50,197 epoch 19 - iter 1251/1391 - loss 0.10124197 - samples/sec: 141.00 - lr: 0.000030
2021-07-22 16:11:21,696 epoch 19 - iter 1390/1391 - loss 0.10043660 - samples/sec: 141.25 - lr: 0.000030
2021-07-22 16:11:21,814 ----------------------------------------------------------------------------------------------------
2021-07-22 16:11:21,814 EPOCH 19 done: loss 0.1004 - lr 0.0000300
2021-07-22 16:11:39,105 DEV : loss 0.11615269631147385 - score 0.9701
2021-07-22 16:11:39,291 BAD EPOCHS (no improvement): 2
2021-07-22 16:11:39,291 ----------------------------------------------------------------------------------------------------
2021-07-22 16:12:11,015 epoch 20 - iter 139/1391 - loss 0.09221273 - samples/sec: 140.26 - lr: 0.000030
2021-07-22 16:12:42,595 epoch 20 - iter 278/1391 - loss 0.09596328 - samples/sec: 140.88 - lr: 0.000030
2021-07-22 16:13:14,493 epoch 20 - iter 417/1391 - loss 0.09689870 - samples/sec: 139.48 - lr: 0.000030
2021-07-22 16:13:46,712 epoch 20 - iter 556/1391 - loss 0.09794220 - samples/sec: 138.08 - lr: 0.000030
2021-07-22 16:14:19,851 epoch 20 - iter 695/1391 - loss 0.09824522 - samples/sec: 134.25 - lr: 0.000030
2021-07-22 16:14:52,088 epoch 20 - iter 834/1391 - loss 0.09830028 - samples/sec: 138.01 - lr: 0.000030
2021-07-22 16:15:24,183 epoch 20 - iter 973/1391 - loss 0.09739964 - samples/sec: 138.62 - lr: 0.000030
2021-07-22 16:15:56,430 epoch 20 - iter 1112/1391 - loss 0.09771421 - samples/sec: 137.97 - lr: 0.000030
2021-07-22 16:16:28,429 epoch 20 - iter 1251/1391 - loss 0.09829985 - samples/sec: 139.03 - lr: 0.000030
2021-07-22 16:17:00,312 epoch 20 - iter 1390/1391 - loss 0.09823604 - samples/sec: 139.54 - lr: 0.000030
2021-07-22 16:17:00,427 ----------------------------------------------------------------------------------------------------
2021-07-22 16:17:00,427 EPOCH 20 done: loss 0.0982 - lr 0.0000300
2021-07-22 16:17:17,835 DEV : loss 0.11708134412765503 - score 0.9697
2021-07-22 16:17:18,022 BAD EPOCHS (no improvement): 3
2021-07-22 16:17:18,022 ----------------------------------------------------------------------------------------------------
2021-07-22 16:17:50,086 epoch 21 - iter 139/1391 - loss 0.09294969 - samples/sec: 138.77 - lr: 0.000030
2021-07-22 16:18:21,867 epoch 21 - iter 278/1391 - loss 0.09212834 - samples/sec: 139.99 - lr: 0.000030
2021-07-22 16:18:53,644 epoch 21 - iter 417/1391 - loss 0.09307569 - samples/sec: 140.00 - lr: 0.000030
2021-07-22 16:19:25,856 epoch 21 - iter 556/1391 - loss 0.09586487 - samples/sec: 138.12 - lr: 0.000030
2021-07-22 16:19:57,780 epoch 21 - iter 695/1391 - loss 0.09622923 - samples/sec: 139.36 - lr: 0.000030
2021-07-22 16:20:30,007 epoch 21 - iter 834/1391 - loss 0.09576179 - samples/sec: 138.05 - lr: 0.000030
2021-07-22 16:21:01,879 epoch 21 - iter 973/1391 - loss 0.09532163 - samples/sec: 139.59 - lr: 0.000030
2021-07-22 16:21:33,713 epoch 21 - iter 1112/1391 - loss 0.09572322 - samples/sec: 139.76 - lr: 0.000030
2021-07-22 16:22:05,780 epoch 21 - iter 1251/1391 - loss 0.09549288 - samples/sec: 138.74 - lr: 0.000030
2021-07-22 16:22:37,579 epoch 21 - iter 1390/1391 - loss 0.09522786 - samples/sec: 139.91 - lr: 0.000030
2021-07-22 16:22:37,691 ----------------------------------------------------------------------------------------------------
2021-07-22 16:22:37,691 EPOCH 21 done: loss 0.0952 - lr 0.0000300
2021-07-22 16:22:55,132 DEV : loss 0.11552079021930695 - score 0.971
2021-07-22 16:22:55,318 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 16:22:57,700 ----------------------------------------------------------------------------------------------------
2021-07-22 16:23:29,694 epoch 22 - iter 139/1391 - loss 0.09572447 - samples/sec: 139.08 - lr: 0.000030
2021-07-22 16:24:01,416 epoch 22 - iter 278/1391 - loss 0.09452325 - samples/sec: 140.25 - lr: 0.000030
2021-07-22 16:24:33,475 epoch 22 - iter 417/1391 - loss 0.09869631 - samples/sec: 138.77 - lr: 0.000030
2021-07-22 16:25:06,141 epoch 22 - iter 556/1391 - loss 0.09712529 - samples/sec: 136.20 - lr: 0.000030
2021-07-22 16:25:37,936 epoch 22 - iter 695/1391 - loss 0.09359964 - samples/sec: 139.93 - lr: 0.000030
2021-07-22 16:26:09,983 epoch 22 - iter 834/1391 - loss 0.09474358 - samples/sec: 138.83 - lr: 0.000030
2021-07-22 16:26:42,380 epoch 22 - iter 973/1391 - loss 0.09510533 - samples/sec: 137.32 - lr: 0.000030
2021-07-22 16:27:14,573 epoch 22 - iter 1112/1391 - loss 0.09468337 - samples/sec: 138.20 - lr: 0.000030
2021-07-22 16:27:46,397 epoch 22 - iter 1251/1391 - loss 0.09445977 - samples/sec: 139.80 - lr: 0.000030
2021-07-22 16:28:18,263 epoch 22 - iter 1390/1391 - loss 0.09427340 - samples/sec: 139.62 - lr: 0.000030
2021-07-22 16:28:18,416 ----------------------------------------------------------------------------------------------------
2021-07-22 16:28:18,416 EPOCH 22 done: loss 0.0943 - lr 0.0000300
2021-07-22 16:28:35,855 DEV : loss 0.11922948062419891 - score 0.97
2021-07-22 16:28:36,040 BAD EPOCHS (no improvement): 1
2021-07-22 16:28:36,040 ----------------------------------------------------------------------------------------------------
2021-07-22 16:29:07,932 epoch 23 - iter 139/1391 - loss 0.08950301 - samples/sec: 139.52 - lr: 0.000030
2021-07-22 16:29:40,427 epoch 23 - iter 278/1391 - loss 0.09006172 - samples/sec: 136.91 - lr: 0.000030
2021-07-22 16:30:12,528 epoch 23 - iter 417/1391 - loss 0.08687007 - samples/sec: 138.59 - lr: 0.000030
2021-07-22 16:30:44,056 epoch 23 - iter 556/1391 - loss 0.08697958 - samples/sec: 141.11 - lr: 0.000030
2021-07-22 16:31:16,223 epoch 23 - iter 695/1391 - loss 0.08958275 - samples/sec: 138.31 - lr: 0.000030
2021-07-22 16:31:48,285 epoch 23 - iter 834/1391 - loss 0.09007621 - samples/sec: 138.76 - lr: 0.000030
2021-07-22 16:32:20,191 epoch 23 - iter 973/1391 - loss 0.09186514 - samples/sec: 139.44 - lr: 0.000030
2021-07-22 16:32:52,391 epoch 23 - iter 1112/1391 - loss 0.09415481 - samples/sec: 138.17 - lr: 0.000030
2021-07-22 16:33:24,276 epoch 23 - iter 1251/1391 - loss 0.09406044 - samples/sec: 139.53 - lr: 0.000030
2021-07-22 16:33:56,086 epoch 23 - iter 1390/1391 - loss 0.09354274 - samples/sec: 139.86 - lr: 0.000030
2021-07-22 16:33:56,224 ----------------------------------------------------------------------------------------------------
2021-07-22 16:33:56,225 EPOCH 23 done: loss 0.0935 - lr 0.0000300
2021-07-22 16:34:13,685 DEV : loss 0.11795011907815933 - score 0.9704
2021-07-22 16:34:13,871 BAD EPOCHS (no improvement): 2
2021-07-22 16:34:13,871 ----------------------------------------------------------------------------------------------------
2021-07-22 16:34:45,976 epoch 24 - iter 139/1391 - loss 0.09544376 - samples/sec: 138.59 - lr: 0.000030
2021-07-22 16:35:17,870 epoch 24 - iter 278/1391 - loss 0.09368543 - samples/sec: 139.50 - lr: 0.000030
2021-07-22 16:35:50,023 epoch 24 - iter 417/1391 - loss 0.09327930 - samples/sec: 138.37 - lr: 0.000030
2021-07-22 16:36:21,627 epoch 24 - iter 556/1391 - loss 0.09248172 - samples/sec: 140.77 - lr: 0.000030
2021-07-22 16:36:53,531 epoch 24 - iter 695/1391 - loss 0.09319151 - samples/sec: 139.45 - lr: 0.000030
2021-07-22 16:37:25,382 epoch 24 - iter 834/1391 - loss 0.09367258 - samples/sec: 139.68 - lr: 0.000030
2021-07-22 16:37:56,798 epoch 24 - iter 973/1391 - loss 0.09196476 - samples/sec: 141.61 - lr: 0.000030
2021-07-22 16:38:28,828 epoch 24 - iter 1112/1391 - loss 0.09260464 - samples/sec: 138.90 - lr: 0.000030
2021-07-22 16:39:00,955 epoch 24 - iter 1251/1391 - loss 0.09155558 - samples/sec: 138.48 - lr: 0.000030
2021-07-22 16:39:34,510 epoch 24 - iter 1390/1391 - loss 0.09274521 - samples/sec: 132.59 - lr: 0.000030
2021-07-22 16:39:34,648 ----------------------------------------------------------------------------------------------------
2021-07-22 16:39:34,648 EPOCH 24 done: loss 0.0927 - lr 0.0000300
2021-07-22 16:39:52,117 DEV : loss 0.11524391174316406 - score 0.9701
2021-07-22 16:39:52,302 BAD EPOCHS (no improvement): 3
2021-07-22 16:39:52,302 ----------------------------------------------------------------------------------------------------
2021-07-22 16:40:24,744 epoch 25 - iter 139/1391 - loss 0.09207406 - samples/sec: 137.15 - lr: 0.000030
2021-07-22 16:40:56,667 epoch 25 - iter 278/1391 - loss 0.08949332 - samples/sec: 139.37 - lr: 0.000030
2021-07-22 16:41:28,769 epoch 25 - iter 417/1391 - loss 0.09080639 - samples/sec: 138.59 - lr: 0.000030
2021-07-22 16:42:00,663 epoch 25 - iter 556/1391 - loss 0.09244987 - samples/sec: 139.49 - lr: 0.000030
2021-07-22 16:42:32,728 epoch 25 - iter 695/1391 - loss 0.09244884 - samples/sec: 138.75 - lr: 0.000030
2021-07-22 16:43:04,835 epoch 25 - iter 834/1391 - loss 0.09276900 - samples/sec: 138.57 - lr: 0.000030
2021-07-22 16:43:36,939 epoch 25 - iter 973/1391 - loss 0.09268257 - samples/sec: 138.58 - lr: 0.000030
2021-07-22 16:44:08,944 epoch 25 - iter 1112/1391 - loss 0.09225413 - samples/sec: 139.01 - lr: 0.000030
2021-07-22 16:44:40,713 epoch 25 - iter 1251/1391 - loss 0.09181671 - samples/sec: 140.04 - lr: 0.000030
2021-07-22 16:45:12,027 epoch 25 - iter 1390/1391 - loss 0.09184876 - samples/sec: 142.08 - lr: 0.000030
2021-07-22 16:45:12,166 ----------------------------------------------------------------------------------------------------
2021-07-22 16:45:12,166 EPOCH 25 done: loss 0.0918 - lr 0.0000300
2021-07-22 16:45:29,473 DEV : loss 0.11704583466053009 - score 0.9721
2021-07-22 16:45:29,664 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 16:45:31,666 ----------------------------------------------------------------------------------------------------
2021-07-22 16:46:03,662 epoch 26 - iter 139/1391 - loss 0.07599473 - samples/sec: 139.07 - lr: 0.000030
2021-07-22 16:46:35,800 epoch 26 - iter 278/1391 - loss 0.08634705 - samples/sec: 138.43 - lr: 0.000030
2021-07-22 16:47:07,704 epoch 26 - iter 417/1391 - loss 0.08659718 - samples/sec: 139.45 - lr: 0.000030
2021-07-22 16:47:39,723 epoch 26 - iter 556/1391 - loss 0.08795094 - samples/sec: 138.95 - lr: 0.000030
2021-07-22 16:48:12,138 epoch 26 - iter 695/1391 - loss 0.08621098 - samples/sec: 137.25 - lr: 0.000030
2021-07-22 16:48:44,389 epoch 26 - iter 834/1391 - loss 0.08773658 - samples/sec: 137.95 - lr: 0.000030
2021-07-22 16:49:16,368 epoch 26 - iter 973/1391 - loss 0.08662723 - samples/sec: 139.12 - lr: 0.000030
2021-07-22 16:49:48,123 epoch 26 - iter 1112/1391 - loss 0.08812332 - samples/sec: 140.10 - lr: 0.000030
2021-07-22 16:50:20,262 epoch 26 - iter 1251/1391 - loss 0.08794456 - samples/sec: 138.43 - lr: 0.000030
2021-07-22 16:50:52,184 epoch 26 - iter 1390/1391 - loss 0.08820219 - samples/sec: 139.37 - lr: 0.000030
2021-07-22 16:50:52,308 ----------------------------------------------------------------------------------------------------
2021-07-22 16:50:52,308 EPOCH 26 done: loss 0.0881 - lr 0.0000300
2021-07-22 16:51:09,606 DEV : loss 0.12137716263532639 - score 0.9716
2021-07-22 16:51:09,794 BAD EPOCHS (no improvement): 1
2021-07-22 16:51:09,794 ----------------------------------------------------------------------------------------------------
2021-07-22 16:51:41,727 epoch 27 - iter 139/1391 - loss 0.09038605 - samples/sec: 139.34 - lr: 0.000030
2021-07-22 16:52:13,649 epoch 27 - iter 278/1391 - loss 0.09087366 - samples/sec: 139.37 - lr: 0.000030
2021-07-22 16:52:45,912 epoch 27 - iter 417/1391 - loss 0.09151974 - samples/sec: 137.90 - lr: 0.000030
2021-07-22 16:53:18,171 epoch 27 - iter 556/1391 - loss 0.09164150 - samples/sec: 137.91 - lr: 0.000030
2021-07-22 16:53:49,774 epoch 27 - iter 695/1391 - loss 0.09156348 - samples/sec: 140.78 - lr: 0.000030
2021-07-22 16:54:22,119 epoch 27 - iter 834/1391 - loss 0.08980163 - samples/sec: 137.55 - lr: 0.000030
2021-07-22 16:54:54,123 epoch 27 - iter 973/1391 - loss 0.09002191 - samples/sec: 139.01 - lr: 0.000030
2021-07-22 16:55:26,425 epoch 27 - iter 1112/1391 - loss 0.08970170 - samples/sec: 137.73 - lr: 0.000030
2021-07-22 16:55:58,596 epoch 27 - iter 1251/1391 - loss 0.08868567 - samples/sec: 138.29 - lr: 0.000030
2021-07-22 16:56:30,255 epoch 27 - iter 1390/1391 - loss 0.08964257 - samples/sec: 140.53 - lr: 0.000030
2021-07-22 16:56:30,390 ----------------------------------------------------------------------------------------------------
2021-07-22 16:56:30,391 EPOCH 27 done: loss 0.0896 - lr 0.0000300
2021-07-22 16:56:47,686 DEV : loss 0.11953221261501312 - score 0.9695
2021-07-22 16:56:47,874 BAD EPOCHS (no improvement): 2
2021-07-22 16:56:47,874 ----------------------------------------------------------------------------------------------------
2021-07-22 16:57:20,236 epoch 28 - iter 139/1391 - loss 0.08264076 - samples/sec: 137.49 - lr: 0.000030
2021-07-22 16:57:52,107 epoch 28 - iter 278/1391 - loss 0.08318183 - samples/sec: 139.59 - lr: 0.000030
2021-07-22 16:58:23,992 epoch 28 - iter 417/1391 - loss 0.08655050 - samples/sec: 139.53 - lr: 0.000030
2021-07-22 16:58:56,299 epoch 28 - iter 556/1391 - loss 0.08666915 - samples/sec: 137.71 - lr: 0.000030
2021-07-22 16:59:28,530 epoch 28 - iter 695/1391 - loss 0.08500598 - samples/sec: 138.04 - lr: 0.000030
2021-07-22 17:00:00,452 epoch 28 - iter 834/1391 - loss 0.08558290 - samples/sec: 139.37 - lr: 0.000030
2021-07-22 17:00:32,499 epoch 28 - iter 973/1391 - loss 0.08689828 - samples/sec: 138.83 - lr: 0.000030
2021-07-22 17:01:04,135 epoch 28 - iter 1112/1391 - loss 0.08742903 - samples/sec: 140.63 - lr: 0.000030
2021-07-22 17:01:35,912 epoch 28 - iter 1251/1391 - loss 0.08668511 - samples/sec: 140.01 - lr: 0.000030
2021-07-22 17:02:07,712 epoch 28 - iter 1390/1391 - loss 0.08652404 - samples/sec: 139.90 - lr: 0.000030
2021-07-22 17:02:07,888 ----------------------------------------------------------------------------------------------------
2021-07-22 17:02:07,888 EPOCH 28 done: loss 0.0865 - lr 0.0000300
2021-07-22 17:02:26,669 DEV : loss 0.1169322207570076 - score 0.9709
2021-07-22 17:02:26,856 BAD EPOCHS (no improvement): 3
2021-07-22 17:02:26,857 ----------------------------------------------------------------------------------------------------
2021-07-22 17:02:58,722 epoch 29 - iter 139/1391 - loss 0.08066942 - samples/sec: 139.63 - lr: 0.000030
2021-07-22 17:03:30,975 epoch 29 - iter 278/1391 - loss 0.08417104 - samples/sec: 137.94 - lr: 0.000030
2021-07-22 17:04:03,042 epoch 29 - iter 417/1391 - loss 0.08391894 - samples/sec: 138.74 - lr: 0.000030
2021-07-22 17:04:34,639 epoch 29 - iter 556/1391 - loss 0.08454574 - samples/sec: 140.80 - lr: 0.000030
2021-07-22 17:05:06,672 epoch 29 - iter 695/1391 - loss 0.08383448 - samples/sec: 138.89 - lr: 0.000030
2021-07-22 17:05:38,831 epoch 29 - iter 834/1391 - loss 0.08210000 - samples/sec: 138.35 - lr: 0.000030
2021-07-22 17:06:10,731 epoch 29 - iter 973/1391 - loss 0.08305683 - samples/sec: 139.46 - lr: 0.000030
2021-07-22 17:06:42,599 epoch 29 - iter 1112/1391 - loss 0.08271883 - samples/sec: 139.61 - lr: 0.000030
2021-07-22 17:07:15,172 epoch 29 - iter 1251/1391 - loss 0.08293282 - samples/sec: 136.58 - lr: 0.000030
2021-07-22 17:07:47,323 epoch 29 - iter 1390/1391 - loss 0.08416958 - samples/sec: 138.38 - lr: 0.000030
2021-07-22 17:07:47,452 ----------------------------------------------------------------------------------------------------
2021-07-22 17:07:47,452 EPOCH 29 done: loss 0.0841 - lr 0.0000300
2021-07-22 17:08:04,770 DEV : loss 0.11748932301998138 - score 0.9697
Epoch    29: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 17:08:04,958 BAD EPOCHS (no improvement): 4
2021-07-22 17:08:04,959 ----------------------------------------------------------------------------------------------------
2021-07-22 17:08:37,191 epoch 30 - iter 139/1391 - loss 0.08788345 - samples/sec: 138.04 - lr: 0.000015
2021-07-22 17:09:09,170 epoch 30 - iter 278/1391 - loss 0.08498567 - samples/sec: 139.12 - lr: 0.000015
2021-07-22 17:09:40,882 epoch 30 - iter 417/1391 - loss 0.08250361 - samples/sec: 140.30 - lr: 0.000015
2021-07-22 17:10:12,641 epoch 30 - iter 556/1391 - loss 0.08355062 - samples/sec: 140.09 - lr: 0.000015
2021-07-22 17:10:44,504 epoch 30 - iter 695/1391 - loss 0.08460709 - samples/sec: 139.63 - lr: 0.000015
2021-07-22 17:11:16,682 epoch 30 - iter 834/1391 - loss 0.08260219 - samples/sec: 138.26 - lr: 0.000015
2021-07-22 17:11:48,611 epoch 30 - iter 973/1391 - loss 0.08284989 - samples/sec: 139.34 - lr: 0.000015
2021-07-22 17:12:20,797 epoch 30 - iter 1112/1391 - loss 0.08319197 - samples/sec: 138.23 - lr: 0.000015
2021-07-22 17:12:53,096 epoch 30 - iter 1251/1391 - loss 0.08350502 - samples/sec: 137.74 - lr: 0.000015
2021-07-22 17:13:24,683 epoch 30 - iter 1390/1391 - loss 0.08302476 - samples/sec: 140.85 - lr: 0.000015
2021-07-22 17:13:24,839 ----------------------------------------------------------------------------------------------------
2021-07-22 17:13:24,839 EPOCH 30 done: loss 0.0832 - lr 0.0000150
2021-07-22 17:13:42,306 DEV : loss 0.1194530725479126 - score 0.9707
2021-07-22 17:13:42,490 BAD EPOCHS (no improvement): 1
2021-07-22 17:13:42,490 ----------------------------------------------------------------------------------------------------
2021-07-22 17:14:14,343 epoch 31 - iter 139/1391 - loss 0.07941697 - samples/sec: 139.69 - lr: 0.000015
2021-07-22 17:14:46,283 epoch 31 - iter 278/1391 - loss 0.08149894 - samples/sec: 139.29 - lr: 0.000015
2021-07-22 17:15:18,285 epoch 31 - iter 417/1391 - loss 0.07948793 - samples/sec: 139.02 - lr: 0.000015
2021-07-22 17:15:50,617 epoch 31 - iter 556/1391 - loss 0.08017255 - samples/sec: 137.60 - lr: 0.000015
2021-07-22 17:16:22,800 epoch 31 - iter 695/1391 - loss 0.08286943 - samples/sec: 138.24 - lr: 0.000015
2021-07-22 17:16:54,702 epoch 31 - iter 834/1391 - loss 0.08245401 - samples/sec: 139.46 - lr: 0.000015
2021-07-22 17:17:26,679 epoch 31 - iter 973/1391 - loss 0.08242177 - samples/sec: 139.13 - lr: 0.000015
2021-07-22 17:17:58,638 epoch 31 - iter 1112/1391 - loss 0.08223709 - samples/sec: 139.21 - lr: 0.000015
2021-07-22 17:18:30,622 epoch 31 - iter 1251/1391 - loss 0.08264056 - samples/sec: 139.10 - lr: 0.000015
2021-07-22 17:19:02,451 epoch 31 - iter 1390/1391 - loss 0.08196187 - samples/sec: 139.78 - lr: 0.000015
2021-07-22 17:19:02,611 ----------------------------------------------------------------------------------------------------
2021-07-22 17:19:02,612 EPOCH 31 done: loss 0.0819 - lr 0.0000150
2021-07-22 17:19:19,994 DEV : loss 0.1208420842885971 - score 0.9708
2021-07-22 17:19:20,180 BAD EPOCHS (no improvement): 2
2021-07-22 17:19:20,181 ----------------------------------------------------------------------------------------------------
2021-07-22 17:19:52,313 epoch 32 - iter 139/1391 - loss 0.08237272 - samples/sec: 138.47 - lr: 0.000015
2021-07-22 17:20:24,283 epoch 32 - iter 278/1391 - loss 0.08080665 - samples/sec: 139.16 - lr: 0.000015
2021-07-22 17:20:56,160 epoch 32 - iter 417/1391 - loss 0.07867429 - samples/sec: 139.57 - lr: 0.000015
2021-07-22 17:21:28,024 epoch 32 - iter 556/1391 - loss 0.07610546 - samples/sec: 139.63 - lr: 0.000015
2021-07-22 17:22:00,358 epoch 32 - iter 695/1391 - loss 0.07804417 - samples/sec: 137.60 - lr: 0.000015
2021-07-22 17:22:32,183 epoch 32 - iter 834/1391 - loss 0.07858091 - samples/sec: 139.80 - lr: 0.000015
2021-07-22 17:23:03,878 epoch 32 - iter 973/1391 - loss 0.08092071 - samples/sec: 140.37 - lr: 0.000015
2021-07-22 17:23:35,335 epoch 32 - iter 1112/1391 - loss 0.08054536 - samples/sec: 141.43 - lr: 0.000015
2021-07-22 17:24:07,247 epoch 32 - iter 1251/1391 - loss 0.08109861 - samples/sec: 139.41 - lr: 0.000015
2021-07-22 17:24:39,192 epoch 32 - iter 1390/1391 - loss 0.08073936 - samples/sec: 139.27 - lr: 0.000015
2021-07-22 17:24:39,332 ----------------------------------------------------------------------------------------------------
2021-07-22 17:24:39,333 EPOCH 32 done: loss 0.0808 - lr 0.0000150
2021-07-22 17:24:58,126 DEV : loss 0.1182423084974289 - score 0.9709
2021-07-22 17:24:58,312 BAD EPOCHS (no improvement): 3
2021-07-22 17:24:58,312 ----------------------------------------------------------------------------------------------------
2021-07-22 17:25:30,236 epoch 33 - iter 139/1391 - loss 0.07403834 - samples/sec: 139.38 - lr: 0.000015
2021-07-22 17:26:02,119 epoch 33 - iter 278/1391 - loss 0.07199971 - samples/sec: 139.54 - lr: 0.000015
2021-07-22 17:26:34,119 epoch 33 - iter 417/1391 - loss 0.07564911 - samples/sec: 139.03 - lr: 0.000015
2021-07-22 17:27:06,068 epoch 33 - iter 556/1391 - loss 0.07747044 - samples/sec: 139.25 - lr: 0.000015
2021-07-22 17:27:38,224 epoch 33 - iter 695/1391 - loss 0.07890473 - samples/sec: 138.36 - lr: 0.000015
2021-07-22 17:28:10,472 epoch 33 - iter 834/1391 - loss 0.07884725 - samples/sec: 137.96 - lr: 0.000015
2021-07-22 17:28:42,204 epoch 33 - iter 973/1391 - loss 0.07914113 - samples/sec: 140.20 - lr: 0.000015
2021-07-22 17:29:14,138 epoch 33 - iter 1112/1391 - loss 0.07935163 - samples/sec: 139.32 - lr: 0.000015
2021-07-22 17:29:46,203 epoch 33 - iter 1251/1391 - loss 0.07892693 - samples/sec: 138.75 - lr: 0.000015
2021-07-22 17:30:18,427 epoch 33 - iter 1390/1391 - loss 0.08060185 - samples/sec: 138.06 - lr: 0.000015
2021-07-22 17:30:18,556 ----------------------------------------------------------------------------------------------------
2021-07-22 17:30:18,556 EPOCH 33 done: loss 0.0806 - lr 0.0000150
2021-07-22 17:30:35,860 DEV : loss 0.12175153195858002 - score 0.9701
Epoch    33: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 17:30:36,046 BAD EPOCHS (no improvement): 4
2021-07-22 17:30:36,047 ----------------------------------------------------------------------------------------------------
2021-07-22 17:31:07,398 epoch 34 - iter 139/1391 - loss 0.07988205 - samples/sec: 141.92 - lr: 0.000008
2021-07-22 17:31:39,350 epoch 34 - iter 278/1391 - loss 0.07552557 - samples/sec: 139.24 - lr: 0.000008
2021-07-22 17:32:11,208 epoch 34 - iter 417/1391 - loss 0.07914892 - samples/sec: 139.65 - lr: 0.000008
2021-07-22 17:32:43,401 epoch 34 - iter 556/1391 - loss 0.07810552 - samples/sec: 138.19 - lr: 0.000008
2021-07-22 17:33:15,487 epoch 34 - iter 695/1391 - loss 0.07716452 - samples/sec: 138.66 - lr: 0.000008
2021-07-22 17:33:47,314 epoch 34 - iter 834/1391 - loss 0.07703581 - samples/sec: 139.79 - lr: 0.000008
2021-07-22 17:34:19,228 epoch 34 - iter 973/1391 - loss 0.07665719 - samples/sec: 139.41 - lr: 0.000008
2021-07-22 17:34:51,380 epoch 34 - iter 1112/1391 - loss 0.07711019 - samples/sec: 138.37 - lr: 0.000008
2021-07-22 17:35:23,473 epoch 34 - iter 1251/1391 - loss 0.07713280 - samples/sec: 138.63 - lr: 0.000008
2021-07-22 17:35:55,764 epoch 34 - iter 1390/1391 - loss 0.07714167 - samples/sec: 137.78 - lr: 0.000008
2021-07-22 17:35:55,916 ----------------------------------------------------------------------------------------------------
2021-07-22 17:35:55,916 EPOCH 34 done: loss 0.0772 - lr 0.0000075
2021-07-22 17:36:13,389 DEV : loss 0.12225568294525146 - score 0.97
2021-07-22 17:36:13,576 BAD EPOCHS (no improvement): 1
2021-07-22 17:36:13,576 ----------------------------------------------------------------------------------------------------
2021-07-22 17:36:45,195 epoch 35 - iter 139/1391 - loss 0.07406263 - samples/sec: 140.72 - lr: 0.000008
2021-07-22 17:37:17,300 epoch 35 - iter 278/1391 - loss 0.07959537 - samples/sec: 138.58 - lr: 0.000008
2021-07-22 17:37:49,268 epoch 35 - iter 417/1391 - loss 0.08120018 - samples/sec: 139.17 - lr: 0.000008
2021-07-22 17:38:20,618 epoch 35 - iter 556/1391 - loss 0.08023269 - samples/sec: 141.92 - lr: 0.000008
2021-07-22 17:38:52,780 epoch 35 - iter 695/1391 - loss 0.08019090 - samples/sec: 138.33 - lr: 0.000008
2021-07-22 17:39:24,336 epoch 35 - iter 834/1391 - loss 0.07903137 - samples/sec: 140.99 - lr: 0.000008
2021-07-22 17:39:55,990 epoch 35 - iter 973/1391 - loss 0.07897059 - samples/sec: 140.55 - lr: 0.000008
2021-07-22 17:40:27,779 epoch 35 - iter 1112/1391 - loss 0.07834059 - samples/sec: 139.95 - lr: 0.000008
2021-07-22 17:41:00,131 epoch 35 - iter 1251/1391 - loss 0.07797849 - samples/sec: 137.52 - lr: 0.000008
2021-07-22 17:41:32,536 epoch 35 - iter 1390/1391 - loss 0.07685567 - samples/sec: 137.29 - lr: 0.000008
2021-07-22 17:41:32,671 ----------------------------------------------------------------------------------------------------
2021-07-22 17:41:32,671 EPOCH 35 done: loss 0.0770 - lr 0.0000075
2021-07-22 17:41:50,016 DEV : loss 0.12362387776374817 - score 0.9697
2021-07-22 17:41:50,205 BAD EPOCHS (no improvement): 2
2021-07-22 17:41:50,205 ----------------------------------------------------------------------------------------------------
2021-07-22 17:42:21,979 epoch 36 - iter 139/1391 - loss 0.08016505 - samples/sec: 140.03 - lr: 0.000008
2021-07-22 17:42:54,140 epoch 36 - iter 278/1391 - loss 0.07942817 - samples/sec: 138.33 - lr: 0.000008
2021-07-22 17:43:26,094 epoch 36 - iter 417/1391 - loss 0.07890768 - samples/sec: 139.23 - lr: 0.000008
2021-07-22 17:43:58,354 epoch 36 - iter 556/1391 - loss 0.07595830 - samples/sec: 137.91 - lr: 0.000008
2021-07-22 17:44:30,215 epoch 36 - iter 695/1391 - loss 0.07637183 - samples/sec: 139.64 - lr: 0.000008
2021-07-22 17:45:02,074 epoch 36 - iter 834/1391 - loss 0.07582592 - samples/sec: 139.64 - lr: 0.000008
2021-07-22 17:45:34,056 epoch 36 - iter 973/1391 - loss 0.07600929 - samples/sec: 139.11 - lr: 0.000008
2021-07-22 17:46:06,813 epoch 36 - iter 1112/1391 - loss 0.07597869 - samples/sec: 135.82 - lr: 0.000008
2021-07-22 17:46:39,159 epoch 36 - iter 1251/1391 - loss 0.07632195 - samples/sec: 137.54 - lr: 0.000008
2021-07-22 17:47:11,059 epoch 36 - iter 1390/1391 - loss 0.07710800 - samples/sec: 139.47 - lr: 0.000008
2021-07-22 17:47:11,173 ----------------------------------------------------------------------------------------------------
2021-07-22 17:47:11,174 EPOCH 36 done: loss 0.0771 - lr 0.0000075
2021-07-22 17:47:29,931 DEV : loss 0.12366512417793274 - score 0.9698
2021-07-22 17:47:30,119 BAD EPOCHS (no improvement): 3
2021-07-22 17:47:30,120 ----------------------------------------------------------------------------------------------------
2021-07-22 17:48:02,296 epoch 37 - iter 139/1391 - loss 0.07885605 - samples/sec: 138.28 - lr: 0.000008
2021-07-22 17:48:34,410 epoch 37 - iter 278/1391 - loss 0.08052183 - samples/sec: 138.54 - lr: 0.000008
2021-07-22 17:49:06,214 epoch 37 - iter 417/1391 - loss 0.07646822 - samples/sec: 139.89 - lr: 0.000008
2021-07-22 17:49:38,254 epoch 37 - iter 556/1391 - loss 0.07630354 - samples/sec: 138.86 - lr: 0.000008
2021-07-22 17:50:10,522 epoch 37 - iter 695/1391 - loss 0.07592803 - samples/sec: 137.88 - lr: 0.000008
2021-07-22 17:50:42,633 epoch 37 - iter 834/1391 - loss 0.07675732 - samples/sec: 138.55 - lr: 0.000008
2021-07-22 17:51:14,460 epoch 37 - iter 973/1391 - loss 0.07755762 - samples/sec: 139.79 - lr: 0.000008
2021-07-22 17:51:46,527 epoch 37 - iter 1112/1391 - loss 0.07799158 - samples/sec: 138.74 - lr: 0.000008
2021-07-22 17:52:18,491 epoch 37 - iter 1251/1391 - loss 0.07764024 - samples/sec: 139.19 - lr: 0.000008
2021-07-22 17:52:50,737 epoch 37 - iter 1390/1391 - loss 0.07692434 - samples/sec: 137.97 - lr: 0.000008
2021-07-22 17:52:50,878 ----------------------------------------------------------------------------------------------------
2021-07-22 17:52:50,878 EPOCH 37 done: loss 0.0769 - lr 0.0000075
2021-07-22 17:53:08,202 DEV : loss 0.12288321554660797 - score 0.9705
Epoch    37: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 17:53:08,389 BAD EPOCHS (no improvement): 4
2021-07-22 17:53:08,390 ----------------------------------------------------------------------------------------------------
2021-07-22 17:53:40,369 epoch 38 - iter 139/1391 - loss 0.07092571 - samples/sec: 139.13 - lr: 0.000004
2021-07-22 17:54:12,685 epoch 38 - iter 278/1391 - loss 0.07349056 - samples/sec: 137.67 - lr: 0.000004
2021-07-22 17:54:44,603 epoch 38 - iter 417/1391 - loss 0.07488800 - samples/sec: 139.39 - lr: 0.000004
2021-07-22 17:55:16,991 epoch 38 - iter 556/1391 - loss 0.07586008 - samples/sec: 137.37 - lr: 0.000004
2021-07-22 17:55:49,252 epoch 38 - iter 695/1391 - loss 0.07415534 - samples/sec: 137.91 - lr: 0.000004
2021-07-22 17:56:21,108 epoch 38 - iter 834/1391 - loss 0.07426658 - samples/sec: 139.66 - lr: 0.000004
2021-07-22 17:56:52,861 epoch 38 - iter 973/1391 - loss 0.07470875 - samples/sec: 140.11 - lr: 0.000004
2021-07-22 17:57:25,005 epoch 38 - iter 1112/1391 - loss 0.07399679 - samples/sec: 138.41 - lr: 0.000004
2021-07-22 17:57:56,668 epoch 38 - iter 1251/1391 - loss 0.07393440 - samples/sec: 140.51 - lr: 0.000004
2021-07-22 17:58:28,727 epoch 38 - iter 1390/1391 - loss 0.07505788 - samples/sec: 138.77 - lr: 0.000004
2021-07-22 17:58:28,871 ----------------------------------------------------------------------------------------------------
2021-07-22 17:58:28,871 EPOCH 38 done: loss 0.0751 - lr 0.0000038
2021-07-22 17:58:46,183 DEV : loss 0.12257403880357742 - score 0.9707
2021-07-22 17:58:46,370 BAD EPOCHS (no improvement): 1
2021-07-22 17:58:46,370 ----------------------------------------------------------------------------------------------------
2021-07-22 17:59:18,320 epoch 39 - iter 139/1391 - loss 0.07122002 - samples/sec: 139.26 - lr: 0.000004
2021-07-22 17:59:50,418 epoch 39 - iter 278/1391 - loss 0.07007707 - samples/sec: 138.61 - lr: 0.000004
2021-07-22 18:00:22,623 epoch 39 - iter 417/1391 - loss 0.06998639 - samples/sec: 138.15 - lr: 0.000004
2021-07-22 18:00:54,671 epoch 39 - iter 556/1391 - loss 0.07215529 - samples/sec: 138.82 - lr: 0.000004
2021-07-22 18:01:26,555 epoch 39 - iter 695/1391 - loss 0.07125301 - samples/sec: 139.54 - lr: 0.000004
2021-07-22 18:01:58,601 epoch 39 - iter 834/1391 - loss 0.07287517 - samples/sec: 138.83 - lr: 0.000004
2021-07-22 18:02:30,415 epoch 39 - iter 973/1391 - loss 0.07319291 - samples/sec: 139.84 - lr: 0.000004
2021-07-22 18:03:03,156 epoch 39 - iter 1112/1391 - loss 0.07469411 - samples/sec: 135.89 - lr: 0.000004
2021-07-22 18:03:34,601 epoch 39 - iter 1251/1391 - loss 0.07432003 - samples/sec: 141.48 - lr: 0.000004
2021-07-22 18:04:06,920 epoch 39 - iter 1390/1391 - loss 0.07456631 - samples/sec: 137.66 - lr: 0.000004
2021-07-22 18:04:07,043 ----------------------------------------------------------------------------------------------------
2021-07-22 18:04:07,043 EPOCH 39 done: loss 0.0747 - lr 0.0000038
2021-07-22 18:04:24,474 DEV : loss 0.12465482950210571 - score 0.9698
2021-07-22 18:04:24,661 BAD EPOCHS (no improvement): 2
2021-07-22 18:04:24,662 ----------------------------------------------------------------------------------------------------
2021-07-22 18:04:56,445 epoch 40 - iter 139/1391 - loss 0.07207747 - samples/sec: 139.99 - lr: 0.000004
2021-07-22 18:05:28,604 epoch 40 - iter 278/1391 - loss 0.07477785 - samples/sec: 138.35 - lr: 0.000004
2021-07-22 18:06:00,608 epoch 40 - iter 417/1391 - loss 0.07604651 - samples/sec: 139.01 - lr: 0.000004
2021-07-22 18:06:32,539 epoch 40 - iter 556/1391 - loss 0.07653743 - samples/sec: 139.33 - lr: 0.000004
2021-07-22 18:07:03,907 epoch 40 - iter 695/1391 - loss 0.07683768 - samples/sec: 141.83 - lr: 0.000004
2021-07-22 18:07:35,535 epoch 40 - iter 834/1391 - loss 0.07564138 - samples/sec: 140.67 - lr: 0.000004
2021-07-22 18:08:07,679 epoch 40 - iter 973/1391 - loss 0.07717250 - samples/sec: 138.41 - lr: 0.000004
2021-07-22 18:08:39,813 epoch 40 - iter 1112/1391 - loss 0.07688847 - samples/sec: 138.45 - lr: 0.000004
2021-07-22 18:09:12,131 epoch 40 - iter 1251/1391 - loss 0.07660062 - samples/sec: 137.66 - lr: 0.000004
2021-07-22 18:09:44,358 epoch 40 - iter 1390/1391 - loss 0.07595770 - samples/sec: 138.05 - lr: 0.000004
2021-07-22 18:09:44,490 ----------------------------------------------------------------------------------------------------
2021-07-22 18:09:44,490 EPOCH 40 done: loss 0.0759 - lr 0.0000038
2021-07-22 18:10:03,270 DEV : loss 0.1239173635840416 - score 0.97
2021-07-22 18:10:03,458 BAD EPOCHS (no improvement): 3
2021-07-22 18:10:04,026 ----------------------------------------------------------------------------------------------------
2021-07-22 18:10:04,027 Testing using best model ...
2021-07-22 18:10:04,028 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/tur.pdtb.tdb/best-model.pt
2021-07-22 18:13:37,321 0.9783	0.9921	0.9852
2021-07-22 18:13:37,322 
Results:
- F1-score (micro) 0.9852
- F1-score (macro) 0.9879

By class:
SENT       tp: 7347 - fp: 268 - fn: 96 - precision: 0.9648 - recall: 0.9871 - f1-score: 0.9758
X          tp: 4731 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 18:13:37,322 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/fas.rst.prstc/
2021-07-22 18:13:37,346 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/fas.rst.prstc
2021-07-22 18:13:37,347 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/fas.rst.prstc/sent_train.txt
2021-07-22 18:13:37,348 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/fas.rst.prstc/sent_dev.txt
2021-07-22 18:13:37,350 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/fas.rst.prstc/sent_test.txt
Corpus: 5067 train + 863 dev + 1552 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 18:13:52,366 ----------------------------------------------------------------------------------------------------
2021-07-22 18:13:52,367 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(100000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 18:13:52,367 ----------------------------------------------------------------------------------------------------
2021-07-22 18:13:52,367 Corpus: "Corpus: 5067 train + 863 dev + 1552 test sentences"
2021-07-22 18:13:52,367 ----------------------------------------------------------------------------------------------------
2021-07-22 18:13:52,367 Parameters:
2021-07-22 18:13:52,367  - learning_rate: "3e-05"
2021-07-22 18:13:52,368  - mini_batch_size: "32"
2021-07-22 18:13:52,368  - patience: "3"
2021-07-22 18:13:52,368  - anneal_factor: "0.5"
2021-07-22 18:13:52,368  - max_epochs: "40"
2021-07-22 18:13:52,368  - shuffle: "True"
2021-07-22 18:13:52,368  - train_with_dev: "False"
2021-07-22 18:13:52,368  - batch_growth_annealing: "False"
2021-07-22 18:13:52,368 ----------------------------------------------------------------------------------------------------
2021-07-22 18:13:52,368 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/fas.rst.prstc"
2021-07-22 18:13:52,368 ----------------------------------------------------------------------------------------------------
2021-07-22 18:13:52,368 Device: cuda:0
2021-07-22 18:13:52,368 ----------------------------------------------------------------------------------------------------
2021-07-22 18:13:52,368 Embeddings storage mode: cpu
2021-07-22 18:13:52,371 ----------------------------------------------------------------------------------------------------
