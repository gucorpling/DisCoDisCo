/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.pdtb.cdtb/
2021-07-18 11:45:39,188 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.pdtb.cdtb
2021-07-18 11:45:39,188 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.pdtb.cdtb/sent_train.txt
2021-07-18 11:45:39,188 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.pdtb.cdtb/sent_dev.txt
2021-07-18 11:45:39,188 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.pdtb.cdtb/sent_test.txt
Corpus: 1893 train + 541 dev + 645 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 11:45:45,203 ----------------------------------------------------------------------------------------------------
2021-07-18 11:45:45,205 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(21128, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 11:45:45,205 ----------------------------------------------------------------------------------------------------
2021-07-18 11:45:45,205 Corpus: "Corpus: 1893 train + 541 dev + 645 test sentences"
2021-07-18 11:45:45,205 ----------------------------------------------------------------------------------------------------
2021-07-18 11:45:45,205 Parameters:
2021-07-18 11:45:45,205  - learning_rate: "3e-05"
2021-07-18 11:45:45,205  - mini_batch_size: "32"
2021-07-18 11:45:45,205  - patience: "3"
2021-07-18 11:45:45,205  - anneal_factor: "0.5"
2021-07-18 11:45:45,205  - max_epochs: "40"
2021-07-18 11:45:45,206  - shuffle: "True"
2021-07-18 11:45:45,206  - train_with_dev: "False"
2021-07-18 11:45:45,206  - batch_growth_annealing: "False"
2021-07-18 11:45:45,206 ----------------------------------------------------------------------------------------------------
2021-07-18 11:45:45,206 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.pdtb.cdtb"
2021-07-18 11:45:45,206 ----------------------------------------------------------------------------------------------------
2021-07-18 11:45:45,206 Device: cuda:0
2021-07-18 11:45:45,206 ----------------------------------------------------------------------------------------------------
2021-07-18 11:45:45,206 Embeddings storage mode: cpu
2021-07-18 11:45:45,209 ----------------------------------------------------------------------------------------------------
2021-07-18 11:45:50,932 epoch 1 - iter 6/60 - loss 11.19809135 - samples/sec: 33.55 - lr: 0.000030
2021-07-18 11:45:56,257 epoch 1 - iter 12/60 - loss 8.00409446 - samples/sec: 36.06 - lr: 0.000030
2021-07-18 11:46:01,660 epoch 1 - iter 18/60 - loss 6.65640144 - samples/sec: 35.54 - lr: 0.000030
2021-07-18 11:46:07,047 epoch 1 - iter 24/60 - loss 5.86025933 - samples/sec: 35.65 - lr: 0.000030
2021-07-18 11:46:12,434 epoch 1 - iter 30/60 - loss 5.31932369 - samples/sec: 35.64 - lr: 0.000030
2021-07-18 11:46:17,835 epoch 1 - iter 36/60 - loss 4.93241445 - samples/sec: 35.55 - lr: 0.000030
2021-07-18 11:46:23,425 epoch 1 - iter 42/60 - loss 4.65253083 - samples/sec: 34.35 - lr: 0.000030
2021-07-18 11:46:28,849 epoch 1 - iter 48/60 - loss 4.42901737 - samples/sec: 35.40 - lr: 0.000030
2021-07-18 11:46:34,312 epoch 1 - iter 54/60 - loss 4.22171651 - samples/sec: 35.14 - lr: 0.000030
2021-07-18 11:46:39,023 epoch 1 - iter 60/60 - loss 4.01308228 - samples/sec: 40.77 - lr: 0.000030
2021-07-18 11:46:39,023 ----------------------------------------------------------------------------------------------------
2021-07-18 11:46:39,023 EPOCH 1 done: loss 4.0131 - lr 0.0000300
2021-07-18 11:46:48,563 DEV : loss 2.062592029571533 - score 0.15
2021-07-18 11:46:48,602 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:46:49,232 ----------------------------------------------------------------------------------------------------
2021-07-18 11:46:51,920 epoch 2 - iter 6/60 - loss 2.25050704 - samples/sec: 71.45 - lr: 0.000030
2021-07-18 11:46:54,645 epoch 2 - iter 12/60 - loss 2.25751866 - samples/sec: 70.48 - lr: 0.000030
2021-07-18 11:46:57,364 epoch 2 - iter 18/60 - loss 2.15517755 - samples/sec: 70.61 - lr: 0.000030
2021-07-18 11:47:00,059 epoch 2 - iter 24/60 - loss 2.09737019 - samples/sec: 71.26 - lr: 0.000030
2021-07-18 11:47:02,752 epoch 2 - iter 30/60 - loss 2.07418514 - samples/sec: 71.32 - lr: 0.000030
2021-07-18 11:47:05,469 epoch 2 - iter 36/60 - loss 2.01120122 - samples/sec: 70.69 - lr: 0.000030
2021-07-18 11:47:08,142 epoch 2 - iter 42/60 - loss 1.96184622 - samples/sec: 71.83 - lr: 0.000030
2021-07-18 11:47:10,836 epoch 2 - iter 48/60 - loss 1.92349341 - samples/sec: 71.30 - lr: 0.000030
2021-07-18 11:47:13,568 epoch 2 - iter 54/60 - loss 1.85644130 - samples/sec: 70.28 - lr: 0.000030
2021-07-18 11:47:15,964 epoch 2 - iter 60/60 - loss 1.83390959 - samples/sec: 80.16 - lr: 0.000030
2021-07-18 11:47:15,964 ----------------------------------------------------------------------------------------------------
2021-07-18 11:47:15,964 EPOCH 2 done: loss 1.8339 - lr 0.0000300
2021-07-18 11:47:18,780 DEV : loss 1.2328534126281738 - score 0.6868
2021-07-18 11:47:18,819 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:47:22,284 ----------------------------------------------------------------------------------------------------
2021-07-18 11:47:24,986 epoch 3 - iter 6/60 - loss 1.51911032 - samples/sec: 71.08 - lr: 0.000030
2021-07-18 11:47:27,673 epoch 3 - iter 12/60 - loss 1.50313641 - samples/sec: 71.45 - lr: 0.000030
2021-07-18 11:47:30,359 epoch 3 - iter 18/60 - loss 1.42377703 - samples/sec: 71.51 - lr: 0.000030
2021-07-18 11:47:33,051 epoch 3 - iter 24/60 - loss 1.37111847 - samples/sec: 71.34 - lr: 0.000030
2021-07-18 11:47:35,763 epoch 3 - iter 30/60 - loss 1.31840616 - samples/sec: 70.81 - lr: 0.000030
2021-07-18 11:47:38,482 epoch 3 - iter 36/60 - loss 1.30484074 - samples/sec: 70.62 - lr: 0.000030
2021-07-18 11:47:41,167 epoch 3 - iter 42/60 - loss 1.31532956 - samples/sec: 71.53 - lr: 0.000030
2021-07-18 11:47:43,860 epoch 3 - iter 48/60 - loss 1.28661263 - samples/sec: 71.32 - lr: 0.000030
2021-07-18 11:47:46,535 epoch 3 - iter 54/60 - loss 1.25060279 - samples/sec: 71.80 - lr: 0.000030
2021-07-18 11:47:48,878 epoch 3 - iter 60/60 - loss 1.21741907 - samples/sec: 81.97 - lr: 0.000030
2021-07-18 11:47:48,878 ----------------------------------------------------------------------------------------------------
2021-07-18 11:47:48,878 EPOCH 3 done: loss 1.2174 - lr 0.0000300
2021-07-18 11:47:51,493 DEV : loss 0.8690457940101624 - score 0.7965
2021-07-18 11:47:51,531 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:47:54,933 ----------------------------------------------------------------------------------------------------
2021-07-18 11:47:57,599 epoch 4 - iter 6/60 - loss 0.97817546 - samples/sec: 72.04 - lr: 0.000030
2021-07-18 11:48:00,295 epoch 4 - iter 12/60 - loss 0.99508074 - samples/sec: 71.25 - lr: 0.000030
2021-07-18 11:48:02,961 epoch 4 - iter 18/60 - loss 0.96519814 - samples/sec: 72.02 - lr: 0.000030
2021-07-18 11:48:05,656 epoch 4 - iter 24/60 - loss 0.96908094 - samples/sec: 71.28 - lr: 0.000030
2021-07-18 11:48:08,360 epoch 4 - iter 30/60 - loss 0.99098449 - samples/sec: 71.02 - lr: 0.000030
2021-07-18 11:48:11,064 epoch 4 - iter 36/60 - loss 0.98788315 - samples/sec: 71.03 - lr: 0.000030
2021-07-18 11:48:13,754 epoch 4 - iter 42/60 - loss 0.97305505 - samples/sec: 71.38 - lr: 0.000030
2021-07-18 11:48:16,450 epoch 4 - iter 48/60 - loss 0.95098557 - samples/sec: 71.23 - lr: 0.000030
2021-07-18 11:48:19,151 epoch 4 - iter 54/60 - loss 0.94654199 - samples/sec: 71.10 - lr: 0.000030
2021-07-18 11:48:21,524 epoch 4 - iter 60/60 - loss 0.92426198 - samples/sec: 80.95 - lr: 0.000030
2021-07-18 11:48:21,524 ----------------------------------------------------------------------------------------------------
2021-07-18 11:48:21,524 EPOCH 4 done: loss 0.9243 - lr 0.0000300
2021-07-18 11:48:24,149 DEV : loss 0.6759858727455139 - score 0.8611
2021-07-18 11:48:24,188 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:48:27,137 ----------------------------------------------------------------------------------------------------
2021-07-18 11:48:29,868 epoch 5 - iter 6/60 - loss 0.75892343 - samples/sec: 70.33 - lr: 0.000030
2021-07-18 11:48:32,566 epoch 5 - iter 12/60 - loss 0.76021180 - samples/sec: 71.18 - lr: 0.000030
2021-07-18 11:48:35,301 epoch 5 - iter 18/60 - loss 0.73402403 - samples/sec: 70.20 - lr: 0.000030
2021-07-18 11:48:38,020 epoch 5 - iter 24/60 - loss 0.74764759 - samples/sec: 70.64 - lr: 0.000030
2021-07-18 11:48:40,722 epoch 5 - iter 30/60 - loss 0.74445339 - samples/sec: 71.09 - lr: 0.000030
2021-07-18 11:48:43,444 epoch 5 - iter 36/60 - loss 0.74348375 - samples/sec: 70.55 - lr: 0.000030
2021-07-18 11:48:46,155 epoch 5 - iter 42/60 - loss 0.73427060 - samples/sec: 70.83 - lr: 0.000030
2021-07-18 11:48:48,913 epoch 5 - iter 48/60 - loss 0.73964206 - samples/sec: 69.62 - lr: 0.000030
2021-07-18 11:48:51,621 epoch 5 - iter 54/60 - loss 0.72690998 - samples/sec: 70.93 - lr: 0.000030
2021-07-18 11:48:54,001 epoch 5 - iter 60/60 - loss 0.73002751 - samples/sec: 80.70 - lr: 0.000030
2021-07-18 11:48:54,001 ----------------------------------------------------------------------------------------------------
2021-07-18 11:48:54,001 EPOCH 5 done: loss 0.7300 - lr 0.0000300
2021-07-18 11:48:56,629 DEV : loss 0.5293059945106506 - score 0.8935
2021-07-18 11:48:56,668 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:49:00,322 ----------------------------------------------------------------------------------------------------
2021-07-18 11:49:03,278 epoch 6 - iter 6/60 - loss 0.67322011 - samples/sec: 64.99 - lr: 0.000030
2021-07-18 11:49:05,980 epoch 6 - iter 12/60 - loss 0.62533138 - samples/sec: 71.06 - lr: 0.000030
2021-07-18 11:49:08,688 epoch 6 - iter 18/60 - loss 0.62251240 - samples/sec: 70.92 - lr: 0.000030
2021-07-18 11:49:11,376 epoch 6 - iter 24/60 - loss 0.60818686 - samples/sec: 71.46 - lr: 0.000030
2021-07-18 11:49:14,028 epoch 6 - iter 30/60 - loss 0.60136971 - samples/sec: 72.41 - lr: 0.000030
2021-07-18 11:49:16,697 epoch 6 - iter 36/60 - loss 0.60035542 - samples/sec: 71.96 - lr: 0.000030
2021-07-18 11:49:19,354 epoch 6 - iter 42/60 - loss 0.58990264 - samples/sec: 72.26 - lr: 0.000030
2021-07-18 11:49:22,048 epoch 6 - iter 48/60 - loss 0.60542658 - samples/sec: 71.29 - lr: 0.000030
2021-07-18 11:49:24,720 epoch 6 - iter 54/60 - loss 0.60844115 - samples/sec: 71.87 - lr: 0.000030
2021-07-18 11:49:27,068 epoch 6 - iter 60/60 - loss 0.60101883 - samples/sec: 81.82 - lr: 0.000030
2021-07-18 11:49:27,068 ----------------------------------------------------------------------------------------------------
2021-07-18 11:49:27,068 EPOCH 6 done: loss 0.6010 - lr 0.0000300
2021-07-18 11:49:29,692 DEV : loss 0.469992458820343 - score 0.9007
2021-07-18 11:49:29,731 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:49:33,601 ----------------------------------------------------------------------------------------------------
2021-07-18 11:49:36,261 epoch 7 - iter 6/60 - loss 0.52333622 - samples/sec: 72.22 - lr: 0.000030
2021-07-18 11:49:38,918 epoch 7 - iter 12/60 - loss 0.47904536 - samples/sec: 72.28 - lr: 0.000030
2021-07-18 11:49:41,614 epoch 7 - iter 18/60 - loss 0.47830161 - samples/sec: 71.23 - lr: 0.000030
2021-07-18 11:49:44,302 epoch 7 - iter 24/60 - loss 0.48441055 - samples/sec: 71.45 - lr: 0.000030
2021-07-18 11:49:47,010 epoch 7 - iter 30/60 - loss 0.51509248 - samples/sec: 70.92 - lr: 0.000030
2021-07-18 11:49:49,683 epoch 7 - iter 36/60 - loss 0.52490782 - samples/sec: 71.84 - lr: 0.000030
2021-07-18 11:49:52,382 epoch 7 - iter 42/60 - loss 0.52591687 - samples/sec: 71.14 - lr: 0.000030
2021-07-18 11:49:55,045 epoch 7 - iter 48/60 - loss 0.53151128 - samples/sec: 72.12 - lr: 0.000030
2021-07-18 11:49:57,702 epoch 7 - iter 54/60 - loss 0.52662715 - samples/sec: 72.28 - lr: 0.000030
2021-07-18 11:50:00,068 epoch 7 - iter 60/60 - loss 0.52800751 - samples/sec: 81.19 - lr: 0.000030
2021-07-18 11:50:00,068 ----------------------------------------------------------------------------------------------------
2021-07-18 11:50:00,068 EPOCH 7 done: loss 0.5280 - lr 0.0000300
2021-07-18 11:50:02,693 DEV : loss 0.42400628328323364 - score 0.9132
2021-07-18 11:50:02,731 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:50:06,451 ----------------------------------------------------------------------------------------------------
2021-07-18 11:50:09,112 epoch 8 - iter 6/60 - loss 0.51447142 - samples/sec: 72.18 - lr: 0.000030
2021-07-18 11:50:11,794 epoch 8 - iter 12/60 - loss 0.47680321 - samples/sec: 71.61 - lr: 0.000030
2021-07-18 11:50:14,481 epoch 8 - iter 18/60 - loss 0.46718315 - samples/sec: 71.47 - lr: 0.000030
2021-07-18 11:50:17,164 epoch 8 - iter 24/60 - loss 0.47201547 - samples/sec: 71.56 - lr: 0.000030
2021-07-18 11:50:19,836 epoch 8 - iter 30/60 - loss 0.49094239 - samples/sec: 71.88 - lr: 0.000030
2021-07-18 11:50:22,505 epoch 8 - iter 36/60 - loss 0.47795182 - samples/sec: 71.96 - lr: 0.000030
2021-07-18 11:50:25,181 epoch 8 - iter 42/60 - loss 0.46645937 - samples/sec: 71.77 - lr: 0.000030
2021-07-18 11:50:27,862 epoch 8 - iter 48/60 - loss 0.47280005 - samples/sec: 71.64 - lr: 0.000030
2021-07-18 11:50:30,554 epoch 8 - iter 54/60 - loss 0.46024825 - samples/sec: 71.32 - lr: 0.000030
2021-07-18 11:50:32,920 epoch 8 - iter 60/60 - loss 0.45315193 - samples/sec: 81.19 - lr: 0.000030
2021-07-18 11:50:32,920 ----------------------------------------------------------------------------------------------------
2021-07-18 11:50:32,921 EPOCH 8 done: loss 0.4532 - lr 0.0000300
2021-07-18 11:50:35,555 DEV : loss 0.3816523253917694 - score 0.9184
2021-07-18 11:50:35,594 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:50:39,363 ----------------------------------------------------------------------------------------------------
2021-07-18 11:50:42,062 epoch 9 - iter 6/60 - loss 0.42796990 - samples/sec: 71.19 - lr: 0.000030
2021-07-18 11:50:44,745 epoch 9 - iter 12/60 - loss 0.43715664 - samples/sec: 71.57 - lr: 0.000030
2021-07-18 11:50:47,475 epoch 9 - iter 18/60 - loss 0.47300615 - samples/sec: 70.35 - lr: 0.000030
2021-07-18 11:50:50,207 epoch 9 - iter 24/60 - loss 0.47118074 - samples/sec: 70.29 - lr: 0.000030
2021-07-18 11:50:52,887 epoch 9 - iter 30/60 - loss 0.46253116 - samples/sec: 71.65 - lr: 0.000030
2021-07-18 11:50:55,590 epoch 9 - iter 36/60 - loss 0.44874697 - samples/sec: 71.05 - lr: 0.000030
2021-07-18 11:50:58,314 epoch 9 - iter 42/60 - loss 0.43956296 - samples/sec: 70.51 - lr: 0.000030
2021-07-18 11:51:01,015 epoch 9 - iter 48/60 - loss 0.43224249 - samples/sec: 71.11 - lr: 0.000030
2021-07-18 11:51:03,686 epoch 9 - iter 54/60 - loss 0.42290223 - samples/sec: 71.88 - lr: 0.000030
2021-07-18 11:51:06,060 epoch 9 - iter 60/60 - loss 0.41907059 - samples/sec: 80.90 - lr: 0.000030
2021-07-18 11:51:06,060 ----------------------------------------------------------------------------------------------------
2021-07-18 11:51:06,061 EPOCH 9 done: loss 0.4191 - lr 0.0000300
2021-07-18 11:51:08,893 DEV : loss 0.3436605930328369 - score 0.9231
2021-07-18 11:51:08,933 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:51:12,415 ----------------------------------------------------------------------------------------------------
2021-07-18 11:51:15,115 epoch 10 - iter 6/60 - loss 0.36574661 - samples/sec: 71.14 - lr: 0.000030
2021-07-18 11:51:17,819 epoch 10 - iter 12/60 - loss 0.38240237 - samples/sec: 71.02 - lr: 0.000030
2021-07-18 11:51:20,535 epoch 10 - iter 18/60 - loss 0.39920906 - samples/sec: 70.73 - lr: 0.000030
2021-07-18 11:51:23,247 epoch 10 - iter 24/60 - loss 0.36859643 - samples/sec: 70.79 - lr: 0.000030
2021-07-18 11:51:25,939 epoch 10 - iter 30/60 - loss 0.38447797 - samples/sec: 71.34 - lr: 0.000030
2021-07-18 11:51:28,643 epoch 10 - iter 36/60 - loss 0.37816865 - samples/sec: 71.03 - lr: 0.000030
2021-07-18 11:51:31,343 epoch 10 - iter 42/60 - loss 0.39278192 - samples/sec: 71.12 - lr: 0.000030
2021-07-18 11:51:34,043 epoch 10 - iter 48/60 - loss 0.38988030 - samples/sec: 71.14 - lr: 0.000030
2021-07-18 11:51:36,671 epoch 10 - iter 54/60 - loss 0.38142824 - samples/sec: 73.09 - lr: 0.000030
2021-07-18 11:51:39,053 epoch 10 - iter 60/60 - loss 0.37803407 - samples/sec: 80.59 - lr: 0.000030
2021-07-18 11:51:39,054 ----------------------------------------------------------------------------------------------------
2021-07-18 11:51:39,054 EPOCH 10 done: loss 0.3780 - lr 0.0000300
2021-07-18 11:51:41,690 DEV : loss 0.33339622616767883 - score 0.9324
2021-07-18 11:51:41,728 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:51:44,812 ----------------------------------------------------------------------------------------------------
2021-07-18 11:51:47,503 epoch 11 - iter 6/60 - loss 0.36040395 - samples/sec: 71.38 - lr: 0.000030
2021-07-18 11:51:50,231 epoch 11 - iter 12/60 - loss 0.34523689 - samples/sec: 70.38 - lr: 0.000030
2021-07-18 11:51:52,958 epoch 11 - iter 18/60 - loss 0.32303165 - samples/sec: 70.42 - lr: 0.000030
2021-07-18 11:51:55,655 epoch 11 - iter 24/60 - loss 0.30881485 - samples/sec: 71.22 - lr: 0.000030
2021-07-18 11:51:58,335 epoch 11 - iter 30/60 - loss 0.32929983 - samples/sec: 71.64 - lr: 0.000030
2021-07-18 11:52:01,029 epoch 11 - iter 36/60 - loss 0.33240270 - samples/sec: 71.30 - lr: 0.000030
2021-07-18 11:52:03,735 epoch 11 - iter 42/60 - loss 0.33725485 - samples/sec: 70.95 - lr: 0.000030
2021-07-18 11:52:06,446 epoch 11 - iter 48/60 - loss 0.32952407 - samples/sec: 70.84 - lr: 0.000030
2021-07-18 11:52:09,155 epoch 11 - iter 54/60 - loss 0.33274718 - samples/sec: 70.90 - lr: 0.000030
2021-07-18 11:52:11,539 epoch 11 - iter 60/60 - loss 0.34025129 - samples/sec: 80.55 - lr: 0.000030
2021-07-18 11:52:11,539 ----------------------------------------------------------------------------------------------------
2021-07-18 11:52:11,540 EPOCH 11 done: loss 0.3403 - lr 0.0000300
2021-07-18 11:52:14,182 DEV : loss 0.315763920545578 - score 0.9315
2021-07-18 11:52:14,221 BAD EPOCHS (no improvement): 1
2021-07-18 11:52:14,221 ----------------------------------------------------------------------------------------------------
2021-07-18 11:52:16,924 epoch 12 - iter 6/60 - loss 0.39356449 - samples/sec: 71.06 - lr: 0.000030
2021-07-18 11:52:19,640 epoch 12 - iter 12/60 - loss 0.33545965 - samples/sec: 70.70 - lr: 0.000030
2021-07-18 11:52:22,339 epoch 12 - iter 18/60 - loss 0.32562163 - samples/sec: 71.15 - lr: 0.000030
2021-07-18 11:52:25,027 epoch 12 - iter 24/60 - loss 0.31370118 - samples/sec: 71.46 - lr: 0.000030
2021-07-18 11:52:27,752 epoch 12 - iter 30/60 - loss 0.31302496 - samples/sec: 70.48 - lr: 0.000030
2021-07-18 11:52:30,452 epoch 12 - iter 36/60 - loss 0.31418754 - samples/sec: 71.11 - lr: 0.000030
2021-07-18 11:52:33,147 epoch 12 - iter 42/60 - loss 0.30714114 - samples/sec: 71.28 - lr: 0.000030
2021-07-18 11:52:35,847 epoch 12 - iter 48/60 - loss 0.30903745 - samples/sec: 71.11 - lr: 0.000030
2021-07-18 11:52:38,552 epoch 12 - iter 54/60 - loss 0.31388775 - samples/sec: 71.01 - lr: 0.000030
2021-07-18 11:52:40,912 epoch 12 - iter 60/60 - loss 0.31622876 - samples/sec: 81.36 - lr: 0.000030
2021-07-18 11:52:40,913 ----------------------------------------------------------------------------------------------------
2021-07-18 11:52:40,913 EPOCH 12 done: loss 0.3162 - lr 0.0000300
2021-07-18 11:52:43,760 DEV : loss 0.32139483094215393 - score 0.9291
2021-07-18 11:52:43,800 BAD EPOCHS (no improvement): 2
2021-07-18 11:52:43,800 ----------------------------------------------------------------------------------------------------
2021-07-18 11:52:46,480 epoch 13 - iter 6/60 - loss 0.34377290 - samples/sec: 71.67 - lr: 0.000030
2021-07-18 11:52:49,164 epoch 13 - iter 12/60 - loss 0.28950228 - samples/sec: 71.53 - lr: 0.000030
2021-07-18 11:52:51,863 epoch 13 - iter 18/60 - loss 0.28262499 - samples/sec: 71.17 - lr: 0.000030
2021-07-18 11:52:54,574 epoch 13 - iter 24/60 - loss 0.27973964 - samples/sec: 70.84 - lr: 0.000030
2021-07-18 11:52:57,307 epoch 13 - iter 30/60 - loss 0.28964062 - samples/sec: 70.28 - lr: 0.000030
2021-07-18 11:53:00,011 epoch 13 - iter 36/60 - loss 0.27984758 - samples/sec: 71.02 - lr: 0.000030
2021-07-18 11:53:02,720 epoch 13 - iter 42/60 - loss 0.28252545 - samples/sec: 70.89 - lr: 0.000030
2021-07-18 11:53:05,389 epoch 13 - iter 48/60 - loss 0.27522044 - samples/sec: 71.96 - lr: 0.000030
2021-07-18 11:53:08,123 epoch 13 - iter 54/60 - loss 0.28380710 - samples/sec: 70.23 - lr: 0.000030
2021-07-18 11:53:10,490 epoch 13 - iter 60/60 - loss 0.28031192 - samples/sec: 81.15 - lr: 0.000030
2021-07-18 11:53:10,490 ----------------------------------------------------------------------------------------------------
2021-07-18 11:53:10,490 EPOCH 13 done: loss 0.2803 - lr 0.0000300
2021-07-18 11:53:13,124 DEV : loss 0.30282285809516907 - score 0.9355
2021-07-18 11:53:13,163 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:53:16,738 ----------------------------------------------------------------------------------------------------
2021-07-18 11:53:19,471 epoch 14 - iter 6/60 - loss 0.27700416 - samples/sec: 70.29 - lr: 0.000030
2021-07-18 11:53:22,172 epoch 14 - iter 12/60 - loss 0.22847448 - samples/sec: 71.11 - lr: 0.000030
2021-07-18 11:53:24,864 epoch 14 - iter 18/60 - loss 0.23079843 - samples/sec: 71.32 - lr: 0.000030
2021-07-18 11:53:27,583 epoch 14 - iter 24/60 - loss 0.23457486 - samples/sec: 70.64 - lr: 0.000030
2021-07-18 11:53:30,282 epoch 14 - iter 30/60 - loss 0.22976086 - samples/sec: 71.14 - lr: 0.000030
2021-07-18 11:53:32,978 epoch 14 - iter 36/60 - loss 0.24226584 - samples/sec: 71.23 - lr: 0.000030
2021-07-18 11:53:35,687 epoch 14 - iter 42/60 - loss 0.23590594 - samples/sec: 70.90 - lr: 0.000030
2021-07-18 11:53:38,387 epoch 14 - iter 48/60 - loss 0.23935645 - samples/sec: 71.12 - lr: 0.000030
2021-07-18 11:53:41,098 epoch 14 - iter 54/60 - loss 0.23864946 - samples/sec: 70.84 - lr: 0.000030
2021-07-18 11:53:43,475 epoch 14 - iter 60/60 - loss 0.25123323 - samples/sec: 80.81 - lr: 0.000030
2021-07-18 11:53:43,475 ----------------------------------------------------------------------------------------------------
2021-07-18 11:53:43,475 EPOCH 14 done: loss 0.2512 - lr 0.0000300
2021-07-18 11:53:46,116 DEV : loss 0.2962026298046112 - score 0.9378
2021-07-18 11:53:46,155 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:53:49,091 ----------------------------------------------------------------------------------------------------
2021-07-18 11:53:51,795 epoch 15 - iter 6/60 - loss 0.30783900 - samples/sec: 71.03 - lr: 0.000030
2021-07-18 11:53:54,543 epoch 15 - iter 12/60 - loss 0.28429585 - samples/sec: 69.88 - lr: 0.000030
2021-07-18 11:53:57,279 epoch 15 - iter 18/60 - loss 0.26307658 - samples/sec: 70.19 - lr: 0.000030
2021-07-18 11:53:59,980 epoch 15 - iter 24/60 - loss 0.25846325 - samples/sec: 71.11 - lr: 0.000030
2021-07-18 11:54:02,668 epoch 15 - iter 30/60 - loss 0.25365848 - samples/sec: 71.45 - lr: 0.000030
2021-07-18 11:54:05,350 epoch 15 - iter 36/60 - loss 0.25131307 - samples/sec: 71.59 - lr: 0.000030
2021-07-18 11:54:07,992 epoch 15 - iter 42/60 - loss 0.23964535 - samples/sec: 72.70 - lr: 0.000030
2021-07-18 11:54:10,643 epoch 15 - iter 48/60 - loss 0.24415919 - samples/sec: 72.43 - lr: 0.000030
2021-07-18 11:54:13,331 epoch 15 - iter 54/60 - loss 0.24380149 - samples/sec: 71.45 - lr: 0.000030
2021-07-18 11:54:15,748 epoch 15 - iter 60/60 - loss 0.23996144 - samples/sec: 79.47 - lr: 0.000030
2021-07-18 11:54:15,748 ----------------------------------------------------------------------------------------------------
2021-07-18 11:54:15,748 EPOCH 15 done: loss 0.2400 - lr 0.0000300
2021-07-18 11:54:18,600 DEV : loss 0.2798588275909424 - score 0.9404
2021-07-18 11:54:18,639 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:54:22,037 ----------------------------------------------------------------------------------------------------
2021-07-18 11:54:24,740 epoch 16 - iter 6/60 - loss 0.22144857 - samples/sec: 71.06 - lr: 0.000030
2021-07-18 11:54:27,472 epoch 16 - iter 12/60 - loss 0.20556440 - samples/sec: 70.30 - lr: 0.000030
2021-07-18 11:54:30,194 epoch 16 - iter 18/60 - loss 0.23289628 - samples/sec: 70.55 - lr: 0.000030
2021-07-18 11:54:32,946 epoch 16 - iter 24/60 - loss 0.22638839 - samples/sec: 69.78 - lr: 0.000030
2021-07-18 11:54:35,639 epoch 16 - iter 30/60 - loss 0.22350682 - samples/sec: 71.33 - lr: 0.000030
2021-07-18 11:54:38,371 epoch 16 - iter 36/60 - loss 0.21905720 - samples/sec: 70.29 - lr: 0.000030
2021-07-18 11:54:41,087 epoch 16 - iter 42/60 - loss 0.22493580 - samples/sec: 70.72 - lr: 0.000030
2021-07-18 11:54:43,816 epoch 16 - iter 48/60 - loss 0.22352449 - samples/sec: 70.36 - lr: 0.000030
2021-07-18 11:54:46,508 epoch 16 - iter 54/60 - loss 0.21452220 - samples/sec: 71.35 - lr: 0.000030
2021-07-18 11:54:48,902 epoch 16 - iter 60/60 - loss 0.21186424 - samples/sec: 80.22 - lr: 0.000030
2021-07-18 11:54:48,902 ----------------------------------------------------------------------------------------------------
2021-07-18 11:54:48,902 EPOCH 16 done: loss 0.2119 - lr 0.0000300
2021-07-18 11:54:51,540 DEV : loss 0.28435125946998596 - score 0.9425
2021-07-18 11:54:51,580 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:54:55,190 ----------------------------------------------------------------------------------------------------
2021-07-18 11:54:57,905 epoch 17 - iter 6/60 - loss 0.22813071 - samples/sec: 70.77 - lr: 0.000030
2021-07-18 11:55:00,559 epoch 17 - iter 12/60 - loss 0.21447908 - samples/sec: 72.35 - lr: 0.000030
2021-07-18 11:55:03,283 epoch 17 - iter 18/60 - loss 0.23483150 - samples/sec: 70.49 - lr: 0.000030
2021-07-18 11:55:06,006 epoch 17 - iter 24/60 - loss 0.24109721 - samples/sec: 70.52 - lr: 0.000030
2021-07-18 11:55:08,762 epoch 17 - iter 30/60 - loss 0.23612223 - samples/sec: 69.70 - lr: 0.000030
2021-07-18 11:55:11,491 epoch 17 - iter 36/60 - loss 0.23485931 - samples/sec: 70.37 - lr: 0.000030
2021-07-18 11:55:14,196 epoch 17 - iter 42/60 - loss 0.23165110 - samples/sec: 70.99 - lr: 0.000030
2021-07-18 11:55:16,929 epoch 17 - iter 48/60 - loss 0.22571478 - samples/sec: 70.27 - lr: 0.000030
2021-07-18 11:55:19,623 epoch 17 - iter 54/60 - loss 0.22006567 - samples/sec: 71.27 - lr: 0.000030
2021-07-18 11:55:22,028 epoch 17 - iter 60/60 - loss 0.20879891 - samples/sec: 79.86 - lr: 0.000030
2021-07-18 11:55:22,029 ----------------------------------------------------------------------------------------------------
2021-07-18 11:55:22,029 EPOCH 17 done: loss 0.2088 - lr 0.0000300
2021-07-18 11:55:24,667 DEV : loss 0.2596418857574463 - score 0.9436
2021-07-18 11:55:24,706 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:55:28,346 ----------------------------------------------------------------------------------------------------
2021-07-18 11:55:31,066 epoch 18 - iter 6/60 - loss 0.22266791 - samples/sec: 70.61 - lr: 0.000030
2021-07-18 11:55:33,795 epoch 18 - iter 12/60 - loss 0.20808969 - samples/sec: 70.38 - lr: 0.000030
2021-07-18 11:55:36,484 epoch 18 - iter 18/60 - loss 0.23318237 - samples/sec: 71.41 - lr: 0.000030
2021-07-18 11:55:39,191 epoch 18 - iter 24/60 - loss 0.21361936 - samples/sec: 70.94 - lr: 0.000030
2021-07-18 11:55:41,944 epoch 18 - iter 30/60 - loss 0.21052441 - samples/sec: 69.76 - lr: 0.000030
2021-07-18 11:55:44,675 epoch 18 - iter 36/60 - loss 0.21082830 - samples/sec: 70.32 - lr: 0.000030
2021-07-18 11:55:47,379 epoch 18 - iter 42/60 - loss 0.21847593 - samples/sec: 71.02 - lr: 0.000030
2021-07-18 11:55:50,107 epoch 18 - iter 48/60 - loss 0.21403014 - samples/sec: 70.40 - lr: 0.000030
2021-07-18 11:55:52,831 epoch 18 - iter 54/60 - loss 0.21601117 - samples/sec: 70.51 - lr: 0.000030
2021-07-18 11:55:55,215 epoch 18 - iter 60/60 - loss 0.21592598 - samples/sec: 80.53 - lr: 0.000030
2021-07-18 11:55:55,216 ----------------------------------------------------------------------------------------------------
2021-07-18 11:55:55,216 EPOCH 18 done: loss 0.2159 - lr 0.0000300
2021-07-18 11:55:58,067 DEV : loss 0.26408278942108154 - score 0.9467
2021-07-18 11:55:58,106 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:56:01,583 ----------------------------------------------------------------------------------------------------
2021-07-18 11:56:04,323 epoch 19 - iter 6/60 - loss 0.23894579 - samples/sec: 70.11 - lr: 0.000030
2021-07-18 11:56:07,067 epoch 19 - iter 12/60 - loss 0.22013629 - samples/sec: 69.98 - lr: 0.000030
2021-07-18 11:56:09,780 epoch 19 - iter 18/60 - loss 0.21913078 - samples/sec: 70.80 - lr: 0.000030
2021-07-18 11:56:12,490 epoch 19 - iter 24/60 - loss 0.21186131 - samples/sec: 70.87 - lr: 0.000030
2021-07-18 11:56:15,220 epoch 19 - iter 30/60 - loss 0.22136298 - samples/sec: 70.34 - lr: 0.000030
2021-07-18 11:56:17,947 epoch 19 - iter 36/60 - loss 0.21873471 - samples/sec: 70.44 - lr: 0.000030
2021-07-18 11:56:20,667 epoch 19 - iter 42/60 - loss 0.21398916 - samples/sec: 70.60 - lr: 0.000030
2021-07-18 11:56:23,400 epoch 19 - iter 48/60 - loss 0.22457386 - samples/sec: 70.27 - lr: 0.000030
2021-07-18 11:56:26,063 epoch 19 - iter 54/60 - loss 0.21744956 - samples/sec: 72.12 - lr: 0.000030
2021-07-18 11:56:28,427 epoch 19 - iter 60/60 - loss 0.22046632 - samples/sec: 81.23 - lr: 0.000030
2021-07-18 11:56:28,427 ----------------------------------------------------------------------------------------------------
2021-07-18 11:56:28,427 EPOCH 19 done: loss 0.2205 - lr 0.0000300
2021-07-18 11:56:31,069 DEV : loss 0.2619854211807251 - score 0.9465
2021-07-18 11:56:31,109 BAD EPOCHS (no improvement): 1
2021-07-18 11:56:31,109 ----------------------------------------------------------------------------------------------------
2021-07-18 11:56:33,815 epoch 20 - iter 6/60 - loss 0.17252807 - samples/sec: 70.97 - lr: 0.000030
2021-07-18 11:56:36,545 epoch 20 - iter 12/60 - loss 0.17681906 - samples/sec: 70.35 - lr: 0.000030
2021-07-18 11:56:39,246 epoch 20 - iter 18/60 - loss 0.16952987 - samples/sec: 71.09 - lr: 0.000030
2021-07-18 11:56:41,976 epoch 20 - iter 24/60 - loss 0.17684336 - samples/sec: 70.37 - lr: 0.000030
2021-07-18 11:56:44,692 epoch 20 - iter 30/60 - loss 0.17058834 - samples/sec: 70.70 - lr: 0.000030
2021-07-18 11:56:47,400 epoch 20 - iter 36/60 - loss 0.16949266 - samples/sec: 70.92 - lr: 0.000030
2021-07-18 11:56:50,114 epoch 20 - iter 42/60 - loss 0.17880109 - samples/sec: 70.75 - lr: 0.000030
2021-07-18 11:56:52,836 epoch 20 - iter 48/60 - loss 0.18202699 - samples/sec: 70.55 - lr: 0.000030
2021-07-18 11:56:55,555 epoch 20 - iter 54/60 - loss 0.17692410 - samples/sec: 70.63 - lr: 0.000030
2021-07-18 11:56:57,912 epoch 20 - iter 60/60 - loss 0.18030442 - samples/sec: 81.48 - lr: 0.000030
2021-07-18 11:56:57,913 ----------------------------------------------------------------------------------------------------
2021-07-18 11:56:57,913 EPOCH 20 done: loss 0.1803 - lr 0.0000300
2021-07-18 11:57:00,556 DEV : loss 0.2590786814689636 - score 0.9441
2021-07-18 11:57:00,594 BAD EPOCHS (no improvement): 2
2021-07-18 11:57:00,595 ----------------------------------------------------------------------------------------------------
2021-07-18 11:57:03,258 epoch 21 - iter 6/60 - loss 0.13357774 - samples/sec: 72.11 - lr: 0.000030
2021-07-18 11:57:05,937 epoch 21 - iter 12/60 - loss 0.16361627 - samples/sec: 71.69 - lr: 0.000030
2021-07-18 11:57:08,581 epoch 21 - iter 18/60 - loss 0.17557260 - samples/sec: 72.64 - lr: 0.000030
2021-07-18 11:57:11,269 epoch 21 - iter 24/60 - loss 0.18034720 - samples/sec: 71.43 - lr: 0.000030
2021-07-18 11:57:13,926 epoch 21 - iter 30/60 - loss 0.18079681 - samples/sec: 72.30 - lr: 0.000030
2021-07-18 11:57:16,613 epoch 21 - iter 36/60 - loss 0.17922708 - samples/sec: 71.47 - lr: 0.000030
2021-07-18 11:57:19,299 epoch 21 - iter 42/60 - loss 0.17732978 - samples/sec: 71.48 - lr: 0.000030
2021-07-18 11:57:22,020 epoch 21 - iter 48/60 - loss 0.17972563 - samples/sec: 70.58 - lr: 0.000030
2021-07-18 11:57:24,745 epoch 21 - iter 54/60 - loss 0.17968301 - samples/sec: 70.48 - lr: 0.000030
2021-07-18 11:57:27,136 epoch 21 - iter 60/60 - loss 0.17705775 - samples/sec: 80.31 - lr: 0.000030
2021-07-18 11:57:27,137 ----------------------------------------------------------------------------------------------------
2021-07-18 11:57:27,137 EPOCH 21 done: loss 0.1771 - lr 0.0000300
2021-07-18 11:57:29,778 DEV : loss 0.26676830649375916 - score 0.9448
2021-07-18 11:57:29,817 BAD EPOCHS (no improvement): 3
2021-07-18 11:57:29,817 ----------------------------------------------------------------------------------------------------
2021-07-18 11:57:32,716 epoch 22 - iter 6/60 - loss 0.13103778 - samples/sec: 66.25 - lr: 0.000030
2021-07-18 11:57:35,442 epoch 22 - iter 12/60 - loss 0.18163852 - samples/sec: 70.43 - lr: 0.000030
2021-07-18 11:57:38,164 epoch 22 - iter 18/60 - loss 0.16604986 - samples/sec: 70.57 - lr: 0.000030
2021-07-18 11:57:40,884 epoch 22 - iter 24/60 - loss 0.17112795 - samples/sec: 70.60 - lr: 0.000030
2021-07-18 11:57:43,596 epoch 22 - iter 30/60 - loss 0.17316091 - samples/sec: 70.80 - lr: 0.000030
2021-07-18 11:57:46,325 epoch 22 - iter 36/60 - loss 0.18438463 - samples/sec: 70.38 - lr: 0.000030
2021-07-18 11:57:49,052 epoch 22 - iter 42/60 - loss 0.18224089 - samples/sec: 70.43 - lr: 0.000030
2021-07-18 11:57:51,764 epoch 22 - iter 48/60 - loss 0.18018985 - samples/sec: 70.81 - lr: 0.000030
2021-07-18 11:57:54,467 epoch 22 - iter 54/60 - loss 0.17836173 - samples/sec: 71.04 - lr: 0.000030
2021-07-18 11:57:56,842 epoch 22 - iter 60/60 - loss 0.18004242 - samples/sec: 80.88 - lr: 0.000030
2021-07-18 11:57:56,842 ----------------------------------------------------------------------------------------------------
2021-07-18 11:57:56,842 EPOCH 22 done: loss 0.1800 - lr 0.0000300
2021-07-18 11:57:59,480 DEV : loss 0.24888740479946136 - score 0.9504
2021-07-18 11:57:59,519 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:58:03,103 ----------------------------------------------------------------------------------------------------
2021-07-18 11:58:05,813 epoch 23 - iter 6/60 - loss 0.18966270 - samples/sec: 70.90 - lr: 0.000030
2021-07-18 11:58:08,547 epoch 23 - iter 12/60 - loss 0.17091852 - samples/sec: 70.23 - lr: 0.000030
2021-07-18 11:58:11,259 epoch 23 - iter 18/60 - loss 0.18380659 - samples/sec: 70.81 - lr: 0.000030
2021-07-18 11:58:13,979 epoch 23 - iter 24/60 - loss 0.17275592 - samples/sec: 70.62 - lr: 0.000030
2021-07-18 11:58:16,706 epoch 23 - iter 30/60 - loss 0.17048288 - samples/sec: 70.42 - lr: 0.000030
2021-07-18 11:58:19,419 epoch 23 - iter 36/60 - loss 0.17167566 - samples/sec: 70.81 - lr: 0.000030
2021-07-18 11:58:22,128 epoch 23 - iter 42/60 - loss 0.17376077 - samples/sec: 70.89 - lr: 0.000030
2021-07-18 11:58:24,855 epoch 23 - iter 48/60 - loss 0.17083372 - samples/sec: 70.42 - lr: 0.000030
2021-07-18 11:58:27,571 epoch 23 - iter 54/60 - loss 0.17016842 - samples/sec: 70.71 - lr: 0.000030
2021-07-18 11:58:29,962 epoch 23 - iter 60/60 - loss 0.17421638 - samples/sec: 80.32 - lr: 0.000030
2021-07-18 11:58:29,962 ----------------------------------------------------------------------------------------------------
2021-07-18 11:58:29,962 EPOCH 23 done: loss 0.1742 - lr 0.0000300
2021-07-18 11:58:32,606 DEV : loss 0.24503029882907867 - score 0.9464
2021-07-18 11:58:32,645 BAD EPOCHS (no improvement): 1
2021-07-18 11:58:32,645 ----------------------------------------------------------------------------------------------------
2021-07-18 11:58:35,371 epoch 24 - iter 6/60 - loss 0.18631501 - samples/sec: 70.47 - lr: 0.000030
2021-07-18 11:58:38,083 epoch 24 - iter 12/60 - loss 0.19603142 - samples/sec: 70.81 - lr: 0.000030
2021-07-18 11:58:40,836 epoch 24 - iter 18/60 - loss 0.19679997 - samples/sec: 69.77 - lr: 0.000030
2021-07-18 11:58:43,535 epoch 24 - iter 24/60 - loss 0.20002824 - samples/sec: 71.15 - lr: 0.000030
2021-07-18 11:58:46,255 epoch 24 - iter 30/60 - loss 0.18944772 - samples/sec: 70.59 - lr: 0.000030
2021-07-18 11:58:48,980 epoch 24 - iter 36/60 - loss 0.18721970 - samples/sec: 70.49 - lr: 0.000030
2021-07-18 11:58:51,679 epoch 24 - iter 42/60 - loss 0.17637362 - samples/sec: 71.15 - lr: 0.000030
2021-07-18 11:58:54,400 epoch 24 - iter 48/60 - loss 0.17055707 - samples/sec: 70.56 - lr: 0.000030
2021-07-18 11:58:57,131 epoch 24 - iter 54/60 - loss 0.17399891 - samples/sec: 70.34 - lr: 0.000030
2021-07-18 11:58:59,497 epoch 24 - iter 60/60 - loss 0.16620911 - samples/sec: 81.15 - lr: 0.000030
2021-07-18 11:58:59,497 ----------------------------------------------------------------------------------------------------
2021-07-18 11:58:59,497 EPOCH 24 done: loss 0.1662 - lr 0.0000300
2021-07-18 11:59:02,138 DEV : loss 0.2471165955066681 - score 0.9476
2021-07-18 11:59:02,177 BAD EPOCHS (no improvement): 2
2021-07-18 11:59:02,177 ----------------------------------------------------------------------------------------------------
2021-07-18 11:59:04,900 epoch 25 - iter 6/60 - loss 0.17674708 - samples/sec: 70.53 - lr: 0.000030
2021-07-18 11:59:07,610 epoch 25 - iter 12/60 - loss 0.13328254 - samples/sec: 70.86 - lr: 0.000030
2021-07-18 11:59:10,520 epoch 25 - iter 18/60 - loss 0.12786882 - samples/sec: 66.00 - lr: 0.000030
2021-07-18 11:59:13,192 epoch 25 - iter 24/60 - loss 0.12601137 - samples/sec: 71.88 - lr: 0.000030
2021-07-18 11:59:15,915 epoch 25 - iter 30/60 - loss 0.12745511 - samples/sec: 70.53 - lr: 0.000030
2021-07-18 11:59:18,631 epoch 25 - iter 36/60 - loss 0.13687935 - samples/sec: 70.69 - lr: 0.000030
2021-07-18 11:59:21,352 epoch 25 - iter 42/60 - loss 0.13579485 - samples/sec: 70.59 - lr: 0.000030
2021-07-18 11:59:24,092 epoch 25 - iter 48/60 - loss 0.13399006 - samples/sec: 70.09 - lr: 0.000030
2021-07-18 11:59:26,832 epoch 25 - iter 54/60 - loss 0.12880820 - samples/sec: 70.08 - lr: 0.000030
2021-07-18 11:59:29,236 epoch 25 - iter 60/60 - loss 0.13199141 - samples/sec: 79.91 - lr: 0.000030
2021-07-18 11:59:29,236 ----------------------------------------------------------------------------------------------------
2021-07-18 11:59:29,236 EPOCH 25 done: loss 0.1320 - lr 0.0000300
2021-07-18 11:59:31,880 DEV : loss 0.23500743508338928 - score 0.951
2021-07-18 11:59:31,919 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 11:59:35,476 ----------------------------------------------------------------------------------------------------
2021-07-18 11:59:38,168 epoch 26 - iter 6/60 - loss 0.21650238 - samples/sec: 71.36 - lr: 0.000030
2021-07-18 11:59:40,903 epoch 26 - iter 12/60 - loss 0.17924076 - samples/sec: 70.20 - lr: 0.000030
2021-07-18 11:59:43,635 epoch 26 - iter 18/60 - loss 0.18658920 - samples/sec: 70.30 - lr: 0.000030
2021-07-18 11:59:46,382 epoch 26 - iter 24/60 - loss 0.18704141 - samples/sec: 69.91 - lr: 0.000030
2021-07-18 11:59:49,092 epoch 26 - iter 30/60 - loss 0.18395715 - samples/sec: 70.87 - lr: 0.000030
2021-07-18 11:59:51,803 epoch 26 - iter 36/60 - loss 0.18520309 - samples/sec: 70.86 - lr: 0.000030
2021-07-18 11:59:54,534 epoch 26 - iter 42/60 - loss 0.17514201 - samples/sec: 70.30 - lr: 0.000030
2021-07-18 11:59:57,241 epoch 26 - iter 48/60 - loss 0.16941896 - samples/sec: 70.96 - lr: 0.000030
2021-07-18 11:59:59,957 epoch 26 - iter 54/60 - loss 0.16438668 - samples/sec: 70.71 - lr: 0.000030
2021-07-18 12:00:02,324 epoch 26 - iter 60/60 - loss 0.15951577 - samples/sec: 81.11 - lr: 0.000030
2021-07-18 12:00:02,325 ----------------------------------------------------------------------------------------------------
2021-07-18 12:00:02,325 EPOCH 26 done: loss 0.1595 - lr 0.0000300
2021-07-18 12:00:04,961 DEV : loss 0.24829959869384766 - score 0.9504
2021-07-18 12:00:04,999 BAD EPOCHS (no improvement): 1
2021-07-18 12:00:05,000 ----------------------------------------------------------------------------------------------------
2021-07-18 12:00:07,711 epoch 27 - iter 6/60 - loss 0.17435280 - samples/sec: 70.83 - lr: 0.000030
2021-07-18 12:00:10,416 epoch 27 - iter 12/60 - loss 0.15136282 - samples/sec: 71.00 - lr: 0.000030
2021-07-18 12:00:13,160 epoch 27 - iter 18/60 - loss 0.14634358 - samples/sec: 70.00 - lr: 0.000030
2021-07-18 12:00:15,890 epoch 27 - iter 24/60 - loss 0.13679783 - samples/sec: 70.32 - lr: 0.000030
2021-07-18 12:00:18,627 epoch 27 - iter 30/60 - loss 0.14352210 - samples/sec: 70.18 - lr: 0.000030
2021-07-18 12:00:21,339 epoch 27 - iter 36/60 - loss 0.14439695 - samples/sec: 70.79 - lr: 0.000030
2021-07-18 12:00:24,052 epoch 27 - iter 42/60 - loss 0.13978799 - samples/sec: 70.81 - lr: 0.000030
2021-07-18 12:00:26,763 epoch 27 - iter 48/60 - loss 0.13859622 - samples/sec: 70.84 - lr: 0.000030
2021-07-18 12:00:29,472 epoch 27 - iter 54/60 - loss 0.14088511 - samples/sec: 70.89 - lr: 0.000030
2021-07-18 12:00:31,860 epoch 27 - iter 60/60 - loss 0.13791953 - samples/sec: 80.41 - lr: 0.000030
2021-07-18 12:00:31,860 ----------------------------------------------------------------------------------------------------
2021-07-18 12:00:31,860 EPOCH 27 done: loss 0.1379 - lr 0.0000300
2021-07-18 12:00:34,500 DEV : loss 0.25510814785957336 - score 0.948
2021-07-18 12:00:34,539 BAD EPOCHS (no improvement): 2
2021-07-18 12:00:34,539 ----------------------------------------------------------------------------------------------------
2021-07-18 12:00:37,250 epoch 28 - iter 6/60 - loss 0.19566644 - samples/sec: 70.83 - lr: 0.000030
2021-07-18 12:00:39,975 epoch 28 - iter 12/60 - loss 0.15812538 - samples/sec: 70.48 - lr: 0.000030
2021-07-18 12:00:42,919 epoch 28 - iter 18/60 - loss 0.14643800 - samples/sec: 65.23 - lr: 0.000030
2021-07-18 12:00:45,652 epoch 28 - iter 24/60 - loss 0.15018043 - samples/sec: 70.27 - lr: 0.000030
2021-07-18 12:00:48,369 epoch 28 - iter 30/60 - loss 0.13495552 - samples/sec: 70.70 - lr: 0.000030
2021-07-18 12:00:51,081 epoch 28 - iter 36/60 - loss 0.12802747 - samples/sec: 70.81 - lr: 0.000030
2021-07-18 12:00:53,822 epoch 28 - iter 42/60 - loss 0.12808275 - samples/sec: 70.05 - lr: 0.000030
2021-07-18 12:00:56,531 epoch 28 - iter 48/60 - loss 0.13232612 - samples/sec: 70.89 - lr: 0.000030
2021-07-18 12:00:59,240 epoch 28 - iter 54/60 - loss 0.13227557 - samples/sec: 70.91 - lr: 0.000030
2021-07-18 12:01:01,616 epoch 28 - iter 60/60 - loss 0.13724554 - samples/sec: 80.82 - lr: 0.000030
2021-07-18 12:01:01,616 ----------------------------------------------------------------------------------------------------
2021-07-18 12:01:01,616 EPOCH 28 done: loss 0.1372 - lr 0.0000300
2021-07-18 12:01:04,260 DEV : loss 0.25007614493370056 - score 0.9453
2021-07-18 12:01:04,299 BAD EPOCHS (no improvement): 3
2021-07-18 12:01:04,299 ----------------------------------------------------------------------------------------------------
2021-07-18 12:01:06,994 epoch 29 - iter 6/60 - loss 0.11693443 - samples/sec: 71.26 - lr: 0.000030
2021-07-18 12:01:09,690 epoch 29 - iter 12/60 - loss 0.13637643 - samples/sec: 71.23 - lr: 0.000030
2021-07-18 12:01:12,412 epoch 29 - iter 18/60 - loss 0.11943123 - samples/sec: 70.55 - lr: 0.000030
2021-07-18 12:01:15,132 epoch 29 - iter 24/60 - loss 0.12074317 - samples/sec: 70.63 - lr: 0.000030
2021-07-18 12:01:17,862 epoch 29 - iter 30/60 - loss 0.13074322 - samples/sec: 70.33 - lr: 0.000030
2021-07-18 12:01:20,569 epoch 29 - iter 36/60 - loss 0.12580706 - samples/sec: 70.96 - lr: 0.000030
2021-07-18 12:01:23,284 epoch 29 - iter 42/60 - loss 0.13456645 - samples/sec: 70.72 - lr: 0.000030
2021-07-18 12:01:26,011 epoch 29 - iter 48/60 - loss 0.13422385 - samples/sec: 70.43 - lr: 0.000030
2021-07-18 12:01:28,740 epoch 29 - iter 54/60 - loss 0.12930098 - samples/sec: 70.39 - lr: 0.000030
2021-07-18 12:01:31,132 epoch 29 - iter 60/60 - loss 0.14692265 - samples/sec: 80.29 - lr: 0.000030
2021-07-18 12:01:31,132 ----------------------------------------------------------------------------------------------------
2021-07-18 12:01:31,132 EPOCH 29 done: loss 0.1469 - lr 0.0000300
2021-07-18 12:01:33,767 DEV : loss 0.24077129364013672 - score 0.9514
2021-07-18 12:01:33,806 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:01:37,341 ----------------------------------------------------------------------------------------------------
2021-07-18 12:01:40,016 epoch 30 - iter 6/60 - loss 0.10869493 - samples/sec: 71.80 - lr: 0.000030
2021-07-18 12:01:42,760 epoch 30 - iter 12/60 - loss 0.12911548 - samples/sec: 70.00 - lr: 0.000030
2021-07-18 12:01:45,483 epoch 30 - iter 18/60 - loss 0.12722615 - samples/sec: 70.51 - lr: 0.000030
2021-07-18 12:01:48,180 epoch 30 - iter 24/60 - loss 0.12926759 - samples/sec: 71.21 - lr: 0.000030
2021-07-18 12:01:50,927 epoch 30 - iter 30/60 - loss 0.13527642 - samples/sec: 69.91 - lr: 0.000030
2021-07-18 12:01:53,645 epoch 30 - iter 36/60 - loss 0.13927139 - samples/sec: 70.67 - lr: 0.000030
2021-07-18 12:01:56,349 epoch 30 - iter 42/60 - loss 0.13708189 - samples/sec: 71.02 - lr: 0.000030
2021-07-18 12:01:59,057 epoch 30 - iter 48/60 - loss 0.13555569 - samples/sec: 70.93 - lr: 0.000030
2021-07-18 12:02:01,793 epoch 30 - iter 54/60 - loss 0.13113803 - samples/sec: 70.17 - lr: 0.000030
2021-07-18 12:02:04,191 epoch 30 - iter 60/60 - loss 0.12857619 - samples/sec: 80.10 - lr: 0.000030
2021-07-18 12:02:04,191 ----------------------------------------------------------------------------------------------------
2021-07-18 12:02:04,191 EPOCH 30 done: loss 0.1286 - lr 0.0000300
2021-07-18 12:02:06,830 DEV : loss 0.23294250667095184 - score 0.9541
2021-07-18 12:02:06,869 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:02:10,515 ----------------------------------------------------------------------------------------------------
2021-07-18 12:02:13,224 epoch 31 - iter 6/60 - loss 0.07695482 - samples/sec: 70.92 - lr: 0.000030
2021-07-18 12:02:15,941 epoch 31 - iter 12/60 - loss 0.13586110 - samples/sec: 70.69 - lr: 0.000030
2021-07-18 12:02:18,670 epoch 31 - iter 18/60 - loss 0.12865138 - samples/sec: 70.36 - lr: 0.000030
2021-07-18 12:02:21,393 epoch 31 - iter 24/60 - loss 0.12593801 - samples/sec: 70.52 - lr: 0.000030
2021-07-18 12:02:24,317 epoch 31 - iter 30/60 - loss 0.11808640 - samples/sec: 65.69 - lr: 0.000030
2021-07-18 12:02:27,071 epoch 31 - iter 36/60 - loss 0.11876641 - samples/sec: 69.73 - lr: 0.000030
2021-07-18 12:02:29,784 epoch 31 - iter 42/60 - loss 0.12206865 - samples/sec: 70.78 - lr: 0.000030
2021-07-18 12:02:32,507 epoch 31 - iter 48/60 - loss 0.11981706 - samples/sec: 70.53 - lr: 0.000030
2021-07-18 12:02:35,208 epoch 31 - iter 54/60 - loss 0.12079761 - samples/sec: 71.11 - lr: 0.000030
2021-07-18 12:02:37,571 epoch 31 - iter 60/60 - loss 0.12233424 - samples/sec: 81.27 - lr: 0.000030
2021-07-18 12:02:37,571 ----------------------------------------------------------------------------------------------------
2021-07-18 12:02:37,571 EPOCH 31 done: loss 0.1223 - lr 0.0000300
2021-07-18 12:02:40,206 DEV : loss 0.24535948038101196 - score 0.9501
2021-07-18 12:02:40,245 BAD EPOCHS (no improvement): 1
2021-07-18 12:02:40,246 ----------------------------------------------------------------------------------------------------
2021-07-18 12:02:42,956 epoch 32 - iter 6/60 - loss 0.14284925 - samples/sec: 70.86 - lr: 0.000030
2021-07-18 12:02:45,650 epoch 32 - iter 12/60 - loss 0.11121692 - samples/sec: 71.28 - lr: 0.000030
2021-07-18 12:02:48,337 epoch 32 - iter 18/60 - loss 0.12103774 - samples/sec: 71.47 - lr: 0.000030
2021-07-18 12:02:51,055 epoch 32 - iter 24/60 - loss 0.12201409 - samples/sec: 70.68 - lr: 0.000030
2021-07-18 12:02:53,767 epoch 32 - iter 30/60 - loss 0.11626214 - samples/sec: 70.80 - lr: 0.000030
2021-07-18 12:02:56,472 epoch 32 - iter 36/60 - loss 0.12598304 - samples/sec: 71.00 - lr: 0.000030
2021-07-18 12:02:59,211 epoch 32 - iter 42/60 - loss 0.12720244 - samples/sec: 70.10 - lr: 0.000030
2021-07-18 12:03:01,934 epoch 32 - iter 48/60 - loss 0.12434801 - samples/sec: 70.55 - lr: 0.000030
2021-07-18 12:03:04,671 epoch 32 - iter 54/60 - loss 0.12142363 - samples/sec: 70.15 - lr: 0.000030
2021-07-18 12:03:07,060 epoch 32 - iter 60/60 - loss 0.12212605 - samples/sec: 80.41 - lr: 0.000030
2021-07-18 12:03:07,060 ----------------------------------------------------------------------------------------------------
2021-07-18 12:03:07,060 EPOCH 32 done: loss 0.1221 - lr 0.0000300
2021-07-18 12:03:09,696 DEV : loss 0.24798640608787537 - score 0.9527
2021-07-18 12:03:09,735 BAD EPOCHS (no improvement): 2
2021-07-18 12:03:09,735 ----------------------------------------------------------------------------------------------------
2021-07-18 12:03:12,428 epoch 33 - iter 6/60 - loss 0.09908975 - samples/sec: 71.33 - lr: 0.000030
2021-07-18 12:03:15,168 epoch 33 - iter 12/60 - loss 0.11580135 - samples/sec: 70.07 - lr: 0.000030
2021-07-18 12:03:17,896 epoch 33 - iter 18/60 - loss 0.10216336 - samples/sec: 70.40 - lr: 0.000030
2021-07-18 12:03:20,593 epoch 33 - iter 24/60 - loss 0.10898641 - samples/sec: 71.22 - lr: 0.000030
2021-07-18 12:03:23,300 epoch 33 - iter 30/60 - loss 0.11004638 - samples/sec: 70.94 - lr: 0.000030
2021-07-18 12:03:26,036 epoch 33 - iter 36/60 - loss 0.11236391 - samples/sec: 70.19 - lr: 0.000030
2021-07-18 12:03:28,751 epoch 33 - iter 42/60 - loss 0.11973930 - samples/sec: 70.72 - lr: 0.000030
2021-07-18 12:03:31,473 epoch 33 - iter 48/60 - loss 0.11975768 - samples/sec: 70.57 - lr: 0.000030
2021-07-18 12:03:34,176 epoch 33 - iter 54/60 - loss 0.11888163 - samples/sec: 71.04 - lr: 0.000030
2021-07-18 12:03:36,560 epoch 33 - iter 60/60 - loss 0.11960444 - samples/sec: 80.56 - lr: 0.000030
2021-07-18 12:03:36,560 ----------------------------------------------------------------------------------------------------
2021-07-18 12:03:36,561 EPOCH 33 done: loss 0.1196 - lr 0.0000300
2021-07-18 12:03:39,200 DEV : loss 0.2346753180027008 - score 0.9526
2021-07-18 12:03:39,239 BAD EPOCHS (no improvement): 3
2021-07-18 12:03:39,240 ----------------------------------------------------------------------------------------------------
2021-07-18 12:03:41,963 epoch 34 - iter 6/60 - loss 0.12636904 - samples/sec: 70.51 - lr: 0.000030
2021-07-18 12:03:44,715 epoch 34 - iter 12/60 - loss 0.10238701 - samples/sec: 69.80 - lr: 0.000030
2021-07-18 12:03:47,414 epoch 34 - iter 18/60 - loss 0.10727430 - samples/sec: 71.14 - lr: 0.000030
2021-07-18 12:03:50,148 epoch 34 - iter 24/60 - loss 0.10712505 - samples/sec: 70.26 - lr: 0.000030
2021-07-18 12:03:52,875 epoch 34 - iter 30/60 - loss 0.10022413 - samples/sec: 70.42 - lr: 0.000030
2021-07-18 12:03:55,576 epoch 34 - iter 36/60 - loss 0.10957630 - samples/sec: 71.08 - lr: 0.000030
2021-07-18 12:03:58,304 epoch 34 - iter 42/60 - loss 0.11282337 - samples/sec: 70.40 - lr: 0.000030
2021-07-18 12:04:01,012 epoch 34 - iter 48/60 - loss 0.11354983 - samples/sec: 70.92 - lr: 0.000030
2021-07-18 12:04:03,887 epoch 34 - iter 54/60 - loss 0.11013182 - samples/sec: 66.80 - lr: 0.000030
2021-07-18 12:04:06,260 epoch 34 - iter 60/60 - loss 0.10617301 - samples/sec: 80.91 - lr: 0.000030
2021-07-18 12:04:06,261 ----------------------------------------------------------------------------------------------------
2021-07-18 12:04:06,261 EPOCH 34 done: loss 0.1062 - lr 0.0000300
2021-07-18 12:04:08,901 DEV : loss 0.25213563442230225 - score 0.9488
Epoch    34: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 12:04:08,940 BAD EPOCHS (no improvement): 4
2021-07-18 12:04:08,940 ----------------------------------------------------------------------------------------------------
2021-07-18 12:04:11,636 epoch 35 - iter 6/60 - loss 0.11265804 - samples/sec: 71.24 - lr: 0.000015
2021-07-18 12:04:14,360 epoch 35 - iter 12/60 - loss 0.11127155 - samples/sec: 70.51 - lr: 0.000015
2021-07-18 12:04:17,067 epoch 35 - iter 18/60 - loss 0.12574541 - samples/sec: 70.94 - lr: 0.000015
2021-07-18 12:04:19,801 epoch 35 - iter 24/60 - loss 0.11842018 - samples/sec: 70.25 - lr: 0.000015
2021-07-18 12:04:22,512 epoch 35 - iter 30/60 - loss 0.11930217 - samples/sec: 70.84 - lr: 0.000015
2021-07-18 12:04:25,244 epoch 35 - iter 36/60 - loss 0.11340283 - samples/sec: 70.29 - lr: 0.000015
2021-07-18 12:04:27,960 epoch 35 - iter 42/60 - loss 0.11197532 - samples/sec: 70.71 - lr: 0.000015
2021-07-18 12:04:30,688 epoch 35 - iter 48/60 - loss 0.11011622 - samples/sec: 70.40 - lr: 0.000015
2021-07-18 12:04:33,396 epoch 35 - iter 54/60 - loss 0.11476263 - samples/sec: 70.91 - lr: 0.000015
2021-07-18 12:04:35,762 epoch 35 - iter 60/60 - loss 0.11067441 - samples/sec: 81.17 - lr: 0.000015
2021-07-18 12:04:35,762 ----------------------------------------------------------------------------------------------------
2021-07-18 12:04:35,762 EPOCH 35 done: loss 0.1107 - lr 0.0000150
2021-07-18 12:04:38,402 DEV : loss 0.2516822814941406 - score 0.9495
2021-07-18 12:04:38,441 BAD EPOCHS (no improvement): 1
2021-07-18 12:04:38,441 ----------------------------------------------------------------------------------------------------
2021-07-18 12:04:41,149 epoch 36 - iter 6/60 - loss 0.08243296 - samples/sec: 70.94 - lr: 0.000015
2021-07-18 12:04:43,867 epoch 36 - iter 12/60 - loss 0.09157539 - samples/sec: 70.65 - lr: 0.000015
2021-07-18 12:04:46,579 epoch 36 - iter 18/60 - loss 0.08087190 - samples/sec: 70.82 - lr: 0.000015
2021-07-18 12:04:49,295 epoch 36 - iter 24/60 - loss 0.09353129 - samples/sec: 70.70 - lr: 0.000015
2021-07-18 12:04:52,009 epoch 36 - iter 30/60 - loss 0.09442740 - samples/sec: 70.77 - lr: 0.000015
2021-07-18 12:04:54,739 epoch 36 - iter 36/60 - loss 0.09230452 - samples/sec: 70.33 - lr: 0.000015
2021-07-18 12:04:57,438 epoch 36 - iter 42/60 - loss 0.09572408 - samples/sec: 71.16 - lr: 0.000015
2021-07-18 12:05:00,161 epoch 36 - iter 48/60 - loss 0.09893157 - samples/sec: 70.54 - lr: 0.000015
2021-07-18 12:05:02,893 epoch 36 - iter 54/60 - loss 0.10002502 - samples/sec: 70.29 - lr: 0.000015
2021-07-18 12:05:05,288 epoch 36 - iter 60/60 - loss 0.10213509 - samples/sec: 80.17 - lr: 0.000015
2021-07-18 12:05:05,288 ----------------------------------------------------------------------------------------------------
2021-07-18 12:05:05,288 EPOCH 36 done: loss 0.1021 - lr 0.0000150
2021-07-18 12:05:07,927 DEV : loss 0.2410396933555603 - score 0.9494
2021-07-18 12:05:07,966 BAD EPOCHS (no improvement): 2
2021-07-18 12:05:07,967 ----------------------------------------------------------------------------------------------------
2021-07-18 12:05:10,671 epoch 37 - iter 6/60 - loss 0.11357498 - samples/sec: 71.02 - lr: 0.000015
2021-07-18 12:05:13,383 epoch 37 - iter 12/60 - loss 0.10684549 - samples/sec: 70.82 - lr: 0.000015
2021-07-18 12:05:16,120 epoch 37 - iter 18/60 - loss 0.09626245 - samples/sec: 70.16 - lr: 0.000015
2021-07-18 12:05:18,819 epoch 37 - iter 24/60 - loss 0.09720123 - samples/sec: 71.15 - lr: 0.000015
2021-07-18 12:05:21,552 epoch 37 - iter 30/60 - loss 0.09014868 - samples/sec: 70.27 - lr: 0.000015
2021-07-18 12:05:24,283 epoch 37 - iter 36/60 - loss 0.09051047 - samples/sec: 70.32 - lr: 0.000015
2021-07-18 12:05:26,993 epoch 37 - iter 42/60 - loss 0.08640954 - samples/sec: 70.88 - lr: 0.000015
2021-07-18 12:05:29,713 epoch 37 - iter 48/60 - loss 0.09072844 - samples/sec: 70.61 - lr: 0.000015
2021-07-18 12:05:32,405 epoch 37 - iter 54/60 - loss 0.08919552 - samples/sec: 71.32 - lr: 0.000015
2021-07-18 12:05:34,813 epoch 37 - iter 60/60 - loss 0.09501109 - samples/sec: 79.78 - lr: 0.000015
2021-07-18 12:05:34,813 ----------------------------------------------------------------------------------------------------
2021-07-18 12:05:34,813 EPOCH 37 done: loss 0.0950 - lr 0.0000150
2021-07-18 12:05:37,654 DEV : loss 0.253850519657135 - score 0.9515
2021-07-18 12:05:37,693 BAD EPOCHS (no improvement): 3
2021-07-18 12:05:37,693 ----------------------------------------------------------------------------------------------------
2021-07-18 12:05:40,405 epoch 38 - iter 6/60 - loss 0.10217250 - samples/sec: 70.84 - lr: 0.000015
2021-07-18 12:05:43,132 epoch 38 - iter 12/60 - loss 0.12718571 - samples/sec: 70.43 - lr: 0.000015
2021-07-18 12:05:45,857 epoch 38 - iter 18/60 - loss 0.11722564 - samples/sec: 70.48 - lr: 0.000015
2021-07-18 12:05:48,580 epoch 38 - iter 24/60 - loss 0.12056973 - samples/sec: 70.51 - lr: 0.000015
2021-07-18 12:05:51,281 epoch 38 - iter 30/60 - loss 0.11014552 - samples/sec: 71.11 - lr: 0.000015
2021-07-18 12:05:54,020 epoch 38 - iter 36/60 - loss 0.10404883 - samples/sec: 70.13 - lr: 0.000015
2021-07-18 12:05:56,749 epoch 38 - iter 42/60 - loss 0.09973501 - samples/sec: 70.37 - lr: 0.000015
2021-07-18 12:05:59,441 epoch 38 - iter 48/60 - loss 0.10168985 - samples/sec: 71.34 - lr: 0.000015
2021-07-18 12:06:02,123 epoch 38 - iter 54/60 - loss 0.11002475 - samples/sec: 71.58 - lr: 0.000015
2021-07-18 12:06:04,518 epoch 38 - iter 60/60 - loss 0.10688958 - samples/sec: 80.22 - lr: 0.000015
2021-07-18 12:06:04,518 ----------------------------------------------------------------------------------------------------
2021-07-18 12:06:04,518 EPOCH 38 done: loss 0.1069 - lr 0.0000150
2021-07-18 12:06:07,160 DEV : loss 0.23811794817447662 - score 0.9516
Epoch    38: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 12:06:07,199 BAD EPOCHS (no improvement): 4
2021-07-18 12:06:07,199 ----------------------------------------------------------------------------------------------------
2021-07-18 12:06:09,908 epoch 39 - iter 6/60 - loss 0.10461565 - samples/sec: 70.90 - lr: 0.000008
2021-07-18 12:06:12,602 epoch 39 - iter 12/60 - loss 0.10199979 - samples/sec: 71.28 - lr: 0.000008
2021-07-18 12:06:15,348 epoch 39 - iter 18/60 - loss 0.09347199 - samples/sec: 69.93 - lr: 0.000008
2021-07-18 12:06:18,055 epoch 39 - iter 24/60 - loss 0.09069173 - samples/sec: 70.95 - lr: 0.000008
2021-07-18 12:06:20,802 epoch 39 - iter 30/60 - loss 0.08998670 - samples/sec: 69.91 - lr: 0.000008
2021-07-18 12:06:23,541 epoch 39 - iter 36/60 - loss 0.08680027 - samples/sec: 70.11 - lr: 0.000008
2021-07-18 12:06:26,259 epoch 39 - iter 42/60 - loss 0.08640007 - samples/sec: 70.65 - lr: 0.000008
2021-07-18 12:06:28,959 epoch 39 - iter 48/60 - loss 0.08363797 - samples/sec: 71.13 - lr: 0.000008
2021-07-18 12:06:31,677 epoch 39 - iter 54/60 - loss 0.08274264 - samples/sec: 70.66 - lr: 0.000008
2021-07-18 12:06:34,059 epoch 39 - iter 60/60 - loss 0.08577304 - samples/sec: 80.62 - lr: 0.000008
2021-07-18 12:06:34,060 ----------------------------------------------------------------------------------------------------
2021-07-18 12:06:34,060 EPOCH 39 done: loss 0.0858 - lr 0.0000075
2021-07-18 12:06:36,700 DEV : loss 0.24044224619865417 - score 0.9504
2021-07-18 12:06:36,739 BAD EPOCHS (no improvement): 1
2021-07-18 12:06:36,739 ----------------------------------------------------------------------------------------------------
2021-07-18 12:06:39,453 epoch 40 - iter 6/60 - loss 0.10020101 - samples/sec: 70.77 - lr: 0.000008
2021-07-18 12:06:42,153 epoch 40 - iter 12/60 - loss 0.09292554 - samples/sec: 71.12 - lr: 0.000008
2021-07-18 12:06:44,855 epoch 40 - iter 18/60 - loss 0.09241003 - samples/sec: 71.08 - lr: 0.000008
2021-07-18 12:06:47,576 epoch 40 - iter 24/60 - loss 0.09110958 - samples/sec: 70.59 - lr: 0.000008
2021-07-18 12:06:50,311 epoch 40 - iter 30/60 - loss 0.09263383 - samples/sec: 70.21 - lr: 0.000008
2021-07-18 12:06:53,025 epoch 40 - iter 36/60 - loss 0.10478404 - samples/sec: 70.77 - lr: 0.000008
2021-07-18 12:06:55,749 epoch 40 - iter 42/60 - loss 0.09921976 - samples/sec: 70.50 - lr: 0.000008
2021-07-18 12:06:58,473 epoch 40 - iter 48/60 - loss 0.09693064 - samples/sec: 70.48 - lr: 0.000008
2021-07-18 12:07:01,193 epoch 40 - iter 54/60 - loss 0.09568229 - samples/sec: 70.61 - lr: 0.000008
2021-07-18 12:07:03,602 epoch 40 - iter 60/60 - loss 0.09553288 - samples/sec: 79.72 - lr: 0.000008
2021-07-18 12:07:03,602 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:03,603 EPOCH 40 done: loss 0.0955 - lr 0.0000075
2021-07-18 12:07:06,450 DEV : loss 0.2430220991373062 - score 0.9481
2021-07-18 12:07:06,490 BAD EPOCHS (no improvement): 2
2021-07-18 12:07:07,125 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:07,125 Testing using best model ...
2021-07-18 12:07:07,125 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.pdtb.cdtb/best-model.pt
2021-07-18 12:07:17,831 0.9852	0.9491	0.9668
2021-07-18 12:07:17,831 
Results:
- F1-score (micro) 0.9668
- F1-score (macro) 0.9668

By class:
SENT       tp: 466 - fp: 7 - fn: 25 - precision: 0.9852 - recall: 0.9491 - f1-score: 0.9668
2021-07-18 12:07:17,831 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.rststb/
2021-07-18 12:07:17,835 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.rststb
2021-07-18 12:07:17,835 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.rststb/sent_train.txt
2021-07-18 12:07:17,836 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.rststb/sent_dev.txt
2021-07-18 12:07:17,836 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.rststb/sent_test.txt
Corpus: 1702 train + 372 dev + 442 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 12:07:21,269 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:21,271 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 12:07:21,271 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:21,271 Corpus: "Corpus: 1702 train + 372 dev + 442 test sentences"
2021-07-18 12:07:21,271 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:21,271 Parameters:
2021-07-18 12:07:21,271  - learning_rate: "3e-05"
2021-07-18 12:07:21,271  - mini_batch_size: "32"
2021-07-18 12:07:21,271  - patience: "3"
2021-07-18 12:07:21,271  - anneal_factor: "0.5"
2021-07-18 12:07:21,271  - max_epochs: "40"
2021-07-18 12:07:21,271  - shuffle: "True"
2021-07-18 12:07:21,271  - train_with_dev: "False"
2021-07-18 12:07:21,272  - batch_growth_annealing: "False"
2021-07-18 12:07:21,272 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:21,272 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.rststb"
2021-07-18 12:07:21,272 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:21,272 Device: cuda:0
2021-07-18 12:07:21,272 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:21,272 Embeddings storage mode: cpu
2021-07-18 12:07:21,274 ----------------------------------------------------------------------------------------------------
2021-07-18 12:07:26,077 epoch 1 - iter 5/54 - loss 24.89938965 - samples/sec: 33.32 - lr: 0.000030
2021-07-18 12:07:30,855 epoch 1 - iter 10/54 - loss 19.37443314 - samples/sec: 33.49 - lr: 0.000030
2021-07-18 12:07:35,618 epoch 1 - iter 15/54 - loss 15.47806988 - samples/sec: 33.59 - lr: 0.000030
2021-07-18 12:07:40,369 epoch 1 - iter 20/54 - loss 12.88879676 - samples/sec: 33.68 - lr: 0.000030
2021-07-18 12:07:45,088 epoch 1 - iter 25/54 - loss 11.18497202 - samples/sec: 33.91 - lr: 0.000030
2021-07-18 12:07:50,003 epoch 1 - iter 30/54 - loss 9.90759571 - samples/sec: 32.56 - lr: 0.000030
2021-07-18 12:07:54,731 epoch 1 - iter 35/54 - loss 8.94685855 - samples/sec: 33.84 - lr: 0.000030
2021-07-18 12:07:59,522 epoch 1 - iter 40/54 - loss 8.21349919 - samples/sec: 33.40 - lr: 0.000030
2021-07-18 12:08:04,357 epoch 1 - iter 45/54 - loss 7.58487234 - samples/sec: 33.10 - lr: 0.000030
2021-07-18 12:08:09,170 epoch 1 - iter 50/54 - loss 7.06516497 - samples/sec: 33.24 - lr: 0.000030
2021-07-18 12:08:12,298 ----------------------------------------------------------------------------------------------------
2021-07-18 12:08:12,298 EPOCH 1 done: loss 6.7363 - lr 0.0000300
2021-07-18 12:08:18,846 DEV : loss 1.5567635297775269 - score 0.0305
2021-07-18 12:08:18,872 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:08:19,599 ----------------------------------------------------------------------------------------------------
2021-07-18 12:08:22,057 epoch 2 - iter 5/54 - loss 2.02553587 - samples/sec: 65.10 - lr: 0.000030
2021-07-18 12:08:24,560 epoch 2 - iter 10/54 - loss 1.85954276 - samples/sec: 63.93 - lr: 0.000030
2021-07-18 12:08:27,068 epoch 2 - iter 15/54 - loss 1.82325386 - samples/sec: 63.82 - lr: 0.000030
2021-07-18 12:08:29,564 epoch 2 - iter 20/54 - loss 1.75978703 - samples/sec: 64.12 - lr: 0.000030
2021-07-18 12:08:32,103 epoch 2 - iter 25/54 - loss 1.70693536 - samples/sec: 63.80 - lr: 0.000030
2021-07-18 12:08:34,596 epoch 2 - iter 30/54 - loss 1.64392467 - samples/sec: 64.20 - lr: 0.000030
2021-07-18 12:08:37,089 epoch 2 - iter 35/54 - loss 1.59506539 - samples/sec: 64.20 - lr: 0.000030
2021-07-18 12:08:39,561 epoch 2 - iter 40/54 - loss 1.53417486 - samples/sec: 64.72 - lr: 0.000030
2021-07-18 12:08:42,081 epoch 2 - iter 45/54 - loss 1.50653118 - samples/sec: 63.53 - lr: 0.000030
2021-07-18 12:08:44,589 epoch 2 - iter 50/54 - loss 1.44894245 - samples/sec: 63.81 - lr: 0.000030
2021-07-18 12:08:46,208 ----------------------------------------------------------------------------------------------------
2021-07-18 12:08:46,208 EPOCH 2 done: loss 1.4299 - lr 0.0000300
2021-07-18 12:08:48,369 DEV : loss 0.4305201768875122 - score 0.9049
2021-07-18 12:08:48,394 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:08:52,279 ----------------------------------------------------------------------------------------------------
2021-07-18 12:08:54,767 epoch 3 - iter 5/54 - loss 1.02418537 - samples/sec: 64.34 - lr: 0.000030
2021-07-18 12:08:57,183 epoch 3 - iter 10/54 - loss 0.89622422 - samples/sec: 66.25 - lr: 0.000030
2021-07-18 12:08:59,640 epoch 3 - iter 15/54 - loss 0.82193071 - samples/sec: 65.12 - lr: 0.000030
2021-07-18 12:09:02,130 epoch 3 - iter 20/54 - loss 0.82607867 - samples/sec: 64.28 - lr: 0.000030
2021-07-18 12:09:04,581 epoch 3 - iter 25/54 - loss 0.81036582 - samples/sec: 65.28 - lr: 0.000030
2021-07-18 12:09:07,064 epoch 3 - iter 30/54 - loss 0.78901699 - samples/sec: 64.45 - lr: 0.000030
2021-07-18 12:09:09,559 epoch 3 - iter 35/54 - loss 0.78487940 - samples/sec: 64.16 - lr: 0.000030
2021-07-18 12:09:12,022 epoch 3 - iter 40/54 - loss 0.78811720 - samples/sec: 64.96 - lr: 0.000030
2021-07-18 12:09:14,470 epoch 3 - iter 45/54 - loss 0.78294060 - samples/sec: 65.38 - lr: 0.000030
2021-07-18 12:09:16,911 epoch 3 - iter 50/54 - loss 0.77072014 - samples/sec: 65.56 - lr: 0.000030
2021-07-18 12:09:18,519 ----------------------------------------------------------------------------------------------------
2021-07-18 12:09:18,519 EPOCH 3 done: loss 0.7726 - lr 0.0000300
2021-07-18 12:09:20,496 DEV : loss 0.2864153981208801 - score 0.9311
2021-07-18 12:09:20,522 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:09:24,270 ----------------------------------------------------------------------------------------------------
2021-07-18 12:09:26,726 epoch 4 - iter 5/54 - loss 0.65362124 - samples/sec: 65.17 - lr: 0.000030
2021-07-18 12:09:29,206 epoch 4 - iter 10/54 - loss 0.66505327 - samples/sec: 64.55 - lr: 0.000030
2021-07-18 12:09:31,659 epoch 4 - iter 15/54 - loss 0.65778301 - samples/sec: 65.24 - lr: 0.000030
2021-07-18 12:09:34,094 epoch 4 - iter 20/54 - loss 0.65090935 - samples/sec: 65.71 - lr: 0.000030
2021-07-18 12:09:36,568 epoch 4 - iter 25/54 - loss 0.64626683 - samples/sec: 64.70 - lr: 0.000030
2021-07-18 12:09:39,035 epoch 4 - iter 30/54 - loss 0.62640481 - samples/sec: 64.86 - lr: 0.000030
2021-07-18 12:09:41,513 epoch 4 - iter 35/54 - loss 0.61233848 - samples/sec: 64.59 - lr: 0.000030
2021-07-18 12:09:43,996 epoch 4 - iter 40/54 - loss 0.60566139 - samples/sec: 64.46 - lr: 0.000030
2021-07-18 12:09:46,497 epoch 4 - iter 45/54 - loss 0.60461572 - samples/sec: 63.98 - lr: 0.000030
2021-07-18 12:09:48,992 epoch 4 - iter 50/54 - loss 0.58623676 - samples/sec: 64.16 - lr: 0.000030
2021-07-18 12:09:50,629 ----------------------------------------------------------------------------------------------------
2021-07-18 12:09:50,630 EPOCH 4 done: loss 0.5667 - lr 0.0000300
2021-07-18 12:09:52,612 DEV : loss 0.22100889682769775 - score 0.9511
2021-07-18 12:09:52,638 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:09:56,389 ----------------------------------------------------------------------------------------------------
2021-07-18 12:09:58,920 epoch 5 - iter 5/54 - loss 0.51677852 - samples/sec: 63.26 - lr: 0.000030
2021-07-18 12:10:01,442 epoch 5 - iter 10/54 - loss 0.47622005 - samples/sec: 63.46 - lr: 0.000030
2021-07-18 12:10:03,923 epoch 5 - iter 15/54 - loss 0.46237559 - samples/sec: 64.49 - lr: 0.000030
2021-07-18 12:10:06,431 epoch 5 - iter 20/54 - loss 0.47500622 - samples/sec: 63.83 - lr: 0.000030
2021-07-18 12:10:08,922 epoch 5 - iter 25/54 - loss 0.51011948 - samples/sec: 64.23 - lr: 0.000030
2021-07-18 12:10:11,433 epoch 5 - iter 30/54 - loss 0.51168478 - samples/sec: 63.74 - lr: 0.000030
2021-07-18 12:10:13,900 epoch 5 - iter 35/54 - loss 0.52138758 - samples/sec: 64.88 - lr: 0.000030
2021-07-18 12:10:16,400 epoch 5 - iter 40/54 - loss 0.55006296 - samples/sec: 64.01 - lr: 0.000030
2021-07-18 12:10:18,888 epoch 5 - iter 45/54 - loss 0.54822234 - samples/sec: 64.33 - lr: 0.000030
2021-07-18 12:10:21,356 epoch 5 - iter 50/54 - loss 0.53283776 - samples/sec: 64.83 - lr: 0.000030
2021-07-18 12:10:22,970 ----------------------------------------------------------------------------------------------------
2021-07-18 12:10:22,970 EPOCH 5 done: loss 0.5363 - lr 0.0000300
2021-07-18 12:10:24,955 DEV : loss 0.19186429679393768 - score 0.9602
2021-07-18 12:10:24,981 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:10:28,736 ----------------------------------------------------------------------------------------------------
2021-07-18 12:10:31,178 epoch 6 - iter 5/54 - loss 0.50011233 - samples/sec: 65.54 - lr: 0.000030
2021-07-18 12:10:33,620 epoch 6 - iter 10/54 - loss 0.46316842 - samples/sec: 65.52 - lr: 0.000030
2021-07-18 12:10:36,102 epoch 6 - iter 15/54 - loss 0.47344091 - samples/sec: 64.48 - lr: 0.000030
2021-07-18 12:10:38,540 epoch 6 - iter 20/54 - loss 0.50311614 - samples/sec: 65.66 - lr: 0.000030
2021-07-18 12:10:41,066 epoch 6 - iter 25/54 - loss 0.49358121 - samples/sec: 63.36 - lr: 0.000030
2021-07-18 12:10:43,594 epoch 6 - iter 30/54 - loss 0.50528900 - samples/sec: 63.30 - lr: 0.000030
2021-07-18 12:10:46,097 epoch 6 - iter 35/54 - loss 0.48298542 - samples/sec: 63.93 - lr: 0.000030
2021-07-18 12:10:48,616 epoch 6 - iter 40/54 - loss 0.49319410 - samples/sec: 63.53 - lr: 0.000030
2021-07-18 12:10:51,081 epoch 6 - iter 45/54 - loss 0.47966387 - samples/sec: 64.94 - lr: 0.000030
2021-07-18 12:10:53,714 epoch 6 - iter 50/54 - loss 0.48013069 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 12:10:55,322 ----------------------------------------------------------------------------------------------------
2021-07-18 12:10:55,322 EPOCH 6 done: loss 0.4675 - lr 0.0000300
2021-07-18 12:10:57,305 DEV : loss 0.17718879878520966 - score 0.962
2021-07-18 12:10:57,331 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:11:01,284 ----------------------------------------------------------------------------------------------------
2021-07-18 12:11:03,812 epoch 7 - iter 5/54 - loss 0.40301423 - samples/sec: 63.31 - lr: 0.000030
2021-07-18 12:11:06,293 epoch 7 - iter 10/54 - loss 0.39425644 - samples/sec: 64.50 - lr: 0.000030
2021-07-18 12:11:08,773 epoch 7 - iter 15/54 - loss 0.43142766 - samples/sec: 64.53 - lr: 0.000030
2021-07-18 12:11:11,257 epoch 7 - iter 20/54 - loss 0.44555480 - samples/sec: 64.44 - lr: 0.000030
2021-07-18 12:11:13,728 epoch 7 - iter 25/54 - loss 0.42445968 - samples/sec: 64.76 - lr: 0.000030
2021-07-18 12:11:16,220 epoch 7 - iter 30/54 - loss 0.41529495 - samples/sec: 64.21 - lr: 0.000030
2021-07-18 12:11:18,708 epoch 7 - iter 35/54 - loss 0.41624499 - samples/sec: 64.34 - lr: 0.000030
2021-07-18 12:11:21,220 epoch 7 - iter 40/54 - loss 0.42186133 - samples/sec: 63.71 - lr: 0.000030
2021-07-18 12:11:23,709 epoch 7 - iter 45/54 - loss 0.42910116 - samples/sec: 64.30 - lr: 0.000030
2021-07-18 12:11:26,206 epoch 7 - iter 50/54 - loss 0.42410296 - samples/sec: 64.08 - lr: 0.000030
2021-07-18 12:11:27,860 ----------------------------------------------------------------------------------------------------
2021-07-18 12:11:27,861 EPOCH 7 done: loss 0.4303 - lr 0.0000300
2021-07-18 12:11:29,838 DEV : loss 0.14769384264945984 - score 0.9632
2021-07-18 12:11:29,864 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:11:33,647 ----------------------------------------------------------------------------------------------------
2021-07-18 12:11:36,141 epoch 8 - iter 5/54 - loss 0.48995840 - samples/sec: 64.19 - lr: 0.000030
2021-07-18 12:11:38,677 epoch 8 - iter 10/54 - loss 0.45831185 - samples/sec: 63.10 - lr: 0.000030
2021-07-18 12:11:41,148 epoch 8 - iter 15/54 - loss 0.42664675 - samples/sec: 64.76 - lr: 0.000030
2021-07-18 12:11:43,589 epoch 8 - iter 20/54 - loss 0.42222271 - samples/sec: 65.57 - lr: 0.000030
2021-07-18 12:11:46,097 epoch 8 - iter 25/54 - loss 0.42035499 - samples/sec: 63.82 - lr: 0.000030
2021-07-18 12:11:48,592 epoch 8 - iter 30/54 - loss 0.41461108 - samples/sec: 64.14 - lr: 0.000030
2021-07-18 12:11:51,104 epoch 8 - iter 35/54 - loss 0.42769251 - samples/sec: 63.69 - lr: 0.000030
2021-07-18 12:11:53,596 epoch 8 - iter 40/54 - loss 0.42188102 - samples/sec: 64.24 - lr: 0.000030
2021-07-18 12:11:56,077 epoch 8 - iter 45/54 - loss 0.42477500 - samples/sec: 64.52 - lr: 0.000030
2021-07-18 12:11:58,575 epoch 8 - iter 50/54 - loss 0.42131596 - samples/sec: 64.05 - lr: 0.000030
2021-07-18 12:12:00,206 ----------------------------------------------------------------------------------------------------
2021-07-18 12:12:00,207 EPOCH 8 done: loss 0.4240 - lr 0.0000300
2021-07-18 12:12:02,184 DEV : loss 0.14767064154148102 - score 0.9617
2021-07-18 12:12:02,210 BAD EPOCHS (no improvement): 1
2021-07-18 12:12:02,211 ----------------------------------------------------------------------------------------------------
2021-07-18 12:12:04,695 epoch 9 - iter 5/54 - loss 0.32220031 - samples/sec: 64.43 - lr: 0.000030
2021-07-18 12:12:07,206 epoch 9 - iter 10/54 - loss 0.38553004 - samples/sec: 63.73 - lr: 0.000030
2021-07-18 12:12:09,683 epoch 9 - iter 15/54 - loss 0.39333069 - samples/sec: 64.60 - lr: 0.000030
2021-07-18 12:12:12,204 epoch 9 - iter 20/54 - loss 0.40893538 - samples/sec: 63.49 - lr: 0.000030
2021-07-18 12:12:14,644 epoch 9 - iter 25/54 - loss 0.38362923 - samples/sec: 65.59 - lr: 0.000030
2021-07-18 12:12:17,130 epoch 9 - iter 30/54 - loss 0.37558855 - samples/sec: 64.38 - lr: 0.000030
2021-07-18 12:12:19,605 epoch 9 - iter 35/54 - loss 0.36578273 - samples/sec: 64.64 - lr: 0.000030
2021-07-18 12:12:22,149 epoch 9 - iter 40/54 - loss 0.38562221 - samples/sec: 62.92 - lr: 0.000030
2021-07-18 12:12:24,647 epoch 9 - iter 45/54 - loss 0.38364563 - samples/sec: 64.08 - lr: 0.000030
2021-07-18 12:12:27,160 epoch 9 - iter 50/54 - loss 0.38541346 - samples/sec: 63.68 - lr: 0.000030
2021-07-18 12:12:28,810 ----------------------------------------------------------------------------------------------------
2021-07-18 12:12:28,810 EPOCH 9 done: loss 0.3760 - lr 0.0000300
2021-07-18 12:12:30,966 DEV : loss 0.1414210945367813 - score 0.9656
2021-07-18 12:12:30,992 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:12:34,983 ----------------------------------------------------------------------------------------------------
2021-07-18 12:12:37,472 epoch 10 - iter 5/54 - loss 0.49047797 - samples/sec: 64.30 - lr: 0.000030
2021-07-18 12:12:39,969 epoch 10 - iter 10/54 - loss 0.41479158 - samples/sec: 64.09 - lr: 0.000030
2021-07-18 12:12:42,437 epoch 10 - iter 15/54 - loss 0.36906618 - samples/sec: 64.87 - lr: 0.000030
2021-07-18 12:12:44,956 epoch 10 - iter 20/54 - loss 0.35307921 - samples/sec: 63.52 - lr: 0.000030
2021-07-18 12:12:47,441 epoch 10 - iter 25/54 - loss 0.33058902 - samples/sec: 64.40 - lr: 0.000030
2021-07-18 12:12:49,882 epoch 10 - iter 30/54 - loss 0.35164878 - samples/sec: 65.56 - lr: 0.000030
2021-07-18 12:12:52,429 epoch 10 - iter 35/54 - loss 0.34532357 - samples/sec: 62.85 - lr: 0.000030
2021-07-18 12:12:54,919 epoch 10 - iter 40/54 - loss 0.35344140 - samples/sec: 64.25 - lr: 0.000030
2021-07-18 12:12:57,440 epoch 10 - iter 45/54 - loss 0.35052085 - samples/sec: 63.48 - lr: 0.000030
2021-07-18 12:12:59,931 epoch 10 - iter 50/54 - loss 0.34851641 - samples/sec: 64.25 - lr: 0.000030
2021-07-18 12:13:01,562 ----------------------------------------------------------------------------------------------------
2021-07-18 12:13:01,562 EPOCH 10 done: loss 0.3459 - lr 0.0000300
2021-07-18 12:13:03,548 DEV : loss 0.12115722894668579 - score 0.9672
2021-07-18 12:13:03,574 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:13:07,587 ----------------------------------------------------------------------------------------------------
2021-07-18 12:13:10,086 epoch 11 - iter 5/54 - loss 0.27571883 - samples/sec: 64.05 - lr: 0.000030
2021-07-18 12:13:12,596 epoch 11 - iter 10/54 - loss 0.29925137 - samples/sec: 63.74 - lr: 0.000030
2021-07-18 12:13:15,062 epoch 11 - iter 15/54 - loss 0.31411733 - samples/sec: 64.92 - lr: 0.000030
2021-07-18 12:13:17,592 epoch 11 - iter 20/54 - loss 0.33268365 - samples/sec: 63.25 - lr: 0.000030
2021-07-18 12:13:20,076 epoch 11 - iter 25/54 - loss 0.32210187 - samples/sec: 64.42 - lr: 0.000030
2021-07-18 12:13:22,548 epoch 11 - iter 30/54 - loss 0.31870840 - samples/sec: 64.74 - lr: 0.000030
2021-07-18 12:13:25,035 epoch 11 - iter 35/54 - loss 0.29721598 - samples/sec: 64.37 - lr: 0.000030
2021-07-18 12:13:27,540 epoch 11 - iter 40/54 - loss 0.29742385 - samples/sec: 63.88 - lr: 0.000030
2021-07-18 12:13:30,033 epoch 11 - iter 45/54 - loss 0.29906905 - samples/sec: 64.21 - lr: 0.000030
2021-07-18 12:13:32,534 epoch 11 - iter 50/54 - loss 0.29679689 - samples/sec: 63.99 - lr: 0.000030
2021-07-18 12:13:34,158 ----------------------------------------------------------------------------------------------------
2021-07-18 12:13:34,158 EPOCH 11 done: loss 0.2910 - lr 0.0000300
2021-07-18 12:13:36,146 DEV : loss 0.1341971457004547 - score 0.9656
2021-07-18 12:13:36,172 BAD EPOCHS (no improvement): 1
2021-07-18 12:13:36,173 ----------------------------------------------------------------------------------------------------
2021-07-18 12:13:38,685 epoch 12 - iter 5/54 - loss 0.29681695 - samples/sec: 63.70 - lr: 0.000030
2021-07-18 12:13:41,208 epoch 12 - iter 10/54 - loss 0.29944621 - samples/sec: 63.43 - lr: 0.000030
2021-07-18 12:13:43,738 epoch 12 - iter 15/54 - loss 0.28152053 - samples/sec: 63.27 - lr: 0.000030
2021-07-18 12:13:46,220 epoch 12 - iter 20/54 - loss 0.26715858 - samples/sec: 64.47 - lr: 0.000030
2021-07-18 12:13:48,673 epoch 12 - iter 25/54 - loss 0.27723740 - samples/sec: 65.25 - lr: 0.000030
2021-07-18 12:13:51,162 epoch 12 - iter 30/54 - loss 0.28203637 - samples/sec: 64.30 - lr: 0.000030
2021-07-18 12:13:53,666 epoch 12 - iter 35/54 - loss 0.28647599 - samples/sec: 63.91 - lr: 0.000030
2021-07-18 12:13:56,123 epoch 12 - iter 40/54 - loss 0.27591366 - samples/sec: 65.14 - lr: 0.000030
2021-07-18 12:13:58,644 epoch 12 - iter 45/54 - loss 0.28285600 - samples/sec: 63.48 - lr: 0.000030
2021-07-18 12:14:01,180 epoch 12 - iter 50/54 - loss 0.27972986 - samples/sec: 63.11 - lr: 0.000030
2021-07-18 12:14:02,805 ----------------------------------------------------------------------------------------------------
2021-07-18 12:14:02,805 EPOCH 12 done: loss 0.2745 - lr 0.0000300
2021-07-18 12:14:04,788 DEV : loss 0.1107199415564537 - score 0.971
2021-07-18 12:14:04,814 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:14:08,560 ----------------------------------------------------------------------------------------------------
2021-07-18 12:14:11,039 epoch 13 - iter 5/54 - loss 0.21164878 - samples/sec: 64.55 - lr: 0.000030
2021-07-18 12:14:13,524 epoch 13 - iter 10/54 - loss 0.20388298 - samples/sec: 64.41 - lr: 0.000030
2021-07-18 12:14:16,036 epoch 13 - iter 15/54 - loss 0.21856978 - samples/sec: 63.71 - lr: 0.000030
2021-07-18 12:14:18,521 epoch 13 - iter 20/54 - loss 0.22158216 - samples/sec: 64.40 - lr: 0.000030
2021-07-18 12:14:21,001 epoch 13 - iter 25/54 - loss 0.20924711 - samples/sec: 64.52 - lr: 0.000030
2021-07-18 12:14:23,474 epoch 13 - iter 30/54 - loss 0.21547324 - samples/sec: 64.72 - lr: 0.000030
2021-07-18 12:14:25,906 epoch 13 - iter 35/54 - loss 0.22860815 - samples/sec: 65.80 - lr: 0.000030
2021-07-18 12:14:28,376 epoch 13 - iter 40/54 - loss 0.22370912 - samples/sec: 64.80 - lr: 0.000030
2021-07-18 12:14:30,853 epoch 13 - iter 45/54 - loss 0.22997341 - samples/sec: 64.61 - lr: 0.000030
2021-07-18 12:14:33,385 epoch 13 - iter 50/54 - loss 0.22132947 - samples/sec: 63.20 - lr: 0.000030
2021-07-18 12:14:35,024 ----------------------------------------------------------------------------------------------------
2021-07-18 12:14:35,024 EPOCH 13 done: loss 0.2427 - lr 0.0000300
2021-07-18 12:14:37,188 DEV : loss 0.13437581062316895 - score 0.9638
2021-07-18 12:14:37,215 BAD EPOCHS (no improvement): 1
2021-07-18 12:14:37,215 ----------------------------------------------------------------------------------------------------
2021-07-18 12:14:39,652 epoch 14 - iter 5/54 - loss 0.18735045 - samples/sec: 65.69 - lr: 0.000030
2021-07-18 12:14:42,154 epoch 14 - iter 10/54 - loss 0.19006713 - samples/sec: 63.96 - lr: 0.000030
2021-07-18 12:14:44,627 epoch 14 - iter 15/54 - loss 0.19921004 - samples/sec: 64.71 - lr: 0.000030
2021-07-18 12:14:47,124 epoch 14 - iter 20/54 - loss 0.19810285 - samples/sec: 64.10 - lr: 0.000030
2021-07-18 12:14:49,624 epoch 14 - iter 25/54 - loss 0.20118103 - samples/sec: 64.00 - lr: 0.000030
2021-07-18 12:14:52,124 epoch 14 - iter 30/54 - loss 0.19643310 - samples/sec: 64.04 - lr: 0.000030
2021-07-18 12:14:54,609 epoch 14 - iter 35/54 - loss 0.20415701 - samples/sec: 64.39 - lr: 0.000030
2021-07-18 12:14:57,090 epoch 14 - iter 40/54 - loss 0.21655840 - samples/sec: 64.51 - lr: 0.000030
2021-07-18 12:14:59,559 epoch 14 - iter 45/54 - loss 0.23227220 - samples/sec: 64.81 - lr: 0.000030
2021-07-18 12:15:02,065 epoch 14 - iter 50/54 - loss 0.23771552 - samples/sec: 63.87 - lr: 0.000030
2021-07-18 12:15:03,697 ----------------------------------------------------------------------------------------------------
2021-07-18 12:15:03,697 EPOCH 14 done: loss 0.2277 - lr 0.0000300
2021-07-18 12:15:05,674 DEV : loss 0.10965000838041306 - score 0.9692
2021-07-18 12:15:05,700 BAD EPOCHS (no improvement): 2
2021-07-18 12:15:05,701 ----------------------------------------------------------------------------------------------------
2021-07-18 12:15:08,139 epoch 15 - iter 5/54 - loss 0.19882418 - samples/sec: 65.63 - lr: 0.000030
2021-07-18 12:15:10,633 epoch 15 - iter 10/54 - loss 0.17490804 - samples/sec: 64.17 - lr: 0.000030
2021-07-18 12:15:13,124 epoch 15 - iter 15/54 - loss 0.18085429 - samples/sec: 64.24 - lr: 0.000030
2021-07-18 12:15:15,624 epoch 15 - iter 20/54 - loss 0.16352355 - samples/sec: 64.03 - lr: 0.000030
2021-07-18 12:15:18,121 epoch 15 - iter 25/54 - loss 0.20336505 - samples/sec: 64.08 - lr: 0.000030
2021-07-18 12:15:20,601 epoch 15 - iter 30/54 - loss 0.18786076 - samples/sec: 64.54 - lr: 0.000030
2021-07-18 12:15:23,100 epoch 15 - iter 35/54 - loss 0.19660583 - samples/sec: 64.04 - lr: 0.000030
2021-07-18 12:15:25,590 epoch 15 - iter 40/54 - loss 0.20747806 - samples/sec: 64.28 - lr: 0.000030
2021-07-18 12:15:28,076 epoch 15 - iter 45/54 - loss 0.20583652 - samples/sec: 64.36 - lr: 0.000030
2021-07-18 12:15:30,571 epoch 15 - iter 50/54 - loss 0.20663971 - samples/sec: 64.15 - lr: 0.000030
2021-07-18 12:15:32,205 ----------------------------------------------------------------------------------------------------
2021-07-18 12:15:32,206 EPOCH 15 done: loss 0.2130 - lr 0.0000300
2021-07-18 12:15:34,188 DEV : loss 0.12085177004337311 - score 0.9692
2021-07-18 12:15:34,214 BAD EPOCHS (no improvement): 3
2021-07-18 12:15:34,214 ----------------------------------------------------------------------------------------------------
2021-07-18 12:15:36,710 epoch 16 - iter 5/54 - loss 0.17973261 - samples/sec: 64.14 - lr: 0.000030
2021-07-18 12:15:39,173 epoch 16 - iter 10/54 - loss 0.18258551 - samples/sec: 64.98 - lr: 0.000030
2021-07-18 12:15:41,684 epoch 16 - iter 15/54 - loss 0.17489957 - samples/sec: 63.74 - lr: 0.000030
2021-07-18 12:15:44,196 epoch 16 - iter 20/54 - loss 0.20905471 - samples/sec: 63.69 - lr: 0.000030
2021-07-18 12:15:46,685 epoch 16 - iter 25/54 - loss 0.19602606 - samples/sec: 64.31 - lr: 0.000030
2021-07-18 12:15:49,173 epoch 16 - iter 30/54 - loss 0.18989657 - samples/sec: 64.33 - lr: 0.000030
2021-07-18 12:15:51,636 epoch 16 - iter 35/54 - loss 0.20126107 - samples/sec: 64.98 - lr: 0.000030
2021-07-18 12:15:54,093 epoch 16 - iter 40/54 - loss 0.19625509 - samples/sec: 65.12 - lr: 0.000030
2021-07-18 12:15:56,567 epoch 16 - iter 45/54 - loss 0.19727393 - samples/sec: 64.68 - lr: 0.000030
2021-07-18 12:15:59,098 epoch 16 - iter 50/54 - loss 0.19206289 - samples/sec: 63.23 - lr: 0.000030
2021-07-18 12:16:00,723 ----------------------------------------------------------------------------------------------------
2021-07-18 12:16:00,723 EPOCH 16 done: loss 0.1907 - lr 0.0000300
2021-07-18 12:16:02,708 DEV : loss 0.11203691363334656 - score 0.9692
Epoch    16: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 12:16:02,734 BAD EPOCHS (no improvement): 4
2021-07-18 12:16:02,734 ----------------------------------------------------------------------------------------------------
2021-07-18 12:16:05,200 epoch 17 - iter 5/54 - loss 0.26526254 - samples/sec: 64.91 - lr: 0.000015
2021-07-18 12:16:07,692 epoch 17 - iter 10/54 - loss 0.21207088 - samples/sec: 64.20 - lr: 0.000015
2021-07-18 12:16:10,211 epoch 17 - iter 15/54 - loss 0.20961640 - samples/sec: 63.54 - lr: 0.000015
2021-07-18 12:16:12,668 epoch 17 - iter 20/54 - loss 0.18916223 - samples/sec: 65.15 - lr: 0.000015
2021-07-18 12:16:15,135 epoch 17 - iter 25/54 - loss 0.19158869 - samples/sec: 64.86 - lr: 0.000015
2021-07-18 12:16:17,569 epoch 17 - iter 30/54 - loss 0.18622165 - samples/sec: 65.75 - lr: 0.000015
2021-07-18 12:16:20,037 epoch 17 - iter 35/54 - loss 0.18822563 - samples/sec: 64.85 - lr: 0.000015
2021-07-18 12:16:22,538 epoch 17 - iter 40/54 - loss 0.19176688 - samples/sec: 63.99 - lr: 0.000015
2021-07-18 12:16:25,021 epoch 17 - iter 45/54 - loss 0.18698136 - samples/sec: 64.47 - lr: 0.000015
2021-07-18 12:16:27,488 epoch 17 - iter 50/54 - loss 0.18669190 - samples/sec: 64.85 - lr: 0.000015
2021-07-18 12:16:29,132 ----------------------------------------------------------------------------------------------------
2021-07-18 12:16:29,132 EPOCH 17 done: loss 0.2034 - lr 0.0000150
2021-07-18 12:16:31,297 DEV : loss 0.10882017016410828 - score 0.9711
2021-07-18 12:16:31,323 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:16:35,184 ----------------------------------------------------------------------------------------------------
2021-07-18 12:16:37,640 epoch 18 - iter 5/54 - loss 0.11566129 - samples/sec: 65.17 - lr: 0.000015
2021-07-18 12:16:40,112 epoch 18 - iter 10/54 - loss 0.14449907 - samples/sec: 64.72 - lr: 0.000015
2021-07-18 12:16:42,609 epoch 18 - iter 15/54 - loss 0.16710851 - samples/sec: 64.14 - lr: 0.000015
2021-07-18 12:16:45,057 epoch 18 - iter 20/54 - loss 0.14991763 - samples/sec: 65.38 - lr: 0.000015
2021-07-18 12:16:47,554 epoch 18 - iter 25/54 - loss 0.16208785 - samples/sec: 64.10 - lr: 0.000015
2021-07-18 12:16:50,066 epoch 18 - iter 30/54 - loss 0.16463146 - samples/sec: 63.71 - lr: 0.000015
2021-07-18 12:16:52,572 epoch 18 - iter 35/54 - loss 0.16634800 - samples/sec: 63.86 - lr: 0.000015
2021-07-18 12:16:55,048 epoch 18 - iter 40/54 - loss 0.16828908 - samples/sec: 64.64 - lr: 0.000015
2021-07-18 12:16:57,574 epoch 18 - iter 45/54 - loss 0.17617993 - samples/sec: 63.35 - lr: 0.000015
2021-07-18 12:17:00,077 epoch 18 - iter 50/54 - loss 0.17847873 - samples/sec: 63.93 - lr: 0.000015
2021-07-18 12:17:01,714 ----------------------------------------------------------------------------------------------------
2021-07-18 12:17:01,714 EPOCH 18 done: loss 0.1790 - lr 0.0000150
2021-07-18 12:17:03,698 DEV : loss 0.11017794907093048 - score 0.9711
2021-07-18 12:17:03,724 BAD EPOCHS (no improvement): 1
2021-07-18 12:17:03,725 ----------------------------------------------------------------------------------------------------
2021-07-18 12:17:06,233 epoch 19 - iter 5/54 - loss 0.17581042 - samples/sec: 63.80 - lr: 0.000015
2021-07-18 12:17:08,714 epoch 19 - iter 10/54 - loss 0.17093240 - samples/sec: 64.50 - lr: 0.000015
2021-07-18 12:17:11,212 epoch 19 - iter 15/54 - loss 0.17696652 - samples/sec: 64.08 - lr: 0.000015
2021-07-18 12:17:13,700 epoch 19 - iter 20/54 - loss 0.18140756 - samples/sec: 64.34 - lr: 0.000015
2021-07-18 12:17:16,179 epoch 19 - iter 25/54 - loss 0.18102823 - samples/sec: 64.55 - lr: 0.000015
2021-07-18 12:17:18,644 epoch 19 - iter 30/54 - loss 0.19006656 - samples/sec: 64.91 - lr: 0.000015
2021-07-18 12:17:21,124 epoch 19 - iter 35/54 - loss 0.19024020 - samples/sec: 64.53 - lr: 0.000015
2021-07-18 12:17:23,608 epoch 19 - iter 40/54 - loss 0.18481538 - samples/sec: 64.45 - lr: 0.000015
2021-07-18 12:17:26,109 epoch 19 - iter 45/54 - loss 0.18891022 - samples/sec: 63.97 - lr: 0.000015
2021-07-18 12:17:28,609 epoch 19 - iter 50/54 - loss 0.18875961 - samples/sec: 64.02 - lr: 0.000015
2021-07-18 12:17:30,220 ----------------------------------------------------------------------------------------------------
2021-07-18 12:17:30,220 EPOCH 19 done: loss 0.1833 - lr 0.0000150
2021-07-18 12:17:32,204 DEV : loss 0.11712159216403961 - score 0.9692
2021-07-18 12:17:32,230 BAD EPOCHS (no improvement): 2
2021-07-18 12:17:32,230 ----------------------------------------------------------------------------------------------------
2021-07-18 12:17:34,689 epoch 20 - iter 5/54 - loss 0.15458752 - samples/sec: 65.09 - lr: 0.000015
2021-07-18 12:17:37,145 epoch 20 - iter 10/54 - loss 0.16546998 - samples/sec: 65.16 - lr: 0.000015
2021-07-18 12:17:39,599 epoch 20 - iter 15/54 - loss 0.18001668 - samples/sec: 65.21 - lr: 0.000015
2021-07-18 12:17:42,100 epoch 20 - iter 20/54 - loss 0.17364846 - samples/sec: 63.98 - lr: 0.000015
2021-07-18 12:17:44,569 epoch 20 - iter 25/54 - loss 0.16816379 - samples/sec: 64.83 - lr: 0.000015
2021-07-18 12:17:47,041 epoch 20 - iter 30/54 - loss 0.17391409 - samples/sec: 64.73 - lr: 0.000015
2021-07-18 12:17:49,539 epoch 20 - iter 35/54 - loss 0.17969938 - samples/sec: 64.09 - lr: 0.000015
2021-07-18 12:17:52,029 epoch 20 - iter 40/54 - loss 0.17879093 - samples/sec: 64.25 - lr: 0.000015
2021-07-18 12:17:54,503 epoch 20 - iter 45/54 - loss 0.17827785 - samples/sec: 64.69 - lr: 0.000015
2021-07-18 12:17:56,992 epoch 20 - iter 50/54 - loss 0.18313580 - samples/sec: 64.30 - lr: 0.000015
2021-07-18 12:17:58,626 ----------------------------------------------------------------------------------------------------
2021-07-18 12:17:58,626 EPOCH 20 done: loss 0.1769 - lr 0.0000150
2021-07-18 12:18:00,618 DEV : loss 0.10643380135297775 - score 0.9711
2021-07-18 12:18:00,645 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:18:04,531 ----------------------------------------------------------------------------------------------------
2021-07-18 12:18:07,017 epoch 21 - iter 5/54 - loss 0.17102252 - samples/sec: 64.38 - lr: 0.000015
2021-07-18 12:18:09,533 epoch 21 - iter 10/54 - loss 0.14797928 - samples/sec: 63.61 - lr: 0.000015
2021-07-18 12:18:12,018 epoch 21 - iter 15/54 - loss 0.16769140 - samples/sec: 64.42 - lr: 0.000015
2021-07-18 12:18:14,525 epoch 21 - iter 20/54 - loss 0.17134938 - samples/sec: 63.81 - lr: 0.000015
2021-07-18 12:18:17,001 epoch 21 - iter 25/54 - loss 0.16972559 - samples/sec: 64.64 - lr: 0.000015
2021-07-18 12:18:19,481 epoch 21 - iter 30/54 - loss 0.16034946 - samples/sec: 64.55 - lr: 0.000015
2021-07-18 12:18:22,140 epoch 21 - iter 35/54 - loss 0.16347688 - samples/sec: 60.17 - lr: 0.000015
2021-07-18 12:18:24,601 epoch 21 - iter 40/54 - loss 0.16812109 - samples/sec: 65.05 - lr: 0.000015
2021-07-18 12:18:27,089 epoch 21 - iter 45/54 - loss 0.17136533 - samples/sec: 64.31 - lr: 0.000015
2021-07-18 12:18:29,536 epoch 21 - iter 50/54 - loss 0.17349441 - samples/sec: 65.40 - lr: 0.000015
2021-07-18 12:18:31,190 ----------------------------------------------------------------------------------------------------
2021-07-18 12:18:31,190 EPOCH 21 done: loss 0.1695 - lr 0.0000150
2021-07-18 12:18:33,179 DEV : loss 0.10140638798475266 - score 0.9749
2021-07-18 12:18:33,206 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:18:37,048 ----------------------------------------------------------------------------------------------------
2021-07-18 12:18:39,549 epoch 22 - iter 5/54 - loss 0.12251349 - samples/sec: 63.99 - lr: 0.000015
2021-07-18 12:18:42,048 epoch 22 - iter 10/54 - loss 0.13993241 - samples/sec: 64.06 - lr: 0.000015
2021-07-18 12:18:44,529 epoch 22 - iter 15/54 - loss 0.16284320 - samples/sec: 64.51 - lr: 0.000015
2021-07-18 12:18:46,984 epoch 22 - iter 20/54 - loss 0.14640697 - samples/sec: 65.19 - lr: 0.000015
2021-07-18 12:18:49,496 epoch 22 - iter 25/54 - loss 0.17731630 - samples/sec: 63.69 - lr: 0.000015
2021-07-18 12:18:51,992 epoch 22 - iter 30/54 - loss 0.17350749 - samples/sec: 64.13 - lr: 0.000015
2021-07-18 12:18:54,465 epoch 22 - iter 35/54 - loss 0.17483323 - samples/sec: 64.72 - lr: 0.000015
2021-07-18 12:18:56,942 epoch 22 - iter 40/54 - loss 0.19045832 - samples/sec: 64.61 - lr: 0.000015
2021-07-18 12:18:59,425 epoch 22 - iter 45/54 - loss 0.18839697 - samples/sec: 64.43 - lr: 0.000015
2021-07-18 12:19:01,939 epoch 22 - iter 50/54 - loss 0.18780050 - samples/sec: 63.67 - lr: 0.000015
2021-07-18 12:19:03,557 ----------------------------------------------------------------------------------------------------
2021-07-18 12:19:03,557 EPOCH 22 done: loss 0.1998 - lr 0.0000150
2021-07-18 12:19:05,541 DEV : loss 0.10315277427434921 - score 0.973
2021-07-18 12:19:05,567 BAD EPOCHS (no improvement): 1
2021-07-18 12:19:05,567 ----------------------------------------------------------------------------------------------------
2021-07-18 12:19:08,001 epoch 23 - iter 5/54 - loss 0.12734117 - samples/sec: 65.77 - lr: 0.000015
2021-07-18 12:19:10,463 epoch 23 - iter 10/54 - loss 0.13228797 - samples/sec: 64.98 - lr: 0.000015
2021-07-18 12:19:12,941 epoch 23 - iter 15/54 - loss 0.13940904 - samples/sec: 64.60 - lr: 0.000015
2021-07-18 12:19:15,432 epoch 23 - iter 20/54 - loss 0.12669191 - samples/sec: 64.24 - lr: 0.000015
2021-07-18 12:19:17,929 epoch 23 - iter 25/54 - loss 0.13723482 - samples/sec: 64.10 - lr: 0.000015
2021-07-18 12:19:20,439 epoch 23 - iter 30/54 - loss 0.14600763 - samples/sec: 63.75 - lr: 0.000015
2021-07-18 12:19:22,929 epoch 23 - iter 35/54 - loss 0.14706637 - samples/sec: 64.27 - lr: 0.000015
2021-07-18 12:19:25,436 epoch 23 - iter 40/54 - loss 0.14106981 - samples/sec: 63.84 - lr: 0.000015
2021-07-18 12:19:27,917 epoch 23 - iter 45/54 - loss 0.14227420 - samples/sec: 64.50 - lr: 0.000015
2021-07-18 12:19:30,411 epoch 23 - iter 50/54 - loss 0.13575789 - samples/sec: 64.19 - lr: 0.000015
2021-07-18 12:19:32,048 ----------------------------------------------------------------------------------------------------
2021-07-18 12:19:32,048 EPOCH 23 done: loss 0.1394 - lr 0.0000150
2021-07-18 12:19:34,037 DEV : loss 0.10175564885139465 - score 0.9749
2021-07-18 12:19:34,063 BAD EPOCHS (no improvement): 2
2021-07-18 12:19:34,064 ----------------------------------------------------------------------------------------------------
2021-07-18 12:19:36,523 epoch 24 - iter 5/54 - loss 0.14377019 - samples/sec: 65.06 - lr: 0.000015
2021-07-18 12:19:39,012 epoch 24 - iter 10/54 - loss 0.13254880 - samples/sec: 64.30 - lr: 0.000015
2021-07-18 12:19:41,494 epoch 24 - iter 15/54 - loss 0.13794347 - samples/sec: 64.50 - lr: 0.000015
2021-07-18 12:19:43,973 epoch 24 - iter 20/54 - loss 0.15091291 - samples/sec: 64.55 - lr: 0.000015
2021-07-18 12:19:46,452 epoch 24 - iter 25/54 - loss 0.14057682 - samples/sec: 64.55 - lr: 0.000015
2021-07-18 12:19:48,942 epoch 24 - iter 30/54 - loss 0.14563475 - samples/sec: 64.29 - lr: 0.000015
2021-07-18 12:19:51,402 epoch 24 - iter 35/54 - loss 0.14648405 - samples/sec: 65.05 - lr: 0.000015
2021-07-18 12:19:53,928 epoch 24 - iter 40/54 - loss 0.14587096 - samples/sec: 63.34 - lr: 0.000015
2021-07-18 12:19:56,427 epoch 24 - iter 45/54 - loss 0.14481177 - samples/sec: 64.04 - lr: 0.000015
2021-07-18 12:19:58,909 epoch 24 - iter 50/54 - loss 0.14474021 - samples/sec: 64.50 - lr: 0.000015
2021-07-18 12:20:00,540 ----------------------------------------------------------------------------------------------------
2021-07-18 12:20:00,541 EPOCH 24 done: loss 0.1437 - lr 0.0000150
2021-07-18 12:20:02,545 DEV : loss 0.10053851455450058 - score 0.9749
2021-07-18 12:20:02,571 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:20:06,411 ----------------------------------------------------------------------------------------------------
2021-07-18 12:20:09,072 epoch 25 - iter 5/54 - loss 0.13924319 - samples/sec: 60.15 - lr: 0.000015
2021-07-18 12:20:11,594 epoch 25 - iter 10/54 - loss 0.11338517 - samples/sec: 63.46 - lr: 0.000015
2021-07-18 12:20:14,104 epoch 25 - iter 15/54 - loss 0.11476858 - samples/sec: 63.76 - lr: 0.000015
2021-07-18 12:20:16,576 epoch 25 - iter 20/54 - loss 0.12161417 - samples/sec: 64.73 - lr: 0.000015
2021-07-18 12:20:19,092 epoch 25 - iter 25/54 - loss 0.13227499 - samples/sec: 63.62 - lr: 0.000015
2021-07-18 12:20:21,596 epoch 25 - iter 30/54 - loss 0.13460169 - samples/sec: 63.90 - lr: 0.000015
2021-07-18 12:20:24,063 epoch 25 - iter 35/54 - loss 0.12817221 - samples/sec: 64.88 - lr: 0.000015
2021-07-18 12:20:26,552 epoch 25 - iter 40/54 - loss 0.13913852 - samples/sec: 64.31 - lr: 0.000015
2021-07-18 12:20:29,000 epoch 25 - iter 45/54 - loss 0.14239638 - samples/sec: 65.38 - lr: 0.000015
2021-07-18 12:20:31,476 epoch 25 - iter 50/54 - loss 0.14463659 - samples/sec: 64.63 - lr: 0.000015
2021-07-18 12:20:33,076 ----------------------------------------------------------------------------------------------------
2021-07-18 12:20:33,077 EPOCH 25 done: loss 0.1491 - lr 0.0000150
2021-07-18 12:20:35,065 DEV : loss 0.09368114918470383 - score 0.9749
2021-07-18 12:20:35,091 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:20:38,983 ----------------------------------------------------------------------------------------------------
2021-07-18 12:20:41,418 epoch 26 - iter 5/54 - loss 0.10491432 - samples/sec: 65.74 - lr: 0.000015
2021-07-18 12:20:43,922 epoch 26 - iter 10/54 - loss 0.12988557 - samples/sec: 63.91 - lr: 0.000015
2021-07-18 12:20:46,389 epoch 26 - iter 15/54 - loss 0.12637429 - samples/sec: 64.87 - lr: 0.000015
2021-07-18 12:20:48,869 epoch 26 - iter 20/54 - loss 0.13101090 - samples/sec: 64.53 - lr: 0.000015
2021-07-18 12:20:51,352 epoch 26 - iter 25/54 - loss 0.12666204 - samples/sec: 64.46 - lr: 0.000015
2021-07-18 12:20:53,862 epoch 26 - iter 30/54 - loss 0.13869873 - samples/sec: 63.77 - lr: 0.000015
2021-07-18 12:20:56,324 epoch 26 - iter 35/54 - loss 0.14474679 - samples/sec: 65.00 - lr: 0.000015
2021-07-18 12:20:58,796 epoch 26 - iter 40/54 - loss 0.13739468 - samples/sec: 64.75 - lr: 0.000015
2021-07-18 12:21:01,285 epoch 26 - iter 45/54 - loss 0.14241514 - samples/sec: 64.28 - lr: 0.000015
2021-07-18 12:21:03,788 epoch 26 - iter 50/54 - loss 0.14750068 - samples/sec: 63.94 - lr: 0.000015
2021-07-18 12:21:05,432 ----------------------------------------------------------------------------------------------------
2021-07-18 12:21:05,432 EPOCH 26 done: loss 0.1487 - lr 0.0000150
2021-07-18 12:21:07,414 DEV : loss 0.09553761780261993 - score 0.9749
2021-07-18 12:21:07,441 BAD EPOCHS (no improvement): 1
2021-07-18 12:21:07,441 ----------------------------------------------------------------------------------------------------
2021-07-18 12:21:09,923 epoch 27 - iter 5/54 - loss 0.08200436 - samples/sec: 64.48 - lr: 0.000015
2021-07-18 12:21:12,407 epoch 27 - iter 10/54 - loss 0.08861646 - samples/sec: 64.45 - lr: 0.000015
2021-07-18 12:21:14,878 epoch 27 - iter 15/54 - loss 0.08954298 - samples/sec: 64.76 - lr: 0.000015
2021-07-18 12:21:17,382 epoch 27 - iter 20/54 - loss 0.10111263 - samples/sec: 63.92 - lr: 0.000015
2021-07-18 12:21:19,868 epoch 27 - iter 25/54 - loss 0.12199516 - samples/sec: 64.37 - lr: 0.000015
2021-07-18 12:21:22,394 epoch 27 - iter 30/54 - loss 0.13298206 - samples/sec: 63.34 - lr: 0.000015
2021-07-18 12:21:24,830 epoch 27 - iter 35/54 - loss 0.13580090 - samples/sec: 65.73 - lr: 0.000015
2021-07-18 12:21:27,292 epoch 27 - iter 40/54 - loss 0.13678316 - samples/sec: 64.99 - lr: 0.000015
2021-07-18 12:21:29,784 epoch 27 - iter 45/54 - loss 0.14090611 - samples/sec: 64.24 - lr: 0.000015
2021-07-18 12:21:32,233 epoch 27 - iter 50/54 - loss 0.14529260 - samples/sec: 65.34 - lr: 0.000015
2021-07-18 12:21:33,884 ----------------------------------------------------------------------------------------------------
2021-07-18 12:21:33,884 EPOCH 27 done: loss 0.1416 - lr 0.0000150
2021-07-18 12:21:35,869 DEV : loss 0.10482342541217804 - score 0.9749
2021-07-18 12:21:35,896 BAD EPOCHS (no improvement): 2
2021-07-18 12:21:35,897 ----------------------------------------------------------------------------------------------------
2021-07-18 12:21:38,320 epoch 28 - iter 5/54 - loss 0.08133106 - samples/sec: 66.03 - lr: 0.000015
2021-07-18 12:21:40,803 epoch 28 - iter 10/54 - loss 0.13467771 - samples/sec: 64.45 - lr: 0.000015
2021-07-18 12:21:43,290 epoch 28 - iter 15/54 - loss 0.15875410 - samples/sec: 64.37 - lr: 0.000015
2021-07-18 12:21:45,772 epoch 28 - iter 20/54 - loss 0.15939274 - samples/sec: 64.48 - lr: 0.000015
2021-07-18 12:21:48,232 epoch 28 - iter 25/54 - loss 0.14166747 - samples/sec: 65.07 - lr: 0.000015
2021-07-18 12:21:50,720 epoch 28 - iter 30/54 - loss 0.14263921 - samples/sec: 64.30 - lr: 0.000015
2021-07-18 12:21:53,248 epoch 28 - iter 35/54 - loss 0.13854418 - samples/sec: 63.31 - lr: 0.000015
2021-07-18 12:21:55,764 epoch 28 - iter 40/54 - loss 0.14744230 - samples/sec: 63.61 - lr: 0.000015
2021-07-18 12:21:58,264 epoch 28 - iter 45/54 - loss 0.14865778 - samples/sec: 64.02 - lr: 0.000015
2021-07-18 12:22:00,745 epoch 28 - iter 50/54 - loss 0.14766097 - samples/sec: 64.49 - lr: 0.000015
2021-07-18 12:22:02,374 ----------------------------------------------------------------------------------------------------
2021-07-18 12:22:02,374 EPOCH 28 done: loss 0.1447 - lr 0.0000150
2021-07-18 12:22:04,549 DEV : loss 0.09941795468330383 - score 0.973
2021-07-18 12:22:04,575 BAD EPOCHS (no improvement): 3
2021-07-18 12:22:04,575 ----------------------------------------------------------------------------------------------------
2021-07-18 12:22:07,055 epoch 29 - iter 5/54 - loss 0.07792189 - samples/sec: 64.52 - lr: 0.000015
2021-07-18 12:22:09,561 epoch 29 - iter 10/54 - loss 0.10089282 - samples/sec: 63.88 - lr: 0.000015
2021-07-18 12:22:12,071 epoch 29 - iter 15/54 - loss 0.10316826 - samples/sec: 63.74 - lr: 0.000015
2021-07-18 12:22:14,518 epoch 29 - iter 20/54 - loss 0.11530238 - samples/sec: 65.43 - lr: 0.000015
2021-07-18 12:22:16,968 epoch 29 - iter 25/54 - loss 0.12192790 - samples/sec: 65.31 - lr: 0.000015
2021-07-18 12:22:19,459 epoch 29 - iter 30/54 - loss 0.12957519 - samples/sec: 64.24 - lr: 0.000015
2021-07-18 12:22:21,963 epoch 29 - iter 35/54 - loss 0.12019620 - samples/sec: 63.92 - lr: 0.000015
2021-07-18 12:22:24,476 epoch 29 - iter 40/54 - loss 0.12437699 - samples/sec: 63.68 - lr: 0.000015
2021-07-18 12:22:26,984 epoch 29 - iter 45/54 - loss 0.12077241 - samples/sec: 63.82 - lr: 0.000015
2021-07-18 12:22:29,433 epoch 29 - iter 50/54 - loss 0.12003500 - samples/sec: 65.35 - lr: 0.000015
2021-07-18 12:22:31,093 ----------------------------------------------------------------------------------------------------
2021-07-18 12:22:31,094 EPOCH 29 done: loss 0.1283 - lr 0.0000150
2021-07-18 12:22:33,080 DEV : loss 0.10541128367185593 - score 0.9711
Epoch    29: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 12:22:33,106 BAD EPOCHS (no improvement): 4
2021-07-18 12:22:33,106 ----------------------------------------------------------------------------------------------------
2021-07-18 12:22:35,580 epoch 30 - iter 5/54 - loss 0.13060272 - samples/sec: 64.70 - lr: 0.000008
2021-07-18 12:22:38,097 epoch 30 - iter 10/54 - loss 0.13488307 - samples/sec: 63.58 - lr: 0.000008
2021-07-18 12:22:40,525 epoch 30 - iter 15/54 - loss 0.12789288 - samples/sec: 65.93 - lr: 0.000008
2021-07-18 12:22:43,024 epoch 30 - iter 20/54 - loss 0.12647563 - samples/sec: 64.03 - lr: 0.000008
2021-07-18 12:22:45,539 epoch 30 - iter 25/54 - loss 0.11326291 - samples/sec: 63.62 - lr: 0.000008
2021-07-18 12:22:48,005 epoch 30 - iter 30/54 - loss 0.12429650 - samples/sec: 64.91 - lr: 0.000008
2021-07-18 12:22:50,490 epoch 30 - iter 35/54 - loss 0.13011952 - samples/sec: 64.39 - lr: 0.000008
2021-07-18 12:22:53,013 epoch 30 - iter 40/54 - loss 0.13056662 - samples/sec: 63.43 - lr: 0.000008
2021-07-18 12:22:55,464 epoch 30 - iter 45/54 - loss 0.12472010 - samples/sec: 65.32 - lr: 0.000008
2021-07-18 12:22:57,942 epoch 30 - iter 50/54 - loss 0.12063853 - samples/sec: 64.56 - lr: 0.000008
2021-07-18 12:22:59,582 ----------------------------------------------------------------------------------------------------
2021-07-18 12:22:59,582 EPOCH 30 done: loss 0.1207 - lr 0.0000075
2021-07-18 12:23:01,570 DEV : loss 0.09789245575666428 - score 0.973
2021-07-18 12:23:01,596 BAD EPOCHS (no improvement): 1
2021-07-18 12:23:01,596 ----------------------------------------------------------------------------------------------------
2021-07-18 12:23:04,064 epoch 31 - iter 5/54 - loss 0.18979686 - samples/sec: 64.87 - lr: 0.000008
2021-07-18 12:23:06,559 epoch 31 - iter 10/54 - loss 0.15533596 - samples/sec: 64.14 - lr: 0.000008
2021-07-18 12:23:09,040 epoch 31 - iter 15/54 - loss 0.13724865 - samples/sec: 64.51 - lr: 0.000008
2021-07-18 12:23:11,503 epoch 31 - iter 20/54 - loss 0.14503344 - samples/sec: 64.97 - lr: 0.000008
2021-07-18 12:23:14,003 epoch 31 - iter 25/54 - loss 0.14315040 - samples/sec: 64.02 - lr: 0.000008
2021-07-18 12:23:16,494 epoch 31 - iter 30/54 - loss 0.14856590 - samples/sec: 64.26 - lr: 0.000008
2021-07-18 12:23:18,977 epoch 31 - iter 35/54 - loss 0.14199433 - samples/sec: 64.45 - lr: 0.000008
2021-07-18 12:23:21,444 epoch 31 - iter 40/54 - loss 0.14138999 - samples/sec: 64.88 - lr: 0.000008
2021-07-18 12:23:23,957 epoch 31 - iter 45/54 - loss 0.13715772 - samples/sec: 63.66 - lr: 0.000008
2021-07-18 12:23:26,468 epoch 31 - iter 50/54 - loss 0.13578269 - samples/sec: 63.74 - lr: 0.000008
2021-07-18 12:23:28,101 ----------------------------------------------------------------------------------------------------
2021-07-18 12:23:28,102 EPOCH 31 done: loss 0.1337 - lr 0.0000075
2021-07-18 12:23:30,085 DEV : loss 0.10396110266447067 - score 0.973
2021-07-18 12:23:30,112 BAD EPOCHS (no improvement): 2
2021-07-18 12:23:30,112 ----------------------------------------------------------------------------------------------------
2021-07-18 12:23:32,589 epoch 32 - iter 5/54 - loss 0.20699132 - samples/sec: 64.61 - lr: 0.000008
2021-07-18 12:23:35,098 epoch 32 - iter 10/54 - loss 0.17675557 - samples/sec: 63.78 - lr: 0.000008
2021-07-18 12:23:37,562 epoch 32 - iter 15/54 - loss 0.17440134 - samples/sec: 64.96 - lr: 0.000008
2021-07-18 12:23:40,045 epoch 32 - iter 20/54 - loss 0.16045728 - samples/sec: 64.45 - lr: 0.000008
2021-07-18 12:23:42,668 epoch 32 - iter 25/54 - loss 0.15291936 - samples/sec: 61.00 - lr: 0.000008
2021-07-18 12:23:45,181 epoch 32 - iter 30/54 - loss 0.14070145 - samples/sec: 63.70 - lr: 0.000008
2021-07-18 12:23:47,692 epoch 32 - iter 35/54 - loss 0.13810907 - samples/sec: 63.73 - lr: 0.000008
2021-07-18 12:23:50,147 epoch 32 - iter 40/54 - loss 0.13786340 - samples/sec: 65.18 - lr: 0.000008
2021-07-18 12:23:52,644 epoch 32 - iter 45/54 - loss 0.13199307 - samples/sec: 64.10 - lr: 0.000008
2021-07-18 12:23:55,148 epoch 32 - iter 50/54 - loss 0.13113757 - samples/sec: 63.92 - lr: 0.000008
2021-07-18 12:23:56,774 ----------------------------------------------------------------------------------------------------
2021-07-18 12:23:56,774 EPOCH 32 done: loss 0.1330 - lr 0.0000075
2021-07-18 12:23:58,761 DEV : loss 0.10211171954870224 - score 0.9749
2021-07-18 12:23:58,788 BAD EPOCHS (no improvement): 3
2021-07-18 12:23:58,788 ----------------------------------------------------------------------------------------------------
2021-07-18 12:24:01,272 epoch 33 - iter 5/54 - loss 0.14338577 - samples/sec: 64.42 - lr: 0.000008
2021-07-18 12:24:03,753 epoch 33 - iter 10/54 - loss 0.10818485 - samples/sec: 64.51 - lr: 0.000008
2021-07-18 12:24:06,224 epoch 33 - iter 15/54 - loss 0.10795710 - samples/sec: 64.77 - lr: 0.000008
2021-07-18 12:24:08,736 epoch 33 - iter 20/54 - loss 0.11124561 - samples/sec: 63.71 - lr: 0.000008
2021-07-18 12:24:11,245 epoch 33 - iter 25/54 - loss 0.10822258 - samples/sec: 63.79 - lr: 0.000008
2021-07-18 12:24:13,680 epoch 33 - iter 30/54 - loss 0.11441822 - samples/sec: 65.70 - lr: 0.000008
2021-07-18 12:24:16,193 epoch 33 - iter 35/54 - loss 0.13308782 - samples/sec: 63.70 - lr: 0.000008
2021-07-18 12:24:18,689 epoch 33 - iter 40/54 - loss 0.13317500 - samples/sec: 64.11 - lr: 0.000008
2021-07-18 12:24:21,179 epoch 33 - iter 45/54 - loss 0.13178108 - samples/sec: 64.26 - lr: 0.000008
2021-07-18 12:24:23,651 epoch 33 - iter 50/54 - loss 0.13394096 - samples/sec: 64.76 - lr: 0.000008
2021-07-18 12:24:25,296 ----------------------------------------------------------------------------------------------------
2021-07-18 12:24:25,296 EPOCH 33 done: loss 0.1318 - lr 0.0000075
2021-07-18 12:24:27,281 DEV : loss 0.10386302322149277 - score 0.973
Epoch    33: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 12:24:27,307 BAD EPOCHS (no improvement): 4
2021-07-18 12:24:27,307 ----------------------------------------------------------------------------------------------------
2021-07-18 12:24:29,757 epoch 34 - iter 5/54 - loss 0.12789416 - samples/sec: 65.33 - lr: 0.000004
2021-07-18 12:24:32,219 epoch 34 - iter 10/54 - loss 0.11018249 - samples/sec: 64.99 - lr: 0.000004
2021-07-18 12:24:34,710 epoch 34 - iter 15/54 - loss 0.13484358 - samples/sec: 64.27 - lr: 0.000004
2021-07-18 12:24:37,164 epoch 34 - iter 20/54 - loss 0.11449875 - samples/sec: 65.19 - lr: 0.000004
2021-07-18 12:24:39,671 epoch 34 - iter 25/54 - loss 0.10630547 - samples/sec: 63.84 - lr: 0.000004
2021-07-18 12:24:42,133 epoch 34 - iter 30/54 - loss 0.10607475 - samples/sec: 65.00 - lr: 0.000004
2021-07-18 12:24:44,616 epoch 34 - iter 35/54 - loss 0.11240657 - samples/sec: 64.46 - lr: 0.000004
2021-07-18 12:24:47,109 epoch 34 - iter 40/54 - loss 0.11120711 - samples/sec: 64.20 - lr: 0.000004
2021-07-18 12:24:49,595 epoch 34 - iter 45/54 - loss 0.11312865 - samples/sec: 64.37 - lr: 0.000004
2021-07-18 12:24:52,099 epoch 34 - iter 50/54 - loss 0.11937694 - samples/sec: 63.92 - lr: 0.000004
2021-07-18 12:24:53,755 ----------------------------------------------------------------------------------------------------
2021-07-18 12:24:53,756 EPOCH 34 done: loss 0.1182 - lr 0.0000038
2021-07-18 12:24:55,741 DEV : loss 0.10681934654712677 - score 0.973
2021-07-18 12:24:55,768 BAD EPOCHS (no improvement): 1
2021-07-18 12:24:55,768 ----------------------------------------------------------------------------------------------------
2021-07-18 12:24:58,225 epoch 35 - iter 5/54 - loss 0.18135096 - samples/sec: 65.13 - lr: 0.000004
2021-07-18 12:25:00,734 epoch 35 - iter 10/54 - loss 0.15379570 - samples/sec: 63.80 - lr: 0.000004
2021-07-18 12:25:03,196 epoch 35 - iter 15/54 - loss 0.14705206 - samples/sec: 64.98 - lr: 0.000004
2021-07-18 12:25:05,708 epoch 35 - iter 20/54 - loss 0.13230056 - samples/sec: 63.73 - lr: 0.000004
2021-07-18 12:25:08,216 epoch 35 - iter 25/54 - loss 0.14923555 - samples/sec: 63.79 - lr: 0.000004
2021-07-18 12:25:10,681 epoch 35 - iter 30/54 - loss 0.13610967 - samples/sec: 64.94 - lr: 0.000004
2021-07-18 12:25:13,140 epoch 35 - iter 35/54 - loss 0.13206673 - samples/sec: 65.12 - lr: 0.000004
2021-07-18 12:25:15,609 epoch 35 - iter 40/54 - loss 0.12475892 - samples/sec: 64.80 - lr: 0.000004
2021-07-18 12:25:18,118 epoch 35 - iter 45/54 - loss 0.12882319 - samples/sec: 63.79 - lr: 0.000004
2021-07-18 12:25:20,600 epoch 35 - iter 50/54 - loss 0.12736169 - samples/sec: 64.48 - lr: 0.000004
2021-07-18 12:25:22,259 ----------------------------------------------------------------------------------------------------
2021-07-18 12:25:22,260 EPOCH 35 done: loss 0.1277 - lr 0.0000038
2021-07-18 12:25:24,240 DEV : loss 0.10422565788030624 - score 0.973
2021-07-18 12:25:24,266 BAD EPOCHS (no improvement): 2
2021-07-18 12:25:24,266 ----------------------------------------------------------------------------------------------------
2021-07-18 12:25:26,925 epoch 36 - iter 5/54 - loss 0.12433383 - samples/sec: 60.19 - lr: 0.000004
2021-07-18 12:25:29,417 epoch 36 - iter 10/54 - loss 0.10539542 - samples/sec: 64.23 - lr: 0.000004
2021-07-18 12:25:31,887 epoch 36 - iter 15/54 - loss 0.09608281 - samples/sec: 64.79 - lr: 0.000004
2021-07-18 12:25:34,382 epoch 36 - iter 20/54 - loss 0.10741865 - samples/sec: 64.13 - lr: 0.000004
2021-07-18 12:25:36,864 epoch 36 - iter 25/54 - loss 0.10020239 - samples/sec: 64.50 - lr: 0.000004
2021-07-18 12:25:39,332 epoch 36 - iter 30/54 - loss 0.10701423 - samples/sec: 64.85 - lr: 0.000004
2021-07-18 12:25:41,796 epoch 36 - iter 35/54 - loss 0.10272643 - samples/sec: 64.94 - lr: 0.000004
2021-07-18 12:25:44,313 epoch 36 - iter 40/54 - loss 0.10730520 - samples/sec: 63.59 - lr: 0.000004
2021-07-18 12:25:46,800 epoch 36 - iter 45/54 - loss 0.10735317 - samples/sec: 64.34 - lr: 0.000004
2021-07-18 12:25:49,286 epoch 36 - iter 50/54 - loss 0.10845550 - samples/sec: 64.37 - lr: 0.000004
2021-07-18 12:25:50,923 ----------------------------------------------------------------------------------------------------
2021-07-18 12:25:50,923 EPOCH 36 done: loss 0.1062 - lr 0.0000038
2021-07-18 12:25:52,908 DEV : loss 0.10143719613552094 - score 0.9749
2021-07-18 12:25:52,935 BAD EPOCHS (no improvement): 3
2021-07-18 12:25:52,935 ----------------------------------------------------------------------------------------------------
2021-07-18 12:25:55,417 epoch 37 - iter 5/54 - loss 0.13142645 - samples/sec: 64.49 - lr: 0.000004
2021-07-18 12:25:57,869 epoch 37 - iter 10/54 - loss 0.12508348 - samples/sec: 65.26 - lr: 0.000004
2021-07-18 12:26:00,376 epoch 37 - iter 15/54 - loss 0.11496797 - samples/sec: 63.85 - lr: 0.000004
2021-07-18 12:26:02,897 epoch 37 - iter 20/54 - loss 0.13105045 - samples/sec: 63.47 - lr: 0.000004
2021-07-18 12:26:05,417 epoch 37 - iter 25/54 - loss 0.12087733 - samples/sec: 63.52 - lr: 0.000004
2021-07-18 12:26:07,873 epoch 37 - iter 30/54 - loss 0.11782886 - samples/sec: 65.16 - lr: 0.000004
2021-07-18 12:26:10,377 epoch 37 - iter 35/54 - loss 0.11470834 - samples/sec: 63.91 - lr: 0.000004
2021-07-18 12:26:12,830 epoch 37 - iter 40/54 - loss 0.12204669 - samples/sec: 65.22 - lr: 0.000004
2021-07-18 12:26:15,342 epoch 37 - iter 45/54 - loss 0.11861782 - samples/sec: 63.73 - lr: 0.000004
2021-07-18 12:26:17,791 epoch 37 - iter 50/54 - loss 0.11973476 - samples/sec: 65.36 - lr: 0.000004
2021-07-18 12:26:19,418 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:19,419 EPOCH 37 done: loss 0.1213 - lr 0.0000038
2021-07-18 12:26:21,402 DEV : loss 0.10002528131008148 - score 0.9749
Epoch    37: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 12:26:21,428 BAD EPOCHS (no improvement): 4
2021-07-18 12:26:21,428 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:21,428 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:21,428 learning rate too small - quitting training!
2021-07-18 12:26:21,428 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:22,152 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:22,152 Testing using best model ...
2021-07-18 12:26:22,152 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.rststb/best-model.pt
2021-07-18 12:26:30,203 0.9636	0.9464	0.9550
2021-07-18 12:26:30,203 
Results:
- F1-score (micro) 0.9550
- F1-score (macro) 0.9550

By class:
SENT       tp: 318 - fp: 12 - fn: 18 - precision: 0.9636 - recall: 0.9464 - f1-score: 0.9550
2021-07-18 12:26:30,204 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.rst.sctb/
2021-07-18 12:26:30,210 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.rst.sctb
2021-07-18 12:26:30,211 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.rst.sctb/sent_train.txt
2021-07-18 12:26:30,211 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.rst.sctb/sent_dev.txt
2021-07-18 12:26:30,211 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.rst.sctb/sent_test.txt
Corpus: 365 train + 111 dev + 109 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 12:26:32,865 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:32,867 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(21128, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 12:26:32,867 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:32,867 Corpus: "Corpus: 365 train + 111 dev + 109 test sentences"
2021-07-18 12:26:32,867 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:32,867 Parameters:
2021-07-18 12:26:32,867  - learning_rate: "3e-05"
2021-07-18 12:26:32,867  - mini_batch_size: "32"
2021-07-18 12:26:32,867  - patience: "3"
2021-07-18 12:26:32,867  - anneal_factor: "0.5"
2021-07-18 12:26:32,867  - max_epochs: "40"
2021-07-18 12:26:32,867  - shuffle: "True"
2021-07-18 12:26:32,867  - train_with_dev: "False"
2021-07-18 12:26:32,867  - batch_growth_annealing: "False"
2021-07-18 12:26:32,867 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:32,867 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.rst.sctb"
2021-07-18 12:26:32,867 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:32,868 Device: cuda:0
2021-07-18 12:26:32,868 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:32,868 Embeddings storage mode: cpu
2021-07-18 12:26:32,870 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:33,765 epoch 1 - iter 1/12 - loss 4.81896305 - samples/sec: 35.76 - lr: 0.000030
2021-07-18 12:26:34,661 epoch 1 - iter 2/12 - loss 4.78330851 - samples/sec: 35.75 - lr: 0.000030
2021-07-18 12:26:35,585 epoch 1 - iter 3/12 - loss 4.74695603 - samples/sec: 34.62 - lr: 0.000030
2021-07-18 12:26:36,500 epoch 1 - iter 4/12 - loss 4.89419973 - samples/sec: 35.02 - lr: 0.000030
2021-07-18 12:26:37,414 epoch 1 - iter 5/12 - loss 4.87615137 - samples/sec: 35.01 - lr: 0.000030
2021-07-18 12:26:38,317 epoch 1 - iter 6/12 - loss 4.65068360 - samples/sec: 35.46 - lr: 0.000030
2021-07-18 12:26:39,225 epoch 1 - iter 7/12 - loss 4.57002303 - samples/sec: 35.24 - lr: 0.000030
2021-07-18 12:26:40,127 epoch 1 - iter 8/12 - loss 4.34241423 - samples/sec: 35.48 - lr: 0.000030
2021-07-18 12:26:41,034 epoch 1 - iter 9/12 - loss 4.26545903 - samples/sec: 35.30 - lr: 0.000030
2021-07-18 12:26:41,945 epoch 1 - iter 10/12 - loss 4.22246263 - samples/sec: 35.15 - lr: 0.000030
2021-07-18 12:26:42,842 epoch 1 - iter 11/12 - loss 4.12856566 - samples/sec: 35.68 - lr: 0.000030
2021-07-18 12:26:43,252 epoch 1 - iter 12/12 - loss 4.02942244 - samples/sec: 78.11 - lr: 0.000030
2021-07-18 12:26:43,252 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:43,252 EPOCH 1 done: loss 4.0294 - lr 0.0000300
2021-07-18 12:26:45,147 DEV : loss 3.320220470428467 - score 0.0
2021-07-18 12:26:45,155 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:26:45,899 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:46,339 epoch 2 - iter 1/12 - loss 3.12689281 - samples/sec: 72.83 - lr: 0.000030
2021-07-18 12:26:46,776 epoch 2 - iter 2/12 - loss 3.64545953 - samples/sec: 73.27 - lr: 0.000030
2021-07-18 12:26:47,220 epoch 2 - iter 3/12 - loss 3.39190078 - samples/sec: 72.14 - lr: 0.000030
2021-07-18 12:26:47,655 epoch 2 - iter 4/12 - loss 3.29371268 - samples/sec: 73.57 - lr: 0.000030
2021-07-18 12:26:48,104 epoch 2 - iter 5/12 - loss 3.21841941 - samples/sec: 71.38 - lr: 0.000030
2021-07-18 12:26:48,560 epoch 2 - iter 6/12 - loss 3.21464694 - samples/sec: 70.25 - lr: 0.000030
2021-07-18 12:26:49,013 epoch 2 - iter 7/12 - loss 3.28074224 - samples/sec: 70.74 - lr: 0.000030
2021-07-18 12:26:49,456 epoch 2 - iter 8/12 - loss 3.24557000 - samples/sec: 72.28 - lr: 0.000030
2021-07-18 12:26:49,908 epoch 2 - iter 9/12 - loss 3.19402107 - samples/sec: 70.83 - lr: 0.000030
2021-07-18 12:26:50,351 epoch 2 - iter 10/12 - loss 3.18561032 - samples/sec: 72.37 - lr: 0.000030
2021-07-18 12:26:50,796 epoch 2 - iter 11/12 - loss 3.15288082 - samples/sec: 71.99 - lr: 0.000030
2021-07-18 12:26:51,021 epoch 2 - iter 12/12 - loss 3.16090234 - samples/sec: 142.29 - lr: 0.000030
2021-07-18 12:26:51,021 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:51,021 EPOCH 2 done: loss 3.1609 - lr 0.0000300
2021-07-18 12:26:51,565 DEV : loss 2.7652392387390137 - score 0.0
2021-07-18 12:26:51,572 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:26:55,332 ----------------------------------------------------------------------------------------------------
2021-07-18 12:26:55,791 epoch 3 - iter 1/12 - loss 3.15080976 - samples/sec: 69.79 - lr: 0.000030
2021-07-18 12:26:56,242 epoch 3 - iter 2/12 - loss 3.21732473 - samples/sec: 70.99 - lr: 0.000030
2021-07-18 12:26:56,692 epoch 3 - iter 3/12 - loss 2.94397982 - samples/sec: 71.22 - lr: 0.000030
2021-07-18 12:26:57,126 epoch 3 - iter 4/12 - loss 2.94018507 - samples/sec: 73.91 - lr: 0.000030
2021-07-18 12:26:57,577 epoch 3 - iter 5/12 - loss 2.95070505 - samples/sec: 70.95 - lr: 0.000030
2021-07-18 12:26:58,024 epoch 3 - iter 6/12 - loss 2.92036092 - samples/sec: 71.58 - lr: 0.000030
2021-07-18 12:26:58,475 epoch 3 - iter 7/12 - loss 2.89971641 - samples/sec: 71.08 - lr: 0.000030
2021-07-18 12:26:58,917 epoch 3 - iter 8/12 - loss 2.86112317 - samples/sec: 72.54 - lr: 0.000030
2021-07-18 12:26:59,365 epoch 3 - iter 9/12 - loss 2.82744794 - samples/sec: 71.43 - lr: 0.000030
2021-07-18 12:26:59,818 epoch 3 - iter 10/12 - loss 2.72988757 - samples/sec: 70.76 - lr: 0.000030
2021-07-18 12:27:00,249 epoch 3 - iter 11/12 - loss 2.70876747 - samples/sec: 74.21 - lr: 0.000030
2021-07-18 12:27:00,466 epoch 3 - iter 12/12 - loss 2.73177686 - samples/sec: 147.84 - lr: 0.000030
2021-07-18 12:27:00,466 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:00,466 EPOCH 3 done: loss 2.7318 - lr 0.0000300
2021-07-18 12:27:01,005 DEV : loss 2.42002534866333 - score 0.0
2021-07-18 12:27:01,013 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:27:04,575 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:05,025 epoch 4 - iter 1/12 - loss 2.98093367 - samples/sec: 71.16 - lr: 0.000030
2021-07-18 12:27:05,476 epoch 4 - iter 2/12 - loss 2.46507144 - samples/sec: 71.11 - lr: 0.000030
2021-07-18 12:27:05,924 epoch 4 - iter 3/12 - loss 2.36450402 - samples/sec: 71.49 - lr: 0.000030
2021-07-18 12:27:06,375 epoch 4 - iter 4/12 - loss 2.29828346 - samples/sec: 70.94 - lr: 0.000030
2021-07-18 12:27:06,824 epoch 4 - iter 5/12 - loss 2.39732504 - samples/sec: 71.45 - lr: 0.000030
2021-07-18 12:27:07,268 epoch 4 - iter 6/12 - loss 2.45110782 - samples/sec: 72.06 - lr: 0.000030
2021-07-18 12:27:07,707 epoch 4 - iter 7/12 - loss 2.42354781 - samples/sec: 72.93 - lr: 0.000030
2021-07-18 12:27:08,149 epoch 4 - iter 8/12 - loss 2.41098785 - samples/sec: 72.49 - lr: 0.000030
2021-07-18 12:27:08,600 epoch 4 - iter 9/12 - loss 2.36579479 - samples/sec: 70.99 - lr: 0.000030
2021-07-18 12:27:09,049 epoch 4 - iter 10/12 - loss 2.41139667 - samples/sec: 71.34 - lr: 0.000030
2021-07-18 12:27:09,503 epoch 4 - iter 11/12 - loss 2.36353555 - samples/sec: 70.53 - lr: 0.000030
2021-07-18 12:27:09,720 epoch 4 - iter 12/12 - loss 2.37899094 - samples/sec: 148.16 - lr: 0.000030
2021-07-18 12:27:09,720 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:09,720 EPOCH 4 done: loss 2.3790 - lr 0.0000300
2021-07-18 12:27:10,260 DEV : loss 2.118195056915283 - score 0.1443
2021-07-18 12:27:10,267 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:27:13,919 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:14,361 epoch 5 - iter 1/12 - loss 2.03435040 - samples/sec: 72.56 - lr: 0.000030
2021-07-18 12:27:14,810 epoch 5 - iter 2/12 - loss 2.12235188 - samples/sec: 71.37 - lr: 0.000030
2021-07-18 12:27:15,260 epoch 5 - iter 3/12 - loss 2.14408509 - samples/sec: 71.06 - lr: 0.000030
2021-07-18 12:27:15,716 epoch 5 - iter 4/12 - loss 2.07828584 - samples/sec: 70.33 - lr: 0.000030
2021-07-18 12:27:16,158 epoch 5 - iter 5/12 - loss 2.12803361 - samples/sec: 72.38 - lr: 0.000030
2021-07-18 12:27:16,608 epoch 5 - iter 6/12 - loss 2.07757771 - samples/sec: 71.16 - lr: 0.000030
2021-07-18 12:27:17,059 epoch 5 - iter 7/12 - loss 2.13564542 - samples/sec: 71.01 - lr: 0.000030
2021-07-18 12:27:17,508 epoch 5 - iter 8/12 - loss 2.11839899 - samples/sec: 71.41 - lr: 0.000030
2021-07-18 12:27:17,960 epoch 5 - iter 9/12 - loss 2.10453162 - samples/sec: 70.93 - lr: 0.000030
2021-07-18 12:27:18,413 epoch 5 - iter 10/12 - loss 2.08732002 - samples/sec: 70.62 - lr: 0.000030
2021-07-18 12:27:18,871 epoch 5 - iter 11/12 - loss 2.10691589 - samples/sec: 69.97 - lr: 0.000030
2021-07-18 12:27:19,096 epoch 5 - iter 12/12 - loss 2.11486600 - samples/sec: 142.09 - lr: 0.000030
2021-07-18 12:27:19,097 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:19,097 EPOCH 5 done: loss 2.1149 - lr 0.0000300
2021-07-18 12:27:19,638 DEV : loss 1.9184834957122803 - score 0.377
2021-07-18 12:27:19,645 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:27:23,275 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:23,729 epoch 6 - iter 1/12 - loss 1.98658872 - samples/sec: 70.55 - lr: 0.000030
2021-07-18 12:27:24,189 epoch 6 - iter 2/12 - loss 2.04804575 - samples/sec: 69.68 - lr: 0.000030
2021-07-18 12:27:24,645 epoch 6 - iter 3/12 - loss 1.91065196 - samples/sec: 70.29 - lr: 0.000030
2021-07-18 12:27:25,104 epoch 6 - iter 4/12 - loss 1.94855067 - samples/sec: 69.71 - lr: 0.000030
2021-07-18 12:27:25,542 epoch 6 - iter 5/12 - loss 1.90466440 - samples/sec: 73.25 - lr: 0.000030
2021-07-18 12:27:25,993 epoch 6 - iter 6/12 - loss 2.00214559 - samples/sec: 70.99 - lr: 0.000030
2021-07-18 12:27:26,432 epoch 6 - iter 7/12 - loss 2.02059468 - samples/sec: 72.92 - lr: 0.000030
2021-07-18 12:27:26,873 epoch 6 - iter 8/12 - loss 1.93270560 - samples/sec: 72.64 - lr: 0.000030
2021-07-18 12:27:27,329 epoch 6 - iter 9/12 - loss 1.93179233 - samples/sec: 70.27 - lr: 0.000030
2021-07-18 12:27:27,784 epoch 6 - iter 10/12 - loss 1.91667689 - samples/sec: 70.38 - lr: 0.000030
2021-07-18 12:27:28,240 epoch 6 - iter 11/12 - loss 1.90580473 - samples/sec: 70.16 - lr: 0.000030
2021-07-18 12:27:28,464 epoch 6 - iter 12/12 - loss 1.90573437 - samples/sec: 143.36 - lr: 0.000030
2021-07-18 12:27:28,464 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:28,464 EPOCH 6 done: loss 1.9057 - lr 0.0000300
2021-07-18 12:27:29,005 DEV : loss 1.7369831800460815 - score 0.4715
2021-07-18 12:27:29,013 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:27:32,516 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:32,961 epoch 7 - iter 1/12 - loss 2.32323360 - samples/sec: 71.97 - lr: 0.000030
2021-07-18 12:27:33,418 epoch 7 - iter 2/12 - loss 2.09129798 - samples/sec: 70.04 - lr: 0.000030
2021-07-18 12:27:33,872 epoch 7 - iter 3/12 - loss 1.82388993 - samples/sec: 70.58 - lr: 0.000030
2021-07-18 12:27:34,325 epoch 7 - iter 4/12 - loss 1.97592548 - samples/sec: 70.70 - lr: 0.000030
2021-07-18 12:27:34,775 epoch 7 - iter 5/12 - loss 1.89967055 - samples/sec: 71.27 - lr: 0.000030
2021-07-18 12:27:35,225 epoch 7 - iter 6/12 - loss 1.84491483 - samples/sec: 71.16 - lr: 0.000030
2021-07-18 12:27:35,668 epoch 7 - iter 7/12 - loss 1.79844192 - samples/sec: 72.34 - lr: 0.000030
2021-07-18 12:27:36,120 epoch 7 - iter 8/12 - loss 1.76154107 - samples/sec: 70.88 - lr: 0.000030
2021-07-18 12:27:36,568 epoch 7 - iter 9/12 - loss 1.75107805 - samples/sec: 71.35 - lr: 0.000030
2021-07-18 12:27:37,029 epoch 7 - iter 10/12 - loss 1.71172698 - samples/sec: 69.47 - lr: 0.000030
2021-07-18 12:27:37,472 epoch 7 - iter 11/12 - loss 1.70000799 - samples/sec: 72.39 - lr: 0.000030
2021-07-18 12:27:37,694 epoch 7 - iter 12/12 - loss 1.70337168 - samples/sec: 144.24 - lr: 0.000030
2021-07-18 12:27:37,695 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:37,695 EPOCH 7 done: loss 1.7034 - lr 0.0000300
2021-07-18 12:27:38,236 DEV : loss 1.6218311786651611 - score 0.5493
2021-07-18 12:27:38,244 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:27:41,768 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:42,216 epoch 8 - iter 1/12 - loss 1.42329526 - samples/sec: 71.64 - lr: 0.000030
2021-07-18 12:27:42,660 epoch 8 - iter 2/12 - loss 1.49758679 - samples/sec: 72.20 - lr: 0.000030
2021-07-18 12:27:43,094 epoch 8 - iter 3/12 - loss 1.47262160 - samples/sec: 73.74 - lr: 0.000030
2021-07-18 12:27:43,542 epoch 8 - iter 4/12 - loss 1.46581835 - samples/sec: 71.51 - lr: 0.000030
2021-07-18 12:27:43,989 epoch 8 - iter 5/12 - loss 1.51348867 - samples/sec: 71.64 - lr: 0.000030
2021-07-18 12:27:44,435 epoch 8 - iter 6/12 - loss 1.53360456 - samples/sec: 71.71 - lr: 0.000030
2021-07-18 12:27:44,874 epoch 8 - iter 7/12 - loss 1.59122125 - samples/sec: 72.98 - lr: 0.000030
2021-07-18 12:27:45,315 epoch 8 - iter 8/12 - loss 1.55825950 - samples/sec: 72.76 - lr: 0.000030
2021-07-18 12:27:45,753 epoch 8 - iter 9/12 - loss 1.56636798 - samples/sec: 73.10 - lr: 0.000030
2021-07-18 12:27:46,201 epoch 8 - iter 10/12 - loss 1.53762751 - samples/sec: 71.38 - lr: 0.000030
2021-07-18 12:27:46,640 epoch 8 - iter 11/12 - loss 1.53496863 - samples/sec: 73.09 - lr: 0.000030
2021-07-18 12:27:46,861 epoch 8 - iter 12/12 - loss 1.49654302 - samples/sec: 145.15 - lr: 0.000030
2021-07-18 12:27:46,861 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:46,861 EPOCH 8 done: loss 1.4965 - lr 0.0000300
2021-07-18 12:27:47,400 DEV : loss 1.5057557821273804 - score 0.5556
2021-07-18 12:27:47,408 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:27:51,196 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:51,644 epoch 9 - iter 1/12 - loss 1.22362614 - samples/sec: 71.41 - lr: 0.000030
2021-07-18 12:27:52,089 epoch 9 - iter 2/12 - loss 1.35266864 - samples/sec: 72.09 - lr: 0.000030
2021-07-18 12:27:52,528 epoch 9 - iter 3/12 - loss 1.39792029 - samples/sec: 72.89 - lr: 0.000030
2021-07-18 12:27:52,973 epoch 9 - iter 4/12 - loss 1.34033504 - samples/sec: 72.07 - lr: 0.000030
2021-07-18 12:27:53,507 epoch 9 - iter 5/12 - loss 1.32784274 - samples/sec: 59.95 - lr: 0.000030
2021-07-18 12:27:53,930 epoch 9 - iter 6/12 - loss 1.35907855 - samples/sec: 75.75 - lr: 0.000030
2021-07-18 12:27:54,372 epoch 9 - iter 7/12 - loss 1.32849252 - samples/sec: 72.33 - lr: 0.000030
2021-07-18 12:27:54,814 epoch 9 - iter 8/12 - loss 1.34925626 - samples/sec: 72.50 - lr: 0.000030
2021-07-18 12:27:55,265 epoch 9 - iter 9/12 - loss 1.42960330 - samples/sec: 71.00 - lr: 0.000030
2021-07-18 12:27:55,710 epoch 9 - iter 10/12 - loss 1.43311790 - samples/sec: 72.04 - lr: 0.000030
2021-07-18 12:27:56,148 epoch 9 - iter 11/12 - loss 1.47088726 - samples/sec: 73.12 - lr: 0.000030
2021-07-18 12:27:56,361 epoch 9 - iter 12/12 - loss 1.52317527 - samples/sec: 150.57 - lr: 0.000030
2021-07-18 12:27:56,361 ----------------------------------------------------------------------------------------------------
2021-07-18 12:27:56,361 EPOCH 9 done: loss 1.5232 - lr 0.0000300
2021-07-18 12:27:56,901 DEV : loss 1.47723388671875 - score 0.5732
2021-07-18 12:27:56,909 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:28:00,455 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:00,901 epoch 10 - iter 1/12 - loss 1.36040783 - samples/sec: 71.95 - lr: 0.000030
2021-07-18 12:28:01,347 epoch 10 - iter 2/12 - loss 1.31057686 - samples/sec: 71.86 - lr: 0.000030
2021-07-18 12:28:01,782 epoch 10 - iter 3/12 - loss 1.38911792 - samples/sec: 73.62 - lr: 0.000030
2021-07-18 12:28:02,219 epoch 10 - iter 4/12 - loss 1.41267395 - samples/sec: 73.28 - lr: 0.000030
2021-07-18 12:28:02,661 epoch 10 - iter 5/12 - loss 1.38791401 - samples/sec: 72.45 - lr: 0.000030
2021-07-18 12:28:03,114 epoch 10 - iter 6/12 - loss 1.45930427 - samples/sec: 70.73 - lr: 0.000030
2021-07-18 12:28:03,560 epoch 10 - iter 7/12 - loss 1.44472820 - samples/sec: 71.83 - lr: 0.000030
2021-07-18 12:28:04,001 epoch 10 - iter 8/12 - loss 1.42783190 - samples/sec: 72.62 - lr: 0.000030
2021-07-18 12:28:04,446 epoch 10 - iter 9/12 - loss 1.40406832 - samples/sec: 71.84 - lr: 0.000030
2021-07-18 12:28:04,888 epoch 10 - iter 10/12 - loss 1.39108641 - samples/sec: 72.57 - lr: 0.000030
2021-07-18 12:28:05,331 epoch 10 - iter 11/12 - loss 1.38286645 - samples/sec: 72.35 - lr: 0.000030
2021-07-18 12:28:05,551 epoch 10 - iter 12/12 - loss 1.33067572 - samples/sec: 145.56 - lr: 0.000030
2021-07-18 12:28:05,551 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:05,551 EPOCH 10 done: loss 1.3307 - lr 0.0000300
2021-07-18 12:28:06,090 DEV : loss 1.3544039726257324 - score 0.5906
2021-07-18 12:28:06,098 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:28:09,760 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:10,206 epoch 11 - iter 1/12 - loss 1.11763346 - samples/sec: 71.80 - lr: 0.000030
2021-07-18 12:28:10,635 epoch 11 - iter 2/12 - loss 1.23238969 - samples/sec: 74.73 - lr: 0.000030
2021-07-18 12:28:11,077 epoch 11 - iter 3/12 - loss 1.17370796 - samples/sec: 72.52 - lr: 0.000030
2021-07-18 12:28:11,520 epoch 11 - iter 4/12 - loss 1.10309286 - samples/sec: 72.27 - lr: 0.000030
2021-07-18 12:28:11,969 epoch 11 - iter 5/12 - loss 1.22438422 - samples/sec: 71.38 - lr: 0.000030
2021-07-18 12:28:12,409 epoch 11 - iter 6/12 - loss 1.29074106 - samples/sec: 72.68 - lr: 0.000030
2021-07-18 12:28:12,854 epoch 11 - iter 7/12 - loss 1.32220324 - samples/sec: 72.08 - lr: 0.000030
2021-07-18 12:28:13,303 epoch 11 - iter 8/12 - loss 1.25836796 - samples/sec: 71.34 - lr: 0.000030
2021-07-18 12:28:13,750 epoch 11 - iter 9/12 - loss 1.26121450 - samples/sec: 71.54 - lr: 0.000030
2021-07-18 12:28:14,192 epoch 11 - iter 10/12 - loss 1.26421779 - samples/sec: 72.47 - lr: 0.000030
2021-07-18 12:28:14,633 epoch 11 - iter 11/12 - loss 1.23260159 - samples/sec: 72.62 - lr: 0.000030
2021-07-18 12:28:14,855 epoch 11 - iter 12/12 - loss 1.22555887 - samples/sec: 144.91 - lr: 0.000030
2021-07-18 12:28:14,855 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:14,855 EPOCH 11 done: loss 1.2256 - lr 0.0000300
2021-07-18 12:28:15,394 DEV : loss 1.3088082075119019 - score 0.6282
2021-07-18 12:28:15,402 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:28:19,329 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:19,779 epoch 12 - iter 1/12 - loss 1.36599708 - samples/sec: 71.34 - lr: 0.000030
2021-07-18 12:28:20,222 epoch 12 - iter 2/12 - loss 1.43291926 - samples/sec: 72.31 - lr: 0.000030
2021-07-18 12:28:20,660 epoch 12 - iter 3/12 - loss 1.45184473 - samples/sec: 73.10 - lr: 0.000030
2021-07-18 12:28:21,092 epoch 12 - iter 4/12 - loss 1.27701604 - samples/sec: 74.21 - lr: 0.000030
2021-07-18 12:28:21,541 epoch 12 - iter 5/12 - loss 1.30532093 - samples/sec: 71.19 - lr: 0.000030
2021-07-18 12:28:21,990 epoch 12 - iter 6/12 - loss 1.35749465 - samples/sec: 71.35 - lr: 0.000030
2021-07-18 12:28:22,417 epoch 12 - iter 7/12 - loss 1.38888030 - samples/sec: 75.01 - lr: 0.000030
2021-07-18 12:28:22,866 epoch 12 - iter 8/12 - loss 1.29428658 - samples/sec: 71.38 - lr: 0.000030
2021-07-18 12:28:23,316 epoch 12 - iter 9/12 - loss 1.22430333 - samples/sec: 71.22 - lr: 0.000030
2021-07-18 12:28:23,762 epoch 12 - iter 10/12 - loss 1.21580719 - samples/sec: 71.70 - lr: 0.000030
2021-07-18 12:28:24,210 epoch 12 - iter 11/12 - loss 1.17423688 - samples/sec: 71.48 - lr: 0.000030
2021-07-18 12:28:24,421 epoch 12 - iter 12/12 - loss 1.20192165 - samples/sec: 152.57 - lr: 0.000030
2021-07-18 12:28:24,421 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:24,421 EPOCH 12 done: loss 1.2019 - lr 0.0000300
2021-07-18 12:28:24,960 DEV : loss 1.2737832069396973 - score 0.5899
2021-07-18 12:28:24,968 BAD EPOCHS (no improvement): 1
2021-07-18 12:28:24,968 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:25,414 epoch 13 - iter 1/12 - loss 1.59227157 - samples/sec: 71.84 - lr: 0.000030
2021-07-18 12:28:25,853 epoch 13 - iter 2/12 - loss 1.30311465 - samples/sec: 72.94 - lr: 0.000030
2021-07-18 12:28:26,289 epoch 13 - iter 3/12 - loss 1.31807359 - samples/sec: 73.47 - lr: 0.000030
2021-07-18 12:28:26,730 epoch 13 - iter 4/12 - loss 1.19833378 - samples/sec: 72.58 - lr: 0.000030
2021-07-18 12:28:27,182 epoch 13 - iter 5/12 - loss 1.23265146 - samples/sec: 70.81 - lr: 0.000030
2021-07-18 12:28:27,608 epoch 13 - iter 6/12 - loss 1.19196075 - samples/sec: 75.33 - lr: 0.000030
2021-07-18 12:28:28,064 epoch 13 - iter 7/12 - loss 1.19486676 - samples/sec: 70.19 - lr: 0.000030
2021-07-18 12:28:28,512 epoch 13 - iter 8/12 - loss 1.14451501 - samples/sec: 71.44 - lr: 0.000030
2021-07-18 12:28:28,970 epoch 13 - iter 9/12 - loss 1.14231070 - samples/sec: 69.99 - lr: 0.000030
2021-07-18 12:28:29,430 epoch 13 - iter 10/12 - loss 1.17523527 - samples/sec: 69.65 - lr: 0.000030
2021-07-18 12:28:29,872 epoch 13 - iter 11/12 - loss 1.15202908 - samples/sec: 72.44 - lr: 0.000030
2021-07-18 12:28:30,090 epoch 13 - iter 12/12 - loss 1.10176424 - samples/sec: 147.16 - lr: 0.000030
2021-07-18 12:28:30,090 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:30,090 EPOCH 13 done: loss 1.1018 - lr 0.0000300
2021-07-18 12:28:30,632 DEV : loss 1.1917027235031128 - score 0.642
2021-07-18 12:28:30,640 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:28:34,144 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:34,600 epoch 14 - iter 1/12 - loss 1.15567398 - samples/sec: 70.31 - lr: 0.000030
2021-07-18 12:28:35,041 epoch 14 - iter 2/12 - loss 1.08338070 - samples/sec: 72.64 - lr: 0.000030
2021-07-18 12:28:35,477 epoch 14 - iter 3/12 - loss 0.97905105 - samples/sec: 73.45 - lr: 0.000030
2021-07-18 12:28:35,934 epoch 14 - iter 4/12 - loss 1.06048287 - samples/sec: 70.07 - lr: 0.000030
2021-07-18 12:28:36,393 epoch 14 - iter 5/12 - loss 0.97496444 - samples/sec: 69.81 - lr: 0.000030
2021-07-18 12:28:36,849 epoch 14 - iter 6/12 - loss 1.02316273 - samples/sec: 70.27 - lr: 0.000030
2021-07-18 12:28:37,296 epoch 14 - iter 7/12 - loss 0.97157512 - samples/sec: 71.68 - lr: 0.000030
2021-07-18 12:28:37,736 epoch 14 - iter 8/12 - loss 0.97761350 - samples/sec: 72.79 - lr: 0.000030
2021-07-18 12:28:38,183 epoch 14 - iter 9/12 - loss 1.06241947 - samples/sec: 71.56 - lr: 0.000030
2021-07-18 12:28:38,634 epoch 14 - iter 10/12 - loss 1.06197215 - samples/sec: 70.99 - lr: 0.000030
2021-07-18 12:28:39,090 epoch 14 - iter 11/12 - loss 1.06043195 - samples/sec: 70.32 - lr: 0.000030
2021-07-18 12:28:39,309 epoch 14 - iter 12/12 - loss 1.03573777 - samples/sec: 146.41 - lr: 0.000030
2021-07-18 12:28:39,309 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:39,309 EPOCH 14 done: loss 1.0357 - lr 0.0000300
2021-07-18 12:28:39,850 DEV : loss 1.1462383270263672 - score 0.671
2021-07-18 12:28:39,858 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:28:43,439 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:43,905 epoch 15 - iter 1/12 - loss 1.38016033 - samples/sec: 68.88 - lr: 0.000030
2021-07-18 12:28:44,364 epoch 15 - iter 2/12 - loss 1.12694883 - samples/sec: 69.68 - lr: 0.000030
2021-07-18 12:28:44,819 epoch 15 - iter 3/12 - loss 1.12776367 - samples/sec: 70.43 - lr: 0.000030
2021-07-18 12:28:45,257 epoch 15 - iter 4/12 - loss 1.10381258 - samples/sec: 73.05 - lr: 0.000030
2021-07-18 12:28:45,700 epoch 15 - iter 5/12 - loss 1.03735908 - samples/sec: 72.45 - lr: 0.000030
2021-07-18 12:28:46,147 epoch 15 - iter 6/12 - loss 1.05035195 - samples/sec: 71.59 - lr: 0.000030
2021-07-18 12:28:46,587 epoch 15 - iter 7/12 - loss 1.04168268 - samples/sec: 72.74 - lr: 0.000030
2021-07-18 12:28:47,052 epoch 15 - iter 8/12 - loss 1.06399017 - samples/sec: 68.92 - lr: 0.000030
2021-07-18 12:28:47,504 epoch 15 - iter 9/12 - loss 1.04982326 - samples/sec: 70.95 - lr: 0.000030
2021-07-18 12:28:47,952 epoch 15 - iter 10/12 - loss 1.04071108 - samples/sec: 71.41 - lr: 0.000030
2021-07-18 12:28:48,408 epoch 15 - iter 11/12 - loss 1.02532006 - samples/sec: 70.25 - lr: 0.000030
2021-07-18 12:28:48,630 epoch 15 - iter 12/12 - loss 1.00955354 - samples/sec: 144.72 - lr: 0.000030
2021-07-18 12:28:48,630 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:48,630 EPOCH 15 done: loss 1.0096 - lr 0.0000300
2021-07-18 12:28:49,171 DEV : loss 1.1157399415969849 - score 0.7152
2021-07-18 12:28:49,179 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:28:52,761 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:53,221 epoch 16 - iter 1/12 - loss 1.61795378 - samples/sec: 69.66 - lr: 0.000030
2021-07-18 12:28:53,665 epoch 16 - iter 2/12 - loss 1.22885647 - samples/sec: 72.19 - lr: 0.000030
2021-07-18 12:28:54,122 epoch 16 - iter 3/12 - loss 1.05485155 - samples/sec: 70.16 - lr: 0.000030
2021-07-18 12:28:54,570 epoch 16 - iter 4/12 - loss 1.01330681 - samples/sec: 71.35 - lr: 0.000030
2021-07-18 12:28:55,017 epoch 16 - iter 5/12 - loss 1.10274833 - samples/sec: 71.70 - lr: 0.000030
2021-07-18 12:28:55,456 epoch 16 - iter 6/12 - loss 1.04167050 - samples/sec: 73.05 - lr: 0.000030
2021-07-18 12:28:55,917 epoch 16 - iter 7/12 - loss 0.99662813 - samples/sec: 69.37 - lr: 0.000030
2021-07-18 12:28:56,372 epoch 16 - iter 8/12 - loss 0.97863227 - samples/sec: 70.50 - lr: 0.000030
2021-07-18 12:28:56,813 epoch 16 - iter 9/12 - loss 0.98456091 - samples/sec: 72.57 - lr: 0.000030
2021-07-18 12:28:57,260 epoch 16 - iter 10/12 - loss 0.94597045 - samples/sec: 71.63 - lr: 0.000030
2021-07-18 12:28:57,704 epoch 16 - iter 11/12 - loss 0.96772089 - samples/sec: 72.09 - lr: 0.000030
2021-07-18 12:28:57,928 epoch 16 - iter 12/12 - loss 0.99823150 - samples/sec: 143.23 - lr: 0.000030
2021-07-18 12:28:57,929 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:57,929 EPOCH 16 done: loss 0.9982 - lr 0.0000300
2021-07-18 12:28:58,469 DEV : loss 1.0609889030456543 - score 0.6797
2021-07-18 12:28:58,477 BAD EPOCHS (no improvement): 1
2021-07-18 12:28:58,477 ----------------------------------------------------------------------------------------------------
2021-07-18 12:28:58,924 epoch 17 - iter 1/12 - loss 1.39199901 - samples/sec: 71.66 - lr: 0.000030
2021-07-18 12:28:59,380 epoch 17 - iter 2/12 - loss 1.29394317 - samples/sec: 70.25 - lr: 0.000030
2021-07-18 12:28:59,827 epoch 17 - iter 3/12 - loss 1.11069993 - samples/sec: 71.63 - lr: 0.000030
2021-07-18 12:29:00,286 epoch 17 - iter 4/12 - loss 1.08263853 - samples/sec: 69.78 - lr: 0.000030
2021-07-18 12:29:00,734 epoch 17 - iter 5/12 - loss 1.03770411 - samples/sec: 71.57 - lr: 0.000030
2021-07-18 12:29:01,183 epoch 17 - iter 6/12 - loss 1.02884703 - samples/sec: 71.23 - lr: 0.000030
2021-07-18 12:29:01,618 epoch 17 - iter 7/12 - loss 1.00542681 - samples/sec: 73.68 - lr: 0.000030
2021-07-18 12:29:02,059 epoch 17 - iter 8/12 - loss 0.96432273 - samples/sec: 72.59 - lr: 0.000030
2021-07-18 12:29:02,525 epoch 17 - iter 9/12 - loss 0.96283130 - samples/sec: 68.78 - lr: 0.000030
2021-07-18 12:29:02,979 epoch 17 - iter 10/12 - loss 0.94677256 - samples/sec: 70.48 - lr: 0.000030
2021-07-18 12:29:03,424 epoch 17 - iter 11/12 - loss 0.95472891 - samples/sec: 71.97 - lr: 0.000030
2021-07-18 12:29:03,646 epoch 17 - iter 12/12 - loss 0.90814926 - samples/sec: 144.36 - lr: 0.000030
2021-07-18 12:29:03,647 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:03,647 EPOCH 17 done: loss 0.9081 - lr 0.0000300
2021-07-18 12:29:04,188 DEV : loss 1.0256730318069458 - score 0.7044
2021-07-18 12:29:04,196 BAD EPOCHS (no improvement): 2
2021-07-18 12:29:04,196 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:04,645 epoch 18 - iter 1/12 - loss 0.83686948 - samples/sec: 71.22 - lr: 0.000030
2021-07-18 12:29:05,101 epoch 18 - iter 2/12 - loss 1.12072319 - samples/sec: 70.24 - lr: 0.000030
2021-07-18 12:29:05,548 epoch 18 - iter 3/12 - loss 0.95722942 - samples/sec: 71.68 - lr: 0.000030
2021-07-18 12:29:05,991 epoch 18 - iter 4/12 - loss 0.91853279 - samples/sec: 72.29 - lr: 0.000030
2021-07-18 12:29:06,446 epoch 18 - iter 5/12 - loss 0.93061070 - samples/sec: 70.39 - lr: 0.000030
2021-07-18 12:29:06,901 epoch 18 - iter 6/12 - loss 0.90531368 - samples/sec: 70.43 - lr: 0.000030
2021-07-18 12:29:07,356 epoch 18 - iter 7/12 - loss 0.89752244 - samples/sec: 70.35 - lr: 0.000030
2021-07-18 12:29:07,796 epoch 18 - iter 8/12 - loss 0.88240475 - samples/sec: 72.83 - lr: 0.000030
2021-07-18 12:29:08,248 epoch 18 - iter 9/12 - loss 0.84743350 - samples/sec: 70.91 - lr: 0.000030
2021-07-18 12:29:08,704 epoch 18 - iter 10/12 - loss 0.85554119 - samples/sec: 70.29 - lr: 0.000030
2021-07-18 12:29:09,141 epoch 18 - iter 11/12 - loss 0.90440296 - samples/sec: 73.24 - lr: 0.000030
2021-07-18 12:29:09,370 epoch 18 - iter 12/12 - loss 0.89560653 - samples/sec: 139.92 - lr: 0.000030
2021-07-18 12:29:09,370 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:09,370 EPOCH 18 done: loss 0.8956 - lr 0.0000300
2021-07-18 12:29:09,912 DEV : loss 1.0210076570510864 - score 0.7125
2021-07-18 12:29:09,920 BAD EPOCHS (no improvement): 3
2021-07-18 12:29:09,920 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:10,376 epoch 19 - iter 1/12 - loss 0.99155879 - samples/sec: 70.16 - lr: 0.000030
2021-07-18 12:29:10,833 epoch 19 - iter 2/12 - loss 0.90598083 - samples/sec: 70.11 - lr: 0.000030
2021-07-18 12:29:11,261 epoch 19 - iter 3/12 - loss 0.82073885 - samples/sec: 74.94 - lr: 0.000030
2021-07-18 12:29:11,717 epoch 19 - iter 4/12 - loss 0.74924491 - samples/sec: 70.20 - lr: 0.000030
2021-07-18 12:29:12,172 epoch 19 - iter 5/12 - loss 0.71626779 - samples/sec: 70.44 - lr: 0.000030
2021-07-18 12:29:12,623 epoch 19 - iter 6/12 - loss 0.75394987 - samples/sec: 70.99 - lr: 0.000030
2021-07-18 12:29:13,084 epoch 19 - iter 7/12 - loss 0.78875095 - samples/sec: 69.45 - lr: 0.000030
2021-07-18 12:29:13,544 epoch 19 - iter 8/12 - loss 0.82239788 - samples/sec: 69.63 - lr: 0.000030
2021-07-18 12:29:13,998 epoch 19 - iter 9/12 - loss 0.87403894 - samples/sec: 70.53 - lr: 0.000030
2021-07-18 12:29:14,431 epoch 19 - iter 10/12 - loss 0.85938188 - samples/sec: 73.96 - lr: 0.000030
2021-07-18 12:29:14,877 epoch 19 - iter 11/12 - loss 0.84352490 - samples/sec: 71.91 - lr: 0.000030
2021-07-18 12:29:15,097 epoch 19 - iter 12/12 - loss 0.82106081 - samples/sec: 145.51 - lr: 0.000030
2021-07-18 12:29:15,097 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:15,097 EPOCH 19 done: loss 0.8211 - lr 0.0000300
2021-07-18 12:29:15,638 DEV : loss 1.0034970045089722 - score 0.7273
2021-07-18 12:29:15,646 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:29:19,387 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:19,838 epoch 20 - iter 1/12 - loss 0.49289310 - samples/sec: 71.14 - lr: 0.000030
2021-07-18 12:29:20,293 epoch 20 - iter 2/12 - loss 0.76858628 - samples/sec: 70.32 - lr: 0.000030
2021-07-18 12:29:20,748 epoch 20 - iter 3/12 - loss 0.77698628 - samples/sec: 70.44 - lr: 0.000030
2021-07-18 12:29:21,205 epoch 20 - iter 4/12 - loss 0.77412266 - samples/sec: 70.02 - lr: 0.000030
2021-07-18 12:29:21,647 epoch 20 - iter 5/12 - loss 0.84985385 - samples/sec: 72.53 - lr: 0.000030
2021-07-18 12:29:22,088 epoch 20 - iter 6/12 - loss 0.81335483 - samples/sec: 72.64 - lr: 0.000030
2021-07-18 12:29:22,544 epoch 20 - iter 7/12 - loss 0.83968237 - samples/sec: 70.26 - lr: 0.000030
2021-07-18 12:29:22,997 epoch 20 - iter 8/12 - loss 0.82535210 - samples/sec: 70.65 - lr: 0.000030
2021-07-18 12:29:23,439 epoch 20 - iter 9/12 - loss 0.79696510 - samples/sec: 72.50 - lr: 0.000030
2021-07-18 12:29:23,883 epoch 20 - iter 10/12 - loss 0.81778059 - samples/sec: 72.16 - lr: 0.000030
2021-07-18 12:29:24,344 epoch 20 - iter 11/12 - loss 0.82636939 - samples/sec: 69.43 - lr: 0.000030
2021-07-18 12:29:24,565 epoch 20 - iter 12/12 - loss 0.78319406 - samples/sec: 145.04 - lr: 0.000030
2021-07-18 12:29:24,566 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:24,566 EPOCH 20 done: loss 0.7832 - lr 0.0000300
2021-07-18 12:29:25,106 DEV : loss 0.9660264849662781 - score 0.7349
2021-07-18 12:29:25,114 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:29:28,969 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:29,427 epoch 21 - iter 1/12 - loss 0.65311611 - samples/sec: 69.90 - lr: 0.000030
2021-07-18 12:29:29,888 epoch 21 - iter 2/12 - loss 0.55799979 - samples/sec: 69.50 - lr: 0.000030
2021-07-18 12:29:30,424 epoch 21 - iter 3/12 - loss 0.65648466 - samples/sec: 59.82 - lr: 0.000030
2021-07-18 12:29:30,862 epoch 21 - iter 4/12 - loss 0.76801644 - samples/sec: 73.05 - lr: 0.000030
2021-07-18 12:29:31,303 epoch 21 - iter 5/12 - loss 0.70613426 - samples/sec: 72.63 - lr: 0.000030
2021-07-18 12:29:31,749 epoch 21 - iter 6/12 - loss 0.74543802 - samples/sec: 71.89 - lr: 0.000030
2021-07-18 12:29:32,201 epoch 21 - iter 7/12 - loss 0.72668639 - samples/sec: 70.72 - lr: 0.000030
2021-07-18 12:29:32,653 epoch 21 - iter 8/12 - loss 0.73471077 - samples/sec: 70.95 - lr: 0.000030
2021-07-18 12:29:33,103 epoch 21 - iter 9/12 - loss 0.72824564 - samples/sec: 71.12 - lr: 0.000030
2021-07-18 12:29:33,547 epoch 21 - iter 10/12 - loss 0.75819260 - samples/sec: 72.15 - lr: 0.000030
2021-07-18 12:29:34,008 epoch 21 - iter 11/12 - loss 0.77206168 - samples/sec: 69.45 - lr: 0.000030
2021-07-18 12:29:34,233 epoch 21 - iter 12/12 - loss 0.77781348 - samples/sec: 142.48 - lr: 0.000030
2021-07-18 12:29:34,234 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:34,234 EPOCH 21 done: loss 0.7778 - lr 0.0000300
2021-07-18 12:29:34,775 DEV : loss 0.9287130236625671 - score 0.7702
2021-07-18 12:29:34,783 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:29:38,548 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:38,979 epoch 22 - iter 1/12 - loss 0.35771763 - samples/sec: 74.29 - lr: 0.000030
2021-07-18 12:29:39,433 epoch 22 - iter 2/12 - loss 0.43735105 - samples/sec: 70.60 - lr: 0.000030
2021-07-18 12:29:39,884 epoch 22 - iter 3/12 - loss 0.48463857 - samples/sec: 70.96 - lr: 0.000030
2021-07-18 12:29:40,324 epoch 22 - iter 4/12 - loss 0.52724825 - samples/sec: 72.89 - lr: 0.000030
2021-07-18 12:29:40,773 epoch 22 - iter 5/12 - loss 0.64297911 - samples/sec: 71.36 - lr: 0.000030
2021-07-18 12:29:41,224 epoch 22 - iter 6/12 - loss 0.61605806 - samples/sec: 70.98 - lr: 0.000030
2021-07-18 12:29:41,677 epoch 22 - iter 7/12 - loss 0.67013094 - samples/sec: 70.74 - lr: 0.000030
2021-07-18 12:29:42,125 epoch 22 - iter 8/12 - loss 0.68251281 - samples/sec: 71.41 - lr: 0.000030
2021-07-18 12:29:42,579 epoch 22 - iter 9/12 - loss 0.68605436 - samples/sec: 70.48 - lr: 0.000030
2021-07-18 12:29:43,032 epoch 22 - iter 10/12 - loss 0.72307581 - samples/sec: 70.71 - lr: 0.000030
2021-07-18 12:29:43,493 epoch 22 - iter 11/12 - loss 0.72378680 - samples/sec: 69.59 - lr: 0.000030
2021-07-18 12:29:43,714 epoch 22 - iter 12/12 - loss 0.73033403 - samples/sec: 144.84 - lr: 0.000030
2021-07-18 12:29:43,714 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:43,714 EPOCH 22 done: loss 0.7303 - lr 0.0000300
2021-07-18 12:29:44,255 DEV : loss 0.9086451530456543 - score 0.7515
2021-07-18 12:29:44,263 BAD EPOCHS (no improvement): 1
2021-07-18 12:29:44,263 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:44,712 epoch 23 - iter 1/12 - loss 0.97778952 - samples/sec: 71.32 - lr: 0.000030
2021-07-18 12:29:45,162 epoch 23 - iter 2/12 - loss 0.99556124 - samples/sec: 71.17 - lr: 0.000030
2021-07-18 12:29:45,599 epoch 23 - iter 3/12 - loss 0.79681903 - samples/sec: 73.27 - lr: 0.000030
2021-07-18 12:29:46,053 epoch 23 - iter 4/12 - loss 0.75183444 - samples/sec: 70.55 - lr: 0.000030
2021-07-18 12:29:46,512 epoch 23 - iter 5/12 - loss 0.79543103 - samples/sec: 69.84 - lr: 0.000030
2021-07-18 12:29:46,975 epoch 23 - iter 6/12 - loss 0.75439957 - samples/sec: 69.10 - lr: 0.000030
2021-07-18 12:29:47,439 epoch 23 - iter 7/12 - loss 0.75609748 - samples/sec: 69.04 - lr: 0.000030
2021-07-18 12:29:47,884 epoch 23 - iter 8/12 - loss 0.72182842 - samples/sec: 72.02 - lr: 0.000030
2021-07-18 12:29:48,327 epoch 23 - iter 9/12 - loss 0.68802316 - samples/sec: 72.24 - lr: 0.000030
2021-07-18 12:29:48,765 epoch 23 - iter 10/12 - loss 0.67889362 - samples/sec: 73.23 - lr: 0.000030
2021-07-18 12:29:49,203 epoch 23 - iter 11/12 - loss 0.67752261 - samples/sec: 73.14 - lr: 0.000030
2021-07-18 12:29:49,425 epoch 23 - iter 12/12 - loss 0.70964769 - samples/sec: 144.02 - lr: 0.000030
2021-07-18 12:29:49,426 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:49,426 EPOCH 23 done: loss 0.7096 - lr 0.0000300
2021-07-18 12:29:49,966 DEV : loss 0.887229859828949 - score 0.759
2021-07-18 12:29:49,974 BAD EPOCHS (no improvement): 2
2021-07-18 12:29:49,974 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:50,422 epoch 24 - iter 1/12 - loss 0.66797209 - samples/sec: 71.53 - lr: 0.000030
2021-07-18 12:29:50,862 epoch 24 - iter 2/12 - loss 0.62060151 - samples/sec: 72.78 - lr: 0.000030
2021-07-18 12:29:51,312 epoch 24 - iter 3/12 - loss 0.68497290 - samples/sec: 71.25 - lr: 0.000030
2021-07-18 12:29:51,769 epoch 24 - iter 4/12 - loss 0.59733735 - samples/sec: 70.09 - lr: 0.000030
2021-07-18 12:29:52,228 epoch 24 - iter 5/12 - loss 0.66400918 - samples/sec: 69.71 - lr: 0.000030
2021-07-18 12:29:52,690 epoch 24 - iter 6/12 - loss 0.72258022 - samples/sec: 69.44 - lr: 0.000030
2021-07-18 12:29:53,141 epoch 24 - iter 7/12 - loss 0.76785073 - samples/sec: 71.01 - lr: 0.000030
2021-07-18 12:29:53,589 epoch 24 - iter 8/12 - loss 0.73741747 - samples/sec: 71.50 - lr: 0.000030
2021-07-18 12:29:54,037 epoch 24 - iter 9/12 - loss 0.70060084 - samples/sec: 71.45 - lr: 0.000030
2021-07-18 12:29:54,473 epoch 24 - iter 10/12 - loss 0.69194540 - samples/sec: 73.39 - lr: 0.000030
2021-07-18 12:29:54,930 epoch 24 - iter 11/12 - loss 0.70753042 - samples/sec: 70.05 - lr: 0.000030
2021-07-18 12:29:55,140 epoch 24 - iter 12/12 - loss 0.67590145 - samples/sec: 152.70 - lr: 0.000030
2021-07-18 12:29:55,141 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:55,141 EPOCH 24 done: loss 0.6759 - lr 0.0000300
2021-07-18 12:29:55,681 DEV : loss 0.8912848234176636 - score 0.759
2021-07-18 12:29:55,689 BAD EPOCHS (no improvement): 3
2021-07-18 12:29:55,689 ----------------------------------------------------------------------------------------------------
2021-07-18 12:29:56,117 epoch 25 - iter 1/12 - loss 0.94106138 - samples/sec: 74.90 - lr: 0.000030
2021-07-18 12:29:56,565 epoch 25 - iter 2/12 - loss 0.77770156 - samples/sec: 71.49 - lr: 0.000030
2021-07-18 12:29:57,024 epoch 25 - iter 3/12 - loss 0.75577509 - samples/sec: 69.73 - lr: 0.000030
2021-07-18 12:29:57,464 epoch 25 - iter 4/12 - loss 0.74563129 - samples/sec: 72.85 - lr: 0.000030
2021-07-18 12:29:57,920 epoch 25 - iter 5/12 - loss 0.74850355 - samples/sec: 70.26 - lr: 0.000030
2021-07-18 12:29:58,368 epoch 25 - iter 6/12 - loss 0.71339044 - samples/sec: 71.41 - lr: 0.000030
2021-07-18 12:29:58,823 epoch 25 - iter 7/12 - loss 0.67787834 - samples/sec: 70.45 - lr: 0.000030
2021-07-18 12:29:59,277 epoch 25 - iter 8/12 - loss 0.68742309 - samples/sec: 70.55 - lr: 0.000030
2021-07-18 12:29:59,741 epoch 25 - iter 9/12 - loss 0.69126744 - samples/sec: 69.03 - lr: 0.000030
2021-07-18 12:30:00,193 epoch 25 - iter 10/12 - loss 0.69671732 - samples/sec: 70.87 - lr: 0.000030
2021-07-18 12:30:00,649 epoch 25 - iter 11/12 - loss 0.68108093 - samples/sec: 70.25 - lr: 0.000030
2021-07-18 12:30:00,859 epoch 25 - iter 12/12 - loss 0.64384638 - samples/sec: 152.66 - lr: 0.000030
2021-07-18 12:30:00,859 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:00,859 EPOCH 25 done: loss 0.6438 - lr 0.0000300
2021-07-18 12:30:01,401 DEV : loss 0.8951648473739624 - score 0.7578
Epoch    25: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 12:30:01,409 BAD EPOCHS (no improvement): 4
2021-07-18 12:30:01,409 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:01,876 epoch 26 - iter 1/12 - loss 0.48258424 - samples/sec: 68.56 - lr: 0.000015
2021-07-18 12:30:02,322 epoch 26 - iter 2/12 - loss 0.68705073 - samples/sec: 71.86 - lr: 0.000015
2021-07-18 12:30:02,759 epoch 26 - iter 3/12 - loss 0.86101252 - samples/sec: 73.39 - lr: 0.000015
2021-07-18 12:30:03,214 epoch 26 - iter 4/12 - loss 0.82761483 - samples/sec: 70.32 - lr: 0.000015
2021-07-18 12:30:03,651 epoch 26 - iter 5/12 - loss 0.77615937 - samples/sec: 73.26 - lr: 0.000015
2021-07-18 12:30:04,100 epoch 26 - iter 6/12 - loss 0.73462532 - samples/sec: 71.32 - lr: 0.000015
2021-07-18 12:30:04,546 epoch 26 - iter 7/12 - loss 0.70089323 - samples/sec: 71.95 - lr: 0.000015
2021-07-18 12:30:04,997 epoch 26 - iter 8/12 - loss 0.73637524 - samples/sec: 70.92 - lr: 0.000015
2021-07-18 12:30:05,432 epoch 26 - iter 9/12 - loss 0.68916607 - samples/sec: 73.66 - lr: 0.000015
2021-07-18 12:30:05,873 epoch 26 - iter 10/12 - loss 0.72661219 - samples/sec: 72.68 - lr: 0.000015
2021-07-18 12:30:06,326 epoch 26 - iter 11/12 - loss 0.71733538 - samples/sec: 70.61 - lr: 0.000015
2021-07-18 12:30:06,547 epoch 26 - iter 12/12 - loss 0.73035394 - samples/sec: 145.55 - lr: 0.000015
2021-07-18 12:30:06,547 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:06,547 EPOCH 26 done: loss 0.7304 - lr 0.0000150
2021-07-18 12:30:07,088 DEV : loss 0.8726234436035156 - score 0.7711
2021-07-18 12:30:07,095 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:30:10,803 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:11,254 epoch 27 - iter 1/12 - loss 0.71770406 - samples/sec: 71.03 - lr: 0.000015
2021-07-18 12:30:11,781 epoch 27 - iter 2/12 - loss 0.90947735 - samples/sec: 60.71 - lr: 0.000015
2021-07-18 12:30:12,233 epoch 27 - iter 3/12 - loss 0.82347425 - samples/sec: 70.96 - lr: 0.000015
2021-07-18 12:30:12,667 epoch 27 - iter 4/12 - loss 0.75037481 - samples/sec: 73.73 - lr: 0.000015
2021-07-18 12:30:13,107 epoch 27 - iter 5/12 - loss 0.66923014 - samples/sec: 72.78 - lr: 0.000015
2021-07-18 12:30:13,555 epoch 27 - iter 6/12 - loss 0.63351715 - samples/sec: 71.55 - lr: 0.000015
2021-07-18 12:30:14,009 epoch 27 - iter 7/12 - loss 0.62280720 - samples/sec: 70.46 - lr: 0.000015
2021-07-18 12:30:14,456 epoch 27 - iter 8/12 - loss 0.60226457 - samples/sec: 71.72 - lr: 0.000015
2021-07-18 12:30:14,907 epoch 27 - iter 9/12 - loss 0.60585550 - samples/sec: 71.09 - lr: 0.000015
2021-07-18 12:30:15,362 epoch 27 - iter 10/12 - loss 0.59957815 - samples/sec: 70.32 - lr: 0.000015
2021-07-18 12:30:15,800 epoch 27 - iter 11/12 - loss 0.60067348 - samples/sec: 73.18 - lr: 0.000015
2021-07-18 12:30:16,009 epoch 27 - iter 12/12 - loss 0.61248627 - samples/sec: 153.17 - lr: 0.000015
2021-07-18 12:30:16,009 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:16,010 EPOCH 27 done: loss 0.6125 - lr 0.0000150
2021-07-18 12:30:16,549 DEV : loss 0.8681168556213379 - score 0.7811
2021-07-18 12:30:16,557 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:30:20,366 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:20,807 epoch 28 - iter 1/12 - loss 0.37249622 - samples/sec: 72.56 - lr: 0.000015
2021-07-18 12:30:21,260 epoch 28 - iter 2/12 - loss 0.50805597 - samples/sec: 70.76 - lr: 0.000015
2021-07-18 12:30:21,724 epoch 28 - iter 3/12 - loss 0.57381013 - samples/sec: 69.08 - lr: 0.000015
2021-07-18 12:30:22,176 epoch 28 - iter 4/12 - loss 0.57879051 - samples/sec: 70.86 - lr: 0.000015
2021-07-18 12:30:22,629 epoch 28 - iter 5/12 - loss 0.65023028 - samples/sec: 70.62 - lr: 0.000015
2021-07-18 12:30:23,069 epoch 28 - iter 6/12 - loss 0.64392671 - samples/sec: 72.88 - lr: 0.000015
2021-07-18 12:30:23,525 epoch 28 - iter 7/12 - loss 0.67784178 - samples/sec: 70.24 - lr: 0.000015
2021-07-18 12:30:23,969 epoch 28 - iter 8/12 - loss 0.65354957 - samples/sec: 72.13 - lr: 0.000015
2021-07-18 12:30:24,412 epoch 28 - iter 9/12 - loss 0.63295552 - samples/sec: 72.31 - lr: 0.000015
2021-07-18 12:30:24,872 epoch 28 - iter 10/12 - loss 0.61859963 - samples/sec: 69.57 - lr: 0.000015
2021-07-18 12:30:25,325 epoch 28 - iter 11/12 - loss 0.60354148 - samples/sec: 70.65 - lr: 0.000015
2021-07-18 12:30:25,543 epoch 28 - iter 12/12 - loss 0.58185505 - samples/sec: 147.36 - lr: 0.000015
2021-07-18 12:30:25,543 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:25,543 EPOCH 28 done: loss 0.5819 - lr 0.0000150
2021-07-18 12:30:26,084 DEV : loss 0.8676373362541199 - score 0.7711
2021-07-18 12:30:26,092 BAD EPOCHS (no improvement): 1
2021-07-18 12:30:26,093 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:26,541 epoch 29 - iter 1/12 - loss 0.89817321 - samples/sec: 71.45 - lr: 0.000015
2021-07-18 12:30:26,993 epoch 29 - iter 2/12 - loss 0.75598645 - samples/sec: 70.84 - lr: 0.000015
2021-07-18 12:30:27,428 epoch 29 - iter 3/12 - loss 0.74578822 - samples/sec: 73.61 - lr: 0.000015
2021-07-18 12:30:27,869 epoch 29 - iter 4/12 - loss 0.67565739 - samples/sec: 72.68 - lr: 0.000015
2021-07-18 12:30:28,325 epoch 29 - iter 5/12 - loss 0.64773917 - samples/sec: 70.17 - lr: 0.000015
2021-07-18 12:30:28,781 epoch 29 - iter 6/12 - loss 0.61496572 - samples/sec: 70.22 - lr: 0.000015
2021-07-18 12:30:29,231 epoch 29 - iter 7/12 - loss 0.58728213 - samples/sec: 71.23 - lr: 0.000015
2021-07-18 12:30:29,683 epoch 29 - iter 8/12 - loss 0.56875688 - samples/sec: 70.84 - lr: 0.000015
2021-07-18 12:30:30,129 epoch 29 - iter 9/12 - loss 0.54124324 - samples/sec: 71.90 - lr: 0.000015
2021-07-18 12:30:30,588 epoch 29 - iter 10/12 - loss 0.57206001 - samples/sec: 69.69 - lr: 0.000015
2021-07-18 12:30:31,044 epoch 29 - iter 11/12 - loss 0.57867126 - samples/sec: 70.22 - lr: 0.000015
2021-07-18 12:30:31,261 epoch 29 - iter 12/12 - loss 0.57550081 - samples/sec: 148.14 - lr: 0.000015
2021-07-18 12:30:31,261 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:31,261 EPOCH 29 done: loss 0.5755 - lr 0.0000150
2021-07-18 12:30:31,803 DEV : loss 0.8512604832649231 - score 0.7738
2021-07-18 12:30:31,811 BAD EPOCHS (no improvement): 2
2021-07-18 12:30:31,811 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:32,249 epoch 30 - iter 1/12 - loss 0.64667469 - samples/sec: 73.10 - lr: 0.000015
2021-07-18 12:30:32,701 epoch 30 - iter 2/12 - loss 0.50401068 - samples/sec: 70.90 - lr: 0.000015
2021-07-18 12:30:33,152 epoch 30 - iter 3/12 - loss 0.45407395 - samples/sec: 70.93 - lr: 0.000015
2021-07-18 12:30:33,587 epoch 30 - iter 4/12 - loss 0.44788153 - samples/sec: 73.63 - lr: 0.000015
2021-07-18 12:30:34,037 epoch 30 - iter 5/12 - loss 0.47114371 - samples/sec: 71.24 - lr: 0.000015
2021-07-18 12:30:34,481 epoch 30 - iter 6/12 - loss 0.45114975 - samples/sec: 72.09 - lr: 0.000015
2021-07-18 12:30:34,933 epoch 30 - iter 7/12 - loss 0.48331038 - samples/sec: 70.89 - lr: 0.000015
2021-07-18 12:30:35,391 epoch 30 - iter 8/12 - loss 0.47700562 - samples/sec: 70.00 - lr: 0.000015
2021-07-18 12:30:35,841 epoch 30 - iter 9/12 - loss 0.50173587 - samples/sec: 71.05 - lr: 0.000015
2021-07-18 12:30:36,292 epoch 30 - iter 10/12 - loss 0.53808307 - samples/sec: 71.11 - lr: 0.000015
2021-07-18 12:30:36,752 epoch 30 - iter 11/12 - loss 0.54196173 - samples/sec: 69.54 - lr: 0.000015
2021-07-18 12:30:36,974 epoch 30 - iter 12/12 - loss 0.52981695 - samples/sec: 144.70 - lr: 0.000015
2021-07-18 12:30:36,974 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:36,974 EPOCH 30 done: loss 0.5298 - lr 0.0000150
2021-07-18 12:30:37,515 DEV : loss 0.8462567329406738 - score 0.7665
2021-07-18 12:30:37,523 BAD EPOCHS (no improvement): 3
2021-07-18 12:30:37,523 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:37,965 epoch 31 - iter 1/12 - loss 0.82572746 - samples/sec: 72.50 - lr: 0.000015
2021-07-18 12:30:38,419 epoch 31 - iter 2/12 - loss 0.63711476 - samples/sec: 70.50 - lr: 0.000015
2021-07-18 12:30:38,873 epoch 31 - iter 3/12 - loss 0.64308051 - samples/sec: 70.60 - lr: 0.000015
2021-07-18 12:30:39,333 epoch 31 - iter 4/12 - loss 0.67178884 - samples/sec: 69.66 - lr: 0.000015
2021-07-18 12:30:39,793 epoch 31 - iter 5/12 - loss 0.68495653 - samples/sec: 69.63 - lr: 0.000015
2021-07-18 12:30:40,215 epoch 31 - iter 6/12 - loss 0.63754483 - samples/sec: 75.89 - lr: 0.000015
2021-07-18 12:30:40,677 epoch 31 - iter 7/12 - loss 0.62497401 - samples/sec: 69.28 - lr: 0.000015
2021-07-18 12:30:41,120 epoch 31 - iter 8/12 - loss 0.59074035 - samples/sec: 72.29 - lr: 0.000015
2021-07-18 12:30:41,577 epoch 31 - iter 9/12 - loss 0.61757392 - samples/sec: 70.08 - lr: 0.000015
2021-07-18 12:30:42,028 epoch 31 - iter 10/12 - loss 0.62189127 - samples/sec: 71.03 - lr: 0.000015
2021-07-18 12:30:42,489 epoch 31 - iter 11/12 - loss 0.61594700 - samples/sec: 69.49 - lr: 0.000015
2021-07-18 12:30:42,701 epoch 31 - iter 12/12 - loss 0.62325872 - samples/sec: 151.49 - lr: 0.000015
2021-07-18 12:30:42,701 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:42,701 EPOCH 31 done: loss 0.6233 - lr 0.0000150
2021-07-18 12:30:43,243 DEV : loss 0.8369017839431763 - score 0.7665
Epoch    31: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 12:30:43,251 BAD EPOCHS (no improvement): 4
2021-07-18 12:30:43,251 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:43,695 epoch 32 - iter 1/12 - loss 0.48317510 - samples/sec: 72.03 - lr: 0.000008
2021-07-18 12:30:44,149 epoch 32 - iter 2/12 - loss 0.62650076 - samples/sec: 70.65 - lr: 0.000008
2021-07-18 12:30:44,602 epoch 32 - iter 3/12 - loss 0.71670256 - samples/sec: 70.74 - lr: 0.000008
2021-07-18 12:30:45,049 epoch 32 - iter 4/12 - loss 0.71710382 - samples/sec: 71.58 - lr: 0.000008
2021-07-18 12:30:45,508 epoch 32 - iter 5/12 - loss 0.65353578 - samples/sec: 69.74 - lr: 0.000008
2021-07-18 12:30:45,959 epoch 32 - iter 6/12 - loss 0.60305175 - samples/sec: 71.13 - lr: 0.000008
2021-07-18 12:30:46,413 epoch 32 - iter 7/12 - loss 0.59396694 - samples/sec: 70.54 - lr: 0.000008
2021-07-18 12:30:46,852 epoch 32 - iter 8/12 - loss 0.55448283 - samples/sec: 72.89 - lr: 0.000008
2021-07-18 12:30:47,293 epoch 32 - iter 9/12 - loss 0.55246194 - samples/sec: 72.69 - lr: 0.000008
2021-07-18 12:30:47,758 epoch 32 - iter 10/12 - loss 0.54905550 - samples/sec: 68.92 - lr: 0.000008
2021-07-18 12:30:48,213 epoch 32 - iter 11/12 - loss 0.56297926 - samples/sec: 70.34 - lr: 0.000008
2021-07-18 12:30:48,432 epoch 32 - iter 12/12 - loss 0.54253455 - samples/sec: 146.20 - lr: 0.000008
2021-07-18 12:30:48,432 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:48,433 EPOCH 32 done: loss 0.5425 - lr 0.0000075
2021-07-18 12:30:48,973 DEV : loss 0.8354621529579163 - score 0.7805
2021-07-18 12:30:48,981 BAD EPOCHS (no improvement): 1
2021-07-18 12:30:48,982 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:49,420 epoch 33 - iter 1/12 - loss 0.40317386 - samples/sec: 73.04 - lr: 0.000008
2021-07-18 12:30:49,961 epoch 33 - iter 2/12 - loss 0.36956045 - samples/sec: 59.17 - lr: 0.000008
2021-07-18 12:30:50,407 epoch 33 - iter 3/12 - loss 0.45330483 - samples/sec: 71.86 - lr: 0.000008
2021-07-18 12:30:50,869 epoch 33 - iter 4/12 - loss 0.52009080 - samples/sec: 69.29 - lr: 0.000008
2021-07-18 12:30:51,321 epoch 33 - iter 5/12 - loss 0.51496195 - samples/sec: 70.83 - lr: 0.000008
2021-07-18 12:30:51,769 epoch 33 - iter 6/12 - loss 0.48692134 - samples/sec: 71.54 - lr: 0.000008
2021-07-18 12:30:52,228 epoch 33 - iter 7/12 - loss 0.48440200 - samples/sec: 69.83 - lr: 0.000008
2021-07-18 12:30:52,668 epoch 33 - iter 8/12 - loss 0.53775899 - samples/sec: 72.71 - lr: 0.000008
2021-07-18 12:30:53,123 epoch 33 - iter 9/12 - loss 0.55115616 - samples/sec: 70.39 - lr: 0.000008
2021-07-18 12:30:53,577 epoch 33 - iter 10/12 - loss 0.55235248 - samples/sec: 70.63 - lr: 0.000008
2021-07-18 12:30:54,023 epoch 33 - iter 11/12 - loss 0.57730758 - samples/sec: 71.88 - lr: 0.000008
2021-07-18 12:30:54,238 epoch 33 - iter 12/12 - loss 0.54663968 - samples/sec: 149.05 - lr: 0.000008
2021-07-18 12:30:54,238 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:54,238 EPOCH 33 done: loss 0.5466 - lr 0.0000075
2021-07-18 12:30:54,780 DEV : loss 0.8354397416114807 - score 0.773
2021-07-18 12:30:54,788 BAD EPOCHS (no improvement): 2
2021-07-18 12:30:54,788 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:55,229 epoch 34 - iter 1/12 - loss 0.39766085 - samples/sec: 72.62 - lr: 0.000008
2021-07-18 12:30:55,689 epoch 34 - iter 2/12 - loss 0.41896337 - samples/sec: 69.68 - lr: 0.000008
2021-07-18 12:30:56,141 epoch 34 - iter 3/12 - loss 0.44538285 - samples/sec: 70.81 - lr: 0.000008
2021-07-18 12:30:56,601 epoch 34 - iter 4/12 - loss 0.47748978 - samples/sec: 69.63 - lr: 0.000008
2021-07-18 12:30:57,061 epoch 34 - iter 5/12 - loss 0.66137286 - samples/sec: 69.62 - lr: 0.000008
2021-07-18 12:30:57,514 epoch 34 - iter 6/12 - loss 0.61395978 - samples/sec: 70.75 - lr: 0.000008
2021-07-18 12:30:57,962 epoch 34 - iter 7/12 - loss 0.61595861 - samples/sec: 71.50 - lr: 0.000008
2021-07-18 12:30:58,413 epoch 34 - iter 8/12 - loss 0.59177037 - samples/sec: 71.01 - lr: 0.000008
2021-07-18 12:30:58,846 epoch 34 - iter 9/12 - loss 0.56753123 - samples/sec: 73.85 - lr: 0.000008
2021-07-18 12:30:59,288 epoch 34 - iter 10/12 - loss 0.55343006 - samples/sec: 72.58 - lr: 0.000008
2021-07-18 12:30:59,740 epoch 34 - iter 11/12 - loss 0.54435149 - samples/sec: 70.74 - lr: 0.000008
2021-07-18 12:30:59,953 epoch 34 - iter 12/12 - loss 0.51672770 - samples/sec: 150.53 - lr: 0.000008
2021-07-18 12:30:59,954 ----------------------------------------------------------------------------------------------------
2021-07-18 12:30:59,954 EPOCH 34 done: loss 0.5167 - lr 0.0000075
2021-07-18 12:31:00,495 DEV : loss 0.8272106051445007 - score 0.773
2021-07-18 12:31:00,502 BAD EPOCHS (no improvement): 3
2021-07-18 12:31:00,503 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:00,952 epoch 35 - iter 1/12 - loss 0.43115205 - samples/sec: 71.25 - lr: 0.000008
2021-07-18 12:31:01,399 epoch 35 - iter 2/12 - loss 0.42487913 - samples/sec: 71.69 - lr: 0.000008
2021-07-18 12:31:01,845 epoch 35 - iter 3/12 - loss 0.39853585 - samples/sec: 71.86 - lr: 0.000008
2021-07-18 12:31:02,298 epoch 35 - iter 4/12 - loss 0.49722806 - samples/sec: 70.72 - lr: 0.000008
2021-07-18 12:31:02,738 epoch 35 - iter 5/12 - loss 0.45962148 - samples/sec: 72.67 - lr: 0.000008
2021-07-18 12:31:03,196 epoch 35 - iter 6/12 - loss 0.45361726 - samples/sec: 69.97 - lr: 0.000008
2021-07-18 12:31:03,651 epoch 35 - iter 7/12 - loss 0.47441452 - samples/sec: 70.38 - lr: 0.000008
2021-07-18 12:31:04,104 epoch 35 - iter 8/12 - loss 0.48478517 - samples/sec: 70.73 - lr: 0.000008
2021-07-18 12:31:04,556 epoch 35 - iter 9/12 - loss 0.52590439 - samples/sec: 70.88 - lr: 0.000008
2021-07-18 12:31:05,003 epoch 35 - iter 10/12 - loss 0.55803358 - samples/sec: 71.61 - lr: 0.000008
2021-07-18 12:31:05,457 epoch 35 - iter 11/12 - loss 0.54552147 - samples/sec: 70.60 - lr: 0.000008
2021-07-18 12:31:05,677 epoch 35 - iter 12/12 - loss 0.54890816 - samples/sec: 145.37 - lr: 0.000008
2021-07-18 12:31:05,678 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:05,678 EPOCH 35 done: loss 0.5489 - lr 0.0000075
2021-07-18 12:31:06,220 DEV : loss 0.82756108045578 - score 0.7805
Epoch    35: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 12:31:06,227 BAD EPOCHS (no improvement): 4
2021-07-18 12:31:06,228 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:06,680 epoch 36 - iter 1/12 - loss 0.40125656 - samples/sec: 70.80 - lr: 0.000004
2021-07-18 12:31:07,131 epoch 36 - iter 2/12 - loss 0.46295756 - samples/sec: 71.04 - lr: 0.000004
2021-07-18 12:31:07,571 epoch 36 - iter 3/12 - loss 0.45794523 - samples/sec: 72.70 - lr: 0.000004
2021-07-18 12:31:08,016 epoch 36 - iter 4/12 - loss 0.61243573 - samples/sec: 72.09 - lr: 0.000004
2021-07-18 12:31:08,476 epoch 36 - iter 5/12 - loss 0.58035314 - samples/sec: 69.53 - lr: 0.000004
2021-07-18 12:31:08,935 epoch 36 - iter 6/12 - loss 0.54353420 - samples/sec: 69.82 - lr: 0.000004
2021-07-18 12:31:09,383 epoch 36 - iter 7/12 - loss 0.57014954 - samples/sec: 71.47 - lr: 0.000004
2021-07-18 12:31:09,835 epoch 36 - iter 8/12 - loss 0.55645080 - samples/sec: 70.95 - lr: 0.000004
2021-07-18 12:31:10,276 epoch 36 - iter 9/12 - loss 0.55230355 - samples/sec: 72.53 - lr: 0.000004
2021-07-18 12:31:10,727 epoch 36 - iter 10/12 - loss 0.52635584 - samples/sec: 71.00 - lr: 0.000004
2021-07-18 12:31:11,172 epoch 36 - iter 11/12 - loss 0.51042386 - samples/sec: 71.99 - lr: 0.000004
2021-07-18 12:31:11,396 epoch 36 - iter 12/12 - loss 0.51304819 - samples/sec: 143.27 - lr: 0.000004
2021-07-18 12:31:11,396 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:11,396 EPOCH 36 done: loss 0.5130 - lr 0.0000038
2021-07-18 12:31:11,939 DEV : loss 0.8256198167800903 - score 0.7831
2021-07-18 12:31:11,947 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:31:15,807 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:16,250 epoch 37 - iter 1/12 - loss 0.33048761 - samples/sec: 72.43 - lr: 0.000004
2021-07-18 12:31:16,684 epoch 37 - iter 2/12 - loss 0.39611733 - samples/sec: 73.71 - lr: 0.000004
2021-07-18 12:31:17,141 epoch 37 - iter 3/12 - loss 0.42510414 - samples/sec: 70.13 - lr: 0.000004
2021-07-18 12:31:17,583 epoch 37 - iter 4/12 - loss 0.39182597 - samples/sec: 72.41 - lr: 0.000004
2021-07-18 12:31:18,036 epoch 37 - iter 5/12 - loss 0.44625592 - samples/sec: 70.79 - lr: 0.000004
2021-07-18 12:31:18,476 epoch 37 - iter 6/12 - loss 0.47824046 - samples/sec: 72.83 - lr: 0.000004
2021-07-18 12:31:18,923 epoch 37 - iter 7/12 - loss 0.48165593 - samples/sec: 71.52 - lr: 0.000004
2021-07-18 12:31:19,372 epoch 37 - iter 8/12 - loss 0.52427065 - samples/sec: 71.33 - lr: 0.000004
2021-07-18 12:31:19,824 epoch 37 - iter 9/12 - loss 0.50731746 - samples/sec: 70.91 - lr: 0.000004
2021-07-18 12:31:20,277 epoch 37 - iter 10/12 - loss 0.49842961 - samples/sec: 70.69 - lr: 0.000004
2021-07-18 12:31:20,726 epoch 37 - iter 11/12 - loss 0.50012429 - samples/sec: 71.44 - lr: 0.000004
2021-07-18 12:31:20,942 epoch 37 - iter 12/12 - loss 0.49973760 - samples/sec: 148.19 - lr: 0.000004
2021-07-18 12:31:20,942 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:20,942 EPOCH 37 done: loss 0.4997 - lr 0.0000038
2021-07-18 12:31:21,483 DEV : loss 0.8237515687942505 - score 0.7904
2021-07-18 12:31:21,490 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:31:25,243 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:25,688 epoch 38 - iter 1/12 - loss 0.47129703 - samples/sec: 72.09 - lr: 0.000004
2021-07-18 12:31:26,141 epoch 38 - iter 2/12 - loss 0.49543166 - samples/sec: 70.75 - lr: 0.000004
2021-07-18 12:31:26,590 epoch 38 - iter 3/12 - loss 0.44787538 - samples/sec: 71.33 - lr: 0.000004
2021-07-18 12:31:27,039 epoch 38 - iter 4/12 - loss 0.42577931 - samples/sec: 71.33 - lr: 0.000004
2021-07-18 12:31:27,488 epoch 38 - iter 5/12 - loss 0.43408725 - samples/sec: 71.25 - lr: 0.000004
2021-07-18 12:31:27,943 epoch 38 - iter 6/12 - loss 0.43044613 - samples/sec: 70.38 - lr: 0.000004
2021-07-18 12:31:28,389 epoch 38 - iter 7/12 - loss 0.47464120 - samples/sec: 71.88 - lr: 0.000004
2021-07-18 12:31:28,832 epoch 38 - iter 8/12 - loss 0.45469014 - samples/sec: 72.30 - lr: 0.000004
2021-07-18 12:31:29,274 epoch 38 - iter 9/12 - loss 0.50140685 - samples/sec: 72.46 - lr: 0.000004
2021-07-18 12:31:29,720 epoch 38 - iter 10/12 - loss 0.50773481 - samples/sec: 71.89 - lr: 0.000004
2021-07-18 12:31:30,160 epoch 38 - iter 11/12 - loss 0.52060587 - samples/sec: 72.73 - lr: 0.000004
2021-07-18 12:31:30,381 epoch 38 - iter 12/12 - loss 0.50251794 - samples/sec: 145.23 - lr: 0.000004
2021-07-18 12:31:30,381 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:30,381 EPOCH 38 done: loss 0.5025 - lr 0.0000038
2021-07-18 12:31:30,921 DEV : loss 0.823519229888916 - score 0.8
2021-07-18 12:31:30,928 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:31:34,755 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:35,213 epoch 39 - iter 1/12 - loss 0.35082030 - samples/sec: 69.97 - lr: 0.000004
2021-07-18 12:31:35,664 epoch 39 - iter 2/12 - loss 0.34593487 - samples/sec: 71.03 - lr: 0.000004
2021-07-18 12:31:36,117 epoch 39 - iter 3/12 - loss 0.60355910 - samples/sec: 70.77 - lr: 0.000004
2021-07-18 12:31:36,577 epoch 39 - iter 4/12 - loss 0.55858815 - samples/sec: 69.56 - lr: 0.000004
2021-07-18 12:31:37,017 epoch 39 - iter 5/12 - loss 0.55938689 - samples/sec: 72.81 - lr: 0.000004
2021-07-18 12:31:37,479 epoch 39 - iter 6/12 - loss 0.50845155 - samples/sec: 69.33 - lr: 0.000004
2021-07-18 12:31:37,923 epoch 39 - iter 7/12 - loss 0.49484436 - samples/sec: 72.10 - lr: 0.000004
2021-07-18 12:31:38,367 epoch 39 - iter 8/12 - loss 0.48343231 - samples/sec: 72.15 - lr: 0.000004
2021-07-18 12:31:38,820 epoch 39 - iter 9/12 - loss 0.48563265 - samples/sec: 70.73 - lr: 0.000004
2021-07-18 12:31:39,263 epoch 39 - iter 10/12 - loss 0.49436100 - samples/sec: 72.31 - lr: 0.000004
2021-07-18 12:31:39,716 epoch 39 - iter 11/12 - loss 0.50837344 - samples/sec: 70.70 - lr: 0.000004
2021-07-18 12:31:39,938 epoch 39 - iter 12/12 - loss 0.52713511 - samples/sec: 144.37 - lr: 0.000004
2021-07-18 12:31:39,938 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:39,938 EPOCH 39 done: loss 0.5271 - lr 0.0000038
2021-07-18 12:31:40,480 DEV : loss 0.8200733661651611 - score 0.7857
2021-07-18 12:31:40,488 BAD EPOCHS (no improvement): 1
2021-07-18 12:31:40,488 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:40,941 epoch 40 - iter 1/12 - loss 0.45570135 - samples/sec: 70.66 - lr: 0.000004
2021-07-18 12:31:41,385 epoch 40 - iter 2/12 - loss 0.45425797 - samples/sec: 72.28 - lr: 0.000004
2021-07-18 12:31:41,824 epoch 40 - iter 3/12 - loss 0.45188270 - samples/sec: 72.81 - lr: 0.000004
2021-07-18 12:31:42,284 epoch 40 - iter 4/12 - loss 0.46778502 - samples/sec: 69.73 - lr: 0.000004
2021-07-18 12:31:42,745 epoch 40 - iter 5/12 - loss 0.45371953 - samples/sec: 69.47 - lr: 0.000004
2021-07-18 12:31:43,182 epoch 40 - iter 6/12 - loss 0.46976192 - samples/sec: 73.19 - lr: 0.000004
2021-07-18 12:31:43,619 epoch 40 - iter 7/12 - loss 0.49280512 - samples/sec: 73.31 - lr: 0.000004
2021-07-18 12:31:44,068 epoch 40 - iter 8/12 - loss 0.51508839 - samples/sec: 71.45 - lr: 0.000004
2021-07-18 12:31:44,512 epoch 40 - iter 9/12 - loss 0.54652154 - samples/sec: 72.11 - lr: 0.000004
2021-07-18 12:31:44,972 epoch 40 - iter 10/12 - loss 0.52468060 - samples/sec: 69.55 - lr: 0.000004
2021-07-18 12:31:45,420 epoch 40 - iter 11/12 - loss 0.50933772 - samples/sec: 71.60 - lr: 0.000004
2021-07-18 12:31:45,636 epoch 40 - iter 12/12 - loss 0.49410191 - samples/sec: 147.85 - lr: 0.000004
2021-07-18 12:31:45,637 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:45,637 EPOCH 40 done: loss 0.4941 - lr 0.0000038
2021-07-18 12:31:46,176 DEV : loss 0.8220080137252808 - score 0.8
2021-07-18 12:31:46,184 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:31:50,644 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:50,644 Testing using best model ...
2021-07-18 12:31:50,645 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/zho.rst.sctb/best-model.pt
2021-07-18 12:31:53,012 0.9211	0.7527	0.8284
2021-07-18 12:31:53,012 
Results:
- F1-score (micro) 0.8284
- F1-score (macro) 0.8284

By class:
SENT       tp: 70 - fp: 6 - fn: 23 - precision: 0.9211 - recall: 0.7527 - f1-score: 0.8284
2021-07-18 12:31:53,012 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eus.rst.ert/
2021-07-18 12:31:53,020 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eus.rst.ert
2021-07-18 12:31:53,020 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eus.rst.ert/sent_train.txt
2021-07-18 12:31:53,020 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eus.rst.ert/sent_dev.txt
2021-07-18 12:31:53,022 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eus.rst.ert/sent_test.txt
Corpus: 1025 train + 356 dev + 490 test sentences
Dictionary with 6 tags: <unk>, O, B-SENT, ., <START>, <STOP>
2021-07-18 12:31:55,674 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:55,675 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(52000, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 12:31:55,675 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:55,675 Corpus: "Corpus: 1025 train + 356 dev + 490 test sentences"
2021-07-18 12:31:55,675 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:55,675 Parameters:
2021-07-18 12:31:55,675  - learning_rate: "3e-05"
2021-07-18 12:31:55,675  - mini_batch_size: "32"
2021-07-18 12:31:55,675  - patience: "3"
2021-07-18 12:31:55,675  - anneal_factor: "0.5"
2021-07-18 12:31:55,675  - max_epochs: "40"
2021-07-18 12:31:55,675  - shuffle: "True"
2021-07-18 12:31:55,675  - train_with_dev: "False"
2021-07-18 12:31:55,675  - batch_growth_annealing: "False"
2021-07-18 12:31:55,675 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:55,675 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eus.rst.ert"
2021-07-18 12:31:55,675 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:55,675 Device: cuda:0
2021-07-18 12:31:55,675 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:55,675 Embeddings storage mode: cpu
2021-07-18 12:31:55,677 ----------------------------------------------------------------------------------------------------
2021-07-18 12:31:58,127 epoch 1 - iter 3/33 - loss 23.38168844 - samples/sec: 39.19 - lr: 0.000030
2021-07-18 12:32:00,525 epoch 1 - iter 6/33 - loss 19.06815084 - samples/sec: 40.04 - lr: 0.000030
2021-07-18 12:32:03,075 epoch 1 - iter 9/33 - loss 16.08611520 - samples/sec: 37.65 - lr: 0.000030
2021-07-18 12:32:05,480 epoch 1 - iter 12/33 - loss 13.94966078 - samples/sec: 39.92 - lr: 0.000030
2021-07-18 12:32:07,885 epoch 1 - iter 15/33 - loss 12.43170026 - samples/sec: 39.93 - lr: 0.000030
2021-07-18 12:32:10,273 epoch 1 - iter 18/33 - loss 11.22995816 - samples/sec: 40.21 - lr: 0.000030
2021-07-18 12:32:12,637 epoch 1 - iter 21/33 - loss 10.33232296 - samples/sec: 40.61 - lr: 0.000030
2021-07-18 12:32:15,030 epoch 1 - iter 24/33 - loss 9.59590340 - samples/sec: 40.13 - lr: 0.000030
2021-07-18 12:32:17,401 epoch 1 - iter 27/33 - loss 8.94181750 - samples/sec: 40.50 - lr: 0.000030
2021-07-18 12:32:19,791 epoch 1 - iter 30/33 - loss 8.42704253 - samples/sec: 40.16 - lr: 0.000030
2021-07-18 12:32:21,444 epoch 1 - iter 33/33 - loss 8.00452115 - samples/sec: 58.12 - lr: 0.000030
2021-07-18 12:32:21,444 ----------------------------------------------------------------------------------------------------
2021-07-18 12:32:21,444 EPOCH 1 done: loss 8.0045 - lr 0.0000300
2021-07-18 12:32:26,425 DEV : loss 2.4917635917663574 - score 0.0372
2021-07-18 12:32:26,449 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:32:27,074 ----------------------------------------------------------------------------------------------------
2021-07-18 12:32:28,581 epoch 2 - iter 3/33 - loss 3.10924498 - samples/sec: 63.72 - lr: 0.000030
2021-07-18 12:32:30,079 epoch 2 - iter 6/33 - loss 3.03415930 - samples/sec: 64.12 - lr: 0.000030
2021-07-18 12:32:31,579 epoch 2 - iter 9/33 - loss 2.85319975 - samples/sec: 64.04 - lr: 0.000030
2021-07-18 12:32:33,103 epoch 2 - iter 12/33 - loss 2.76433386 - samples/sec: 62.98 - lr: 0.000030
2021-07-18 12:32:34,628 epoch 2 - iter 15/33 - loss 2.70026455 - samples/sec: 62.97 - lr: 0.000030
2021-07-18 12:32:36,101 epoch 2 - iter 18/33 - loss 2.56088639 - samples/sec: 65.22 - lr: 0.000030
2021-07-18 12:32:37,596 epoch 2 - iter 21/33 - loss 2.45605124 - samples/sec: 64.24 - lr: 0.000030
2021-07-18 12:32:39,109 epoch 2 - iter 24/33 - loss 2.34818277 - samples/sec: 63.45 - lr: 0.000030
2021-07-18 12:32:40,593 epoch 2 - iter 27/33 - loss 2.23994581 - samples/sec: 64.73 - lr: 0.000030
2021-07-18 12:32:42,086 epoch 2 - iter 30/33 - loss 2.15625960 - samples/sec: 64.33 - lr: 0.000030
2021-07-18 12:32:43,147 epoch 2 - iter 33/33 - loss 2.05812610 - samples/sec: 90.49 - lr: 0.000030
2021-07-18 12:32:43,147 ----------------------------------------------------------------------------------------------------
2021-07-18 12:32:43,148 EPOCH 2 done: loss 2.0581 - lr 0.0000300
2021-07-18 12:32:45,227 DEV : loss 0.8410653471946716 - score 0.8706
2021-07-18 12:32:45,252 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:32:48,307 ----------------------------------------------------------------------------------------------------
2021-07-18 12:32:49,826 epoch 3 - iter 3/33 - loss 1.45421203 - samples/sec: 63.23 - lr: 0.000030
2021-07-18 12:32:51,348 epoch 3 - iter 6/33 - loss 1.33126779 - samples/sec: 63.11 - lr: 0.000030
2021-07-18 12:32:52,862 epoch 3 - iter 9/33 - loss 1.26674704 - samples/sec: 63.40 - lr: 0.000030
2021-07-18 12:32:54,326 epoch 3 - iter 12/33 - loss 1.21004715 - samples/sec: 65.64 - lr: 0.000030
2021-07-18 12:32:55,828 epoch 3 - iter 15/33 - loss 1.16270674 - samples/sec: 63.89 - lr: 0.000030
2021-07-18 12:32:57,319 epoch 3 - iter 18/33 - loss 1.11244934 - samples/sec: 64.44 - lr: 0.000030
2021-07-18 12:32:58,793 epoch 3 - iter 21/33 - loss 1.08880495 - samples/sec: 65.12 - lr: 0.000030
2021-07-18 12:33:00,288 epoch 3 - iter 24/33 - loss 1.09228338 - samples/sec: 64.27 - lr: 0.000030
2021-07-18 12:33:01,800 epoch 3 - iter 27/33 - loss 1.05060434 - samples/sec: 63.50 - lr: 0.000030
2021-07-18 12:33:03,280 epoch 3 - iter 30/33 - loss 1.04046317 - samples/sec: 64.86 - lr: 0.000030
2021-07-18 12:33:04,362 epoch 3 - iter 33/33 - loss 1.01892774 - samples/sec: 88.82 - lr: 0.000030
2021-07-18 12:33:04,362 ----------------------------------------------------------------------------------------------------
2021-07-18 12:33:04,362 EPOCH 3 done: loss 1.0189 - lr 0.0000300
2021-07-18 12:33:06,288 DEV : loss 0.6243022680282593 - score 0.8981
2021-07-18 12:33:06,313 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:33:09,341 ----------------------------------------------------------------------------------------------------
2021-07-18 12:33:10,849 epoch 4 - iter 3/33 - loss 0.77405894 - samples/sec: 63.69 - lr: 0.000030
2021-07-18 12:33:12,330 epoch 4 - iter 6/33 - loss 0.72765097 - samples/sec: 64.85 - lr: 0.000030
2021-07-18 12:33:13,856 epoch 4 - iter 9/33 - loss 0.79777339 - samples/sec: 62.91 - lr: 0.000030
2021-07-18 12:33:15,350 epoch 4 - iter 12/33 - loss 0.80250447 - samples/sec: 64.27 - lr: 0.000030
2021-07-18 12:33:16,855 epoch 4 - iter 15/33 - loss 0.81551465 - samples/sec: 63.81 - lr: 0.000030
2021-07-18 12:33:18,328 epoch 4 - iter 18/33 - loss 0.80032550 - samples/sec: 65.19 - lr: 0.000030
2021-07-18 12:33:19,815 epoch 4 - iter 21/33 - loss 0.82150769 - samples/sec: 64.60 - lr: 0.000030
2021-07-18 12:33:21,289 epoch 4 - iter 24/33 - loss 0.79817567 - samples/sec: 65.13 - lr: 0.000030
2021-07-18 12:33:22,801 epoch 4 - iter 27/33 - loss 0.78505652 - samples/sec: 63.54 - lr: 0.000030
2021-07-18 12:33:24,283 epoch 4 - iter 30/33 - loss 0.78873042 - samples/sec: 64.77 - lr: 0.000030
2021-07-18 12:33:25,361 epoch 4 - iter 33/33 - loss 0.76263224 - samples/sec: 89.09 - lr: 0.000030
2021-07-18 12:33:25,362 ----------------------------------------------------------------------------------------------------
2021-07-18 12:33:25,362 EPOCH 4 done: loss 0.7626 - lr 0.0000300
2021-07-18 12:33:27,290 DEV : loss 0.5921887159347534 - score 0.9033
2021-07-18 12:33:27,315 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:33:30,357 ----------------------------------------------------------------------------------------------------
2021-07-18 12:33:31,869 epoch 5 - iter 3/33 - loss 0.87472379 - samples/sec: 63.55 - lr: 0.000030
2021-07-18 12:33:33,348 epoch 5 - iter 6/33 - loss 0.89542256 - samples/sec: 64.92 - lr: 0.000030
2021-07-18 12:33:34,851 epoch 5 - iter 9/33 - loss 0.80455689 - samples/sec: 63.92 - lr: 0.000030
2021-07-18 12:33:36,357 epoch 5 - iter 12/33 - loss 0.77891051 - samples/sec: 63.75 - lr: 0.000030
2021-07-18 12:33:37,849 epoch 5 - iter 15/33 - loss 0.77210605 - samples/sec: 64.39 - lr: 0.000030
2021-07-18 12:33:39,366 epoch 5 - iter 18/33 - loss 0.76334808 - samples/sec: 63.27 - lr: 0.000030
2021-07-18 12:33:40,887 epoch 5 - iter 21/33 - loss 0.75124050 - samples/sec: 63.15 - lr: 0.000030
2021-07-18 12:33:42,381 epoch 5 - iter 24/33 - loss 0.72471083 - samples/sec: 64.26 - lr: 0.000030
2021-07-18 12:33:43,890 epoch 5 - iter 27/33 - loss 0.70074517 - samples/sec: 63.65 - lr: 0.000030
2021-07-18 12:33:45,427 epoch 5 - iter 30/33 - loss 0.70177844 - samples/sec: 62.50 - lr: 0.000030
2021-07-18 12:33:46,500 epoch 5 - iter 33/33 - loss 0.67915892 - samples/sec: 89.47 - lr: 0.000030
2021-07-18 12:33:46,501 ----------------------------------------------------------------------------------------------------
2021-07-18 12:33:46,501 EPOCH 5 done: loss 0.6792 - lr 0.0000300
2021-07-18 12:33:48,579 DEV : loss 0.49617213010787964 - score 0.9214
2021-07-18 12:33:48,604 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:33:51,634 ----------------------------------------------------------------------------------------------------
2021-07-18 12:33:53,162 epoch 6 - iter 3/33 - loss 0.59834462 - samples/sec: 62.86 - lr: 0.000030
2021-07-18 12:33:54,678 epoch 6 - iter 6/33 - loss 0.61987683 - samples/sec: 63.35 - lr: 0.000030
2021-07-18 12:33:56,214 epoch 6 - iter 9/33 - loss 0.63220724 - samples/sec: 62.54 - lr: 0.000030
2021-07-18 12:33:57,727 epoch 6 - iter 12/33 - loss 0.61055088 - samples/sec: 63.47 - lr: 0.000030
2021-07-18 12:33:59,224 epoch 6 - iter 15/33 - loss 0.56392412 - samples/sec: 64.14 - lr: 0.000030
2021-07-18 12:34:00,732 epoch 6 - iter 18/33 - loss 0.58622112 - samples/sec: 63.71 - lr: 0.000030
2021-07-18 12:34:02,240 epoch 6 - iter 21/33 - loss 0.59602689 - samples/sec: 63.67 - lr: 0.000030
2021-07-18 12:34:03,778 epoch 6 - iter 24/33 - loss 0.60195372 - samples/sec: 62.46 - lr: 0.000030
2021-07-18 12:34:05,311 epoch 6 - iter 27/33 - loss 0.59821165 - samples/sec: 62.64 - lr: 0.000030
2021-07-18 12:34:06,807 epoch 6 - iter 30/33 - loss 0.60894949 - samples/sec: 64.18 - lr: 0.000030
2021-07-18 12:34:07,848 epoch 6 - iter 33/33 - loss 0.59977506 - samples/sec: 92.23 - lr: 0.000030
2021-07-18 12:34:07,849 ----------------------------------------------------------------------------------------------------
2021-07-18 12:34:07,849 EPOCH 6 done: loss 0.5998 - lr 0.0000300
2021-07-18 12:34:09,778 DEV : loss 0.45842692255973816 - score 0.9293
2021-07-18 12:34:09,803 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:34:12,747 ----------------------------------------------------------------------------------------------------
2021-07-18 12:34:14,229 epoch 7 - iter 3/33 - loss 0.50939177 - samples/sec: 64.84 - lr: 0.000030
2021-07-18 12:34:15,736 epoch 7 - iter 6/33 - loss 0.56073256 - samples/sec: 63.70 - lr: 0.000030
2021-07-18 12:34:17,239 epoch 7 - iter 9/33 - loss 0.60619057 - samples/sec: 63.90 - lr: 0.000030
2021-07-18 12:34:18,743 epoch 7 - iter 12/33 - loss 0.61006351 - samples/sec: 63.84 - lr: 0.000030
2021-07-18 12:34:20,274 epoch 7 - iter 15/33 - loss 0.60226220 - samples/sec: 62.74 - lr: 0.000030
2021-07-18 12:34:21,802 epoch 7 - iter 18/33 - loss 0.57888148 - samples/sec: 62.83 - lr: 0.000030
2021-07-18 12:34:23,334 epoch 7 - iter 21/33 - loss 0.57534641 - samples/sec: 62.70 - lr: 0.000030
2021-07-18 12:34:24,857 epoch 7 - iter 24/33 - loss 0.56690953 - samples/sec: 63.04 - lr: 0.000030
2021-07-18 12:34:26,403 epoch 7 - iter 27/33 - loss 0.55477938 - samples/sec: 62.14 - lr: 0.000030
2021-07-18 12:34:27,950 epoch 7 - iter 30/33 - loss 0.55371762 - samples/sec: 62.06 - lr: 0.000030
2021-07-18 12:34:29,028 epoch 7 - iter 33/33 - loss 0.56244677 - samples/sec: 89.12 - lr: 0.000030
2021-07-18 12:34:29,028 ----------------------------------------------------------------------------------------------------
2021-07-18 12:34:29,028 EPOCH 7 done: loss 0.5624 - lr 0.0000300
2021-07-18 12:34:30,965 DEV : loss 0.4415425658226013 - score 0.93
2021-07-18 12:34:30,990 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:34:34,143 ----------------------------------------------------------------------------------------------------
2021-07-18 12:34:35,658 epoch 8 - iter 3/33 - loss 0.40791936 - samples/sec: 63.43 - lr: 0.000030
2021-07-18 12:34:37,184 epoch 8 - iter 6/33 - loss 0.44441165 - samples/sec: 62.92 - lr: 0.000030
2021-07-18 12:34:38,701 epoch 8 - iter 9/33 - loss 0.45499401 - samples/sec: 63.32 - lr: 0.000030
2021-07-18 12:34:40,196 epoch 8 - iter 12/33 - loss 0.45840168 - samples/sec: 64.22 - lr: 0.000030
2021-07-18 12:34:41,751 epoch 8 - iter 15/33 - loss 0.44674443 - samples/sec: 61.74 - lr: 0.000030
2021-07-18 12:34:43,258 epoch 8 - iter 18/33 - loss 0.44963022 - samples/sec: 63.72 - lr: 0.000030
2021-07-18 12:34:44,786 epoch 8 - iter 21/33 - loss 0.46780906 - samples/sec: 62.85 - lr: 0.000030
2021-07-18 12:34:46,309 epoch 8 - iter 24/33 - loss 0.48580154 - samples/sec: 63.05 - lr: 0.000030
2021-07-18 12:34:47,819 epoch 8 - iter 27/33 - loss 0.48904928 - samples/sec: 63.60 - lr: 0.000030
2021-07-18 12:34:49,335 epoch 8 - iter 30/33 - loss 0.49649877 - samples/sec: 63.34 - lr: 0.000030
2021-07-18 12:34:50,395 epoch 8 - iter 33/33 - loss 0.48167590 - samples/sec: 90.66 - lr: 0.000030
2021-07-18 12:34:50,395 ----------------------------------------------------------------------------------------------------
2021-07-18 12:34:50,395 EPOCH 8 done: loss 0.4817 - lr 0.0000300
2021-07-18 12:34:52,326 DEV : loss 0.43016988039016724 - score 0.9311
2021-07-18 12:34:52,350 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:34:55,681 ----------------------------------------------------------------------------------------------------
2021-07-18 12:34:57,213 epoch 9 - iter 3/33 - loss 0.56255233 - samples/sec: 62.70 - lr: 0.000030
2021-07-18 12:34:58,731 epoch 9 - iter 6/33 - loss 0.50195796 - samples/sec: 63.27 - lr: 0.000030
2021-07-18 12:35:00,242 epoch 9 - iter 9/33 - loss 0.47645212 - samples/sec: 63.58 - lr: 0.000030
2021-07-18 12:35:01,779 epoch 9 - iter 12/33 - loss 0.47446862 - samples/sec: 62.47 - lr: 0.000030
2021-07-18 12:35:03,323 epoch 9 - iter 15/33 - loss 0.48894556 - samples/sec: 62.21 - lr: 0.000030
2021-07-18 12:35:04,824 epoch 9 - iter 18/33 - loss 0.46267216 - samples/sec: 63.98 - lr: 0.000030
2021-07-18 12:35:06,343 epoch 9 - iter 21/33 - loss 0.44200399 - samples/sec: 63.22 - lr: 0.000030
2021-07-18 12:35:07,843 epoch 9 - iter 24/33 - loss 0.44131565 - samples/sec: 64.02 - lr: 0.000030
2021-07-18 12:35:09,394 epoch 9 - iter 27/33 - loss 0.43942964 - samples/sec: 61.92 - lr: 0.000030
2021-07-18 12:35:10,875 epoch 9 - iter 30/33 - loss 0.43757475 - samples/sec: 64.81 - lr: 0.000030
2021-07-18 12:35:11,960 epoch 9 - iter 33/33 - loss 0.43345430 - samples/sec: 88.54 - lr: 0.000030
2021-07-18 12:35:11,960 ----------------------------------------------------------------------------------------------------
2021-07-18 12:35:11,960 EPOCH 9 done: loss 0.4335 - lr 0.0000300
2021-07-18 12:35:14,041 DEV : loss 0.4286351799964905 - score 0.9317
2021-07-18 12:35:14,066 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:35:17,030 ----------------------------------------------------------------------------------------------------
2021-07-18 12:35:18,552 epoch 10 - iter 3/33 - loss 0.32441660 - samples/sec: 63.11 - lr: 0.000030
2021-07-18 12:35:20,039 epoch 10 - iter 6/33 - loss 0.42508427 - samples/sec: 64.56 - lr: 0.000030
2021-07-18 12:35:21,535 epoch 10 - iter 9/33 - loss 0.37552398 - samples/sec: 64.22 - lr: 0.000030
2021-07-18 12:35:23,063 epoch 10 - iter 12/33 - loss 0.38595626 - samples/sec: 62.84 - lr: 0.000030
2021-07-18 12:35:24,579 epoch 10 - iter 15/33 - loss 0.40599432 - samples/sec: 63.33 - lr: 0.000030
2021-07-18 12:35:26,118 epoch 10 - iter 18/33 - loss 0.40522430 - samples/sec: 62.40 - lr: 0.000030
2021-07-18 12:35:27,630 epoch 10 - iter 21/33 - loss 0.39669322 - samples/sec: 63.49 - lr: 0.000030
2021-07-18 12:35:29,155 epoch 10 - iter 24/33 - loss 0.38907579 - samples/sec: 63.00 - lr: 0.000030
2021-07-18 12:35:30,659 epoch 10 - iter 27/33 - loss 0.39759602 - samples/sec: 63.84 - lr: 0.000030
2021-07-18 12:35:32,151 epoch 10 - iter 30/33 - loss 0.39113859 - samples/sec: 64.35 - lr: 0.000030
2021-07-18 12:35:33,196 epoch 10 - iter 33/33 - loss 0.38705979 - samples/sec: 91.97 - lr: 0.000030
2021-07-18 12:35:33,196 ----------------------------------------------------------------------------------------------------
2021-07-18 12:35:33,196 EPOCH 10 done: loss 0.3871 - lr 0.0000300
2021-07-18 12:35:35,128 DEV : loss 0.4185534119606018 - score 0.9399
2021-07-18 12:35:35,153 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:35:38,157 ----------------------------------------------------------------------------------------------------
2021-07-18 12:35:39,648 epoch 11 - iter 3/33 - loss 0.36898653 - samples/sec: 64.45 - lr: 0.000030
2021-07-18 12:35:41,162 epoch 11 - iter 6/33 - loss 0.38294518 - samples/sec: 63.42 - lr: 0.000030
2021-07-18 12:35:42,653 epoch 11 - iter 9/33 - loss 0.35252711 - samples/sec: 64.39 - lr: 0.000030
2021-07-18 12:35:44,138 epoch 11 - iter 12/33 - loss 0.38587004 - samples/sec: 64.70 - lr: 0.000030
2021-07-18 12:35:45,651 epoch 11 - iter 15/33 - loss 0.40376693 - samples/sec: 63.47 - lr: 0.000030
2021-07-18 12:35:47,117 epoch 11 - iter 18/33 - loss 0.39328494 - samples/sec: 65.49 - lr: 0.000030
2021-07-18 12:35:48,620 epoch 11 - iter 21/33 - loss 0.39441836 - samples/sec: 63.91 - lr: 0.000030
2021-07-18 12:35:50,096 epoch 11 - iter 24/33 - loss 0.38728315 - samples/sec: 65.03 - lr: 0.000030
2021-07-18 12:35:51,602 epoch 11 - iter 27/33 - loss 0.39779238 - samples/sec: 63.78 - lr: 0.000030
2021-07-18 12:35:53,118 epoch 11 - iter 30/33 - loss 0.38920305 - samples/sec: 63.34 - lr: 0.000030
2021-07-18 12:35:54,194 epoch 11 - iter 33/33 - loss 0.42859625 - samples/sec: 89.26 - lr: 0.000030
2021-07-18 12:35:54,194 ----------------------------------------------------------------------------------------------------
2021-07-18 12:35:54,194 EPOCH 11 done: loss 0.4286 - lr 0.0000300
2021-07-18 12:35:56,128 DEV : loss 0.41448312997817993 - score 0.9324
2021-07-18 12:35:56,153 BAD EPOCHS (no improvement): 1
2021-07-18 12:35:56,154 ----------------------------------------------------------------------------------------------------
2021-07-18 12:35:57,622 epoch 12 - iter 3/33 - loss 0.21812459 - samples/sec: 65.40 - lr: 0.000030
2021-07-18 12:35:59,127 epoch 12 - iter 6/33 - loss 0.31349995 - samples/sec: 63.83 - lr: 0.000030
2021-07-18 12:36:00,576 epoch 12 - iter 9/33 - loss 0.31456800 - samples/sec: 66.24 - lr: 0.000030
2021-07-18 12:36:02,114 epoch 12 - iter 12/33 - loss 0.32080818 - samples/sec: 62.44 - lr: 0.000030
2021-07-18 12:36:03,623 epoch 12 - iter 15/33 - loss 0.31886482 - samples/sec: 63.67 - lr: 0.000030
2021-07-18 12:36:05,139 epoch 12 - iter 18/33 - loss 0.34103480 - samples/sec: 63.34 - lr: 0.000030
2021-07-18 12:36:06,657 epoch 12 - iter 21/33 - loss 0.35058337 - samples/sec: 63.25 - lr: 0.000030
2021-07-18 12:36:08,137 epoch 12 - iter 24/33 - loss 0.34297054 - samples/sec: 64.87 - lr: 0.000030
2021-07-18 12:36:09,613 epoch 12 - iter 27/33 - loss 0.36458112 - samples/sec: 65.09 - lr: 0.000030
2021-07-18 12:36:11,115 epoch 12 - iter 30/33 - loss 0.37159132 - samples/sec: 63.92 - lr: 0.000030
2021-07-18 12:36:12,192 epoch 12 - iter 33/33 - loss 0.35964629 - samples/sec: 89.24 - lr: 0.000030
2021-07-18 12:36:12,192 ----------------------------------------------------------------------------------------------------
2021-07-18 12:36:12,192 EPOCH 12 done: loss 0.3596 - lr 0.0000300
2021-07-18 12:36:14,129 DEV : loss 0.4159529209136963 - score 0.9359
2021-07-18 12:36:14,154 BAD EPOCHS (no improvement): 2
2021-07-18 12:36:14,154 ----------------------------------------------------------------------------------------------------
2021-07-18 12:36:15,802 epoch 13 - iter 3/33 - loss 0.34102555 - samples/sec: 58.29 - lr: 0.000030
2021-07-18 12:36:17,336 epoch 13 - iter 6/33 - loss 0.37664873 - samples/sec: 62.59 - lr: 0.000030
2021-07-18 12:36:18,845 epoch 13 - iter 9/33 - loss 0.35090452 - samples/sec: 63.62 - lr: 0.000030
2021-07-18 12:36:20,358 epoch 13 - iter 12/33 - loss 0.32695850 - samples/sec: 63.48 - lr: 0.000030
2021-07-18 12:36:21,875 epoch 13 - iter 15/33 - loss 0.33588979 - samples/sec: 63.30 - lr: 0.000030
2021-07-18 12:36:23,407 epoch 13 - iter 18/33 - loss 0.38282861 - samples/sec: 62.70 - lr: 0.000030
2021-07-18 12:36:24,935 epoch 13 - iter 21/33 - loss 0.37552522 - samples/sec: 62.84 - lr: 0.000030
2021-07-18 12:36:26,469 epoch 13 - iter 24/33 - loss 0.36207969 - samples/sec: 62.58 - lr: 0.000030
2021-07-18 12:36:27,989 epoch 13 - iter 27/33 - loss 0.35870887 - samples/sec: 63.18 - lr: 0.000030
2021-07-18 12:36:29,499 epoch 13 - iter 30/33 - loss 0.34894800 - samples/sec: 63.63 - lr: 0.000030
2021-07-18 12:36:30,568 epoch 13 - iter 33/33 - loss 0.34914430 - samples/sec: 89.81 - lr: 0.000030
2021-07-18 12:36:30,568 ----------------------------------------------------------------------------------------------------
2021-07-18 12:36:30,568 EPOCH 13 done: loss 0.3491 - lr 0.0000300
2021-07-18 12:36:32,503 DEV : loss 0.3932071924209595 - score 0.941
2021-07-18 12:36:32,529 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:36:35,672 ----------------------------------------------------------------------------------------------------
2021-07-18 12:36:37,177 epoch 14 - iter 3/33 - loss 0.24990495 - samples/sec: 63.80 - lr: 0.000030
2021-07-18 12:36:38,660 epoch 14 - iter 6/33 - loss 0.28514781 - samples/sec: 64.78 - lr: 0.000030
2021-07-18 12:36:40,186 epoch 14 - iter 9/33 - loss 0.30956429 - samples/sec: 62.90 - lr: 0.000030
2021-07-18 12:36:41,702 epoch 14 - iter 12/33 - loss 0.30515661 - samples/sec: 63.37 - lr: 0.000030
2021-07-18 12:36:43,227 epoch 14 - iter 15/33 - loss 0.31267801 - samples/sec: 62.99 - lr: 0.000030
2021-07-18 12:36:44,735 epoch 14 - iter 18/33 - loss 0.32569380 - samples/sec: 63.67 - lr: 0.000030
2021-07-18 12:36:46,262 epoch 14 - iter 21/33 - loss 0.32715281 - samples/sec: 62.86 - lr: 0.000030
2021-07-18 12:36:47,791 epoch 14 - iter 24/33 - loss 0.33138694 - samples/sec: 62.81 - lr: 0.000030
2021-07-18 12:36:49,323 epoch 14 - iter 27/33 - loss 0.34727172 - samples/sec: 62.70 - lr: 0.000030
2021-07-18 12:36:50,825 epoch 14 - iter 30/33 - loss 0.33747191 - samples/sec: 63.92 - lr: 0.000030
2021-07-18 12:36:51,889 epoch 14 - iter 33/33 - loss 0.32265611 - samples/sec: 90.26 - lr: 0.000030
2021-07-18 12:36:51,890 ----------------------------------------------------------------------------------------------------
2021-07-18 12:36:51,890 EPOCH 14 done: loss 0.3227 - lr 0.0000300
2021-07-18 12:36:53,821 DEV : loss 0.39600953459739685 - score 0.9426
2021-07-18 12:36:53,846 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:36:56,975 ----------------------------------------------------------------------------------------------------
2021-07-18 12:36:58,471 epoch 15 - iter 3/33 - loss 0.35600996 - samples/sec: 64.20 - lr: 0.000030
2021-07-18 12:36:59,995 epoch 15 - iter 6/33 - loss 0.29884161 - samples/sec: 63.04 - lr: 0.000030
2021-07-18 12:37:01,494 epoch 15 - iter 9/33 - loss 0.27260988 - samples/sec: 64.03 - lr: 0.000030
2021-07-18 12:37:03,001 epoch 15 - iter 12/33 - loss 0.27863173 - samples/sec: 63.73 - lr: 0.000030
2021-07-18 12:37:04,539 epoch 15 - iter 15/33 - loss 0.29267180 - samples/sec: 62.46 - lr: 0.000030
2021-07-18 12:37:06,059 epoch 15 - iter 18/33 - loss 0.28346811 - samples/sec: 63.17 - lr: 0.000030
2021-07-18 12:37:07,582 epoch 15 - iter 21/33 - loss 0.28146338 - samples/sec: 63.04 - lr: 0.000030
2021-07-18 12:37:09,096 epoch 15 - iter 24/33 - loss 0.28024835 - samples/sec: 63.45 - lr: 0.000030
2021-07-18 12:37:10,590 epoch 15 - iter 27/33 - loss 0.27382728 - samples/sec: 64.28 - lr: 0.000030
2021-07-18 12:37:12,096 epoch 15 - iter 30/33 - loss 0.28771223 - samples/sec: 63.75 - lr: 0.000030
2021-07-18 12:37:13,206 epoch 15 - iter 33/33 - loss 0.28259161 - samples/sec: 86.56 - lr: 0.000030
2021-07-18 12:37:13,206 ----------------------------------------------------------------------------------------------------
2021-07-18 12:37:13,206 EPOCH 15 done: loss 0.2826 - lr 0.0000300
2021-07-18 12:37:15,134 DEV : loss 0.40301820635795593 - score 0.9384
2021-07-18 12:37:15,159 BAD EPOCHS (no improvement): 1
2021-07-18 12:37:15,160 ----------------------------------------------------------------------------------------------------
2021-07-18 12:37:16,627 epoch 16 - iter 3/33 - loss 0.21560538 - samples/sec: 65.45 - lr: 0.000030
2021-07-18 12:37:18,131 epoch 16 - iter 6/33 - loss 0.27441341 - samples/sec: 63.84 - lr: 0.000030
2021-07-18 12:37:19,655 epoch 16 - iter 9/33 - loss 0.28832028 - samples/sec: 63.03 - lr: 0.000030
2021-07-18 12:37:21,146 epoch 16 - iter 12/33 - loss 0.27933786 - samples/sec: 64.39 - lr: 0.000030
2021-07-18 12:37:22,697 epoch 16 - iter 15/33 - loss 0.29102525 - samples/sec: 61.93 - lr: 0.000030
2021-07-18 12:37:24,211 epoch 16 - iter 18/33 - loss 0.27729667 - samples/sec: 63.43 - lr: 0.000030
2021-07-18 12:37:25,719 epoch 16 - iter 21/33 - loss 0.28187474 - samples/sec: 63.67 - lr: 0.000030
2021-07-18 12:37:27,231 epoch 16 - iter 24/33 - loss 0.29309222 - samples/sec: 63.52 - lr: 0.000030
2021-07-18 12:37:28,782 epoch 16 - iter 27/33 - loss 0.29076238 - samples/sec: 61.91 - lr: 0.000030
2021-07-18 12:37:30,306 epoch 16 - iter 30/33 - loss 0.28440168 - samples/sec: 63.01 - lr: 0.000030
2021-07-18 12:37:31,530 epoch 16 - iter 33/33 - loss 0.27444909 - samples/sec: 78.48 - lr: 0.000030
2021-07-18 12:37:31,530 ----------------------------------------------------------------------------------------------------
2021-07-18 12:37:31,530 EPOCH 16 done: loss 0.2744 - lr 0.0000300
2021-07-18 12:37:33,460 DEV : loss 0.3963997960090637 - score 0.937
2021-07-18 12:37:33,485 BAD EPOCHS (no improvement): 2
2021-07-18 12:37:33,485 ----------------------------------------------------------------------------------------------------
2021-07-18 12:37:34,955 epoch 17 - iter 3/33 - loss 0.23957703 - samples/sec: 65.36 - lr: 0.000030
2021-07-18 12:37:36,453 epoch 17 - iter 6/33 - loss 0.27902472 - samples/sec: 64.08 - lr: 0.000030
2021-07-18 12:37:37,984 epoch 17 - iter 9/33 - loss 0.30949636 - samples/sec: 62.72 - lr: 0.000030
2021-07-18 12:37:39,504 epoch 17 - iter 12/33 - loss 0.31325756 - samples/sec: 63.19 - lr: 0.000030
2021-07-18 12:37:41,033 epoch 17 - iter 15/33 - loss 0.32433407 - samples/sec: 62.81 - lr: 0.000030
2021-07-18 12:37:42,545 epoch 17 - iter 18/33 - loss 0.29973983 - samples/sec: 63.51 - lr: 0.000030
2021-07-18 12:37:44,055 epoch 17 - iter 21/33 - loss 0.30171305 - samples/sec: 63.63 - lr: 0.000030
2021-07-18 12:37:45,570 epoch 17 - iter 24/33 - loss 0.29405159 - samples/sec: 63.37 - lr: 0.000030
2021-07-18 12:37:47,105 epoch 17 - iter 27/33 - loss 0.29104175 - samples/sec: 62.56 - lr: 0.000030
2021-07-18 12:37:48,627 epoch 17 - iter 30/33 - loss 0.29023367 - samples/sec: 63.10 - lr: 0.000030
2021-07-18 12:37:49,711 epoch 17 - iter 33/33 - loss 0.28350315 - samples/sec: 88.64 - lr: 0.000030
2021-07-18 12:37:49,711 ----------------------------------------------------------------------------------------------------
2021-07-18 12:37:49,711 EPOCH 17 done: loss 0.2835 - lr 0.0000300
2021-07-18 12:37:51,642 DEV : loss 0.37897294759750366 - score 0.9397
2021-07-18 12:37:51,667 BAD EPOCHS (no improvement): 3
2021-07-18 12:37:51,667 ----------------------------------------------------------------------------------------------------
2021-07-18 12:37:53,189 epoch 18 - iter 3/33 - loss 0.28716826 - samples/sec: 63.09 - lr: 0.000030
2021-07-18 12:37:54,691 epoch 18 - iter 6/33 - loss 0.24713999 - samples/sec: 63.97 - lr: 0.000030
2021-07-18 12:37:56,206 epoch 18 - iter 9/33 - loss 0.24052088 - samples/sec: 63.37 - lr: 0.000030
2021-07-18 12:37:57,737 epoch 18 - iter 12/33 - loss 0.23879166 - samples/sec: 62.72 - lr: 0.000030
2021-07-18 12:37:59,216 epoch 18 - iter 15/33 - loss 0.25499557 - samples/sec: 64.93 - lr: 0.000030
2021-07-18 12:38:00,727 epoch 18 - iter 18/33 - loss 0.26634882 - samples/sec: 63.58 - lr: 0.000030
2021-07-18 12:38:02,231 epoch 18 - iter 21/33 - loss 0.28277867 - samples/sec: 63.83 - lr: 0.000030
2021-07-18 12:38:03,761 epoch 18 - iter 24/33 - loss 0.28790777 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 12:38:05,282 epoch 18 - iter 27/33 - loss 0.27887893 - samples/sec: 63.15 - lr: 0.000030
2021-07-18 12:38:06,775 epoch 18 - iter 30/33 - loss 0.28810382 - samples/sec: 64.34 - lr: 0.000030
2021-07-18 12:38:07,879 epoch 18 - iter 33/33 - loss 0.27685553 - samples/sec: 86.98 - lr: 0.000030
2021-07-18 12:38:07,879 ----------------------------------------------------------------------------------------------------
2021-07-18 12:38:07,879 EPOCH 18 done: loss 0.2769 - lr 0.0000300
2021-07-18 12:38:09,819 DEV : loss 0.37727639079093933 - score 0.9421
Epoch    18: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 12:38:09,844 BAD EPOCHS (no improvement): 4
2021-07-18 12:38:09,845 ----------------------------------------------------------------------------------------------------
2021-07-18 12:38:11,334 epoch 19 - iter 3/33 - loss 0.22838018 - samples/sec: 64.46 - lr: 0.000015
2021-07-18 12:38:12,876 epoch 19 - iter 6/33 - loss 0.26957986 - samples/sec: 62.27 - lr: 0.000015
2021-07-18 12:38:14,383 epoch 19 - iter 9/33 - loss 0.26907632 - samples/sec: 63.73 - lr: 0.000015
2021-07-18 12:38:15,874 epoch 19 - iter 12/33 - loss 0.27696469 - samples/sec: 64.41 - lr: 0.000015
2021-07-18 12:38:17,378 epoch 19 - iter 15/33 - loss 0.26103499 - samples/sec: 63.86 - lr: 0.000015
2021-07-18 12:38:18,902 epoch 19 - iter 18/33 - loss 0.26758049 - samples/sec: 63.01 - lr: 0.000015
2021-07-18 12:38:20,431 epoch 19 - iter 21/33 - loss 0.26011986 - samples/sec: 62.82 - lr: 0.000015
2021-07-18 12:38:21,930 epoch 19 - iter 24/33 - loss 0.27859570 - samples/sec: 64.06 - lr: 0.000015
2021-07-18 12:38:23,443 epoch 19 - iter 27/33 - loss 0.26757210 - samples/sec: 63.45 - lr: 0.000015
2021-07-18 12:38:24,987 epoch 19 - iter 30/33 - loss 0.27321294 - samples/sec: 62.20 - lr: 0.000015
2021-07-18 12:38:26,055 epoch 19 - iter 33/33 - loss 0.26183703 - samples/sec: 89.91 - lr: 0.000015
2021-07-18 12:38:26,056 ----------------------------------------------------------------------------------------------------
2021-07-18 12:38:26,056 EPOCH 19 done: loss 0.2618 - lr 0.0000150
2021-07-18 12:38:28,148 DEV : loss 0.37819886207580566 - score 0.9423
2021-07-18 12:38:28,173 BAD EPOCHS (no improvement): 1
2021-07-18 12:38:28,173 ----------------------------------------------------------------------------------------------------
2021-07-18 12:38:29,654 epoch 20 - iter 3/33 - loss 0.36444419 - samples/sec: 64.84 - lr: 0.000015
2021-07-18 12:38:31,191 epoch 20 - iter 6/33 - loss 0.28342534 - samples/sec: 62.55 - lr: 0.000015
2021-07-18 12:38:32,666 epoch 20 - iter 9/33 - loss 0.25139353 - samples/sec: 65.07 - lr: 0.000015
2021-07-18 12:38:34,154 epoch 20 - iter 12/33 - loss 0.24070150 - samples/sec: 64.55 - lr: 0.000015
2021-07-18 12:38:35,695 epoch 20 - iter 15/33 - loss 0.26175874 - samples/sec: 62.31 - lr: 0.000015
2021-07-18 12:38:37,236 epoch 20 - iter 18/33 - loss 0.26642705 - samples/sec: 62.34 - lr: 0.000015
2021-07-18 12:38:38,771 epoch 20 - iter 21/33 - loss 0.25578243 - samples/sec: 62.56 - lr: 0.000015
2021-07-18 12:38:40,290 epoch 20 - iter 24/33 - loss 0.24804259 - samples/sec: 63.20 - lr: 0.000015
2021-07-18 12:38:41,801 epoch 20 - iter 27/33 - loss 0.23977364 - samples/sec: 63.55 - lr: 0.000015
2021-07-18 12:38:43,318 epoch 20 - iter 30/33 - loss 0.24200465 - samples/sec: 63.31 - lr: 0.000015
2021-07-18 12:38:44,400 epoch 20 - iter 33/33 - loss 0.23727449 - samples/sec: 88.75 - lr: 0.000015
2021-07-18 12:38:44,401 ----------------------------------------------------------------------------------------------------
2021-07-18 12:38:44,401 EPOCH 20 done: loss 0.2373 - lr 0.0000150
2021-07-18 12:38:46,343 DEV : loss 0.37454769015312195 - score 0.9451
2021-07-18 12:38:46,368 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:38:49,478 ----------------------------------------------------------------------------------------------------
2021-07-18 12:38:50,991 epoch 21 - iter 3/33 - loss 0.21662022 - samples/sec: 63.50 - lr: 0.000015
2021-07-18 12:38:52,525 epoch 21 - iter 6/33 - loss 0.20640690 - samples/sec: 62.60 - lr: 0.000015
2021-07-18 12:38:54,055 epoch 21 - iter 9/33 - loss 0.18822121 - samples/sec: 62.77 - lr: 0.000015
2021-07-18 12:38:55,563 epoch 21 - iter 12/33 - loss 0.20926587 - samples/sec: 63.67 - lr: 0.000015
2021-07-18 12:38:57,070 epoch 21 - iter 15/33 - loss 0.20114456 - samples/sec: 63.73 - lr: 0.000015
2021-07-18 12:38:58,571 epoch 21 - iter 18/33 - loss 0.22833822 - samples/sec: 63.99 - lr: 0.000015
2021-07-18 12:39:00,090 epoch 21 - iter 21/33 - loss 0.22199793 - samples/sec: 63.21 - lr: 0.000015
2021-07-18 12:39:01,632 epoch 21 - iter 24/33 - loss 0.22111336 - samples/sec: 62.26 - lr: 0.000015
2021-07-18 12:39:03,138 epoch 21 - iter 27/33 - loss 0.22247415 - samples/sec: 63.77 - lr: 0.000015
2021-07-18 12:39:04,632 epoch 21 - iter 30/33 - loss 0.22962835 - samples/sec: 64.27 - lr: 0.000015
2021-07-18 12:39:05,698 epoch 21 - iter 33/33 - loss 0.22856744 - samples/sec: 90.14 - lr: 0.000015
2021-07-18 12:39:05,698 ----------------------------------------------------------------------------------------------------
2021-07-18 12:39:05,698 EPOCH 21 done: loss 0.2286 - lr 0.0000150
2021-07-18 12:39:07,640 DEV : loss 0.37502866983413696 - score 0.9402
2021-07-18 12:39:07,665 BAD EPOCHS (no improvement): 1
2021-07-18 12:39:07,666 ----------------------------------------------------------------------------------------------------
2021-07-18 12:39:09,178 epoch 22 - iter 3/33 - loss 0.22584844 - samples/sec: 63.48 - lr: 0.000015
2021-07-18 12:39:10,731 epoch 22 - iter 6/33 - loss 0.20700719 - samples/sec: 61.85 - lr: 0.000015
2021-07-18 12:39:12,260 epoch 22 - iter 9/33 - loss 0.27493279 - samples/sec: 62.82 - lr: 0.000015
2021-07-18 12:39:13,771 epoch 22 - iter 12/33 - loss 0.26507276 - samples/sec: 63.53 - lr: 0.000015
2021-07-18 12:39:15,291 epoch 22 - iter 15/33 - loss 0.23835100 - samples/sec: 63.19 - lr: 0.000015
2021-07-18 12:39:16,808 epoch 22 - iter 18/33 - loss 0.24571326 - samples/sec: 63.32 - lr: 0.000015
2021-07-18 12:39:18,316 epoch 22 - iter 21/33 - loss 0.23538958 - samples/sec: 63.67 - lr: 0.000015
2021-07-18 12:39:19,841 epoch 22 - iter 24/33 - loss 0.23495923 - samples/sec: 62.96 - lr: 0.000015
2021-07-18 12:39:21,334 epoch 22 - iter 27/33 - loss 0.23529931 - samples/sec: 64.32 - lr: 0.000015
2021-07-18 12:39:22,827 epoch 22 - iter 30/33 - loss 0.23789583 - samples/sec: 64.32 - lr: 0.000015
2021-07-18 12:39:23,898 epoch 22 - iter 33/33 - loss 0.22767320 - samples/sec: 89.71 - lr: 0.000015
2021-07-18 12:39:23,898 ----------------------------------------------------------------------------------------------------
2021-07-18 12:39:23,898 EPOCH 22 done: loss 0.2277 - lr 0.0000150
2021-07-18 12:39:25,832 DEV : loss 0.3738412857055664 - score 0.9438
2021-07-18 12:39:25,857 BAD EPOCHS (no improvement): 2
2021-07-18 12:39:25,857 ----------------------------------------------------------------------------------------------------
2021-07-18 12:39:27,442 epoch 23 - iter 3/33 - loss 0.19816780 - samples/sec: 60.57 - lr: 0.000015
2021-07-18 12:39:28,977 epoch 23 - iter 6/33 - loss 0.24113563 - samples/sec: 62.59 - lr: 0.000015
2021-07-18 12:39:30,494 epoch 23 - iter 9/33 - loss 0.21685327 - samples/sec: 63.28 - lr: 0.000015
2021-07-18 12:39:32,021 epoch 23 - iter 12/33 - loss 0.21647019 - samples/sec: 62.89 - lr: 0.000015
2021-07-18 12:39:33,526 epoch 23 - iter 15/33 - loss 0.22499167 - samples/sec: 63.84 - lr: 0.000015
2021-07-18 12:39:35,037 epoch 23 - iter 18/33 - loss 0.21036484 - samples/sec: 63.52 - lr: 0.000015
2021-07-18 12:39:36,579 epoch 23 - iter 21/33 - loss 0.21322322 - samples/sec: 62.29 - lr: 0.000015
2021-07-18 12:39:38,098 epoch 23 - iter 24/33 - loss 0.21651498 - samples/sec: 63.23 - lr: 0.000015
2021-07-18 12:39:39,606 epoch 23 - iter 27/33 - loss 0.21567001 - samples/sec: 63.70 - lr: 0.000015
2021-07-18 12:39:41,095 epoch 23 - iter 30/33 - loss 0.21224704 - samples/sec: 64.49 - lr: 0.000015
2021-07-18 12:39:42,185 epoch 23 - iter 33/33 - loss 0.21711400 - samples/sec: 88.08 - lr: 0.000015
2021-07-18 12:39:42,185 ----------------------------------------------------------------------------------------------------
2021-07-18 12:39:42,185 EPOCH 23 done: loss 0.2171 - lr 0.0000150
2021-07-18 12:39:44,127 DEV : loss 0.3718435764312744 - score 0.9425
2021-07-18 12:39:44,153 BAD EPOCHS (no improvement): 3
2021-07-18 12:39:44,153 ----------------------------------------------------------------------------------------------------
2021-07-18 12:39:45,620 epoch 24 - iter 3/33 - loss 0.19279587 - samples/sec: 65.44 - lr: 0.000015
2021-07-18 12:39:47,126 epoch 24 - iter 6/33 - loss 0.20240651 - samples/sec: 63.80 - lr: 0.000015
2021-07-18 12:39:48,617 epoch 24 - iter 9/33 - loss 0.19226014 - samples/sec: 64.38 - lr: 0.000015
2021-07-18 12:39:50,139 epoch 24 - iter 12/33 - loss 0.19880035 - samples/sec: 63.10 - lr: 0.000015
2021-07-18 12:39:51,656 epoch 24 - iter 15/33 - loss 0.20560252 - samples/sec: 63.29 - lr: 0.000015
2021-07-18 12:39:53,162 epoch 24 - iter 18/33 - loss 0.19317317 - samples/sec: 63.77 - lr: 0.000015
2021-07-18 12:39:54,686 epoch 24 - iter 21/33 - loss 0.20674209 - samples/sec: 63.04 - lr: 0.000015
2021-07-18 12:39:56,214 epoch 24 - iter 24/33 - loss 0.19912133 - samples/sec: 62.85 - lr: 0.000015
2021-07-18 12:39:57,752 epoch 24 - iter 27/33 - loss 0.20718915 - samples/sec: 62.43 - lr: 0.000015
2021-07-18 12:39:59,278 epoch 24 - iter 30/33 - loss 0.20839076 - samples/sec: 62.91 - lr: 0.000015
2021-07-18 12:40:00,365 epoch 24 - iter 33/33 - loss 0.20919648 - samples/sec: 88.36 - lr: 0.000015
2021-07-18 12:40:00,366 ----------------------------------------------------------------------------------------------------
2021-07-18 12:40:00,366 EPOCH 24 done: loss 0.2092 - lr 0.0000150
2021-07-18 12:40:02,304 DEV : loss 0.37297534942626953 - score 0.9439
Epoch    24: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 12:40:02,329 BAD EPOCHS (no improvement): 4
2021-07-18 12:40:02,329 ----------------------------------------------------------------------------------------------------
2021-07-18 12:40:03,824 epoch 25 - iter 3/33 - loss 0.18808847 - samples/sec: 64.26 - lr: 0.000008
2021-07-18 12:40:05,333 epoch 25 - iter 6/33 - loss 0.22620928 - samples/sec: 63.63 - lr: 0.000008
2021-07-18 12:40:06,872 epoch 25 - iter 9/33 - loss 0.23040614 - samples/sec: 62.39 - lr: 0.000008
2021-07-18 12:40:08,382 epoch 25 - iter 12/33 - loss 0.21803687 - samples/sec: 63.60 - lr: 0.000008
2021-07-18 12:40:09,883 epoch 25 - iter 15/33 - loss 0.21406550 - samples/sec: 63.99 - lr: 0.000008
2021-07-18 12:40:11,410 epoch 25 - iter 18/33 - loss 0.21167150 - samples/sec: 62.85 - lr: 0.000008
2021-07-18 12:40:12,923 epoch 25 - iter 21/33 - loss 0.21843339 - samples/sec: 63.50 - lr: 0.000008
2021-07-18 12:40:14,443 epoch 25 - iter 24/33 - loss 0.21080034 - samples/sec: 63.17 - lr: 0.000008
2021-07-18 12:40:15,949 epoch 25 - iter 27/33 - loss 0.20868623 - samples/sec: 63.75 - lr: 0.000008
2021-07-18 12:40:17,470 epoch 25 - iter 30/33 - loss 0.20908073 - samples/sec: 63.14 - lr: 0.000008
2021-07-18 12:40:18,531 epoch 25 - iter 33/33 - loss 0.20196424 - samples/sec: 90.50 - lr: 0.000008
2021-07-18 12:40:18,532 ----------------------------------------------------------------------------------------------------
2021-07-18 12:40:18,532 EPOCH 25 done: loss 0.2020 - lr 0.0000075
2021-07-18 12:40:20,461 DEV : loss 0.37340742349624634 - score 0.9516
2021-07-18 12:40:20,486 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 12:40:23,651 ----------------------------------------------------------------------------------------------------
2021-07-18 12:40:25,156 epoch 26 - iter 3/33 - loss 0.30371332 - samples/sec: 63.83 - lr: 0.000008
2021-07-18 12:40:26,674 epoch 26 - iter 6/33 - loss 0.27115230 - samples/sec: 63.27 - lr: 0.000008
2021-07-18 12:40:28,194 epoch 26 - iter 9/33 - loss 0.25697504 - samples/sec: 63.16 - lr: 0.000008
2021-07-18 12:40:29,715 epoch 26 - iter 12/33 - loss 0.24280325 - samples/sec: 63.13 - lr: 0.000008
2021-07-18 12:40:31,218 epoch 26 - iter 15/33 - loss 0.23682546 - samples/sec: 63.89 - lr: 0.000008
2021-07-18 12:40:32,743 epoch 26 - iter 18/33 - loss 0.22719318 - samples/sec: 62.99 - lr: 0.000008
2021-07-18 12:40:34,218 epoch 26 - iter 21/33 - loss 0.22337738 - samples/sec: 65.11 - lr: 0.000008
2021-07-18 12:40:35,754 epoch 26 - iter 24/33 - loss 0.22356904 - samples/sec: 62.50 - lr: 0.000008
2021-07-18 12:40:37,302 epoch 26 - iter 27/33 - loss 0.22107185 - samples/sec: 62.05 - lr: 0.000008
2021-07-18 12:40:38,818 epoch 26 - iter 30/33 - loss 0.21867415 - samples/sec: 63.37 - lr: 0.000008
2021-07-18 12:40:39,879 epoch 26 - iter 33/33 - loss 0.21460333 - samples/sec: 90.48 - lr: 0.000008
2021-07-18 12:40:39,879 ----------------------------------------------------------------------------------------------------
2021-07-18 12:40:39,879 EPOCH 26 done: loss 0.2146 - lr 0.0000075
2021-07-18 12:40:41,962 DEV : loss 0.3745902180671692 - score 0.9401
2021-07-18 12:40:41,987 BAD EPOCHS (no improvement): 1
2021-07-18 12:40:41,987 ----------------------------------------------------------------------------------------------------
2021-07-18 12:40:43,510 epoch 27 - iter 3/33 - loss 0.28115507 - samples/sec: 63.03 - lr: 0.000008
2021-07-18 12:40:45,047 epoch 27 - iter 6/33 - loss 0.25910276 - samples/sec: 62.49 - lr: 0.000008
2021-07-18 12:40:46,561 epoch 27 - iter 9/33 - loss 0.23232661 - samples/sec: 63.42 - lr: 0.000008
2021-07-18 12:40:48,046 epoch 27 - iter 12/33 - loss 0.22695179 - samples/sec: 64.70 - lr: 0.000008
2021-07-18 12:40:49,559 epoch 27 - iter 15/33 - loss 0.21867345 - samples/sec: 63.47 - lr: 0.000008
2021-07-18 12:40:51,064 epoch 27 - iter 18/33 - loss 0.20787960 - samples/sec: 63.79 - lr: 0.000008
2021-07-18 12:40:52,602 epoch 27 - iter 21/33 - loss 0.20291711 - samples/sec: 62.42 - lr: 0.000008
2021-07-18 12:40:54,106 epoch 27 - iter 24/33 - loss 0.20510279 - samples/sec: 63.87 - lr: 0.000008
2021-07-18 12:40:55,626 epoch 27 - iter 27/33 - loss 0.20867665 - samples/sec: 63.20 - lr: 0.000008
2021-07-18 12:40:57,139 epoch 27 - iter 30/33 - loss 0.20245415 - samples/sec: 63.45 - lr: 0.000008
2021-07-18 12:40:58,208 epoch 27 - iter 33/33 - loss 0.20059105 - samples/sec: 89.85 - lr: 0.000008
2021-07-18 12:40:58,208 ----------------------------------------------------------------------------------------------------
2021-07-18 12:40:58,208 EPOCH 27 done: loss 0.2006 - lr 0.0000075
2021-07-18 12:41:00,134 DEV : loss 0.3750527501106262 - score 0.9477
2021-07-18 12:41:00,159 BAD EPOCHS (no improvement): 2
2021-07-18 12:41:00,159 ----------------------------------------------------------------------------------------------------
2021-07-18 12:41:01,665 epoch 28 - iter 3/33 - loss 0.25803341 - samples/sec: 63.75 - lr: 0.000008
2021-07-18 12:41:03,199 epoch 28 - iter 6/33 - loss 0.22152749 - samples/sec: 62.63 - lr: 0.000008
2021-07-18 12:41:04,727 epoch 28 - iter 9/33 - loss 0.20424379 - samples/sec: 62.86 - lr: 0.000008
2021-07-18 12:41:06,259 epoch 28 - iter 12/33 - loss 0.20064483 - samples/sec: 62.68 - lr: 0.000008
2021-07-18 12:41:07,791 epoch 28 - iter 15/33 - loss 0.20618953 - samples/sec: 62.68 - lr: 0.000008
2021-07-18 12:41:09,290 epoch 28 - iter 18/33 - loss 0.20228637 - samples/sec: 64.06 - lr: 0.000008
2021-07-18 12:41:10,807 epoch 28 - iter 21/33 - loss 0.19825898 - samples/sec: 63.30 - lr: 0.000008
2021-07-18 12:41:12,309 epoch 28 - iter 24/33 - loss 0.20384798 - samples/sec: 63.92 - lr: 0.000008
2021-07-18 12:41:13,782 epoch 28 - iter 27/33 - loss 0.20215546 - samples/sec: 65.23 - lr: 0.000008
2021-07-18 12:41:15,289 epoch 28 - iter 30/33 - loss 0.20719486 - samples/sec: 63.69 - lr: 0.000008
2021-07-18 12:41:16,361 epoch 28 - iter 33/33 - loss 0.19743619 - samples/sec: 89.61 - lr: 0.000008
2021-07-18 12:41:16,362 ----------------------------------------------------------------------------------------------------
2021-07-18 12:41:16,362 EPOCH 28 done: loss 0.1974 - lr 0.0000075
2021-07-18 12:41:18,293 DEV : loss 0.37660521268844604 - score 0.9413
2021-07-18 12:41:18,318 BAD EPOCHS (no improvement): 3
2021-07-18 12:41:18,319 ----------------------------------------------------------------------------------------------------
2021-07-18 12:41:19,831 epoch 29 - iter 3/33 - loss 0.17450723 - samples/sec: 63.51 - lr: 0.000008
2021-07-18 12:41:21,367 epoch 29 - iter 6/33 - loss 0.21103127 - samples/sec: 62.52 - lr: 0.000008
2021-07-18 12:41:22,825 epoch 29 - iter 9/33 - loss 0.19988387 - samples/sec: 65.87 - lr: 0.000008
2021-07-18 12:41:24,358 epoch 29 - iter 12/33 - loss 0.18601092 - samples/sec: 62.63 - lr: 0.000008
2021-07-18 12:41:25,838 epoch 29 - iter 15/33 - loss 0.19498955 - samples/sec: 64.89 - lr: 0.000008
2021-07-18 12:41:27,368 epoch 29 - iter 18/33 - loss 0.18680313 - samples/sec: 62.78 - lr: 0.000008
2021-07-18 12:41:28,875 epoch 29 - iter 21/33 - loss 0.19755463 - samples/sec: 63.72 - lr: 0.000008
2021-07-18 12:41:30,374 epoch 29 - iter 24/33 - loss 0.19359217 - samples/sec: 64.06 - lr: 0.000008
2021-07-18 12:41:31,898 epoch 29 - iter 27/33 - loss 0.18876219 - samples/sec: 63.03 - lr: 0.000008
2021-07-18 12:41:33,417 epoch 29 - iter 30/33 - loss 0.19360521 - samples/sec: 63.20 - lr: 0.000008
2021-07-18 12:41:34,516 epoch 29 - iter 33/33 - loss 0.18891303 - samples/sec: 87.36 - lr: 0.000008
2021-07-18 12:41:34,517 ----------------------------------------------------------------------------------------------------
2021-07-18 12:41:34,517 EPOCH 29 done: loss 0.1889 - lr 0.0000075
2021-07-18 12:41:36,594 DEV : loss 0.3736746311187744 - score 0.9477
Epoch    29: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 12:41:36,619 BAD EPOCHS (no improvement): 4
2021-07-18 12:41:36,620 ----------------------------------------------------------------------------------------------------
2021-07-18 12:41:38,135 epoch 30 - iter 3/33 - loss 0.16844260 - samples/sec: 63.37 - lr: 0.000004
2021-07-18 12:41:39,664 epoch 30 - iter 6/33 - loss 0.18699003 - samples/sec: 62.80 - lr: 0.000004
2021-07-18 12:41:41,158 epoch 30 - iter 9/33 - loss 0.18242985 - samples/sec: 64.29 - lr: 0.000004
2021-07-18 12:41:42,679 epoch 30 - iter 12/33 - loss 0.18003209 - samples/sec: 63.13 - lr: 0.000004
2021-07-18 12:41:44,179 epoch 30 - iter 15/33 - loss 0.17987923 - samples/sec: 64.03 - lr: 0.000004
2021-07-18 12:41:45,675 epoch 30 - iter 18/33 - loss 0.18343448 - samples/sec: 64.21 - lr: 0.000004
2021-07-18 12:41:47,221 epoch 30 - iter 21/33 - loss 0.19504142 - samples/sec: 62.08 - lr: 0.000004
2021-07-18 12:41:48,719 epoch 30 - iter 24/33 - loss 0.18797960 - samples/sec: 64.13 - lr: 0.000004
2021-07-18 12:41:50,223 epoch 30 - iter 27/33 - loss 0.19784348 - samples/sec: 63.83 - lr: 0.000004
2021-07-18 12:41:51,766 epoch 30 - iter 30/33 - loss 0.19632151 - samples/sec: 62.26 - lr: 0.000004
2021-07-18 12:41:52,855 epoch 30 - iter 33/33 - loss 0.19555998 - samples/sec: 88.19 - lr: 0.000004
2021-07-18 12:41:52,855 ----------------------------------------------------------------------------------------------------
2021-07-18 12:41:52,855 EPOCH 30 done: loss 0.1956 - lr 0.0000038
2021-07-18 12:41:54,787 DEV : loss 0.3757924735546112 - score 0.9451
2021-07-18 12:41:54,812 BAD EPOCHS (no improvement): 1
2021-07-18 12:41:54,813 ----------------------------------------------------------------------------------------------------
2021-07-18 12:41:56,286 epoch 31 - iter 3/33 - loss 0.10437505 - samples/sec: 65.16 - lr: 0.000004
2021-07-18 12:41:57,793 epoch 31 - iter 6/33 - loss 0.17998767 - samples/sec: 63.73 - lr: 0.000004
2021-07-18 12:41:59,337 epoch 31 - iter 9/33 - loss 0.18550578 - samples/sec: 62.22 - lr: 0.000004
2021-07-18 12:42:00,851 epoch 31 - iter 12/33 - loss 0.19382300 - samples/sec: 63.42 - lr: 0.000004
2021-07-18 12:42:02,400 epoch 31 - iter 15/33 - loss 0.20086690 - samples/sec: 61.99 - lr: 0.000004
2021-07-18 12:42:03,912 epoch 31 - iter 18/33 - loss 0.18209537 - samples/sec: 63.52 - lr: 0.000004
2021-07-18 12:42:05,423 epoch 31 - iter 21/33 - loss 0.17875904 - samples/sec: 63.53 - lr: 0.000004
2021-07-18 12:42:06,963 epoch 31 - iter 24/33 - loss 0.18028831 - samples/sec: 62.37 - lr: 0.000004
2021-07-18 12:42:08,476 epoch 31 - iter 27/33 - loss 0.17928609 - samples/sec: 63.49 - lr: 0.000004
2021-07-18 12:42:10,011 epoch 31 - iter 30/33 - loss 0.18209728 - samples/sec: 62.54 - lr: 0.000004
2021-07-18 12:42:11,097 epoch 31 - iter 33/33 - loss 0.17770722 - samples/sec: 88.49 - lr: 0.000004
2021-07-18 12:42:11,097 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:11,097 EPOCH 31 done: loss 0.1777 - lr 0.0000038
2021-07-18 12:42:13,028 DEV : loss 0.37615808844566345 - score 0.9451
2021-07-18 12:42:13,053 BAD EPOCHS (no improvement): 2
2021-07-18 12:42:13,053 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:14,551 epoch 32 - iter 3/33 - loss 0.30048047 - samples/sec: 64.13 - lr: 0.000004
2021-07-18 12:42:16,065 epoch 32 - iter 6/33 - loss 0.26093957 - samples/sec: 63.40 - lr: 0.000004
2021-07-18 12:42:17,587 epoch 32 - iter 9/33 - loss 0.24095321 - samples/sec: 63.10 - lr: 0.000004
2021-07-18 12:42:19,128 epoch 32 - iter 12/33 - loss 0.22444779 - samples/sec: 62.33 - lr: 0.000004
2021-07-18 12:42:20,656 epoch 32 - iter 15/33 - loss 0.21422010 - samples/sec: 62.85 - lr: 0.000004
2021-07-18 12:42:22,203 epoch 32 - iter 18/33 - loss 0.21338362 - samples/sec: 62.08 - lr: 0.000004
2021-07-18 12:42:23,734 epoch 32 - iter 21/33 - loss 0.20111801 - samples/sec: 62.70 - lr: 0.000004
2021-07-18 12:42:25,251 epoch 32 - iter 24/33 - loss 0.20055341 - samples/sec: 63.34 - lr: 0.000004
2021-07-18 12:42:26,779 epoch 32 - iter 27/33 - loss 0.20018376 - samples/sec: 62.83 - lr: 0.000004
2021-07-18 12:42:28,283 epoch 32 - iter 30/33 - loss 0.20174474 - samples/sec: 63.87 - lr: 0.000004
2021-07-18 12:42:29,376 epoch 32 - iter 33/33 - loss 0.19738693 - samples/sec: 87.86 - lr: 0.000004
2021-07-18 12:42:29,376 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:29,376 EPOCH 32 done: loss 0.1974 - lr 0.0000038
2021-07-18 12:42:31,305 DEV : loss 0.3752290904521942 - score 0.9451
2021-07-18 12:42:31,330 BAD EPOCHS (no improvement): 3
2021-07-18 12:42:31,331 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:32,843 epoch 33 - iter 3/33 - loss 0.23970850 - samples/sec: 63.51 - lr: 0.000004
2021-07-18 12:42:34,388 epoch 33 - iter 6/33 - loss 0.18225002 - samples/sec: 62.16 - lr: 0.000004
2021-07-18 12:42:35,918 epoch 33 - iter 9/33 - loss 0.17362707 - samples/sec: 62.75 - lr: 0.000004
2021-07-18 12:42:37,444 epoch 33 - iter 12/33 - loss 0.17015008 - samples/sec: 62.92 - lr: 0.000004
2021-07-18 12:42:38,972 epoch 33 - iter 15/33 - loss 0.17466285 - samples/sec: 62.87 - lr: 0.000004
2021-07-18 12:42:40,506 epoch 33 - iter 18/33 - loss 0.19851973 - samples/sec: 62.60 - lr: 0.000004
2021-07-18 12:42:42,047 epoch 33 - iter 21/33 - loss 0.19973958 - samples/sec: 62.32 - lr: 0.000004
2021-07-18 12:42:43,567 epoch 33 - iter 24/33 - loss 0.20020471 - samples/sec: 63.19 - lr: 0.000004
2021-07-18 12:42:45,064 epoch 33 - iter 27/33 - loss 0.19392658 - samples/sec: 64.14 - lr: 0.000004
2021-07-18 12:42:46,576 epoch 33 - iter 30/33 - loss 0.20546604 - samples/sec: 63.52 - lr: 0.000004
2021-07-18 12:42:47,639 epoch 33 - iter 33/33 - loss 0.19711552 - samples/sec: 90.33 - lr: 0.000004
2021-07-18 12:42:47,639 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:47,639 EPOCH 33 done: loss 0.1971 - lr 0.0000038
2021-07-18 12:42:49,714 DEV : loss 0.3751198649406433 - score 0.9449
Epoch    33: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 12:42:49,740 BAD EPOCHS (no improvement): 4
2021-07-18 12:42:49,740 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:49,740 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:49,740 learning rate too small - quitting training!
2021-07-18 12:42:49,740 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:50,356 ----------------------------------------------------------------------------------------------------
2021-07-18 12:42:50,357 Testing using best model ...
2021-07-18 12:42:50,357 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eus.rst.ert/best-model.pt
2021-07-18 12:42:57,461 0.9655	0.9482	0.9568
2021-07-18 12:42:57,461 
Results:
- F1-score (micro) 0.9568
- F1-score (macro) 0.9568

By class:
SENT       tp: 476 - fp: 17 - fn: 26 - precision: 0.9655 - recall: 0.9482 - f1-score: 0.9568
2021-07-18 12:42:57,462 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.pdtb.pdtb/
2021-07-18 12:42:57,471 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.pdtb.pdtb
2021-07-18 12:42:57,471 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.pdtb.pdtb/sent_train.txt
2021-07-18 12:42:57,471 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.pdtb.pdtb/sent_dev.txt
2021-07-18 12:42:57,472 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.pdtb.pdtb/sent_test.txt
Corpus: 37816 train + 1929 dev + 13665 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 12:43:19,052 ----------------------------------------------------------------------------------------------------
2021-07-18 12:43:19,054 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 12:43:19,054 ----------------------------------------------------------------------------------------------------
2021-07-18 12:43:19,054 Corpus: "Corpus: 37816 train + 1929 dev + 13665 test sentences"
2021-07-18 12:43:19,054 ----------------------------------------------------------------------------------------------------
2021-07-18 12:43:19,054 Parameters:
2021-07-18 12:43:19,054  - learning_rate: "3e-05"
2021-07-18 12:43:19,054  - mini_batch_size: "32"
2021-07-18 12:43:19,054  - patience: "3"
2021-07-18 12:43:19,054  - anneal_factor: "0.5"
2021-07-18 12:43:19,054  - max_epochs: "40"
2021-07-18 12:43:19,055  - shuffle: "True"
2021-07-18 12:43:19,055  - train_with_dev: "False"
2021-07-18 12:43:19,055  - batch_growth_annealing: "False"
2021-07-18 12:43:19,055 ----------------------------------------------------------------------------------------------------
2021-07-18 12:43:19,055 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.pdtb.pdtb"
2021-07-18 12:43:19,055 ----------------------------------------------------------------------------------------------------
2021-07-18 12:43:19,055 Device: cuda:0
2021-07-18 12:43:19,055 ----------------------------------------------------------------------------------------------------
2021-07-18 12:43:19,055 Embeddings storage mode: cpu
2021-07-18 12:43:19,057 ----------------------------------------------------------------------------------------------------
2021-07-18 12:45:13,173 epoch 1 - iter 118/1182 - loss 1.74599559 - samples/sec: 33.09 - lr: 0.000030
2021-07-18 12:47:07,019 epoch 1 - iter 236/1182 - loss 1.18686189 - samples/sec: 33.17 - lr: 0.000030
2021-07-18 12:49:01,484 epoch 1 - iter 354/1182 - loss 0.95078018 - samples/sec: 32.99 - lr: 0.000030
2021-07-18 12:50:56,075 epoch 1 - iter 472/1182 - loss 0.81395003 - samples/sec: 32.95 - lr: 0.000030
2021-07-18 12:52:53,023 epoch 1 - iter 590/1182 - loss 0.72243423 - samples/sec: 32.29 - lr: 0.000030
2021-07-18 12:54:47,816 epoch 1 - iter 708/1182 - loss 0.65544146 - samples/sec: 32.90 - lr: 0.000030
2021-07-18 12:56:42,660 epoch 1 - iter 826/1182 - loss 0.60918258 - samples/sec: 32.88 - lr: 0.000030
2021-07-18 12:58:37,476 epoch 1 - iter 944/1182 - loss 0.57264582 - samples/sec: 32.89 - lr: 0.000030
2021-07-18 13:00:32,532 epoch 1 - iter 1062/1182 - loss 0.53917035 - samples/sec: 32.82 - lr: 0.000030
2021-07-18 13:02:27,351 epoch 1 - iter 1180/1182 - loss 0.50991931 - samples/sec: 32.89 - lr: 0.000030
2021-07-18 13:02:29,047 ----------------------------------------------------------------------------------------------------
2021-07-18 13:02:29,047 EPOCH 1 done: loss 0.5094 - lr 0.0000300
2021-07-18 13:03:04,112 DEV : loss 0.18485552072525024 - score 0.9595
2021-07-18 13:03:04,246 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 13:03:05,099 ----------------------------------------------------------------------------------------------------
2021-07-18 13:04:04,460 epoch 2 - iter 118/1182 - loss 0.26337202 - samples/sec: 63.62 - lr: 0.000030
2021-07-18 13:05:03,377 epoch 2 - iter 236/1182 - loss 0.26112501 - samples/sec: 64.10 - lr: 0.000030
2021-07-18 13:06:02,635 epoch 2 - iter 354/1182 - loss 0.25386528 - samples/sec: 63.73 - lr: 0.000030
2021-07-18 13:07:01,821 epoch 2 - iter 472/1182 - loss 0.25814674 - samples/sec: 63.81 - lr: 0.000030
2021-07-18 13:08:01,036 epoch 2 - iter 590/1182 - loss 0.25472380 - samples/sec: 63.77 - lr: 0.000030
2021-07-18 13:09:00,276 epoch 2 - iter 708/1182 - loss 0.25046213 - samples/sec: 63.75 - lr: 0.000030
2021-07-18 13:09:59,589 epoch 2 - iter 826/1182 - loss 0.24800904 - samples/sec: 63.67 - lr: 0.000030
2021-07-18 13:10:59,189 epoch 2 - iter 944/1182 - loss 0.24555098 - samples/sec: 63.36 - lr: 0.000030
2021-07-18 13:11:58,665 epoch 2 - iter 1062/1182 - loss 0.24287110 - samples/sec: 63.49 - lr: 0.000030
2021-07-18 13:12:58,405 epoch 2 - iter 1180/1182 - loss 0.24005945 - samples/sec: 63.21 - lr: 0.000030
2021-07-18 13:12:59,311 ----------------------------------------------------------------------------------------------------
2021-07-18 13:12:59,311 EPOCH 2 done: loss 0.2401 - lr 0.0000300
2021-07-18 13:13:12,283 DEV : loss 0.15251827239990234 - score 0.9672
2021-07-18 13:13:12,416 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 13:13:16,353 ----------------------------------------------------------------------------------------------------
2021-07-18 13:14:16,260 epoch 3 - iter 118/1182 - loss 0.22197694 - samples/sec: 63.04 - lr: 0.000030
2021-07-18 13:15:15,865 epoch 3 - iter 236/1182 - loss 0.20084012 - samples/sec: 63.36 - lr: 0.000030
2021-07-18 13:16:15,464 epoch 3 - iter 354/1182 - loss 0.20410541 - samples/sec: 63.36 - lr: 0.000030
2021-07-18 13:17:15,125 epoch 3 - iter 472/1182 - loss 0.20440981 - samples/sec: 63.30 - lr: 0.000030
2021-07-18 13:18:14,980 epoch 3 - iter 590/1182 - loss 0.20539880 - samples/sec: 63.09 - lr: 0.000030
2021-07-18 13:19:14,832 epoch 3 - iter 708/1182 - loss 0.20581345 - samples/sec: 63.10 - lr: 0.000030
2021-07-18 13:20:14,699 epoch 3 - iter 826/1182 - loss 0.20471695 - samples/sec: 63.08 - lr: 0.000030
2021-07-18 13:21:14,645 epoch 3 - iter 944/1182 - loss 0.20485078 - samples/sec: 63.00 - lr: 0.000030
2021-07-18 13:22:14,627 epoch 3 - iter 1062/1182 - loss 0.20306347 - samples/sec: 62.96 - lr: 0.000030
2021-07-18 13:23:14,500 epoch 3 - iter 1180/1182 - loss 0.20262519 - samples/sec: 63.07 - lr: 0.000030
2021-07-18 13:23:15,379 ----------------------------------------------------------------------------------------------------
2021-07-18 13:23:15,379 EPOCH 3 done: loss 0.2024 - lr 0.0000300
2021-07-18 13:23:25,657 DEV : loss 0.14598964154720306 - score 0.9669
2021-07-18 13:23:25,794 BAD EPOCHS (no improvement): 1
2021-07-18 13:23:25,794 ----------------------------------------------------------------------------------------------------
2021-07-18 13:24:25,709 epoch 4 - iter 118/1182 - loss 0.19000102 - samples/sec: 63.03 - lr: 0.000030
2021-07-18 13:25:25,652 epoch 4 - iter 236/1182 - loss 0.19103878 - samples/sec: 63.00 - lr: 0.000030
2021-07-18 13:26:25,758 epoch 4 - iter 354/1182 - loss 0.19011759 - samples/sec: 62.83 - lr: 0.000030
2021-07-18 13:27:25,628 epoch 4 - iter 472/1182 - loss 0.18347720 - samples/sec: 63.08 - lr: 0.000030
2021-07-18 13:28:25,548 epoch 4 - iter 590/1182 - loss 0.18535290 - samples/sec: 63.02 - lr: 0.000030
2021-07-18 13:29:25,564 epoch 4 - iter 708/1182 - loss 0.18659762 - samples/sec: 62.92 - lr: 0.000030
2021-07-18 13:30:25,523 epoch 4 - iter 826/1182 - loss 0.18628348 - samples/sec: 62.98 - lr: 0.000030
2021-07-18 13:31:25,551 epoch 4 - iter 944/1182 - loss 0.18499321 - samples/sec: 62.91 - lr: 0.000030
2021-07-18 13:32:25,463 epoch 4 - iter 1062/1182 - loss 0.18291396 - samples/sec: 63.03 - lr: 0.000030
2021-07-18 13:33:24,983 epoch 4 - iter 1180/1182 - loss 0.18371942 - samples/sec: 63.45 - lr: 0.000030
2021-07-18 13:33:25,890 ----------------------------------------------------------------------------------------------------
2021-07-18 13:33:25,890 EPOCH 4 done: loss 0.1837 - lr 0.0000300
2021-07-18 13:33:36,195 DEV : loss 0.13912467658519745 - score 0.9676
2021-07-18 13:33:36,330 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 13:33:40,219 ----------------------------------------------------------------------------------------------------
2021-07-18 13:34:40,025 epoch 5 - iter 118/1182 - loss 0.16482877 - samples/sec: 63.15 - lr: 0.000030
2021-07-18 13:35:39,808 epoch 5 - iter 236/1182 - loss 0.16215684 - samples/sec: 63.17 - lr: 0.000030
2021-07-18 13:36:39,496 epoch 5 - iter 354/1182 - loss 0.16517600 - samples/sec: 63.27 - lr: 0.000030
2021-07-18 13:37:39,245 epoch 5 - iter 472/1182 - loss 0.16533653 - samples/sec: 63.20 - lr: 0.000030
2021-07-18 13:38:39,309 epoch 5 - iter 590/1182 - loss 0.16700834 - samples/sec: 62.87 - lr: 0.000030
2021-07-18 13:39:39,453 epoch 5 - iter 708/1182 - loss 0.16444790 - samples/sec: 62.79 - lr: 0.000030
2021-07-18 13:40:39,463 epoch 5 - iter 826/1182 - loss 0.16507325 - samples/sec: 62.93 - lr: 0.000030
2021-07-18 13:41:39,528 epoch 5 - iter 944/1182 - loss 0.16433789 - samples/sec: 62.87 - lr: 0.000030
2021-07-18 13:42:39,509 epoch 5 - iter 1062/1182 - loss 0.16512116 - samples/sec: 62.96 - lr: 0.000030
2021-07-18 13:43:39,123 epoch 5 - iter 1180/1182 - loss 0.16540318 - samples/sec: 63.35 - lr: 0.000030
2021-07-18 13:43:40,045 ----------------------------------------------------------------------------------------------------
2021-07-18 13:43:40,045 EPOCH 5 done: loss 0.1654 - lr 0.0000300
2021-07-18 13:43:50,351 DEV : loss 0.13178305327892303 - score 0.9696
2021-07-18 13:43:50,488 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 13:43:54,479 ----------------------------------------------------------------------------------------------------
2021-07-18 13:44:54,527 epoch 6 - iter 118/1182 - loss 0.14589588 - samples/sec: 62.89 - lr: 0.000030
2021-07-18 13:45:54,752 epoch 6 - iter 236/1182 - loss 0.15562545 - samples/sec: 62.70 - lr: 0.000030
2021-07-18 13:46:54,881 epoch 6 - iter 354/1182 - loss 0.15583039 - samples/sec: 62.81 - lr: 0.000030
2021-07-18 13:47:54,961 epoch 6 - iter 472/1182 - loss 0.15575185 - samples/sec: 62.86 - lr: 0.000030
2021-07-18 13:48:54,566 epoch 6 - iter 590/1182 - loss 0.15671518 - samples/sec: 63.36 - lr: 0.000030
2021-07-18 13:49:54,391 epoch 6 - iter 708/1182 - loss 0.15780650 - samples/sec: 63.12 - lr: 0.000030
2021-07-18 13:50:54,144 epoch 6 - iter 826/1182 - loss 0.16017844 - samples/sec: 63.20 - lr: 0.000030
2021-07-18 13:51:53,967 epoch 6 - iter 944/1182 - loss 0.15851275 - samples/sec: 63.13 - lr: 0.000030
2021-07-18 13:52:53,571 epoch 6 - iter 1062/1182 - loss 0.15785270 - samples/sec: 63.36 - lr: 0.000030
2021-07-18 13:53:53,185 epoch 6 - iter 1180/1182 - loss 0.15757060 - samples/sec: 63.35 - lr: 0.000030
2021-07-18 13:53:54,082 ----------------------------------------------------------------------------------------------------
2021-07-18 13:53:54,083 EPOCH 6 done: loss 0.1577 - lr 0.0000300
2021-07-18 13:54:04,402 DEV : loss 0.12726925313472748 - score 0.97
2021-07-18 13:54:04,539 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 13:54:08,420 ----------------------------------------------------------------------------------------------------
2021-07-18 13:55:07,764 epoch 7 - iter 118/1182 - loss 0.14047368 - samples/sec: 63.64 - lr: 0.000030
2021-07-18 13:56:07,065 epoch 7 - iter 236/1182 - loss 0.12868611 - samples/sec: 63.68 - lr: 0.000030
2021-07-18 13:57:06,721 epoch 7 - iter 354/1182 - loss 0.13562142 - samples/sec: 63.30 - lr: 0.000030
2021-07-18 13:58:06,093 epoch 7 - iter 472/1182 - loss 0.13941352 - samples/sec: 63.61 - lr: 0.000030
2021-07-18 13:59:05,319 epoch 7 - iter 590/1182 - loss 0.13915964 - samples/sec: 63.76 - lr: 0.000030
2021-07-18 14:00:04,391 epoch 7 - iter 708/1182 - loss 0.14054264 - samples/sec: 63.93 - lr: 0.000030
2021-07-18 14:01:03,829 epoch 7 - iter 826/1182 - loss 0.14078708 - samples/sec: 63.53 - lr: 0.000030
2021-07-18 14:02:03,482 epoch 7 - iter 944/1182 - loss 0.14180015 - samples/sec: 63.31 - lr: 0.000030
2021-07-18 14:03:03,059 epoch 7 - iter 1062/1182 - loss 0.14205148 - samples/sec: 63.39 - lr: 0.000030
2021-07-18 14:04:02,959 epoch 7 - iter 1180/1182 - loss 0.14232058 - samples/sec: 63.05 - lr: 0.000030
2021-07-18 14:04:03,855 ----------------------------------------------------------------------------------------------------
2021-07-18 14:04:03,856 EPOCH 7 done: loss 0.1424 - lr 0.0000300
2021-07-18 14:04:14,165 DEV : loss 0.12422960251569748 - score 0.973
2021-07-18 14:04:14,302 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 14:04:18,152 ----------------------------------------------------------------------------------------------------
2021-07-18 14:05:17,927 epoch 8 - iter 118/1182 - loss 0.12081014 - samples/sec: 63.18 - lr: 0.000030
2021-07-18 14:06:17,551 epoch 8 - iter 236/1182 - loss 0.13137937 - samples/sec: 63.34 - lr: 0.000030
2021-07-18 14:07:17,251 epoch 8 - iter 354/1182 - loss 0.13559357 - samples/sec: 63.26 - lr: 0.000030
2021-07-18 14:08:17,117 epoch 8 - iter 472/1182 - loss 0.13610184 - samples/sec: 63.08 - lr: 0.000030
2021-07-18 14:09:17,157 epoch 8 - iter 590/1182 - loss 0.13726607 - samples/sec: 62.90 - lr: 0.000030
2021-07-18 14:10:17,348 epoch 8 - iter 708/1182 - loss 0.13751331 - samples/sec: 62.74 - lr: 0.000030
2021-07-18 14:11:17,285 epoch 8 - iter 826/1182 - loss 0.13706957 - samples/sec: 63.01 - lr: 0.000030
2021-07-18 14:12:17,154 epoch 8 - iter 944/1182 - loss 0.13579014 - samples/sec: 63.08 - lr: 0.000030
2021-07-18 14:13:16,887 epoch 8 - iter 1062/1182 - loss 0.13355719 - samples/sec: 63.22 - lr: 0.000030
2021-07-18 14:14:16,773 epoch 8 - iter 1180/1182 - loss 0.13312174 - samples/sec: 63.06 - lr: 0.000030
2021-07-18 14:14:17,678 ----------------------------------------------------------------------------------------------------
2021-07-18 14:14:17,678 EPOCH 8 done: loss 0.1331 - lr 0.0000300
2021-07-18 14:14:30,788 DEV : loss 0.12099581211805344 - score 0.9708
2021-07-18 14:14:30,926 BAD EPOCHS (no improvement): 1
2021-07-18 14:14:30,926 ----------------------------------------------------------------------------------------------------
2021-07-18 14:15:30,716 epoch 9 - iter 118/1182 - loss 0.11207490 - samples/sec: 63.16 - lr: 0.000030
2021-07-18 14:16:30,481 epoch 9 - iter 236/1182 - loss 0.11906822 - samples/sec: 63.19 - lr: 0.000030
2021-07-18 14:17:30,309 epoch 9 - iter 354/1182 - loss 0.12359054 - samples/sec: 63.12 - lr: 0.000030
2021-07-18 14:18:30,388 epoch 9 - iter 472/1182 - loss 0.12295428 - samples/sec: 62.86 - lr: 0.000030
2021-07-18 14:19:30,454 epoch 9 - iter 590/1182 - loss 0.12598357 - samples/sec: 62.87 - lr: 0.000030
2021-07-18 14:20:30,170 epoch 9 - iter 708/1182 - loss 0.12731081 - samples/sec: 63.24 - lr: 0.000030
2021-07-18 14:21:29,853 epoch 9 - iter 826/1182 - loss 0.12759031 - samples/sec: 63.27 - lr: 0.000030
2021-07-18 14:22:29,418 epoch 9 - iter 944/1182 - loss 0.12628826 - samples/sec: 63.40 - lr: 0.000030
2021-07-18 14:23:29,389 epoch 9 - iter 1062/1182 - loss 0.12585632 - samples/sec: 62.97 - lr: 0.000030
2021-07-18 14:24:29,195 epoch 9 - iter 1180/1182 - loss 0.12775989 - samples/sec: 63.14 - lr: 0.000030
2021-07-18 14:24:30,087 ----------------------------------------------------------------------------------------------------
2021-07-18 14:24:30,087 EPOCH 9 done: loss 0.1278 - lr 0.0000300
2021-07-18 14:24:40,408 DEV : loss 0.1163891926407814 - score 0.9746
2021-07-18 14:24:40,545 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 14:24:44,420 ----------------------------------------------------------------------------------------------------
2021-07-18 14:25:44,419 epoch 10 - iter 118/1182 - loss 0.11639049 - samples/sec: 62.94 - lr: 0.000030
2021-07-18 14:26:44,318 epoch 10 - iter 236/1182 - loss 0.11910375 - samples/sec: 63.05 - lr: 0.000030
2021-07-18 14:27:44,336 epoch 10 - iter 354/1182 - loss 0.11926146 - samples/sec: 62.92 - lr: 0.000030
2021-07-18 14:28:44,338 epoch 10 - iter 472/1182 - loss 0.11765759 - samples/sec: 62.94 - lr: 0.000030
2021-07-18 14:29:44,155 epoch 10 - iter 590/1182 - loss 0.11905262 - samples/sec: 63.13 - lr: 0.000030
2021-07-18 14:30:43,565 epoch 10 - iter 708/1182 - loss 0.11927348 - samples/sec: 63.56 - lr: 0.000030
2021-07-18 14:31:43,506 epoch 10 - iter 826/1182 - loss 0.11915794 - samples/sec: 63.00 - lr: 0.000030
2021-07-18 14:32:43,509 epoch 10 - iter 944/1182 - loss 0.11967743 - samples/sec: 62.94 - lr: 0.000030
2021-07-18 14:33:43,390 epoch 10 - iter 1062/1182 - loss 0.11832931 - samples/sec: 63.06 - lr: 0.000030
2021-07-18 14:34:43,575 epoch 10 - iter 1180/1182 - loss 0.11906327 - samples/sec: 62.75 - lr: 0.000030
2021-07-18 14:34:44,478 ----------------------------------------------------------------------------------------------------
2021-07-18 14:34:44,479 EPOCH 10 done: loss 0.1191 - lr 0.0000300
2021-07-18 14:34:54,802 DEV : loss 0.1251068413257599 - score 0.9738
2021-07-18 14:34:54,940 BAD EPOCHS (no improvement): 1
2021-07-18 14:34:54,941 ----------------------------------------------------------------------------------------------------
2021-07-18 14:35:54,953 epoch 11 - iter 118/1182 - loss 0.12053354 - samples/sec: 62.93 - lr: 0.000030
2021-07-18 14:36:54,677 epoch 11 - iter 236/1182 - loss 0.11957094 - samples/sec: 63.23 - lr: 0.000030
2021-07-18 14:37:54,349 epoch 11 - iter 354/1182 - loss 0.11508596 - samples/sec: 63.29 - lr: 0.000030
2021-07-18 14:38:53,953 epoch 11 - iter 472/1182 - loss 0.11189953 - samples/sec: 63.36 - lr: 0.000030
2021-07-18 14:39:53,610 epoch 11 - iter 590/1182 - loss 0.11224288 - samples/sec: 63.30 - lr: 0.000030
2021-07-18 14:40:53,608 epoch 11 - iter 708/1182 - loss 0.11311330 - samples/sec: 62.94 - lr: 0.000030
2021-07-18 14:41:53,397 epoch 11 - iter 826/1182 - loss 0.11287877 - samples/sec: 63.16 - lr: 0.000030
2021-07-18 14:42:52,997 epoch 11 - iter 944/1182 - loss 0.11302119 - samples/sec: 63.36 - lr: 0.000030
2021-07-18 14:43:52,833 epoch 11 - iter 1062/1182 - loss 0.11466430 - samples/sec: 63.11 - lr: 0.000030
2021-07-18 14:44:52,866 epoch 11 - iter 1180/1182 - loss 0.11388930 - samples/sec: 62.90 - lr: 0.000030
2021-07-18 14:44:53,765 ----------------------------------------------------------------------------------------------------
2021-07-18 14:44:53,765 EPOCH 11 done: loss 0.1140 - lr 0.0000300
2021-07-18 14:45:04,096 DEV : loss 0.11502117663621902 - score 0.9754
2021-07-18 14:45:04,235 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 14:45:08,031 ----------------------------------------------------------------------------------------------------
2021-07-18 14:46:07,837 epoch 12 - iter 118/1182 - loss 0.10272146 - samples/sec: 63.15 - lr: 0.000030
2021-07-18 14:47:07,898 epoch 12 - iter 236/1182 - loss 0.10358428 - samples/sec: 62.88 - lr: 0.000030
2021-07-18 14:48:08,047 epoch 12 - iter 354/1182 - loss 0.09968674 - samples/sec: 62.78 - lr: 0.000030
2021-07-18 14:49:07,492 epoch 12 - iter 472/1182 - loss 0.10397243 - samples/sec: 63.53 - lr: 0.000030
2021-07-18 14:50:06,893 epoch 12 - iter 590/1182 - loss 0.10511225 - samples/sec: 63.57 - lr: 0.000030
2021-07-18 14:51:06,448 epoch 12 - iter 708/1182 - loss 0.10625623 - samples/sec: 63.41 - lr: 0.000030
2021-07-18 14:52:06,233 epoch 12 - iter 826/1182 - loss 0.10471522 - samples/sec: 63.17 - lr: 0.000030
2021-07-18 14:53:05,973 epoch 12 - iter 944/1182 - loss 0.10520163 - samples/sec: 63.21 - lr: 0.000030
2021-07-18 14:54:05,498 epoch 12 - iter 1062/1182 - loss 0.10651137 - samples/sec: 63.44 - lr: 0.000030
2021-07-18 14:55:05,217 epoch 12 - iter 1180/1182 - loss 0.10583122 - samples/sec: 63.24 - lr: 0.000030
2021-07-18 14:55:06,111 ----------------------------------------------------------------------------------------------------
2021-07-18 14:55:06,111 EPOCH 12 done: loss 0.1059 - lr 0.0000300
2021-07-18 14:55:16,464 DEV : loss 0.11829687654972076 - score 0.9724
2021-07-18 14:55:16,603 BAD EPOCHS (no improvement): 1
2021-07-18 14:55:16,604 ----------------------------------------------------------------------------------------------------
2021-07-18 14:56:16,661 epoch 13 - iter 118/1182 - loss 0.09444066 - samples/sec: 62.88 - lr: 0.000030
2021-07-18 14:57:16,813 epoch 13 - iter 236/1182 - loss 0.10607746 - samples/sec: 62.78 - lr: 0.000030
2021-07-18 14:58:16,830 epoch 13 - iter 354/1182 - loss 0.10476976 - samples/sec: 62.92 - lr: 0.000030
2021-07-18 14:59:16,833 epoch 13 - iter 472/1182 - loss 0.10418967 - samples/sec: 62.94 - lr: 0.000030
2021-07-18 15:00:16,413 epoch 13 - iter 590/1182 - loss 0.10184794 - samples/sec: 63.38 - lr: 0.000030
2021-07-18 15:01:15,970 epoch 13 - iter 708/1182 - loss 0.10272107 - samples/sec: 63.41 - lr: 0.000030
2021-07-18 15:02:15,337 epoch 13 - iter 826/1182 - loss 0.10177283 - samples/sec: 63.61 - lr: 0.000030
2021-07-18 15:03:14,838 epoch 13 - iter 944/1182 - loss 0.10155313 - samples/sec: 63.47 - lr: 0.000030
2021-07-18 15:04:14,534 epoch 13 - iter 1062/1182 - loss 0.10166455 - samples/sec: 63.26 - lr: 0.000030
2021-07-18 15:05:14,024 epoch 13 - iter 1180/1182 - loss 0.10106830 - samples/sec: 63.48 - lr: 0.000030
2021-07-18 15:05:14,929 ----------------------------------------------------------------------------------------------------
2021-07-18 15:05:14,930 EPOCH 13 done: loss 0.1013 - lr 0.0000300
2021-07-18 15:05:25,269 DEV : loss 0.12223728746175766 - score 0.9764
2021-07-18 15:05:25,406 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 15:05:29,291 ----------------------------------------------------------------------------------------------------
2021-07-18 15:06:28,997 epoch 14 - iter 118/1182 - loss 0.09626181 - samples/sec: 63.25 - lr: 0.000030
2021-07-18 15:07:31,518 epoch 14 - iter 236/1182 - loss 0.09514631 - samples/sec: 60.40 - lr: 0.000030
2021-07-18 15:08:31,363 epoch 14 - iter 354/1182 - loss 0.10092624 - samples/sec: 63.10 - lr: 0.000030
2021-07-18 15:09:31,293 epoch 14 - iter 472/1182 - loss 0.09654938 - samples/sec: 63.01 - lr: 0.000030
2021-07-18 15:10:31,372 epoch 14 - iter 590/1182 - loss 0.09895166 - samples/sec: 62.86 - lr: 0.000030
2021-07-18 15:11:31,436 epoch 14 - iter 708/1182 - loss 0.09915923 - samples/sec: 62.87 - lr: 0.000030
2021-07-18 15:12:31,600 epoch 14 - iter 826/1182 - loss 0.09734611 - samples/sec: 62.77 - lr: 0.000030
2021-07-18 15:13:31,742 epoch 14 - iter 944/1182 - loss 0.09793699 - samples/sec: 62.79 - lr: 0.000030
2021-07-18 15:14:31,419 epoch 14 - iter 1062/1182 - loss 0.09839730 - samples/sec: 63.28 - lr: 0.000030
2021-07-18 15:15:31,496 epoch 14 - iter 1180/1182 - loss 0.09862979 - samples/sec: 62.86 - lr: 0.000030
2021-07-18 15:15:32,400 ----------------------------------------------------------------------------------------------------
2021-07-18 15:15:32,400 EPOCH 14 done: loss 0.0985 - lr 0.0000300
2021-07-18 15:15:42,751 DEV : loss 0.11529035121202469 - score 0.9766
2021-07-18 15:15:42,889 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 15:15:46,873 ----------------------------------------------------------------------------------------------------
2021-07-18 15:16:46,753 epoch 15 - iter 118/1182 - loss 0.09791494 - samples/sec: 63.07 - lr: 0.000030
2021-07-18 15:17:46,573 epoch 15 - iter 236/1182 - loss 0.09447217 - samples/sec: 63.13 - lr: 0.000030
2021-07-18 15:18:46,485 epoch 15 - iter 354/1182 - loss 0.09113426 - samples/sec: 63.03 - lr: 0.000030
2021-07-18 15:19:46,186 epoch 15 - iter 472/1182 - loss 0.08904781 - samples/sec: 63.26 - lr: 0.000030
2021-07-18 15:20:45,959 epoch 15 - iter 590/1182 - loss 0.09065407 - samples/sec: 63.18 - lr: 0.000030
2021-07-18 15:21:46,225 epoch 15 - iter 708/1182 - loss 0.09071362 - samples/sec: 62.66 - lr: 0.000030
2021-07-18 15:22:46,255 epoch 15 - iter 826/1182 - loss 0.09199704 - samples/sec: 62.91 - lr: 0.000030
2021-07-18 15:23:46,443 epoch 15 - iter 944/1182 - loss 0.09143131 - samples/sec: 62.74 - lr: 0.000030
2021-07-18 15:24:45,997 epoch 15 - iter 1062/1182 - loss 0.09137156 - samples/sec: 63.41 - lr: 0.000030
2021-07-18 15:25:45,966 epoch 15 - iter 1180/1182 - loss 0.09188411 - samples/sec: 62.97 - lr: 0.000030
2021-07-18 15:25:46,881 ----------------------------------------------------------------------------------------------------
2021-07-18 15:25:46,881 EPOCH 15 done: loss 0.0920 - lr 0.0000300
2021-07-18 15:25:57,205 DEV : loss 0.1117933914065361 - score 0.9789
2021-07-18 15:25:57,343 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 15:26:01,435 ----------------------------------------------------------------------------------------------------
2021-07-18 15:27:00,881 epoch 16 - iter 118/1182 - loss 0.08020872 - samples/sec: 63.53 - lr: 0.000030
2021-07-18 15:28:00,526 epoch 16 - iter 236/1182 - loss 0.07816083 - samples/sec: 63.31 - lr: 0.000030
2021-07-18 15:29:00,405 epoch 16 - iter 354/1182 - loss 0.07705660 - samples/sec: 63.07 - lr: 0.000030
2021-07-18 15:30:00,489 epoch 16 - iter 472/1182 - loss 0.08151072 - samples/sec: 62.85 - lr: 0.000030
2021-07-18 15:31:00,292 epoch 16 - iter 590/1182 - loss 0.08397918 - samples/sec: 63.15 - lr: 0.000030
2021-07-18 15:32:00,414 epoch 16 - iter 708/1182 - loss 0.08388674 - samples/sec: 62.81 - lr: 0.000030
2021-07-18 15:33:00,410 epoch 16 - iter 826/1182 - loss 0.08497797 - samples/sec: 62.94 - lr: 0.000030
2021-07-18 15:34:00,700 epoch 16 - iter 944/1182 - loss 0.08683149 - samples/sec: 62.64 - lr: 0.000030
2021-07-18 15:35:00,657 epoch 16 - iter 1062/1182 - loss 0.08639870 - samples/sec: 62.98 - lr: 0.000030
2021-07-18 15:36:00,698 epoch 16 - iter 1180/1182 - loss 0.08589331 - samples/sec: 62.90 - lr: 0.000030
2021-07-18 15:36:01,606 ----------------------------------------------------------------------------------------------------
2021-07-18 15:36:01,606 EPOCH 16 done: loss 0.0860 - lr 0.0000300
2021-07-18 15:36:11,942 DEV : loss 0.11327540874481201 - score 0.9755
2021-07-18 15:36:12,080 BAD EPOCHS (no improvement): 1
2021-07-18 15:36:12,081 ----------------------------------------------------------------------------------------------------
2021-07-18 15:37:11,609 epoch 17 - iter 118/1182 - loss 0.08678133 - samples/sec: 63.44 - lr: 0.000030
2021-07-18 15:38:10,926 epoch 17 - iter 236/1182 - loss 0.08249705 - samples/sec: 63.66 - lr: 0.000030
2021-07-18 15:39:10,333 epoch 17 - iter 354/1182 - loss 0.07936464 - samples/sec: 63.57 - lr: 0.000030
2021-07-18 15:40:09,994 epoch 17 - iter 472/1182 - loss 0.08270114 - samples/sec: 63.30 - lr: 0.000030
2021-07-18 15:41:09,806 epoch 17 - iter 590/1182 - loss 0.08396183 - samples/sec: 63.14 - lr: 0.000030
2021-07-18 15:42:09,597 epoch 17 - iter 708/1182 - loss 0.08369387 - samples/sec: 63.16 - lr: 0.000030
2021-07-18 15:43:09,442 epoch 17 - iter 826/1182 - loss 0.08281226 - samples/sec: 63.10 - lr: 0.000030
2021-07-18 15:44:09,271 epoch 17 - iter 944/1182 - loss 0.08274476 - samples/sec: 63.12 - lr: 0.000030
2021-07-18 15:45:09,151 epoch 17 - iter 1062/1182 - loss 0.08255099 - samples/sec: 63.07 - lr: 0.000030
2021-07-18 15:46:08,864 epoch 17 - iter 1180/1182 - loss 0.08236976 - samples/sec: 63.24 - lr: 0.000030
2021-07-18 15:46:09,768 ----------------------------------------------------------------------------------------------------
2021-07-18 15:46:09,768 EPOCH 17 done: loss 0.0823 - lr 0.0000300
2021-07-18 15:46:20,099 DEV : loss 0.11945654451847076 - score 0.9743
2021-07-18 15:46:20,238 BAD EPOCHS (no improvement): 2
2021-07-18 15:46:20,239 ----------------------------------------------------------------------------------------------------
2021-07-18 15:47:20,380 epoch 18 - iter 118/1182 - loss 0.07575654 - samples/sec: 62.79 - lr: 0.000030
2021-07-18 15:48:20,485 epoch 18 - iter 236/1182 - loss 0.07008221 - samples/sec: 62.83 - lr: 0.000030
2021-07-18 15:49:20,746 epoch 18 - iter 354/1182 - loss 0.07221104 - samples/sec: 62.67 - lr: 0.000030
2021-07-18 15:50:20,946 epoch 18 - iter 472/1182 - loss 0.07427697 - samples/sec: 62.73 - lr: 0.000030
2021-07-18 15:51:20,702 epoch 18 - iter 590/1182 - loss 0.07687192 - samples/sec: 63.20 - lr: 0.000030
2021-07-18 15:52:20,610 epoch 18 - iter 708/1182 - loss 0.07704214 - samples/sec: 63.04 - lr: 0.000030
2021-07-18 15:53:20,444 epoch 18 - iter 826/1182 - loss 0.07870762 - samples/sec: 63.11 - lr: 0.000030
2021-07-18 15:54:20,085 epoch 18 - iter 944/1182 - loss 0.08112648 - samples/sec: 63.32 - lr: 0.000030
2021-07-18 15:55:19,912 epoch 18 - iter 1062/1182 - loss 0.08070044 - samples/sec: 63.12 - lr: 0.000030
2021-07-18 15:56:19,826 epoch 18 - iter 1180/1182 - loss 0.08067717 - samples/sec: 63.03 - lr: 0.000030
2021-07-18 15:56:20,743 ----------------------------------------------------------------------------------------------------
2021-07-18 15:56:20,743 EPOCH 18 done: loss 0.0807 - lr 0.0000300
2021-07-18 15:56:31,096 DEV : loss 0.11607306450605392 - score 0.9769
2021-07-18 15:56:31,235 BAD EPOCHS (no improvement): 3
2021-07-18 15:56:31,236 ----------------------------------------------------------------------------------------------------
2021-07-18 15:57:31,018 epoch 19 - iter 118/1182 - loss 0.07074331 - samples/sec: 63.17 - lr: 0.000030
2021-07-18 15:58:30,882 epoch 19 - iter 236/1182 - loss 0.07273178 - samples/sec: 63.08 - lr: 0.000030
2021-07-18 15:59:30,666 epoch 19 - iter 354/1182 - loss 0.07103557 - samples/sec: 63.17 - lr: 0.000030
2021-07-18 16:00:30,588 epoch 19 - iter 472/1182 - loss 0.07312696 - samples/sec: 63.02 - lr: 0.000030
2021-07-18 16:01:33,089 epoch 19 - iter 590/1182 - loss 0.07282954 - samples/sec: 60.42 - lr: 0.000030
2021-07-18 16:02:32,882 epoch 19 - iter 708/1182 - loss 0.07381556 - samples/sec: 63.16 - lr: 0.000030
2021-07-18 16:03:32,669 epoch 19 - iter 826/1182 - loss 0.07382486 - samples/sec: 63.16 - lr: 0.000030
2021-07-18 16:04:32,728 epoch 19 - iter 944/1182 - loss 0.07487247 - samples/sec: 62.88 - lr: 0.000030
2021-07-18 16:05:32,967 epoch 19 - iter 1062/1182 - loss 0.07582818 - samples/sec: 62.69 - lr: 0.000030
2021-07-18 16:06:32,932 epoch 19 - iter 1180/1182 - loss 0.07585144 - samples/sec: 62.98 - lr: 0.000030
2021-07-18 16:06:33,856 ----------------------------------------------------------------------------------------------------
2021-07-18 16:06:33,856 EPOCH 19 done: loss 0.0758 - lr 0.0000300
2021-07-18 16:06:44,202 DEV : loss 0.12982942163944244 - score 0.9767
Epoch    19: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 16:06:44,339 BAD EPOCHS (no improvement): 4
2021-07-18 16:06:44,339 ----------------------------------------------------------------------------------------------------
2021-07-18 16:07:44,470 epoch 20 - iter 118/1182 - loss 0.06039600 - samples/sec: 62.80 - lr: 0.000015
2021-07-18 16:08:44,608 epoch 20 - iter 236/1182 - loss 0.06393611 - samples/sec: 62.80 - lr: 0.000015
2021-07-18 16:09:44,862 epoch 20 - iter 354/1182 - loss 0.06482840 - samples/sec: 62.67 - lr: 0.000015
2021-07-18 16:10:45,054 epoch 20 - iter 472/1182 - loss 0.06296744 - samples/sec: 62.74 - lr: 0.000015
2021-07-18 16:11:45,236 epoch 20 - iter 590/1182 - loss 0.06228748 - samples/sec: 62.75 - lr: 0.000015
2021-07-18 16:12:45,255 epoch 20 - iter 708/1182 - loss 0.06135846 - samples/sec: 62.92 - lr: 0.000015
2021-07-18 16:13:45,405 epoch 20 - iter 826/1182 - loss 0.06249853 - samples/sec: 62.78 - lr: 0.000015
2021-07-18 16:14:45,566 epoch 20 - iter 944/1182 - loss 0.06386425 - samples/sec: 62.77 - lr: 0.000015
2021-07-18 16:15:45,878 epoch 20 - iter 1062/1182 - loss 0.06475688 - samples/sec: 62.61 - lr: 0.000015
2021-07-18 16:16:45,941 epoch 20 - iter 1180/1182 - loss 0.06481884 - samples/sec: 62.87 - lr: 0.000015
2021-07-18 16:16:46,853 ----------------------------------------------------------------------------------------------------
2021-07-18 16:16:46,853 EPOCH 20 done: loss 0.0648 - lr 0.0000150
2021-07-18 16:16:57,196 DEV : loss 0.11720036715269089 - score 0.9766
2021-07-18 16:16:57,336 BAD EPOCHS (no improvement): 1
2021-07-18 16:16:57,336 ----------------------------------------------------------------------------------------------------
2021-07-18 16:17:57,342 epoch 21 - iter 118/1182 - loss 0.06370558 - samples/sec: 62.94 - lr: 0.000015
2021-07-18 16:18:57,335 epoch 21 - iter 236/1182 - loss 0.06405806 - samples/sec: 62.95 - lr: 0.000015
2021-07-18 16:19:57,506 epoch 21 - iter 354/1182 - loss 0.06441466 - samples/sec: 62.76 - lr: 0.000015
2021-07-18 16:20:57,670 epoch 21 - iter 472/1182 - loss 0.06694533 - samples/sec: 62.77 - lr: 0.000015
2021-07-18 16:21:57,857 epoch 21 - iter 590/1182 - loss 0.06499444 - samples/sec: 62.74 - lr: 0.000015
2021-07-18 16:22:58,162 epoch 21 - iter 708/1182 - loss 0.06435795 - samples/sec: 62.62 - lr: 0.000015
2021-07-18 16:23:58,393 epoch 21 - iter 826/1182 - loss 0.06280537 - samples/sec: 62.70 - lr: 0.000015
2021-07-18 16:24:58,329 epoch 21 - iter 944/1182 - loss 0.06254140 - samples/sec: 63.01 - lr: 0.000015
2021-07-18 16:25:58,312 epoch 21 - iter 1062/1182 - loss 0.06147240 - samples/sec: 62.96 - lr: 0.000015
2021-07-18 16:26:58,557 epoch 21 - iter 1180/1182 - loss 0.06188894 - samples/sec: 62.68 - lr: 0.000015
2021-07-18 16:26:59,461 ----------------------------------------------------------------------------------------------------
2021-07-18 16:26:59,462 EPOCH 21 done: loss 0.0619 - lr 0.0000150
2021-07-18 16:27:09,848 DEV : loss 0.11368132382631302 - score 0.9754
2021-07-18 16:27:09,989 BAD EPOCHS (no improvement): 2
2021-07-18 16:27:09,989 ----------------------------------------------------------------------------------------------------
2021-07-18 16:28:09,958 epoch 22 - iter 118/1182 - loss 0.05706298 - samples/sec: 62.97 - lr: 0.000015
2021-07-18 16:29:10,110 epoch 22 - iter 236/1182 - loss 0.06307610 - samples/sec: 62.78 - lr: 0.000015
2021-07-18 16:30:10,168 epoch 22 - iter 354/1182 - loss 0.06037816 - samples/sec: 62.88 - lr: 0.000015
2021-07-18 16:31:09,971 epoch 22 - iter 472/1182 - loss 0.06128714 - samples/sec: 63.15 - lr: 0.000015
2021-07-18 16:32:09,764 epoch 22 - iter 590/1182 - loss 0.05975960 - samples/sec: 63.16 - lr: 0.000015
2021-07-18 16:33:09,548 epoch 22 - iter 708/1182 - loss 0.06032391 - samples/sec: 63.17 - lr: 0.000015
2021-07-18 16:34:09,355 epoch 22 - iter 826/1182 - loss 0.06190190 - samples/sec: 63.14 - lr: 0.000015
2021-07-18 16:35:09,179 epoch 22 - iter 944/1182 - loss 0.06069695 - samples/sec: 63.12 - lr: 0.000015
2021-07-18 16:36:09,004 epoch 22 - iter 1062/1182 - loss 0.06148602 - samples/sec: 63.12 - lr: 0.000015
2021-07-18 16:37:08,822 epoch 22 - iter 1180/1182 - loss 0.06196304 - samples/sec: 63.13 - lr: 0.000015
2021-07-18 16:37:09,733 ----------------------------------------------------------------------------------------------------
2021-07-18 16:37:09,733 EPOCH 22 done: loss 0.0619 - lr 0.0000150
2021-07-18 16:37:20,068 DEV : loss 0.11877459287643433 - score 0.976
2021-07-18 16:37:20,205 BAD EPOCHS (no improvement): 3
2021-07-18 16:37:20,206 ----------------------------------------------------------------------------------------------------
2021-07-18 16:38:20,022 epoch 23 - iter 118/1182 - loss 0.05581195 - samples/sec: 63.13 - lr: 0.000015
2021-07-18 16:39:20,130 epoch 23 - iter 236/1182 - loss 0.05656961 - samples/sec: 62.83 - lr: 0.000015
2021-07-18 16:40:20,179 epoch 23 - iter 354/1182 - loss 0.05949377 - samples/sec: 62.89 - lr: 0.000015
2021-07-18 16:41:20,375 epoch 23 - iter 472/1182 - loss 0.05822963 - samples/sec: 62.73 - lr: 0.000015
2021-07-18 16:42:20,233 epoch 23 - iter 590/1182 - loss 0.05642045 - samples/sec: 63.09 - lr: 0.000015
2021-07-18 16:43:20,096 epoch 23 - iter 708/1182 - loss 0.05846328 - samples/sec: 63.08 - lr: 0.000015
2021-07-18 16:44:20,208 epoch 23 - iter 826/1182 - loss 0.05775653 - samples/sec: 62.82 - lr: 0.000015
2021-07-18 16:45:20,210 epoch 23 - iter 944/1182 - loss 0.05920261 - samples/sec: 62.94 - lr: 0.000015
2021-07-18 16:46:20,178 epoch 23 - iter 1062/1182 - loss 0.05870948 - samples/sec: 62.97 - lr: 0.000015
2021-07-18 16:47:20,295 epoch 23 - iter 1180/1182 - loss 0.05829637 - samples/sec: 62.82 - lr: 0.000015
2021-07-18 16:47:21,200 ----------------------------------------------------------------------------------------------------
2021-07-18 16:47:21,200 EPOCH 23 done: loss 0.0584 - lr 0.0000150
2021-07-18 16:47:31,552 DEV : loss 0.11483804136514664 - score 0.9804
2021-07-18 16:47:31,691 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 16:47:35,541 ----------------------------------------------------------------------------------------------------
2021-07-18 16:48:35,833 epoch 24 - iter 118/1182 - loss 0.06312298 - samples/sec: 62.64 - lr: 0.000015
2021-07-18 16:49:36,061 epoch 24 - iter 236/1182 - loss 0.05819423 - samples/sec: 62.70 - lr: 0.000015
2021-07-18 16:50:35,968 epoch 24 - iter 354/1182 - loss 0.05716532 - samples/sec: 63.04 - lr: 0.000015
2021-07-18 16:51:35,830 epoch 24 - iter 472/1182 - loss 0.05702809 - samples/sec: 63.09 - lr: 0.000015
2021-07-18 16:52:35,704 epoch 24 - iter 590/1182 - loss 0.05729565 - samples/sec: 63.07 - lr: 0.000015
2021-07-18 16:53:35,726 epoch 24 - iter 708/1182 - loss 0.05676823 - samples/sec: 62.92 - lr: 0.000015
2021-07-18 16:54:35,970 epoch 24 - iter 826/1182 - loss 0.05690046 - samples/sec: 62.68 - lr: 0.000015
2021-07-18 16:55:36,130 epoch 24 - iter 944/1182 - loss 0.05711798 - samples/sec: 62.77 - lr: 0.000015
2021-07-18 16:56:36,199 epoch 24 - iter 1062/1182 - loss 0.05638614 - samples/sec: 62.87 - lr: 0.000015
2021-07-18 16:57:36,133 epoch 24 - iter 1180/1182 - loss 0.05534472 - samples/sec: 63.01 - lr: 0.000015
2021-07-18 16:57:37,043 ----------------------------------------------------------------------------------------------------
2021-07-18 16:57:37,043 EPOCH 24 done: loss 0.0553 - lr 0.0000150
2021-07-18 16:57:47,413 DEV : loss 0.11530610173940659 - score 0.976
2021-07-18 16:57:47,554 BAD EPOCHS (no improvement): 1
2021-07-18 16:57:47,554 ----------------------------------------------------------------------------------------------------
2021-07-18 16:58:47,404 epoch 25 - iter 118/1182 - loss 0.04931226 - samples/sec: 63.10 - lr: 0.000015
2021-07-18 16:59:47,276 epoch 25 - iter 236/1182 - loss 0.05454884 - samples/sec: 63.07 - lr: 0.000015
2021-07-18 17:00:47,200 epoch 25 - iter 354/1182 - loss 0.05195965 - samples/sec: 63.02 - lr: 0.000015
2021-07-18 17:01:47,357 epoch 25 - iter 472/1182 - loss 0.05418870 - samples/sec: 62.78 - lr: 0.000015
2021-07-18 17:02:47,573 epoch 25 - iter 590/1182 - loss 0.05401175 - samples/sec: 62.71 - lr: 0.000015
2021-07-18 17:03:47,740 epoch 25 - iter 708/1182 - loss 0.05291142 - samples/sec: 62.76 - lr: 0.000015
2021-07-18 17:04:47,990 epoch 25 - iter 826/1182 - loss 0.05261742 - samples/sec: 62.68 - lr: 0.000015
2021-07-18 17:05:48,338 epoch 25 - iter 944/1182 - loss 0.05350447 - samples/sec: 62.58 - lr: 0.000015
2021-07-18 17:06:48,505 epoch 25 - iter 1062/1182 - loss 0.05373527 - samples/sec: 62.77 - lr: 0.000015
2021-07-18 17:07:48,650 epoch 25 - iter 1180/1182 - loss 0.05352354 - samples/sec: 62.79 - lr: 0.000015
2021-07-18 17:07:49,563 ----------------------------------------------------------------------------------------------------
2021-07-18 17:07:49,563 EPOCH 25 done: loss 0.0535 - lr 0.0000150
2021-07-18 17:07:59,910 DEV : loss 0.11907174438238144 - score 0.9777
2021-07-18 17:08:00,048 BAD EPOCHS (no improvement): 2
2021-07-18 17:08:00,048 ----------------------------------------------------------------------------------------------------
2021-07-18 17:09:00,145 epoch 26 - iter 118/1182 - loss 0.05312322 - samples/sec: 62.84 - lr: 0.000015
2021-07-18 17:10:00,224 epoch 26 - iter 236/1182 - loss 0.05094815 - samples/sec: 62.86 - lr: 0.000015
2021-07-18 17:11:03,037 epoch 26 - iter 354/1182 - loss 0.05102876 - samples/sec: 60.12 - lr: 0.000015
2021-07-18 17:12:03,213 epoch 26 - iter 472/1182 - loss 0.05094884 - samples/sec: 62.76 - lr: 0.000015
2021-07-18 17:13:03,477 epoch 26 - iter 590/1182 - loss 0.05108410 - samples/sec: 62.66 - lr: 0.000015
2021-07-18 17:14:03,694 epoch 26 - iter 708/1182 - loss 0.05088075 - samples/sec: 62.71 - lr: 0.000015
2021-07-18 17:15:03,833 epoch 26 - iter 826/1182 - loss 0.05179057 - samples/sec: 62.79 - lr: 0.000015
2021-07-18 17:16:04,005 epoch 26 - iter 944/1182 - loss 0.05208966 - samples/sec: 62.76 - lr: 0.000015
2021-07-18 17:17:04,299 epoch 26 - iter 1062/1182 - loss 0.05357547 - samples/sec: 62.63 - lr: 0.000015
2021-07-18 17:18:04,134 epoch 26 - iter 1180/1182 - loss 0.05310867 - samples/sec: 63.11 - lr: 0.000015
2021-07-18 17:18:05,051 ----------------------------------------------------------------------------------------------------
2021-07-18 17:18:05,051 EPOCH 26 done: loss 0.0531 - lr 0.0000150
2021-07-18 17:18:15,402 DEV : loss 0.11519081890583038 - score 0.9777
2021-07-18 17:18:15,540 BAD EPOCHS (no improvement): 3
2021-07-18 17:18:15,540 ----------------------------------------------------------------------------------------------------
2021-07-18 17:19:15,570 epoch 27 - iter 118/1182 - loss 0.05449054 - samples/sec: 62.91 - lr: 0.000015
2021-07-18 17:20:15,706 epoch 27 - iter 236/1182 - loss 0.05397503 - samples/sec: 62.80 - lr: 0.000015
2021-07-18 17:21:15,857 epoch 27 - iter 354/1182 - loss 0.04965049 - samples/sec: 62.78 - lr: 0.000015
2021-07-18 17:22:16,036 epoch 27 - iter 472/1182 - loss 0.04768805 - samples/sec: 62.75 - lr: 0.000015
2021-07-18 17:23:16,181 epoch 27 - iter 590/1182 - loss 0.04760466 - samples/sec: 62.79 - lr: 0.000015
2021-07-18 17:24:16,355 epoch 27 - iter 708/1182 - loss 0.04846690 - samples/sec: 62.76 - lr: 0.000015
2021-07-18 17:25:15,824 epoch 27 - iter 826/1182 - loss 0.04803938 - samples/sec: 63.50 - lr: 0.000015
2021-07-18 17:26:16,142 epoch 27 - iter 944/1182 - loss 0.04884939 - samples/sec: 62.61 - lr: 0.000015
2021-07-18 17:27:16,461 epoch 27 - iter 1062/1182 - loss 0.04797725 - samples/sec: 62.61 - lr: 0.000015
2021-07-18 17:28:16,643 epoch 27 - iter 1180/1182 - loss 0.04801592 - samples/sec: 62.75 - lr: 0.000015
2021-07-18 17:28:17,555 ----------------------------------------------------------------------------------------------------
2021-07-18 17:28:17,556 EPOCH 27 done: loss 0.0479 - lr 0.0000150
2021-07-18 17:28:27,895 DEV : loss 0.12146931141614914 - score 0.9786
Epoch    27: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 17:28:28,032 BAD EPOCHS (no improvement): 4
2021-07-18 17:28:28,032 ----------------------------------------------------------------------------------------------------
2021-07-18 17:29:28,269 epoch 28 - iter 118/1182 - loss 0.05620184 - samples/sec: 62.69 - lr: 0.000008
2021-07-18 17:30:28,519 epoch 28 - iter 236/1182 - loss 0.04947920 - samples/sec: 62.68 - lr: 0.000008
2021-07-18 17:31:28,803 epoch 28 - iter 354/1182 - loss 0.05007050 - samples/sec: 62.64 - lr: 0.000008
2021-07-18 17:32:28,519 epoch 28 - iter 472/1182 - loss 0.04779973 - samples/sec: 63.24 - lr: 0.000008
2021-07-18 17:33:27,988 epoch 28 - iter 590/1182 - loss 0.04684821 - samples/sec: 63.50 - lr: 0.000008
2021-07-18 17:34:28,239 epoch 28 - iter 708/1182 - loss 0.04762158 - samples/sec: 62.68 - lr: 0.000008
2021-07-18 17:35:28,309 epoch 28 - iter 826/1182 - loss 0.04706205 - samples/sec: 62.87 - lr: 0.000008
2021-07-18 17:36:28,685 epoch 28 - iter 944/1182 - loss 0.04720807 - samples/sec: 62.55 - lr: 0.000008
2021-07-18 17:37:28,959 epoch 28 - iter 1062/1182 - loss 0.04747531 - samples/sec: 62.65 - lr: 0.000008
2021-07-18 17:38:28,897 epoch 28 - iter 1180/1182 - loss 0.04684459 - samples/sec: 63.01 - lr: 0.000008
2021-07-18 17:38:29,789 ----------------------------------------------------------------------------------------------------
2021-07-18 17:38:29,789 EPOCH 28 done: loss 0.0469 - lr 0.0000075
2021-07-18 17:38:40,147 DEV : loss 0.12350501120090485 - score 0.9795
2021-07-18 17:38:40,286 BAD EPOCHS (no improvement): 1
2021-07-18 17:38:40,286 ----------------------------------------------------------------------------------------------------
2021-07-18 17:39:40,495 epoch 29 - iter 118/1182 - loss 0.04079284 - samples/sec: 62.72 - lr: 0.000008
2021-07-18 17:40:40,217 epoch 29 - iter 236/1182 - loss 0.03990858 - samples/sec: 63.23 - lr: 0.000008
2021-07-18 17:41:40,459 epoch 29 - iter 354/1182 - loss 0.04164189 - samples/sec: 62.69 - lr: 0.000008
2021-07-18 17:42:40,697 epoch 29 - iter 472/1182 - loss 0.04108989 - samples/sec: 62.69 - lr: 0.000008
2021-07-18 17:43:40,561 epoch 29 - iter 590/1182 - loss 0.04079715 - samples/sec: 63.08 - lr: 0.000008
2021-07-18 17:44:40,681 epoch 29 - iter 708/1182 - loss 0.04194113 - samples/sec: 62.81 - lr: 0.000008
2021-07-18 17:45:40,837 epoch 29 - iter 826/1182 - loss 0.04387662 - samples/sec: 62.78 - lr: 0.000008
2021-07-18 17:46:40,707 epoch 29 - iter 944/1182 - loss 0.04454085 - samples/sec: 63.08 - lr: 0.000008
2021-07-18 17:47:40,449 epoch 29 - iter 1062/1182 - loss 0.04446262 - samples/sec: 63.21 - lr: 0.000008
2021-07-18 17:48:40,429 epoch 29 - iter 1180/1182 - loss 0.04409223 - samples/sec: 62.96 - lr: 0.000008
2021-07-18 17:48:41,343 ----------------------------------------------------------------------------------------------------
2021-07-18 17:48:41,343 EPOCH 29 done: loss 0.0441 - lr 0.0000075
2021-07-18 17:48:51,701 DEV : loss 0.12427863478660583 - score 0.9777
2021-07-18 17:48:51,839 BAD EPOCHS (no improvement): 2
2021-07-18 17:48:51,840 ----------------------------------------------------------------------------------------------------
2021-07-18 17:49:51,958 epoch 30 - iter 118/1182 - loss 0.04024025 - samples/sec: 62.82 - lr: 0.000008
2021-07-18 17:50:52,226 epoch 30 - iter 236/1182 - loss 0.04142431 - samples/sec: 62.66 - lr: 0.000008
2021-07-18 17:51:52,307 epoch 30 - iter 354/1182 - loss 0.04291145 - samples/sec: 62.86 - lr: 0.000008
2021-07-18 17:52:52,008 epoch 30 - iter 472/1182 - loss 0.04523257 - samples/sec: 63.25 - lr: 0.000008
2021-07-18 17:53:51,574 epoch 30 - iter 590/1182 - loss 0.04299993 - samples/sec: 63.40 - lr: 0.000008
2021-07-18 17:54:51,698 epoch 30 - iter 708/1182 - loss 0.04307554 - samples/sec: 62.81 - lr: 0.000008
2021-07-18 17:55:52,071 epoch 30 - iter 826/1182 - loss 0.04319968 - samples/sec: 62.55 - lr: 0.000008
2021-07-18 17:56:52,241 epoch 30 - iter 944/1182 - loss 0.04385143 - samples/sec: 62.76 - lr: 0.000008
2021-07-18 17:57:52,575 epoch 30 - iter 1062/1182 - loss 0.04413558 - samples/sec: 62.59 - lr: 0.000008
2021-07-18 17:58:52,785 epoch 30 - iter 1180/1182 - loss 0.04405767 - samples/sec: 62.72 - lr: 0.000008
2021-07-18 17:58:53,679 ----------------------------------------------------------------------------------------------------
2021-07-18 17:58:53,679 EPOCH 30 done: loss 0.0440 - lr 0.0000075
2021-07-18 17:59:06,717 DEV : loss 0.12324885278940201 - score 0.9789
2021-07-18 17:59:06,857 BAD EPOCHS (no improvement): 3
2021-07-18 17:59:06,857 ----------------------------------------------------------------------------------------------------
2021-07-18 18:00:06,973 epoch 31 - iter 118/1182 - loss 0.04108228 - samples/sec: 62.82 - lr: 0.000008
2021-07-18 18:01:07,265 epoch 31 - iter 236/1182 - loss 0.03798589 - samples/sec: 62.63 - lr: 0.000008
2021-07-18 18:02:07,154 epoch 31 - iter 354/1182 - loss 0.03930362 - samples/sec: 63.06 - lr: 0.000008
2021-07-18 18:03:07,497 epoch 31 - iter 472/1182 - loss 0.03971496 - samples/sec: 62.58 - lr: 0.000008
2021-07-18 18:04:07,750 epoch 31 - iter 590/1182 - loss 0.04059475 - samples/sec: 62.67 - lr: 0.000008
2021-07-18 18:05:08,022 epoch 31 - iter 708/1182 - loss 0.04107142 - samples/sec: 62.66 - lr: 0.000008
2021-07-18 18:06:08,092 epoch 31 - iter 826/1182 - loss 0.04066830 - samples/sec: 62.87 - lr: 0.000008
2021-07-18 18:07:08,349 epoch 31 - iter 944/1182 - loss 0.04108516 - samples/sec: 62.67 - lr: 0.000008
2021-07-18 18:08:08,735 epoch 31 - iter 1062/1182 - loss 0.04118429 - samples/sec: 62.54 - lr: 0.000008
2021-07-18 18:09:08,922 epoch 31 - iter 1180/1182 - loss 0.04187940 - samples/sec: 62.74 - lr: 0.000008
2021-07-18 18:09:09,821 ----------------------------------------------------------------------------------------------------
2021-07-18 18:09:09,821 EPOCH 31 done: loss 0.0418 - lr 0.0000075
2021-07-18 18:09:20,169 DEV : loss 0.1272950917482376 - score 0.9775
Epoch    31: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 18:09:20,308 BAD EPOCHS (no improvement): 4
2021-07-18 18:09:20,308 ----------------------------------------------------------------------------------------------------
2021-07-18 18:10:20,199 epoch 32 - iter 118/1182 - loss 0.03629701 - samples/sec: 63.06 - lr: 0.000004
2021-07-18 18:11:19,910 epoch 32 - iter 236/1182 - loss 0.03885561 - samples/sec: 63.24 - lr: 0.000004
2021-07-18 18:12:20,174 epoch 32 - iter 354/1182 - loss 0.03927681 - samples/sec: 62.66 - lr: 0.000004
2021-07-18 18:13:20,508 epoch 32 - iter 472/1182 - loss 0.04072905 - samples/sec: 62.59 - lr: 0.000004
2021-07-18 18:14:20,638 epoch 32 - iter 590/1182 - loss 0.04078685 - samples/sec: 62.80 - lr: 0.000004
2021-07-18 18:15:20,005 epoch 32 - iter 708/1182 - loss 0.03985635 - samples/sec: 63.61 - lr: 0.000004
2021-07-18 18:16:19,358 epoch 32 - iter 826/1182 - loss 0.04021685 - samples/sec: 63.63 - lr: 0.000004
2021-07-18 18:17:19,217 epoch 32 - iter 944/1182 - loss 0.03997983 - samples/sec: 63.09 - lr: 0.000004
2021-07-18 18:18:19,437 epoch 32 - iter 1062/1182 - loss 0.04021548 - samples/sec: 62.71 - lr: 0.000004
2021-07-18 18:19:19,622 epoch 32 - iter 1180/1182 - loss 0.04041025 - samples/sec: 62.75 - lr: 0.000004
2021-07-18 18:19:20,508 ----------------------------------------------------------------------------------------------------
2021-07-18 18:19:20,508 EPOCH 32 done: loss 0.0404 - lr 0.0000038
2021-07-18 18:19:30,861 DEV : loss 0.12454556673765182 - score 0.9787
2021-07-18 18:19:30,998 BAD EPOCHS (no improvement): 1
2021-07-18 18:19:30,998 ----------------------------------------------------------------------------------------------------
2021-07-18 18:20:31,182 epoch 33 - iter 118/1182 - loss 0.04304844 - samples/sec: 62.75 - lr: 0.000004
2021-07-18 18:21:31,413 epoch 33 - iter 236/1182 - loss 0.04142041 - samples/sec: 62.70 - lr: 0.000004
2021-07-18 18:22:31,572 epoch 33 - iter 354/1182 - loss 0.03922530 - samples/sec: 62.77 - lr: 0.000004
2021-07-18 18:23:31,762 epoch 33 - iter 472/1182 - loss 0.03933000 - samples/sec: 62.74 - lr: 0.000004
2021-07-18 18:24:32,041 epoch 33 - iter 590/1182 - loss 0.03997902 - samples/sec: 62.65 - lr: 0.000004
2021-07-18 18:25:32,122 epoch 33 - iter 708/1182 - loss 0.04066885 - samples/sec: 62.85 - lr: 0.000004
2021-07-18 18:26:32,500 epoch 33 - iter 826/1182 - loss 0.04082103 - samples/sec: 62.55 - lr: 0.000004
2021-07-18 18:27:32,859 epoch 33 - iter 944/1182 - loss 0.04005960 - samples/sec: 62.57 - lr: 0.000004
2021-07-18 18:28:33,093 epoch 33 - iter 1062/1182 - loss 0.03959204 - samples/sec: 62.69 - lr: 0.000004
2021-07-18 18:29:33,252 epoch 33 - iter 1180/1182 - loss 0.03990696 - samples/sec: 62.77 - lr: 0.000004
2021-07-18 18:29:34,167 ----------------------------------------------------------------------------------------------------
2021-07-18 18:29:34,168 EPOCH 33 done: loss 0.0399 - lr 0.0000038
2021-07-18 18:29:44,520 DEV : loss 0.12435790151357651 - score 0.9781
2021-07-18 18:29:44,659 BAD EPOCHS (no improvement): 2
2021-07-18 18:29:44,659 ----------------------------------------------------------------------------------------------------
2021-07-18 18:30:44,706 epoch 34 - iter 118/1182 - loss 0.03424644 - samples/sec: 62.89 - lr: 0.000004
2021-07-18 18:31:44,439 epoch 34 - iter 236/1182 - loss 0.03650941 - samples/sec: 63.22 - lr: 0.000004
2021-07-18 18:32:44,358 epoch 34 - iter 354/1182 - loss 0.03804242 - samples/sec: 63.02 - lr: 0.000004
2021-07-18 18:33:44,418 epoch 34 - iter 472/1182 - loss 0.03958120 - samples/sec: 62.88 - lr: 0.000004
2021-07-18 18:34:44,372 epoch 34 - iter 590/1182 - loss 0.03861739 - samples/sec: 62.99 - lr: 0.000004
2021-07-18 18:35:44,393 epoch 34 - iter 708/1182 - loss 0.03920123 - samples/sec: 62.92 - lr: 0.000004
2021-07-18 18:36:44,280 epoch 34 - iter 826/1182 - loss 0.03816771 - samples/sec: 63.06 - lr: 0.000004
2021-07-18 18:37:44,237 epoch 34 - iter 944/1182 - loss 0.03815761 - samples/sec: 62.98 - lr: 0.000004
2021-07-18 18:38:44,166 epoch 34 - iter 1062/1182 - loss 0.03818748 - samples/sec: 63.01 - lr: 0.000004
2021-07-18 18:39:44,454 epoch 34 - iter 1180/1182 - loss 0.03888147 - samples/sec: 62.64 - lr: 0.000004
2021-07-18 18:39:45,373 ----------------------------------------------------------------------------------------------------
2021-07-18 18:39:45,373 EPOCH 34 done: loss 0.0389 - lr 0.0000038
2021-07-18 18:39:55,729 DEV : loss 0.12410341948270798 - score 0.9789
2021-07-18 18:39:55,869 BAD EPOCHS (no improvement): 3
2021-07-18 18:39:55,870 ----------------------------------------------------------------------------------------------------
2021-07-18 18:40:55,986 epoch 35 - iter 118/1182 - loss 0.04183741 - samples/sec: 62.82 - lr: 0.000004
2021-07-18 18:41:56,246 epoch 35 - iter 236/1182 - loss 0.04157666 - samples/sec: 62.67 - lr: 0.000004
2021-07-18 18:42:56,590 epoch 35 - iter 354/1182 - loss 0.04172252 - samples/sec: 62.58 - lr: 0.000004
2021-07-18 18:43:56,803 epoch 35 - iter 472/1182 - loss 0.04142022 - samples/sec: 62.72 - lr: 0.000004
2021-07-18 18:44:56,883 epoch 35 - iter 590/1182 - loss 0.03993616 - samples/sec: 62.86 - lr: 0.000004
2021-07-18 18:45:57,065 epoch 35 - iter 708/1182 - loss 0.04090054 - samples/sec: 62.75 - lr: 0.000004
2021-07-18 18:46:57,469 epoch 35 - iter 826/1182 - loss 0.04042499 - samples/sec: 62.52 - lr: 0.000004
2021-07-18 18:47:57,742 epoch 35 - iter 944/1182 - loss 0.04002091 - samples/sec: 62.65 - lr: 0.000004
2021-07-18 18:48:58,174 epoch 35 - iter 1062/1182 - loss 0.03910541 - samples/sec: 62.49 - lr: 0.000004
2021-07-18 18:49:58,317 epoch 35 - iter 1180/1182 - loss 0.03952890 - samples/sec: 62.79 - lr: 0.000004
2021-07-18 18:49:59,235 ----------------------------------------------------------------------------------------------------
2021-07-18 18:49:59,235 EPOCH 35 done: loss 0.0395 - lr 0.0000038
2021-07-18 18:50:12,351 DEV : loss 0.12471553683280945 - score 0.9778
Epoch    35: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 18:50:12,487 BAD EPOCHS (no improvement): 4
2021-07-18 18:50:12,488 ----------------------------------------------------------------------------------------------------
2021-07-18 18:50:12,488 ----------------------------------------------------------------------------------------------------
2021-07-18 18:50:12,488 learning rate too small - quitting training!
2021-07-18 18:50:12,488 ----------------------------------------------------------------------------------------------------
2021-07-18 18:50:13,326 ----------------------------------------------------------------------------------------------------
2021-07-18 18:50:13,326 Testing using best model ...
2021-07-18 18:50:13,326 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.pdtb.pdtb/best-model.pt
2021-07-18 18:53:57,432 0.9725	0.9799	0.9762
2021-07-18 18:53:57,432 
Results:
- F1-score (micro) 0.9762
- F1-score (macro) 0.9762

By class:
SENT       tp: 11678 - fp: 330 - fn: 240 - precision: 0.9725 - recall: 0.9799 - f1-score: 0.9762
2021-07-18 18:53:57,432 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.gum/
2021-07-18 18:53:57,451 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.gum
2021-07-18 18:53:57,452 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.gum/sent_train.txt
2021-07-18 18:53:57,454 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.gum/sent_dev.txt
2021-07-18 18:53:57,456 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.gum/sent_test.txt
Corpus: 4282 train + 865 dev + 1250 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 18:54:01,152 ----------------------------------------------------------------------------------------------------
2021-07-18 18:54:01,154 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 18:54:01,154 ----------------------------------------------------------------------------------------------------
2021-07-18 18:54:01,154 Corpus: "Corpus: 4282 train + 865 dev + 1250 test sentences"
2021-07-18 18:54:01,154 ----------------------------------------------------------------------------------------------------
2021-07-18 18:54:01,154 Parameters:
2021-07-18 18:54:01,154  - learning_rate: "3e-05"
2021-07-18 18:54:01,154  - mini_batch_size: "32"
2021-07-18 18:54:01,154  - patience: "3"
2021-07-18 18:54:01,154  - anneal_factor: "0.5"
2021-07-18 18:54:01,154  - max_epochs: "40"
2021-07-18 18:54:01,154  - shuffle: "True"
2021-07-18 18:54:01,154  - train_with_dev: "False"
2021-07-18 18:54:01,154  - batch_growth_annealing: "False"
2021-07-18 18:54:01,154 ----------------------------------------------------------------------------------------------------
2021-07-18 18:54:01,154 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.gum"
2021-07-18 18:54:01,154 ----------------------------------------------------------------------------------------------------
2021-07-18 18:54:01,154 Device: cuda:0
2021-07-18 18:54:01,154 ----------------------------------------------------------------------------------------------------
2021-07-18 18:54:01,154 Embeddings storage mode: cpu
2021-07-18 18:54:01,157 ----------------------------------------------------------------------------------------------------
2021-07-18 18:54:13,957 epoch 1 - iter 13/134 - loss 19.08292448 - samples/sec: 32.50 - lr: 0.000030
2021-07-18 18:54:36,109 epoch 1 - iter 26/134 - loss 12.72835071 - samples/sec: 18.78 - lr: 0.000030
2021-07-18 18:54:49,566 epoch 1 - iter 39/134 - loss 9.95125641 - samples/sec: 30.91 - lr: 0.000030
2021-07-18 18:55:03,012 epoch 1 - iter 52/134 - loss 8.26743217 - samples/sec: 30.94 - lr: 0.000030
2021-07-18 18:55:16,449 epoch 1 - iter 65/134 - loss 7.08687676 - samples/sec: 30.96 - lr: 0.000030
2021-07-18 18:55:29,842 epoch 1 - iter 78/134 - loss 6.19443828 - samples/sec: 31.06 - lr: 0.000030
2021-07-18 18:55:43,302 epoch 1 - iter 91/134 - loss 5.52319623 - samples/sec: 30.91 - lr: 0.000030
2021-07-18 18:55:56,768 epoch 1 - iter 104/134 - loss 5.00458721 - samples/sec: 30.89 - lr: 0.000030
2021-07-18 18:56:10,236 epoch 1 - iter 117/134 - loss 4.58521630 - samples/sec: 30.89 - lr: 0.000030
2021-07-18 18:56:23,683 epoch 1 - iter 130/134 - loss 4.23242949 - samples/sec: 30.94 - lr: 0.000030
2021-07-18 18:56:27,615 ----------------------------------------------------------------------------------------------------
2021-07-18 18:56:27,615 EPOCH 1 done: loss 4.1422 - lr 0.0000300
2021-07-18 18:56:43,383 DEV : loss 0.5194799900054932 - score 0.9256
2021-07-18 18:56:43,448 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 18:56:44,122 ----------------------------------------------------------------------------------------------------
2021-07-18 18:56:50,974 epoch 2 - iter 13/134 - loss 1.04242226 - samples/sec: 60.72 - lr: 0.000030
2021-07-18 18:56:57,846 epoch 2 - iter 26/134 - loss 0.94708256 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 18:57:04,760 epoch 2 - iter 39/134 - loss 0.96845478 - samples/sec: 60.18 - lr: 0.000030
2021-07-18 18:57:11,630 epoch 2 - iter 52/134 - loss 0.94598709 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 18:57:18,487 epoch 2 - iter 65/134 - loss 0.93097635 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 18:57:25,364 epoch 2 - iter 78/134 - loss 0.90971146 - samples/sec: 60.50 - lr: 0.000030
2021-07-18 18:57:32,227 epoch 2 - iter 91/134 - loss 0.90664313 - samples/sec: 60.63 - lr: 0.000030
2021-07-18 18:57:39,077 epoch 2 - iter 104/134 - loss 0.90412927 - samples/sec: 60.74 - lr: 0.000030
2021-07-18 18:57:45,882 epoch 2 - iter 117/134 - loss 0.88969621 - samples/sec: 61.14 - lr: 0.000030
2021-07-18 18:57:52,775 epoch 2 - iter 130/134 - loss 0.87770834 - samples/sec: 60.36 - lr: 0.000030
2021-07-18 18:57:54,811 ----------------------------------------------------------------------------------------------------
2021-07-18 18:57:54,811 EPOCH 2 done: loss 0.8738 - lr 0.0000300
2021-07-18 18:57:59,565 DEV : loss 0.39416250586509705 - score 0.9444
2021-07-18 18:57:59,629 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 18:58:03,425 ----------------------------------------------------------------------------------------------------
2021-07-18 18:58:10,258 epoch 3 - iter 13/134 - loss 0.81877116 - samples/sec: 60.89 - lr: 0.000030
2021-07-18 18:58:17,083 epoch 3 - iter 26/134 - loss 0.78016347 - samples/sec: 60.96 - lr: 0.000030
2021-07-18 18:58:23,902 epoch 3 - iter 39/134 - loss 0.75861286 - samples/sec: 61.02 - lr: 0.000030
2021-07-18 18:58:30,769 epoch 3 - iter 52/134 - loss 0.71563056 - samples/sec: 60.59 - lr: 0.000030
2021-07-18 18:58:37,587 epoch 3 - iter 65/134 - loss 0.71320176 - samples/sec: 61.02 - lr: 0.000030
2021-07-18 18:58:44,443 epoch 3 - iter 78/134 - loss 0.68999932 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 18:58:51,238 epoch 3 - iter 91/134 - loss 0.67865608 - samples/sec: 61.24 - lr: 0.000030
2021-07-18 18:58:58,086 epoch 3 - iter 104/134 - loss 0.68517134 - samples/sec: 60.75 - lr: 0.000030
2021-07-18 18:59:04,895 epoch 3 - iter 117/134 - loss 0.68543277 - samples/sec: 61.11 - lr: 0.000030
2021-07-18 18:59:11,782 epoch 3 - iter 130/134 - loss 0.67835120 - samples/sec: 60.41 - lr: 0.000030
2021-07-18 18:59:13,816 ----------------------------------------------------------------------------------------------------
2021-07-18 18:59:13,817 EPOCH 3 done: loss 0.6756 - lr 0.0000300
2021-07-18 18:59:18,956 DEV : loss 0.3382870852947235 - score 0.9487
2021-07-18 18:59:19,021 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 18:59:22,700 ----------------------------------------------------------------------------------------------------
2021-07-18 18:59:29,541 epoch 4 - iter 13/134 - loss 0.55151093 - samples/sec: 60.82 - lr: 0.000030
2021-07-18 18:59:36,398 epoch 4 - iter 26/134 - loss 0.56111363 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 18:59:43,219 epoch 4 - iter 39/134 - loss 0.55906847 - samples/sec: 60.99 - lr: 0.000030
2021-07-18 18:59:50,052 epoch 4 - iter 52/134 - loss 0.56088327 - samples/sec: 60.89 - lr: 0.000030
2021-07-18 18:59:56,930 epoch 4 - iter 65/134 - loss 0.58962517 - samples/sec: 60.49 - lr: 0.000030
2021-07-18 19:00:03,741 epoch 4 - iter 78/134 - loss 0.58173616 - samples/sec: 61.09 - lr: 0.000030
2021-07-18 19:00:10,575 epoch 4 - iter 91/134 - loss 0.57003449 - samples/sec: 60.88 - lr: 0.000030
2021-07-18 19:00:17,391 epoch 4 - iter 104/134 - loss 0.56587024 - samples/sec: 61.04 - lr: 0.000030
2021-07-18 19:00:24,246 epoch 4 - iter 117/134 - loss 0.56197613 - samples/sec: 60.69 - lr: 0.000030
2021-07-18 19:00:31,119 epoch 4 - iter 130/134 - loss 0.56114568 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:00:33,129 ----------------------------------------------------------------------------------------------------
2021-07-18 19:00:33,129 EPOCH 4 done: loss 0.5571 - lr 0.0000300
2021-07-18 19:00:37,841 DEV : loss 0.30259472131729126 - score 0.9534
2021-07-18 19:00:37,906 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:00:41,655 ----------------------------------------------------------------------------------------------------
2021-07-18 19:00:48,490 epoch 5 - iter 13/134 - loss 0.57957294 - samples/sec: 60.88 - lr: 0.000030
2021-07-18 19:00:55,371 epoch 5 - iter 26/134 - loss 0.56865096 - samples/sec: 60.47 - lr: 0.000030
2021-07-18 19:01:02,278 epoch 5 - iter 39/134 - loss 0.54238214 - samples/sec: 60.24 - lr: 0.000030
2021-07-18 19:01:09,096 epoch 5 - iter 52/134 - loss 0.52267454 - samples/sec: 61.02 - lr: 0.000030
2021-07-18 19:01:15,967 epoch 5 - iter 65/134 - loss 0.51589336 - samples/sec: 60.55 - lr: 0.000030
2021-07-18 19:01:22,842 epoch 5 - iter 78/134 - loss 0.51157750 - samples/sec: 60.52 - lr: 0.000030
2021-07-18 19:01:29,753 epoch 5 - iter 91/134 - loss 0.50782444 - samples/sec: 60.21 - lr: 0.000030
2021-07-18 19:01:36,679 epoch 5 - iter 104/134 - loss 0.50643542 - samples/sec: 60.07 - lr: 0.000030
2021-07-18 19:01:43,547 epoch 5 - iter 117/134 - loss 0.50685833 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 19:01:50,442 epoch 5 - iter 130/134 - loss 0.49806164 - samples/sec: 60.34 - lr: 0.000030
2021-07-18 19:01:52,465 ----------------------------------------------------------------------------------------------------
2021-07-18 19:01:52,466 EPOCH 5 done: loss 0.4914 - lr 0.0000300
2021-07-18 19:01:57,179 DEV : loss 0.28609466552734375 - score 0.956
2021-07-18 19:01:57,245 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:02:00,936 ----------------------------------------------------------------------------------------------------
2021-07-18 19:02:07,793 epoch 6 - iter 13/134 - loss 0.47681996 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 19:02:14,698 epoch 6 - iter 26/134 - loss 0.49947945 - samples/sec: 60.26 - lr: 0.000030
2021-07-18 19:02:21,584 epoch 6 - iter 39/134 - loss 0.48224522 - samples/sec: 60.42 - lr: 0.000030
2021-07-18 19:02:28,446 epoch 6 - iter 52/134 - loss 0.46978175 - samples/sec: 60.63 - lr: 0.000030
2021-07-18 19:02:35,348 epoch 6 - iter 65/134 - loss 0.45789316 - samples/sec: 60.29 - lr: 0.000030
2021-07-18 19:02:42,160 epoch 6 - iter 78/134 - loss 0.45029261 - samples/sec: 61.08 - lr: 0.000030
2021-07-18 19:02:49,081 epoch 6 - iter 91/134 - loss 0.44898581 - samples/sec: 60.11 - lr: 0.000030
2021-07-18 19:02:55,992 epoch 6 - iter 104/134 - loss 0.44413002 - samples/sec: 60.21 - lr: 0.000030
2021-07-18 19:03:02,888 epoch 6 - iter 117/134 - loss 0.43867904 - samples/sec: 60.33 - lr: 0.000030
2021-07-18 19:03:09,739 epoch 6 - iter 130/134 - loss 0.43649061 - samples/sec: 60.73 - lr: 0.000030
2021-07-18 19:03:11,780 ----------------------------------------------------------------------------------------------------
2021-07-18 19:03:11,781 EPOCH 6 done: loss 0.4375 - lr 0.0000300
2021-07-18 19:03:16,501 DEV : loss 0.2553088366985321 - score 0.958
2021-07-18 19:03:16,566 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:03:20,473 ----------------------------------------------------------------------------------------------------
2021-07-18 19:03:27,366 epoch 7 - iter 13/134 - loss 0.44627400 - samples/sec: 60.37 - lr: 0.000030
2021-07-18 19:03:34,249 epoch 7 - iter 26/134 - loss 0.42331530 - samples/sec: 60.44 - lr: 0.000030
2021-07-18 19:03:41,103 epoch 7 - iter 39/134 - loss 0.42631155 - samples/sec: 60.71 - lr: 0.000030
2021-07-18 19:03:48,000 epoch 7 - iter 52/134 - loss 0.42939349 - samples/sec: 60.32 - lr: 0.000030
2021-07-18 19:03:54,850 epoch 7 - iter 65/134 - loss 0.42588869 - samples/sec: 60.74 - lr: 0.000030
2021-07-18 19:04:01,748 epoch 7 - iter 78/134 - loss 0.42314426 - samples/sec: 60.31 - lr: 0.000030
2021-07-18 19:04:08,623 epoch 7 - iter 91/134 - loss 0.42217765 - samples/sec: 60.52 - lr: 0.000030
2021-07-18 19:04:15,459 epoch 7 - iter 104/134 - loss 0.42061491 - samples/sec: 60.86 - lr: 0.000030
2021-07-18 19:04:22,315 epoch 7 - iter 117/134 - loss 0.41566928 - samples/sec: 60.69 - lr: 0.000030
2021-07-18 19:04:29,197 epoch 7 - iter 130/134 - loss 0.41287992 - samples/sec: 60.45 - lr: 0.000030
2021-07-18 19:04:31,223 ----------------------------------------------------------------------------------------------------
2021-07-18 19:04:31,224 EPOCH 7 done: loss 0.4107 - lr 0.0000300
2021-07-18 19:04:36,370 DEV : loss 0.2612186074256897 - score 0.9583
2021-07-18 19:04:36,435 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:04:40,271 ----------------------------------------------------------------------------------------------------
2021-07-18 19:04:47,162 epoch 8 - iter 13/134 - loss 0.41990415 - samples/sec: 60.38 - lr: 0.000030
2021-07-18 19:04:53,990 epoch 8 - iter 26/134 - loss 0.36186289 - samples/sec: 60.94 - lr: 0.000030
2021-07-18 19:05:00,853 epoch 8 - iter 39/134 - loss 0.36005814 - samples/sec: 60.62 - lr: 0.000030
2021-07-18 19:05:07,766 epoch 8 - iter 52/134 - loss 0.38633858 - samples/sec: 60.19 - lr: 0.000030
2021-07-18 19:05:14,633 epoch 8 - iter 65/134 - loss 0.37184876 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 19:05:21,526 epoch 8 - iter 78/134 - loss 0.35890579 - samples/sec: 60.36 - lr: 0.000030
2021-07-18 19:05:28,407 epoch 8 - iter 91/134 - loss 0.36973613 - samples/sec: 60.47 - lr: 0.000030
2021-07-18 19:05:35,292 epoch 8 - iter 104/134 - loss 0.36670256 - samples/sec: 60.43 - lr: 0.000030
2021-07-18 19:05:42,133 epoch 8 - iter 117/134 - loss 0.36348327 - samples/sec: 60.81 - lr: 0.000030
2021-07-18 19:05:49,004 epoch 8 - iter 130/134 - loss 0.37442308 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 19:05:51,046 ----------------------------------------------------------------------------------------------------
2021-07-18 19:05:51,047 EPOCH 8 done: loss 0.3791 - lr 0.0000300
2021-07-18 19:05:55,760 DEV : loss 0.24885398149490356 - score 0.9596
2021-07-18 19:05:55,826 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:05:59,456 ----------------------------------------------------------------------------------------------------
2021-07-18 19:06:06,326 epoch 9 - iter 13/134 - loss 0.32369870 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 19:06:13,244 epoch 9 - iter 26/134 - loss 0.37018287 - samples/sec: 60.14 - lr: 0.000030
2021-07-18 19:06:20,158 epoch 9 - iter 39/134 - loss 0.39184574 - samples/sec: 60.17 - lr: 0.000030
2021-07-18 19:06:27,030 epoch 9 - iter 52/134 - loss 0.36832779 - samples/sec: 60.55 - lr: 0.000030
2021-07-18 19:06:33,891 epoch 9 - iter 65/134 - loss 0.37086972 - samples/sec: 60.64 - lr: 0.000030
2021-07-18 19:06:40,743 epoch 9 - iter 78/134 - loss 0.36349831 - samples/sec: 60.72 - lr: 0.000030
2021-07-18 19:06:47,595 epoch 9 - iter 91/134 - loss 0.36222628 - samples/sec: 60.72 - lr: 0.000030
2021-07-18 19:06:54,470 epoch 9 - iter 104/134 - loss 0.36355962 - samples/sec: 60.52 - lr: 0.000030
2021-07-18 19:07:01,360 epoch 9 - iter 117/134 - loss 0.36938165 - samples/sec: 60.39 - lr: 0.000030
2021-07-18 19:07:08,264 epoch 9 - iter 130/134 - loss 0.36529615 - samples/sec: 60.26 - lr: 0.000030
2021-07-18 19:07:10,293 ----------------------------------------------------------------------------------------------------
2021-07-18 19:07:10,293 EPOCH 9 done: loss 0.3682 - lr 0.0000300
2021-07-18 19:07:15,005 DEV : loss 0.26653537154197693 - score 0.9579
2021-07-18 19:07:15,070 BAD EPOCHS (no improvement): 1
2021-07-18 19:07:15,070 ----------------------------------------------------------------------------------------------------
2021-07-18 19:07:21,983 epoch 10 - iter 13/134 - loss 0.38659652 - samples/sec: 60.19 - lr: 0.000030
2021-07-18 19:07:28,862 epoch 10 - iter 26/134 - loss 0.37247918 - samples/sec: 60.48 - lr: 0.000030
2021-07-18 19:07:35,742 epoch 10 - iter 39/134 - loss 0.33592837 - samples/sec: 60.47 - lr: 0.000030
2021-07-18 19:07:42,642 epoch 10 - iter 52/134 - loss 0.31453228 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 19:07:49,526 epoch 10 - iter 65/134 - loss 0.32901756 - samples/sec: 60.44 - lr: 0.000030
2021-07-18 19:07:56,382 epoch 10 - iter 78/134 - loss 0.34109356 - samples/sec: 60.69 - lr: 0.000030
2021-07-18 19:08:03,283 epoch 10 - iter 91/134 - loss 0.33959914 - samples/sec: 60.29 - lr: 0.000030
2021-07-18 19:08:10,204 epoch 10 - iter 104/134 - loss 0.33742982 - samples/sec: 60.12 - lr: 0.000030
2021-07-18 19:08:17,094 epoch 10 - iter 117/134 - loss 0.32981931 - samples/sec: 60.39 - lr: 0.000030
2021-07-18 19:08:23,959 epoch 10 - iter 130/134 - loss 0.33408573 - samples/sec: 60.61 - lr: 0.000030
2021-07-18 19:08:25,964 ----------------------------------------------------------------------------------------------------
2021-07-18 19:08:25,965 EPOCH 10 done: loss 0.3342 - lr 0.0000300
2021-07-18 19:08:31,112 DEV : loss 0.23610641062259674 - score 0.961
2021-07-18 19:08:31,177 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:08:35,070 ----------------------------------------------------------------------------------------------------
2021-07-18 19:08:41,972 epoch 11 - iter 13/134 - loss 0.31512217 - samples/sec: 60.28 - lr: 0.000030
2021-07-18 19:08:48,825 epoch 11 - iter 26/134 - loss 0.30890855 - samples/sec: 60.71 - lr: 0.000030
2021-07-18 19:08:55,714 epoch 11 - iter 39/134 - loss 0.29551534 - samples/sec: 60.40 - lr: 0.000030
2021-07-18 19:09:02,589 epoch 11 - iter 52/134 - loss 0.28185226 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 19:09:09,488 epoch 11 - iter 65/134 - loss 0.28066372 - samples/sec: 60.31 - lr: 0.000030
2021-07-18 19:09:16,396 epoch 11 - iter 78/134 - loss 0.29304272 - samples/sec: 60.23 - lr: 0.000030
2021-07-18 19:09:23,296 epoch 11 - iter 91/134 - loss 0.29069360 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 19:09:30,160 epoch 11 - iter 104/134 - loss 0.30261515 - samples/sec: 60.61 - lr: 0.000030
2021-07-18 19:09:36,996 epoch 11 - iter 117/134 - loss 0.30648792 - samples/sec: 60.87 - lr: 0.000030
2021-07-18 19:09:43,807 epoch 11 - iter 130/134 - loss 0.30975833 - samples/sec: 61.09 - lr: 0.000030
2021-07-18 19:09:45,832 ----------------------------------------------------------------------------------------------------
2021-07-18 19:09:45,832 EPOCH 11 done: loss 0.3096 - lr 0.0000300
2021-07-18 19:09:50,533 DEV : loss 0.2483854740858078 - score 0.9619
2021-07-18 19:09:50,598 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:09:54,285 ----------------------------------------------------------------------------------------------------
2021-07-18 19:10:01,130 epoch 12 - iter 13/134 - loss 0.24598760 - samples/sec: 60.79 - lr: 0.000030
2021-07-18 19:10:07,998 epoch 12 - iter 26/134 - loss 0.30861155 - samples/sec: 60.57 - lr: 0.000030
2021-07-18 19:10:14,816 epoch 12 - iter 39/134 - loss 0.31577801 - samples/sec: 61.03 - lr: 0.000030
2021-07-18 19:10:21,648 epoch 12 - iter 52/134 - loss 0.29695263 - samples/sec: 60.90 - lr: 0.000030
2021-07-18 19:10:28,493 epoch 12 - iter 65/134 - loss 0.28866768 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 19:10:35,329 epoch 12 - iter 78/134 - loss 0.29234005 - samples/sec: 60.87 - lr: 0.000030
2021-07-18 19:10:42,153 epoch 12 - iter 91/134 - loss 0.29448810 - samples/sec: 60.96 - lr: 0.000030
2021-07-18 19:10:48,998 epoch 12 - iter 104/134 - loss 0.28904490 - samples/sec: 60.79 - lr: 0.000030
2021-07-18 19:10:55,846 epoch 12 - iter 117/134 - loss 0.28674259 - samples/sec: 60.75 - lr: 0.000030
2021-07-18 19:11:02,722 epoch 12 - iter 130/134 - loss 0.28933275 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 19:11:04,749 ----------------------------------------------------------------------------------------------------
2021-07-18 19:11:04,749 EPOCH 12 done: loss 0.2905 - lr 0.0000300
2021-07-18 19:11:09,453 DEV : loss 0.23538583517074585 - score 0.9594
2021-07-18 19:11:09,518 BAD EPOCHS (no improvement): 1
2021-07-18 19:11:09,518 ----------------------------------------------------------------------------------------------------
2021-07-18 19:11:16,383 epoch 13 - iter 13/134 - loss 0.34154604 - samples/sec: 60.61 - lr: 0.000030
2021-07-18 19:11:23,251 epoch 13 - iter 26/134 - loss 0.31073780 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 19:11:30,123 epoch 13 - iter 39/134 - loss 0.30427538 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:11:37,020 epoch 13 - iter 52/134 - loss 0.29627396 - samples/sec: 60.32 - lr: 0.000030
2021-07-18 19:11:43,899 epoch 13 - iter 65/134 - loss 0.28950446 - samples/sec: 60.48 - lr: 0.000030
2021-07-18 19:11:50,731 epoch 13 - iter 78/134 - loss 0.28692785 - samples/sec: 60.90 - lr: 0.000030
2021-07-18 19:11:57,607 epoch 13 - iter 91/134 - loss 0.29185008 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 19:12:04,427 epoch 13 - iter 104/134 - loss 0.28964443 - samples/sec: 61.00 - lr: 0.000030
2021-07-18 19:12:11,299 epoch 13 - iter 117/134 - loss 0.28230746 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:12:18,126 epoch 13 - iter 130/134 - loss 0.28846384 - samples/sec: 60.95 - lr: 0.000030
2021-07-18 19:12:20,140 ----------------------------------------------------------------------------------------------------
2021-07-18 19:12:20,141 EPOCH 13 done: loss 0.2882 - lr 0.0000300
2021-07-18 19:12:25,286 DEV : loss 0.2416093349456787 - score 0.9587
2021-07-18 19:12:25,351 BAD EPOCHS (no improvement): 2
2021-07-18 19:12:25,352 ----------------------------------------------------------------------------------------------------
2021-07-18 19:12:32,162 epoch 14 - iter 13/134 - loss 0.25568253 - samples/sec: 61.09 - lr: 0.000030
2021-07-18 19:12:39,030 epoch 14 - iter 26/134 - loss 0.26582154 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 19:12:45,886 epoch 14 - iter 39/134 - loss 0.27922234 - samples/sec: 60.69 - lr: 0.000030
2021-07-18 19:12:52,697 epoch 14 - iter 52/134 - loss 0.27440937 - samples/sec: 61.09 - lr: 0.000030
2021-07-18 19:12:59,538 epoch 14 - iter 65/134 - loss 0.27677560 - samples/sec: 60.82 - lr: 0.000030
2021-07-18 19:13:06,411 epoch 14 - iter 78/134 - loss 0.28209037 - samples/sec: 60.53 - lr: 0.000030
2021-07-18 19:13:13,278 epoch 14 - iter 91/134 - loss 0.28102133 - samples/sec: 60.59 - lr: 0.000030
2021-07-18 19:13:20,150 epoch 14 - iter 104/134 - loss 0.28337385 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:13:26,953 epoch 14 - iter 117/134 - loss 0.27920861 - samples/sec: 61.16 - lr: 0.000030
2021-07-18 19:13:33,782 epoch 14 - iter 130/134 - loss 0.27658266 - samples/sec: 60.93 - lr: 0.000030
2021-07-18 19:13:35,782 ----------------------------------------------------------------------------------------------------
2021-07-18 19:13:35,782 EPOCH 14 done: loss 0.2740 - lr 0.0000300
2021-07-18 19:13:40,487 DEV : loss 0.23448455333709717 - score 0.9604
2021-07-18 19:13:40,553 BAD EPOCHS (no improvement): 3
2021-07-18 19:13:40,553 ----------------------------------------------------------------------------------------------------
2021-07-18 19:13:47,416 epoch 15 - iter 13/134 - loss 0.20311446 - samples/sec: 60.62 - lr: 0.000030
2021-07-18 19:13:54,262 epoch 15 - iter 26/134 - loss 0.22609120 - samples/sec: 60.77 - lr: 0.000030
2021-07-18 19:14:01,082 epoch 15 - iter 39/134 - loss 0.22377346 - samples/sec: 61.01 - lr: 0.000030
2021-07-18 19:14:07,943 epoch 15 - iter 52/134 - loss 0.22587560 - samples/sec: 60.65 - lr: 0.000030
2021-07-18 19:14:14,778 epoch 15 - iter 65/134 - loss 0.23543511 - samples/sec: 60.87 - lr: 0.000030
2021-07-18 19:14:21,618 epoch 15 - iter 78/134 - loss 0.25078760 - samples/sec: 60.83 - lr: 0.000030
2021-07-18 19:14:28,482 epoch 15 - iter 91/134 - loss 0.25263015 - samples/sec: 60.62 - lr: 0.000030
2021-07-18 19:14:35,334 epoch 15 - iter 104/134 - loss 0.25557666 - samples/sec: 60.72 - lr: 0.000030
2021-07-18 19:14:42,170 epoch 15 - iter 117/134 - loss 0.25987830 - samples/sec: 60.86 - lr: 0.000030
2021-07-18 19:14:48,998 epoch 15 - iter 130/134 - loss 0.25630906 - samples/sec: 60.94 - lr: 0.000030
2021-07-18 19:14:51,013 ----------------------------------------------------------------------------------------------------
2021-07-18 19:14:51,014 EPOCH 15 done: loss 0.2561 - lr 0.0000300
2021-07-18 19:14:55,718 DEV : loss 0.2304656207561493 - score 0.9619
2021-07-18 19:14:55,783 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:14:59,472 ----------------------------------------------------------------------------------------------------
2021-07-18 19:15:06,307 epoch 16 - iter 13/134 - loss 0.23165582 - samples/sec: 60.88 - lr: 0.000030
2021-07-18 19:15:13,155 epoch 16 - iter 26/134 - loss 0.21353278 - samples/sec: 60.76 - lr: 0.000030
2021-07-18 19:15:19,982 epoch 16 - iter 39/134 - loss 0.22278802 - samples/sec: 60.95 - lr: 0.000030
2021-07-18 19:15:26,824 epoch 16 - iter 52/134 - loss 0.23613689 - samples/sec: 60.81 - lr: 0.000030
2021-07-18 19:15:33,662 epoch 16 - iter 65/134 - loss 0.24357722 - samples/sec: 60.84 - lr: 0.000030
2021-07-18 19:15:40,510 epoch 16 - iter 78/134 - loss 0.24241160 - samples/sec: 60.76 - lr: 0.000030
2021-07-18 19:15:47,318 epoch 16 - iter 91/134 - loss 0.23329372 - samples/sec: 61.11 - lr: 0.000030
2021-07-18 19:15:54,162 epoch 16 - iter 104/134 - loss 0.23289072 - samples/sec: 60.79 - lr: 0.000030
2021-07-18 19:16:00,987 epoch 16 - iter 117/134 - loss 0.23749177 - samples/sec: 60.96 - lr: 0.000030
2021-07-18 19:16:07,858 epoch 16 - iter 130/134 - loss 0.23817082 - samples/sec: 60.55 - lr: 0.000030
2021-07-18 19:16:09,896 ----------------------------------------------------------------------------------------------------
2021-07-18 19:16:09,896 EPOCH 16 done: loss 0.2356 - lr 0.0000300
2021-07-18 19:16:14,595 DEV : loss 0.23733191192150116 - score 0.9632
2021-07-18 19:16:14,661 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:16:18,333 ----------------------------------------------------------------------------------------------------
2021-07-18 19:16:25,258 epoch 17 - iter 13/134 - loss 0.25328196 - samples/sec: 60.09 - lr: 0.000030
2021-07-18 19:16:32,142 epoch 17 - iter 26/134 - loss 0.25892092 - samples/sec: 60.44 - lr: 0.000030
2021-07-18 19:16:39,012 epoch 17 - iter 39/134 - loss 0.24491150 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 19:16:45,906 epoch 17 - iter 52/134 - loss 0.23334555 - samples/sec: 60.35 - lr: 0.000030
2021-07-18 19:16:53,183 epoch 17 - iter 65/134 - loss 0.23740935 - samples/sec: 57.17 - lr: 0.000030
2021-07-18 19:17:00,026 epoch 17 - iter 78/134 - loss 0.23341447 - samples/sec: 60.81 - lr: 0.000030
2021-07-18 19:17:06,904 epoch 17 - iter 91/134 - loss 0.23069818 - samples/sec: 60.49 - lr: 0.000030
2021-07-18 19:17:13,750 epoch 17 - iter 104/134 - loss 0.23191969 - samples/sec: 60.77 - lr: 0.000030
2021-07-18 19:17:20,636 epoch 17 - iter 117/134 - loss 0.23146375 - samples/sec: 60.43 - lr: 0.000030
2021-07-18 19:17:27,506 epoch 17 - iter 130/134 - loss 0.23450046 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 19:17:29,528 ----------------------------------------------------------------------------------------------------
2021-07-18 19:17:29,529 EPOCH 17 done: loss 0.2345 - lr 0.0000300
2021-07-18 19:17:34,224 DEV : loss 0.23009845614433289 - score 0.9609
2021-07-18 19:17:34,289 BAD EPOCHS (no improvement): 1
2021-07-18 19:17:34,289 ----------------------------------------------------------------------------------------------------
2021-07-18 19:17:41,084 epoch 18 - iter 13/134 - loss 0.20877855 - samples/sec: 61.24 - lr: 0.000030
2021-07-18 19:17:47,909 epoch 18 - iter 26/134 - loss 0.23055963 - samples/sec: 60.96 - lr: 0.000030
2021-07-18 19:17:54,730 epoch 18 - iter 39/134 - loss 0.22772970 - samples/sec: 61.00 - lr: 0.000030
2021-07-18 19:18:01,523 epoch 18 - iter 52/134 - loss 0.22826399 - samples/sec: 61.24 - lr: 0.000030
2021-07-18 19:18:08,313 epoch 18 - iter 65/134 - loss 0.21705310 - samples/sec: 61.28 - lr: 0.000030
2021-07-18 19:18:15,103 epoch 18 - iter 78/134 - loss 0.22351734 - samples/sec: 61.27 - lr: 0.000030
2021-07-18 19:18:21,881 epoch 18 - iter 91/134 - loss 0.21869585 - samples/sec: 61.38 - lr: 0.000030
2021-07-18 19:18:28,667 epoch 18 - iter 104/134 - loss 0.21354617 - samples/sec: 61.31 - lr: 0.000030
2021-07-18 19:18:35,457 epoch 18 - iter 117/134 - loss 0.21375446 - samples/sec: 61.28 - lr: 0.000030
2021-07-18 19:18:42,239 epoch 18 - iter 130/134 - loss 0.22494158 - samples/sec: 61.34 - lr: 0.000030
2021-07-18 19:18:44,245 ----------------------------------------------------------------------------------------------------
2021-07-18 19:18:44,246 EPOCH 18 done: loss 0.2262 - lr 0.0000300
2021-07-18 19:18:48,941 DEV : loss 0.24299344420433044 - score 0.9608
2021-07-18 19:18:49,007 BAD EPOCHS (no improvement): 2
2021-07-18 19:18:49,008 ----------------------------------------------------------------------------------------------------
2021-07-18 19:18:55,840 epoch 19 - iter 13/134 - loss 0.21611770 - samples/sec: 60.90 - lr: 0.000030
2021-07-18 19:19:02,668 epoch 19 - iter 26/134 - loss 0.21876442 - samples/sec: 60.94 - lr: 0.000030
2021-07-18 19:19:09,466 epoch 19 - iter 39/134 - loss 0.21819842 - samples/sec: 61.20 - lr: 0.000030
2021-07-18 19:19:16,287 epoch 19 - iter 52/134 - loss 0.21239058 - samples/sec: 61.00 - lr: 0.000030
2021-07-18 19:19:23,121 epoch 19 - iter 65/134 - loss 0.21339093 - samples/sec: 60.88 - lr: 0.000030
2021-07-18 19:19:29,958 epoch 19 - iter 78/134 - loss 0.21154856 - samples/sec: 60.85 - lr: 0.000030
2021-07-18 19:19:36,763 epoch 19 - iter 91/134 - loss 0.20451735 - samples/sec: 61.14 - lr: 0.000030
2021-07-18 19:19:43,572 epoch 19 - iter 104/134 - loss 0.20212090 - samples/sec: 61.10 - lr: 0.000030
2021-07-18 19:19:50,450 epoch 19 - iter 117/134 - loss 0.20894041 - samples/sec: 60.50 - lr: 0.000030
2021-07-18 19:19:57,335 epoch 19 - iter 130/134 - loss 0.21329909 - samples/sec: 60.43 - lr: 0.000030
2021-07-18 19:19:59,366 ----------------------------------------------------------------------------------------------------
2021-07-18 19:19:59,366 EPOCH 19 done: loss 0.2143 - lr 0.0000300
2021-07-18 19:20:04,067 DEV : loss 0.2549701929092407 - score 0.9585
2021-07-18 19:20:04,132 BAD EPOCHS (no improvement): 3
2021-07-18 19:20:04,132 ----------------------------------------------------------------------------------------------------
2021-07-18 19:20:10,984 epoch 20 - iter 13/134 - loss 0.20924776 - samples/sec: 60.72 - lr: 0.000030
2021-07-18 19:20:17,868 epoch 20 - iter 26/134 - loss 0.18796218 - samples/sec: 60.44 - lr: 0.000030
2021-07-18 19:20:24,757 epoch 20 - iter 39/134 - loss 0.18746147 - samples/sec: 60.40 - lr: 0.000030
2021-07-18 19:20:31,602 epoch 20 - iter 52/134 - loss 0.17928819 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 19:20:38,454 epoch 20 - iter 65/134 - loss 0.18419834 - samples/sec: 60.72 - lr: 0.000030
2021-07-18 19:20:45,330 epoch 20 - iter 78/134 - loss 0.19044950 - samples/sec: 60.50 - lr: 0.000030
2021-07-18 19:20:52,170 epoch 20 - iter 91/134 - loss 0.19422053 - samples/sec: 60.83 - lr: 0.000030
2021-07-18 19:20:59,103 epoch 20 - iter 104/134 - loss 0.19540694 - samples/sec: 60.01 - lr: 0.000030
2021-07-18 19:21:05,974 epoch 20 - iter 117/134 - loss 0.19812731 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 19:21:12,826 epoch 20 - iter 130/134 - loss 0.19742564 - samples/sec: 60.72 - lr: 0.000030
2021-07-18 19:21:14,844 ----------------------------------------------------------------------------------------------------
2021-07-18 19:21:14,844 EPOCH 20 done: loss 0.1974 - lr 0.0000300
2021-07-18 19:21:19,957 DEV : loss 0.2334422469139099 - score 0.9626
Epoch    20: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 19:21:20,023 BAD EPOCHS (no improvement): 4
2021-07-18 19:21:20,023 ----------------------------------------------------------------------------------------------------
2021-07-18 19:21:26,896 epoch 21 - iter 13/134 - loss 0.18567207 - samples/sec: 60.54 - lr: 0.000015
2021-07-18 19:21:33,764 epoch 21 - iter 26/134 - loss 0.18934475 - samples/sec: 60.58 - lr: 0.000015
2021-07-18 19:21:40,666 epoch 21 - iter 39/134 - loss 0.17006999 - samples/sec: 60.28 - lr: 0.000015
2021-07-18 19:21:47,551 epoch 21 - iter 52/134 - loss 0.17749871 - samples/sec: 60.43 - lr: 0.000015
2021-07-18 19:21:54,355 epoch 21 - iter 65/134 - loss 0.18102044 - samples/sec: 61.15 - lr: 0.000015
2021-07-18 19:22:01,205 epoch 21 - iter 78/134 - loss 0.18148334 - samples/sec: 60.74 - lr: 0.000015
2021-07-18 19:22:08,099 epoch 21 - iter 91/134 - loss 0.19036925 - samples/sec: 60.35 - lr: 0.000015
2021-07-18 19:22:14,982 epoch 21 - iter 104/134 - loss 0.18824766 - samples/sec: 60.45 - lr: 0.000015
2021-07-18 19:22:21,820 epoch 21 - iter 117/134 - loss 0.19343638 - samples/sec: 60.85 - lr: 0.000015
2021-07-18 19:22:28,698 epoch 21 - iter 130/134 - loss 0.18998294 - samples/sec: 60.49 - lr: 0.000015
2021-07-18 19:22:30,729 ----------------------------------------------------------------------------------------------------
2021-07-18 19:22:30,730 EPOCH 21 done: loss 0.1874 - lr 0.0000150
2021-07-18 19:22:35,425 DEV : loss 0.24394339323043823 - score 0.9614
2021-07-18 19:22:35,492 BAD EPOCHS (no improvement): 1
2021-07-18 19:22:35,492 ----------------------------------------------------------------------------------------------------
2021-07-18 19:22:42,354 epoch 22 - iter 13/134 - loss 0.25546303 - samples/sec: 60.64 - lr: 0.000015
2021-07-18 19:22:49,246 epoch 22 - iter 26/134 - loss 0.20278865 - samples/sec: 60.37 - lr: 0.000015
2021-07-18 19:22:56,114 epoch 22 - iter 39/134 - loss 0.18488556 - samples/sec: 60.58 - lr: 0.000015
2021-07-18 19:23:02,987 epoch 22 - iter 52/134 - loss 0.19327162 - samples/sec: 60.54 - lr: 0.000015
2021-07-18 19:23:09,839 epoch 22 - iter 65/134 - loss 0.18525512 - samples/sec: 60.72 - lr: 0.000015
2021-07-18 19:23:16,718 epoch 22 - iter 78/134 - loss 0.17890781 - samples/sec: 60.48 - lr: 0.000015
2021-07-18 19:23:23,599 epoch 22 - iter 91/134 - loss 0.18373174 - samples/sec: 60.47 - lr: 0.000015
2021-07-18 19:23:30,438 epoch 22 - iter 104/134 - loss 0.18001153 - samples/sec: 60.84 - lr: 0.000015
2021-07-18 19:23:37,322 epoch 22 - iter 117/134 - loss 0.17828031 - samples/sec: 60.44 - lr: 0.000015
2021-07-18 19:23:44,174 epoch 22 - iter 130/134 - loss 0.18393716 - samples/sec: 60.72 - lr: 0.000015
2021-07-18 19:23:46,211 ----------------------------------------------------------------------------------------------------
2021-07-18 19:23:46,211 EPOCH 22 done: loss 0.1854 - lr 0.0000150
2021-07-18 19:23:50,903 DEV : loss 0.2354544997215271 - score 0.9628
2021-07-18 19:23:50,970 BAD EPOCHS (no improvement): 2
2021-07-18 19:23:50,970 ----------------------------------------------------------------------------------------------------
2021-07-18 19:23:57,856 epoch 23 - iter 13/134 - loss 0.23549544 - samples/sec: 60.43 - lr: 0.000015
2021-07-18 19:24:04,734 epoch 23 - iter 26/134 - loss 0.17842903 - samples/sec: 60.49 - lr: 0.000015
2021-07-18 19:24:11,630 epoch 23 - iter 39/134 - loss 0.17546590 - samples/sec: 60.34 - lr: 0.000015
2021-07-18 19:24:18,466 epoch 23 - iter 52/134 - loss 0.17705174 - samples/sec: 60.86 - lr: 0.000015
2021-07-18 19:24:25,360 epoch 23 - iter 65/134 - loss 0.18020554 - samples/sec: 60.35 - lr: 0.000015
2021-07-18 19:24:32,199 epoch 23 - iter 78/134 - loss 0.17661098 - samples/sec: 60.84 - lr: 0.000015
2021-07-18 19:24:39,046 epoch 23 - iter 91/134 - loss 0.17326331 - samples/sec: 60.77 - lr: 0.000015
2021-07-18 19:24:45,904 epoch 23 - iter 104/134 - loss 0.18008021 - samples/sec: 60.67 - lr: 0.000015
2021-07-18 19:24:52,768 epoch 23 - iter 117/134 - loss 0.18180372 - samples/sec: 60.61 - lr: 0.000015
2021-07-18 19:24:59,655 epoch 23 - iter 130/134 - loss 0.18325693 - samples/sec: 60.42 - lr: 0.000015
2021-07-18 19:25:01,699 ----------------------------------------------------------------------------------------------------
2021-07-18 19:25:01,699 EPOCH 23 done: loss 0.1806 - lr 0.0000150
2021-07-18 19:25:06,828 DEV : loss 0.2450684905052185 - score 0.9604
2021-07-18 19:25:06,894 BAD EPOCHS (no improvement): 3
2021-07-18 19:25:06,894 ----------------------------------------------------------------------------------------------------
2021-07-18 19:25:13,786 epoch 24 - iter 13/134 - loss 0.18801087 - samples/sec: 60.37 - lr: 0.000015
2021-07-18 19:25:20,631 epoch 24 - iter 26/134 - loss 0.16443886 - samples/sec: 60.79 - lr: 0.000015
2021-07-18 19:25:27,523 epoch 24 - iter 39/134 - loss 0.15885128 - samples/sec: 60.37 - lr: 0.000015
2021-07-18 19:25:34,353 epoch 24 - iter 52/134 - loss 0.16500898 - samples/sec: 60.92 - lr: 0.000015
2021-07-18 19:25:41,203 epoch 24 - iter 65/134 - loss 0.16664555 - samples/sec: 60.74 - lr: 0.000015
2021-07-18 19:25:48,090 epoch 24 - iter 78/134 - loss 0.17545181 - samples/sec: 60.41 - lr: 0.000015
2021-07-18 19:25:54,881 epoch 24 - iter 91/134 - loss 0.17425065 - samples/sec: 61.27 - lr: 0.000015
2021-07-18 19:26:01,708 epoch 24 - iter 104/134 - loss 0.17611074 - samples/sec: 60.95 - lr: 0.000015
2021-07-18 19:26:08,542 epoch 24 - iter 117/134 - loss 0.17549702 - samples/sec: 60.88 - lr: 0.000015
2021-07-18 19:26:15,393 epoch 24 - iter 130/134 - loss 0.17745803 - samples/sec: 60.73 - lr: 0.000015
2021-07-18 19:26:17,418 ----------------------------------------------------------------------------------------------------
2021-07-18 19:26:17,418 EPOCH 24 done: loss 0.1772 - lr 0.0000150
2021-07-18 19:26:22,110 DEV : loss 0.24166040122509003 - score 0.9599
Epoch    24: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 19:26:22,175 BAD EPOCHS (no improvement): 4
2021-07-18 19:26:22,175 ----------------------------------------------------------------------------------------------------
2021-07-18 19:26:29,024 epoch 25 - iter 13/134 - loss 0.15452339 - samples/sec: 60.76 - lr: 0.000008
2021-07-18 19:26:35,906 epoch 25 - iter 26/134 - loss 0.16812541 - samples/sec: 60.45 - lr: 0.000008
2021-07-18 19:26:42,754 epoch 25 - iter 39/134 - loss 0.17384553 - samples/sec: 60.76 - lr: 0.000008
2021-07-18 19:26:49,638 epoch 25 - iter 52/134 - loss 0.17015490 - samples/sec: 60.44 - lr: 0.000008
2021-07-18 19:26:56,466 epoch 25 - iter 65/134 - loss 0.17023730 - samples/sec: 60.93 - lr: 0.000008
2021-07-18 19:27:03,356 epoch 25 - iter 78/134 - loss 0.16963445 - samples/sec: 60.39 - lr: 0.000008
2021-07-18 19:27:10,193 epoch 25 - iter 91/134 - loss 0.16895244 - samples/sec: 60.85 - lr: 0.000008
2021-07-18 19:27:17,056 epoch 25 - iter 104/134 - loss 0.17218249 - samples/sec: 60.63 - lr: 0.000008
2021-07-18 19:27:23,940 epoch 25 - iter 117/134 - loss 0.17071662 - samples/sec: 60.44 - lr: 0.000008
2021-07-18 19:27:30,800 epoch 25 - iter 130/134 - loss 0.17273677 - samples/sec: 60.65 - lr: 0.000008
2021-07-18 19:27:32,841 ----------------------------------------------------------------------------------------------------
2021-07-18 19:27:32,841 EPOCH 25 done: loss 0.1710 - lr 0.0000075
2021-07-18 19:27:37,542 DEV : loss 0.23927459120750427 - score 0.9615
2021-07-18 19:27:37,608 BAD EPOCHS (no improvement): 1
2021-07-18 19:27:37,608 ----------------------------------------------------------------------------------------------------
2021-07-18 19:27:44,471 epoch 26 - iter 13/134 - loss 0.13743313 - samples/sec: 60.63 - lr: 0.000008
2021-07-18 19:27:51,324 epoch 26 - iter 26/134 - loss 0.13850403 - samples/sec: 60.71 - lr: 0.000008
2021-07-18 19:27:58,151 epoch 26 - iter 39/134 - loss 0.15476644 - samples/sec: 60.95 - lr: 0.000008
2021-07-18 19:28:04,936 epoch 26 - iter 52/134 - loss 0.15881597 - samples/sec: 61.32 - lr: 0.000008
2021-07-18 19:28:11,788 epoch 26 - iter 65/134 - loss 0.15627941 - samples/sec: 60.72 - lr: 0.000008
2021-07-18 19:28:18,654 epoch 26 - iter 78/134 - loss 0.16121619 - samples/sec: 60.60 - lr: 0.000008
2021-07-18 19:28:25,515 epoch 26 - iter 91/134 - loss 0.15976776 - samples/sec: 60.64 - lr: 0.000008
2021-07-18 19:28:32,371 epoch 26 - iter 104/134 - loss 0.16158538 - samples/sec: 60.68 - lr: 0.000008
2021-07-18 19:28:39,243 epoch 26 - iter 117/134 - loss 0.16329618 - samples/sec: 60.55 - lr: 0.000008
2021-07-18 19:28:46,107 epoch 26 - iter 130/134 - loss 0.16377764 - samples/sec: 60.61 - lr: 0.000008
2021-07-18 19:28:48,140 ----------------------------------------------------------------------------------------------------
2021-07-18 19:28:48,140 EPOCH 26 done: loss 0.1648 - lr 0.0000075
2021-07-18 19:28:52,834 DEV : loss 0.2304108440876007 - score 0.9621
2021-07-18 19:28:52,899 BAD EPOCHS (no improvement): 2
2021-07-18 19:28:52,900 ----------------------------------------------------------------------------------------------------
2021-07-18 19:29:00,154 epoch 27 - iter 13/134 - loss 0.18981419 - samples/sec: 57.36 - lr: 0.000008
2021-07-18 19:29:07,020 epoch 27 - iter 26/134 - loss 0.20614308 - samples/sec: 60.59 - lr: 0.000008
2021-07-18 19:29:13,891 epoch 27 - iter 39/134 - loss 0.18931526 - samples/sec: 60.55 - lr: 0.000008
2021-07-18 19:29:20,770 epoch 27 - iter 52/134 - loss 0.17739198 - samples/sec: 60.49 - lr: 0.000008
2021-07-18 19:29:27,659 epoch 27 - iter 65/134 - loss 0.16424193 - samples/sec: 60.39 - lr: 0.000008
2021-07-18 19:29:34,511 epoch 27 - iter 78/134 - loss 0.15941837 - samples/sec: 60.72 - lr: 0.000008
2021-07-18 19:29:41,387 epoch 27 - iter 91/134 - loss 0.15727329 - samples/sec: 60.50 - lr: 0.000008
2021-07-18 19:29:48,281 epoch 27 - iter 104/134 - loss 0.15864163 - samples/sec: 60.35 - lr: 0.000008
2021-07-18 19:29:55,147 epoch 27 - iter 117/134 - loss 0.16007403 - samples/sec: 60.61 - lr: 0.000008
2021-07-18 19:30:01,981 epoch 27 - iter 130/134 - loss 0.15822364 - samples/sec: 60.88 - lr: 0.000008
2021-07-18 19:30:04,024 ----------------------------------------------------------------------------------------------------
2021-07-18 19:30:04,025 EPOCH 27 done: loss 0.1607 - lr 0.0000075
2021-07-18 19:30:08,715 DEV : loss 0.2368679940700531 - score 0.9626
2021-07-18 19:30:08,780 BAD EPOCHS (no improvement): 3
2021-07-18 19:30:08,781 ----------------------------------------------------------------------------------------------------
2021-07-18 19:30:15,649 epoch 28 - iter 13/134 - loss 0.13282277 - samples/sec: 60.58 - lr: 0.000008
2021-07-18 19:30:22,507 epoch 28 - iter 26/134 - loss 0.12607948 - samples/sec: 60.67 - lr: 0.000008
2021-07-18 19:30:29,373 epoch 28 - iter 39/134 - loss 0.13751973 - samples/sec: 60.60 - lr: 0.000008
2021-07-18 19:30:36,251 epoch 28 - iter 52/134 - loss 0.14811060 - samples/sec: 60.49 - lr: 0.000008
2021-07-18 19:30:43,137 epoch 28 - iter 65/134 - loss 0.15253328 - samples/sec: 60.42 - lr: 0.000008
2021-07-18 19:30:50,019 epoch 28 - iter 78/134 - loss 0.15603466 - samples/sec: 60.46 - lr: 0.000008
2021-07-18 19:30:56,870 epoch 28 - iter 91/134 - loss 0.15542094 - samples/sec: 60.73 - lr: 0.000008
2021-07-18 19:31:03,715 epoch 28 - iter 104/134 - loss 0.15222984 - samples/sec: 60.79 - lr: 0.000008
2021-07-18 19:31:10,531 epoch 28 - iter 117/134 - loss 0.15246969 - samples/sec: 61.04 - lr: 0.000008
2021-07-18 19:31:17,355 epoch 28 - iter 130/134 - loss 0.15137600 - samples/sec: 60.97 - lr: 0.000008
2021-07-18 19:31:19,387 ----------------------------------------------------------------------------------------------------
2021-07-18 19:31:19,388 EPOCH 28 done: loss 0.1544 - lr 0.0000075
2021-07-18 19:31:24,077 DEV : loss 0.24471993744373322 - score 0.9603
Epoch    28: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 19:31:24,143 BAD EPOCHS (no improvement): 4
2021-07-18 19:31:24,143 ----------------------------------------------------------------------------------------------------
2021-07-18 19:31:31,010 epoch 29 - iter 13/134 - loss 0.15359585 - samples/sec: 60.59 - lr: 0.000004
2021-07-18 19:31:37,895 epoch 29 - iter 26/134 - loss 0.14973944 - samples/sec: 60.43 - lr: 0.000004
2021-07-18 19:31:44,767 epoch 29 - iter 39/134 - loss 0.14308282 - samples/sec: 60.54 - lr: 0.000004
2021-07-18 19:31:51,643 epoch 29 - iter 52/134 - loss 0.15419380 - samples/sec: 60.51 - lr: 0.000004
2021-07-18 19:31:58,516 epoch 29 - iter 65/134 - loss 0.16046218 - samples/sec: 60.54 - lr: 0.000004
2021-07-18 19:32:05,376 epoch 29 - iter 78/134 - loss 0.15799665 - samples/sec: 60.65 - lr: 0.000004
2021-07-18 19:32:12,231 epoch 29 - iter 91/134 - loss 0.15517550 - samples/sec: 60.69 - lr: 0.000004
2021-07-18 19:32:19,132 epoch 29 - iter 104/134 - loss 0.14930408 - samples/sec: 60.29 - lr: 0.000004
2021-07-18 19:32:26,010 epoch 29 - iter 117/134 - loss 0.14785897 - samples/sec: 60.49 - lr: 0.000004
2021-07-18 19:32:32,867 epoch 29 - iter 130/134 - loss 0.14621836 - samples/sec: 60.68 - lr: 0.000004
2021-07-18 19:32:34,876 ----------------------------------------------------------------------------------------------------
2021-07-18 19:32:34,877 EPOCH 29 done: loss 0.1472 - lr 0.0000038
2021-07-18 19:32:39,571 DEV : loss 0.23959791660308838 - score 0.962
2021-07-18 19:32:39,636 BAD EPOCHS (no improvement): 1
2021-07-18 19:32:39,637 ----------------------------------------------------------------------------------------------------
2021-07-18 19:32:46,499 epoch 30 - iter 13/134 - loss 0.14841238 - samples/sec: 60.63 - lr: 0.000004
2021-07-18 19:32:53,355 epoch 30 - iter 26/134 - loss 0.13346271 - samples/sec: 60.69 - lr: 0.000004
2021-07-18 19:33:00,258 epoch 30 - iter 39/134 - loss 0.13133672 - samples/sec: 60.27 - lr: 0.000004
2021-07-18 19:33:07,106 epoch 30 - iter 52/134 - loss 0.13714363 - samples/sec: 60.76 - lr: 0.000004
2021-07-18 19:33:13,896 epoch 30 - iter 65/134 - loss 0.13841163 - samples/sec: 61.28 - lr: 0.000004
2021-07-18 19:33:20,696 epoch 30 - iter 78/134 - loss 0.14442799 - samples/sec: 61.18 - lr: 0.000004
2021-07-18 19:33:27,500 epoch 30 - iter 91/134 - loss 0.14311814 - samples/sec: 61.15 - lr: 0.000004
2021-07-18 19:33:34,750 epoch 30 - iter 104/134 - loss 0.13814246 - samples/sec: 57.39 - lr: 0.000004
2021-07-18 19:33:41,602 epoch 30 - iter 117/134 - loss 0.13865474 - samples/sec: 60.72 - lr: 0.000004
2021-07-18 19:33:48,433 epoch 30 - iter 130/134 - loss 0.13873384 - samples/sec: 60.91 - lr: 0.000004
2021-07-18 19:33:50,414 ----------------------------------------------------------------------------------------------------
2021-07-18 19:33:50,414 EPOCH 30 done: loss 0.1389 - lr 0.0000038
2021-07-18 19:33:55,114 DEV : loss 0.24050991237163544 - score 0.962
2021-07-18 19:33:55,181 BAD EPOCHS (no improvement): 2
2021-07-18 19:33:55,181 ----------------------------------------------------------------------------------------------------
2021-07-18 19:34:01,998 epoch 31 - iter 13/134 - loss 0.15240061 - samples/sec: 61.04 - lr: 0.000004
2021-07-18 19:34:08,820 epoch 31 - iter 26/134 - loss 0.13402414 - samples/sec: 60.99 - lr: 0.000004
2021-07-18 19:34:15,634 epoch 31 - iter 39/134 - loss 0.14881614 - samples/sec: 61.06 - lr: 0.000004
2021-07-18 19:34:22,543 epoch 31 - iter 52/134 - loss 0.14771013 - samples/sec: 60.21 - lr: 0.000004
2021-07-18 19:34:29,431 epoch 31 - iter 65/134 - loss 0.14968633 - samples/sec: 60.41 - lr: 0.000004
2021-07-18 19:34:36,296 epoch 31 - iter 78/134 - loss 0.15550590 - samples/sec: 60.61 - lr: 0.000004
2021-07-18 19:34:43,144 epoch 31 - iter 91/134 - loss 0.15916262 - samples/sec: 60.75 - lr: 0.000004
2021-07-18 19:34:50,036 epoch 31 - iter 104/134 - loss 0.15911058 - samples/sec: 60.37 - lr: 0.000004
2021-07-18 19:34:56,915 epoch 31 - iter 117/134 - loss 0.15488085 - samples/sec: 60.49 - lr: 0.000004
2021-07-18 19:35:03,800 epoch 31 - iter 130/134 - loss 0.15299416 - samples/sec: 60.43 - lr: 0.000004
2021-07-18 19:35:05,824 ----------------------------------------------------------------------------------------------------
2021-07-18 19:35:05,824 EPOCH 31 done: loss 0.1511 - lr 0.0000038
2021-07-18 19:35:10,528 DEV : loss 0.2412695586681366 - score 0.9609
2021-07-18 19:35:10,594 BAD EPOCHS (no improvement): 3
2021-07-18 19:35:10,594 ----------------------------------------------------------------------------------------------------
2021-07-18 19:35:17,470 epoch 32 - iter 13/134 - loss 0.15236134 - samples/sec: 60.51 - lr: 0.000004
2021-07-18 19:35:24,335 epoch 32 - iter 26/134 - loss 0.16523559 - samples/sec: 60.61 - lr: 0.000004
2021-07-18 19:35:31,202 epoch 32 - iter 39/134 - loss 0.15683986 - samples/sec: 60.59 - lr: 0.000004
2021-07-18 19:35:38,058 epoch 32 - iter 52/134 - loss 0.16438713 - samples/sec: 60.68 - lr: 0.000004
2021-07-18 19:35:44,919 epoch 32 - iter 65/134 - loss 0.15022307 - samples/sec: 60.64 - lr: 0.000004
2021-07-18 19:35:51,775 epoch 32 - iter 78/134 - loss 0.15309394 - samples/sec: 60.69 - lr: 0.000004
2021-07-18 19:35:58,671 epoch 32 - iter 91/134 - loss 0.15326341 - samples/sec: 60.33 - lr: 0.000004
2021-07-18 19:36:05,523 epoch 32 - iter 104/134 - loss 0.15138559 - samples/sec: 60.72 - lr: 0.000004
2021-07-18 19:36:12,426 epoch 32 - iter 117/134 - loss 0.15235674 - samples/sec: 60.27 - lr: 0.000004
2021-07-18 19:36:19,314 epoch 32 - iter 130/134 - loss 0.15097011 - samples/sec: 60.41 - lr: 0.000004
2021-07-18 19:36:21,334 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:21,334 EPOCH 32 done: loss 0.1516 - lr 0.0000038
2021-07-18 19:36:26,028 DEV : loss 0.2417004555463791 - score 0.9625
Epoch    32: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 19:36:26,093 BAD EPOCHS (no improvement): 4
2021-07-18 19:36:26,094 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:26,094 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:26,094 learning rate too small - quitting training!
2021-07-18 19:36:26,094 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:26,756 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:26,756 Testing using best model ...
2021-07-18 19:36:26,756 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.gum/best-model.pt
2021-07-18 19:36:48,294 0.9476	0.9393	0.9435
2021-07-18 19:36:48,294 
Results:
- F1-score (micro) 0.9435
- F1-score (macro) 0.9435

By class:
SENT       tp: 1285 - fp: 71 - fn: 83 - precision: 0.9476 - recall: 0.9393 - f1-score: 0.9435
2021-07-18 19:36:48,294 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/nld.rst.nldt/
2021-07-18 19:36:48,309 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/nld.rst.nldt
2021-07-18 19:36:48,311 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/nld.rst.nldt/sent_train.txt
2021-07-18 19:36:48,313 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/nld.rst.nldt/sent_dev.txt
2021-07-18 19:36:48,315 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/nld.rst.nldt/sent_test.txt
Corpus: 649 train + 186 dev + 216 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 19:36:50,969 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:50,971 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30073, 768, padding_idx=3)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 19:36:50,971 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:50,971 Corpus: "Corpus: 649 train + 186 dev + 216 test sentences"
2021-07-18 19:36:50,971 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:50,971 Parameters:
2021-07-18 19:36:50,971  - learning_rate: "3e-05"
2021-07-18 19:36:50,971  - mini_batch_size: "32"
2021-07-18 19:36:50,971  - patience: "3"
2021-07-18 19:36:50,971  - anneal_factor: "0.5"
2021-07-18 19:36:50,971  - max_epochs: "40"
2021-07-18 19:36:50,971  - shuffle: "True"
2021-07-18 19:36:50,971  - train_with_dev: "False"
2021-07-18 19:36:50,971  - batch_growth_annealing: "False"
2021-07-18 19:36:50,971 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:50,971 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/nld.rst.nldt"
2021-07-18 19:36:50,971 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:50,971 Device: cuda:0
2021-07-18 19:36:50,971 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:50,971 Embeddings storage mode: cpu
2021-07-18 19:36:50,975 ----------------------------------------------------------------------------------------------------
2021-07-18 19:36:53,434 epoch 1 - iter 2/21 - loss 47.73195839 - samples/sec: 26.03 - lr: 0.000030
2021-07-18 19:36:55,497 epoch 1 - iter 4/21 - loss 45.35768604 - samples/sec: 31.02 - lr: 0.000030
2021-07-18 19:36:57,583 epoch 1 - iter 6/21 - loss 42.44719251 - samples/sec: 30.69 - lr: 0.000030
2021-07-18 19:36:59,674 epoch 1 - iter 8/21 - loss 39.91568208 - samples/sec: 30.60 - lr: 0.000030
2021-07-18 19:37:01,778 epoch 1 - iter 10/21 - loss 37.22359028 - samples/sec: 30.43 - lr: 0.000030
2021-07-18 19:37:03,884 epoch 1 - iter 12/21 - loss 34.82124249 - samples/sec: 30.40 - lr: 0.000030
2021-07-18 19:37:05,996 epoch 1 - iter 14/21 - loss 32.72417041 - samples/sec: 30.31 - lr: 0.000030
2021-07-18 19:37:08,077 epoch 1 - iter 16/21 - loss 30.62586093 - samples/sec: 30.76 - lr: 0.000030
2021-07-18 19:37:10,161 epoch 1 - iter 18/21 - loss 28.69912847 - samples/sec: 30.70 - lr: 0.000030
2021-07-18 19:37:12,253 epoch 1 - iter 20/21 - loss 26.98362513 - samples/sec: 30.60 - lr: 0.000030
2021-07-18 19:37:12,588 ----------------------------------------------------------------------------------------------------
2021-07-18 19:37:12,588 EPOCH 1 done: loss 26.0991 - lr 0.0000300
2021-07-18 19:37:15,906 DEV : loss 5.909020900726318 - score 0.0
2021-07-18 19:37:15,919 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:37:16,688 ----------------------------------------------------------------------------------------------------
2021-07-18 19:37:17,712 epoch 2 - iter 2/21 - loss 8.56667805 - samples/sec: 62.53 - lr: 0.000030
2021-07-18 19:37:18,767 epoch 2 - iter 4/21 - loss 8.23783135 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 19:37:19,827 epoch 2 - iter 6/21 - loss 7.86734581 - samples/sec: 60.40 - lr: 0.000030
2021-07-18 19:37:20,873 epoch 2 - iter 8/21 - loss 7.38378632 - samples/sec: 61.21 - lr: 0.000030
2021-07-18 19:37:21,911 epoch 2 - iter 10/21 - loss 7.11745224 - samples/sec: 61.71 - lr: 0.000030
2021-07-18 19:37:22,985 epoch 2 - iter 12/21 - loss 6.93249424 - samples/sec: 59.63 - lr: 0.000030
2021-07-18 19:37:24,035 epoch 2 - iter 14/21 - loss 6.61786073 - samples/sec: 60.95 - lr: 0.000030
2021-07-18 19:37:25,079 epoch 2 - iter 16/21 - loss 6.35081801 - samples/sec: 61.33 - lr: 0.000030
2021-07-18 19:37:26,128 epoch 2 - iter 18/21 - loss 6.12586959 - samples/sec: 61.07 - lr: 0.000030
2021-07-18 19:37:27,199 epoch 2 - iter 20/21 - loss 5.91097816 - samples/sec: 59.75 - lr: 0.000030
2021-07-18 19:37:27,397 ----------------------------------------------------------------------------------------------------
2021-07-18 19:37:27,397 EPOCH 2 done: loss 5.7968 - lr 0.0000300
2021-07-18 19:37:28,417 DEV : loss 3.504934310913086 - score 0.0
2021-07-18 19:37:28,430 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:37:32,249 ----------------------------------------------------------------------------------------------------
2021-07-18 19:37:33,323 epoch 3 - iter 2/21 - loss 3.96959090 - samples/sec: 59.62 - lr: 0.000030
2021-07-18 19:37:34,379 epoch 3 - iter 4/21 - loss 3.74853879 - samples/sec: 60.61 - lr: 0.000030
2021-07-18 19:37:35,436 epoch 3 - iter 6/21 - loss 3.49364305 - samples/sec: 60.60 - lr: 0.000030
2021-07-18 19:37:36,474 epoch 3 - iter 8/21 - loss 3.34017453 - samples/sec: 61.67 - lr: 0.000030
2021-07-18 19:37:37,523 epoch 3 - iter 10/21 - loss 3.25624971 - samples/sec: 61.06 - lr: 0.000030
2021-07-18 19:37:38,586 epoch 3 - iter 12/21 - loss 3.18212742 - samples/sec: 60.22 - lr: 0.000030
2021-07-18 19:37:39,647 epoch 3 - iter 14/21 - loss 3.11963526 - samples/sec: 60.34 - lr: 0.000030
2021-07-18 19:37:40,690 epoch 3 - iter 16/21 - loss 3.01502448 - samples/sec: 61.42 - lr: 0.000030
2021-07-18 19:37:41,757 epoch 3 - iter 18/21 - loss 2.93548289 - samples/sec: 59.99 - lr: 0.000030
2021-07-18 19:37:42,831 epoch 3 - iter 20/21 - loss 2.85275738 - samples/sec: 59.65 - lr: 0.000030
2021-07-18 19:37:43,036 ----------------------------------------------------------------------------------------------------
2021-07-18 19:37:43,036 EPOCH 3 done: loss 2.8146 - lr 0.0000300
2021-07-18 19:37:45,352 DEV : loss 1.3768706321716309 - score 0.7902
2021-07-18 19:37:45,366 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:37:49,131 ----------------------------------------------------------------------------------------------------
2021-07-18 19:37:50,198 epoch 4 - iter 2/21 - loss 1.85060042 - samples/sec: 60.02 - lr: 0.000030
2021-07-18 19:37:51,264 epoch 4 - iter 4/21 - loss 1.73118237 - samples/sec: 60.09 - lr: 0.000030
2021-07-18 19:37:52,343 epoch 4 - iter 6/21 - loss 1.69138265 - samples/sec: 59.31 - lr: 0.000030
2021-07-18 19:37:53,410 epoch 4 - iter 8/21 - loss 1.64381665 - samples/sec: 60.03 - lr: 0.000030
2021-07-18 19:37:54,471 epoch 4 - iter 10/21 - loss 1.66278696 - samples/sec: 60.36 - lr: 0.000030
2021-07-18 19:37:55,529 epoch 4 - iter 12/21 - loss 1.62584912 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:37:56,559 epoch 4 - iter 14/21 - loss 1.58323757 - samples/sec: 62.14 - lr: 0.000030
2021-07-18 19:37:57,621 epoch 4 - iter 16/21 - loss 1.52199043 - samples/sec: 60.33 - lr: 0.000030
2021-07-18 19:37:58,646 epoch 4 - iter 18/21 - loss 1.46884422 - samples/sec: 62.46 - lr: 0.000030
2021-07-18 19:37:59,695 epoch 4 - iter 20/21 - loss 1.44917346 - samples/sec: 61.00 - lr: 0.000030
2021-07-18 19:37:59,894 ----------------------------------------------------------------------------------------------------
2021-07-18 19:37:59,894 EPOCH 4 done: loss 1.4381 - lr 0.0000300
2021-07-18 19:38:00,917 DEV : loss 0.7635650038719177 - score 0.8996
2021-07-18 19:38:00,930 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:38:04,907 ----------------------------------------------------------------------------------------------------
2021-07-18 19:38:05,983 epoch 5 - iter 2/21 - loss 1.05230749 - samples/sec: 59.56 - lr: 0.000030
2021-07-18 19:38:07,036 epoch 5 - iter 4/21 - loss 1.03540787 - samples/sec: 60.79 - lr: 0.000030
2021-07-18 19:38:08,115 epoch 5 - iter 6/21 - loss 1.11388908 - samples/sec: 59.32 - lr: 0.000030
2021-07-18 19:38:09,167 epoch 5 - iter 8/21 - loss 1.04450747 - samples/sec: 60.89 - lr: 0.000030
2021-07-18 19:38:10,220 epoch 5 - iter 10/21 - loss 0.96312012 - samples/sec: 60.82 - lr: 0.000030
2021-07-18 19:38:11,279 epoch 5 - iter 12/21 - loss 0.94826060 - samples/sec: 60.44 - lr: 0.000030
2021-07-18 19:38:12,308 epoch 5 - iter 14/21 - loss 0.93903929 - samples/sec: 62.23 - lr: 0.000030
2021-07-18 19:38:13,367 epoch 5 - iter 16/21 - loss 0.92493985 - samples/sec: 60.45 - lr: 0.000030
2021-07-18 19:38:14,430 epoch 5 - iter 18/21 - loss 0.95178874 - samples/sec: 60.26 - lr: 0.000030
2021-07-18 19:38:15,467 epoch 5 - iter 20/21 - loss 0.95615796 - samples/sec: 61.77 - lr: 0.000030
2021-07-18 19:38:15,662 ----------------------------------------------------------------------------------------------------
2021-07-18 19:38:15,662 EPOCH 5 done: loss 0.9399 - lr 0.0000300
2021-07-18 19:38:16,682 DEV : loss 0.6101303696632385 - score 0.9234
2021-07-18 19:38:16,695 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:38:20,747 ----------------------------------------------------------------------------------------------------
2021-07-18 19:38:21,819 epoch 6 - iter 2/21 - loss 0.92254579 - samples/sec: 59.78 - lr: 0.000030
2021-07-18 19:38:22,844 epoch 6 - iter 4/21 - loss 1.02565378 - samples/sec: 62.45 - lr: 0.000030
2021-07-18 19:38:23,904 epoch 6 - iter 6/21 - loss 0.90893286 - samples/sec: 60.43 - lr: 0.000030
2021-07-18 19:38:24,952 epoch 6 - iter 8/21 - loss 0.87980729 - samples/sec: 61.11 - lr: 0.000030
2021-07-18 19:38:26,009 epoch 6 - iter 10/21 - loss 0.93022314 - samples/sec: 60.52 - lr: 0.000030
2021-07-18 19:38:27,070 epoch 6 - iter 12/21 - loss 0.90802485 - samples/sec: 60.40 - lr: 0.000030
2021-07-18 19:38:28,140 epoch 6 - iter 14/21 - loss 0.89402370 - samples/sec: 59.84 - lr: 0.000030
2021-07-18 19:38:29,197 epoch 6 - iter 16/21 - loss 0.86912037 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 19:38:30,259 epoch 6 - iter 18/21 - loss 0.83549792 - samples/sec: 60.25 - lr: 0.000030
2021-07-18 19:38:31,303 epoch 6 - iter 20/21 - loss 0.81796979 - samples/sec: 61.36 - lr: 0.000030
2021-07-18 19:38:31,504 ----------------------------------------------------------------------------------------------------
2021-07-18 19:38:31,504 EPOCH 6 done: loss 0.8034 - lr 0.0000300
2021-07-18 19:38:32,525 DEV : loss 0.5646220445632935 - score 0.9299
2021-07-18 19:38:32,539 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:38:36,297 ----------------------------------------------------------------------------------------------------
2021-07-18 19:38:37,351 epoch 7 - iter 2/21 - loss 0.82774889 - samples/sec: 60.76 - lr: 0.000030
2021-07-18 19:38:38,410 epoch 7 - iter 4/21 - loss 0.90225272 - samples/sec: 60.47 - lr: 0.000030
2021-07-18 19:38:39,474 epoch 7 - iter 6/21 - loss 0.81127015 - samples/sec: 60.20 - lr: 0.000030
2021-07-18 19:38:40,503 epoch 7 - iter 8/21 - loss 0.74939914 - samples/sec: 62.25 - lr: 0.000030
2021-07-18 19:38:41,564 epoch 7 - iter 10/21 - loss 0.79087451 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 19:38:42,630 epoch 7 - iter 12/21 - loss 0.74350391 - samples/sec: 60.10 - lr: 0.000030
2021-07-18 19:38:43,700 epoch 7 - iter 14/21 - loss 0.72670465 - samples/sec: 59.86 - lr: 0.000030
2021-07-18 19:38:44,753 epoch 7 - iter 16/21 - loss 0.71273762 - samples/sec: 60.79 - lr: 0.000030
2021-07-18 19:38:45,824 epoch 7 - iter 18/21 - loss 0.68798553 - samples/sec: 59.80 - lr: 0.000030
2021-07-18 19:38:46,859 epoch 7 - iter 20/21 - loss 0.68807513 - samples/sec: 61.83 - lr: 0.000030
2021-07-18 19:38:47,058 ----------------------------------------------------------------------------------------------------
2021-07-18 19:38:47,058 EPOCH 7 done: loss 0.7103 - lr 0.0000300
2021-07-18 19:38:48,078 DEV : loss 0.5137653350830078 - score 0.9363
2021-07-18 19:38:48,092 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:38:51,942 ----------------------------------------------------------------------------------------------------
2021-07-18 19:38:53,000 epoch 8 - iter 2/21 - loss 0.69984627 - samples/sec: 60.53 - lr: 0.000030
2021-07-18 19:38:54,143 epoch 8 - iter 4/21 - loss 0.66523309 - samples/sec: 56.00 - lr: 0.000030
2021-07-18 19:38:55,198 epoch 8 - iter 6/21 - loss 0.65901384 - samples/sec: 60.71 - lr: 0.000030
2021-07-18 19:38:56,280 epoch 8 - iter 8/21 - loss 0.67233098 - samples/sec: 59.14 - lr: 0.000030
2021-07-18 19:38:57,344 epoch 8 - iter 10/21 - loss 0.63691236 - samples/sec: 60.22 - lr: 0.000030
2021-07-18 19:38:58,417 epoch 8 - iter 12/21 - loss 0.63621795 - samples/sec: 59.67 - lr: 0.000030
2021-07-18 19:38:59,456 epoch 8 - iter 14/21 - loss 0.65649128 - samples/sec: 61.61 - lr: 0.000030
2021-07-18 19:39:00,506 epoch 8 - iter 16/21 - loss 0.65452166 - samples/sec: 61.02 - lr: 0.000030
2021-07-18 19:39:01,538 epoch 8 - iter 18/21 - loss 0.64609547 - samples/sec: 61.99 - lr: 0.000030
2021-07-18 19:39:02,619 epoch 8 - iter 20/21 - loss 0.64754722 - samples/sec: 59.25 - lr: 0.000030
2021-07-18 19:39:02,818 ----------------------------------------------------------------------------------------------------
2021-07-18 19:39:02,819 EPOCH 8 done: loss 0.6347 - lr 0.0000300
2021-07-18 19:39:03,839 DEV : loss 0.478287935256958 - score 0.9444
2021-07-18 19:39:03,852 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:39:07,723 ----------------------------------------------------------------------------------------------------
2021-07-18 19:39:08,774 epoch 9 - iter 2/21 - loss 0.50741744 - samples/sec: 60.95 - lr: 0.000030
2021-07-18 19:39:09,817 epoch 9 - iter 4/21 - loss 0.57123584 - samples/sec: 61.37 - lr: 0.000030
2021-07-18 19:39:10,862 epoch 9 - iter 6/21 - loss 0.53492373 - samples/sec: 61.30 - lr: 0.000030
2021-07-18 19:39:11,925 epoch 9 - iter 8/21 - loss 0.57610957 - samples/sec: 60.24 - lr: 0.000030
2021-07-18 19:39:12,950 epoch 9 - iter 10/21 - loss 0.55405945 - samples/sec: 62.43 - lr: 0.000030
2021-07-18 19:39:13,996 epoch 9 - iter 12/21 - loss 0.52352184 - samples/sec: 61.25 - lr: 0.000030
2021-07-18 19:39:15,051 epoch 9 - iter 14/21 - loss 0.52290310 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 19:39:16,092 epoch 9 - iter 16/21 - loss 0.50514547 - samples/sec: 61.48 - lr: 0.000030
2021-07-18 19:39:17,094 epoch 9 - iter 18/21 - loss 0.51370088 - samples/sec: 63.93 - lr: 0.000030
2021-07-18 19:39:18,155 epoch 9 - iter 20/21 - loss 0.54329215 - samples/sec: 60.37 - lr: 0.000030
2021-07-18 19:39:18,354 ----------------------------------------------------------------------------------------------------
2021-07-18 19:39:18,354 EPOCH 9 done: loss 0.5585 - lr 0.0000300
2021-07-18 19:39:19,371 DEV : loss 0.4700254797935486 - score 0.9461
2021-07-18 19:39:19,385 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:39:23,296 ----------------------------------------------------------------------------------------------------
2021-07-18 19:39:24,344 epoch 10 - iter 2/21 - loss 0.36702311 - samples/sec: 61.14 - lr: 0.000030
2021-07-18 19:39:25,395 epoch 10 - iter 4/21 - loss 0.43561698 - samples/sec: 60.91 - lr: 0.000030
2021-07-18 19:39:26,432 epoch 10 - iter 6/21 - loss 0.47682725 - samples/sec: 61.72 - lr: 0.000030
2021-07-18 19:39:27,469 epoch 10 - iter 8/21 - loss 0.47461644 - samples/sec: 61.78 - lr: 0.000030
2021-07-18 19:39:28,531 epoch 10 - iter 10/21 - loss 0.47028189 - samples/sec: 60.26 - lr: 0.000030
2021-07-18 19:39:29,563 epoch 10 - iter 12/21 - loss 0.49742115 - samples/sec: 62.07 - lr: 0.000030
2021-07-18 19:39:30,591 epoch 10 - iter 14/21 - loss 0.48258918 - samples/sec: 62.26 - lr: 0.000030
2021-07-18 19:39:31,631 epoch 10 - iter 16/21 - loss 0.49496258 - samples/sec: 61.57 - lr: 0.000030
2021-07-18 19:39:32,685 epoch 10 - iter 18/21 - loss 0.48671332 - samples/sec: 60.79 - lr: 0.000030
2021-07-18 19:39:33,749 epoch 10 - iter 20/21 - loss 0.49110816 - samples/sec: 60.16 - lr: 0.000030
2021-07-18 19:39:33,949 ----------------------------------------------------------------------------------------------------
2021-07-18 19:39:33,949 EPOCH 10 done: loss 0.4785 - lr 0.0000300
2021-07-18 19:39:34,967 DEV : loss 0.45096516609191895 - score 0.9482
2021-07-18 19:39:34,980 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:39:38,727 ----------------------------------------------------------------------------------------------------
2021-07-18 19:39:39,777 epoch 11 - iter 2/21 - loss 0.43177511 - samples/sec: 60.98 - lr: 0.000030
2021-07-18 19:39:40,831 epoch 11 - iter 4/21 - loss 0.39629077 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 19:39:41,888 epoch 11 - iter 6/21 - loss 0.44973470 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 19:39:42,920 epoch 11 - iter 8/21 - loss 0.49865032 - samples/sec: 62.03 - lr: 0.000030
2021-07-18 19:39:43,953 epoch 11 - iter 10/21 - loss 0.49625956 - samples/sec: 62.00 - lr: 0.000030
2021-07-18 19:39:44,980 epoch 11 - iter 12/21 - loss 0.48782356 - samples/sec: 62.37 - lr: 0.000030
2021-07-18 19:39:46,008 epoch 11 - iter 14/21 - loss 0.47099660 - samples/sec: 62.23 - lr: 0.000030
2021-07-18 19:39:47,060 epoch 11 - iter 16/21 - loss 0.46590270 - samples/sec: 60.86 - lr: 0.000030
2021-07-18 19:39:48,123 epoch 11 - iter 18/21 - loss 0.45903862 - samples/sec: 60.29 - lr: 0.000030
2021-07-18 19:39:49,172 epoch 11 - iter 20/21 - loss 0.47580421 - samples/sec: 61.00 - lr: 0.000030
2021-07-18 19:39:49,374 ----------------------------------------------------------------------------------------------------
2021-07-18 19:39:49,375 EPOCH 11 done: loss 0.4820 - lr 0.0000300
2021-07-18 19:39:50,392 DEV : loss 0.43963202834129333 - score 0.9482
2021-07-18 19:39:50,406 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:39:54,205 ----------------------------------------------------------------------------------------------------
2021-07-18 19:39:55,352 epoch 12 - iter 2/21 - loss 0.44780186 - samples/sec: 55.85 - lr: 0.000030
2021-07-18 19:39:56,410 epoch 12 - iter 4/21 - loss 0.41058871 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 19:39:57,455 epoch 12 - iter 6/21 - loss 0.45664806 - samples/sec: 61.26 - lr: 0.000030
2021-07-18 19:39:58,512 epoch 12 - iter 8/21 - loss 0.42220654 - samples/sec: 60.60 - lr: 0.000030
2021-07-18 19:39:59,575 epoch 12 - iter 10/21 - loss 0.41815323 - samples/sec: 60.22 - lr: 0.000030
2021-07-18 19:40:00,637 epoch 12 - iter 12/21 - loss 0.41807529 - samples/sec: 60.29 - lr: 0.000030
2021-07-18 19:40:01,688 epoch 12 - iter 14/21 - loss 0.40977134 - samples/sec: 60.95 - lr: 0.000030
2021-07-18 19:40:02,720 epoch 12 - iter 16/21 - loss 0.41849097 - samples/sec: 62.01 - lr: 0.000030
2021-07-18 19:40:03,740 epoch 12 - iter 18/21 - loss 0.42905548 - samples/sec: 62.77 - lr: 0.000030
2021-07-18 19:40:04,795 epoch 12 - iter 20/21 - loss 0.42472325 - samples/sec: 60.67 - lr: 0.000030
2021-07-18 19:40:04,983 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:04,983 EPOCH 12 done: loss 0.4303 - lr 0.0000300
2021-07-18 19:40:06,002 DEV : loss 0.43325865268707275 - score 0.944
2021-07-18 19:40:06,015 BAD EPOCHS (no improvement): 1
2021-07-18 19:40:06,016 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:07,069 epoch 13 - iter 2/21 - loss 0.37694809 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 19:40:08,114 epoch 13 - iter 4/21 - loss 0.35831757 - samples/sec: 61.28 - lr: 0.000030
2021-07-18 19:40:09,162 epoch 13 - iter 6/21 - loss 0.39825413 - samples/sec: 61.11 - lr: 0.000030
2021-07-18 19:40:10,196 epoch 13 - iter 8/21 - loss 0.39996132 - samples/sec: 61.90 - lr: 0.000030
2021-07-18 19:40:11,216 epoch 13 - iter 10/21 - loss 0.39829663 - samples/sec: 62.81 - lr: 0.000030
2021-07-18 19:40:12,271 epoch 13 - iter 12/21 - loss 0.40896137 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 19:40:13,320 epoch 13 - iter 14/21 - loss 0.39657792 - samples/sec: 61.04 - lr: 0.000030
2021-07-18 19:40:14,373 epoch 13 - iter 16/21 - loss 0.39356810 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 19:40:15,432 epoch 13 - iter 18/21 - loss 0.38840531 - samples/sec: 60.48 - lr: 0.000030
2021-07-18 19:40:16,483 epoch 13 - iter 20/21 - loss 0.37595520 - samples/sec: 60.96 - lr: 0.000030
2021-07-18 19:40:16,676 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:16,676 EPOCH 13 done: loss 0.3687 - lr 0.0000300
2021-07-18 19:40:17,693 DEV : loss 0.43139562010765076 - score 0.9398
2021-07-18 19:40:17,707 BAD EPOCHS (no improvement): 2
2021-07-18 19:40:17,707 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:18,747 epoch 14 - iter 2/21 - loss 0.39030334 - samples/sec: 61.57 - lr: 0.000030
2021-07-18 19:40:19,809 epoch 14 - iter 4/21 - loss 0.37963288 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 19:40:20,849 epoch 14 - iter 6/21 - loss 0.36500407 - samples/sec: 61.57 - lr: 0.000030
2021-07-18 19:40:21,882 epoch 14 - iter 8/21 - loss 0.34704068 - samples/sec: 61.96 - lr: 0.000030
2021-07-18 19:40:22,910 epoch 14 - iter 10/21 - loss 0.33441639 - samples/sec: 62.30 - lr: 0.000030
2021-07-18 19:40:23,962 epoch 14 - iter 12/21 - loss 0.35101952 - samples/sec: 60.88 - lr: 0.000030
2021-07-18 19:40:25,007 epoch 14 - iter 14/21 - loss 0.36582748 - samples/sec: 61.24 - lr: 0.000030
2021-07-18 19:40:26,069 epoch 14 - iter 16/21 - loss 0.36282014 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 19:40:27,123 epoch 14 - iter 18/21 - loss 0.38532311 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 19:40:28,143 epoch 14 - iter 20/21 - loss 0.39781650 - samples/sec: 62.77 - lr: 0.000030
2021-07-18 19:40:28,342 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:28,342 EPOCH 14 done: loss 0.3988 - lr 0.0000300
2021-07-18 19:40:29,359 DEV : loss 0.42833709716796875 - score 0.9416
2021-07-18 19:40:29,372 BAD EPOCHS (no improvement): 3
2021-07-18 19:40:29,373 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:30,408 epoch 15 - iter 2/21 - loss 0.35756916 - samples/sec: 61.84 - lr: 0.000030
2021-07-18 19:40:31,458 epoch 15 - iter 4/21 - loss 0.36847672 - samples/sec: 61.00 - lr: 0.000030
2021-07-18 19:40:32,499 epoch 15 - iter 6/21 - loss 0.34405646 - samples/sec: 61.50 - lr: 0.000030
2021-07-18 19:40:33,533 epoch 15 - iter 8/21 - loss 0.33502453 - samples/sec: 61.89 - lr: 0.000030
2021-07-18 19:40:34,593 epoch 15 - iter 10/21 - loss 0.32322421 - samples/sec: 60.43 - lr: 0.000030
2021-07-18 19:40:35,637 epoch 15 - iter 12/21 - loss 0.33035068 - samples/sec: 61.35 - lr: 0.000030
2021-07-18 19:40:36,698 epoch 15 - iter 14/21 - loss 0.31995778 - samples/sec: 60.32 - lr: 0.000030
2021-07-18 19:40:37,745 epoch 15 - iter 16/21 - loss 0.32706304 - samples/sec: 61.15 - lr: 0.000030
2021-07-18 19:40:38,796 epoch 15 - iter 18/21 - loss 0.32438048 - samples/sec: 60.96 - lr: 0.000030
2021-07-18 19:40:39,835 epoch 15 - iter 20/21 - loss 0.33019115 - samples/sec: 61.64 - lr: 0.000030
2021-07-18 19:40:40,021 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:40,021 EPOCH 15 done: loss 0.3283 - lr 0.0000300
2021-07-18 19:40:41,041 DEV : loss 0.4240851402282715 - score 0.9438
Epoch    15: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 19:40:41,055 BAD EPOCHS (no improvement): 4
2021-07-18 19:40:41,055 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:42,092 epoch 16 - iter 2/21 - loss 0.40638870 - samples/sec: 61.74 - lr: 0.000015
2021-07-18 19:40:43,153 epoch 16 - iter 4/21 - loss 0.34831256 - samples/sec: 60.38 - lr: 0.000015
2021-07-18 19:40:44,208 epoch 16 - iter 6/21 - loss 0.34236694 - samples/sec: 60.66 - lr: 0.000015
2021-07-18 19:40:45,275 epoch 16 - iter 8/21 - loss 0.34613422 - samples/sec: 60.02 - lr: 0.000015
2021-07-18 19:40:46,312 epoch 16 - iter 10/21 - loss 0.35418327 - samples/sec: 61.73 - lr: 0.000015
2021-07-18 19:40:47,344 epoch 16 - iter 12/21 - loss 0.33679012 - samples/sec: 62.09 - lr: 0.000015
2021-07-18 19:40:48,377 epoch 16 - iter 14/21 - loss 0.33099289 - samples/sec: 61.99 - lr: 0.000015
2021-07-18 19:40:49,432 epoch 16 - iter 16/21 - loss 0.33539872 - samples/sec: 60.66 - lr: 0.000015
2021-07-18 19:40:50,463 epoch 16 - iter 18/21 - loss 0.32206921 - samples/sec: 62.09 - lr: 0.000015
2021-07-18 19:40:51,507 epoch 16 - iter 20/21 - loss 0.32281441 - samples/sec: 61.35 - lr: 0.000015
2021-07-18 19:40:51,704 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:51,704 EPOCH 16 done: loss 0.3183 - lr 0.0000150
2021-07-18 19:40:52,826 DEV : loss 0.4473673701286316 - score 0.9393
2021-07-18 19:40:52,840 BAD EPOCHS (no improvement): 1
2021-07-18 19:40:52,840 ----------------------------------------------------------------------------------------------------
2021-07-18 19:40:53,867 epoch 17 - iter 2/21 - loss 0.27270220 - samples/sec: 62.36 - lr: 0.000015
2021-07-18 19:40:54,913 epoch 17 - iter 4/21 - loss 0.33290405 - samples/sec: 61.22 - lr: 0.000015
2021-07-18 19:40:55,949 epoch 17 - iter 6/21 - loss 0.38654372 - samples/sec: 61.78 - lr: 0.000015
2021-07-18 19:40:57,013 epoch 17 - iter 8/21 - loss 0.38697124 - samples/sec: 60.18 - lr: 0.000015
2021-07-18 19:40:58,073 epoch 17 - iter 10/21 - loss 0.36868072 - samples/sec: 60.41 - lr: 0.000015
2021-07-18 19:40:59,137 epoch 17 - iter 12/21 - loss 0.35030422 - samples/sec: 60.19 - lr: 0.000015
2021-07-18 19:41:00,183 epoch 17 - iter 14/21 - loss 0.33895139 - samples/sec: 61.23 - lr: 0.000015
2021-07-18 19:41:01,216 epoch 17 - iter 16/21 - loss 0.34802756 - samples/sec: 61.95 - lr: 0.000015
2021-07-18 19:41:02,270 epoch 17 - iter 18/21 - loss 0.33503852 - samples/sec: 60.74 - lr: 0.000015
2021-07-18 19:41:03,316 epoch 17 - iter 20/21 - loss 0.33970237 - samples/sec: 61.21 - lr: 0.000015
2021-07-18 19:41:03,505 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:03,505 EPOCH 17 done: loss 0.3420 - lr 0.0000150
2021-07-18 19:41:04,523 DEV : loss 0.4121115207672119 - score 0.9478
2021-07-18 19:41:04,536 BAD EPOCHS (no improvement): 2
2021-07-18 19:41:04,537 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:05,547 epoch 18 - iter 2/21 - loss 0.40202051 - samples/sec: 63.38 - lr: 0.000015
2021-07-18 19:41:06,583 epoch 18 - iter 4/21 - loss 0.38969909 - samples/sec: 61.76 - lr: 0.000015
2021-07-18 19:41:07,639 epoch 18 - iter 6/21 - loss 0.34032334 - samples/sec: 60.68 - lr: 0.000015
2021-07-18 19:41:08,683 epoch 18 - iter 8/21 - loss 0.37691873 - samples/sec: 61.29 - lr: 0.000015
2021-07-18 19:41:09,747 epoch 18 - iter 10/21 - loss 0.34964598 - samples/sec: 60.19 - lr: 0.000015
2021-07-18 19:41:10,787 epoch 18 - iter 12/21 - loss 0.32995336 - samples/sec: 61.57 - lr: 0.000015
2021-07-18 19:41:11,829 epoch 18 - iter 14/21 - loss 0.31823421 - samples/sec: 61.48 - lr: 0.000015
2021-07-18 19:41:12,873 epoch 18 - iter 16/21 - loss 0.31983787 - samples/sec: 61.33 - lr: 0.000015
2021-07-18 19:41:13,917 epoch 18 - iter 18/21 - loss 0.32221986 - samples/sec: 61.34 - lr: 0.000015
2021-07-18 19:41:14,979 epoch 18 - iter 20/21 - loss 0.32677520 - samples/sec: 60.28 - lr: 0.000015
2021-07-18 19:41:15,175 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:15,175 EPOCH 18 done: loss 0.3172 - lr 0.0000150
2021-07-18 19:41:16,193 DEV : loss 0.42632195353507996 - score 0.9435
2021-07-18 19:41:16,207 BAD EPOCHS (no improvement): 3
2021-07-18 19:41:16,207 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:17,248 epoch 19 - iter 2/21 - loss 0.46591502 - samples/sec: 61.51 - lr: 0.000015
2021-07-18 19:41:18,267 epoch 19 - iter 4/21 - loss 0.31965673 - samples/sec: 62.82 - lr: 0.000015
2021-07-18 19:41:19,325 epoch 19 - iter 6/21 - loss 0.27819797 - samples/sec: 60.56 - lr: 0.000015
2021-07-18 19:41:20,365 epoch 19 - iter 8/21 - loss 0.27616561 - samples/sec: 61.54 - lr: 0.000015
2021-07-18 19:41:21,387 epoch 19 - iter 10/21 - loss 0.27739133 - samples/sec: 62.68 - lr: 0.000015
2021-07-18 19:41:22,430 epoch 19 - iter 12/21 - loss 0.28440811 - samples/sec: 61.36 - lr: 0.000015
2021-07-18 19:41:23,497 epoch 19 - iter 14/21 - loss 0.28737114 - samples/sec: 60.00 - lr: 0.000015
2021-07-18 19:41:24,545 epoch 19 - iter 16/21 - loss 0.30164672 - samples/sec: 61.14 - lr: 0.000015
2021-07-18 19:41:25,616 epoch 19 - iter 18/21 - loss 0.29314809 - samples/sec: 59.79 - lr: 0.000015
2021-07-18 19:41:26,671 epoch 19 - iter 20/21 - loss 0.28592046 - samples/sec: 60.64 - lr: 0.000015
2021-07-18 19:41:26,870 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:26,870 EPOCH 19 done: loss 0.2847 - lr 0.0000150
2021-07-18 19:41:27,888 DEV : loss 0.42296192049980164 - score 0.9457
Epoch    19: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 19:41:27,901 BAD EPOCHS (no improvement): 4
2021-07-18 19:41:27,902 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:28,947 epoch 20 - iter 2/21 - loss 0.34527767 - samples/sec: 61.25 - lr: 0.000008
2021-07-18 19:41:29,992 epoch 20 - iter 4/21 - loss 0.27352509 - samples/sec: 61.28 - lr: 0.000008
2021-07-18 19:41:31,039 epoch 20 - iter 6/21 - loss 0.28208951 - samples/sec: 61.14 - lr: 0.000008
2021-07-18 19:41:32,108 epoch 20 - iter 8/21 - loss 0.30463314 - samples/sec: 59.91 - lr: 0.000008
2021-07-18 19:41:33,151 epoch 20 - iter 10/21 - loss 0.27947395 - samples/sec: 61.37 - lr: 0.000008
2021-07-18 19:41:34,196 epoch 20 - iter 12/21 - loss 0.29088408 - samples/sec: 61.32 - lr: 0.000008
2021-07-18 19:41:35,241 epoch 20 - iter 14/21 - loss 0.32417587 - samples/sec: 61.22 - lr: 0.000008
2021-07-18 19:41:36,264 epoch 20 - iter 16/21 - loss 0.31028038 - samples/sec: 62.62 - lr: 0.000008
2021-07-18 19:41:37,299 epoch 20 - iter 18/21 - loss 0.30240340 - samples/sec: 61.87 - lr: 0.000008
2021-07-18 19:41:38,336 epoch 20 - iter 20/21 - loss 0.30845862 - samples/sec: 61.76 - lr: 0.000008
2021-07-18 19:41:38,530 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:38,531 EPOCH 20 done: loss 0.3056 - lr 0.0000075
2021-07-18 19:41:39,652 DEV : loss 0.4234997630119324 - score 0.9457
2021-07-18 19:41:39,665 BAD EPOCHS (no improvement): 1
2021-07-18 19:41:39,665 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:40,689 epoch 21 - iter 2/21 - loss 0.22171690 - samples/sec: 62.55 - lr: 0.000008
2021-07-18 19:41:41,723 epoch 21 - iter 4/21 - loss 0.30239831 - samples/sec: 61.96 - lr: 0.000008
2021-07-18 19:41:42,793 epoch 21 - iter 6/21 - loss 0.31046588 - samples/sec: 59.80 - lr: 0.000008
2021-07-18 19:41:43,848 epoch 21 - iter 8/21 - loss 0.30261843 - samples/sec: 60.73 - lr: 0.000008
2021-07-18 19:41:44,927 epoch 21 - iter 10/21 - loss 0.30214977 - samples/sec: 59.35 - lr: 0.000008
2021-07-18 19:41:45,972 epoch 21 - iter 12/21 - loss 0.30144733 - samples/sec: 61.26 - lr: 0.000008
2021-07-18 19:41:47,032 epoch 21 - iter 14/21 - loss 0.28867756 - samples/sec: 60.41 - lr: 0.000008
2021-07-18 19:41:48,083 epoch 21 - iter 16/21 - loss 0.30197678 - samples/sec: 60.93 - lr: 0.000008
2021-07-18 19:41:49,155 epoch 21 - iter 18/21 - loss 0.29097252 - samples/sec: 59.70 - lr: 0.000008
2021-07-18 19:41:50,206 epoch 21 - iter 20/21 - loss 0.28941637 - samples/sec: 60.94 - lr: 0.000008
2021-07-18 19:41:50,397 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:50,398 EPOCH 21 done: loss 0.2919 - lr 0.0000075
2021-07-18 19:41:51,416 DEV : loss 0.41878029704093933 - score 0.9457
2021-07-18 19:41:51,430 BAD EPOCHS (no improvement): 2
2021-07-18 19:41:51,430 ----------------------------------------------------------------------------------------------------
2021-07-18 19:41:52,486 epoch 22 - iter 2/21 - loss 0.42708844 - samples/sec: 60.63 - lr: 0.000008
2021-07-18 19:41:53,554 epoch 22 - iter 4/21 - loss 0.44686188 - samples/sec: 59.93 - lr: 0.000008
2021-07-18 19:41:54,609 epoch 22 - iter 6/21 - loss 0.37150964 - samples/sec: 60.71 - lr: 0.000008
2021-07-18 19:41:55,671 epoch 22 - iter 8/21 - loss 0.35515409 - samples/sec: 60.33 - lr: 0.000008
2021-07-18 19:41:56,720 epoch 22 - iter 10/21 - loss 0.33341483 - samples/sec: 61.02 - lr: 0.000008
2021-07-18 19:41:57,774 epoch 22 - iter 12/21 - loss 0.32884566 - samples/sec: 60.73 - lr: 0.000008
2021-07-18 19:41:58,850 epoch 22 - iter 14/21 - loss 0.32280532 - samples/sec: 59.49 - lr: 0.000008
2021-07-18 19:41:59,901 epoch 22 - iter 16/21 - loss 0.31201911 - samples/sec: 60.92 - lr: 0.000008
2021-07-18 19:42:00,937 epoch 22 - iter 18/21 - loss 0.30342762 - samples/sec: 61.80 - lr: 0.000008
2021-07-18 19:42:01,992 epoch 22 - iter 20/21 - loss 0.29539344 - samples/sec: 60.73 - lr: 0.000008
2021-07-18 19:42:02,189 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:02,190 EPOCH 22 done: loss 0.2867 - lr 0.0000075
2021-07-18 19:42:03,207 DEV : loss 0.41617435216903687 - score 0.9478
2021-07-18 19:42:03,220 BAD EPOCHS (no improvement): 3
2021-07-18 19:42:03,221 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:04,266 epoch 23 - iter 2/21 - loss 0.20209402 - samples/sec: 61.27 - lr: 0.000008
2021-07-18 19:42:05,318 epoch 23 - iter 4/21 - loss 0.19185930 - samples/sec: 60.83 - lr: 0.000008
2021-07-18 19:42:06,371 epoch 23 - iter 6/21 - loss 0.19607553 - samples/sec: 60.82 - lr: 0.000008
2021-07-18 19:42:07,435 epoch 23 - iter 8/21 - loss 0.22440701 - samples/sec: 60.17 - lr: 0.000008
2021-07-18 19:42:08,498 epoch 23 - iter 10/21 - loss 0.23959903 - samples/sec: 60.27 - lr: 0.000008
2021-07-18 19:42:09,550 epoch 23 - iter 12/21 - loss 0.25015308 - samples/sec: 60.81 - lr: 0.000008
2021-07-18 19:42:10,606 epoch 23 - iter 14/21 - loss 0.26066440 - samples/sec: 60.69 - lr: 0.000008
2021-07-18 19:42:11,670 epoch 23 - iter 16/21 - loss 0.26267685 - samples/sec: 60.17 - lr: 0.000008
2021-07-18 19:42:12,712 epoch 23 - iter 18/21 - loss 0.25256792 - samples/sec: 61.44 - lr: 0.000008
2021-07-18 19:42:13,777 epoch 23 - iter 20/21 - loss 0.25950491 - samples/sec: 60.09 - lr: 0.000008
2021-07-18 19:42:13,970 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:13,970 EPOCH 23 done: loss 0.2539 - lr 0.0000075
2021-07-18 19:42:14,997 DEV : loss 0.41325414180755615 - score 0.9459
Epoch    23: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 19:42:15,010 BAD EPOCHS (no improvement): 4
2021-07-18 19:42:15,011 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:16,051 epoch 24 - iter 2/21 - loss 0.26584475 - samples/sec: 61.51 - lr: 0.000004
2021-07-18 19:42:17,106 epoch 24 - iter 4/21 - loss 0.26445656 - samples/sec: 60.69 - lr: 0.000004
2021-07-18 19:42:18,147 epoch 24 - iter 6/21 - loss 0.24226349 - samples/sec: 61.54 - lr: 0.000004
2021-07-18 19:42:19,203 epoch 24 - iter 8/21 - loss 0.23435197 - samples/sec: 60.63 - lr: 0.000004
2021-07-18 19:42:20,265 epoch 24 - iter 10/21 - loss 0.25300480 - samples/sec: 60.27 - lr: 0.000004
2021-07-18 19:42:21,314 epoch 24 - iter 12/21 - loss 0.25552818 - samples/sec: 61.06 - lr: 0.000004
2021-07-18 19:42:22,390 epoch 24 - iter 14/21 - loss 0.25743863 - samples/sec: 59.52 - lr: 0.000004
2021-07-18 19:42:23,460 epoch 24 - iter 16/21 - loss 0.26222656 - samples/sec: 59.82 - lr: 0.000004
2021-07-18 19:42:24,523 epoch 24 - iter 18/21 - loss 0.27148779 - samples/sec: 60.26 - lr: 0.000004
2021-07-18 19:42:25,594 epoch 24 - iter 20/21 - loss 0.27812489 - samples/sec: 59.77 - lr: 0.000004
2021-07-18 19:42:25,793 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:25,793 EPOCH 24 done: loss 0.2699 - lr 0.0000038
2021-07-18 19:42:26,815 DEV : loss 0.4128572940826416 - score 0.9459
2021-07-18 19:42:26,829 BAD EPOCHS (no improvement): 1
2021-07-18 19:42:26,829 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:27,875 epoch 25 - iter 2/21 - loss 0.32941535 - samples/sec: 61.24 - lr: 0.000004
2021-07-18 19:42:28,910 epoch 25 - iter 4/21 - loss 0.26836668 - samples/sec: 61.87 - lr: 0.000004
2021-07-18 19:42:29,946 epoch 25 - iter 6/21 - loss 0.26269495 - samples/sec: 61.77 - lr: 0.000004
2021-07-18 19:42:31,026 epoch 25 - iter 8/21 - loss 0.26621264 - samples/sec: 59.30 - lr: 0.000004
2021-07-18 19:42:32,100 epoch 25 - iter 10/21 - loss 0.25771202 - samples/sec: 59.64 - lr: 0.000004
2021-07-18 19:42:33,151 epoch 25 - iter 12/21 - loss 0.26024465 - samples/sec: 60.88 - lr: 0.000004
2021-07-18 19:42:34,228 epoch 25 - iter 14/21 - loss 0.25563128 - samples/sec: 59.48 - lr: 0.000004
2021-07-18 19:42:35,268 epoch 25 - iter 16/21 - loss 0.27082716 - samples/sec: 61.55 - lr: 0.000004
2021-07-18 19:42:36,426 epoch 25 - iter 18/21 - loss 0.26550310 - samples/sec: 55.30 - lr: 0.000004
2021-07-18 19:42:37,504 epoch 25 - iter 20/21 - loss 0.26307694 - samples/sec: 59.40 - lr: 0.000004
2021-07-18 19:42:37,706 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:37,706 EPOCH 25 done: loss 0.2823 - lr 0.0000038
2021-07-18 19:42:38,728 DEV : loss 0.4126337468624115 - score 0.9459
2021-07-18 19:42:38,741 BAD EPOCHS (no improvement): 2
2021-07-18 19:42:38,741 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:39,794 epoch 26 - iter 2/21 - loss 0.30281174 - samples/sec: 60.86 - lr: 0.000004
2021-07-18 19:42:40,865 epoch 26 - iter 4/21 - loss 0.26694554 - samples/sec: 59.76 - lr: 0.000004
2021-07-18 19:42:41,928 epoch 26 - iter 6/21 - loss 0.27090995 - samples/sec: 60.24 - lr: 0.000004
2021-07-18 19:42:42,990 epoch 26 - iter 8/21 - loss 0.26596344 - samples/sec: 60.31 - lr: 0.000004
2021-07-18 19:42:44,068 epoch 26 - iter 10/21 - loss 0.28231833 - samples/sec: 59.41 - lr: 0.000004
2021-07-18 19:42:45,138 epoch 26 - iter 12/21 - loss 0.28323654 - samples/sec: 59.84 - lr: 0.000004
2021-07-18 19:42:46,191 epoch 26 - iter 14/21 - loss 0.29194881 - samples/sec: 60.76 - lr: 0.000004
2021-07-18 19:42:47,249 epoch 26 - iter 16/21 - loss 0.28444334 - samples/sec: 60.53 - lr: 0.000004
2021-07-18 19:42:48,297 epoch 26 - iter 18/21 - loss 0.26787479 - samples/sec: 61.09 - lr: 0.000004
2021-07-18 19:42:49,326 epoch 26 - iter 20/21 - loss 0.25950440 - samples/sec: 62.28 - lr: 0.000004
2021-07-18 19:42:49,510 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:49,510 EPOCH 26 done: loss 0.2505 - lr 0.0000038
2021-07-18 19:42:50,531 DEV : loss 0.41830477118492126 - score 0.9478
2021-07-18 19:42:50,544 BAD EPOCHS (no improvement): 3
2021-07-18 19:42:50,545 ----------------------------------------------------------------------------------------------------
2021-07-18 19:42:51,578 epoch 27 - iter 2/21 - loss 0.30020446 - samples/sec: 61.97 - lr: 0.000004
2021-07-18 19:42:52,643 epoch 27 - iter 4/21 - loss 0.25872120 - samples/sec: 60.10 - lr: 0.000004
2021-07-18 19:42:53,708 epoch 27 - iter 6/21 - loss 0.26245769 - samples/sec: 60.13 - lr: 0.000004
2021-07-18 19:42:54,779 epoch 27 - iter 8/21 - loss 0.26933046 - samples/sec: 59.81 - lr: 0.000004
2021-07-18 19:42:55,847 epoch 27 - iter 10/21 - loss 0.28273998 - samples/sec: 59.91 - lr: 0.000004
2021-07-18 19:42:56,904 epoch 27 - iter 12/21 - loss 0.28172254 - samples/sec: 60.62 - lr: 0.000004
2021-07-18 19:42:57,964 epoch 27 - iter 14/21 - loss 0.28460270 - samples/sec: 60.37 - lr: 0.000004
2021-07-18 19:42:59,038 epoch 27 - iter 16/21 - loss 0.27760923 - samples/sec: 59.63 - lr: 0.000004
2021-07-18 19:43:00,106 epoch 27 - iter 18/21 - loss 0.28324108 - samples/sec: 59.93 - lr: 0.000004
2021-07-18 19:43:01,143 epoch 27 - iter 20/21 - loss 0.28751724 - samples/sec: 61.77 - lr: 0.000004
2021-07-18 19:43:01,341 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:01,341 EPOCH 27 done: loss 0.2819 - lr 0.0000038
2021-07-18 19:43:02,373 DEV : loss 0.4121137857437134 - score 0.9459
Epoch    27: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 19:43:02,387 BAD EPOCHS (no improvement): 4
2021-07-18 19:43:02,387 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:02,387 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:02,387 learning rate too small - quitting training!
2021-07-18 19:43:02,387 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:03,098 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:03,098 Testing using best model ...
2021-07-18 19:43:03,098 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/nld.rst.nldt/best-model.pt
2021-07-18 19:43:07,487 0.9608	0.9696	0.9652
2021-07-18 19:43:07,487 
Results:
- F1-score (micro) 0.9652
- F1-score (macro) 0.9652

By class:
SENT       tp: 319 - fp: 13 - fn: 10 - precision: 0.9608 - recall: 0.9696 - f1-score: 0.9652
2021-07-18 19:43:07,487 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/por.rst.cstn/
2021-07-18 19:43:07,496 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/por.rst.cstn
2021-07-18 19:43:07,497 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/por.rst.cstn/sent_train.txt
2021-07-18 19:43:07,499 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/por.rst.cstn/sent_dev.txt
2021-07-18 19:43:07,499 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/por.rst.cstn/sent_test.txt
Corpus: 1880 train + 316 dev + 479 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 19:43:10,810 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:10,812 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(29794, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 19:43:10,812 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:10,812 Corpus: "Corpus: 1880 train + 316 dev + 479 test sentences"
2021-07-18 19:43:10,812 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:10,812 Parameters:
2021-07-18 19:43:10,812  - learning_rate: "3e-05"
2021-07-18 19:43:10,812  - mini_batch_size: "32"
2021-07-18 19:43:10,812  - patience: "3"
2021-07-18 19:43:10,812  - anneal_factor: "0.5"
2021-07-18 19:43:10,812  - max_epochs: "40"
2021-07-18 19:43:10,812  - shuffle: "True"
2021-07-18 19:43:10,812  - train_with_dev: "False"
2021-07-18 19:43:10,812  - batch_growth_annealing: "False"
2021-07-18 19:43:10,812 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:10,812 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/por.rst.cstn"
2021-07-18 19:43:10,812 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:10,812 Device: cuda:0
2021-07-18 19:43:10,812 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:10,812 Embeddings storage mode: cpu
2021-07-18 19:43:10,815 ----------------------------------------------------------------------------------------------------
2021-07-18 19:43:15,930 epoch 1 - iter 5/59 - loss 13.82541351 - samples/sec: 31.29 - lr: 0.000030
2021-07-18 19:43:21,027 epoch 1 - iter 10/59 - loss 10.43699050 - samples/sec: 31.39 - lr: 0.000030
2021-07-18 19:43:26,153 epoch 1 - iter 15/59 - loss 8.62354701 - samples/sec: 31.22 - lr: 0.000030
2021-07-18 19:43:31,292 epoch 1 - iter 20/59 - loss 7.52351079 - samples/sec: 31.14 - lr: 0.000030
2021-07-18 19:43:36,394 epoch 1 - iter 25/59 - loss 6.75591345 - samples/sec: 31.36 - lr: 0.000030
2021-07-18 19:43:41,487 epoch 1 - iter 30/59 - loss 6.17271496 - samples/sec: 31.42 - lr: 0.000030
2021-07-18 19:43:46,614 epoch 1 - iter 35/59 - loss 5.65138908 - samples/sec: 31.21 - lr: 0.000030
2021-07-18 19:43:51,698 epoch 1 - iter 40/59 - loss 5.25808917 - samples/sec: 31.47 - lr: 0.000030
2021-07-18 19:43:56,740 epoch 1 - iter 45/59 - loss 4.91274702 - samples/sec: 31.74 - lr: 0.000030
2021-07-18 19:44:01,856 epoch 1 - iter 50/59 - loss 4.60906609 - samples/sec: 31.28 - lr: 0.000030
2021-07-18 19:44:06,978 epoch 1 - iter 55/59 - loss 4.32917737 - samples/sec: 31.24 - lr: 0.000030
2021-07-18 19:44:10,986 ----------------------------------------------------------------------------------------------------
2021-07-18 19:44:10,986 EPOCH 1 done: loss 4.1267 - lr 0.0000300
2021-07-18 19:44:16,603 DEV : loss 0.8309232592582703 - score 0.7804
2021-07-18 19:44:16,627 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:44:17,396 ----------------------------------------------------------------------------------------------------
2021-07-18 19:44:20,018 epoch 2 - iter 5/59 - loss 1.04092677 - samples/sec: 61.03 - lr: 0.000030
2021-07-18 19:44:22,679 epoch 2 - iter 10/59 - loss 1.04692588 - samples/sec: 60.15 - lr: 0.000030
2021-07-18 19:44:25,278 epoch 2 - iter 15/59 - loss 0.96954768 - samples/sec: 61.58 - lr: 0.000030
2021-07-18 19:44:27,891 epoch 2 - iter 20/59 - loss 0.92889404 - samples/sec: 61.24 - lr: 0.000030
2021-07-18 19:44:30,543 epoch 2 - iter 25/59 - loss 0.92027869 - samples/sec: 60.36 - lr: 0.000030
2021-07-18 19:44:33,172 epoch 2 - iter 30/59 - loss 0.88511532 - samples/sec: 60.86 - lr: 0.000030
2021-07-18 19:44:35,799 epoch 2 - iter 35/59 - loss 0.85261144 - samples/sec: 60.92 - lr: 0.000030
2021-07-18 19:44:38,450 epoch 2 - iter 40/59 - loss 0.83320231 - samples/sec: 60.36 - lr: 0.000030
2021-07-18 19:44:41,095 epoch 2 - iter 45/59 - loss 0.80835025 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 19:44:43,750 epoch 2 - iter 50/59 - loss 0.79114104 - samples/sec: 60.29 - lr: 0.000030
2021-07-18 19:44:46,379 epoch 2 - iter 55/59 - loss 0.78123275 - samples/sec: 60.87 - lr: 0.000030
2021-07-18 19:44:48,343 ----------------------------------------------------------------------------------------------------
2021-07-18 19:44:48,344 EPOCH 2 done: loss 0.7664 - lr 0.0000300
2021-07-18 19:44:50,084 DEV : loss 0.2710939347743988 - score 0.9537
2021-07-18 19:44:50,108 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:44:54,027 ----------------------------------------------------------------------------------------------------
2021-07-18 19:44:56,659 epoch 3 - iter 5/59 - loss 0.61637310 - samples/sec: 60.83 - lr: 0.000030
2021-07-18 19:44:59,304 epoch 3 - iter 10/59 - loss 0.59245969 - samples/sec: 60.50 - lr: 0.000030
2021-07-18 19:45:01,941 epoch 3 - iter 15/59 - loss 0.59843057 - samples/sec: 60.69 - lr: 0.000030
2021-07-18 19:45:04,546 epoch 3 - iter 20/59 - loss 0.57841411 - samples/sec: 61.42 - lr: 0.000030
2021-07-18 19:45:07,167 epoch 3 - iter 25/59 - loss 0.57646052 - samples/sec: 61.05 - lr: 0.000030
2021-07-18 19:45:09,771 epoch 3 - iter 30/59 - loss 0.56891288 - samples/sec: 61.47 - lr: 0.000030
2021-07-18 19:45:12,371 epoch 3 - iter 35/59 - loss 0.56383632 - samples/sec: 61.56 - lr: 0.000030
2021-07-18 19:45:15,012 epoch 3 - iter 40/59 - loss 0.54192743 - samples/sec: 60.59 - lr: 0.000030
2021-07-18 19:45:17,642 epoch 3 - iter 45/59 - loss 0.54136782 - samples/sec: 60.85 - lr: 0.000030
2021-07-18 19:45:20,226 epoch 3 - iter 50/59 - loss 0.52208029 - samples/sec: 61.95 - lr: 0.000030
2021-07-18 19:45:22,863 epoch 3 - iter 55/59 - loss 0.51830320 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 19:45:24,846 ----------------------------------------------------------------------------------------------------
2021-07-18 19:45:24,846 EPOCH 3 done: loss 0.5101 - lr 0.0000300
2021-07-18 19:45:26,572 DEV : loss 0.18604309856891632 - score 0.9653
2021-07-18 19:45:26,596 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:45:30,417 ----------------------------------------------------------------------------------------------------
2021-07-18 19:45:33,013 epoch 4 - iter 5/59 - loss 0.43262795 - samples/sec: 61.66 - lr: 0.000030
2021-07-18 19:45:35,625 epoch 4 - iter 10/59 - loss 0.42761335 - samples/sec: 61.26 - lr: 0.000030
2021-07-18 19:45:38,208 epoch 4 - iter 15/59 - loss 0.38472515 - samples/sec: 61.95 - lr: 0.000030
2021-07-18 19:45:40,802 epoch 4 - iter 20/59 - loss 0.38094679 - samples/sec: 61.70 - lr: 0.000030
2021-07-18 19:45:43,426 epoch 4 - iter 25/59 - loss 0.39607638 - samples/sec: 61.00 - lr: 0.000030
2021-07-18 19:45:46,063 epoch 4 - iter 30/59 - loss 0.39284075 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 19:45:48,716 epoch 4 - iter 35/59 - loss 0.39646199 - samples/sec: 60.34 - lr: 0.000030
2021-07-18 19:45:51,347 epoch 4 - iter 40/59 - loss 0.39544156 - samples/sec: 60.81 - lr: 0.000030
2021-07-18 19:45:53,990 epoch 4 - iter 45/59 - loss 0.39729758 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 19:45:56,642 epoch 4 - iter 50/59 - loss 0.38796259 - samples/sec: 60.35 - lr: 0.000030
2021-07-18 19:45:59,273 epoch 4 - iter 55/59 - loss 0.38289274 - samples/sec: 60.82 - lr: 0.000030
2021-07-18 19:46:01,287 ----------------------------------------------------------------------------------------------------
2021-07-18 19:46:01,288 EPOCH 4 done: loss 0.3826 - lr 0.0000300
2021-07-18 19:46:03,204 DEV : loss 0.14156661927700043 - score 0.9653
2021-07-18 19:46:03,228 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:46:07,208 ----------------------------------------------------------------------------------------------------
2021-07-18 19:46:09,859 epoch 5 - iter 5/59 - loss 0.31878330 - samples/sec: 60.38 - lr: 0.000030
2021-07-18 19:46:12,514 epoch 5 - iter 10/59 - loss 0.28649462 - samples/sec: 60.27 - lr: 0.000030
2021-07-18 19:46:15,162 epoch 5 - iter 15/59 - loss 0.27666758 - samples/sec: 60.43 - lr: 0.000030
2021-07-18 19:46:17,796 epoch 5 - iter 20/59 - loss 0.28325811 - samples/sec: 60.75 - lr: 0.000030
2021-07-18 19:46:20,400 epoch 5 - iter 25/59 - loss 0.29761754 - samples/sec: 61.47 - lr: 0.000030
2021-07-18 19:46:23,040 epoch 5 - iter 30/59 - loss 0.30374204 - samples/sec: 60.61 - lr: 0.000030
2021-07-18 19:46:25,664 epoch 5 - iter 35/59 - loss 0.30631807 - samples/sec: 61.00 - lr: 0.000030
2021-07-18 19:46:28,296 epoch 5 - iter 40/59 - loss 0.30944277 - samples/sec: 60.80 - lr: 0.000030
2021-07-18 19:46:30,949 epoch 5 - iter 45/59 - loss 0.31261500 - samples/sec: 60.32 - lr: 0.000030
2021-07-18 19:46:33,619 epoch 5 - iter 50/59 - loss 0.31509890 - samples/sec: 59.94 - lr: 0.000030
2021-07-18 19:46:36,245 epoch 5 - iter 55/59 - loss 0.31348117 - samples/sec: 60.95 - lr: 0.000030
2021-07-18 19:46:38,236 ----------------------------------------------------------------------------------------------------
2021-07-18 19:46:38,237 EPOCH 5 done: loss 0.3127 - lr 0.0000300
2021-07-18 19:46:39,965 DEV : loss 0.11297013610601425 - score 0.9747
2021-07-18 19:46:39,988 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:46:43,809 ----------------------------------------------------------------------------------------------------
2021-07-18 19:46:46,451 epoch 6 - iter 5/59 - loss 0.30727553 - samples/sec: 60.59 - lr: 0.000030
2021-07-18 19:46:49,058 epoch 6 - iter 10/59 - loss 0.27591689 - samples/sec: 61.39 - lr: 0.000030
2021-07-18 19:46:51,709 epoch 6 - iter 15/59 - loss 0.28743038 - samples/sec: 60.37 - lr: 0.000030
2021-07-18 19:46:54,297 epoch 6 - iter 20/59 - loss 0.27813698 - samples/sec: 61.82 - lr: 0.000030
2021-07-18 19:46:56,953 epoch 6 - iter 25/59 - loss 0.27090817 - samples/sec: 60.26 - lr: 0.000030
2021-07-18 19:46:59,615 epoch 6 - iter 30/59 - loss 0.27272359 - samples/sec: 60.12 - lr: 0.000030
2021-07-18 19:47:02,275 epoch 6 - iter 35/59 - loss 0.26723186 - samples/sec: 60.17 - lr: 0.000030
2021-07-18 19:47:04,937 epoch 6 - iter 40/59 - loss 0.26089092 - samples/sec: 60.12 - lr: 0.000030
2021-07-18 19:47:07,570 epoch 6 - iter 45/59 - loss 0.25607029 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 19:47:10,203 epoch 6 - iter 50/59 - loss 0.24686857 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 19:47:12,840 epoch 6 - iter 55/59 - loss 0.25026498 - samples/sec: 60.69 - lr: 0.000030
2021-07-18 19:47:14,801 ----------------------------------------------------------------------------------------------------
2021-07-18 19:47:14,801 EPOCH 6 done: loss 0.2470 - lr 0.0000300
2021-07-18 19:47:16,526 DEV : loss 0.09388350695371628 - score 0.9844
2021-07-18 19:47:16,550 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:47:20,732 ----------------------------------------------------------------------------------------------------
2021-07-18 19:47:23,371 epoch 7 - iter 5/59 - loss 0.24373807 - samples/sec: 60.65 - lr: 0.000030
2021-07-18 19:47:25,995 epoch 7 - iter 10/59 - loss 0.21520729 - samples/sec: 60.99 - lr: 0.000030
2021-07-18 19:47:28,644 epoch 7 - iter 15/59 - loss 0.22741538 - samples/sec: 60.43 - lr: 0.000030
2021-07-18 19:47:31,276 epoch 7 - iter 20/59 - loss 0.22835256 - samples/sec: 60.80 - lr: 0.000030
2021-07-18 19:47:33,922 epoch 7 - iter 25/59 - loss 0.21327806 - samples/sec: 60.48 - lr: 0.000030
2021-07-18 19:47:36,579 epoch 7 - iter 30/59 - loss 0.22003369 - samples/sec: 60.25 - lr: 0.000030
2021-07-18 19:47:39,198 epoch 7 - iter 35/59 - loss 0.21735150 - samples/sec: 61.10 - lr: 0.000030
2021-07-18 19:47:41,817 epoch 7 - iter 40/59 - loss 0.21130352 - samples/sec: 61.11 - lr: 0.000030
2021-07-18 19:47:44,451 epoch 7 - iter 45/59 - loss 0.20991935 - samples/sec: 60.75 - lr: 0.000030
2021-07-18 19:47:47,115 epoch 7 - iter 50/59 - loss 0.20850895 - samples/sec: 60.07 - lr: 0.000030
2021-07-18 19:47:49,770 epoch 7 - iter 55/59 - loss 0.21281741 - samples/sec: 60.29 - lr: 0.000030
2021-07-18 19:47:51,764 ----------------------------------------------------------------------------------------------------
2021-07-18 19:47:51,765 EPOCH 7 done: loss 0.2106 - lr 0.0000300
2021-07-18 19:47:53,490 DEV : loss 0.07699970155954361 - score 0.9863
2021-07-18 19:47:53,514 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:47:57,582 ----------------------------------------------------------------------------------------------------
2021-07-18 19:48:00,204 epoch 8 - iter 5/59 - loss 0.18899847 - samples/sec: 61.04 - lr: 0.000030
2021-07-18 19:48:02,847 epoch 8 - iter 10/59 - loss 0.20390046 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 19:48:05,490 epoch 8 - iter 15/59 - loss 0.20103314 - samples/sec: 60.55 - lr: 0.000030
2021-07-18 19:48:08,115 epoch 8 - iter 20/59 - loss 0.19773705 - samples/sec: 60.97 - lr: 0.000030
2021-07-18 19:48:10,735 epoch 8 - iter 25/59 - loss 0.19451014 - samples/sec: 61.09 - lr: 0.000030
2021-07-18 19:48:13,389 epoch 8 - iter 30/59 - loss 0.19139402 - samples/sec: 60.31 - lr: 0.000030
2021-07-18 19:48:16,039 epoch 8 - iter 35/59 - loss 0.19728600 - samples/sec: 60.38 - lr: 0.000030
2021-07-18 19:48:18,674 epoch 8 - iter 40/59 - loss 0.19261754 - samples/sec: 60.73 - lr: 0.000030
2021-07-18 19:48:21,310 epoch 8 - iter 45/59 - loss 0.19287868 - samples/sec: 60.72 - lr: 0.000030
2021-07-18 19:48:23,975 epoch 8 - iter 50/59 - loss 0.19941249 - samples/sec: 60.06 - lr: 0.000030
2021-07-18 19:48:26,615 epoch 8 - iter 55/59 - loss 0.19492526 - samples/sec: 60.62 - lr: 0.000030
2021-07-18 19:48:28,637 ----------------------------------------------------------------------------------------------------
2021-07-18 19:48:28,637 EPOCH 8 done: loss 0.1973 - lr 0.0000300
2021-07-18 19:48:30,561 DEV : loss 0.07211794704198837 - score 0.9864
2021-07-18 19:48:30,585 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:48:34,390 ----------------------------------------------------------------------------------------------------
2021-07-18 19:48:37,012 epoch 9 - iter 5/59 - loss 0.13190303 - samples/sec: 61.04 - lr: 0.000030
2021-07-18 19:48:39,654 epoch 9 - iter 10/59 - loss 0.16972764 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 19:48:42,308 epoch 9 - iter 15/59 - loss 0.17186688 - samples/sec: 60.29 - lr: 0.000030
2021-07-18 19:48:44,955 epoch 9 - iter 20/59 - loss 0.16444379 - samples/sec: 60.45 - lr: 0.000030
2021-07-18 19:48:47,582 epoch 9 - iter 25/59 - loss 0.17499188 - samples/sec: 60.93 - lr: 0.000030
2021-07-18 19:48:50,226 epoch 9 - iter 30/59 - loss 0.16668598 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:48:52,873 epoch 9 - iter 35/59 - loss 0.16989115 - samples/sec: 60.46 - lr: 0.000030
2021-07-18 19:48:55,529 epoch 9 - iter 40/59 - loss 0.16869181 - samples/sec: 60.25 - lr: 0.000030
2021-07-18 19:48:58,182 epoch 9 - iter 45/59 - loss 0.16330712 - samples/sec: 60.34 - lr: 0.000030
2021-07-18 19:49:00,804 epoch 9 - iter 50/59 - loss 0.15786615 - samples/sec: 61.03 - lr: 0.000030
2021-07-18 19:49:03,467 epoch 9 - iter 55/59 - loss 0.15725087 - samples/sec: 60.10 - lr: 0.000030
2021-07-18 19:49:05,437 ----------------------------------------------------------------------------------------------------
2021-07-18 19:49:05,438 EPOCH 9 done: loss 0.1589 - lr 0.0000300
2021-07-18 19:49:07,168 DEV : loss 0.06569529324769974 - score 0.9883
2021-07-18 19:49:07,192 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:49:11,090 ----------------------------------------------------------------------------------------------------
2021-07-18 19:49:13,726 epoch 10 - iter 5/59 - loss 0.13010857 - samples/sec: 60.73 - lr: 0.000030
2021-07-18 19:49:16,389 epoch 10 - iter 10/59 - loss 0.15359169 - samples/sec: 60.09 - lr: 0.000030
2021-07-18 19:49:19,061 epoch 10 - iter 15/59 - loss 0.14669112 - samples/sec: 59.91 - lr: 0.000030
2021-07-18 19:49:21,682 epoch 10 - iter 20/59 - loss 0.14181410 - samples/sec: 61.04 - lr: 0.000030
2021-07-18 19:49:24,305 epoch 10 - iter 25/59 - loss 0.14406567 - samples/sec: 61.03 - lr: 0.000030
2021-07-18 19:49:26,947 epoch 10 - iter 30/59 - loss 0.14823387 - samples/sec: 60.57 - lr: 0.000030
2021-07-18 19:49:29,590 epoch 10 - iter 35/59 - loss 0.15780965 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:49:32,249 epoch 10 - iter 40/59 - loss 0.16064529 - samples/sec: 60.21 - lr: 0.000030
2021-07-18 19:49:34,852 epoch 10 - iter 45/59 - loss 0.17176529 - samples/sec: 61.47 - lr: 0.000030
2021-07-18 19:49:37,483 epoch 10 - iter 50/59 - loss 0.16933608 - samples/sec: 60.82 - lr: 0.000030
2021-07-18 19:49:40,123 epoch 10 - iter 55/59 - loss 0.17109905 - samples/sec: 60.62 - lr: 0.000030
2021-07-18 19:49:42,136 ----------------------------------------------------------------------------------------------------
2021-07-18 19:49:42,137 EPOCH 10 done: loss 0.1741 - lr 0.0000300
2021-07-18 19:49:43,864 DEV : loss 0.06425400823354721 - score 0.9903
2021-07-18 19:49:43,888 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 19:49:47,725 ----------------------------------------------------------------------------------------------------
2021-07-18 19:49:50,378 epoch 11 - iter 5/59 - loss 0.20413346 - samples/sec: 60.33 - lr: 0.000030
2021-07-18 19:49:53,014 epoch 11 - iter 10/59 - loss 0.16524851 - samples/sec: 60.71 - lr: 0.000030
2021-07-18 19:49:55,656 epoch 11 - iter 15/59 - loss 0.16014487 - samples/sec: 60.60 - lr: 0.000030
2021-07-18 19:49:58,290 epoch 11 - iter 20/59 - loss 0.15591214 - samples/sec: 60.75 - lr: 0.000030
2021-07-18 19:50:00,926 epoch 11 - iter 25/59 - loss 0.15089262 - samples/sec: 60.70 - lr: 0.000030
2021-07-18 19:50:03,600 epoch 11 - iter 30/59 - loss 0.14776064 - samples/sec: 59.85 - lr: 0.000030
2021-07-18 19:50:06,248 epoch 11 - iter 35/59 - loss 0.15310072 - samples/sec: 60.45 - lr: 0.000030
2021-07-18 19:50:08,898 epoch 11 - iter 40/59 - loss 0.15383499 - samples/sec: 60.39 - lr: 0.000030
2021-07-18 19:50:11,575 epoch 11 - iter 45/59 - loss 0.15628409 - samples/sec: 59.78 - lr: 0.000030
2021-07-18 19:50:14,182 epoch 11 - iter 50/59 - loss 0.15172114 - samples/sec: 61.39 - lr: 0.000030
2021-07-18 19:50:16,793 epoch 11 - iter 55/59 - loss 0.15476176 - samples/sec: 61.30 - lr: 0.000030
2021-07-18 19:50:18,829 ----------------------------------------------------------------------------------------------------
2021-07-18 19:50:18,829 EPOCH 11 done: loss 0.1540 - lr 0.0000300
2021-07-18 19:50:20,558 DEV : loss 0.06064049154520035 - score 0.9883
2021-07-18 19:50:20,582 BAD EPOCHS (no improvement): 1
2021-07-18 19:50:20,582 ----------------------------------------------------------------------------------------------------
2021-07-18 19:50:23,219 epoch 12 - iter 5/59 - loss 0.13444955 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 19:50:25,831 epoch 12 - iter 10/59 - loss 0.12152482 - samples/sec: 61.28 - lr: 0.000030
2021-07-18 19:50:28,469 epoch 12 - iter 15/59 - loss 0.11273556 - samples/sec: 60.65 - lr: 0.000030
2021-07-18 19:50:31,067 epoch 12 - iter 20/59 - loss 0.13340075 - samples/sec: 61.60 - lr: 0.000030
2021-07-18 19:50:33,711 epoch 12 - iter 25/59 - loss 0.12619566 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:50:36,363 epoch 12 - iter 30/59 - loss 0.12837663 - samples/sec: 60.34 - lr: 0.000030
2021-07-18 19:50:39,011 epoch 12 - iter 35/59 - loss 0.12636494 - samples/sec: 60.44 - lr: 0.000030
2021-07-18 19:50:41,678 epoch 12 - iter 40/59 - loss 0.13447919 - samples/sec: 60.01 - lr: 0.000030
2021-07-18 19:50:44,303 epoch 12 - iter 45/59 - loss 0.13971307 - samples/sec: 60.98 - lr: 0.000030
2021-07-18 19:50:46,952 epoch 12 - iter 50/59 - loss 0.13867703 - samples/sec: 60.41 - lr: 0.000030
2021-07-18 19:50:49,580 epoch 12 - iter 55/59 - loss 0.13422691 - samples/sec: 60.88 - lr: 0.000030
2021-07-18 19:50:51,589 ----------------------------------------------------------------------------------------------------
2021-07-18 19:50:51,589 EPOCH 12 done: loss 0.1327 - lr 0.0000300
2021-07-18 19:50:53,509 DEV : loss 0.062040895223617554 - score 0.9883
2021-07-18 19:50:53,533 BAD EPOCHS (no improvement): 2
2021-07-18 19:50:53,533 ----------------------------------------------------------------------------------------------------
2021-07-18 19:50:56,175 epoch 13 - iter 5/59 - loss 0.10091299 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 19:50:58,810 epoch 13 - iter 10/59 - loss 0.14062430 - samples/sec: 60.73 - lr: 0.000030
2021-07-18 19:51:01,482 epoch 13 - iter 15/59 - loss 0.12370076 - samples/sec: 59.90 - lr: 0.000030
2021-07-18 19:51:04,159 epoch 13 - iter 20/59 - loss 0.12827713 - samples/sec: 59.78 - lr: 0.000030
2021-07-18 19:51:06,792 epoch 13 - iter 25/59 - loss 0.12119918 - samples/sec: 60.79 - lr: 0.000030
2021-07-18 19:51:09,415 epoch 13 - iter 30/59 - loss 0.11770345 - samples/sec: 61.02 - lr: 0.000030
2021-07-18 19:51:12,012 epoch 13 - iter 35/59 - loss 0.11106172 - samples/sec: 61.62 - lr: 0.000030
2021-07-18 19:51:14,615 epoch 13 - iter 40/59 - loss 0.10884352 - samples/sec: 61.48 - lr: 0.000030
2021-07-18 19:51:17,275 epoch 13 - iter 45/59 - loss 0.11174311 - samples/sec: 60.16 - lr: 0.000030
2021-07-18 19:51:19,919 epoch 13 - iter 50/59 - loss 0.11220023 - samples/sec: 60.53 - lr: 0.000030
2021-07-18 19:51:22,571 epoch 13 - iter 55/59 - loss 0.11392555 - samples/sec: 60.35 - lr: 0.000030
2021-07-18 19:51:24,558 ----------------------------------------------------------------------------------------------------
2021-07-18 19:51:24,558 EPOCH 13 done: loss 0.1150 - lr 0.0000300
2021-07-18 19:51:26,290 DEV : loss 0.060568857938051224 - score 0.9883
2021-07-18 19:51:26,314 BAD EPOCHS (no improvement): 3
2021-07-18 19:51:26,314 ----------------------------------------------------------------------------------------------------
2021-07-18 19:51:28,927 epoch 14 - iter 5/59 - loss 0.08231927 - samples/sec: 61.26 - lr: 0.000030
2021-07-18 19:51:31,568 epoch 14 - iter 10/59 - loss 0.07927990 - samples/sec: 60.61 - lr: 0.000030
2021-07-18 19:51:34,211 epoch 14 - iter 15/59 - loss 0.08865578 - samples/sec: 60.55 - lr: 0.000030
2021-07-18 19:51:36,866 epoch 14 - iter 20/59 - loss 0.09476203 - samples/sec: 60.28 - lr: 0.000030
2021-07-18 19:51:39,526 epoch 14 - iter 25/59 - loss 0.08989104 - samples/sec: 60.16 - lr: 0.000030
2021-07-18 19:51:42,180 epoch 14 - iter 30/59 - loss 0.09836866 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 19:51:44,818 epoch 14 - iter 35/59 - loss 0.09753645 - samples/sec: 60.65 - lr: 0.000030
2021-07-18 19:51:47,462 epoch 14 - iter 40/59 - loss 0.09963349 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 19:51:50,107 epoch 14 - iter 45/59 - loss 0.09756133 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 19:51:52,735 epoch 14 - iter 50/59 - loss 0.09864302 - samples/sec: 60.90 - lr: 0.000030
2021-07-18 19:51:55,386 epoch 14 - iter 55/59 - loss 0.10342836 - samples/sec: 60.36 - lr: 0.000030
2021-07-18 19:51:57,381 ----------------------------------------------------------------------------------------------------
2021-07-18 19:51:57,381 EPOCH 14 done: loss 0.1075 - lr 0.0000300
2021-07-18 19:51:59,106 DEV : loss 0.057463791221380234 - score 0.9883
Epoch    14: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 19:51:59,130 BAD EPOCHS (no improvement): 4
2021-07-18 19:51:59,131 ----------------------------------------------------------------------------------------------------
2021-07-18 19:52:01,763 epoch 15 - iter 5/59 - loss 0.11713781 - samples/sec: 60.80 - lr: 0.000015
2021-07-18 19:52:04,399 epoch 15 - iter 10/59 - loss 0.12648475 - samples/sec: 60.72 - lr: 0.000015
2021-07-18 19:52:07,050 epoch 15 - iter 15/59 - loss 0.10631137 - samples/sec: 60.36 - lr: 0.000015
2021-07-18 19:52:09,662 epoch 15 - iter 20/59 - loss 0.10183516 - samples/sec: 61.29 - lr: 0.000015
2021-07-18 19:52:12,280 epoch 15 - iter 25/59 - loss 0.10845722 - samples/sec: 61.12 - lr: 0.000015
2021-07-18 19:52:14,943 epoch 15 - iter 30/59 - loss 0.11225076 - samples/sec: 60.10 - lr: 0.000015
2021-07-18 19:52:17,618 epoch 15 - iter 35/59 - loss 0.10792227 - samples/sec: 59.83 - lr: 0.000015
2021-07-18 19:52:20,264 epoch 15 - iter 40/59 - loss 0.10467557 - samples/sec: 60.49 - lr: 0.000015
2021-07-18 19:52:22,848 epoch 15 - iter 45/59 - loss 0.10492676 - samples/sec: 61.92 - lr: 0.000015
2021-07-18 19:52:25,515 epoch 15 - iter 50/59 - loss 0.09981835 - samples/sec: 60.01 - lr: 0.000015
2021-07-18 19:52:28,160 epoch 15 - iter 55/59 - loss 0.10627904 - samples/sec: 60.52 - lr: 0.000015
2021-07-18 19:52:30,156 ----------------------------------------------------------------------------------------------------
2021-07-18 19:52:30,156 EPOCH 15 done: loss 0.1063 - lr 0.0000150
2021-07-18 19:52:31,891 DEV : loss 0.05788296461105347 - score 0.9883
2021-07-18 19:52:31,914 BAD EPOCHS (no improvement): 1
2021-07-18 19:52:31,914 ----------------------------------------------------------------------------------------------------
2021-07-18 19:52:34,572 epoch 16 - iter 5/59 - loss 0.12341108 - samples/sec: 60.22 - lr: 0.000015
2021-07-18 19:52:37,221 epoch 16 - iter 10/59 - loss 0.10169336 - samples/sec: 60.42 - lr: 0.000015
2021-07-18 19:52:39,840 epoch 16 - iter 15/59 - loss 0.10495593 - samples/sec: 61.10 - lr: 0.000015
2021-07-18 19:52:42,466 epoch 16 - iter 20/59 - loss 0.10694983 - samples/sec: 60.94 - lr: 0.000015
2021-07-18 19:52:45,110 epoch 16 - iter 25/59 - loss 0.09909709 - samples/sec: 60.52 - lr: 0.000015
2021-07-18 19:52:47,750 epoch 16 - iter 30/59 - loss 0.10955869 - samples/sec: 60.64 - lr: 0.000015
2021-07-18 19:52:50,383 epoch 16 - iter 35/59 - loss 0.10750217 - samples/sec: 60.78 - lr: 0.000015
2021-07-18 19:52:53,015 epoch 16 - iter 40/59 - loss 0.11057131 - samples/sec: 60.79 - lr: 0.000015
2021-07-18 19:52:55,675 epoch 16 - iter 45/59 - loss 0.11003345 - samples/sec: 60.18 - lr: 0.000015
2021-07-18 19:52:58,322 epoch 16 - iter 50/59 - loss 0.10701819 - samples/sec: 60.44 - lr: 0.000015
2021-07-18 19:53:00,972 epoch 16 - iter 55/59 - loss 0.10595061 - samples/sec: 60.41 - lr: 0.000015
2021-07-18 19:53:02,952 ----------------------------------------------------------------------------------------------------
2021-07-18 19:53:02,953 EPOCH 16 done: loss 0.1026 - lr 0.0000150
2021-07-18 19:53:04,683 DEV : loss 0.059996601194143295 - score 0.9883
2021-07-18 19:53:04,707 BAD EPOCHS (no improvement): 2
2021-07-18 19:53:04,707 ----------------------------------------------------------------------------------------------------
2021-07-18 19:53:07,540 epoch 17 - iter 5/59 - loss 0.08055318 - samples/sec: 56.49 - lr: 0.000015
2021-07-18 19:53:10,171 epoch 17 - iter 10/59 - loss 0.07772678 - samples/sec: 60.83 - lr: 0.000015
2021-07-18 19:53:12,843 epoch 17 - iter 15/59 - loss 0.08856596 - samples/sec: 59.88 - lr: 0.000015
2021-07-18 19:53:15,496 epoch 17 - iter 20/59 - loss 0.10359335 - samples/sec: 60.33 - lr: 0.000015
2021-07-18 19:53:18,159 epoch 17 - iter 25/59 - loss 0.09867514 - samples/sec: 60.10 - lr: 0.000015
2021-07-18 19:53:20,794 epoch 17 - iter 30/59 - loss 0.09221357 - samples/sec: 60.73 - lr: 0.000015
2021-07-18 19:53:23,446 epoch 17 - iter 35/59 - loss 0.08705442 - samples/sec: 60.34 - lr: 0.000015
2021-07-18 19:53:26,080 epoch 17 - iter 40/59 - loss 0.08560426 - samples/sec: 60.78 - lr: 0.000015
2021-07-18 19:53:28,715 epoch 17 - iter 45/59 - loss 0.09654162 - samples/sec: 60.72 - lr: 0.000015
2021-07-18 19:53:31,352 epoch 17 - iter 50/59 - loss 0.09912904 - samples/sec: 60.70 - lr: 0.000015
2021-07-18 19:53:33,971 epoch 17 - iter 55/59 - loss 0.10140761 - samples/sec: 61.11 - lr: 0.000015
2021-07-18 19:53:35,969 ----------------------------------------------------------------------------------------------------
2021-07-18 19:53:35,969 EPOCH 17 done: loss 0.1045 - lr 0.0000150
2021-07-18 19:53:37,694 DEV : loss 0.06017153337597847 - score 0.9883
2021-07-18 19:53:37,718 BAD EPOCHS (no improvement): 3
2021-07-18 19:53:37,718 ----------------------------------------------------------------------------------------------------
2021-07-18 19:53:40,335 epoch 18 - iter 5/59 - loss 0.10985342 - samples/sec: 61.15 - lr: 0.000015
2021-07-18 19:53:42,939 epoch 18 - iter 10/59 - loss 0.11859749 - samples/sec: 61.47 - lr: 0.000015
2021-07-18 19:53:45,563 epoch 18 - iter 15/59 - loss 0.10008981 - samples/sec: 60.98 - lr: 0.000015
2021-07-18 19:53:48,186 epoch 18 - iter 20/59 - loss 0.09144162 - samples/sec: 61.03 - lr: 0.000015
2021-07-18 19:53:50,781 epoch 18 - iter 25/59 - loss 0.10515267 - samples/sec: 61.66 - lr: 0.000015
2021-07-18 19:53:53,385 epoch 18 - iter 30/59 - loss 0.10504324 - samples/sec: 61.47 - lr: 0.000015
2021-07-18 19:53:56,008 epoch 18 - iter 35/59 - loss 0.10180952 - samples/sec: 61.00 - lr: 0.000015
2021-07-18 19:53:58,647 epoch 18 - iter 40/59 - loss 0.10182346 - samples/sec: 60.65 - lr: 0.000015
2021-07-18 19:54:01,299 epoch 18 - iter 45/59 - loss 0.10061367 - samples/sec: 60.35 - lr: 0.000015
2021-07-18 19:54:03,935 epoch 18 - iter 50/59 - loss 0.10054966 - samples/sec: 60.72 - lr: 0.000015
2021-07-18 19:54:06,573 epoch 18 - iter 55/59 - loss 0.10199095 - samples/sec: 60.67 - lr: 0.000015
2021-07-18 19:54:08,566 ----------------------------------------------------------------------------------------------------
2021-07-18 19:54:08,566 EPOCH 18 done: loss 0.0989 - lr 0.0000150
2021-07-18 19:54:10,291 DEV : loss 0.061027973890304565 - score 0.9883
Epoch    18: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 19:54:10,315 BAD EPOCHS (no improvement): 4
2021-07-18 19:54:10,315 ----------------------------------------------------------------------------------------------------
2021-07-18 19:54:12,916 epoch 19 - iter 5/59 - loss 0.09754934 - samples/sec: 61.52 - lr: 0.000008
2021-07-18 19:54:15,523 epoch 19 - iter 10/59 - loss 0.12518285 - samples/sec: 61.39 - lr: 0.000008
2021-07-18 19:54:18,172 epoch 19 - iter 15/59 - loss 0.10646521 - samples/sec: 60.42 - lr: 0.000008
2021-07-18 19:54:20,783 epoch 19 - iter 20/59 - loss 0.10800134 - samples/sec: 61.28 - lr: 0.000008
2021-07-18 19:54:23,423 epoch 19 - iter 25/59 - loss 0.10994852 - samples/sec: 60.62 - lr: 0.000008
2021-07-18 19:54:26,039 epoch 19 - iter 30/59 - loss 0.09955207 - samples/sec: 61.19 - lr: 0.000008
2021-07-18 19:54:28,652 epoch 19 - iter 35/59 - loss 0.09684882 - samples/sec: 61.26 - lr: 0.000008
2021-07-18 19:54:31,259 epoch 19 - iter 40/59 - loss 0.09616544 - samples/sec: 61.38 - lr: 0.000008
2021-07-18 19:54:33,862 epoch 19 - iter 45/59 - loss 0.09688771 - samples/sec: 61.48 - lr: 0.000008
2021-07-18 19:54:36,462 epoch 19 - iter 50/59 - loss 0.09630131 - samples/sec: 61.55 - lr: 0.000008
2021-07-18 19:54:39,107 epoch 19 - iter 55/59 - loss 0.09518878 - samples/sec: 60.50 - lr: 0.000008
2021-07-18 19:54:41,097 ----------------------------------------------------------------------------------------------------
2021-07-18 19:54:41,097 EPOCH 19 done: loss 0.0966 - lr 0.0000075
2021-07-18 19:54:42,819 DEV : loss 0.05825147032737732 - score 0.9883
2021-07-18 19:54:42,842 BAD EPOCHS (no improvement): 1
2021-07-18 19:54:42,842 ----------------------------------------------------------------------------------------------------
2021-07-18 19:54:45,452 epoch 20 - iter 5/59 - loss 0.05605217 - samples/sec: 61.33 - lr: 0.000008
2021-07-18 19:54:48,089 epoch 20 - iter 10/59 - loss 0.06077986 - samples/sec: 60.67 - lr: 0.000008
2021-07-18 19:54:50,730 epoch 20 - iter 15/59 - loss 0.06339091 - samples/sec: 60.60 - lr: 0.000008
2021-07-18 19:54:53,338 epoch 20 - iter 20/59 - loss 0.07967583 - samples/sec: 61.36 - lr: 0.000008
2021-07-18 19:54:55,982 epoch 20 - iter 25/59 - loss 0.07599108 - samples/sec: 60.53 - lr: 0.000008
2021-07-18 19:54:58,601 epoch 20 - iter 30/59 - loss 0.08350205 - samples/sec: 61.10 - lr: 0.000008
2021-07-18 19:55:01,256 epoch 20 - iter 35/59 - loss 0.07842255 - samples/sec: 60.29 - lr: 0.000008
2021-07-18 19:55:03,883 epoch 20 - iter 40/59 - loss 0.07280365 - samples/sec: 60.92 - lr: 0.000008
2021-07-18 19:55:06,507 epoch 20 - iter 45/59 - loss 0.07519762 - samples/sec: 60.98 - lr: 0.000008
2021-07-18 19:55:09,082 epoch 20 - iter 50/59 - loss 0.07826447 - samples/sec: 62.16 - lr: 0.000008
2021-07-18 19:55:11,727 epoch 20 - iter 55/59 - loss 0.08008175 - samples/sec: 60.50 - lr: 0.000008
2021-07-18 19:55:13,716 ----------------------------------------------------------------------------------------------------
2021-07-18 19:55:13,717 EPOCH 20 done: loss 0.0820 - lr 0.0000075
2021-07-18 19:55:15,633 DEV : loss 0.05688803270459175 - score 0.9883
2021-07-18 19:55:15,657 BAD EPOCHS (no improvement): 2
2021-07-18 19:55:15,657 ----------------------------------------------------------------------------------------------------
2021-07-18 19:55:18,243 epoch 21 - iter 5/59 - loss 0.09353613 - samples/sec: 61.90 - lr: 0.000008
2021-07-18 19:55:20,887 epoch 21 - iter 10/59 - loss 0.09054748 - samples/sec: 60.52 - lr: 0.000008
2021-07-18 19:55:23,483 epoch 21 - iter 15/59 - loss 0.08733490 - samples/sec: 61.66 - lr: 0.000008
2021-07-18 19:55:26,083 epoch 21 - iter 20/59 - loss 0.07747206 - samples/sec: 61.56 - lr: 0.000008
2021-07-18 19:55:28,695 epoch 21 - iter 25/59 - loss 0.07627069 - samples/sec: 61.26 - lr: 0.000008
2021-07-18 19:55:31,347 epoch 21 - iter 30/59 - loss 0.07544428 - samples/sec: 60.35 - lr: 0.000008
2021-07-18 19:55:33,962 epoch 21 - iter 35/59 - loss 0.07762810 - samples/sec: 61.21 - lr: 0.000008
2021-07-18 19:55:36,596 epoch 21 - iter 40/59 - loss 0.08105980 - samples/sec: 60.76 - lr: 0.000008
2021-07-18 19:55:39,214 epoch 21 - iter 45/59 - loss 0.08133931 - samples/sec: 61.11 - lr: 0.000008
2021-07-18 19:55:41,844 epoch 21 - iter 50/59 - loss 0.08281908 - samples/sec: 60.87 - lr: 0.000008
2021-07-18 19:55:44,494 epoch 21 - iter 55/59 - loss 0.08296312 - samples/sec: 60.38 - lr: 0.000008
2021-07-18 19:55:46,495 ----------------------------------------------------------------------------------------------------
2021-07-18 19:55:46,495 EPOCH 21 done: loss 0.0830 - lr 0.0000075
2021-07-18 19:55:48,220 DEV : loss 0.057868462055921555 - score 0.9883
2021-07-18 19:55:48,244 BAD EPOCHS (no improvement): 3
2021-07-18 19:55:48,245 ----------------------------------------------------------------------------------------------------
2021-07-18 19:55:50,880 epoch 22 - iter 5/59 - loss 0.05504552 - samples/sec: 60.73 - lr: 0.000008
2021-07-18 19:55:53,487 epoch 22 - iter 10/59 - loss 0.07374543 - samples/sec: 61.37 - lr: 0.000008
2021-07-18 19:55:56,133 epoch 22 - iter 15/59 - loss 0.07748806 - samples/sec: 60.48 - lr: 0.000008
2021-07-18 19:55:58,784 epoch 22 - iter 20/59 - loss 0.07207664 - samples/sec: 60.38 - lr: 0.000008
2021-07-18 19:56:01,383 epoch 22 - iter 25/59 - loss 0.07062820 - samples/sec: 61.58 - lr: 0.000008
2021-07-18 19:56:04,012 epoch 22 - iter 30/59 - loss 0.07611125 - samples/sec: 60.88 - lr: 0.000008
2021-07-18 19:56:06,637 epoch 22 - iter 35/59 - loss 0.07599590 - samples/sec: 60.95 - lr: 0.000008
2021-07-18 19:56:09,262 epoch 22 - iter 40/59 - loss 0.07488068 - samples/sec: 60.99 - lr: 0.000008
2021-07-18 19:56:11,867 epoch 22 - iter 45/59 - loss 0.07661172 - samples/sec: 61.44 - lr: 0.000008
2021-07-18 19:56:14,472 epoch 22 - iter 50/59 - loss 0.07661064 - samples/sec: 61.41 - lr: 0.000008
2021-07-18 19:56:17,099 epoch 22 - iter 55/59 - loss 0.08217626 - samples/sec: 60.92 - lr: 0.000008
2021-07-18 19:56:19,078 ----------------------------------------------------------------------------------------------------
2021-07-18 19:56:19,078 EPOCH 22 done: loss 0.0808 - lr 0.0000075
2021-07-18 19:56:20,798 DEV : loss 0.05702465772628784 - score 0.9883
Epoch    22: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 19:56:20,822 BAD EPOCHS (no improvement): 4
2021-07-18 19:56:20,822 ----------------------------------------------------------------------------------------------------
2021-07-18 19:56:23,431 epoch 23 - iter 5/59 - loss 0.10840901 - samples/sec: 61.34 - lr: 0.000004
2021-07-18 19:56:26,064 epoch 23 - iter 10/59 - loss 0.11985477 - samples/sec: 60.80 - lr: 0.000004
2021-07-18 19:56:28,686 epoch 23 - iter 15/59 - loss 0.09895145 - samples/sec: 61.04 - lr: 0.000004
2021-07-18 19:56:31,283 epoch 23 - iter 20/59 - loss 0.09009169 - samples/sec: 61.62 - lr: 0.000004
2021-07-18 19:56:33,910 epoch 23 - iter 25/59 - loss 0.08538605 - samples/sec: 60.93 - lr: 0.000004
2021-07-18 19:56:36,546 epoch 23 - iter 30/59 - loss 0.08836049 - samples/sec: 60.70 - lr: 0.000004
2021-07-18 19:56:39,166 epoch 23 - iter 35/59 - loss 0.08421193 - samples/sec: 61.09 - lr: 0.000004
2021-07-18 19:56:41,800 epoch 23 - iter 40/59 - loss 0.08081989 - samples/sec: 60.75 - lr: 0.000004
2021-07-18 19:56:44,415 epoch 23 - iter 45/59 - loss 0.08405902 - samples/sec: 61.22 - lr: 0.000004
2021-07-18 19:56:47,037 epoch 23 - iter 50/59 - loss 0.08391515 - samples/sec: 61.03 - lr: 0.000004
2021-07-18 19:56:49,640 epoch 23 - iter 55/59 - loss 0.08295812 - samples/sec: 61.48 - lr: 0.000004
2021-07-18 19:56:51,636 ----------------------------------------------------------------------------------------------------
2021-07-18 19:56:51,636 EPOCH 23 done: loss 0.0863 - lr 0.0000038
2021-07-18 19:56:53,357 DEV : loss 0.05810285732150078 - score 0.9883
2021-07-18 19:56:53,381 BAD EPOCHS (no improvement): 1
2021-07-18 19:56:53,381 ----------------------------------------------------------------------------------------------------
2021-07-18 19:56:55,987 epoch 24 - iter 5/59 - loss 0.07801933 - samples/sec: 61.41 - lr: 0.000004
2021-07-18 19:56:58,623 epoch 24 - iter 10/59 - loss 0.07308838 - samples/sec: 60.70 - lr: 0.000004
2021-07-18 19:57:01,246 epoch 24 - iter 15/59 - loss 0.06198699 - samples/sec: 61.02 - lr: 0.000004
2021-07-18 19:57:03,876 epoch 24 - iter 20/59 - loss 0.06727262 - samples/sec: 60.87 - lr: 0.000004
2021-07-18 19:57:06,506 epoch 24 - iter 25/59 - loss 0.07409460 - samples/sec: 60.84 - lr: 0.000004
2021-07-18 19:57:09,114 epoch 24 - iter 30/59 - loss 0.07655296 - samples/sec: 61.37 - lr: 0.000004
2021-07-18 19:57:11,713 epoch 24 - iter 35/59 - loss 0.07411300 - samples/sec: 61.59 - lr: 0.000004
2021-07-18 19:57:14,351 epoch 24 - iter 40/59 - loss 0.07490758 - samples/sec: 60.67 - lr: 0.000004
2021-07-18 19:57:16,974 epoch 24 - iter 45/59 - loss 0.07583620 - samples/sec: 61.02 - lr: 0.000004
2021-07-18 19:57:19,606 epoch 24 - iter 50/59 - loss 0.08134820 - samples/sec: 60.79 - lr: 0.000004
2021-07-18 19:57:22,236 epoch 24 - iter 55/59 - loss 0.08481801 - samples/sec: 60.86 - lr: 0.000004
2021-07-18 19:57:24,228 ----------------------------------------------------------------------------------------------------
2021-07-18 19:57:24,228 EPOCH 24 done: loss 0.0885 - lr 0.0000038
2021-07-18 19:57:25,954 DEV : loss 0.058115389198064804 - score 0.9883
2021-07-18 19:57:25,978 BAD EPOCHS (no improvement): 2
2021-07-18 19:57:25,978 ----------------------------------------------------------------------------------------------------
2021-07-18 19:57:28,624 epoch 25 - iter 5/59 - loss 0.09041691 - samples/sec: 60.48 - lr: 0.000004
2021-07-18 19:57:31,250 epoch 25 - iter 10/59 - loss 0.07371922 - samples/sec: 60.94 - lr: 0.000004
2021-07-18 19:57:33,855 epoch 25 - iter 15/59 - loss 0.06953552 - samples/sec: 61.43 - lr: 0.000004
2021-07-18 19:57:36,483 epoch 25 - iter 20/59 - loss 0.07807915 - samples/sec: 60.90 - lr: 0.000004
2021-07-18 19:57:39,108 epoch 25 - iter 25/59 - loss 0.07460179 - samples/sec: 60.98 - lr: 0.000004
2021-07-18 19:57:41,742 epoch 25 - iter 30/59 - loss 0.08675096 - samples/sec: 60.75 - lr: 0.000004
2021-07-18 19:57:44,308 epoch 25 - iter 35/59 - loss 0.08578167 - samples/sec: 62.37 - lr: 0.000004
2021-07-18 19:57:46,946 epoch 25 - iter 40/59 - loss 0.08116423 - samples/sec: 60.66 - lr: 0.000004
2021-07-18 19:57:49,585 epoch 25 - iter 45/59 - loss 0.08070005 - samples/sec: 60.65 - lr: 0.000004
2021-07-18 19:57:52,154 epoch 25 - iter 50/59 - loss 0.08091228 - samples/sec: 62.30 - lr: 0.000004
2021-07-18 19:57:54,791 epoch 25 - iter 55/59 - loss 0.08784794 - samples/sec: 60.68 - lr: 0.000004
2021-07-18 19:57:56,754 ----------------------------------------------------------------------------------------------------
2021-07-18 19:57:56,754 EPOCH 25 done: loss 0.0847 - lr 0.0000038
2021-07-18 19:57:58,664 DEV : loss 0.057874687016010284 - score 0.9883
2021-07-18 19:57:58,688 BAD EPOCHS (no improvement): 3
2021-07-18 19:57:58,688 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:01,315 epoch 26 - iter 5/59 - loss 0.10152379 - samples/sec: 60.93 - lr: 0.000004
2021-07-18 19:58:03,962 epoch 26 - iter 10/59 - loss 0.07680628 - samples/sec: 60.46 - lr: 0.000004
2021-07-18 19:58:06,566 epoch 26 - iter 15/59 - loss 0.08300522 - samples/sec: 61.46 - lr: 0.000004
2021-07-18 19:58:09,211 epoch 26 - iter 20/59 - loss 0.07772998 - samples/sec: 60.52 - lr: 0.000004
2021-07-18 19:58:11,862 epoch 26 - iter 25/59 - loss 0.07111765 - samples/sec: 60.35 - lr: 0.000004
2021-07-18 19:58:14,468 epoch 26 - iter 30/59 - loss 0.07423323 - samples/sec: 61.43 - lr: 0.000004
2021-07-18 19:58:17,106 epoch 26 - iter 35/59 - loss 0.07179639 - samples/sec: 60.65 - lr: 0.000004
2021-07-18 19:58:19,730 epoch 26 - iter 40/59 - loss 0.06922549 - samples/sec: 61.00 - lr: 0.000004
2021-07-18 19:58:22,359 epoch 26 - iter 45/59 - loss 0.06811568 - samples/sec: 60.87 - lr: 0.000004
2021-07-18 19:58:24,995 epoch 26 - iter 50/59 - loss 0.07048849 - samples/sec: 60.71 - lr: 0.000004
2021-07-18 19:58:27,644 epoch 26 - iter 55/59 - loss 0.07424224 - samples/sec: 60.43 - lr: 0.000004
2021-07-18 19:58:29,632 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:29,632 EPOCH 26 done: loss 0.0738 - lr 0.0000038
2021-07-18 19:58:31,356 DEV : loss 0.0574319064617157 - score 0.9883
Epoch    26: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 19:58:31,380 BAD EPOCHS (no improvement): 4
2021-07-18 19:58:31,380 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:31,380 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:31,380 learning rate too small - quitting training!
2021-07-18 19:58:31,380 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:32,156 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:32,156 Testing using best model ...
2021-07-18 19:58:32,156 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/por.rst.cstn/best-model.pt
2021-07-18 19:58:40,824 0.9486	0.9887	0.9683
2021-07-18 19:58:40,825 
Results:
- F1-score (micro) 0.9683
- F1-score (macro) 0.9683

By class:
SENT       tp: 351 - fp: 19 - fn: 4 - precision: 0.9486 - recall: 0.9887 - f1-score: 0.9683
2021-07-18 19:58:40,825 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/fas.rst.prstc/
2021-07-18 19:58:40,838 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/fas.rst.prstc
2021-07-18 19:58:40,838 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/fas.rst.prstc/sent_train.txt
2021-07-18 19:58:40,840 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/fas.rst.prstc/sent_dev.txt
2021-07-18 19:58:40,842 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/fas.rst.prstc/sent_test.txt
Corpus: 2078 train + 341 dev + 472 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 19:58:45,770 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:45,772 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(100000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 19:58:45,772 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:45,772 Corpus: "Corpus: 2078 train + 341 dev + 472 test sentences"
2021-07-18 19:58:45,772 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:45,772 Parameters:
2021-07-18 19:58:45,772  - learning_rate: "3e-05"
2021-07-18 19:58:45,772  - mini_batch_size: "32"
2021-07-18 19:58:45,772  - patience: "3"
2021-07-18 19:58:45,772  - anneal_factor: "0.5"
2021-07-18 19:58:45,772  - max_epochs: "40"
2021-07-18 19:58:45,772  - shuffle: "True"
2021-07-18 19:58:45,772  - train_with_dev: "False"
2021-07-18 19:58:45,772  - batch_growth_annealing: "False"
2021-07-18 19:58:45,772 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:45,772 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/fas.rst.prstc"
2021-07-18 19:58:45,772 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:45,772 Device: cuda:0
2021-07-18 19:58:45,772 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:45,772 Embeddings storage mode: cpu
2021-07-18 19:58:45,775 ----------------------------------------------------------------------------------------------------
2021-07-18 19:58:52,706 epoch 1 - iter 6/65 - loss 20.17411296 - samples/sec: 27.70 - lr: 0.000030
2021-07-18 19:58:58,860 epoch 1 - iter 12/65 - loss 14.80764194 - samples/sec: 31.20 - lr: 0.000030
2021-07-18 19:59:05,175 epoch 1 - iter 18/65 - loss 11.67260257 - samples/sec: 30.41 - lr: 0.000030
2021-07-18 19:59:11,276 epoch 1 - iter 24/65 - loss 9.71155902 - samples/sec: 31.47 - lr: 0.000030
2021-07-18 19:59:17,368 epoch 1 - iter 30/65 - loss 8.44300748 - samples/sec: 31.52 - lr: 0.000030
2021-07-18 19:59:23,490 epoch 1 - iter 36/65 - loss 7.55404523 - samples/sec: 31.36 - lr: 0.000030
2021-07-18 19:59:29,642 epoch 1 - iter 42/65 - loss 6.89083395 - samples/sec: 31.21 - lr: 0.000030
2021-07-18 19:59:35,748 epoch 1 - iter 48/65 - loss 6.34970106 - samples/sec: 31.45 - lr: 0.000030
2021-07-18 19:59:41,845 epoch 1 - iter 54/65 - loss 5.90071552 - samples/sec: 31.49 - lr: 0.000030
2021-07-18 19:59:47,934 epoch 1 - iter 60/65 - loss 5.50931503 - samples/sec: 31.53 - lr: 0.000030
2021-07-18 19:59:53,017 ----------------------------------------------------------------------------------------------------
2021-07-18 19:59:53,018 EPOCH 1 done: loss 5.2506 - lr 0.0000300
2021-07-18 19:59:59,414 DEV : loss 1.4038572311401367 - score 0.1551
2021-07-18 19:59:59,439 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:00:00,727 ----------------------------------------------------------------------------------------------------
2021-07-18 20:00:03,784 epoch 2 - iter 6/65 - loss 1.92986870 - samples/sec: 62.82 - lr: 0.000030
2021-07-18 20:00:06,819 epoch 2 - iter 12/65 - loss 1.79537719 - samples/sec: 63.28 - lr: 0.000030
2021-07-18 20:00:09,907 epoch 2 - iter 18/65 - loss 1.76229183 - samples/sec: 62.19 - lr: 0.000030
2021-07-18 20:00:13,036 epoch 2 - iter 24/65 - loss 1.66765071 - samples/sec: 61.38 - lr: 0.000030
2021-07-18 20:00:16,136 epoch 2 - iter 30/65 - loss 1.60924479 - samples/sec: 61.96 - lr: 0.000030
2021-07-18 20:00:19,206 epoch 2 - iter 36/65 - loss 1.54815338 - samples/sec: 62.54 - lr: 0.000030
2021-07-18 20:00:22,251 epoch 2 - iter 42/65 - loss 1.49502848 - samples/sec: 63.08 - lr: 0.000030
2021-07-18 20:00:25,331 epoch 2 - iter 48/65 - loss 1.44210441 - samples/sec: 62.34 - lr: 0.000030
2021-07-18 20:00:28,395 epoch 2 - iter 54/65 - loss 1.39917947 - samples/sec: 62.69 - lr: 0.000030
2021-07-18 20:00:31,496 epoch 2 - iter 60/65 - loss 1.36670453 - samples/sec: 61.92 - lr: 0.000030
2021-07-18 20:00:34,038 ----------------------------------------------------------------------------------------------------
2021-07-18 20:00:34,038 EPOCH 2 done: loss 1.3418 - lr 0.0000300
2021-07-18 20:00:35,858 DEV : loss 0.6131609678268433 - score 0.8338
2021-07-18 20:00:35,884 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:00:41,680 ----------------------------------------------------------------------------------------------------
2021-07-18 20:00:44,749 epoch 3 - iter 6/65 - loss 0.86469100 - samples/sec: 62.59 - lr: 0.000030
2021-07-18 20:00:47,820 epoch 3 - iter 12/65 - loss 0.93250088 - samples/sec: 62.53 - lr: 0.000030
2021-07-18 20:00:50,891 epoch 3 - iter 18/65 - loss 0.91208064 - samples/sec: 62.54 - lr: 0.000030
2021-07-18 20:00:53,948 epoch 3 - iter 24/65 - loss 0.90480897 - samples/sec: 62.81 - lr: 0.000030
2021-07-18 20:00:56,963 epoch 3 - iter 30/65 - loss 0.87873611 - samples/sec: 63.69 - lr: 0.000030
2021-07-18 20:01:00,046 epoch 3 - iter 36/65 - loss 0.87410712 - samples/sec: 62.28 - lr: 0.000030
2021-07-18 20:01:03,095 epoch 3 - iter 42/65 - loss 0.85166154 - samples/sec: 63.00 - lr: 0.000030
2021-07-18 20:01:06,135 epoch 3 - iter 48/65 - loss 0.85465280 - samples/sec: 63.16 - lr: 0.000030
2021-07-18 20:01:09,202 epoch 3 - iter 54/65 - loss 0.85403451 - samples/sec: 62.61 - lr: 0.000030
2021-07-18 20:01:12,247 epoch 3 - iter 60/65 - loss 0.83477317 - samples/sec: 63.06 - lr: 0.000030
2021-07-18 20:01:14,771 ----------------------------------------------------------------------------------------------------
2021-07-18 20:01:14,772 EPOCH 3 done: loss 0.8273 - lr 0.0000300
2021-07-18 20:01:16,579 DEV : loss 0.3790322244167328 - score 0.9073
2021-07-18 20:01:16,605 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:01:22,560 ----------------------------------------------------------------------------------------------------
2021-07-18 20:01:25,620 epoch 4 - iter 6/65 - loss 0.61654947 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 20:01:28,663 epoch 4 - iter 12/65 - loss 0.60766230 - samples/sec: 63.11 - lr: 0.000030
2021-07-18 20:01:31,726 epoch 4 - iter 18/65 - loss 0.62031080 - samples/sec: 62.70 - lr: 0.000030
2021-07-18 20:01:34,752 epoch 4 - iter 24/65 - loss 0.63126803 - samples/sec: 63.48 - lr: 0.000030
2021-07-18 20:01:37,839 epoch 4 - iter 30/65 - loss 0.65300138 - samples/sec: 62.20 - lr: 0.000030
2021-07-18 20:01:40,930 epoch 4 - iter 36/65 - loss 0.65963596 - samples/sec: 62.12 - lr: 0.000030
2021-07-18 20:01:43,999 epoch 4 - iter 42/65 - loss 0.66297770 - samples/sec: 62.59 - lr: 0.000030
2021-07-18 20:01:47,115 epoch 4 - iter 48/65 - loss 0.66847852 - samples/sec: 61.62 - lr: 0.000030
2021-07-18 20:01:50,140 epoch 4 - iter 54/65 - loss 0.64519920 - samples/sec: 63.48 - lr: 0.000030
2021-07-18 20:01:53,208 epoch 4 - iter 60/65 - loss 0.63838234 - samples/sec: 62.61 - lr: 0.000030
2021-07-18 20:01:55,716 ----------------------------------------------------------------------------------------------------
2021-07-18 20:01:55,717 EPOCH 4 done: loss 0.6273 - lr 0.0000300
2021-07-18 20:01:57,524 DEV : loss 0.30065304040908813 - score 0.9235
2021-07-18 20:01:57,549 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:02:03,284 ----------------------------------------------------------------------------------------------------
2021-07-18 20:02:06,372 epoch 5 - iter 6/65 - loss 0.53954035 - samples/sec: 62.19 - lr: 0.000030
2021-07-18 20:02:09,438 epoch 5 - iter 12/65 - loss 0.57910570 - samples/sec: 62.63 - lr: 0.000030
2021-07-18 20:02:12,495 epoch 5 - iter 18/65 - loss 0.51783534 - samples/sec: 62.83 - lr: 0.000030
2021-07-18 20:02:15,574 epoch 5 - iter 24/65 - loss 0.52205478 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 20:02:18,663 epoch 5 - iter 30/65 - loss 0.51967659 - samples/sec: 62.15 - lr: 0.000030
2021-07-18 20:02:21,754 epoch 5 - iter 36/65 - loss 0.51810858 - samples/sec: 62.13 - lr: 0.000030
2021-07-18 20:02:25,035 epoch 5 - iter 42/65 - loss 0.51982662 - samples/sec: 58.55 - lr: 0.000030
2021-07-18 20:02:28,067 epoch 5 - iter 48/65 - loss 0.51486097 - samples/sec: 63.33 - lr: 0.000030
2021-07-18 20:02:31,135 epoch 5 - iter 54/65 - loss 0.50617784 - samples/sec: 62.58 - lr: 0.000030
2021-07-18 20:02:34,231 epoch 5 - iter 60/65 - loss 0.50889378 - samples/sec: 62.05 - lr: 0.000030
2021-07-18 20:02:36,734 ----------------------------------------------------------------------------------------------------
2021-07-18 20:02:36,735 EPOCH 5 done: loss 0.5076 - lr 0.0000300
2021-07-18 20:02:38,543 DEV : loss 0.27195030450820923 - score 0.9227
2021-07-18 20:02:38,568 BAD EPOCHS (no improvement): 1
2021-07-18 20:02:38,569 ----------------------------------------------------------------------------------------------------
2021-07-18 20:02:41,648 epoch 6 - iter 6/65 - loss 0.47506292 - samples/sec: 62.37 - lr: 0.000030
2021-07-18 20:02:44,698 epoch 6 - iter 12/65 - loss 0.46552334 - samples/sec: 62.97 - lr: 0.000030
2021-07-18 20:02:47,787 epoch 6 - iter 18/65 - loss 0.47070296 - samples/sec: 62.17 - lr: 0.000030
2021-07-18 20:02:50,867 epoch 6 - iter 24/65 - loss 0.48549986 - samples/sec: 62.34 - lr: 0.000030
2021-07-18 20:02:53,940 epoch 6 - iter 30/65 - loss 0.48619480 - samples/sec: 62.50 - lr: 0.000030
2021-07-18 20:02:57,019 epoch 6 - iter 36/65 - loss 0.45969516 - samples/sec: 62.36 - lr: 0.000030
2021-07-18 20:03:00,081 epoch 6 - iter 42/65 - loss 0.46306710 - samples/sec: 62.73 - lr: 0.000030
2021-07-18 20:03:03,198 epoch 6 - iter 48/65 - loss 0.46393256 - samples/sec: 61.61 - lr: 0.000030
2021-07-18 20:03:06,246 epoch 6 - iter 54/65 - loss 0.45135498 - samples/sec: 63.01 - lr: 0.000030
2021-07-18 20:03:09,272 epoch 6 - iter 60/65 - loss 0.43851729 - samples/sec: 63.46 - lr: 0.000030
2021-07-18 20:03:11,819 ----------------------------------------------------------------------------------------------------
2021-07-18 20:03:11,819 EPOCH 6 done: loss 0.4335 - lr 0.0000300
2021-07-18 20:03:13,628 DEV : loss 0.22088049352169037 - score 0.9287
2021-07-18 20:03:13,653 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:03:19,350 ----------------------------------------------------------------------------------------------------
2021-07-18 20:03:22,410 epoch 7 - iter 6/65 - loss 0.38593304 - samples/sec: 62.77 - lr: 0.000030
2021-07-18 20:03:25,492 epoch 7 - iter 12/65 - loss 0.42353396 - samples/sec: 62.31 - lr: 0.000030
2021-07-18 20:03:28,583 epoch 7 - iter 18/65 - loss 0.41426294 - samples/sec: 62.13 - lr: 0.000030
2021-07-18 20:03:31,658 epoch 7 - iter 24/65 - loss 0.40974829 - samples/sec: 62.45 - lr: 0.000030
2021-07-18 20:03:34,743 epoch 7 - iter 30/65 - loss 0.39197955 - samples/sec: 62.25 - lr: 0.000030
2021-07-18 20:03:37,844 epoch 7 - iter 36/65 - loss 0.38150615 - samples/sec: 61.94 - lr: 0.000030
2021-07-18 20:03:40,911 epoch 7 - iter 42/65 - loss 0.38104355 - samples/sec: 62.62 - lr: 0.000030
2021-07-18 20:03:43,968 epoch 7 - iter 48/65 - loss 0.38430267 - samples/sec: 62.80 - lr: 0.000030
2021-07-18 20:03:47,023 epoch 7 - iter 54/65 - loss 0.37921310 - samples/sec: 62.87 - lr: 0.000030
2021-07-18 20:03:50,102 epoch 7 - iter 60/65 - loss 0.37928541 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 20:03:52,635 ----------------------------------------------------------------------------------------------------
2021-07-18 20:03:52,636 EPOCH 7 done: loss 0.3754 - lr 0.0000300
2021-07-18 20:03:54,443 DEV : loss 0.20032210648059845 - score 0.9353
2021-07-18 20:03:54,469 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:04:00,190 ----------------------------------------------------------------------------------------------------
2021-07-18 20:04:03,266 epoch 8 - iter 6/65 - loss 0.38114095 - samples/sec: 62.43 - lr: 0.000030
2021-07-18 20:04:06,352 epoch 8 - iter 12/65 - loss 0.35342838 - samples/sec: 62.24 - lr: 0.000030
2021-07-18 20:04:09,423 epoch 8 - iter 18/65 - loss 0.35878160 - samples/sec: 62.53 - lr: 0.000030
2021-07-18 20:04:12,493 epoch 8 - iter 24/65 - loss 0.35845220 - samples/sec: 62.55 - lr: 0.000030
2021-07-18 20:04:15,564 epoch 8 - iter 30/65 - loss 0.36906601 - samples/sec: 62.54 - lr: 0.000030
2021-07-18 20:04:18,624 epoch 8 - iter 36/65 - loss 0.36817883 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 20:04:21,696 epoch 8 - iter 42/65 - loss 0.36602980 - samples/sec: 62.52 - lr: 0.000030
2021-07-18 20:04:24,762 epoch 8 - iter 48/65 - loss 0.36157688 - samples/sec: 62.62 - lr: 0.000030
2021-07-18 20:04:27,824 epoch 8 - iter 54/65 - loss 0.36005943 - samples/sec: 62.73 - lr: 0.000030
2021-07-18 20:04:30,907 epoch 8 - iter 60/65 - loss 0.35458407 - samples/sec: 62.30 - lr: 0.000030
2021-07-18 20:04:33,439 ----------------------------------------------------------------------------------------------------
2021-07-18 20:04:33,440 EPOCH 8 done: loss 0.3474 - lr 0.0000300
2021-07-18 20:04:35,255 DEV : loss 0.22555997967720032 - score 0.9187
2021-07-18 20:04:35,280 BAD EPOCHS (no improvement): 1
2021-07-18 20:04:35,280 ----------------------------------------------------------------------------------------------------
2021-07-18 20:04:38,383 epoch 9 - iter 6/65 - loss 0.36739246 - samples/sec: 61.90 - lr: 0.000030
2021-07-18 20:04:41,446 epoch 9 - iter 12/65 - loss 0.38681424 - samples/sec: 62.69 - lr: 0.000030
2021-07-18 20:04:44,532 epoch 9 - iter 18/65 - loss 0.33805935 - samples/sec: 62.24 - lr: 0.000030
2021-07-18 20:04:47,561 epoch 9 - iter 24/65 - loss 0.34517113 - samples/sec: 63.41 - lr: 0.000030
2021-07-18 20:04:50,812 epoch 9 - iter 30/65 - loss 0.33929692 - samples/sec: 59.07 - lr: 0.000030
2021-07-18 20:04:53,894 epoch 9 - iter 36/65 - loss 0.33415087 - samples/sec: 62.30 - lr: 0.000030
2021-07-18 20:04:56,951 epoch 9 - iter 42/65 - loss 0.32483377 - samples/sec: 62.82 - lr: 0.000030
2021-07-18 20:05:00,028 epoch 9 - iter 48/65 - loss 0.31278378 - samples/sec: 62.41 - lr: 0.000030
2021-07-18 20:05:03,148 epoch 9 - iter 54/65 - loss 0.31092667 - samples/sec: 61.56 - lr: 0.000030
2021-07-18 20:05:06,203 epoch 9 - iter 60/65 - loss 0.30619941 - samples/sec: 62.86 - lr: 0.000030
2021-07-18 20:05:08,734 ----------------------------------------------------------------------------------------------------
2021-07-18 20:05:08,734 EPOCH 9 done: loss 0.3075 - lr 0.0000300
2021-07-18 20:05:10,542 DEV : loss 0.20240426063537598 - score 0.934
2021-07-18 20:05:10,567 BAD EPOCHS (no improvement): 2
2021-07-18 20:05:10,567 ----------------------------------------------------------------------------------------------------
2021-07-18 20:05:13,595 epoch 10 - iter 6/65 - loss 0.26307926 - samples/sec: 63.42 - lr: 0.000030
2021-07-18 20:05:16,660 epoch 10 - iter 12/65 - loss 0.28927738 - samples/sec: 62.66 - lr: 0.000030
2021-07-18 20:05:19,725 epoch 10 - iter 18/65 - loss 0.26927506 - samples/sec: 62.67 - lr: 0.000030
2021-07-18 20:05:22,801 epoch 10 - iter 24/65 - loss 0.27121206 - samples/sec: 62.43 - lr: 0.000030
2021-07-18 20:05:25,905 epoch 10 - iter 30/65 - loss 0.27900292 - samples/sec: 61.86 - lr: 0.000030
2021-07-18 20:05:28,978 epoch 10 - iter 36/65 - loss 0.27676673 - samples/sec: 62.51 - lr: 0.000030
2021-07-18 20:05:32,010 epoch 10 - iter 42/65 - loss 0.27757454 - samples/sec: 63.33 - lr: 0.000030
2021-07-18 20:05:35,050 epoch 10 - iter 48/65 - loss 0.29508545 - samples/sec: 63.18 - lr: 0.000030
2021-07-18 20:05:38,141 epoch 10 - iter 54/65 - loss 0.29644914 - samples/sec: 62.14 - lr: 0.000030
2021-07-18 20:05:41,190 epoch 10 - iter 60/65 - loss 0.29169394 - samples/sec: 62.97 - lr: 0.000030
2021-07-18 20:05:43,701 ----------------------------------------------------------------------------------------------------
2021-07-18 20:05:43,702 EPOCH 10 done: loss 0.2876 - lr 0.0000300
2021-07-18 20:05:45,509 DEV : loss 0.18606775999069214 - score 0.9386
2021-07-18 20:05:45,535 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:05:51,363 ----------------------------------------------------------------------------------------------------
2021-07-18 20:05:54,434 epoch 11 - iter 6/65 - loss 0.27315764 - samples/sec: 62.55 - lr: 0.000030
2021-07-18 20:05:57,527 epoch 11 - iter 12/65 - loss 0.31387570 - samples/sec: 62.10 - lr: 0.000030
2021-07-18 20:06:00,611 epoch 11 - iter 18/65 - loss 0.29777997 - samples/sec: 62.26 - lr: 0.000030
2021-07-18 20:06:03,647 epoch 11 - iter 24/65 - loss 0.27523414 - samples/sec: 63.27 - lr: 0.000030
2021-07-18 20:06:06,692 epoch 11 - iter 30/65 - loss 0.26914605 - samples/sec: 63.06 - lr: 0.000030
2021-07-18 20:06:09,729 epoch 11 - iter 36/65 - loss 0.26578102 - samples/sec: 63.23 - lr: 0.000030
2021-07-18 20:06:12,822 epoch 11 - iter 42/65 - loss 0.27151730 - samples/sec: 62.10 - lr: 0.000030
2021-07-18 20:06:15,934 epoch 11 - iter 48/65 - loss 0.27998393 - samples/sec: 61.71 - lr: 0.000030
2021-07-18 20:06:18,971 epoch 11 - iter 54/65 - loss 0.27501848 - samples/sec: 63.23 - lr: 0.000030
2021-07-18 20:06:22,038 epoch 11 - iter 60/65 - loss 0.26972566 - samples/sec: 62.61 - lr: 0.000030
2021-07-18 20:06:24,551 ----------------------------------------------------------------------------------------------------
2021-07-18 20:06:24,551 EPOCH 11 done: loss 0.2718 - lr 0.0000300
2021-07-18 20:06:26,363 DEV : loss 0.18871545791625977 - score 0.934
2021-07-18 20:06:26,389 BAD EPOCHS (no improvement): 1
2021-07-18 20:06:26,389 ----------------------------------------------------------------------------------------------------
2021-07-18 20:06:29,446 epoch 12 - iter 6/65 - loss 0.27263244 - samples/sec: 62.82 - lr: 0.000030
2021-07-18 20:06:32,487 epoch 12 - iter 12/65 - loss 0.23902652 - samples/sec: 63.15 - lr: 0.000030
2021-07-18 20:06:35,559 epoch 12 - iter 18/65 - loss 0.23919644 - samples/sec: 62.52 - lr: 0.000030
2021-07-18 20:06:38,644 epoch 12 - iter 24/65 - loss 0.25217180 - samples/sec: 62.26 - lr: 0.000030
2021-07-18 20:06:41,739 epoch 12 - iter 30/65 - loss 0.26023495 - samples/sec: 62.04 - lr: 0.000030
2021-07-18 20:06:44,804 epoch 12 - iter 36/65 - loss 0.25846627 - samples/sec: 62.66 - lr: 0.000030
2021-07-18 20:06:47,852 epoch 12 - iter 42/65 - loss 0.26775255 - samples/sec: 63.00 - lr: 0.000030
2021-07-18 20:06:50,947 epoch 12 - iter 48/65 - loss 0.25807911 - samples/sec: 62.06 - lr: 0.000030
2021-07-18 20:06:54,040 epoch 12 - iter 54/65 - loss 0.25857835 - samples/sec: 62.09 - lr: 0.000030
2021-07-18 20:06:57,101 epoch 12 - iter 60/65 - loss 0.25150122 - samples/sec: 62.74 - lr: 0.000030
2021-07-18 20:06:59,642 ----------------------------------------------------------------------------------------------------
2021-07-18 20:06:59,643 EPOCH 12 done: loss 0.2547 - lr 0.0000300
2021-07-18 20:07:01,681 DEV : loss 0.1725919246673584 - score 0.9386
2021-07-18 20:07:01,707 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:07:07,087 ----------------------------------------------------------------------------------------------------
2021-07-18 20:07:10,183 epoch 13 - iter 6/65 - loss 0.22362183 - samples/sec: 62.04 - lr: 0.000030
2021-07-18 20:07:13,239 epoch 13 - iter 12/65 - loss 0.23974629 - samples/sec: 62.84 - lr: 0.000030
2021-07-18 20:07:16,299 epoch 13 - iter 18/65 - loss 0.24121768 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 20:07:19,375 epoch 13 - iter 24/65 - loss 0.23059457 - samples/sec: 62.44 - lr: 0.000030
2021-07-18 20:07:22,446 epoch 13 - iter 30/65 - loss 0.23188347 - samples/sec: 62.53 - lr: 0.000030
2021-07-18 20:07:25,519 epoch 13 - iter 36/65 - loss 0.23330868 - samples/sec: 62.51 - lr: 0.000030
2021-07-18 20:07:28,591 epoch 13 - iter 42/65 - loss 0.23703890 - samples/sec: 62.50 - lr: 0.000030
2021-07-18 20:07:31,671 epoch 13 - iter 48/65 - loss 0.23002168 - samples/sec: 62.36 - lr: 0.000030
2021-07-18 20:07:34,756 epoch 13 - iter 54/65 - loss 0.23383864 - samples/sec: 62.26 - lr: 0.000030
2021-07-18 20:07:37,838 epoch 13 - iter 60/65 - loss 0.24456121 - samples/sec: 62.31 - lr: 0.000030
2021-07-18 20:07:40,358 ----------------------------------------------------------------------------------------------------
2021-07-18 20:07:40,359 EPOCH 13 done: loss 0.2439 - lr 0.0000300
2021-07-18 20:07:42,171 DEV : loss 0.1834622174501419 - score 0.934
2021-07-18 20:07:42,196 BAD EPOCHS (no improvement): 1
2021-07-18 20:07:42,197 ----------------------------------------------------------------------------------------------------
2021-07-18 20:07:45,270 epoch 14 - iter 6/65 - loss 0.21478390 - samples/sec: 62.49 - lr: 0.000030
2021-07-18 20:07:48,298 epoch 14 - iter 12/65 - loss 0.24832489 - samples/sec: 63.42 - lr: 0.000030
2021-07-18 20:07:51,347 epoch 14 - iter 18/65 - loss 0.24193662 - samples/sec: 62.98 - lr: 0.000030
2021-07-18 20:07:54,425 epoch 14 - iter 24/65 - loss 0.22796048 - samples/sec: 62.39 - lr: 0.000030
2021-07-18 20:07:57,471 epoch 14 - iter 30/65 - loss 0.22490820 - samples/sec: 63.06 - lr: 0.000030
2021-07-18 20:08:00,543 epoch 14 - iter 36/65 - loss 0.22428740 - samples/sec: 62.51 - lr: 0.000030
2021-07-18 20:08:03,610 epoch 14 - iter 42/65 - loss 0.22292615 - samples/sec: 62.61 - lr: 0.000030
2021-07-18 20:08:06,626 epoch 14 - iter 48/65 - loss 0.22331602 - samples/sec: 63.68 - lr: 0.000030
2021-07-18 20:08:09,663 epoch 14 - iter 54/65 - loss 0.22030470 - samples/sec: 63.22 - lr: 0.000030
2021-07-18 20:08:12,752 epoch 14 - iter 60/65 - loss 0.21756642 - samples/sec: 62.18 - lr: 0.000030
2021-07-18 20:08:15,278 ----------------------------------------------------------------------------------------------------
2021-07-18 20:08:15,278 EPOCH 14 done: loss 0.2232 - lr 0.0000300
2021-07-18 20:08:17,083 DEV : loss 0.17351339757442474 - score 0.9386
2021-07-18 20:08:17,109 BAD EPOCHS (no improvement): 2
2021-07-18 20:08:17,109 ----------------------------------------------------------------------------------------------------
2021-07-18 20:08:20,179 epoch 15 - iter 6/65 - loss 0.25914404 - samples/sec: 62.56 - lr: 0.000030
2021-07-18 20:08:23,276 epoch 15 - iter 12/65 - loss 0.19085704 - samples/sec: 62.01 - lr: 0.000030
2021-07-18 20:08:26,338 epoch 15 - iter 18/65 - loss 0.19001205 - samples/sec: 62.73 - lr: 0.000030
2021-07-18 20:08:29,390 epoch 15 - iter 24/65 - loss 0.21224920 - samples/sec: 62.92 - lr: 0.000030
2021-07-18 20:08:32,450 epoch 15 - iter 30/65 - loss 0.21212949 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 20:08:35,542 epoch 15 - iter 36/65 - loss 0.21714529 - samples/sec: 62.11 - lr: 0.000030
2021-07-18 20:08:38,641 epoch 15 - iter 42/65 - loss 0.22574022 - samples/sec: 61.98 - lr: 0.000030
2021-07-18 20:08:41,714 epoch 15 - iter 48/65 - loss 0.23262734 - samples/sec: 62.49 - lr: 0.000030
2021-07-18 20:08:44,771 epoch 15 - iter 54/65 - loss 0.23213974 - samples/sec: 62.82 - lr: 0.000030
2021-07-18 20:08:47,870 epoch 15 - iter 60/65 - loss 0.23007042 - samples/sec: 61.98 - lr: 0.000030
2021-07-18 20:08:50,364 ----------------------------------------------------------------------------------------------------
2021-07-18 20:08:50,364 EPOCH 15 done: loss 0.2309 - lr 0.0000300
2021-07-18 20:08:52,171 DEV : loss 0.1953859180212021 - score 0.9257
2021-07-18 20:08:52,197 BAD EPOCHS (no improvement): 3
2021-07-18 20:08:52,197 ----------------------------------------------------------------------------------------------------
2021-07-18 20:08:55,227 epoch 16 - iter 6/65 - loss 0.20790419 - samples/sec: 63.39 - lr: 0.000030
2021-07-18 20:08:58,319 epoch 16 - iter 12/65 - loss 0.19463778 - samples/sec: 62.11 - lr: 0.000030
2021-07-18 20:09:01,391 epoch 16 - iter 18/65 - loss 0.19913997 - samples/sec: 62.50 - lr: 0.000030
2021-07-18 20:09:04,470 epoch 16 - iter 24/65 - loss 0.18606082 - samples/sec: 62.39 - lr: 0.000030
2021-07-18 20:09:07,548 epoch 16 - iter 30/65 - loss 0.18721299 - samples/sec: 62.39 - lr: 0.000030
2021-07-18 20:09:10,631 epoch 16 - iter 36/65 - loss 0.18855929 - samples/sec: 62.29 - lr: 0.000030
2021-07-18 20:09:13,742 epoch 16 - iter 42/65 - loss 0.19300213 - samples/sec: 61.73 - lr: 0.000030
2021-07-18 20:09:16,783 epoch 16 - iter 48/65 - loss 0.19037052 - samples/sec: 63.15 - lr: 0.000030
2021-07-18 20:09:19,842 epoch 16 - iter 54/65 - loss 0.18387402 - samples/sec: 62.79 - lr: 0.000030
2021-07-18 20:09:22,882 epoch 16 - iter 60/65 - loss 0.18583800 - samples/sec: 63.16 - lr: 0.000030
2021-07-18 20:09:25,383 ----------------------------------------------------------------------------------------------------
2021-07-18 20:09:25,383 EPOCH 16 done: loss 0.1883 - lr 0.0000300
2021-07-18 20:09:27,191 DEV : loss 0.17150479555130005 - score 0.9366
Epoch    16: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 20:09:27,217 BAD EPOCHS (no improvement): 4
2021-07-18 20:09:27,217 ----------------------------------------------------------------------------------------------------
2021-07-18 20:09:30,491 epoch 17 - iter 6/65 - loss 0.16504651 - samples/sec: 58.66 - lr: 0.000015
2021-07-18 20:09:33,558 epoch 17 - iter 12/65 - loss 0.17029146 - samples/sec: 62.60 - lr: 0.000015
2021-07-18 20:09:36,599 epoch 17 - iter 18/65 - loss 0.18561416 - samples/sec: 63.16 - lr: 0.000015
2021-07-18 20:09:39,658 epoch 17 - iter 24/65 - loss 0.18964298 - samples/sec: 62.77 - lr: 0.000015
2021-07-18 20:09:42,731 epoch 17 - iter 30/65 - loss 0.18687188 - samples/sec: 62.49 - lr: 0.000015
2021-07-18 20:09:45,747 epoch 17 - iter 36/65 - loss 0.18437772 - samples/sec: 63.68 - lr: 0.000015
2021-07-18 20:09:48,826 epoch 17 - iter 42/65 - loss 0.18290937 - samples/sec: 62.37 - lr: 0.000015
2021-07-18 20:09:51,940 epoch 17 - iter 48/65 - loss 0.18418185 - samples/sec: 61.67 - lr: 0.000015
2021-07-18 20:09:55,017 epoch 17 - iter 54/65 - loss 0.18081499 - samples/sec: 62.42 - lr: 0.000015
2021-07-18 20:09:58,098 epoch 17 - iter 60/65 - loss 0.17635613 - samples/sec: 62.32 - lr: 0.000015
2021-07-18 20:10:00,658 ----------------------------------------------------------------------------------------------------
2021-07-18 20:10:00,659 EPOCH 17 done: loss 0.1749 - lr 0.0000150
2021-07-18 20:10:02,467 DEV : loss 0.16348965466022491 - score 0.9412
2021-07-18 20:10:02,492 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:10:08,289 ----------------------------------------------------------------------------------------------------
2021-07-18 20:10:11,338 epoch 18 - iter 6/65 - loss 0.13102432 - samples/sec: 63.00 - lr: 0.000015
2021-07-18 20:10:14,414 epoch 18 - iter 12/65 - loss 0.17021241 - samples/sec: 62.42 - lr: 0.000015
2021-07-18 20:10:17,506 epoch 18 - iter 18/65 - loss 0.17984445 - samples/sec: 62.11 - lr: 0.000015
2021-07-18 20:10:20,554 epoch 18 - iter 24/65 - loss 0.17809776 - samples/sec: 63.01 - lr: 0.000015
2021-07-18 20:10:23,644 epoch 18 - iter 30/65 - loss 0.17999170 - samples/sec: 62.15 - lr: 0.000015
2021-07-18 20:10:26,711 epoch 18 - iter 36/65 - loss 0.18458850 - samples/sec: 62.62 - lr: 0.000015
2021-07-18 20:10:29,803 epoch 18 - iter 42/65 - loss 0.18739123 - samples/sec: 62.11 - lr: 0.000015
2021-07-18 20:10:32,846 epoch 18 - iter 48/65 - loss 0.18436343 - samples/sec: 63.10 - lr: 0.000015
2021-07-18 20:10:35,894 epoch 18 - iter 54/65 - loss 0.18293327 - samples/sec: 63.01 - lr: 0.000015
2021-07-18 20:10:38,986 epoch 18 - iter 60/65 - loss 0.18709126 - samples/sec: 62.11 - lr: 0.000015
2021-07-18 20:10:41,535 ----------------------------------------------------------------------------------------------------
2021-07-18 20:10:41,536 EPOCH 18 done: loss 0.1900 - lr 0.0000150
2021-07-18 20:10:43,345 DEV : loss 0.1709159016609192 - score 0.9395
2021-07-18 20:10:43,371 BAD EPOCHS (no improvement): 1
2021-07-18 20:10:43,371 ----------------------------------------------------------------------------------------------------
2021-07-18 20:10:46,440 epoch 19 - iter 6/65 - loss 0.13267615 - samples/sec: 62.58 - lr: 0.000015
2021-07-18 20:10:49,532 epoch 19 - iter 12/65 - loss 0.15450565 - samples/sec: 62.11 - lr: 0.000015
2021-07-18 20:10:52,618 epoch 19 - iter 18/65 - loss 0.16197459 - samples/sec: 62.23 - lr: 0.000015
2021-07-18 20:10:55,667 epoch 19 - iter 24/65 - loss 0.16325767 - samples/sec: 62.99 - lr: 0.000015
2021-07-18 20:10:58,769 epoch 19 - iter 30/65 - loss 0.16131796 - samples/sec: 61.90 - lr: 0.000015
2021-07-18 20:11:01,816 epoch 19 - iter 36/65 - loss 0.15785782 - samples/sec: 63.04 - lr: 0.000015
2021-07-18 20:11:04,910 epoch 19 - iter 42/65 - loss 0.16049570 - samples/sec: 62.05 - lr: 0.000015
2021-07-18 20:11:07,971 epoch 19 - iter 48/65 - loss 0.15781068 - samples/sec: 62.75 - lr: 0.000015
2021-07-18 20:11:11,045 epoch 19 - iter 54/65 - loss 0.15386506 - samples/sec: 62.46 - lr: 0.000015
2021-07-18 20:11:14,062 epoch 19 - iter 60/65 - loss 0.15695900 - samples/sec: 63.67 - lr: 0.000015
2021-07-18 20:11:16,597 ----------------------------------------------------------------------------------------------------
2021-07-18 20:11:16,598 EPOCH 19 done: loss 0.1604 - lr 0.0000150
2021-07-18 20:11:18,405 DEV : loss 0.1661568284034729 - score 0.9435
2021-07-18 20:11:18,431 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:11:24,350 ----------------------------------------------------------------------------------------------------
2021-07-18 20:11:27,408 epoch 20 - iter 6/65 - loss 0.16506963 - samples/sec: 62.81 - lr: 0.000015
2021-07-18 20:11:30,487 epoch 20 - iter 12/65 - loss 0.18130979 - samples/sec: 62.37 - lr: 0.000015
2021-07-18 20:11:33,574 epoch 20 - iter 18/65 - loss 0.16183168 - samples/sec: 62.21 - lr: 0.000015
2021-07-18 20:11:36,647 epoch 20 - iter 24/65 - loss 0.18529810 - samples/sec: 62.50 - lr: 0.000015
2021-07-18 20:11:39,750 epoch 20 - iter 30/65 - loss 0.18898739 - samples/sec: 61.88 - lr: 0.000015
2021-07-18 20:11:42,830 epoch 20 - iter 36/65 - loss 0.17961460 - samples/sec: 62.36 - lr: 0.000015
2021-07-18 20:11:45,878 epoch 20 - iter 42/65 - loss 0.17299536 - samples/sec: 63.00 - lr: 0.000015
2021-07-18 20:11:48,934 epoch 20 - iter 48/65 - loss 0.16908686 - samples/sec: 62.83 - lr: 0.000015
2021-07-18 20:11:52,012 epoch 20 - iter 54/65 - loss 0.16640176 - samples/sec: 62.41 - lr: 0.000015
2021-07-18 20:11:55,089 epoch 20 - iter 60/65 - loss 0.16838425 - samples/sec: 62.41 - lr: 0.000015
2021-07-18 20:11:57,603 ----------------------------------------------------------------------------------------------------
2021-07-18 20:11:57,603 EPOCH 20 done: loss 0.1674 - lr 0.0000150
2021-07-18 20:11:59,413 DEV : loss 0.18441733717918396 - score 0.9423
2021-07-18 20:11:59,439 BAD EPOCHS (no improvement): 1
2021-07-18 20:11:59,439 ----------------------------------------------------------------------------------------------------
2021-07-18 20:12:02,725 epoch 21 - iter 6/65 - loss 0.19272710 - samples/sec: 58.44 - lr: 0.000015
2021-07-18 20:12:05,785 epoch 21 - iter 12/65 - loss 0.16402252 - samples/sec: 62.77 - lr: 0.000015
2021-07-18 20:12:08,870 epoch 21 - iter 18/65 - loss 0.16363308 - samples/sec: 62.24 - lr: 0.000015
2021-07-18 20:12:11,947 epoch 21 - iter 24/65 - loss 0.15520829 - samples/sec: 62.42 - lr: 0.000015
2021-07-18 20:12:15,034 epoch 21 - iter 30/65 - loss 0.15817824 - samples/sec: 62.21 - lr: 0.000015
2021-07-18 20:12:18,112 epoch 21 - iter 36/65 - loss 0.16983917 - samples/sec: 62.39 - lr: 0.000015
2021-07-18 20:12:21,144 epoch 21 - iter 42/65 - loss 0.17873497 - samples/sec: 63.33 - lr: 0.000015
2021-07-18 20:12:24,228 epoch 21 - iter 48/65 - loss 0.17245949 - samples/sec: 62.27 - lr: 0.000015
2021-07-18 20:12:27,295 epoch 21 - iter 54/65 - loss 0.16724521 - samples/sec: 62.62 - lr: 0.000015
2021-07-18 20:12:30,341 epoch 21 - iter 60/65 - loss 0.16247453 - samples/sec: 63.03 - lr: 0.000015
2021-07-18 20:12:32,874 ----------------------------------------------------------------------------------------------------
2021-07-18 20:12:32,874 EPOCH 21 done: loss 0.1587 - lr 0.0000150
2021-07-18 20:12:34,681 DEV : loss 0.16827473044395447 - score 0.9409
2021-07-18 20:12:34,707 BAD EPOCHS (no improvement): 2
2021-07-18 20:12:34,707 ----------------------------------------------------------------------------------------------------
2021-07-18 20:12:37,783 epoch 22 - iter 6/65 - loss 0.12955470 - samples/sec: 62.44 - lr: 0.000015
2021-07-18 20:12:40,844 epoch 22 - iter 12/65 - loss 0.13974184 - samples/sec: 62.73 - lr: 0.000015
2021-07-18 20:12:43,914 epoch 22 - iter 18/65 - loss 0.14394014 - samples/sec: 62.57 - lr: 0.000015
2021-07-18 20:12:47,030 epoch 22 - iter 24/65 - loss 0.14462261 - samples/sec: 61.62 - lr: 0.000015
2021-07-18 20:12:50,091 epoch 22 - iter 30/65 - loss 0.14907952 - samples/sec: 62.74 - lr: 0.000015
2021-07-18 20:12:53,159 epoch 22 - iter 36/65 - loss 0.14318722 - samples/sec: 62.60 - lr: 0.000015
2021-07-18 20:12:56,252 epoch 22 - iter 42/65 - loss 0.14410086 - samples/sec: 62.08 - lr: 0.000015
2021-07-18 20:12:59,316 epoch 22 - iter 48/65 - loss 0.14769545 - samples/sec: 62.69 - lr: 0.000015
2021-07-18 20:13:02,350 epoch 22 - iter 54/65 - loss 0.14468452 - samples/sec: 63.28 - lr: 0.000015
2021-07-18 20:13:05,407 epoch 22 - iter 60/65 - loss 0.15111318 - samples/sec: 62.82 - lr: 0.000015
2021-07-18 20:13:07,918 ----------------------------------------------------------------------------------------------------
2021-07-18 20:13:07,918 EPOCH 22 done: loss 0.1526 - lr 0.0000150
2021-07-18 20:13:09,729 DEV : loss 0.16999751329421997 - score 0.9412
2021-07-18 20:13:09,755 BAD EPOCHS (no improvement): 3
2021-07-18 20:13:09,755 ----------------------------------------------------------------------------------------------------
2021-07-18 20:13:12,823 epoch 23 - iter 6/65 - loss 0.13750818 - samples/sec: 62.60 - lr: 0.000015
2021-07-18 20:13:15,911 epoch 23 - iter 12/65 - loss 0.15960342 - samples/sec: 62.19 - lr: 0.000015
2021-07-18 20:13:18,990 epoch 23 - iter 18/65 - loss 0.15445489 - samples/sec: 62.37 - lr: 0.000015
2021-07-18 20:13:22,094 epoch 23 - iter 24/65 - loss 0.14899735 - samples/sec: 61.87 - lr: 0.000015
2021-07-18 20:13:25,176 epoch 23 - iter 30/65 - loss 0.15306281 - samples/sec: 62.30 - lr: 0.000015
2021-07-18 20:13:28,246 epoch 23 - iter 36/65 - loss 0.15192566 - samples/sec: 62.55 - lr: 0.000015
2021-07-18 20:13:31,288 epoch 23 - iter 42/65 - loss 0.15159879 - samples/sec: 63.14 - lr: 0.000015
2021-07-18 20:13:34,342 epoch 23 - iter 48/65 - loss 0.14809279 - samples/sec: 62.87 - lr: 0.000015
2021-07-18 20:13:37,426 epoch 23 - iter 54/65 - loss 0.14823280 - samples/sec: 62.28 - lr: 0.000015
2021-07-18 20:13:40,504 epoch 23 - iter 60/65 - loss 0.14675637 - samples/sec: 62.39 - lr: 0.000015
2021-07-18 20:13:42,987 ----------------------------------------------------------------------------------------------------
2021-07-18 20:13:42,988 EPOCH 23 done: loss 0.1493 - lr 0.0000150
2021-07-18 20:13:44,797 DEV : loss 0.16400684416294098 - score 0.9412
Epoch    23: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 20:13:44,823 BAD EPOCHS (no improvement): 4
2021-07-18 20:13:44,823 ----------------------------------------------------------------------------------------------------
2021-07-18 20:13:47,871 epoch 24 - iter 6/65 - loss 0.11575970 - samples/sec: 63.01 - lr: 0.000008
2021-07-18 20:13:50,942 epoch 24 - iter 12/65 - loss 0.12707318 - samples/sec: 62.54 - lr: 0.000008
2021-07-18 20:13:54,018 epoch 24 - iter 18/65 - loss 0.12879755 - samples/sec: 62.43 - lr: 0.000008
2021-07-18 20:13:57,055 epoch 24 - iter 24/65 - loss 0.12874342 - samples/sec: 63.24 - lr: 0.000008
2021-07-18 20:14:00,157 epoch 24 - iter 30/65 - loss 0.13983911 - samples/sec: 61.90 - lr: 0.000008
2021-07-18 20:14:03,191 epoch 24 - iter 36/65 - loss 0.14211624 - samples/sec: 63.31 - lr: 0.000008
2021-07-18 20:14:06,271 epoch 24 - iter 42/65 - loss 0.14301010 - samples/sec: 62.34 - lr: 0.000008
2021-07-18 20:14:09,358 epoch 24 - iter 48/65 - loss 0.14420647 - samples/sec: 62.22 - lr: 0.000008
2021-07-18 20:14:12,443 epoch 24 - iter 54/65 - loss 0.14302199 - samples/sec: 62.24 - lr: 0.000008
2021-07-18 20:14:15,536 epoch 24 - iter 60/65 - loss 0.14270574 - samples/sec: 62.10 - lr: 0.000008
2021-07-18 20:14:18,066 ----------------------------------------------------------------------------------------------------
2021-07-18 20:14:18,066 EPOCH 24 done: loss 0.1429 - lr 0.0000075
2021-07-18 20:14:20,083 DEV : loss 0.1698763370513916 - score 0.9415
2021-07-18 20:14:20,108 BAD EPOCHS (no improvement): 1
2021-07-18 20:14:20,108 ----------------------------------------------------------------------------------------------------
2021-07-18 20:14:23,196 epoch 25 - iter 6/65 - loss 0.15872807 - samples/sec: 62.21 - lr: 0.000008
2021-07-18 20:14:26,246 epoch 25 - iter 12/65 - loss 0.16298218 - samples/sec: 62.97 - lr: 0.000008
2021-07-18 20:14:29,330 epoch 25 - iter 18/65 - loss 0.15570249 - samples/sec: 62.26 - lr: 0.000008
2021-07-18 20:14:32,410 epoch 25 - iter 24/65 - loss 0.16085544 - samples/sec: 62.36 - lr: 0.000008
2021-07-18 20:14:35,481 epoch 25 - iter 30/65 - loss 0.14765140 - samples/sec: 62.52 - lr: 0.000008
2021-07-18 20:14:38,543 epoch 25 - iter 36/65 - loss 0.15360127 - samples/sec: 62.72 - lr: 0.000008
2021-07-18 20:14:41,622 epoch 25 - iter 42/65 - loss 0.14922936 - samples/sec: 62.38 - lr: 0.000008
2021-07-18 20:14:44,699 epoch 25 - iter 48/65 - loss 0.14585159 - samples/sec: 62.42 - lr: 0.000008
2021-07-18 20:14:47,780 epoch 25 - iter 54/65 - loss 0.14724658 - samples/sec: 62.34 - lr: 0.000008
2021-07-18 20:14:50,839 epoch 25 - iter 60/65 - loss 0.14760349 - samples/sec: 62.77 - lr: 0.000008
2021-07-18 20:14:53,344 ----------------------------------------------------------------------------------------------------
2021-07-18 20:14:53,344 EPOCH 25 done: loss 0.1429 - lr 0.0000075
2021-07-18 20:14:55,155 DEV : loss 0.16835880279541016 - score 0.9438
2021-07-18 20:14:55,181 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:15:00,885 ----------------------------------------------------------------------------------------------------
2021-07-18 20:15:03,978 epoch 26 - iter 6/65 - loss 0.10791362 - samples/sec: 62.09 - lr: 0.000008
2021-07-18 20:15:07,070 epoch 26 - iter 12/65 - loss 0.12915369 - samples/sec: 62.11 - lr: 0.000008
2021-07-18 20:15:10,127 epoch 26 - iter 18/65 - loss 0.11478702 - samples/sec: 62.83 - lr: 0.000008
2021-07-18 20:15:13,215 epoch 26 - iter 24/65 - loss 0.12205384 - samples/sec: 62.19 - lr: 0.000008
2021-07-18 20:15:16,279 epoch 26 - iter 30/65 - loss 0.12482283 - samples/sec: 62.68 - lr: 0.000008
2021-07-18 20:15:19,355 epoch 26 - iter 36/65 - loss 0.13111283 - samples/sec: 62.43 - lr: 0.000008
2021-07-18 20:15:22,428 epoch 26 - iter 42/65 - loss 0.13346912 - samples/sec: 62.49 - lr: 0.000008
2021-07-18 20:15:25,516 epoch 26 - iter 48/65 - loss 0.13575320 - samples/sec: 62.20 - lr: 0.000008
2021-07-18 20:15:28,555 epoch 26 - iter 54/65 - loss 0.13666562 - samples/sec: 63.19 - lr: 0.000008
2021-07-18 20:15:31,607 epoch 26 - iter 60/65 - loss 0.13380796 - samples/sec: 62.92 - lr: 0.000008
2021-07-18 20:15:34,161 ----------------------------------------------------------------------------------------------------
2021-07-18 20:15:34,161 EPOCH 26 done: loss 0.1377 - lr 0.0000075
2021-07-18 20:15:35,969 DEV : loss 0.16490553319454193 - score 0.9412
2021-07-18 20:15:35,994 BAD EPOCHS (no improvement): 1
2021-07-18 20:15:35,995 ----------------------------------------------------------------------------------------------------
2021-07-18 20:15:39,015 epoch 27 - iter 6/65 - loss 0.15272841 - samples/sec: 63.59 - lr: 0.000008
2021-07-18 20:15:42,047 epoch 27 - iter 12/65 - loss 0.13744520 - samples/sec: 63.32 - lr: 0.000008
2021-07-18 20:15:45,112 epoch 27 - iter 18/65 - loss 0.14145928 - samples/sec: 62.66 - lr: 0.000008
2021-07-18 20:15:48,133 epoch 27 - iter 24/65 - loss 0.13836206 - samples/sec: 63.58 - lr: 0.000008
2021-07-18 20:15:51,196 epoch 27 - iter 30/65 - loss 0.13272748 - samples/sec: 62.70 - lr: 0.000008
2021-07-18 20:15:54,248 epoch 27 - iter 36/65 - loss 0.13261439 - samples/sec: 62.91 - lr: 0.000008
2021-07-18 20:15:57,272 epoch 27 - iter 42/65 - loss 0.14300497 - samples/sec: 63.51 - lr: 0.000008
2021-07-18 20:16:00,302 epoch 27 - iter 48/65 - loss 0.14275224 - samples/sec: 63.39 - lr: 0.000008
2021-07-18 20:16:03,320 epoch 27 - iter 54/65 - loss 0.14046800 - samples/sec: 63.64 - lr: 0.000008
2021-07-18 20:16:06,348 epoch 27 - iter 60/65 - loss 0.14270947 - samples/sec: 63.41 - lr: 0.000008
2021-07-18 20:16:08,876 ----------------------------------------------------------------------------------------------------
2021-07-18 20:16:08,876 EPOCH 27 done: loss 0.1418 - lr 0.0000075
2021-07-18 20:16:10,682 DEV : loss 0.17697849869728088 - score 0.9392
2021-07-18 20:16:10,708 BAD EPOCHS (no improvement): 2
2021-07-18 20:16:10,708 ----------------------------------------------------------------------------------------------------
2021-07-18 20:16:13,755 epoch 28 - iter 6/65 - loss 0.18350065 - samples/sec: 63.02 - lr: 0.000008
2021-07-18 20:16:16,790 epoch 28 - iter 12/65 - loss 0.16399206 - samples/sec: 63.27 - lr: 0.000008
2021-07-18 20:16:19,832 epoch 28 - iter 18/65 - loss 0.14423136 - samples/sec: 63.14 - lr: 0.000008
2021-07-18 20:16:22,869 epoch 28 - iter 24/65 - loss 0.14074428 - samples/sec: 63.24 - lr: 0.000008
2021-07-18 20:16:25,908 epoch 28 - iter 30/65 - loss 0.13991473 - samples/sec: 63.18 - lr: 0.000008
2021-07-18 20:16:28,911 epoch 28 - iter 36/65 - loss 0.13187991 - samples/sec: 63.95 - lr: 0.000008
2021-07-18 20:16:31,975 epoch 28 - iter 42/65 - loss 0.13167748 - samples/sec: 62.69 - lr: 0.000008
2021-07-18 20:16:35,048 epoch 28 - iter 48/65 - loss 0.13142430 - samples/sec: 62.50 - lr: 0.000008
2021-07-18 20:16:38,086 epoch 28 - iter 54/65 - loss 0.12741999 - samples/sec: 63.21 - lr: 0.000008
2021-07-18 20:16:41,141 epoch 28 - iter 60/65 - loss 0.12872652 - samples/sec: 62.87 - lr: 0.000008
2021-07-18 20:16:43,652 ----------------------------------------------------------------------------------------------------
2021-07-18 20:16:43,652 EPOCH 28 done: loss 0.1330 - lr 0.0000075
2021-07-18 20:16:45,461 DEV : loss 0.1702522188425064 - score 0.9412
2021-07-18 20:16:45,486 BAD EPOCHS (no improvement): 3
2021-07-18 20:16:45,486 ----------------------------------------------------------------------------------------------------
2021-07-18 20:16:48,725 epoch 29 - iter 6/65 - loss 0.15341315 - samples/sec: 59.31 - lr: 0.000008
2021-07-18 20:16:51,789 epoch 29 - iter 12/65 - loss 0.14989636 - samples/sec: 62.66 - lr: 0.000008
2021-07-18 20:16:54,851 epoch 29 - iter 18/65 - loss 0.14850048 - samples/sec: 62.72 - lr: 0.000008
2021-07-18 20:16:57,923 epoch 29 - iter 24/65 - loss 0.15340740 - samples/sec: 62.51 - lr: 0.000008
2021-07-18 20:17:00,951 epoch 29 - iter 30/65 - loss 0.14338234 - samples/sec: 63.43 - lr: 0.000008
2021-07-18 20:17:04,006 epoch 29 - iter 36/65 - loss 0.14048644 - samples/sec: 62.85 - lr: 0.000008
2021-07-18 20:17:07,051 epoch 29 - iter 42/65 - loss 0.13393709 - samples/sec: 63.07 - lr: 0.000008
2021-07-18 20:17:10,107 epoch 29 - iter 48/65 - loss 0.13667331 - samples/sec: 62.85 - lr: 0.000008
2021-07-18 20:17:13,190 epoch 29 - iter 54/65 - loss 0.13896481 - samples/sec: 62.28 - lr: 0.000008
2021-07-18 20:17:16,226 epoch 29 - iter 60/65 - loss 0.14234624 - samples/sec: 63.26 - lr: 0.000008
2021-07-18 20:17:18,745 ----------------------------------------------------------------------------------------------------
2021-07-18 20:17:18,746 EPOCH 29 done: loss 0.1383 - lr 0.0000075
2021-07-18 20:17:20,556 DEV : loss 0.1785193681716919 - score 0.9443
2021-07-18 20:17:20,582 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:17:26,255 ----------------------------------------------------------------------------------------------------
2021-07-18 20:17:29,287 epoch 30 - iter 6/65 - loss 0.15411840 - samples/sec: 63.36 - lr: 0.000008
2021-07-18 20:17:32,347 epoch 30 - iter 12/65 - loss 0.13588230 - samples/sec: 62.76 - lr: 0.000008
2021-07-18 20:17:35,403 epoch 30 - iter 18/65 - loss 0.13758477 - samples/sec: 62.85 - lr: 0.000008
2021-07-18 20:17:38,438 epoch 30 - iter 24/65 - loss 0.13209739 - samples/sec: 63.27 - lr: 0.000008
2021-07-18 20:17:41,523 epoch 30 - iter 30/65 - loss 0.13475784 - samples/sec: 62.25 - lr: 0.000008
2021-07-18 20:17:44,610 epoch 30 - iter 36/65 - loss 0.14178471 - samples/sec: 62.20 - lr: 0.000008
2021-07-18 20:17:47,665 epoch 30 - iter 42/65 - loss 0.14079159 - samples/sec: 62.88 - lr: 0.000008
2021-07-18 20:17:50,734 epoch 30 - iter 48/65 - loss 0.14240440 - samples/sec: 62.57 - lr: 0.000008
2021-07-18 20:17:53,786 epoch 30 - iter 54/65 - loss 0.13691345 - samples/sec: 62.93 - lr: 0.000008
2021-07-18 20:17:56,834 epoch 30 - iter 60/65 - loss 0.13894235 - samples/sec: 62.99 - lr: 0.000008
2021-07-18 20:17:59,358 ----------------------------------------------------------------------------------------------------
2021-07-18 20:17:59,358 EPOCH 30 done: loss 0.1394 - lr 0.0000075
2021-07-18 20:18:01,165 DEV : loss 0.17368607223033905 - score 0.9415
2021-07-18 20:18:01,191 BAD EPOCHS (no improvement): 1
2021-07-18 20:18:01,191 ----------------------------------------------------------------------------------------------------
2021-07-18 20:18:04,238 epoch 31 - iter 6/65 - loss 0.12689101 - samples/sec: 63.03 - lr: 0.000008
2021-07-18 20:18:07,314 epoch 31 - iter 12/65 - loss 0.12271133 - samples/sec: 62.42 - lr: 0.000008
2021-07-18 20:18:10,351 epoch 31 - iter 18/65 - loss 0.12689449 - samples/sec: 63.24 - lr: 0.000008
2021-07-18 20:18:13,448 epoch 31 - iter 24/65 - loss 0.13263634 - samples/sec: 62.03 - lr: 0.000008
2021-07-18 20:18:16,505 epoch 31 - iter 30/65 - loss 0.14782368 - samples/sec: 62.81 - lr: 0.000008
2021-07-18 20:18:19,584 epoch 31 - iter 36/65 - loss 0.14637137 - samples/sec: 62.38 - lr: 0.000008
2021-07-18 20:18:22,673 epoch 31 - iter 42/65 - loss 0.14711833 - samples/sec: 62.15 - lr: 0.000008
2021-07-18 20:18:25,764 epoch 31 - iter 48/65 - loss 0.13966430 - samples/sec: 62.14 - lr: 0.000008
2021-07-18 20:18:28,818 epoch 31 - iter 54/65 - loss 0.13651538 - samples/sec: 62.88 - lr: 0.000008
2021-07-18 20:18:31,891 epoch 31 - iter 60/65 - loss 0.13862767 - samples/sec: 62.50 - lr: 0.000008
2021-07-18 20:18:34,434 ----------------------------------------------------------------------------------------------------
2021-07-18 20:18:34,435 EPOCH 31 done: loss 0.1389 - lr 0.0000075
2021-07-18 20:18:36,245 DEV : loss 0.1780223846435547 - score 0.9443
2021-07-18 20:18:36,272 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:18:42,065 ----------------------------------------------------------------------------------------------------
2021-07-18 20:18:45,147 epoch 32 - iter 6/65 - loss 0.12753340 - samples/sec: 62.32 - lr: 0.000008
2021-07-18 20:18:48,230 epoch 32 - iter 12/65 - loss 0.13625792 - samples/sec: 62.30 - lr: 0.000008
2021-07-18 20:18:51,325 epoch 32 - iter 18/65 - loss 0.13699867 - samples/sec: 62.05 - lr: 0.000008
2021-07-18 20:18:54,367 epoch 32 - iter 24/65 - loss 0.13393716 - samples/sec: 63.13 - lr: 0.000008
2021-07-18 20:18:57,457 epoch 32 - iter 30/65 - loss 0.14442515 - samples/sec: 62.15 - lr: 0.000008
2021-07-18 20:19:00,511 epoch 32 - iter 36/65 - loss 0.14247231 - samples/sec: 62.88 - lr: 0.000008
2021-07-18 20:19:03,584 epoch 32 - iter 42/65 - loss 0.14158744 - samples/sec: 62.50 - lr: 0.000008
2021-07-18 20:19:06,651 epoch 32 - iter 48/65 - loss 0.13858756 - samples/sec: 62.61 - lr: 0.000008
2021-07-18 20:19:09,734 epoch 32 - iter 54/65 - loss 0.13579425 - samples/sec: 62.29 - lr: 0.000008
2021-07-18 20:19:12,812 epoch 32 - iter 60/65 - loss 0.13563749 - samples/sec: 62.39 - lr: 0.000008
2021-07-18 20:19:15,334 ----------------------------------------------------------------------------------------------------
2021-07-18 20:19:15,335 EPOCH 32 done: loss 0.1371 - lr 0.0000075
2021-07-18 20:19:17,147 DEV : loss 0.16707666218280792 - score 0.9412
2021-07-18 20:19:17,173 BAD EPOCHS (no improvement): 1
2021-07-18 20:19:17,173 ----------------------------------------------------------------------------------------------------
2021-07-18 20:19:20,471 epoch 33 - iter 6/65 - loss 0.14029172 - samples/sec: 58.24 - lr: 0.000008
2021-07-18 20:19:23,544 epoch 33 - iter 12/65 - loss 0.14280557 - samples/sec: 62.48 - lr: 0.000008
2021-07-18 20:19:26,623 epoch 33 - iter 18/65 - loss 0.14177496 - samples/sec: 62.38 - lr: 0.000008
2021-07-18 20:19:29,739 epoch 33 - iter 24/65 - loss 0.14628686 - samples/sec: 61.63 - lr: 0.000008
2021-07-18 20:19:32,798 epoch 33 - iter 30/65 - loss 0.14212397 - samples/sec: 62.79 - lr: 0.000008
2021-07-18 20:19:35,837 epoch 33 - iter 36/65 - loss 0.14156961 - samples/sec: 63.19 - lr: 0.000008
2021-07-18 20:19:38,866 epoch 33 - iter 42/65 - loss 0.13503887 - samples/sec: 63.39 - lr: 0.000008
2021-07-18 20:19:41,940 epoch 33 - iter 48/65 - loss 0.13353755 - samples/sec: 62.49 - lr: 0.000008
2021-07-18 20:19:45,027 epoch 33 - iter 54/65 - loss 0.13296817 - samples/sec: 62.20 - lr: 0.000008
2021-07-18 20:19:48,084 epoch 33 - iter 60/65 - loss 0.13206755 - samples/sec: 62.82 - lr: 0.000008
2021-07-18 20:19:50,639 ----------------------------------------------------------------------------------------------------
2021-07-18 20:19:50,639 EPOCH 33 done: loss 0.1337 - lr 0.0000075
2021-07-18 20:19:52,449 DEV : loss 0.16147327423095703 - score 0.9438
2021-07-18 20:19:52,475 BAD EPOCHS (no improvement): 2
2021-07-18 20:19:52,475 ----------------------------------------------------------------------------------------------------
2021-07-18 20:19:55,574 epoch 34 - iter 6/65 - loss 0.12149204 - samples/sec: 61.97 - lr: 0.000008
2021-07-18 20:19:58,662 epoch 34 - iter 12/65 - loss 0.12304082 - samples/sec: 62.20 - lr: 0.000008
2021-07-18 20:20:01,750 epoch 34 - iter 18/65 - loss 0.11816296 - samples/sec: 62.18 - lr: 0.000008
2021-07-18 20:20:04,810 epoch 34 - iter 24/65 - loss 0.10856297 - samples/sec: 62.75 - lr: 0.000008
2021-07-18 20:20:07,899 epoch 34 - iter 30/65 - loss 0.11888434 - samples/sec: 62.18 - lr: 0.000008
2021-07-18 20:20:10,972 epoch 34 - iter 36/65 - loss 0.12833996 - samples/sec: 62.48 - lr: 0.000008
2021-07-18 20:20:14,047 epoch 34 - iter 42/65 - loss 0.12132632 - samples/sec: 62.46 - lr: 0.000008
2021-07-18 20:20:17,112 epoch 34 - iter 48/65 - loss 0.11838483 - samples/sec: 62.65 - lr: 0.000008
2021-07-18 20:20:20,208 epoch 34 - iter 54/65 - loss 0.11852342 - samples/sec: 62.04 - lr: 0.000008
2021-07-18 20:20:23,258 epoch 34 - iter 60/65 - loss 0.11674783 - samples/sec: 62.97 - lr: 0.000008
2021-07-18 20:20:25,755 ----------------------------------------------------------------------------------------------------
2021-07-18 20:20:25,756 EPOCH 34 done: loss 0.1184 - lr 0.0000075
2021-07-18 20:20:27,564 DEV : loss 0.17589278519153595 - score 0.9443
2021-07-18 20:20:27,590 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:20:33,494 ----------------------------------------------------------------------------------------------------
2021-07-18 20:20:36,562 epoch 35 - iter 6/65 - loss 0.10861342 - samples/sec: 62.60 - lr: 0.000008
2021-07-18 20:20:39,633 epoch 35 - iter 12/65 - loss 0.12538593 - samples/sec: 62.54 - lr: 0.000008
2021-07-18 20:20:42,683 epoch 35 - iter 18/65 - loss 0.12276701 - samples/sec: 62.97 - lr: 0.000008
2021-07-18 20:20:45,790 epoch 35 - iter 24/65 - loss 0.12439629 - samples/sec: 61.81 - lr: 0.000008
2021-07-18 20:20:48,859 epoch 35 - iter 30/65 - loss 0.13195208 - samples/sec: 62.57 - lr: 0.000008
2021-07-18 20:20:51,923 epoch 35 - iter 36/65 - loss 0.13261994 - samples/sec: 62.69 - lr: 0.000008
2021-07-18 20:20:55,003 epoch 35 - iter 42/65 - loss 0.13088878 - samples/sec: 62.33 - lr: 0.000008
2021-07-18 20:20:58,090 epoch 35 - iter 48/65 - loss 0.12655932 - samples/sec: 62.22 - lr: 0.000008
2021-07-18 20:21:01,172 epoch 35 - iter 54/65 - loss 0.12420589 - samples/sec: 62.32 - lr: 0.000008
2021-07-18 20:21:04,242 epoch 35 - iter 60/65 - loss 0.12414364 - samples/sec: 62.54 - lr: 0.000008
2021-07-18 20:21:06,800 ----------------------------------------------------------------------------------------------------
2021-07-18 20:21:06,800 EPOCH 35 done: loss 0.1269 - lr 0.0000075
2021-07-18 20:21:08,607 DEV : loss 0.17305004596710205 - score 0.9466
2021-07-18 20:21:08,633 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:21:13,827 ----------------------------------------------------------------------------------------------------
2021-07-18 20:21:16,857 epoch 36 - iter 6/65 - loss 0.15604537 - samples/sec: 63.39 - lr: 0.000008
2021-07-18 20:21:19,915 epoch 36 - iter 12/65 - loss 0.13682561 - samples/sec: 62.80 - lr: 0.000008
2021-07-18 20:21:22,996 epoch 36 - iter 18/65 - loss 0.13157982 - samples/sec: 62.33 - lr: 0.000008
2021-07-18 20:21:26,076 epoch 36 - iter 24/65 - loss 0.12312321 - samples/sec: 62.36 - lr: 0.000008
2021-07-18 20:21:29,178 epoch 36 - iter 30/65 - loss 0.12286817 - samples/sec: 61.91 - lr: 0.000008
2021-07-18 20:21:32,244 epoch 36 - iter 36/65 - loss 0.12572329 - samples/sec: 62.64 - lr: 0.000008
2021-07-18 20:21:35,331 epoch 36 - iter 42/65 - loss 0.12354332 - samples/sec: 62.21 - lr: 0.000008
2021-07-18 20:21:38,379 epoch 36 - iter 48/65 - loss 0.12549191 - samples/sec: 63.00 - lr: 0.000008
2021-07-18 20:21:41,475 epoch 36 - iter 54/65 - loss 0.12339254 - samples/sec: 62.03 - lr: 0.000008
2021-07-18 20:21:44,562 epoch 36 - iter 60/65 - loss 0.12344023 - samples/sec: 62.21 - lr: 0.000008
2021-07-18 20:21:47,108 ----------------------------------------------------------------------------------------------------
2021-07-18 20:21:47,108 EPOCH 36 done: loss 0.1209 - lr 0.0000075
2021-07-18 20:21:48,915 DEV : loss 0.16999554634094238 - score 0.9466
2021-07-18 20:21:48,941 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:21:54,664 ----------------------------------------------------------------------------------------------------
2021-07-18 20:21:57,728 epoch 37 - iter 6/65 - loss 0.09464822 - samples/sec: 62.68 - lr: 0.000008
2021-07-18 20:22:00,770 epoch 37 - iter 12/65 - loss 0.09340871 - samples/sec: 63.14 - lr: 0.000008
2021-07-18 20:22:03,867 epoch 37 - iter 18/65 - loss 0.10317465 - samples/sec: 62.00 - lr: 0.000008
2021-07-18 20:22:07,166 epoch 37 - iter 24/65 - loss 0.11815936 - samples/sec: 58.22 - lr: 0.000008
2021-07-18 20:22:10,210 epoch 37 - iter 30/65 - loss 0.11289783 - samples/sec: 63.09 - lr: 0.000008
2021-07-18 20:22:13,271 epoch 37 - iter 36/65 - loss 0.11203001 - samples/sec: 62.73 - lr: 0.000008
2021-07-18 20:22:16,358 epoch 37 - iter 42/65 - loss 0.11390973 - samples/sec: 62.21 - lr: 0.000008
2021-07-18 20:22:19,431 epoch 37 - iter 48/65 - loss 0.11438964 - samples/sec: 62.50 - lr: 0.000008
2021-07-18 20:22:22,446 epoch 37 - iter 54/65 - loss 0.11057046 - samples/sec: 63.69 - lr: 0.000008
2021-07-18 20:22:25,552 epoch 37 - iter 60/65 - loss 0.11254649 - samples/sec: 61.84 - lr: 0.000008
2021-07-18 20:22:28,070 ----------------------------------------------------------------------------------------------------
2021-07-18 20:22:28,071 EPOCH 37 done: loss 0.1137 - lr 0.0000075
2021-07-18 20:22:29,887 DEV : loss 0.1639026403427124 - score 0.9438
2021-07-18 20:22:29,913 BAD EPOCHS (no improvement): 1
2021-07-18 20:22:29,913 ----------------------------------------------------------------------------------------------------
2021-07-18 20:22:32,940 epoch 38 - iter 6/65 - loss 0.06805794 - samples/sec: 63.45 - lr: 0.000008
2021-07-18 20:22:35,991 epoch 38 - iter 12/65 - loss 0.09053919 - samples/sec: 62.93 - lr: 0.000008
2021-07-18 20:22:39,019 epoch 38 - iter 18/65 - loss 0.09105967 - samples/sec: 63.42 - lr: 0.000008
2021-07-18 20:22:42,078 epoch 38 - iter 24/65 - loss 0.09731773 - samples/sec: 62.78 - lr: 0.000008
2021-07-18 20:22:45,163 epoch 38 - iter 30/65 - loss 0.11314971 - samples/sec: 62.26 - lr: 0.000008
2021-07-18 20:22:48,219 epoch 38 - iter 36/65 - loss 0.12436608 - samples/sec: 62.85 - lr: 0.000008
2021-07-18 20:22:51,268 epoch 38 - iter 42/65 - loss 0.11879649 - samples/sec: 62.98 - lr: 0.000008
2021-07-18 20:22:54,345 epoch 38 - iter 48/65 - loss 0.11754877 - samples/sec: 62.40 - lr: 0.000008
2021-07-18 20:22:57,418 epoch 38 - iter 54/65 - loss 0.11579582 - samples/sec: 62.50 - lr: 0.000008
2021-07-18 20:23:00,516 epoch 38 - iter 60/65 - loss 0.11772450 - samples/sec: 62.00 - lr: 0.000008
2021-07-18 20:23:03,042 ----------------------------------------------------------------------------------------------------
2021-07-18 20:23:03,043 EPOCH 38 done: loss 0.1156 - lr 0.0000075
2021-07-18 20:23:04,849 DEV : loss 0.17249314486980438 - score 0.9469
2021-07-18 20:23:04,875 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:23:10,229 ----------------------------------------------------------------------------------------------------
2021-07-18 20:23:13,267 epoch 39 - iter 6/65 - loss 0.10772419 - samples/sec: 63.22 - lr: 0.000008
2021-07-18 20:23:16,303 epoch 39 - iter 12/65 - loss 0.09888275 - samples/sec: 63.26 - lr: 0.000008
2021-07-18 20:23:19,322 epoch 39 - iter 18/65 - loss 0.10701653 - samples/sec: 63.59 - lr: 0.000008
2021-07-18 20:23:22,361 epoch 39 - iter 24/65 - loss 0.10502848 - samples/sec: 63.20 - lr: 0.000008
2021-07-18 20:23:25,415 epoch 39 - iter 30/65 - loss 0.10738606 - samples/sec: 62.88 - lr: 0.000008
2021-07-18 20:23:28,453 epoch 39 - iter 36/65 - loss 0.11372787 - samples/sec: 63.22 - lr: 0.000008
2021-07-18 20:23:31,482 epoch 39 - iter 42/65 - loss 0.11559191 - samples/sec: 63.40 - lr: 0.000008
2021-07-18 20:23:34,521 epoch 39 - iter 48/65 - loss 0.11326765 - samples/sec: 63.19 - lr: 0.000008
2021-07-18 20:23:37,564 epoch 39 - iter 54/65 - loss 0.11017697 - samples/sec: 63.11 - lr: 0.000008
2021-07-18 20:23:40,617 epoch 39 - iter 60/65 - loss 0.11039396 - samples/sec: 62.92 - lr: 0.000008
2021-07-18 20:23:43,148 ----------------------------------------------------------------------------------------------------
2021-07-18 20:23:43,148 EPOCH 39 done: loss 0.1119 - lr 0.0000075
2021-07-18 20:23:44,962 DEV : loss 0.17444825172424316 - score 0.9443
2021-07-18 20:23:44,987 BAD EPOCHS (no improvement): 1
2021-07-18 20:23:44,988 ----------------------------------------------------------------------------------------------------
2021-07-18 20:23:48,003 epoch 40 - iter 6/65 - loss 0.14252180 - samples/sec: 63.69 - lr: 0.000008
2021-07-18 20:23:51,001 epoch 40 - iter 12/65 - loss 0.11719472 - samples/sec: 64.06 - lr: 0.000008
2021-07-18 20:23:54,079 epoch 40 - iter 18/65 - loss 0.11667154 - samples/sec: 62.38 - lr: 0.000008
2021-07-18 20:23:57,174 epoch 40 - iter 24/65 - loss 0.11929289 - samples/sec: 62.06 - lr: 0.000008
2021-07-18 20:24:00,250 epoch 40 - iter 30/65 - loss 0.12114862 - samples/sec: 62.43 - lr: 0.000008
2021-07-18 20:24:03,331 epoch 40 - iter 36/65 - loss 0.11565838 - samples/sec: 62.34 - lr: 0.000008
2021-07-18 20:24:06,404 epoch 40 - iter 42/65 - loss 0.11277795 - samples/sec: 62.49 - lr: 0.000008
2021-07-18 20:24:09,486 epoch 40 - iter 48/65 - loss 0.10991261 - samples/sec: 62.31 - lr: 0.000008
2021-07-18 20:24:12,540 epoch 40 - iter 54/65 - loss 0.11140881 - samples/sec: 62.89 - lr: 0.000008
2021-07-18 20:24:15,622 epoch 40 - iter 60/65 - loss 0.11192620 - samples/sec: 62.31 - lr: 0.000008
2021-07-18 20:24:18,135 ----------------------------------------------------------------------------------------------------
2021-07-18 20:24:18,135 EPOCH 40 done: loss 0.1129 - lr 0.0000075
2021-07-18 20:24:19,945 DEV : loss 0.1681046187877655 - score 0.9443
2021-07-18 20:24:19,970 BAD EPOCHS (no improvement): 2
2021-07-18 20:24:21,310 ----------------------------------------------------------------------------------------------------
2021-07-18 20:24:21,310 Testing using best model ...
2021-07-18 20:24:21,310 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/fas.rst.prstc/best-model.pt
2021-07-18 20:24:30,863 0.9353	0.9475	0.9414
2021-07-18 20:24:30,863 
Results:
- F1-score (micro) 0.9414
- F1-score (macro) 0.9414

By class:
SENT       tp: 289 - fp: 20 - fn: 16 - precision: 0.9353 - recall: 0.9475 - f1-score: 0.9414
2021-07-18 20:24:30,863 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/tur.pdtb.tdb/
2021-07-18 20:24:30,886 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/tur.pdtb.tdb
2021-07-18 20:24:30,888 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/tur.pdtb.tdb/sent_train.txt
2021-07-18 20:24:30,890 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/tur.pdtb.tdb/sent_dev.txt
2021-07-18 20:24:30,892 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/tur.pdtb.tdb/sent_test.txt
Corpus: 14258 train + 2347 dev + 4457 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 20:24:42,201 ----------------------------------------------------------------------------------------------------
2021-07-18 20:24:42,203 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(32000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 20:24:42,203 ----------------------------------------------------------------------------------------------------
2021-07-18 20:24:42,203 Corpus: "Corpus: 14258 train + 2347 dev + 4457 test sentences"
2021-07-18 20:24:42,203 ----------------------------------------------------------------------------------------------------
2021-07-18 20:24:42,203 Parameters:
2021-07-18 20:24:42,203  - learning_rate: "3e-05"
2021-07-18 20:24:42,203  - mini_batch_size: "32"
2021-07-18 20:24:42,203  - patience: "3"
2021-07-18 20:24:42,203  - anneal_factor: "0.5"
2021-07-18 20:24:42,203  - max_epochs: "40"
2021-07-18 20:24:42,203  - shuffle: "True"
2021-07-18 20:24:42,203  - train_with_dev: "False"
2021-07-18 20:24:42,203  - batch_growth_annealing: "False"
2021-07-18 20:24:42,203 ----------------------------------------------------------------------------------------------------
2021-07-18 20:24:42,203 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/tur.pdtb.tdb"
2021-07-18 20:24:42,203 ----------------------------------------------------------------------------------------------------
2021-07-18 20:24:42,204 Device: cuda:0
2021-07-18 20:24:42,204 ----------------------------------------------------------------------------------------------------
2021-07-18 20:24:42,204 Embeddings storage mode: cpu
2021-07-18 20:24:42,207 ----------------------------------------------------------------------------------------------------
2021-07-18 20:25:28,541 epoch 1 - iter 44/446 - loss 8.45459340 - samples/sec: 30.39 - lr: 0.000030
2021-07-18 20:26:14,378 epoch 1 - iter 88/446 - loss 5.54340026 - samples/sec: 30.72 - lr: 0.000030
2021-07-18 20:27:00,232 epoch 1 - iter 132/446 - loss 4.19214420 - samples/sec: 30.71 - lr: 0.000030
2021-07-18 20:27:46,398 epoch 1 - iter 176/446 - loss 3.43256094 - samples/sec: 30.50 - lr: 0.000030
2021-07-18 20:28:34,165 epoch 1 - iter 220/446 - loss 2.93946920 - samples/sec: 29.48 - lr: 0.000030
2021-07-18 20:29:20,994 epoch 1 - iter 264/446 - loss 2.59805359 - samples/sec: 30.07 - lr: 0.000030
2021-07-18 20:30:07,906 epoch 1 - iter 308/446 - loss 2.35492073 - samples/sec: 30.02 - lr: 0.000030
2021-07-18 20:30:54,932 epoch 1 - iter 352/446 - loss 2.15361936 - samples/sec: 29.94 - lr: 0.000030
2021-07-18 20:31:41,953 epoch 1 - iter 396/446 - loss 1.99501788 - samples/sec: 29.95 - lr: 0.000030
2021-07-18 20:32:29,316 epoch 1 - iter 440/446 - loss 1.86347762 - samples/sec: 29.73 - lr: 0.000030
2021-07-18 20:32:35,420 ----------------------------------------------------------------------------------------------------
2021-07-18 20:32:35,420 EPOCH 1 done: loss 1.8484 - lr 0.0000300
2021-07-18 20:33:19,518 DEV : loss 0.7493063807487488 - score 0.9304
2021-07-18 20:33:19,692 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:33:20,459 ----------------------------------------------------------------------------------------------------
2021-07-18 20:33:44,334 epoch 2 - iter 44/446 - loss 0.56855995 - samples/sec: 58.98 - lr: 0.000030
2021-07-18 20:34:08,308 epoch 2 - iter 88/446 - loss 0.59247960 - samples/sec: 58.74 - lr: 0.000030
2021-07-18 20:34:32,278 epoch 2 - iter 132/446 - loss 0.58685715 - samples/sec: 58.75 - lr: 0.000030
2021-07-18 20:34:56,268 epoch 2 - iter 176/446 - loss 0.59222001 - samples/sec: 58.70 - lr: 0.000030
2021-07-18 20:35:20,276 epoch 2 - iter 220/446 - loss 0.58283358 - samples/sec: 58.65 - lr: 0.000030
2021-07-18 20:35:44,280 epoch 2 - iter 264/446 - loss 0.57671377 - samples/sec: 58.66 - lr: 0.000030
2021-07-18 20:36:08,219 epoch 2 - iter 308/446 - loss 0.57228309 - samples/sec: 58.82 - lr: 0.000030
2021-07-18 20:36:32,163 epoch 2 - iter 352/446 - loss 0.56745243 - samples/sec: 58.81 - lr: 0.000030
2021-07-18 20:36:56,125 epoch 2 - iter 396/446 - loss 0.56152650 - samples/sec: 58.77 - lr: 0.000030
2021-07-18 20:37:20,114 epoch 2 - iter 440/446 - loss 0.55201753 - samples/sec: 58.70 - lr: 0.000030
2021-07-18 20:37:23,163 ----------------------------------------------------------------------------------------------------
2021-07-18 20:37:23,163 EPOCH 2 done: loss 0.5504 - lr 0.0000300
2021-07-18 20:37:36,409 DEV : loss 0.6797060370445251 - score 0.9355
2021-07-18 20:37:36,587 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:37:40,468 ----------------------------------------------------------------------------------------------------
2021-07-18 20:38:04,256 epoch 3 - iter 44/446 - loss 0.44746827 - samples/sec: 59.20 - lr: 0.000030
2021-07-18 20:38:28,024 epoch 3 - iter 88/446 - loss 0.46285939 - samples/sec: 59.25 - lr: 0.000030
2021-07-18 20:38:51,852 epoch 3 - iter 132/446 - loss 0.45185437 - samples/sec: 59.10 - lr: 0.000030
2021-07-18 20:39:15,626 epoch 3 - iter 176/446 - loss 0.43999522 - samples/sec: 59.23 - lr: 0.000030
2021-07-18 20:39:39,411 epoch 3 - iter 220/446 - loss 0.43639521 - samples/sec: 59.21 - lr: 0.000030
2021-07-18 20:40:03,248 epoch 3 - iter 264/446 - loss 0.43865757 - samples/sec: 59.07 - lr: 0.000030
2021-07-18 20:40:27,043 epoch 3 - iter 308/446 - loss 0.43989533 - samples/sec: 59.18 - lr: 0.000030
2021-07-18 20:40:50,755 epoch 3 - iter 352/446 - loss 0.43950042 - samples/sec: 59.39 - lr: 0.000030
2021-07-18 20:41:14,619 epoch 3 - iter 396/446 - loss 0.44016628 - samples/sec: 59.01 - lr: 0.000030
2021-07-18 20:41:38,499 epoch 3 - iter 440/446 - loss 0.43431026 - samples/sec: 58.97 - lr: 0.000030
2021-07-18 20:41:41,551 ----------------------------------------------------------------------------------------------------
2021-07-18 20:41:41,552 EPOCH 3 done: loss 0.4346 - lr 0.0000300
2021-07-18 20:41:54,725 DEV : loss 0.659922182559967 - score 0.9364
2021-07-18 20:41:54,903 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:41:58,912 ----------------------------------------------------------------------------------------------------
2021-07-18 20:42:22,727 epoch 4 - iter 44/446 - loss 0.39702540 - samples/sec: 59.13 - lr: 0.000030
2021-07-18 20:42:46,595 epoch 4 - iter 88/446 - loss 0.40998083 - samples/sec: 59.00 - lr: 0.000030
2021-07-18 20:43:10,515 epoch 4 - iter 132/446 - loss 0.39097030 - samples/sec: 58.87 - lr: 0.000030
2021-07-18 20:43:34,412 epoch 4 - iter 176/446 - loss 0.37875457 - samples/sec: 58.93 - lr: 0.000030
2021-07-18 20:43:58,251 epoch 4 - iter 220/446 - loss 0.38261745 - samples/sec: 59.07 - lr: 0.000030
2021-07-18 20:44:22,103 epoch 4 - iter 264/446 - loss 0.38042439 - samples/sec: 59.04 - lr: 0.000030
2021-07-18 20:44:45,911 epoch 4 - iter 308/446 - loss 0.38526884 - samples/sec: 59.15 - lr: 0.000030
2021-07-18 20:45:09,671 epoch 4 - iter 352/446 - loss 0.37867931 - samples/sec: 59.27 - lr: 0.000030
2021-07-18 20:45:33,424 epoch 4 - iter 396/446 - loss 0.37818154 - samples/sec: 59.28 - lr: 0.000030
2021-07-18 20:45:57,112 epoch 4 - iter 440/446 - loss 0.37606593 - samples/sec: 59.45 - lr: 0.000030
2021-07-18 20:46:00,137 ----------------------------------------------------------------------------------------------------
2021-07-18 20:46:00,137 EPOCH 4 done: loss 0.3742 - lr 0.0000300
2021-07-18 20:46:13,423 DEV : loss 0.653144121170044 - score 0.943
2021-07-18 20:46:13,598 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:46:17,512 ----------------------------------------------------------------------------------------------------
2021-07-18 20:46:41,199 epoch 5 - iter 44/446 - loss 0.36130224 - samples/sec: 59.45 - lr: 0.000030
2021-07-18 20:47:05,083 epoch 5 - iter 88/446 - loss 0.33432699 - samples/sec: 58.96 - lr: 0.000030
2021-07-18 20:47:30,127 epoch 5 - iter 132/446 - loss 0.34599446 - samples/sec: 56.23 - lr: 0.000030
2021-07-18 20:47:53,924 epoch 5 - iter 176/446 - loss 0.33867393 - samples/sec: 59.17 - lr: 0.000030
2021-07-18 20:48:17,656 epoch 5 - iter 220/446 - loss 0.33896079 - samples/sec: 59.33 - lr: 0.000030
2021-07-18 20:48:41,454 epoch 5 - iter 264/446 - loss 0.33567885 - samples/sec: 59.17 - lr: 0.000030
2021-07-18 20:49:05,403 epoch 5 - iter 308/446 - loss 0.33351230 - samples/sec: 58.80 - lr: 0.000030
2021-07-18 20:49:29,307 epoch 5 - iter 352/446 - loss 0.33071914 - samples/sec: 58.91 - lr: 0.000030
2021-07-18 20:49:53,211 epoch 5 - iter 396/446 - loss 0.33323635 - samples/sec: 58.91 - lr: 0.000030
2021-07-18 20:50:17,110 epoch 5 - iter 440/446 - loss 0.33486241 - samples/sec: 58.92 - lr: 0.000030
2021-07-18 20:50:20,166 ----------------------------------------------------------------------------------------------------
2021-07-18 20:50:20,167 EPOCH 5 done: loss 0.3336 - lr 0.0000300
2021-07-18 20:50:33,463 DEV : loss 0.6389933824539185 - score 0.9437
2021-07-18 20:50:33,642 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:50:37,552 ----------------------------------------------------------------------------------------------------
2021-07-18 20:51:01,460 epoch 6 - iter 44/446 - loss 0.28616811 - samples/sec: 58.90 - lr: 0.000030
2021-07-18 20:51:25,322 epoch 6 - iter 88/446 - loss 0.30009906 - samples/sec: 59.01 - lr: 0.000030
2021-07-18 20:51:49,211 epoch 6 - iter 132/446 - loss 0.30175894 - samples/sec: 58.95 - lr: 0.000030
2021-07-18 20:52:13,058 epoch 6 - iter 176/446 - loss 0.30559817 - samples/sec: 59.05 - lr: 0.000030
2021-07-18 20:52:36,957 epoch 6 - iter 220/446 - loss 0.31607844 - samples/sec: 58.92 - lr: 0.000030
2021-07-18 20:53:00,737 epoch 6 - iter 264/446 - loss 0.30722236 - samples/sec: 59.22 - lr: 0.000030
2021-07-18 20:53:24,427 epoch 6 - iter 308/446 - loss 0.31399375 - samples/sec: 59.44 - lr: 0.000030
2021-07-18 20:53:48,182 epoch 6 - iter 352/446 - loss 0.31599412 - samples/sec: 59.28 - lr: 0.000030
2021-07-18 20:54:11,939 epoch 6 - iter 396/446 - loss 0.31439766 - samples/sec: 59.27 - lr: 0.000030
2021-07-18 20:54:35,649 epoch 6 - iter 440/446 - loss 0.31444531 - samples/sec: 59.39 - lr: 0.000030
2021-07-18 20:54:38,689 ----------------------------------------------------------------------------------------------------
2021-07-18 20:54:38,690 EPOCH 6 done: loss 0.3142 - lr 0.0000300
2021-07-18 20:54:52,016 DEV : loss 0.6647692322731018 - score 0.9416
2021-07-18 20:54:52,192 BAD EPOCHS (no improvement): 1
2021-07-18 20:54:52,193 ----------------------------------------------------------------------------------------------------
2021-07-18 20:55:15,951 epoch 7 - iter 44/446 - loss 0.28014217 - samples/sec: 59.27 - lr: 0.000030
2021-07-18 20:55:39,688 epoch 7 - iter 88/446 - loss 0.27757958 - samples/sec: 59.32 - lr: 0.000030
2021-07-18 20:56:03,435 epoch 7 - iter 132/446 - loss 0.28889682 - samples/sec: 59.30 - lr: 0.000030
2021-07-18 20:56:27,203 epoch 7 - iter 176/446 - loss 0.29621458 - samples/sec: 59.25 - lr: 0.000030
2021-07-18 20:56:50,966 epoch 7 - iter 220/446 - loss 0.28501745 - samples/sec: 59.26 - lr: 0.000030
2021-07-18 20:57:14,686 epoch 7 - iter 264/446 - loss 0.29935690 - samples/sec: 59.36 - lr: 0.000030
2021-07-18 20:57:38,396 epoch 7 - iter 308/446 - loss 0.29651700 - samples/sec: 59.39 - lr: 0.000030
2021-07-18 20:58:02,108 epoch 7 - iter 352/446 - loss 0.29845929 - samples/sec: 59.39 - lr: 0.000030
2021-07-18 20:58:25,851 epoch 7 - iter 396/446 - loss 0.29919733 - samples/sec: 59.31 - lr: 0.000030
2021-07-18 20:58:49,624 epoch 7 - iter 440/446 - loss 0.29634215 - samples/sec: 59.23 - lr: 0.000030
2021-07-18 20:58:52,673 ----------------------------------------------------------------------------------------------------
2021-07-18 20:58:52,673 EPOCH 7 done: loss 0.2958 - lr 0.0000300
2021-07-18 20:59:05,969 DEV : loss 0.6797244548797607 - score 0.9447
2021-07-18 20:59:06,145 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 20:59:09,967 ----------------------------------------------------------------------------------------------------
2021-07-18 20:59:33,906 epoch 8 - iter 44/446 - loss 0.28026284 - samples/sec: 58.83 - lr: 0.000030
2021-07-18 20:59:57,803 epoch 8 - iter 88/446 - loss 0.28067337 - samples/sec: 58.93 - lr: 0.000030
2021-07-18 21:00:22,922 epoch 8 - iter 132/446 - loss 0.27406786 - samples/sec: 56.06 - lr: 0.000030
2021-07-18 21:00:46,790 epoch 8 - iter 176/446 - loss 0.27340939 - samples/sec: 59.00 - lr: 0.000030
2021-07-18 21:01:10,648 epoch 8 - iter 220/446 - loss 0.27809242 - samples/sec: 59.02 - lr: 0.000030
2021-07-18 21:01:34,535 epoch 8 - iter 264/446 - loss 0.27863451 - samples/sec: 58.95 - lr: 0.000030
2021-07-18 21:01:58,411 epoch 8 - iter 308/446 - loss 0.27804353 - samples/sec: 58.98 - lr: 0.000030
2021-07-18 21:02:22,083 epoch 8 - iter 352/446 - loss 0.27649075 - samples/sec: 59.48 - lr: 0.000030
2021-07-18 21:02:45,732 epoch 8 - iter 396/446 - loss 0.27567251 - samples/sec: 59.55 - lr: 0.000030
2021-07-18 21:03:09,343 epoch 8 - iter 440/446 - loss 0.27607945 - samples/sec: 59.64 - lr: 0.000030
2021-07-18 21:03:12,355 ----------------------------------------------------------------------------------------------------
2021-07-18 21:03:12,356 EPOCH 8 done: loss 0.2756 - lr 0.0000300
2021-07-18 21:03:25,664 DEV : loss 0.6704658269882202 - score 0.9442
2021-07-18 21:03:25,842 BAD EPOCHS (no improvement): 1
2021-07-18 21:03:25,842 ----------------------------------------------------------------------------------------------------
2021-07-18 21:03:49,540 epoch 9 - iter 44/446 - loss 0.25349957 - samples/sec: 59.42 - lr: 0.000030
2021-07-18 21:04:13,429 epoch 9 - iter 88/446 - loss 0.25214267 - samples/sec: 58.95 - lr: 0.000030
2021-07-18 21:04:37,320 epoch 9 - iter 132/446 - loss 0.26180647 - samples/sec: 58.94 - lr: 0.000030
2021-07-18 21:05:01,132 epoch 9 - iter 176/446 - loss 0.25122617 - samples/sec: 59.14 - lr: 0.000030
2021-07-18 21:05:24,909 epoch 9 - iter 220/446 - loss 0.25059900 - samples/sec: 59.22 - lr: 0.000030
2021-07-18 21:05:48,548 epoch 9 - iter 264/446 - loss 0.25242872 - samples/sec: 59.57 - lr: 0.000030
2021-07-18 21:06:12,229 epoch 9 - iter 308/446 - loss 0.25291359 - samples/sec: 59.46 - lr: 0.000030
2021-07-18 21:06:35,867 epoch 9 - iter 352/446 - loss 0.25298575 - samples/sec: 59.57 - lr: 0.000030
2021-07-18 21:06:59,588 epoch 9 - iter 396/446 - loss 0.25506987 - samples/sec: 59.36 - lr: 0.000030
2021-07-18 21:07:23,527 epoch 9 - iter 440/446 - loss 0.25913690 - samples/sec: 58.82 - lr: 0.000030
2021-07-18 21:07:26,559 ----------------------------------------------------------------------------------------------------
2021-07-18 21:07:26,559 EPOCH 9 done: loss 0.2592 - lr 0.0000300
2021-07-18 21:07:39,842 DEV : loss 0.6786470413208008 - score 0.9419
2021-07-18 21:07:40,020 BAD EPOCHS (no improvement): 2
2021-07-18 21:07:40,021 ----------------------------------------------------------------------------------------------------
2021-07-18 21:08:03,847 epoch 10 - iter 44/446 - loss 0.26680941 - samples/sec: 59.10 - lr: 0.000030
2021-07-18 21:08:27,723 epoch 10 - iter 88/446 - loss 0.25454917 - samples/sec: 58.98 - lr: 0.000030
2021-07-18 21:08:51,576 epoch 10 - iter 132/446 - loss 0.24676906 - samples/sec: 59.03 - lr: 0.000030
2021-07-18 21:09:15,428 epoch 10 - iter 176/446 - loss 0.24497229 - samples/sec: 59.04 - lr: 0.000030
2021-07-18 21:09:39,274 epoch 10 - iter 220/446 - loss 0.24450074 - samples/sec: 59.05 - lr: 0.000030
2021-07-18 21:10:03,114 epoch 10 - iter 264/446 - loss 0.24839578 - samples/sec: 59.07 - lr: 0.000030
2021-07-18 21:10:26,970 epoch 10 - iter 308/446 - loss 0.24450830 - samples/sec: 59.03 - lr: 0.000030
2021-07-18 21:10:50,823 epoch 10 - iter 352/446 - loss 0.24848050 - samples/sec: 59.03 - lr: 0.000030
2021-07-18 21:11:14,708 epoch 10 - iter 396/446 - loss 0.24992185 - samples/sec: 58.96 - lr: 0.000030
2021-07-18 21:11:38,546 epoch 10 - iter 440/446 - loss 0.24983265 - samples/sec: 59.07 - lr: 0.000030
2021-07-18 21:11:41,585 ----------------------------------------------------------------------------------------------------
2021-07-18 21:11:41,585 EPOCH 10 done: loss 0.2500 - lr 0.0000300
2021-07-18 21:11:54,833 DEV : loss 0.6897023916244507 - score 0.9444
2021-07-18 21:11:55,009 BAD EPOCHS (no improvement): 3
2021-07-18 21:11:55,009 ----------------------------------------------------------------------------------------------------
2021-07-18 21:12:18,860 epoch 11 - iter 44/446 - loss 0.22336912 - samples/sec: 59.04 - lr: 0.000030
2021-07-18 21:12:42,654 epoch 11 - iter 88/446 - loss 0.23132477 - samples/sec: 59.18 - lr: 0.000030
2021-07-18 21:13:07,684 epoch 11 - iter 132/446 - loss 0.21664681 - samples/sec: 56.26 - lr: 0.000030
2021-07-18 21:13:31,575 epoch 11 - iter 176/446 - loss 0.22331967 - samples/sec: 58.94 - lr: 0.000030
2021-07-18 21:13:55,451 epoch 11 - iter 220/446 - loss 0.22172086 - samples/sec: 58.98 - lr: 0.000030
2021-07-18 21:14:19,338 epoch 11 - iter 264/446 - loss 0.22510373 - samples/sec: 58.95 - lr: 0.000030
2021-07-18 21:14:43,159 epoch 11 - iter 308/446 - loss 0.22478818 - samples/sec: 59.11 - lr: 0.000030
2021-07-18 21:15:07,050 epoch 11 - iter 352/446 - loss 0.22796263 - samples/sec: 58.94 - lr: 0.000030
2021-07-18 21:15:30,992 epoch 11 - iter 396/446 - loss 0.22640501 - samples/sec: 58.82 - lr: 0.000030
2021-07-18 21:15:54,835 epoch 11 - iter 440/446 - loss 0.22952718 - samples/sec: 59.06 - lr: 0.000030
2021-07-18 21:15:57,888 ----------------------------------------------------------------------------------------------------
2021-07-18 21:15:57,888 EPOCH 11 done: loss 0.2299 - lr 0.0000300
2021-07-18 21:16:11,131 DEV : loss 0.6980054378509521 - score 0.9451
2021-07-18 21:16:11,310 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 21:16:15,398 ----------------------------------------------------------------------------------------------------
2021-07-18 21:16:39,241 epoch 12 - iter 44/446 - loss 0.19621889 - samples/sec: 59.06 - lr: 0.000030
2021-07-18 21:17:03,103 epoch 12 - iter 88/446 - loss 0.20248872 - samples/sec: 59.01 - lr: 0.000030
2021-07-18 21:17:26,886 epoch 12 - iter 132/446 - loss 0.22288331 - samples/sec: 59.21 - lr: 0.000030
2021-07-18 21:17:50,663 epoch 12 - iter 176/446 - loss 0.22621062 - samples/sec: 59.22 - lr: 0.000030
2021-07-18 21:18:14,424 epoch 12 - iter 220/446 - loss 0.22541806 - samples/sec: 59.26 - lr: 0.000030
2021-07-18 21:18:38,240 epoch 12 - iter 264/446 - loss 0.22342183 - samples/sec: 59.12 - lr: 0.000030
2021-07-18 21:19:02,067 epoch 12 - iter 308/446 - loss 0.22706329 - samples/sec: 59.10 - lr: 0.000030
2021-07-18 21:19:25,914 epoch 12 - iter 352/446 - loss 0.22837006 - samples/sec: 59.05 - lr: 0.000030
2021-07-18 21:19:49,810 epoch 12 - iter 396/446 - loss 0.23136618 - samples/sec: 58.93 - lr: 0.000030
2021-07-18 21:20:13,650 epoch 12 - iter 440/446 - loss 0.22993015 - samples/sec: 59.07 - lr: 0.000030
2021-07-18 21:20:16,697 ----------------------------------------------------------------------------------------------------
2021-07-18 21:20:16,697 EPOCH 12 done: loss 0.2295 - lr 0.0000300
2021-07-18 21:20:29,959 DEV : loss 0.7068195343017578 - score 0.9451
2021-07-18 21:20:30,135 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 21:20:34,037 ----------------------------------------------------------------------------------------------------
2021-07-18 21:20:57,898 epoch 13 - iter 44/446 - loss 0.22117558 - samples/sec: 59.02 - lr: 0.000030
2021-07-18 21:21:21,779 epoch 13 - iter 88/446 - loss 0.21550404 - samples/sec: 58.97 - lr: 0.000030
2021-07-18 21:21:45,622 epoch 13 - iter 132/446 - loss 0.20319131 - samples/sec: 59.06 - lr: 0.000030
2021-07-18 21:22:09,491 epoch 13 - iter 176/446 - loss 0.20378853 - samples/sec: 58.99 - lr: 0.000030
2021-07-18 21:22:33,367 epoch 13 - iter 220/446 - loss 0.20392810 - samples/sec: 58.98 - lr: 0.000030
2021-07-18 21:22:57,200 epoch 13 - iter 264/446 - loss 0.20811651 - samples/sec: 59.08 - lr: 0.000030
2021-07-18 21:23:21,027 epoch 13 - iter 308/446 - loss 0.20589626 - samples/sec: 59.10 - lr: 0.000030
2021-07-18 21:23:44,840 epoch 13 - iter 352/446 - loss 0.20779126 - samples/sec: 59.14 - lr: 0.000030
2021-07-18 21:24:08,678 epoch 13 - iter 396/446 - loss 0.20852468 - samples/sec: 59.07 - lr: 0.000030
2021-07-18 21:24:32,527 epoch 13 - iter 440/446 - loss 0.21216391 - samples/sec: 59.04 - lr: 0.000030
2021-07-18 21:24:35,575 ----------------------------------------------------------------------------------------------------
2021-07-18 21:24:35,575 EPOCH 13 done: loss 0.2119 - lr 0.0000300
2021-07-18 21:24:48,811 DEV : loss 0.6996062397956848 - score 0.9431
2021-07-18 21:24:48,991 BAD EPOCHS (no improvement): 1
2021-07-18 21:24:48,991 ----------------------------------------------------------------------------------------------------
2021-07-18 21:25:12,867 epoch 14 - iter 44/446 - loss 0.18034174 - samples/sec: 58.98 - lr: 0.000030
2021-07-18 21:25:36,716 epoch 14 - iter 88/446 - loss 0.19164624 - samples/sec: 59.04 - lr: 0.000030
2021-07-18 21:26:00,508 epoch 14 - iter 132/446 - loss 0.19813781 - samples/sec: 59.18 - lr: 0.000030
2021-07-18 21:26:24,376 epoch 14 - iter 176/446 - loss 0.20042521 - samples/sec: 59.00 - lr: 0.000030
2021-07-18 21:26:48,211 epoch 14 - iter 220/446 - loss 0.20115057 - samples/sec: 59.08 - lr: 0.000030
2021-07-18 21:27:12,078 epoch 14 - iter 264/446 - loss 0.20430069 - samples/sec: 59.00 - lr: 0.000030
2021-07-18 21:27:35,955 epoch 14 - iter 308/446 - loss 0.20240580 - samples/sec: 58.98 - lr: 0.000030
2021-07-18 21:27:59,818 epoch 14 - iter 352/446 - loss 0.20659644 - samples/sec: 59.01 - lr: 0.000030
2021-07-18 21:28:23,718 epoch 14 - iter 396/446 - loss 0.20827406 - samples/sec: 58.92 - lr: 0.000030
2021-07-18 21:28:47,586 epoch 14 - iter 440/446 - loss 0.20958874 - samples/sec: 59.00 - lr: 0.000030
2021-07-18 21:28:50,616 ----------------------------------------------------------------------------------------------------
2021-07-18 21:28:50,617 EPOCH 14 done: loss 0.2093 - lr 0.0000300
2021-07-18 21:29:05,059 DEV : loss 0.7248491644859314 - score 0.9434
2021-07-18 21:29:05,235 BAD EPOCHS (no improvement): 2
2021-07-18 21:29:05,236 ----------------------------------------------------------------------------------------------------
2021-07-18 21:29:29,084 epoch 15 - iter 44/446 - loss 0.18041282 - samples/sec: 59.05 - lr: 0.000030
2021-07-18 21:29:52,930 epoch 15 - iter 88/446 - loss 0.18733141 - samples/sec: 59.05 - lr: 0.000030
2021-07-18 21:30:16,746 epoch 15 - iter 132/446 - loss 0.19513633 - samples/sec: 59.13 - lr: 0.000030
2021-07-18 21:30:40,628 epoch 15 - iter 176/446 - loss 0.19521929 - samples/sec: 58.96 - lr: 0.000030
2021-07-18 21:31:04,475 epoch 15 - iter 220/446 - loss 0.19422720 - samples/sec: 59.05 - lr: 0.000030
2021-07-18 21:31:28,280 epoch 15 - iter 264/446 - loss 0.19367320 - samples/sec: 59.15 - lr: 0.000030
2021-07-18 21:31:52,022 epoch 15 - iter 308/446 - loss 0.19140085 - samples/sec: 59.31 - lr: 0.000030
2021-07-18 21:32:15,693 epoch 15 - iter 352/446 - loss 0.19271474 - samples/sec: 59.49 - lr: 0.000030
2021-07-18 21:32:39,511 epoch 15 - iter 396/446 - loss 0.19514734 - samples/sec: 59.12 - lr: 0.000030
2021-07-18 21:33:03,427 epoch 15 - iter 440/446 - loss 0.19557111 - samples/sec: 58.88 - lr: 0.000030
2021-07-18 21:33:06,467 ----------------------------------------------------------------------------------------------------
2021-07-18 21:33:06,467 EPOCH 15 done: loss 0.1951 - lr 0.0000300
2021-07-18 21:33:19,710 DEV : loss 0.7205060124397278 - score 0.945
2021-07-18 21:33:19,888 BAD EPOCHS (no improvement): 3
2021-07-18 21:33:19,888 ----------------------------------------------------------------------------------------------------
2021-07-18 21:33:43,743 epoch 16 - iter 44/446 - loss 0.21040159 - samples/sec: 59.03 - lr: 0.000030
2021-07-18 21:34:07,559 epoch 16 - iter 88/446 - loss 0.18188199 - samples/sec: 59.13 - lr: 0.000030
2021-07-18 21:34:31,402 epoch 16 - iter 132/446 - loss 0.19177240 - samples/sec: 59.06 - lr: 0.000030
2021-07-18 21:34:55,239 epoch 16 - iter 176/446 - loss 0.19458689 - samples/sec: 59.07 - lr: 0.000030
2021-07-18 21:35:19,123 epoch 16 - iter 220/446 - loss 0.19252620 - samples/sec: 58.96 - lr: 0.000030
2021-07-18 21:35:43,014 epoch 16 - iter 264/446 - loss 0.18932669 - samples/sec: 58.94 - lr: 0.000030
2021-07-18 21:36:06,869 epoch 16 - iter 308/446 - loss 0.18714157 - samples/sec: 59.03 - lr: 0.000030
2021-07-18 21:36:30,607 epoch 16 - iter 352/446 - loss 0.18763884 - samples/sec: 59.32 - lr: 0.000030
2021-07-18 21:36:54,339 epoch 16 - iter 396/446 - loss 0.18763801 - samples/sec: 59.34 - lr: 0.000030
2021-07-18 21:37:18,147 epoch 16 - iter 440/446 - loss 0.18768101 - samples/sec: 59.14 - lr: 0.000030
2021-07-18 21:37:21,195 ----------------------------------------------------------------------------------------------------
2021-07-18 21:37:21,195 EPOCH 16 done: loss 0.1881 - lr 0.0000300
2021-07-18 21:37:34,393 DEV : loss 0.7255992293357849 - score 0.9444
Epoch    16: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 21:37:34,571 BAD EPOCHS (no improvement): 4
2021-07-18 21:37:34,572 ----------------------------------------------------------------------------------------------------
2021-07-18 21:37:58,271 epoch 17 - iter 44/446 - loss 0.18057417 - samples/sec: 59.42 - lr: 0.000015
2021-07-18 21:38:21,943 epoch 17 - iter 88/446 - loss 0.17588400 - samples/sec: 59.48 - lr: 0.000015
2021-07-18 21:38:45,626 epoch 17 - iter 132/446 - loss 0.17674725 - samples/sec: 59.46 - lr: 0.000015
2021-07-18 21:39:09,440 epoch 17 - iter 176/446 - loss 0.17611218 - samples/sec: 59.13 - lr: 0.000015
2021-07-18 21:39:33,141 epoch 17 - iter 220/446 - loss 0.17382320 - samples/sec: 59.41 - lr: 0.000015
2021-07-18 21:39:56,763 epoch 17 - iter 264/446 - loss 0.17379695 - samples/sec: 59.61 - lr: 0.000015
2021-07-18 21:40:20,352 epoch 17 - iter 308/446 - loss 0.17256236 - samples/sec: 59.70 - lr: 0.000015
2021-07-18 21:40:44,051 epoch 17 - iter 352/446 - loss 0.17228283 - samples/sec: 59.42 - lr: 0.000015
2021-07-18 21:41:07,847 epoch 17 - iter 396/446 - loss 0.17271584 - samples/sec: 59.18 - lr: 0.000015
2021-07-18 21:41:31,432 epoch 17 - iter 440/446 - loss 0.17282789 - samples/sec: 59.71 - lr: 0.000015
2021-07-18 21:41:34,460 ----------------------------------------------------------------------------------------------------
2021-07-18 21:41:34,461 EPOCH 17 done: loss 0.1725 - lr 0.0000150
2021-07-18 21:41:48,907 DEV : loss 0.7266553640365601 - score 0.9443
2021-07-18 21:41:49,086 BAD EPOCHS (no improvement): 1
2021-07-18 21:41:49,087 ----------------------------------------------------------------------------------------------------
2021-07-18 21:42:12,884 epoch 18 - iter 44/446 - loss 0.16673078 - samples/sec: 59.17 - lr: 0.000015
2021-07-18 21:42:36,779 epoch 18 - iter 88/446 - loss 0.16673000 - samples/sec: 58.93 - lr: 0.000015
2021-07-18 21:43:00,477 epoch 18 - iter 132/446 - loss 0.16415547 - samples/sec: 59.42 - lr: 0.000015
2021-07-18 21:43:24,034 epoch 18 - iter 176/446 - loss 0.16421620 - samples/sec: 59.78 - lr: 0.000015
2021-07-18 21:43:47,653 epoch 18 - iter 220/446 - loss 0.16848398 - samples/sec: 59.62 - lr: 0.000015
2021-07-18 21:44:11,322 epoch 18 - iter 264/446 - loss 0.16695955 - samples/sec: 59.50 - lr: 0.000015
2021-07-18 21:44:34,950 epoch 18 - iter 308/446 - loss 0.17126716 - samples/sec: 59.59 - lr: 0.000015
2021-07-18 21:44:58,533 epoch 18 - iter 352/446 - loss 0.16883234 - samples/sec: 59.71 - lr: 0.000015
2021-07-18 21:45:22,383 epoch 18 - iter 396/446 - loss 0.16940220 - samples/sec: 59.04 - lr: 0.000015
2021-07-18 21:45:46,233 epoch 18 - iter 440/446 - loss 0.17015095 - samples/sec: 59.04 - lr: 0.000015
2021-07-18 21:45:49,263 ----------------------------------------------------------------------------------------------------
2021-07-18 21:45:49,263 EPOCH 18 done: loss 0.1695 - lr 0.0000150
2021-07-18 21:46:02,479 DEV : loss 0.7368990778923035 - score 0.9452
2021-07-18 21:46:02,658 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 21:46:06,547 ----------------------------------------------------------------------------------------------------
2021-07-18 21:46:30,442 epoch 19 - iter 44/446 - loss 0.15307087 - samples/sec: 58.93 - lr: 0.000015
2021-07-18 21:46:54,299 epoch 19 - iter 88/446 - loss 0.16189431 - samples/sec: 59.02 - lr: 0.000015
2021-07-18 21:47:18,153 epoch 19 - iter 132/446 - loss 0.16604099 - samples/sec: 59.03 - lr: 0.000015
2021-07-18 21:47:42,054 epoch 19 - iter 176/446 - loss 0.16141051 - samples/sec: 58.92 - lr: 0.000015
2021-07-18 21:48:05,859 epoch 19 - iter 220/446 - loss 0.16340046 - samples/sec: 59.15 - lr: 0.000015
2021-07-18 21:48:29,725 epoch 19 - iter 264/446 - loss 0.16368622 - samples/sec: 59.00 - lr: 0.000015
2021-07-18 21:48:53,568 epoch 19 - iter 308/446 - loss 0.16414292 - samples/sec: 59.06 - lr: 0.000015
2021-07-18 21:49:17,464 epoch 19 - iter 352/446 - loss 0.16684394 - samples/sec: 58.93 - lr: 0.000015
2021-07-18 21:49:41,296 epoch 19 - iter 396/446 - loss 0.16705954 - samples/sec: 59.09 - lr: 0.000015
2021-07-18 21:50:05,203 epoch 19 - iter 440/446 - loss 0.16608841 - samples/sec: 58.90 - lr: 0.000015
2021-07-18 21:50:08,243 ----------------------------------------------------------------------------------------------------
2021-07-18 21:50:08,244 EPOCH 19 done: loss 0.1652 - lr 0.0000150
2021-07-18 21:50:21,474 DEV : loss 0.7415094971656799 - score 0.9447
2021-07-18 21:50:21,653 BAD EPOCHS (no improvement): 1
2021-07-18 21:50:21,653 ----------------------------------------------------------------------------------------------------
2021-07-18 21:50:45,533 epoch 20 - iter 44/446 - loss 0.15922627 - samples/sec: 58.97 - lr: 0.000015
2021-07-18 21:51:09,202 epoch 20 - iter 88/446 - loss 0.16135214 - samples/sec: 59.49 - lr: 0.000015
2021-07-18 21:51:33,025 epoch 20 - iter 132/446 - loss 0.15584780 - samples/sec: 59.11 - lr: 0.000015
2021-07-18 21:51:56,939 epoch 20 - iter 176/446 - loss 0.15753132 - samples/sec: 58.88 - lr: 0.000015
2021-07-18 21:52:20,823 epoch 20 - iter 220/446 - loss 0.16063788 - samples/sec: 58.96 - lr: 0.000015
2021-07-18 21:52:44,708 epoch 20 - iter 264/446 - loss 0.16112472 - samples/sec: 58.96 - lr: 0.000015
2021-07-18 21:53:08,567 epoch 20 - iter 308/446 - loss 0.15936701 - samples/sec: 59.02 - lr: 0.000015
2021-07-18 21:53:32,436 epoch 20 - iter 352/446 - loss 0.16109264 - samples/sec: 59.00 - lr: 0.000015
2021-07-18 21:53:56,231 epoch 20 - iter 396/446 - loss 0.16271192 - samples/sec: 59.18 - lr: 0.000015
2021-07-18 21:54:20,103 epoch 20 - iter 440/446 - loss 0.15963533 - samples/sec: 58.99 - lr: 0.000015
2021-07-18 21:54:23,167 ----------------------------------------------------------------------------------------------------
2021-07-18 21:54:23,167 EPOCH 20 done: loss 0.1586 - lr 0.0000150
2021-07-18 21:54:37,680 DEV : loss 0.7525427937507629 - score 0.9449
2021-07-18 21:54:37,860 BAD EPOCHS (no improvement): 2
2021-07-18 21:54:37,861 ----------------------------------------------------------------------------------------------------
2021-07-18 21:55:01,706 epoch 21 - iter 44/446 - loss 0.14387862 - samples/sec: 59.05 - lr: 0.000015
2021-07-18 21:55:25,560 epoch 21 - iter 88/446 - loss 0.15118863 - samples/sec: 59.03 - lr: 0.000015
2021-07-18 21:55:49,346 epoch 21 - iter 132/446 - loss 0.15484947 - samples/sec: 59.20 - lr: 0.000015
2021-07-18 21:56:13,258 epoch 21 - iter 176/446 - loss 0.16449296 - samples/sec: 58.89 - lr: 0.000015
2021-07-18 21:56:37,096 epoch 21 - iter 220/446 - loss 0.16679100 - samples/sec: 59.07 - lr: 0.000015
2021-07-18 21:57:01,002 epoch 21 - iter 264/446 - loss 0.16202146 - samples/sec: 58.90 - lr: 0.000015
2021-07-18 21:57:24,867 epoch 21 - iter 308/446 - loss 0.16098172 - samples/sec: 59.01 - lr: 0.000015
2021-07-18 21:57:48,674 epoch 21 - iter 352/446 - loss 0.15941822 - samples/sec: 59.15 - lr: 0.000015
2021-07-18 21:58:12,443 epoch 21 - iter 396/446 - loss 0.15741547 - samples/sec: 59.24 - lr: 0.000015
2021-07-18 21:58:36,220 epoch 21 - iter 440/446 - loss 0.15668756 - samples/sec: 59.22 - lr: 0.000015
2021-07-18 21:58:39,264 ----------------------------------------------------------------------------------------------------
2021-07-18 21:58:39,264 EPOCH 21 done: loss 0.1565 - lr 0.0000150
2021-07-18 21:58:52,495 DEV : loss 0.7562628984451294 - score 0.9455
2021-07-18 21:58:52,674 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 21:58:56,578 ----------------------------------------------------------------------------------------------------
2021-07-18 21:59:20,336 epoch 22 - iter 44/446 - loss 0.13749513 - samples/sec: 59.27 - lr: 0.000015
2021-07-18 21:59:44,070 epoch 22 - iter 88/446 - loss 0.14387266 - samples/sec: 59.33 - lr: 0.000015
2021-07-18 22:00:07,895 epoch 22 - iter 132/446 - loss 0.14025891 - samples/sec: 59.10 - lr: 0.000015
2021-07-18 22:00:31,686 epoch 22 - iter 176/446 - loss 0.14578558 - samples/sec: 59.19 - lr: 0.000015
2021-07-18 22:00:55,440 epoch 22 - iter 220/446 - loss 0.14754518 - samples/sec: 59.28 - lr: 0.000015
2021-07-18 22:01:19,091 epoch 22 - iter 264/446 - loss 0.15131609 - samples/sec: 59.54 - lr: 0.000015
2021-07-18 22:01:42,920 epoch 22 - iter 308/446 - loss 0.15273156 - samples/sec: 59.09 - lr: 0.000015
2021-07-18 22:02:06,758 epoch 22 - iter 352/446 - loss 0.15535840 - samples/sec: 59.07 - lr: 0.000015
2021-07-18 22:02:30,683 epoch 22 - iter 396/446 - loss 0.15615282 - samples/sec: 58.86 - lr: 0.000015
2021-07-18 22:02:54,555 epoch 22 - iter 440/446 - loss 0.15481650 - samples/sec: 58.99 - lr: 0.000015
2021-07-18 22:02:57,609 ----------------------------------------------------------------------------------------------------
2021-07-18 22:02:57,609 EPOCH 22 done: loss 0.1547 - lr 0.0000150
2021-07-18 22:03:10,847 DEV : loss 0.7618439793586731 - score 0.9459
2021-07-18 22:03:11,028 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 22:03:15,058 ----------------------------------------------------------------------------------------------------
2021-07-18 22:03:38,876 epoch 23 - iter 44/446 - loss 0.13867098 - samples/sec: 59.12 - lr: 0.000015
2021-07-18 22:04:02,762 epoch 23 - iter 88/446 - loss 0.13081901 - samples/sec: 58.95 - lr: 0.000015
2021-07-18 22:04:26,616 epoch 23 - iter 132/446 - loss 0.14234613 - samples/sec: 59.03 - lr: 0.000015
2021-07-18 22:04:50,450 epoch 23 - iter 176/446 - loss 0.14613598 - samples/sec: 59.08 - lr: 0.000015
2021-07-18 22:05:14,299 epoch 23 - iter 220/446 - loss 0.14959502 - samples/sec: 59.05 - lr: 0.000015
2021-07-18 22:05:38,218 epoch 23 - iter 264/446 - loss 0.15175028 - samples/sec: 58.87 - lr: 0.000015
2021-07-18 22:06:02,086 epoch 23 - iter 308/446 - loss 0.14926534 - samples/sec: 59.00 - lr: 0.000015
2021-07-18 22:06:25,983 epoch 23 - iter 352/446 - loss 0.14972162 - samples/sec: 58.93 - lr: 0.000015
2021-07-18 22:06:49,868 epoch 23 - iter 396/446 - loss 0.15157546 - samples/sec: 58.96 - lr: 0.000015
2021-07-18 22:07:13,609 epoch 23 - iter 440/446 - loss 0.15040371 - samples/sec: 59.31 - lr: 0.000015
2021-07-18 22:07:16,622 ----------------------------------------------------------------------------------------------------
2021-07-18 22:07:16,622 EPOCH 23 done: loss 0.1502 - lr 0.0000150
2021-07-18 22:07:29,917 DEV : loss 0.758437991142273 - score 0.9448
2021-07-18 22:07:30,099 BAD EPOCHS (no improvement): 1
2021-07-18 22:07:30,099 ----------------------------------------------------------------------------------------------------
2021-07-18 22:07:53,882 epoch 24 - iter 44/446 - loss 0.14709042 - samples/sec: 59.21 - lr: 0.000015
2021-07-18 22:08:17,711 epoch 24 - iter 88/446 - loss 0.13790787 - samples/sec: 59.09 - lr: 0.000015
2021-07-18 22:08:41,639 epoch 24 - iter 132/446 - loss 0.13494107 - samples/sec: 58.85 - lr: 0.000015
2021-07-18 22:09:05,590 epoch 24 - iter 176/446 - loss 0.13832899 - samples/sec: 58.79 - lr: 0.000015
2021-07-18 22:09:29,447 epoch 24 - iter 220/446 - loss 0.14398559 - samples/sec: 59.02 - lr: 0.000015
2021-07-18 22:09:53,329 epoch 24 - iter 264/446 - loss 0.14223417 - samples/sec: 58.96 - lr: 0.000015
2021-07-18 22:10:17,162 epoch 24 - iter 308/446 - loss 0.14151622 - samples/sec: 59.08 - lr: 0.000015
2021-07-18 22:10:42,302 epoch 24 - iter 352/446 - loss 0.14625261 - samples/sec: 56.01 - lr: 0.000015
2021-07-18 22:11:06,177 epoch 24 - iter 396/446 - loss 0.14511348 - samples/sec: 58.98 - lr: 0.000015
2021-07-18 22:11:29,992 epoch 24 - iter 440/446 - loss 0.14632602 - samples/sec: 59.13 - lr: 0.000015
2021-07-18 22:11:33,048 ----------------------------------------------------------------------------------------------------
2021-07-18 22:11:33,048 EPOCH 24 done: loss 0.1454 - lr 0.0000150
2021-07-18 22:11:46,249 DEV : loss 0.7656832933425903 - score 0.945
2021-07-18 22:11:46,426 BAD EPOCHS (no improvement): 2
2021-07-18 22:11:46,426 ----------------------------------------------------------------------------------------------------
2021-07-18 22:12:10,274 epoch 25 - iter 44/446 - loss 0.13572852 - samples/sec: 59.05 - lr: 0.000015
2021-07-18 22:12:34,071 epoch 25 - iter 88/446 - loss 0.13297733 - samples/sec: 59.18 - lr: 0.000015
2021-07-18 22:12:57,955 epoch 25 - iter 132/446 - loss 0.13500003 - samples/sec: 58.96 - lr: 0.000015
2021-07-18 22:13:21,794 epoch 25 - iter 176/446 - loss 0.13370130 - samples/sec: 59.07 - lr: 0.000015
2021-07-18 22:13:45,683 epoch 25 - iter 220/446 - loss 0.13532229 - samples/sec: 58.95 - lr: 0.000015
2021-07-18 22:14:09,528 epoch 25 - iter 264/446 - loss 0.13722356 - samples/sec: 59.06 - lr: 0.000015
2021-07-18 22:14:33,414 epoch 25 - iter 308/446 - loss 0.13826663 - samples/sec: 58.95 - lr: 0.000015
2021-07-18 22:14:57,271 epoch 25 - iter 352/446 - loss 0.13856482 - samples/sec: 59.02 - lr: 0.000015
2021-07-18 22:15:21,143 epoch 25 - iter 396/446 - loss 0.13835543 - samples/sec: 58.99 - lr: 0.000015
2021-07-18 22:15:45,071 epoch 25 - iter 440/446 - loss 0.14021452 - samples/sec: 58.85 - lr: 0.000015
2021-07-18 22:15:48,108 ----------------------------------------------------------------------------------------------------
2021-07-18 22:15:48,109 EPOCH 25 done: loss 0.1399 - lr 0.0000150
2021-07-18 22:16:01,309 DEV : loss 0.7746251225471497 - score 0.9442
2021-07-18 22:16:01,487 BAD EPOCHS (no improvement): 3
2021-07-18 22:16:01,487 ----------------------------------------------------------------------------------------------------
2021-07-18 22:16:25,380 epoch 26 - iter 44/446 - loss 0.13035459 - samples/sec: 58.94 - lr: 0.000015
2021-07-18 22:16:49,219 epoch 26 - iter 88/446 - loss 0.13209311 - samples/sec: 59.07 - lr: 0.000015
2021-07-18 22:17:13,048 epoch 26 - iter 132/446 - loss 0.13120598 - samples/sec: 59.09 - lr: 0.000015
2021-07-18 22:17:36,938 epoch 26 - iter 176/446 - loss 0.12903192 - samples/sec: 58.94 - lr: 0.000015
2021-07-18 22:18:00,858 epoch 26 - iter 220/446 - loss 0.12792661 - samples/sec: 58.87 - lr: 0.000015
2021-07-18 22:18:24,721 epoch 26 - iter 264/446 - loss 0.13010853 - samples/sec: 59.01 - lr: 0.000015
2021-07-18 22:18:48,447 epoch 26 - iter 308/446 - loss 0.13786063 - samples/sec: 59.35 - lr: 0.000015
2021-07-18 22:19:12,171 epoch 26 - iter 352/446 - loss 0.13926560 - samples/sec: 59.35 - lr: 0.000015
2021-07-18 22:19:35,930 epoch 26 - iter 396/446 - loss 0.13930791 - samples/sec: 59.27 - lr: 0.000015
2021-07-18 22:19:59,755 epoch 26 - iter 440/446 - loss 0.14064886 - samples/sec: 59.10 - lr: 0.000015
2021-07-18 22:20:02,787 ----------------------------------------------------------------------------------------------------
2021-07-18 22:20:02,787 EPOCH 26 done: loss 0.1402 - lr 0.0000150
2021-07-18 22:20:15,993 DEV : loss 0.7750165462493896 - score 0.9449
Epoch    26: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 22:20:16,173 BAD EPOCHS (no improvement): 4
2021-07-18 22:20:16,173 ----------------------------------------------------------------------------------------------------
2021-07-18 22:20:39,966 epoch 27 - iter 44/446 - loss 0.11624779 - samples/sec: 59.18 - lr: 0.000008
2021-07-18 22:21:03,755 epoch 27 - iter 88/446 - loss 0.13473216 - samples/sec: 59.19 - lr: 0.000008
2021-07-18 22:21:27,515 epoch 27 - iter 132/446 - loss 0.13192689 - samples/sec: 59.27 - lr: 0.000008
2021-07-18 22:21:51,168 epoch 27 - iter 176/446 - loss 0.13438358 - samples/sec: 59.53 - lr: 0.000008
2021-07-18 22:22:14,866 epoch 27 - iter 220/446 - loss 0.13325550 - samples/sec: 59.42 - lr: 0.000008
2021-07-18 22:22:38,655 epoch 27 - iter 264/446 - loss 0.13163529 - samples/sec: 59.19 - lr: 0.000008
2021-07-18 22:23:02,452 epoch 27 - iter 308/446 - loss 0.13230093 - samples/sec: 59.17 - lr: 0.000008
2021-07-18 22:23:26,243 epoch 27 - iter 352/446 - loss 0.13280294 - samples/sec: 59.19 - lr: 0.000008
2021-07-18 22:23:50,037 epoch 27 - iter 396/446 - loss 0.13371445 - samples/sec: 59.18 - lr: 0.000008
2021-07-18 22:24:13,928 epoch 27 - iter 440/446 - loss 0.13355146 - samples/sec: 58.94 - lr: 0.000008
2021-07-18 22:24:16,946 ----------------------------------------------------------------------------------------------------
2021-07-18 22:24:16,947 EPOCH 27 done: loss 0.1336 - lr 0.0000075
2021-07-18 22:24:31,375 DEV : loss 0.7809708714485168 - score 0.945
2021-07-18 22:24:31,555 BAD EPOCHS (no improvement): 1
2021-07-18 22:24:31,556 ----------------------------------------------------------------------------------------------------
2021-07-18 22:24:55,454 epoch 28 - iter 44/446 - loss 0.11640069 - samples/sec: 58.92 - lr: 0.000008
2021-07-18 22:25:19,378 epoch 28 - iter 88/446 - loss 0.12303591 - samples/sec: 58.86 - lr: 0.000008
2021-07-18 22:25:43,179 epoch 28 - iter 132/446 - loss 0.12619965 - samples/sec: 59.16 - lr: 0.000008
2021-07-18 22:26:07,086 epoch 28 - iter 176/446 - loss 0.12841498 - samples/sec: 58.90 - lr: 0.000008
2021-07-18 22:26:30,937 epoch 28 - iter 220/446 - loss 0.13098723 - samples/sec: 59.04 - lr: 0.000008
2021-07-18 22:26:54,738 epoch 28 - iter 264/446 - loss 0.13460476 - samples/sec: 59.16 - lr: 0.000008
2021-07-18 22:27:18,576 epoch 28 - iter 308/446 - loss 0.13339256 - samples/sec: 59.07 - lr: 0.000008
2021-07-18 22:27:42,439 epoch 28 - iter 352/446 - loss 0.13236733 - samples/sec: 59.01 - lr: 0.000008
2021-07-18 22:28:06,339 epoch 28 - iter 396/446 - loss 0.13111713 - samples/sec: 58.92 - lr: 0.000008
2021-07-18 22:28:30,218 epoch 28 - iter 440/446 - loss 0.13010319 - samples/sec: 58.97 - lr: 0.000008
2021-07-18 22:28:33,268 ----------------------------------------------------------------------------------------------------
2021-07-18 22:28:33,268 EPOCH 28 done: loss 0.1301 - lr 0.0000075
2021-07-18 22:28:46,460 DEV : loss 0.7849529385566711 - score 0.9465
2021-07-18 22:28:46,641 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 22:28:50,525 ----------------------------------------------------------------------------------------------------
2021-07-18 22:29:14,215 epoch 29 - iter 44/446 - loss 0.11439908 - samples/sec: 59.44 - lr: 0.000008
2021-07-18 22:29:37,935 epoch 29 - iter 88/446 - loss 0.12206090 - samples/sec: 59.37 - lr: 0.000008
2021-07-18 22:30:01,637 epoch 29 - iter 132/446 - loss 0.12350544 - samples/sec: 59.41 - lr: 0.000008
2021-07-18 22:30:25,358 epoch 29 - iter 176/446 - loss 0.12986650 - samples/sec: 59.36 - lr: 0.000008
2021-07-18 22:30:49,123 epoch 29 - iter 220/446 - loss 0.12731702 - samples/sec: 59.25 - lr: 0.000008
2021-07-18 22:31:12,922 epoch 29 - iter 264/446 - loss 0.12999508 - samples/sec: 59.17 - lr: 0.000008
2021-07-18 22:31:36,680 epoch 29 - iter 308/446 - loss 0.12831079 - samples/sec: 59.27 - lr: 0.000008
2021-07-18 22:32:00,475 epoch 29 - iter 352/446 - loss 0.13122385 - samples/sec: 59.18 - lr: 0.000008
2021-07-18 22:32:24,315 epoch 29 - iter 396/446 - loss 0.12971998 - samples/sec: 59.06 - lr: 0.000008
2021-07-18 22:32:48,095 epoch 29 - iter 440/446 - loss 0.13046035 - samples/sec: 59.22 - lr: 0.000008
2021-07-18 22:32:51,119 ----------------------------------------------------------------------------------------------------
2021-07-18 22:32:51,119 EPOCH 29 done: loss 0.1312 - lr 0.0000075
2021-07-18 22:33:04,323 DEV : loss 0.7828337550163269 - score 0.9461
2021-07-18 22:33:04,502 BAD EPOCHS (no improvement): 1
2021-07-18 22:33:04,503 ----------------------------------------------------------------------------------------------------
2021-07-18 22:33:28,267 epoch 30 - iter 44/446 - loss 0.12251473 - samples/sec: 59.26 - lr: 0.000008
2021-07-18 22:33:52,091 epoch 30 - iter 88/446 - loss 0.12724140 - samples/sec: 59.10 - lr: 0.000008
2021-07-18 22:34:15,938 epoch 30 - iter 132/446 - loss 0.12836883 - samples/sec: 59.05 - lr: 0.000008
2021-07-18 22:34:39,734 epoch 30 - iter 176/446 - loss 0.12220307 - samples/sec: 59.18 - lr: 0.000008
2021-07-18 22:35:03,541 epoch 30 - iter 220/446 - loss 0.12672158 - samples/sec: 59.15 - lr: 0.000008
2021-07-18 22:35:27,344 epoch 30 - iter 264/446 - loss 0.12747585 - samples/sec: 59.16 - lr: 0.000008
2021-07-18 22:35:51,155 epoch 30 - iter 308/446 - loss 0.12796265 - samples/sec: 59.14 - lr: 0.000008
2021-07-18 22:36:14,966 epoch 30 - iter 352/446 - loss 0.12723483 - samples/sec: 59.14 - lr: 0.000008
2021-07-18 22:36:38,750 epoch 30 - iter 396/446 - loss 0.12598171 - samples/sec: 59.21 - lr: 0.000008
2021-07-18 22:37:02,549 epoch 30 - iter 440/446 - loss 0.12446269 - samples/sec: 59.17 - lr: 0.000008
2021-07-18 22:37:05,584 ----------------------------------------------------------------------------------------------------
2021-07-18 22:37:05,584 EPOCH 30 done: loss 0.1248 - lr 0.0000075
2021-07-18 22:37:20,092 DEV : loss 0.7940992712974548 - score 0.9463
2021-07-18 22:37:20,272 BAD EPOCHS (no improvement): 2
2021-07-18 22:37:20,272 ----------------------------------------------------------------------------------------------------
2021-07-18 22:37:44,033 epoch 31 - iter 44/446 - loss 0.10100720 - samples/sec: 59.26 - lr: 0.000008
2021-07-18 22:38:07,879 epoch 31 - iter 88/446 - loss 0.11829009 - samples/sec: 59.05 - lr: 0.000008
2021-07-18 22:38:31,804 epoch 31 - iter 132/446 - loss 0.11629919 - samples/sec: 58.86 - lr: 0.000008
2021-07-18 22:38:55,672 epoch 31 - iter 176/446 - loss 0.11745001 - samples/sec: 59.00 - lr: 0.000008
2021-07-18 22:39:19,622 epoch 31 - iter 220/446 - loss 0.12193913 - samples/sec: 58.79 - lr: 0.000008
2021-07-18 22:39:43,507 epoch 31 - iter 264/446 - loss 0.12378924 - samples/sec: 58.96 - lr: 0.000008
2021-07-18 22:40:07,376 epoch 31 - iter 308/446 - loss 0.12718965 - samples/sec: 58.99 - lr: 0.000008
2021-07-18 22:40:31,246 epoch 31 - iter 352/446 - loss 0.12890892 - samples/sec: 58.99 - lr: 0.000008
2021-07-18 22:40:55,179 epoch 31 - iter 396/446 - loss 0.12837770 - samples/sec: 58.84 - lr: 0.000008
2021-07-18 22:41:19,058 epoch 31 - iter 440/446 - loss 0.12692916 - samples/sec: 58.97 - lr: 0.000008
2021-07-18 22:41:22,084 ----------------------------------------------------------------------------------------------------
2021-07-18 22:41:22,084 EPOCH 31 done: loss 0.1268 - lr 0.0000075
2021-07-18 22:41:35,281 DEV : loss 0.7969733476638794 - score 0.9463
2021-07-18 22:41:35,462 BAD EPOCHS (no improvement): 3
2021-07-18 22:41:35,462 ----------------------------------------------------------------------------------------------------
2021-07-18 22:41:59,346 epoch 32 - iter 44/446 - loss 0.14060433 - samples/sec: 58.96 - lr: 0.000008
2021-07-18 22:42:23,224 epoch 32 - iter 88/446 - loss 0.12759660 - samples/sec: 58.97 - lr: 0.000008
2021-07-18 22:42:47,039 epoch 32 - iter 132/446 - loss 0.12286317 - samples/sec: 59.13 - lr: 0.000008
2021-07-18 22:43:10,887 epoch 32 - iter 176/446 - loss 0.12543680 - samples/sec: 59.05 - lr: 0.000008
2021-07-18 22:43:34,759 epoch 32 - iter 220/446 - loss 0.12885192 - samples/sec: 58.99 - lr: 0.000008
2021-07-18 22:43:58,604 epoch 32 - iter 264/446 - loss 0.12595735 - samples/sec: 59.05 - lr: 0.000008
2021-07-18 22:44:22,499 epoch 32 - iter 308/446 - loss 0.12698848 - samples/sec: 58.93 - lr: 0.000008
2021-07-18 22:44:46,395 epoch 32 - iter 352/446 - loss 0.12540772 - samples/sec: 58.93 - lr: 0.000008
2021-07-18 22:45:10,234 epoch 32 - iter 396/446 - loss 0.12337857 - samples/sec: 59.07 - lr: 0.000008
2021-07-18 22:45:34,159 epoch 32 - iter 440/446 - loss 0.12425781 - samples/sec: 58.86 - lr: 0.000008
2021-07-18 22:45:37,195 ----------------------------------------------------------------------------------------------------
2021-07-18 22:45:37,195 EPOCH 32 done: loss 0.1239 - lr 0.0000075
2021-07-18 22:45:50,403 DEV : loss 0.808245837688446 - score 0.9457
Epoch    32: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 22:45:50,580 BAD EPOCHS (no improvement): 4
2021-07-18 22:45:50,581 ----------------------------------------------------------------------------------------------------
2021-07-18 22:46:14,487 epoch 33 - iter 44/446 - loss 0.12239223 - samples/sec: 58.90 - lr: 0.000004
2021-07-18 22:46:38,307 epoch 33 - iter 88/446 - loss 0.11791414 - samples/sec: 59.12 - lr: 0.000004
2021-07-18 22:47:02,107 epoch 33 - iter 132/446 - loss 0.12285050 - samples/sec: 59.17 - lr: 0.000004
2021-07-18 22:47:25,808 epoch 33 - iter 176/446 - loss 0.12472664 - samples/sec: 59.41 - lr: 0.000004
2021-07-18 22:47:49,712 epoch 33 - iter 220/446 - loss 0.12325875 - samples/sec: 58.91 - lr: 0.000004
2021-07-18 22:48:13,583 epoch 33 - iter 264/446 - loss 0.12020154 - samples/sec: 58.99 - lr: 0.000004
2021-07-18 22:48:37,424 epoch 33 - iter 308/446 - loss 0.11726155 - samples/sec: 59.06 - lr: 0.000004
2021-07-18 22:49:01,240 epoch 33 - iter 352/446 - loss 0.11822224 - samples/sec: 59.13 - lr: 0.000004
2021-07-18 22:49:25,042 epoch 33 - iter 396/446 - loss 0.11605585 - samples/sec: 59.16 - lr: 0.000004
2021-07-18 22:49:48,819 epoch 33 - iter 440/446 - loss 0.11704939 - samples/sec: 59.22 - lr: 0.000004
2021-07-18 22:49:51,856 ----------------------------------------------------------------------------------------------------
2021-07-18 22:49:51,857 EPOCH 33 done: loss 0.1166 - lr 0.0000038
2021-07-18 22:50:05,066 DEV : loss 0.807674765586853 - score 0.9463
2021-07-18 22:50:05,245 BAD EPOCHS (no improvement): 1
2021-07-18 22:50:05,245 ----------------------------------------------------------------------------------------------------
2021-07-18 22:50:29,101 epoch 34 - iter 44/446 - loss 0.11436409 - samples/sec: 59.03 - lr: 0.000004
2021-07-18 22:50:52,840 epoch 34 - iter 88/446 - loss 0.11998596 - samples/sec: 59.32 - lr: 0.000004
2021-07-18 22:51:16,603 epoch 34 - iter 132/446 - loss 0.11440383 - samples/sec: 59.26 - lr: 0.000004
2021-07-18 22:51:40,299 epoch 34 - iter 176/446 - loss 0.11669306 - samples/sec: 59.43 - lr: 0.000004
2021-07-18 22:52:04,078 epoch 34 - iter 220/446 - loss 0.11626755 - samples/sec: 59.22 - lr: 0.000004
2021-07-18 22:52:27,850 epoch 34 - iter 264/446 - loss 0.11732885 - samples/sec: 59.24 - lr: 0.000004
2021-07-18 22:52:51,609 epoch 34 - iter 308/446 - loss 0.11665068 - samples/sec: 59.27 - lr: 0.000004
2021-07-18 22:53:15,358 epoch 34 - iter 352/446 - loss 0.11652313 - samples/sec: 59.29 - lr: 0.000004
2021-07-18 22:53:39,111 epoch 34 - iter 396/446 - loss 0.11937005 - samples/sec: 59.28 - lr: 0.000004
2021-07-18 22:54:02,895 epoch 34 - iter 440/446 - loss 0.11909595 - samples/sec: 59.21 - lr: 0.000004
2021-07-18 22:54:05,927 ----------------------------------------------------------------------------------------------------
2021-07-18 22:54:05,927 EPOCH 34 done: loss 0.1190 - lr 0.0000038
2021-07-18 22:54:20,417 DEV : loss 0.8058483004570007 - score 0.9456
2021-07-18 22:54:20,597 BAD EPOCHS (no improvement): 2
2021-07-18 22:54:20,598 ----------------------------------------------------------------------------------------------------
2021-07-18 22:54:44,414 epoch 35 - iter 44/446 - loss 0.12991335 - samples/sec: 59.13 - lr: 0.000004
2021-07-18 22:55:08,186 epoch 35 - iter 88/446 - loss 0.11537974 - samples/sec: 59.24 - lr: 0.000004
2021-07-18 22:55:31,983 epoch 35 - iter 132/446 - loss 0.11888490 - samples/sec: 59.17 - lr: 0.000004
2021-07-18 22:55:55,760 epoch 35 - iter 176/446 - loss 0.12048959 - samples/sec: 59.22 - lr: 0.000004
2021-07-18 22:56:19,548 epoch 35 - iter 220/446 - loss 0.11899893 - samples/sec: 59.20 - lr: 0.000004
2021-07-18 22:56:43,330 epoch 35 - iter 264/446 - loss 0.11883456 - samples/sec: 59.21 - lr: 0.000004
2021-07-18 22:57:07,160 epoch 35 - iter 308/446 - loss 0.11838374 - samples/sec: 59.09 - lr: 0.000004
2021-07-18 22:57:30,983 epoch 35 - iter 352/446 - loss 0.12094871 - samples/sec: 59.11 - lr: 0.000004
2021-07-18 22:57:54,900 epoch 35 - iter 396/446 - loss 0.12078971 - samples/sec: 58.88 - lr: 0.000004
2021-07-18 22:58:18,803 epoch 35 - iter 440/446 - loss 0.12088248 - samples/sec: 58.91 - lr: 0.000004
2021-07-18 22:58:21,835 ----------------------------------------------------------------------------------------------------
2021-07-18 22:58:21,835 EPOCH 35 done: loss 0.1216 - lr 0.0000038
2021-07-18 22:58:35,014 DEV : loss 0.8016971349716187 - score 0.9463
2021-07-18 22:58:35,193 BAD EPOCHS (no improvement): 3
2021-07-18 22:58:35,193 ----------------------------------------------------------------------------------------------------
2021-07-18 22:58:59,102 epoch 36 - iter 44/446 - loss 0.09889788 - samples/sec: 58.90 - lr: 0.000004
2021-07-18 22:59:22,991 epoch 36 - iter 88/446 - loss 0.10740072 - samples/sec: 58.95 - lr: 0.000004
2021-07-18 22:59:46,933 epoch 36 - iter 132/446 - loss 0.11081961 - samples/sec: 58.82 - lr: 0.000004
2021-07-18 23:00:10,794 epoch 36 - iter 176/446 - loss 0.11868951 - samples/sec: 59.01 - lr: 0.000004
2021-07-18 23:00:34,683 epoch 36 - iter 220/446 - loss 0.11819112 - samples/sec: 58.94 - lr: 0.000004
2021-07-18 23:00:58,640 epoch 36 - iter 264/446 - loss 0.11680319 - samples/sec: 58.78 - lr: 0.000004
2021-07-18 23:01:22,500 epoch 36 - iter 308/446 - loss 0.11382797 - samples/sec: 59.02 - lr: 0.000004
2021-07-18 23:01:46,348 epoch 36 - iter 352/446 - loss 0.11523998 - samples/sec: 59.05 - lr: 0.000004
2021-07-18 23:02:10,284 epoch 36 - iter 396/446 - loss 0.11515805 - samples/sec: 58.83 - lr: 0.000004
2021-07-18 23:02:34,203 epoch 36 - iter 440/446 - loss 0.11486545 - samples/sec: 58.87 - lr: 0.000004
2021-07-18 23:02:37,261 ----------------------------------------------------------------------------------------------------
2021-07-18 23:02:37,261 EPOCH 36 done: loss 0.1151 - lr 0.0000038
2021-07-18 23:02:50,477 DEV : loss 0.8098646402359009 - score 0.9464
Epoch    36: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 23:02:50,655 BAD EPOCHS (no improvement): 4
2021-07-18 23:02:50,656 ----------------------------------------------------------------------------------------------------
2021-07-18 23:02:50,656 ----------------------------------------------------------------------------------------------------
2021-07-18 23:02:50,656 learning rate too small - quitting training!
2021-07-18 23:02:50,656 ----------------------------------------------------------------------------------------------------
2021-07-18 23:02:51,432 ----------------------------------------------------------------------------------------------------
2021-07-18 23:02:51,432 Testing using best model ...
2021-07-18 23:02:51,433 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/tur.pdtb.tdb/best-model.pt
2021-07-18 23:04:08,640 0.9603	0.9740	0.9671
2021-07-18 23:04:08,640 
Results:
- F1-score (micro) 0.9671
- F1-score (macro) 0.9671

By class:
SENT       tp: 4868 - fp: 201 - fn: 130 - precision: 0.9603 - recall: 0.9740 - f1-score: 0.9671
2021-07-18 23:04:08,640 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.sdrt.stac/
2021-07-18 23:04:08,660 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.sdrt.stac
2021-07-18 23:04:08,660 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.sdrt.stac/sent_train.txt
2021-07-18 23:04:08,662 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.sdrt.stac/sent_dev.txt
2021-07-18 23:04:08,664 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.sdrt.stac/sent_test.txt
Corpus: 1521 train + 228 dev + 451 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 23:04:11,318 ----------------------------------------------------------------------------------------------------
2021-07-18 23:04:11,319 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 23:04:11,319 ----------------------------------------------------------------------------------------------------
2021-07-18 23:04:11,319 Corpus: "Corpus: 1521 train + 228 dev + 451 test sentences"
2021-07-18 23:04:11,319 ----------------------------------------------------------------------------------------------------
2021-07-18 23:04:11,319 Parameters:
2021-07-18 23:04:11,319  - learning_rate: "3e-05"
2021-07-18 23:04:11,319  - mini_batch_size: "32"
2021-07-18 23:04:11,320  - patience: "3"
2021-07-18 23:04:11,320  - anneal_factor: "0.5"
2021-07-18 23:04:11,320  - max_epochs: "40"
2021-07-18 23:04:11,320  - shuffle: "True"
2021-07-18 23:04:11,320  - train_with_dev: "False"
2021-07-18 23:04:11,320  - batch_growth_annealing: "False"
2021-07-18 23:04:11,320 ----------------------------------------------------------------------------------------------------
2021-07-18 23:04:11,320 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.sdrt.stac"
2021-07-18 23:04:11,320 ----------------------------------------------------------------------------------------------------
2021-07-18 23:04:11,320 Device: cuda:0
2021-07-18 23:04:11,320 ----------------------------------------------------------------------------------------------------
2021-07-18 23:04:11,320 Embeddings storage mode: cpu
2021-07-18 23:04:11,322 ----------------------------------------------------------------------------------------------------
2021-07-18 23:04:15,288 epoch 1 - iter 4/48 - loss 41.58816147 - samples/sec: 32.29 - lr: 0.000030
2021-07-18 23:04:19,275 epoch 1 - iter 8/48 - loss 35.89358449 - samples/sec: 32.11 - lr: 0.000030
2021-07-18 23:04:23,262 epoch 1 - iter 12/48 - loss 31.30152591 - samples/sec: 32.11 - lr: 0.000030
2021-07-18 23:04:27,260 epoch 1 - iter 16/48 - loss 27.81663585 - samples/sec: 32.02 - lr: 0.000030
2021-07-18 23:04:31,264 epoch 1 - iter 20/48 - loss 25.17532430 - samples/sec: 31.97 - lr: 0.000030
2021-07-18 23:04:35,257 epoch 1 - iter 24/48 - loss 23.03497334 - samples/sec: 32.06 - lr: 0.000030
2021-07-18 23:04:39,280 epoch 1 - iter 28/48 - loss 21.30762536 - samples/sec: 31.83 - lr: 0.000030
2021-07-18 23:04:43,280 epoch 1 - iter 32/48 - loss 19.88279915 - samples/sec: 32.00 - lr: 0.000030
2021-07-18 23:04:47,268 epoch 1 - iter 36/48 - loss 18.66222241 - samples/sec: 32.09 - lr: 0.000030
2021-07-18 23:04:51,265 epoch 1 - iter 40/48 - loss 17.63393002 - samples/sec: 32.03 - lr: 0.000030
2021-07-18 23:04:55,264 epoch 1 - iter 44/48 - loss 16.78184550 - samples/sec: 32.01 - lr: 0.000030
2021-07-18 23:04:58,810 epoch 1 - iter 48/48 - loss 16.01934194 - samples/sec: 36.11 - lr: 0.000030
2021-07-18 23:04:58,810 ----------------------------------------------------------------------------------------------------
2021-07-18 23:04:58,810 EPOCH 1 done: loss 16.0193 - lr 0.0000300
2021-07-18 23:05:02,847 DEV : loss 6.74504280090332 - score 0.6518
2021-07-18 23:05:02,864 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:05:03,679 ----------------------------------------------------------------------------------------------------
2021-07-18 23:05:05,702 epoch 2 - iter 4/48 - loss 6.90685463 - samples/sec: 63.31 - lr: 0.000030
2021-07-18 23:05:07,737 epoch 2 - iter 8/48 - loss 6.88617986 - samples/sec: 62.92 - lr: 0.000030
2021-07-18 23:05:09,763 epoch 2 - iter 12/48 - loss 6.91362170 - samples/sec: 63.18 - lr: 0.000030
2021-07-18 23:05:11,805 epoch 2 - iter 16/48 - loss 6.80935061 - samples/sec: 62.71 - lr: 0.000030
2021-07-18 23:05:13,828 epoch 2 - iter 20/48 - loss 6.69381185 - samples/sec: 63.31 - lr: 0.000030
2021-07-18 23:05:15,863 epoch 2 - iter 24/48 - loss 6.67825282 - samples/sec: 62.90 - lr: 0.000030
2021-07-18 23:05:17,912 epoch 2 - iter 28/48 - loss 6.64215514 - samples/sec: 62.51 - lr: 0.000030
2021-07-18 23:05:19,968 epoch 2 - iter 32/48 - loss 6.61483666 - samples/sec: 62.25 - lr: 0.000030
2021-07-18 23:05:22,029 epoch 2 - iter 36/48 - loss 6.57825577 - samples/sec: 62.13 - lr: 0.000030
2021-07-18 23:05:24,083 epoch 2 - iter 40/48 - loss 6.53002112 - samples/sec: 62.32 - lr: 0.000030
2021-07-18 23:05:26,138 epoch 2 - iter 44/48 - loss 6.46247175 - samples/sec: 62.31 - lr: 0.000030
2021-07-18 23:05:27,971 epoch 2 - iter 48/48 - loss 6.42917120 - samples/sec: 69.87 - lr: 0.000030
2021-07-18 23:05:27,971 ----------------------------------------------------------------------------------------------------
2021-07-18 23:05:27,971 EPOCH 2 done: loss 6.4292 - lr 0.0000300
2021-07-18 23:05:29,215 DEV : loss 5.233912944793701 - score 0.7579
2021-07-18 23:05:29,232 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:05:33,163 ----------------------------------------------------------------------------------------------------
2021-07-18 23:05:35,208 epoch 3 - iter 4/48 - loss 5.61771142 - samples/sec: 62.61 - lr: 0.000030
2021-07-18 23:05:37,259 epoch 3 - iter 8/48 - loss 5.40217233 - samples/sec: 62.44 - lr: 0.000030
2021-07-18 23:05:39,312 epoch 3 - iter 12/48 - loss 5.43396791 - samples/sec: 62.35 - lr: 0.000030
2021-07-18 23:05:41,364 epoch 3 - iter 16/48 - loss 5.50769773 - samples/sec: 62.40 - lr: 0.000030
2021-07-18 23:05:43,423 epoch 3 - iter 20/48 - loss 5.54822297 - samples/sec: 62.17 - lr: 0.000030
2021-07-18 23:05:45,460 epoch 3 - iter 24/48 - loss 5.61009407 - samples/sec: 62.86 - lr: 0.000030
2021-07-18 23:05:47,494 epoch 3 - iter 28/48 - loss 5.60871415 - samples/sec: 62.95 - lr: 0.000030
2021-07-18 23:05:49,543 epoch 3 - iter 32/48 - loss 5.64586188 - samples/sec: 62.48 - lr: 0.000030
2021-07-18 23:05:51,583 epoch 3 - iter 36/48 - loss 5.62706445 - samples/sec: 62.78 - lr: 0.000030
2021-07-18 23:05:53,632 epoch 3 - iter 40/48 - loss 5.62783921 - samples/sec: 62.50 - lr: 0.000030
2021-07-18 23:05:55,684 epoch 3 - iter 44/48 - loss 5.63971316 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 23:05:57,510 epoch 3 - iter 48/48 - loss 5.60898788 - samples/sec: 70.14 - lr: 0.000030
2021-07-18 23:05:57,510 ----------------------------------------------------------------------------------------------------
2021-07-18 23:05:57,510 EPOCH 3 done: loss 5.6090 - lr 0.0000300
2021-07-18 23:05:58,745 DEV : loss 4.673155784606934 - score 0.7835
2021-07-18 23:05:58,763 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:06:02,782 ----------------------------------------------------------------------------------------------------
2021-07-18 23:06:04,808 epoch 4 - iter 4/48 - loss 5.18913198 - samples/sec: 63.21 - lr: 0.000030
2021-07-18 23:06:06,836 epoch 4 - iter 8/48 - loss 5.37390941 - samples/sec: 63.14 - lr: 0.000030
2021-07-18 23:06:08,887 epoch 4 - iter 12/48 - loss 5.56028485 - samples/sec: 62.41 - lr: 0.000030
2021-07-18 23:06:10,928 epoch 4 - iter 16/48 - loss 5.40440014 - samples/sec: 62.74 - lr: 0.000030
2021-07-18 23:06:12,986 epoch 4 - iter 20/48 - loss 5.43465481 - samples/sec: 62.22 - lr: 0.000030
2021-07-18 23:06:15,032 epoch 4 - iter 24/48 - loss 5.39915160 - samples/sec: 62.58 - lr: 0.000030
2021-07-18 23:06:17,081 epoch 4 - iter 28/48 - loss 5.34949914 - samples/sec: 62.49 - lr: 0.000030
2021-07-18 23:06:19,141 epoch 4 - iter 32/48 - loss 5.34774928 - samples/sec: 62.16 - lr: 0.000030
2021-07-18 23:06:21,180 epoch 4 - iter 36/48 - loss 5.37528110 - samples/sec: 62.79 - lr: 0.000030
2021-07-18 23:06:23,223 epoch 4 - iter 40/48 - loss 5.37910599 - samples/sec: 62.67 - lr: 0.000030
2021-07-18 23:06:25,272 epoch 4 - iter 44/48 - loss 5.38124348 - samples/sec: 62.49 - lr: 0.000030
2021-07-18 23:06:27,108 epoch 4 - iter 48/48 - loss 5.37749054 - samples/sec: 69.75 - lr: 0.000030
2021-07-18 23:06:27,108 ----------------------------------------------------------------------------------------------------
2021-07-18 23:06:27,108 EPOCH 4 done: loss 5.3775 - lr 0.0000300
2021-07-18 23:06:28,344 DEV : loss 4.551337718963623 - score 0.7861
2021-07-18 23:06:28,362 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:06:32,294 ----------------------------------------------------------------------------------------------------
2021-07-18 23:06:34,353 epoch 5 - iter 4/48 - loss 5.19583154 - samples/sec: 62.19 - lr: 0.000030
2021-07-18 23:06:36,380 epoch 5 - iter 8/48 - loss 5.07134134 - samples/sec: 63.19 - lr: 0.000030
2021-07-18 23:06:38,423 epoch 5 - iter 12/48 - loss 5.07158573 - samples/sec: 62.65 - lr: 0.000030
2021-07-18 23:06:40,485 epoch 5 - iter 16/48 - loss 4.95824143 - samples/sec: 62.09 - lr: 0.000030
2021-07-18 23:06:42,519 epoch 5 - iter 20/48 - loss 4.98097587 - samples/sec: 62.94 - lr: 0.000030
2021-07-18 23:06:44,579 epoch 5 - iter 24/48 - loss 5.06576713 - samples/sec: 62.16 - lr: 0.000030
2021-07-18 23:06:46,631 epoch 5 - iter 28/48 - loss 5.08077526 - samples/sec: 62.40 - lr: 0.000030
2021-07-18 23:06:48,690 epoch 5 - iter 32/48 - loss 5.09819412 - samples/sec: 62.18 - lr: 0.000030
2021-07-18 23:06:50,719 epoch 5 - iter 36/48 - loss 5.14668940 - samples/sec: 63.10 - lr: 0.000030
2021-07-18 23:06:52,743 epoch 5 - iter 40/48 - loss 5.16422250 - samples/sec: 63.28 - lr: 0.000030
2021-07-18 23:06:54,772 epoch 5 - iter 44/48 - loss 5.19527345 - samples/sec: 63.08 - lr: 0.000030
2021-07-18 23:06:56,610 epoch 5 - iter 48/48 - loss 5.15989700 - samples/sec: 69.69 - lr: 0.000030
2021-07-18 23:06:56,610 ----------------------------------------------------------------------------------------------------
2021-07-18 23:06:56,610 EPOCH 5 done: loss 5.1599 - lr 0.0000300
2021-07-18 23:06:57,845 DEV : loss 4.3594255447387695 - score 0.7931
2021-07-18 23:06:57,862 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:07:01,704 ----------------------------------------------------------------------------------------------------
2021-07-18 23:07:03,748 epoch 6 - iter 4/48 - loss 5.24807501 - samples/sec: 62.66 - lr: 0.000030
2021-07-18 23:07:05,793 epoch 6 - iter 8/48 - loss 5.05341047 - samples/sec: 62.59 - lr: 0.000030
2021-07-18 23:07:07,842 epoch 6 - iter 12/48 - loss 5.11818035 - samples/sec: 62.51 - lr: 0.000030
2021-07-18 23:07:09,879 epoch 6 - iter 16/48 - loss 5.05920649 - samples/sec: 62.83 - lr: 0.000030
2021-07-18 23:07:11,923 epoch 6 - iter 20/48 - loss 5.05618041 - samples/sec: 62.64 - lr: 0.000030
2021-07-18 23:07:13,967 epoch 6 - iter 24/48 - loss 5.05853383 - samples/sec: 62.66 - lr: 0.000030
2021-07-18 23:07:16,024 epoch 6 - iter 28/48 - loss 5.01805583 - samples/sec: 62.24 - lr: 0.000030
2021-07-18 23:07:18,071 epoch 6 - iter 32/48 - loss 4.99867409 - samples/sec: 62.55 - lr: 0.000030
2021-07-18 23:07:20,123 epoch 6 - iter 36/48 - loss 4.98785962 - samples/sec: 62.39 - lr: 0.000030
2021-07-18 23:07:22,151 epoch 6 - iter 40/48 - loss 4.96868794 - samples/sec: 63.14 - lr: 0.000030
2021-07-18 23:07:24,209 epoch 6 - iter 44/48 - loss 4.99428336 - samples/sec: 62.19 - lr: 0.000030
2021-07-18 23:07:26,041 epoch 6 - iter 48/48 - loss 4.99352910 - samples/sec: 69.90 - lr: 0.000030
2021-07-18 23:07:26,042 ----------------------------------------------------------------------------------------------------
2021-07-18 23:07:26,042 EPOCH 6 done: loss 4.9935 - lr 0.0000300
2021-07-18 23:07:27,279 DEV : loss 4.395444393157959 - score 0.8039
2021-07-18 23:07:27,296 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:07:31,168 ----------------------------------------------------------------------------------------------------
2021-07-18 23:07:33,212 epoch 7 - iter 4/48 - loss 5.07575524 - samples/sec: 62.65 - lr: 0.000030
2021-07-18 23:07:35,266 epoch 7 - iter 8/48 - loss 4.88240993 - samples/sec: 62.31 - lr: 0.000030
2021-07-18 23:07:37,325 epoch 7 - iter 12/48 - loss 4.83054165 - samples/sec: 62.21 - lr: 0.000030
2021-07-18 23:07:39,358 epoch 7 - iter 16/48 - loss 4.78495419 - samples/sec: 62.98 - lr: 0.000030
2021-07-18 23:07:41,398 epoch 7 - iter 20/48 - loss 4.83280070 - samples/sec: 62.75 - lr: 0.000030
2021-07-18 23:07:43,451 epoch 7 - iter 24/48 - loss 4.84780987 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 23:07:45,500 epoch 7 - iter 28/48 - loss 4.86151666 - samples/sec: 62.48 - lr: 0.000030
2021-07-18 23:07:47,541 epoch 7 - iter 32/48 - loss 4.85919200 - samples/sec: 62.72 - lr: 0.000030
2021-07-18 23:07:49,583 epoch 7 - iter 36/48 - loss 4.87687945 - samples/sec: 62.71 - lr: 0.000030
2021-07-18 23:07:51,617 epoch 7 - iter 40/48 - loss 4.85570170 - samples/sec: 62.95 - lr: 0.000030
2021-07-18 23:07:53,660 epoch 7 - iter 44/48 - loss 4.86053713 - samples/sec: 62.67 - lr: 0.000030
2021-07-18 23:07:55,491 epoch 7 - iter 48/48 - loss 4.83240297 - samples/sec: 69.93 - lr: 0.000030
2021-07-18 23:07:55,491 ----------------------------------------------------------------------------------------------------
2021-07-18 23:07:55,492 EPOCH 7 done: loss 4.8324 - lr 0.0000300
2021-07-18 23:07:56,725 DEV : loss 4.187537670135498 - score 0.8119
2021-07-18 23:07:56,743 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:08:00,689 ----------------------------------------------------------------------------------------------------
2021-07-18 23:08:02,738 epoch 8 - iter 4/48 - loss 4.33096623 - samples/sec: 62.49 - lr: 0.000030
2021-07-18 23:08:04,788 epoch 8 - iter 8/48 - loss 4.66099632 - samples/sec: 62.45 - lr: 0.000030
2021-07-18 23:08:06,820 epoch 8 - iter 12/48 - loss 4.63323208 - samples/sec: 63.00 - lr: 0.000030
2021-07-18 23:08:08,873 epoch 8 - iter 16/48 - loss 4.74977368 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 23:08:10,931 epoch 8 - iter 20/48 - loss 4.75657241 - samples/sec: 62.22 - lr: 0.000030
2021-07-18 23:08:12,986 epoch 8 - iter 24/48 - loss 4.76739591 - samples/sec: 62.30 - lr: 0.000030
2021-07-18 23:08:15,026 epoch 8 - iter 28/48 - loss 4.80030145 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 23:08:17,076 epoch 8 - iter 32/48 - loss 4.75861172 - samples/sec: 62.46 - lr: 0.000030
2021-07-18 23:08:19,118 epoch 8 - iter 36/48 - loss 4.74797057 - samples/sec: 62.71 - lr: 0.000030
2021-07-18 23:08:21,164 epoch 8 - iter 40/48 - loss 4.76723356 - samples/sec: 62.57 - lr: 0.000030
2021-07-18 23:08:23,199 epoch 8 - iter 44/48 - loss 4.75477474 - samples/sec: 62.93 - lr: 0.000030
2021-07-18 23:08:25,027 epoch 8 - iter 48/48 - loss 4.75089585 - samples/sec: 70.04 - lr: 0.000030
2021-07-18 23:08:25,027 ----------------------------------------------------------------------------------------------------
2021-07-18 23:08:25,027 EPOCH 8 done: loss 4.7509 - lr 0.0000300
2021-07-18 23:08:26,260 DEV : loss 4.294879913330078 - score 0.8113
2021-07-18 23:08:26,278 BAD EPOCHS (no improvement): 1
2021-07-18 23:08:26,278 ----------------------------------------------------------------------------------------------------
2021-07-18 23:08:28,314 epoch 9 - iter 4/48 - loss 4.63460720 - samples/sec: 62.90 - lr: 0.000030
2021-07-18 23:08:30,369 epoch 9 - iter 8/48 - loss 4.69035536 - samples/sec: 62.31 - lr: 0.000030
2021-07-18 23:08:32,414 epoch 9 - iter 12/48 - loss 4.72473530 - samples/sec: 62.61 - lr: 0.000030
2021-07-18 23:08:34,448 epoch 9 - iter 16/48 - loss 4.77481842 - samples/sec: 62.94 - lr: 0.000030
2021-07-18 23:08:36,495 epoch 9 - iter 20/48 - loss 4.78134069 - samples/sec: 62.56 - lr: 0.000030
2021-07-18 23:08:38,531 epoch 9 - iter 24/48 - loss 4.73439801 - samples/sec: 62.88 - lr: 0.000030
2021-07-18 23:08:40,566 epoch 9 - iter 28/48 - loss 4.73553056 - samples/sec: 62.92 - lr: 0.000030
2021-07-18 23:08:42,606 epoch 9 - iter 32/48 - loss 4.70597871 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 23:08:44,651 epoch 9 - iter 36/48 - loss 4.65631135 - samples/sec: 62.61 - lr: 0.000030
2021-07-18 23:08:46,699 epoch 9 - iter 40/48 - loss 4.64939900 - samples/sec: 62.52 - lr: 0.000030
2021-07-18 23:08:48,748 epoch 9 - iter 44/48 - loss 4.66490262 - samples/sec: 62.49 - lr: 0.000030
2021-07-18 23:08:50,578 epoch 9 - iter 48/48 - loss 4.64682314 - samples/sec: 69.96 - lr: 0.000030
2021-07-18 23:08:50,579 ----------------------------------------------------------------------------------------------------
2021-07-18 23:08:50,579 EPOCH 9 done: loss 4.6468 - lr 0.0000300
2021-07-18 23:08:51,817 DEV : loss 4.127617835998535 - score 0.8231
2021-07-18 23:08:51,834 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:08:55,227 ----------------------------------------------------------------------------------------------------
2021-07-18 23:08:57,269 epoch 10 - iter 4/48 - loss 4.45657420 - samples/sec: 62.73 - lr: 0.000030
2021-07-18 23:08:59,310 epoch 10 - iter 8/48 - loss 4.61355591 - samples/sec: 62.71 - lr: 0.000030
2021-07-18 23:09:01,359 epoch 10 - iter 12/48 - loss 4.60580218 - samples/sec: 62.51 - lr: 0.000030
2021-07-18 23:09:03,418 epoch 10 - iter 16/48 - loss 4.64323181 - samples/sec: 62.18 - lr: 0.000030
2021-07-18 23:09:05,475 epoch 10 - iter 20/48 - loss 4.68612955 - samples/sec: 62.24 - lr: 0.000030
2021-07-18 23:09:07,522 epoch 10 - iter 24/48 - loss 4.70938156 - samples/sec: 62.54 - lr: 0.000030
2021-07-18 23:09:09,566 epoch 10 - iter 28/48 - loss 4.70815323 - samples/sec: 62.65 - lr: 0.000030
2021-07-18 23:09:11,619 epoch 10 - iter 32/48 - loss 4.69092758 - samples/sec: 62.36 - lr: 0.000030
2021-07-18 23:09:13,663 epoch 10 - iter 36/48 - loss 4.68413787 - samples/sec: 62.66 - lr: 0.000030
2021-07-18 23:09:15,712 epoch 10 - iter 40/48 - loss 4.67159346 - samples/sec: 62.49 - lr: 0.000030
2021-07-18 23:09:17,758 epoch 10 - iter 44/48 - loss 4.62819863 - samples/sec: 62.56 - lr: 0.000030
2021-07-18 23:09:19,595 epoch 10 - iter 48/48 - loss 4.61875229 - samples/sec: 69.73 - lr: 0.000030
2021-07-18 23:09:19,595 ----------------------------------------------------------------------------------------------------
2021-07-18 23:09:19,595 EPOCH 10 done: loss 4.6188 - lr 0.0000300
2021-07-18 23:09:20,833 DEV : loss 4.145187854766846 - score 0.8218
2021-07-18 23:09:20,851 BAD EPOCHS (no improvement): 1
2021-07-18 23:09:20,851 ----------------------------------------------------------------------------------------------------
2021-07-18 23:09:22,882 epoch 11 - iter 4/48 - loss 4.52925551 - samples/sec: 63.03 - lr: 0.000030
2021-07-18 23:09:24,937 epoch 11 - iter 8/48 - loss 4.54803491 - samples/sec: 62.33 - lr: 0.000030
2021-07-18 23:09:26,988 epoch 11 - iter 12/48 - loss 4.53781327 - samples/sec: 62.41 - lr: 0.000030
2021-07-18 23:09:29,029 epoch 11 - iter 16/48 - loss 4.55948550 - samples/sec: 62.74 - lr: 0.000030
2021-07-18 23:09:31,088 epoch 11 - iter 20/48 - loss 4.56875818 - samples/sec: 62.18 - lr: 0.000030
2021-07-18 23:09:33,146 epoch 11 - iter 24/48 - loss 4.63278556 - samples/sec: 62.21 - lr: 0.000030
2021-07-18 23:09:35,208 epoch 11 - iter 28/48 - loss 4.61045780 - samples/sec: 62.12 - lr: 0.000030
2021-07-18 23:09:37,227 epoch 11 - iter 32/48 - loss 4.58800223 - samples/sec: 63.41 - lr: 0.000030
2021-07-18 23:09:39,279 epoch 11 - iter 36/48 - loss 4.56232899 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 23:09:41,324 epoch 11 - iter 40/48 - loss 4.54414967 - samples/sec: 62.62 - lr: 0.000030
2021-07-18 23:09:43,368 epoch 11 - iter 44/48 - loss 4.52393990 - samples/sec: 62.64 - lr: 0.000030
2021-07-18 23:09:45,200 epoch 11 - iter 48/48 - loss 4.52755766 - samples/sec: 69.90 - lr: 0.000030
2021-07-18 23:09:45,200 ----------------------------------------------------------------------------------------------------
2021-07-18 23:09:45,200 EPOCH 11 done: loss 4.5276 - lr 0.0000300
2021-07-18 23:09:46,435 DEV : loss 4.059513092041016 - score 0.8198
2021-07-18 23:09:46,453 BAD EPOCHS (no improvement): 2
2021-07-18 23:09:46,453 ----------------------------------------------------------------------------------------------------
2021-07-18 23:09:48,482 epoch 12 - iter 4/48 - loss 4.54475880 - samples/sec: 63.11 - lr: 0.000030
2021-07-18 23:09:50,534 epoch 12 - iter 8/48 - loss 4.57634979 - samples/sec: 62.39 - lr: 0.000030
2021-07-18 23:09:52,585 epoch 12 - iter 12/48 - loss 4.55158552 - samples/sec: 62.44 - lr: 0.000030
2021-07-18 23:09:54,604 epoch 12 - iter 16/48 - loss 4.48541608 - samples/sec: 63.42 - lr: 0.000030
2021-07-18 23:09:56,651 epoch 12 - iter 20/48 - loss 4.50880445 - samples/sec: 62.55 - lr: 0.000030
2021-07-18 23:09:58,700 epoch 12 - iter 24/48 - loss 4.51210993 - samples/sec: 62.48 - lr: 0.000030
2021-07-18 23:10:00,751 epoch 12 - iter 28/48 - loss 4.51716472 - samples/sec: 62.43 - lr: 0.000030
2021-07-18 23:10:02,799 epoch 12 - iter 32/48 - loss 4.49883944 - samples/sec: 62.53 - lr: 0.000030
2021-07-18 23:10:04,855 epoch 12 - iter 36/48 - loss 4.44611029 - samples/sec: 62.26 - lr: 0.000030
2021-07-18 23:10:06,884 epoch 12 - iter 40/48 - loss 4.43248376 - samples/sec: 63.11 - lr: 0.000030
2021-07-18 23:10:08,936 epoch 12 - iter 44/48 - loss 4.41022304 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 23:10:10,778 epoch 12 - iter 48/48 - loss 4.43761609 - samples/sec: 69.52 - lr: 0.000030
2021-07-18 23:10:10,779 ----------------------------------------------------------------------------------------------------
2021-07-18 23:10:10,779 EPOCH 12 done: loss 4.4376 - lr 0.0000300
2021-07-18 23:10:12,016 DEV : loss 4.195436954498291 - score 0.8258
2021-07-18 23:10:12,034 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:10:16,011 ----------------------------------------------------------------------------------------------------
2021-07-18 23:10:18,046 epoch 13 - iter 4/48 - loss 4.31973726 - samples/sec: 62.95 - lr: 0.000030
2021-07-18 23:10:20,088 epoch 13 - iter 8/48 - loss 4.49552163 - samples/sec: 62.69 - lr: 0.000030
2021-07-18 23:10:22,128 epoch 13 - iter 12/48 - loss 4.52963303 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 23:10:24,181 epoch 13 - iter 16/48 - loss 4.54371390 - samples/sec: 62.37 - lr: 0.000030
2021-07-18 23:10:26,242 epoch 13 - iter 20/48 - loss 4.48604295 - samples/sec: 62.13 - lr: 0.000030
2021-07-18 23:10:28,275 epoch 13 - iter 24/48 - loss 4.46026751 - samples/sec: 62.99 - lr: 0.000030
2021-07-18 23:10:34,272 epoch 13 - iter 28/48 - loss 4.42140493 - samples/sec: 21.35 - lr: 0.000030
2021-07-18 23:10:36,328 epoch 13 - iter 32/48 - loss 4.44402445 - samples/sec: 62.27 - lr: 0.000030
2021-07-18 23:10:38,386 epoch 13 - iter 36/48 - loss 4.38866213 - samples/sec: 62.20 - lr: 0.000030
2021-07-18 23:10:40,418 epoch 13 - iter 40/48 - loss 4.37227545 - samples/sec: 63.01 - lr: 0.000030
2021-07-18 23:10:42,476 epoch 13 - iter 44/48 - loss 4.37216171 - samples/sec: 62.20 - lr: 0.000030
2021-07-18 23:10:44,321 epoch 13 - iter 48/48 - loss 4.39497481 - samples/sec: 69.41 - lr: 0.000030
2021-07-18 23:10:44,321 ----------------------------------------------------------------------------------------------------
2021-07-18 23:10:44,321 EPOCH 13 done: loss 4.3950 - lr 0.0000300
2021-07-18 23:10:45,567 DEV : loss 3.9186534881591797 - score 0.8161
2021-07-18 23:10:45,585 BAD EPOCHS (no improvement): 1
2021-07-18 23:10:45,585 ----------------------------------------------------------------------------------------------------
2021-07-18 23:10:47,612 epoch 14 - iter 4/48 - loss 4.11919957 - samples/sec: 63.17 - lr: 0.000030
2021-07-18 23:10:49,668 epoch 14 - iter 8/48 - loss 4.32910040 - samples/sec: 62.29 - lr: 0.000030
2021-07-18 23:10:51,719 epoch 14 - iter 12/48 - loss 4.28004013 - samples/sec: 62.43 - lr: 0.000030
2021-07-18 23:10:53,780 epoch 14 - iter 16/48 - loss 4.33673055 - samples/sec: 62.11 - lr: 0.000030
2021-07-18 23:10:55,841 epoch 14 - iter 20/48 - loss 4.37930807 - samples/sec: 62.14 - lr: 0.000030
2021-07-18 23:10:57,895 epoch 14 - iter 24/48 - loss 4.37376314 - samples/sec: 62.34 - lr: 0.000030
2021-07-18 23:10:59,936 epoch 14 - iter 28/48 - loss 4.33972662 - samples/sec: 62.73 - lr: 0.000030
2021-07-18 23:11:01,997 epoch 14 - iter 32/48 - loss 4.32685865 - samples/sec: 62.12 - lr: 0.000030
2021-07-18 23:11:04,059 epoch 14 - iter 36/48 - loss 4.34618389 - samples/sec: 62.08 - lr: 0.000030
2021-07-18 23:11:06,116 epoch 14 - iter 40/48 - loss 4.32185963 - samples/sec: 62.25 - lr: 0.000030
2021-07-18 23:11:08,161 epoch 14 - iter 44/48 - loss 4.30549291 - samples/sec: 62.60 - lr: 0.000030
2021-07-18 23:11:10,012 epoch 14 - iter 48/48 - loss 4.31061292 - samples/sec: 69.20 - lr: 0.000030
2021-07-18 23:11:10,012 ----------------------------------------------------------------------------------------------------
2021-07-18 23:11:10,012 EPOCH 14 done: loss 4.3106 - lr 0.0000300
2021-07-18 23:11:11,251 DEV : loss 3.910654306411743 - score 0.8269
2021-07-18 23:11:11,269 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:11:15,066 ----------------------------------------------------------------------------------------------------
2021-07-18 23:11:17,128 epoch 15 - iter 4/48 - loss 4.16250479 - samples/sec: 62.11 - lr: 0.000030
2021-07-18 23:11:19,179 epoch 15 - iter 8/48 - loss 4.17237005 - samples/sec: 62.42 - lr: 0.000030
2021-07-18 23:11:21,231 epoch 15 - iter 12/48 - loss 4.21022401 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 23:11:23,288 epoch 15 - iter 16/48 - loss 4.17668338 - samples/sec: 62.26 - lr: 0.000030
2021-07-18 23:11:25,327 epoch 15 - iter 20/48 - loss 4.17907346 - samples/sec: 62.78 - lr: 0.000030
2021-07-18 23:11:27,347 epoch 15 - iter 24/48 - loss 4.15908220 - samples/sec: 63.40 - lr: 0.000030
2021-07-18 23:11:29,394 epoch 15 - iter 28/48 - loss 4.19511016 - samples/sec: 62.55 - lr: 0.000030
2021-07-18 23:11:31,424 epoch 15 - iter 32/48 - loss 4.17457613 - samples/sec: 63.06 - lr: 0.000030
2021-07-18 23:11:33,453 epoch 15 - iter 36/48 - loss 4.21042554 - samples/sec: 63.10 - lr: 0.000030
2021-07-18 23:11:35,504 epoch 15 - iter 40/48 - loss 4.20540679 - samples/sec: 62.45 - lr: 0.000030
2021-07-18 23:11:37,571 epoch 15 - iter 44/48 - loss 4.21895321 - samples/sec: 61.94 - lr: 0.000030
2021-07-18 23:11:39,413 epoch 15 - iter 48/48 - loss 4.21322381 - samples/sec: 69.52 - lr: 0.000030
2021-07-18 23:11:39,413 ----------------------------------------------------------------------------------------------------
2021-07-18 23:11:39,413 EPOCH 15 done: loss 4.2132 - lr 0.0000300
2021-07-18 23:11:40,655 DEV : loss 3.9117016792297363 - score 0.8253
2021-07-18 23:11:40,672 BAD EPOCHS (no improvement): 1
2021-07-18 23:11:40,672 ----------------------------------------------------------------------------------------------------
2021-07-18 23:11:42,736 epoch 16 - iter 4/48 - loss 4.27877545 - samples/sec: 62.06 - lr: 0.000030
2021-07-18 23:11:44,779 epoch 16 - iter 8/48 - loss 4.34940374 - samples/sec: 62.65 - lr: 0.000030
2021-07-18 23:11:46,847 epoch 16 - iter 12/48 - loss 4.33348310 - samples/sec: 61.92 - lr: 0.000030
2021-07-18 23:11:48,902 epoch 16 - iter 16/48 - loss 4.22859639 - samples/sec: 62.32 - lr: 0.000030
2021-07-18 23:11:50,955 epoch 16 - iter 20/48 - loss 4.25690881 - samples/sec: 62.34 - lr: 0.000030
2021-07-18 23:11:53,028 epoch 16 - iter 24/48 - loss 4.25941592 - samples/sec: 61.77 - lr: 0.000030
2021-07-18 23:11:55,084 epoch 16 - iter 28/48 - loss 4.24815100 - samples/sec: 62.29 - lr: 0.000030
2021-07-18 23:11:57,130 epoch 16 - iter 32/48 - loss 4.22921105 - samples/sec: 62.57 - lr: 0.000030
2021-07-18 23:11:59,180 epoch 16 - iter 36/48 - loss 4.21989381 - samples/sec: 62.47 - lr: 0.000030
2021-07-18 23:12:01,218 epoch 16 - iter 40/48 - loss 4.22467497 - samples/sec: 62.81 - lr: 0.000030
2021-07-18 23:12:03,295 epoch 16 - iter 44/48 - loss 4.19771180 - samples/sec: 61.66 - lr: 0.000030
2021-07-18 23:12:05,136 epoch 16 - iter 48/48 - loss 4.17372330 - samples/sec: 69.55 - lr: 0.000030
2021-07-18 23:12:05,136 ----------------------------------------------------------------------------------------------------
2021-07-18 23:12:05,136 EPOCH 16 done: loss 4.1737 - lr 0.0000300
2021-07-18 23:12:06,377 DEV : loss 3.8183908462524414 - score 0.82
2021-07-18 23:12:06,395 BAD EPOCHS (no improvement): 2
2021-07-18 23:12:06,395 ----------------------------------------------------------------------------------------------------
2021-07-18 23:12:08,439 epoch 17 - iter 4/48 - loss 4.26861608 - samples/sec: 62.65 - lr: 0.000030
2021-07-18 23:12:10,487 epoch 17 - iter 8/48 - loss 4.11897421 - samples/sec: 62.50 - lr: 0.000030
2021-07-18 23:12:12,527 epoch 17 - iter 12/48 - loss 4.06194560 - samples/sec: 62.76 - lr: 0.000030
2021-07-18 23:12:14,588 epoch 17 - iter 16/48 - loss 4.13526712 - samples/sec: 62.12 - lr: 0.000030
2021-07-18 23:12:16,652 epoch 17 - iter 20/48 - loss 4.15900817 - samples/sec: 62.04 - lr: 0.000030
2021-07-18 23:12:18,702 epoch 17 - iter 24/48 - loss 4.15199248 - samples/sec: 62.46 - lr: 0.000030
2021-07-18 23:12:20,776 epoch 17 - iter 28/48 - loss 4.15692300 - samples/sec: 61.74 - lr: 0.000030
2021-07-18 23:12:22,833 epoch 17 - iter 32/48 - loss 4.14967740 - samples/sec: 62.24 - lr: 0.000030
2021-07-18 23:12:24,883 epoch 17 - iter 36/48 - loss 4.17347703 - samples/sec: 62.46 - lr: 0.000030
2021-07-18 23:12:26,947 epoch 17 - iter 40/48 - loss 4.18765167 - samples/sec: 62.04 - lr: 0.000030
2021-07-18 23:12:29,021 epoch 17 - iter 44/48 - loss 4.17860148 - samples/sec: 61.75 - lr: 0.000030
2021-07-18 23:12:30,867 epoch 17 - iter 48/48 - loss 4.15862413 - samples/sec: 69.35 - lr: 0.000030
2021-07-18 23:12:30,867 ----------------------------------------------------------------------------------------------------
2021-07-18 23:12:30,867 EPOCH 17 done: loss 4.1586 - lr 0.0000300
2021-07-18 23:12:32,283 DEV : loss 3.8662848472595215 - score 0.825
2021-07-18 23:12:32,301 BAD EPOCHS (no improvement): 3
2021-07-18 23:12:32,301 ----------------------------------------------------------------------------------------------------
2021-07-18 23:12:34,350 epoch 18 - iter 4/48 - loss 4.10085076 - samples/sec: 62.48 - lr: 0.000030
2021-07-18 23:12:36,410 epoch 18 - iter 8/48 - loss 4.07644379 - samples/sec: 62.16 - lr: 0.000030
2021-07-18 23:12:38,473 epoch 18 - iter 12/48 - loss 4.10100834 - samples/sec: 62.08 - lr: 0.000030
2021-07-18 23:12:40,526 epoch 18 - iter 16/48 - loss 4.12456116 - samples/sec: 62.36 - lr: 0.000030
2021-07-18 23:12:42,576 epoch 18 - iter 20/48 - loss 4.09139020 - samples/sec: 62.45 - lr: 0.000030
2021-07-18 23:12:44,635 epoch 18 - iter 24/48 - loss 4.09913039 - samples/sec: 62.20 - lr: 0.000030
2021-07-18 23:12:46,708 epoch 18 - iter 28/48 - loss 4.05894391 - samples/sec: 61.76 - lr: 0.000030
2021-07-18 23:12:48,755 epoch 18 - iter 32/48 - loss 4.04212577 - samples/sec: 62.56 - lr: 0.000030
2021-07-18 23:12:50,832 epoch 18 - iter 36/48 - loss 4.07111745 - samples/sec: 61.64 - lr: 0.000030
2021-07-18 23:12:52,889 epoch 18 - iter 40/48 - loss 4.03351082 - samples/sec: 62.24 - lr: 0.000030
2021-07-18 23:12:54,942 epoch 18 - iter 44/48 - loss 4.04159435 - samples/sec: 62.36 - lr: 0.000030
2021-07-18 23:12:56,783 epoch 18 - iter 48/48 - loss 4.08200159 - samples/sec: 69.57 - lr: 0.000030
2021-07-18 23:12:56,783 ----------------------------------------------------------------------------------------------------
2021-07-18 23:12:56,783 EPOCH 18 done: loss 4.0820 - lr 0.0000300
2021-07-18 23:12:58,025 DEV : loss 3.813516139984131 - score 0.8303
2021-07-18 23:12:58,042 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:13:01,883 ----------------------------------------------------------------------------------------------------
2021-07-18 23:13:03,938 epoch 19 - iter 4/48 - loss 3.89827847 - samples/sec: 62.30 - lr: 0.000030
2021-07-18 23:13:05,980 epoch 19 - iter 8/48 - loss 3.86268607 - samples/sec: 62.73 - lr: 0.000030
2021-07-18 23:13:08,056 epoch 19 - iter 12/48 - loss 3.98731786 - samples/sec: 61.67 - lr: 0.000030
2021-07-18 23:13:10,123 epoch 19 - iter 16/48 - loss 3.98930617 - samples/sec: 61.95 - lr: 0.000030
2021-07-18 23:13:12,190 epoch 19 - iter 20/48 - loss 4.04459790 - samples/sec: 61.92 - lr: 0.000030
2021-07-18 23:13:14,240 epoch 19 - iter 24/48 - loss 4.06269907 - samples/sec: 62.47 - lr: 0.000030
2021-07-18 23:13:16,286 epoch 19 - iter 28/48 - loss 4.09668131 - samples/sec: 62.58 - lr: 0.000030
2021-07-18 23:13:18,347 epoch 19 - iter 32/48 - loss 4.12443595 - samples/sec: 62.12 - lr: 0.000030
2021-07-18 23:13:20,407 epoch 19 - iter 36/48 - loss 4.11009682 - samples/sec: 62.16 - lr: 0.000030
2021-07-18 23:13:22,479 epoch 19 - iter 40/48 - loss 4.08646033 - samples/sec: 61.82 - lr: 0.000030
2021-07-18 23:13:24,518 epoch 19 - iter 44/48 - loss 4.06583480 - samples/sec: 62.79 - lr: 0.000030
2021-07-18 23:13:26,367 epoch 19 - iter 48/48 - loss 4.04270034 - samples/sec: 69.26 - lr: 0.000030
2021-07-18 23:13:26,367 ----------------------------------------------------------------------------------------------------
2021-07-18 23:13:26,367 EPOCH 19 done: loss 4.0427 - lr 0.0000300
2021-07-18 23:13:27,608 DEV : loss 3.7590508460998535 - score 0.8286
2021-07-18 23:13:27,626 BAD EPOCHS (no improvement): 1
2021-07-18 23:13:27,626 ----------------------------------------------------------------------------------------------------
2021-07-18 23:13:29,679 epoch 20 - iter 4/48 - loss 3.97597754 - samples/sec: 62.36 - lr: 0.000030
2021-07-18 23:13:31,716 epoch 20 - iter 8/48 - loss 3.80366626 - samples/sec: 62.85 - lr: 0.000030
2021-07-18 23:13:33,757 epoch 20 - iter 12/48 - loss 3.72512698 - samples/sec: 62.75 - lr: 0.000030
2021-07-18 23:13:35,792 epoch 20 - iter 16/48 - loss 3.69209358 - samples/sec: 62.91 - lr: 0.000030
2021-07-18 23:13:37,852 epoch 20 - iter 20/48 - loss 3.71966468 - samples/sec: 62.17 - lr: 0.000030
2021-07-18 23:13:39,924 epoch 20 - iter 24/48 - loss 3.76631207 - samples/sec: 61.78 - lr: 0.000030
2021-07-18 23:13:41,987 epoch 20 - iter 28/48 - loss 3.82300311 - samples/sec: 62.07 - lr: 0.000030
2021-07-18 23:13:44,056 epoch 20 - iter 32/48 - loss 3.87787932 - samples/sec: 61.89 - lr: 0.000030
2021-07-18 23:13:46,119 epoch 20 - iter 36/48 - loss 3.92256699 - samples/sec: 62.06 - lr: 0.000030
2021-07-18 23:13:48,195 epoch 20 - iter 40/48 - loss 3.95972502 - samples/sec: 61.68 - lr: 0.000030
2021-07-18 23:13:50,241 epoch 20 - iter 44/48 - loss 3.92384639 - samples/sec: 62.58 - lr: 0.000030
2021-07-18 23:13:52,084 epoch 20 - iter 48/48 - loss 3.94016761 - samples/sec: 69.45 - lr: 0.000030
2021-07-18 23:13:52,084 ----------------------------------------------------------------------------------------------------
2021-07-18 23:13:52,085 EPOCH 20 done: loss 3.9402 - lr 0.0000300
2021-07-18 23:13:53,329 DEV : loss 3.782353401184082 - score 0.8262
2021-07-18 23:13:53,347 BAD EPOCHS (no improvement): 2
2021-07-18 23:13:53,347 ----------------------------------------------------------------------------------------------------
2021-07-18 23:13:55,396 epoch 21 - iter 4/48 - loss 3.74227566 - samples/sec: 62.50 - lr: 0.000030
2021-07-18 23:13:57,458 epoch 21 - iter 8/48 - loss 3.86668247 - samples/sec: 62.08 - lr: 0.000030
2021-07-18 23:13:59,511 epoch 21 - iter 12/48 - loss 3.85373890 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 23:14:01,564 epoch 21 - iter 16/48 - loss 3.85542586 - samples/sec: 62.36 - lr: 0.000030
2021-07-18 23:14:03,632 epoch 21 - iter 20/48 - loss 3.91797895 - samples/sec: 61.92 - lr: 0.000030
2021-07-18 23:14:05,684 epoch 21 - iter 24/48 - loss 3.90297398 - samples/sec: 62.39 - lr: 0.000030
2021-07-18 23:14:07,757 epoch 21 - iter 28/48 - loss 3.91826626 - samples/sec: 61.78 - lr: 0.000030
2021-07-18 23:14:09,815 epoch 21 - iter 32/48 - loss 3.95836125 - samples/sec: 62.21 - lr: 0.000030
2021-07-18 23:14:11,880 epoch 21 - iter 36/48 - loss 3.96574145 - samples/sec: 61.99 - lr: 0.000030
2021-07-18 23:14:13,933 epoch 21 - iter 40/48 - loss 3.95213549 - samples/sec: 62.38 - lr: 0.000030
2021-07-18 23:14:15,979 epoch 21 - iter 44/48 - loss 3.97119233 - samples/sec: 62.57 - lr: 0.000030
2021-07-18 23:14:17,828 epoch 21 - iter 48/48 - loss 3.96256937 - samples/sec: 69.25 - lr: 0.000030
2021-07-18 23:14:17,829 ----------------------------------------------------------------------------------------------------
2021-07-18 23:14:17,829 EPOCH 21 done: loss 3.9626 - lr 0.0000300
2021-07-18 23:14:19,072 DEV : loss 3.713279962539673 - score 0.8196
2021-07-18 23:14:19,089 BAD EPOCHS (no improvement): 3
2021-07-18 23:14:19,089 ----------------------------------------------------------------------------------------------------
2021-07-18 23:14:21,144 epoch 22 - iter 4/48 - loss 4.16570854 - samples/sec: 62.31 - lr: 0.000030
2021-07-18 23:14:23,199 epoch 22 - iter 8/48 - loss 3.96498033 - samples/sec: 62.33 - lr: 0.000030
2021-07-18 23:14:25,271 epoch 22 - iter 12/48 - loss 3.85114676 - samples/sec: 61.79 - lr: 0.000030
2021-07-18 23:14:27,344 epoch 22 - iter 16/48 - loss 3.85216455 - samples/sec: 61.77 - lr: 0.000030
2021-07-18 23:14:29,391 epoch 22 - iter 20/48 - loss 3.88652359 - samples/sec: 62.53 - lr: 0.000030
2021-07-18 23:14:31,457 epoch 22 - iter 24/48 - loss 3.88167802 - samples/sec: 61.97 - lr: 0.000030
2021-07-18 23:14:33,523 epoch 22 - iter 28/48 - loss 3.89151645 - samples/sec: 61.97 - lr: 0.000030
2021-07-18 23:14:35,579 epoch 22 - iter 32/48 - loss 3.91045362 - samples/sec: 62.28 - lr: 0.000030
2021-07-18 23:14:37,636 epoch 22 - iter 36/48 - loss 3.90831404 - samples/sec: 62.26 - lr: 0.000030
2021-07-18 23:14:39,693 epoch 22 - iter 40/48 - loss 3.89881140 - samples/sec: 62.24 - lr: 0.000030
2021-07-18 23:14:41,739 epoch 22 - iter 44/48 - loss 3.86294872 - samples/sec: 62.57 - lr: 0.000030
2021-07-18 23:14:43,591 epoch 22 - iter 48/48 - loss 3.86448563 - samples/sec: 69.16 - lr: 0.000030
2021-07-18 23:14:43,591 ----------------------------------------------------------------------------------------------------
2021-07-18 23:14:43,592 EPOCH 22 done: loss 3.8645 - lr 0.0000300
2021-07-18 23:14:44,837 DEV : loss 3.7258718013763428 - score 0.8299
Epoch    22: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 23:14:44,854 BAD EPOCHS (no improvement): 4
2021-07-18 23:14:44,854 ----------------------------------------------------------------------------------------------------
2021-07-18 23:14:46,890 epoch 23 - iter 4/48 - loss 3.55110621 - samples/sec: 62.89 - lr: 0.000015
2021-07-18 23:14:49,116 epoch 23 - iter 8/48 - loss 3.77892286 - samples/sec: 57.52 - lr: 0.000015
2021-07-18 23:14:51,180 epoch 23 - iter 12/48 - loss 3.89143248 - samples/sec: 62.04 - lr: 0.000015
2021-07-18 23:14:53,238 epoch 23 - iter 16/48 - loss 3.80320589 - samples/sec: 62.19 - lr: 0.000015
2021-07-18 23:14:55,290 epoch 23 - iter 20/48 - loss 3.83584700 - samples/sec: 62.40 - lr: 0.000015
2021-07-18 23:14:57,358 epoch 23 - iter 24/48 - loss 3.84362861 - samples/sec: 61.92 - lr: 0.000015
2021-07-18 23:14:59,428 epoch 23 - iter 28/48 - loss 3.78364752 - samples/sec: 61.86 - lr: 0.000015
2021-07-18 23:15:01,488 epoch 23 - iter 32/48 - loss 3.78822882 - samples/sec: 62.16 - lr: 0.000015
2021-07-18 23:15:03,549 epoch 23 - iter 36/48 - loss 3.79801987 - samples/sec: 62.11 - lr: 0.000015
2021-07-18 23:15:05,605 epoch 23 - iter 40/48 - loss 3.80164528 - samples/sec: 62.29 - lr: 0.000015
2021-07-18 23:15:07,650 epoch 23 - iter 44/48 - loss 3.80809328 - samples/sec: 62.59 - lr: 0.000015
2021-07-18 23:15:09,479 epoch 23 - iter 48/48 - loss 3.78899345 - samples/sec: 70.03 - lr: 0.000015
2021-07-18 23:15:09,479 ----------------------------------------------------------------------------------------------------
2021-07-18 23:15:09,479 EPOCH 23 done: loss 3.7890 - lr 0.0000150
2021-07-18 23:15:10,721 DEV : loss 3.7128381729125977 - score 0.8266
2021-07-18 23:15:10,739 BAD EPOCHS (no improvement): 1
2021-07-18 23:15:10,739 ----------------------------------------------------------------------------------------------------
2021-07-18 23:15:12,796 epoch 24 - iter 4/48 - loss 3.59145534 - samples/sec: 62.24 - lr: 0.000015
2021-07-18 23:15:14,844 epoch 24 - iter 8/48 - loss 3.53294483 - samples/sec: 62.52 - lr: 0.000015
2021-07-18 23:15:16,908 epoch 24 - iter 12/48 - loss 3.69527574 - samples/sec: 62.04 - lr: 0.000015
2021-07-18 23:15:18,958 epoch 24 - iter 16/48 - loss 3.66210832 - samples/sec: 62.45 - lr: 0.000015
2021-07-18 23:15:20,994 epoch 24 - iter 20/48 - loss 3.65470921 - samples/sec: 62.90 - lr: 0.000015
2021-07-18 23:15:23,066 epoch 24 - iter 24/48 - loss 3.66502085 - samples/sec: 61.80 - lr: 0.000015
2021-07-18 23:15:25,127 epoch 24 - iter 28/48 - loss 3.64993037 - samples/sec: 62.11 - lr: 0.000015
2021-07-18 23:15:27,175 epoch 24 - iter 32/48 - loss 3.66195813 - samples/sec: 62.53 - lr: 0.000015
2021-07-18 23:15:29,234 epoch 24 - iter 36/48 - loss 3.67379017 - samples/sec: 62.18 - lr: 0.000015
2021-07-18 23:15:31,285 epoch 24 - iter 40/48 - loss 3.70282925 - samples/sec: 62.45 - lr: 0.000015
2021-07-18 23:15:33,344 epoch 24 - iter 44/48 - loss 3.71571552 - samples/sec: 62.18 - lr: 0.000015
2021-07-18 23:15:35,192 epoch 24 - iter 48/48 - loss 3.72715278 - samples/sec: 69.29 - lr: 0.000015
2021-07-18 23:15:35,192 ----------------------------------------------------------------------------------------------------
2021-07-18 23:15:35,192 EPOCH 24 done: loss 3.7272 - lr 0.0000150
2021-07-18 23:15:36,432 DEV : loss 3.7428202629089355 - score 0.8344
2021-07-18 23:15:36,450 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:15:40,213 ----------------------------------------------------------------------------------------------------
2021-07-18 23:15:42,269 epoch 25 - iter 4/48 - loss 4.15254849 - samples/sec: 62.28 - lr: 0.000015
2021-07-18 23:15:44,319 epoch 25 - iter 8/48 - loss 3.92484549 - samples/sec: 62.45 - lr: 0.000015
2021-07-18 23:15:46,372 epoch 25 - iter 12/48 - loss 3.84547470 - samples/sec: 62.36 - lr: 0.000015
2021-07-18 23:15:48,431 epoch 25 - iter 16/48 - loss 3.79621732 - samples/sec: 62.21 - lr: 0.000015
2021-07-18 23:15:50,486 epoch 25 - iter 20/48 - loss 3.76110227 - samples/sec: 62.29 - lr: 0.000015
2021-07-18 23:15:52,560 epoch 25 - iter 24/48 - loss 3.78255605 - samples/sec: 61.74 - lr: 0.000015
2021-07-18 23:15:54,623 epoch 25 - iter 28/48 - loss 3.81921734 - samples/sec: 62.05 - lr: 0.000015
2021-07-18 23:15:56,691 epoch 25 - iter 32/48 - loss 3.82478762 - samples/sec: 61.92 - lr: 0.000015
2021-07-18 23:15:58,735 epoch 25 - iter 36/48 - loss 3.80924677 - samples/sec: 62.65 - lr: 0.000015
2021-07-18 23:16:00,788 epoch 25 - iter 40/48 - loss 3.82717499 - samples/sec: 62.36 - lr: 0.000015
2021-07-18 23:16:02,859 epoch 25 - iter 44/48 - loss 3.81920233 - samples/sec: 61.81 - lr: 0.000015
2021-07-18 23:16:04,705 epoch 25 - iter 48/48 - loss 3.81273681 - samples/sec: 69.39 - lr: 0.000015
2021-07-18 23:16:04,705 ----------------------------------------------------------------------------------------------------
2021-07-18 23:16:04,705 EPOCH 25 done: loss 3.8127 - lr 0.0000150
2021-07-18 23:16:05,948 DEV : loss 3.7165162563323975 - score 0.8268
2021-07-18 23:16:05,965 BAD EPOCHS (no improvement): 1
2021-07-18 23:16:05,966 ----------------------------------------------------------------------------------------------------
2021-07-18 23:16:08,019 epoch 26 - iter 4/48 - loss 4.10230863 - samples/sec: 62.36 - lr: 0.000015
2021-07-18 23:16:10,071 epoch 26 - iter 8/48 - loss 3.96393639 - samples/sec: 62.39 - lr: 0.000015
2021-07-18 23:16:12,123 epoch 26 - iter 12/48 - loss 3.83871134 - samples/sec: 62.40 - lr: 0.000015
2021-07-18 23:16:14,195 epoch 26 - iter 16/48 - loss 3.81886716 - samples/sec: 61.78 - lr: 0.000015
2021-07-18 23:16:16,246 epoch 26 - iter 20/48 - loss 3.81732553 - samples/sec: 62.44 - lr: 0.000015
2021-07-18 23:16:18,312 epoch 26 - iter 24/48 - loss 3.80577407 - samples/sec: 61.98 - lr: 0.000015
2021-07-18 23:16:20,375 epoch 26 - iter 28/48 - loss 3.75565140 - samples/sec: 62.06 - lr: 0.000015
2021-07-18 23:16:22,432 epoch 26 - iter 32/48 - loss 3.73249242 - samples/sec: 62.25 - lr: 0.000015
2021-07-18 23:16:24,497 epoch 26 - iter 36/48 - loss 3.74153492 - samples/sec: 62.00 - lr: 0.000015
2021-07-18 23:16:26,556 epoch 26 - iter 40/48 - loss 3.74062935 - samples/sec: 62.19 - lr: 0.000015
2021-07-18 23:16:28,627 epoch 26 - iter 44/48 - loss 3.75117986 - samples/sec: 61.82 - lr: 0.000015
2021-07-18 23:16:30,468 epoch 26 - iter 48/48 - loss 3.75409464 - samples/sec: 69.55 - lr: 0.000015
2021-07-18 23:16:30,468 ----------------------------------------------------------------------------------------------------
2021-07-18 23:16:30,468 EPOCH 26 done: loss 3.7541 - lr 0.0000150
2021-07-18 23:16:31,711 DEV : loss 3.7225208282470703 - score 0.8334
2021-07-18 23:16:31,729 BAD EPOCHS (no improvement): 2
2021-07-18 23:16:31,729 ----------------------------------------------------------------------------------------------------
2021-07-18 23:16:33,760 epoch 27 - iter 4/48 - loss 3.63890165 - samples/sec: 63.04 - lr: 0.000015
2021-07-18 23:16:35,832 epoch 27 - iter 8/48 - loss 3.74922818 - samples/sec: 61.79 - lr: 0.000015
2021-07-18 23:16:37,886 epoch 27 - iter 12/48 - loss 3.67707058 - samples/sec: 62.33 - lr: 0.000015
2021-07-18 23:16:39,931 epoch 27 - iter 16/48 - loss 3.71168058 - samples/sec: 62.61 - lr: 0.000015
2021-07-18 23:16:41,990 epoch 27 - iter 20/48 - loss 3.69012246 - samples/sec: 62.19 - lr: 0.000015
2021-07-18 23:16:44,228 epoch 27 - iter 24/48 - loss 3.65715567 - samples/sec: 57.22 - lr: 0.000015
2021-07-18 23:16:46,279 epoch 27 - iter 28/48 - loss 3.67784974 - samples/sec: 62.42 - lr: 0.000015
2021-07-18 23:16:48,355 epoch 27 - iter 32/48 - loss 3.67604986 - samples/sec: 61.68 - lr: 0.000015
2021-07-18 23:16:50,428 epoch 27 - iter 36/48 - loss 3.67792171 - samples/sec: 61.76 - lr: 0.000015
2021-07-18 23:16:52,499 epoch 27 - iter 40/48 - loss 3.69780224 - samples/sec: 61.83 - lr: 0.000015
2021-07-18 23:16:54,565 epoch 27 - iter 44/48 - loss 3.69443471 - samples/sec: 61.99 - lr: 0.000015
2021-07-18 23:16:56,407 epoch 27 - iter 48/48 - loss 3.70486695 - samples/sec: 69.51 - lr: 0.000015
2021-07-18 23:16:56,407 ----------------------------------------------------------------------------------------------------
2021-07-18 23:16:56,407 EPOCH 27 done: loss 3.7049 - lr 0.0000150
2021-07-18 23:16:57,650 DEV : loss 3.6968812942504883 - score 0.8313
2021-07-18 23:16:57,667 BAD EPOCHS (no improvement): 3
2021-07-18 23:16:57,668 ----------------------------------------------------------------------------------------------------
2021-07-18 23:16:59,718 epoch 28 - iter 4/48 - loss 3.51619798 - samples/sec: 62.44 - lr: 0.000015
2021-07-18 23:17:01,780 epoch 28 - iter 8/48 - loss 3.70571482 - samples/sec: 62.10 - lr: 0.000015
2021-07-18 23:17:03,852 epoch 28 - iter 12/48 - loss 3.75423481 - samples/sec: 61.80 - lr: 0.000015
2021-07-18 23:17:05,906 epoch 28 - iter 16/48 - loss 3.65082142 - samples/sec: 62.32 - lr: 0.000015
2021-07-18 23:17:07,968 epoch 28 - iter 20/48 - loss 3.66299483 - samples/sec: 62.09 - lr: 0.000015
2021-07-18 23:17:10,031 epoch 28 - iter 24/48 - loss 3.66798932 - samples/sec: 62.06 - lr: 0.000015
2021-07-18 23:17:12,092 epoch 28 - iter 28/48 - loss 3.68267359 - samples/sec: 62.15 - lr: 0.000015
2021-07-18 23:17:14,159 epoch 28 - iter 32/48 - loss 3.64160974 - samples/sec: 61.95 - lr: 0.000015
2021-07-18 23:17:16,202 epoch 28 - iter 36/48 - loss 3.62625906 - samples/sec: 62.66 - lr: 0.000015
2021-07-18 23:17:18,243 epoch 28 - iter 40/48 - loss 3.65119731 - samples/sec: 62.74 - lr: 0.000015
2021-07-18 23:17:20,308 epoch 28 - iter 44/48 - loss 3.68545979 - samples/sec: 62.01 - lr: 0.000015
2021-07-18 23:17:22,156 epoch 28 - iter 48/48 - loss 3.70721614 - samples/sec: 69.28 - lr: 0.000015
2021-07-18 23:17:22,157 ----------------------------------------------------------------------------------------------------
2021-07-18 23:17:22,157 EPOCH 28 done: loss 3.7072 - lr 0.0000150
2021-07-18 23:17:23,400 DEV : loss 3.748713493347168 - score 0.8334
Epoch    28: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 23:17:23,419 BAD EPOCHS (no improvement): 4
2021-07-18 23:17:23,419 ----------------------------------------------------------------------------------------------------
2021-07-18 23:17:25,483 epoch 29 - iter 4/48 - loss 3.93488324 - samples/sec: 62.03 - lr: 0.000008
2021-07-18 23:17:27,519 epoch 29 - iter 8/48 - loss 3.74385136 - samples/sec: 62.89 - lr: 0.000008
2021-07-18 23:17:29,579 epoch 29 - iter 12/48 - loss 3.86964860 - samples/sec: 62.15 - lr: 0.000008
2021-07-18 23:17:31,644 epoch 29 - iter 16/48 - loss 3.86818993 - samples/sec: 61.99 - lr: 0.000008
2021-07-18 23:17:33,712 epoch 29 - iter 20/48 - loss 3.81672440 - samples/sec: 61.92 - lr: 0.000008
2021-07-18 23:17:35,759 epoch 29 - iter 24/48 - loss 3.74993294 - samples/sec: 62.55 - lr: 0.000008
2021-07-18 23:17:37,812 epoch 29 - iter 28/48 - loss 3.72849077 - samples/sec: 62.38 - lr: 0.000008
2021-07-18 23:17:39,855 epoch 29 - iter 32/48 - loss 3.72744194 - samples/sec: 62.67 - lr: 0.000008
2021-07-18 23:17:41,920 epoch 29 - iter 36/48 - loss 3.65155832 - samples/sec: 62.01 - lr: 0.000008
2021-07-18 23:17:43,988 epoch 29 - iter 40/48 - loss 3.64658934 - samples/sec: 61.91 - lr: 0.000008
2021-07-18 23:17:46,057 epoch 29 - iter 44/48 - loss 3.66583859 - samples/sec: 61.90 - lr: 0.000008
2021-07-18 23:17:47,900 epoch 29 - iter 48/48 - loss 3.68246664 - samples/sec: 69.45 - lr: 0.000008
2021-07-18 23:17:47,900 ----------------------------------------------------------------------------------------------------
2021-07-18 23:17:47,901 EPOCH 29 done: loss 3.6825 - lr 0.0000075
2021-07-18 23:17:49,147 DEV : loss 3.7188496589660645 - score 0.8333
2021-07-18 23:17:49,164 BAD EPOCHS (no improvement): 1
2021-07-18 23:17:49,164 ----------------------------------------------------------------------------------------------------
2021-07-18 23:17:51,223 epoch 30 - iter 4/48 - loss 3.61504006 - samples/sec: 62.20 - lr: 0.000008
2021-07-18 23:17:53,289 epoch 30 - iter 8/48 - loss 3.73793420 - samples/sec: 61.98 - lr: 0.000008
2021-07-18 23:17:55,366 epoch 30 - iter 12/48 - loss 3.77985028 - samples/sec: 61.62 - lr: 0.000008
2021-07-18 23:17:57,401 epoch 30 - iter 16/48 - loss 3.74564271 - samples/sec: 62.93 - lr: 0.000008
2021-07-18 23:17:59,460 epoch 30 - iter 20/48 - loss 3.71402479 - samples/sec: 62.18 - lr: 0.000008
2021-07-18 23:18:01,516 epoch 30 - iter 24/48 - loss 3.65952731 - samples/sec: 62.28 - lr: 0.000008
2021-07-18 23:18:03,579 epoch 30 - iter 28/48 - loss 3.62971807 - samples/sec: 62.05 - lr: 0.000008
2021-07-18 23:18:05,644 epoch 30 - iter 32/48 - loss 3.60568038 - samples/sec: 62.01 - lr: 0.000008
2021-07-18 23:18:07,689 epoch 30 - iter 36/48 - loss 3.61854312 - samples/sec: 62.61 - lr: 0.000008
2021-07-18 23:18:09,747 epoch 30 - iter 40/48 - loss 3.61561669 - samples/sec: 62.22 - lr: 0.000008
2021-07-18 23:18:11,808 epoch 30 - iter 44/48 - loss 3.63006357 - samples/sec: 62.10 - lr: 0.000008
2021-07-18 23:18:13,660 epoch 30 - iter 48/48 - loss 3.61029019 - samples/sec: 69.17 - lr: 0.000008
2021-07-18 23:18:13,660 ----------------------------------------------------------------------------------------------------
2021-07-18 23:18:13,660 EPOCH 30 done: loss 3.6103 - lr 0.0000075
2021-07-18 23:18:14,901 DEV : loss 3.684913396835327 - score 0.8307
2021-07-18 23:18:14,919 BAD EPOCHS (no improvement): 2
2021-07-18 23:18:14,919 ----------------------------------------------------------------------------------------------------
2021-07-18 23:18:16,962 epoch 31 - iter 4/48 - loss 3.39941853 - samples/sec: 62.66 - lr: 0.000008
2021-07-18 23:18:19,018 epoch 31 - iter 8/48 - loss 3.55695018 - samples/sec: 62.27 - lr: 0.000008
2021-07-18 23:18:21,070 epoch 31 - iter 12/48 - loss 3.58167352 - samples/sec: 62.41 - lr: 0.000008
2021-07-18 23:18:23,135 epoch 31 - iter 16/48 - loss 3.55216758 - samples/sec: 62.01 - lr: 0.000008
2021-07-18 23:18:25,187 epoch 31 - iter 20/48 - loss 3.55023171 - samples/sec: 62.39 - lr: 0.000008
2021-07-18 23:18:27,253 epoch 31 - iter 24/48 - loss 3.56065321 - samples/sec: 61.98 - lr: 0.000008
2021-07-18 23:18:29,319 epoch 31 - iter 28/48 - loss 3.55934551 - samples/sec: 61.98 - lr: 0.000008
2021-07-18 23:18:31,366 epoch 31 - iter 32/48 - loss 3.60112161 - samples/sec: 62.52 - lr: 0.000008
2021-07-18 23:18:33,420 epoch 31 - iter 36/48 - loss 3.61842672 - samples/sec: 62.34 - lr: 0.000008
2021-07-18 23:18:35,479 epoch 31 - iter 40/48 - loss 3.61586359 - samples/sec: 62.20 - lr: 0.000008
2021-07-18 23:18:37,534 epoch 31 - iter 44/48 - loss 3.60832772 - samples/sec: 62.29 - lr: 0.000008
2021-07-18 23:18:39,378 epoch 31 - iter 48/48 - loss 3.61555519 - samples/sec: 69.45 - lr: 0.000008
2021-07-18 23:18:39,378 ----------------------------------------------------------------------------------------------------
2021-07-18 23:18:39,378 EPOCH 31 done: loss 3.6156 - lr 0.0000075
2021-07-18 23:18:40,620 DEV : loss 3.6829495429992676 - score 0.8291
2021-07-18 23:18:40,638 BAD EPOCHS (no improvement): 3
2021-07-18 23:18:40,638 ----------------------------------------------------------------------------------------------------
2021-07-18 23:18:42,696 epoch 32 - iter 4/48 - loss 3.36911517 - samples/sec: 62.22 - lr: 0.000008
2021-07-18 23:18:44,759 epoch 32 - iter 8/48 - loss 3.40917692 - samples/sec: 62.05 - lr: 0.000008
2021-07-18 23:18:46,796 epoch 32 - iter 12/48 - loss 3.49481718 - samples/sec: 62.86 - lr: 0.000008
2021-07-18 23:18:48,857 epoch 32 - iter 16/48 - loss 3.45558794 - samples/sec: 62.11 - lr: 0.000008
2021-07-18 23:18:50,919 epoch 32 - iter 20/48 - loss 3.56299500 - samples/sec: 62.09 - lr: 0.000008
2021-07-18 23:18:53,160 epoch 32 - iter 24/48 - loss 3.54197498 - samples/sec: 57.13 - lr: 0.000008
2021-07-18 23:18:55,207 epoch 32 - iter 28/48 - loss 3.53075877 - samples/sec: 62.56 - lr: 0.000008
2021-07-18 23:18:57,264 epoch 32 - iter 32/48 - loss 3.54038478 - samples/sec: 62.25 - lr: 0.000008
2021-07-18 23:18:59,306 epoch 32 - iter 36/48 - loss 3.54720190 - samples/sec: 62.69 - lr: 0.000008
2021-07-18 23:19:01,368 epoch 32 - iter 40/48 - loss 3.59339846 - samples/sec: 62.11 - lr: 0.000008
2021-07-18 23:19:03,435 epoch 32 - iter 44/48 - loss 3.59609370 - samples/sec: 61.93 - lr: 0.000008
2021-07-18 23:19:05,276 epoch 32 - iter 48/48 - loss 3.60200078 - samples/sec: 69.55 - lr: 0.000008
2021-07-18 23:19:05,277 ----------------------------------------------------------------------------------------------------
2021-07-18 23:19:05,277 EPOCH 32 done: loss 3.6020 - lr 0.0000075
2021-07-18 23:19:06,517 DEV : loss 3.734464645385742 - score 0.8329
Epoch    32: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 23:19:06,534 BAD EPOCHS (no improvement): 4
2021-07-18 23:19:06,535 ----------------------------------------------------------------------------------------------------
2021-07-18 23:19:08,595 epoch 33 - iter 4/48 - loss 3.69520366 - samples/sec: 62.13 - lr: 0.000004
2021-07-18 23:19:10,667 epoch 33 - iter 8/48 - loss 3.67769504 - samples/sec: 61.82 - lr: 0.000004
2021-07-18 23:19:12,704 epoch 33 - iter 12/48 - loss 3.68855216 - samples/sec: 62.84 - lr: 0.000004
2021-07-18 23:19:14,774 epoch 33 - iter 16/48 - loss 3.64371531 - samples/sec: 61.84 - lr: 0.000004
2021-07-18 23:19:16,815 epoch 33 - iter 20/48 - loss 3.58089141 - samples/sec: 62.73 - lr: 0.000004
2021-07-18 23:19:18,867 epoch 33 - iter 24/48 - loss 3.54750942 - samples/sec: 62.40 - lr: 0.000004
2021-07-18 23:19:20,931 epoch 33 - iter 28/48 - loss 3.57326809 - samples/sec: 62.04 - lr: 0.000004
2021-07-18 23:19:22,988 epoch 33 - iter 32/48 - loss 3.55915882 - samples/sec: 62.26 - lr: 0.000004
2021-07-18 23:19:25,037 epoch 33 - iter 36/48 - loss 3.57441894 - samples/sec: 62.48 - lr: 0.000004
2021-07-18 23:19:27,100 epoch 33 - iter 40/48 - loss 3.63318619 - samples/sec: 62.08 - lr: 0.000004
2021-07-18 23:19:29,173 epoch 33 - iter 44/48 - loss 3.61331161 - samples/sec: 61.77 - lr: 0.000004
2021-07-18 23:19:31,019 epoch 33 - iter 48/48 - loss 3.59603050 - samples/sec: 69.34 - lr: 0.000004
2021-07-18 23:19:31,020 ----------------------------------------------------------------------------------------------------
2021-07-18 23:19:31,020 EPOCH 33 done: loss 3.5960 - lr 0.0000038
2021-07-18 23:19:32,263 DEV : loss 3.764209508895874 - score 0.832
2021-07-18 23:19:32,280 BAD EPOCHS (no improvement): 1
2021-07-18 23:19:32,280 ----------------------------------------------------------------------------------------------------
2021-07-18 23:19:34,331 epoch 34 - iter 4/48 - loss 3.44247651 - samples/sec: 62.42 - lr: 0.000004
2021-07-18 23:19:36,386 epoch 34 - iter 8/48 - loss 3.65310934 - samples/sec: 62.32 - lr: 0.000004
2021-07-18 23:19:38,441 epoch 34 - iter 12/48 - loss 3.66439877 - samples/sec: 62.30 - lr: 0.000004
2021-07-18 23:19:40,476 epoch 34 - iter 16/48 - loss 3.59730127 - samples/sec: 62.94 - lr: 0.000004
2021-07-18 23:19:42,537 epoch 34 - iter 20/48 - loss 3.63426154 - samples/sec: 62.11 - lr: 0.000004
2021-07-18 23:19:44,604 epoch 34 - iter 24/48 - loss 3.58690170 - samples/sec: 61.95 - lr: 0.000004
2021-07-18 23:19:46,657 epoch 34 - iter 28/48 - loss 3.65088124 - samples/sec: 62.37 - lr: 0.000004
2021-07-18 23:19:48,737 epoch 34 - iter 32/48 - loss 3.63914521 - samples/sec: 61.54 - lr: 0.000004
2021-07-18 23:19:50,795 epoch 34 - iter 36/48 - loss 3.60322869 - samples/sec: 62.22 - lr: 0.000004
2021-07-18 23:19:52,859 epoch 34 - iter 40/48 - loss 3.59178173 - samples/sec: 62.03 - lr: 0.000004
2021-07-18 23:19:54,924 epoch 34 - iter 44/48 - loss 3.61783299 - samples/sec: 62.02 - lr: 0.000004
2021-07-18 23:19:56,750 epoch 34 - iter 48/48 - loss 3.60154246 - samples/sec: 70.11 - lr: 0.000004
2021-07-18 23:19:56,750 ----------------------------------------------------------------------------------------------------
2021-07-18 23:19:56,750 EPOCH 34 done: loss 3.6015 - lr 0.0000038
2021-07-18 23:19:57,993 DEV : loss 3.716484308242798 - score 0.8322
2021-07-18 23:19:58,010 BAD EPOCHS (no improvement): 2
2021-07-18 23:19:58,011 ----------------------------------------------------------------------------------------------------
2021-07-18 23:20:00,059 epoch 35 - iter 4/48 - loss 3.22026354 - samples/sec: 62.52 - lr: 0.000004
2021-07-18 23:20:02,095 epoch 35 - iter 8/48 - loss 3.36081576 - samples/sec: 62.88 - lr: 0.000004
2021-07-18 23:20:04,144 epoch 35 - iter 12/48 - loss 3.56095427 - samples/sec: 62.48 - lr: 0.000004
2021-07-18 23:20:06,215 epoch 35 - iter 16/48 - loss 3.55711278 - samples/sec: 61.85 - lr: 0.000004
2021-07-18 23:20:08,274 epoch 35 - iter 20/48 - loss 3.54959353 - samples/sec: 62.17 - lr: 0.000004
2021-07-18 23:20:10,343 epoch 35 - iter 24/48 - loss 3.58128197 - samples/sec: 61.89 - lr: 0.000004
2021-07-18 23:20:12,394 epoch 35 - iter 28/48 - loss 3.59222404 - samples/sec: 62.42 - lr: 0.000004
2021-07-18 23:20:14,463 epoch 35 - iter 32/48 - loss 3.57944793 - samples/sec: 61.89 - lr: 0.000004
2021-07-18 23:20:16,531 epoch 35 - iter 36/48 - loss 3.57213232 - samples/sec: 61.91 - lr: 0.000004
2021-07-18 23:20:18,586 epoch 35 - iter 40/48 - loss 3.60140156 - samples/sec: 62.33 - lr: 0.000004
2021-07-18 23:20:20,625 epoch 35 - iter 44/48 - loss 3.58284003 - samples/sec: 62.78 - lr: 0.000004
2021-07-18 23:20:22,443 epoch 35 - iter 48/48 - loss 3.56998775 - samples/sec: 70.42 - lr: 0.000004
2021-07-18 23:20:22,444 ----------------------------------------------------------------------------------------------------
2021-07-18 23:20:22,444 EPOCH 35 done: loss 3.5700 - lr 0.0000038
2021-07-18 23:20:23,683 DEV : loss 3.6928794384002686 - score 0.8319
2021-07-18 23:20:23,700 BAD EPOCHS (no improvement): 3
2021-07-18 23:20:23,701 ----------------------------------------------------------------------------------------------------
2021-07-18 23:20:25,724 epoch 36 - iter 4/48 - loss 3.58093095 - samples/sec: 63.27 - lr: 0.000004
2021-07-18 23:20:27,765 epoch 36 - iter 8/48 - loss 3.70009992 - samples/sec: 62.76 - lr: 0.000004
2021-07-18 23:20:29,797 epoch 36 - iter 12/48 - loss 3.66512158 - samples/sec: 63.00 - lr: 0.000004
2021-07-18 23:20:31,836 epoch 36 - iter 16/48 - loss 3.63450189 - samples/sec: 62.79 - lr: 0.000004
2021-07-18 23:20:33,876 epoch 36 - iter 20/48 - loss 3.73054608 - samples/sec: 62.76 - lr: 0.000004
2021-07-18 23:20:35,924 epoch 36 - iter 24/48 - loss 3.64860318 - samples/sec: 62.52 - lr: 0.000004
2021-07-18 23:20:37,978 epoch 36 - iter 28/48 - loss 3.61042974 - samples/sec: 62.34 - lr: 0.000004
2021-07-18 23:20:40,038 epoch 36 - iter 32/48 - loss 3.60264836 - samples/sec: 62.15 - lr: 0.000004
2021-07-18 23:20:42,075 epoch 36 - iter 36/48 - loss 3.57270592 - samples/sec: 62.86 - lr: 0.000004
2021-07-18 23:20:44,094 epoch 36 - iter 40/48 - loss 3.59775624 - samples/sec: 63.43 - lr: 0.000004
2021-07-18 23:20:46,303 epoch 36 - iter 44/48 - loss 3.59363592 - samples/sec: 57.95 - lr: 0.000004
2021-07-18 23:20:48,122 epoch 36 - iter 48/48 - loss 3.57840501 - samples/sec: 70.42 - lr: 0.000004
2021-07-18 23:20:48,122 ----------------------------------------------------------------------------------------------------
2021-07-18 23:20:48,122 EPOCH 36 done: loss 3.5784 - lr 0.0000038
2021-07-18 23:20:49,362 DEV : loss 3.7046220302581787 - score 0.8329
Epoch    36: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 23:20:49,379 BAD EPOCHS (no improvement): 4
2021-07-18 23:20:49,379 ----------------------------------------------------------------------------------------------------
2021-07-18 23:20:49,379 ----------------------------------------------------------------------------------------------------
2021-07-18 23:20:49,379 learning rate too small - quitting training!
2021-07-18 23:20:49,379 ----------------------------------------------------------------------------------------------------
2021-07-18 23:20:50,081 ----------------------------------------------------------------------------------------------------
2021-07-18 23:20:50,081 Testing using best model ...
2021-07-18 23:20:50,081 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.sdrt.stac/best-model.pt
2021-07-18 23:20:58,062 0.8011	0.8464	0.8231
2021-07-18 23:20:58,062 
Results:
- F1-score (micro) 0.8231
- F1-score (macro) 0.8231

By class:
SENT       tp: 1824 - fp: 453 - fn: 331 - precision: 0.8011 - recall: 0.8464 - f1-score: 0.8231
2021-07-18 23:20:58,062 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.sctb/
2021-07-18 23:20:58,074 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.sctb
2021-07-18 23:20:58,074 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.sctb/sent_train.txt
2021-07-18 23:20:58,076 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.sctb/sent_dev.txt
2021-07-18 23:20:58,078 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.sctb/sent_test.txt
Corpus: 390 train + 120 dev + 111 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 23:21:01,068 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:01,070 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 23:21:01,070 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:01,070 Corpus: "Corpus: 390 train + 120 dev + 111 test sentences"
2021-07-18 23:21:01,070 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:01,070 Parameters:
2021-07-18 23:21:01,070  - learning_rate: "3e-05"
2021-07-18 23:21:01,070  - mini_batch_size: "32"
2021-07-18 23:21:01,070  - patience: "3"
2021-07-18 23:21:01,070  - anneal_factor: "0.5"
2021-07-18 23:21:01,070  - max_epochs: "40"
2021-07-18 23:21:01,070  - shuffle: "True"
2021-07-18 23:21:01,071  - train_with_dev: "False"
2021-07-18 23:21:01,071  - batch_growth_annealing: "False"
2021-07-18 23:21:01,071 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:01,071 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.sctb"
2021-07-18 23:21:01,071 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:01,071 Device: cuda:0
2021-07-18 23:21:01,071 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:01,071 Embeddings storage mode: cpu
2021-07-18 23:21:01,074 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:02,334 epoch 1 - iter 1/13 - loss 41.38987732 - samples/sec: 25.41 - lr: 0.000030
2021-07-18 23:21:03,587 epoch 1 - iter 2/13 - loss 37.82203865 - samples/sec: 25.55 - lr: 0.000030
2021-07-18 23:21:04,758 epoch 1 - iter 3/13 - loss 36.96368535 - samples/sec: 27.33 - lr: 0.000030
2021-07-18 23:21:05,784 epoch 1 - iter 4/13 - loss 35.57665968 - samples/sec: 31.20 - lr: 0.000030
2021-07-18 23:21:06,799 epoch 1 - iter 5/13 - loss 33.73900490 - samples/sec: 31.54 - lr: 0.000030
2021-07-18 23:21:07,835 epoch 1 - iter 6/13 - loss 32.19875685 - samples/sec: 30.89 - lr: 0.000030
2021-07-18 23:21:08,857 epoch 1 - iter 7/13 - loss 30.58923095 - samples/sec: 31.34 - lr: 0.000030
2021-07-18 23:21:09,898 epoch 1 - iter 8/13 - loss 29.15256333 - samples/sec: 30.75 - lr: 0.000030
2021-07-18 23:21:10,941 epoch 1 - iter 9/13 - loss 27.82301352 - samples/sec: 30.68 - lr: 0.000030
2021-07-18 23:21:11,991 epoch 1 - iter 10/13 - loss 26.59664879 - samples/sec: 30.48 - lr: 0.000030
2021-07-18 23:21:13,035 epoch 1 - iter 11/13 - loss 25.56561834 - samples/sec: 30.67 - lr: 0.000030
2021-07-18 23:21:14,057 epoch 1 - iter 12/13 - loss 24.48640267 - samples/sec: 31.32 - lr: 0.000030
2021-07-18 23:21:14,303 epoch 1 - iter 13/13 - loss 23.24297274 - samples/sec: 130.00 - lr: 0.000030
2021-07-18 23:21:14,303 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:14,303 EPOCH 1 done: loss 23.2430 - lr 0.0000300
2021-07-18 23:21:16,455 DEV : loss 5.311516761779785 - score 0.0
2021-07-18 23:21:16,465 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:21:17,260 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:17,779 epoch 2 - iter 1/13 - loss 9.98123741 - samples/sec: 61.69 - lr: 0.000030
2021-07-18 23:21:18,321 epoch 2 - iter 2/13 - loss 9.40796375 - samples/sec: 59.11 - lr: 0.000030
2021-07-18 23:21:18,845 epoch 2 - iter 3/13 - loss 9.09328429 - samples/sec: 61.07 - lr: 0.000030
2021-07-18 23:21:19,347 epoch 2 - iter 4/13 - loss 8.49214530 - samples/sec: 63.79 - lr: 0.000030
2021-07-18 23:21:19,873 epoch 2 - iter 5/13 - loss 8.05345669 - samples/sec: 60.94 - lr: 0.000030
2021-07-18 23:21:20,380 epoch 2 - iter 6/13 - loss 7.50072749 - samples/sec: 63.10 - lr: 0.000030
2021-07-18 23:21:20,917 epoch 2 - iter 7/13 - loss 7.31072167 - samples/sec: 59.69 - lr: 0.000030
2021-07-18 23:21:21,444 epoch 2 - iter 8/13 - loss 7.06960142 - samples/sec: 60.81 - lr: 0.000030
2021-07-18 23:21:21,978 epoch 2 - iter 9/13 - loss 6.74062988 - samples/sec: 59.97 - lr: 0.000030
2021-07-18 23:21:22,510 epoch 2 - iter 10/13 - loss 6.53939600 - samples/sec: 60.20 - lr: 0.000030
2021-07-18 23:21:23,148 epoch 2 - iter 11/13 - loss 6.29624176 - samples/sec: 50.14 - lr: 0.000030
2021-07-18 23:21:23,688 epoch 2 - iter 12/13 - loss 6.09133697 - samples/sec: 59.34 - lr: 0.000030
2021-07-18 23:21:23,836 epoch 2 - iter 13/13 - loss 5.83765630 - samples/sec: 216.40 - lr: 0.000030
2021-07-18 23:21:23,837 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:23,837 EPOCH 2 done: loss 5.8377 - lr 0.0000300
2021-07-18 23:21:24,502 DEV : loss 2.947145462036133 - score 0.0
2021-07-18 23:21:24,511 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:21:28,355 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:28,861 epoch 3 - iter 1/13 - loss 3.12605381 - samples/sec: 63.34 - lr: 0.000030
2021-07-18 23:21:29,395 epoch 3 - iter 2/13 - loss 3.21328259 - samples/sec: 59.90 - lr: 0.000030
2021-07-18 23:21:29,918 epoch 3 - iter 3/13 - loss 3.22466882 - samples/sec: 61.31 - lr: 0.000030
2021-07-18 23:21:30,432 epoch 3 - iter 4/13 - loss 2.95068896 - samples/sec: 62.28 - lr: 0.000030
2021-07-18 23:21:30,969 epoch 3 - iter 5/13 - loss 2.95639377 - samples/sec: 59.60 - lr: 0.000030
2021-07-18 23:21:31,489 epoch 3 - iter 6/13 - loss 2.92897030 - samples/sec: 61.58 - lr: 0.000030
2021-07-18 23:21:32,018 epoch 3 - iter 7/13 - loss 2.94320842 - samples/sec: 60.55 - lr: 0.000030
2021-07-18 23:21:32,555 epoch 3 - iter 8/13 - loss 2.96888664 - samples/sec: 59.72 - lr: 0.000030
2021-07-18 23:21:33,095 epoch 3 - iter 9/13 - loss 3.00244935 - samples/sec: 59.23 - lr: 0.000030
2021-07-18 23:21:33,624 epoch 3 - iter 10/13 - loss 2.99640813 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 23:21:34,150 epoch 3 - iter 11/13 - loss 2.94074934 - samples/sec: 60.94 - lr: 0.000030
2021-07-18 23:21:34,688 epoch 3 - iter 12/13 - loss 3.02449201 - samples/sec: 59.55 - lr: 0.000030
2021-07-18 23:21:34,833 epoch 3 - iter 13/13 - loss 2.94053291 - samples/sec: 220.76 - lr: 0.000030
2021-07-18 23:21:34,833 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:34,834 EPOCH 3 done: loss 2.9405 - lr 0.0000300
2021-07-18 23:21:35,496 DEV : loss 2.2718942165374756 - score 0.0
2021-07-18 23:21:35,505 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:21:39,371 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:39,882 epoch 4 - iter 1/13 - loss 2.44924355 - samples/sec: 62.69 - lr: 0.000030
2021-07-18 23:21:40,420 epoch 4 - iter 2/13 - loss 2.54508281 - samples/sec: 59.55 - lr: 0.000030
2021-07-18 23:21:40,920 epoch 4 - iter 3/13 - loss 2.45826753 - samples/sec: 64.10 - lr: 0.000030
2021-07-18 23:21:41,456 epoch 4 - iter 4/13 - loss 2.32759625 - samples/sec: 59.72 - lr: 0.000030
2021-07-18 23:21:41,983 epoch 4 - iter 5/13 - loss 2.28765092 - samples/sec: 60.80 - lr: 0.000030
2021-07-18 23:21:42,509 epoch 4 - iter 6/13 - loss 2.23621416 - samples/sec: 60.85 - lr: 0.000030
2021-07-18 23:21:43,041 epoch 4 - iter 7/13 - loss 2.23988942 - samples/sec: 60.19 - lr: 0.000030
2021-07-18 23:21:43,568 epoch 4 - iter 8/13 - loss 2.17799315 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 23:21:44,091 epoch 4 - iter 9/13 - loss 2.11616450 - samples/sec: 61.26 - lr: 0.000030
2021-07-18 23:21:44,629 epoch 4 - iter 10/13 - loss 2.10508215 - samples/sec: 59.58 - lr: 0.000030
2021-07-18 23:21:45,160 epoch 4 - iter 11/13 - loss 2.07274074 - samples/sec: 60.33 - lr: 0.000030
2021-07-18 23:21:45,683 epoch 4 - iter 12/13 - loss 2.02537415 - samples/sec: 61.21 - lr: 0.000030
2021-07-18 23:21:45,838 epoch 4 - iter 13/13 - loss 1.96336038 - samples/sec: 206.87 - lr: 0.000030
2021-07-18 23:21:45,838 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:45,838 EPOCH 4 done: loss 1.9634 - lr 0.0000300
2021-07-18 23:21:46,499 DEV : loss 1.1665000915527344 - score 0.0759
2021-07-18 23:21:46,508 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:21:50,457 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:50,984 epoch 5 - iter 1/13 - loss 1.66748202 - samples/sec: 60.89 - lr: 0.000030
2021-07-18 23:21:51,522 epoch 5 - iter 2/13 - loss 1.47654110 - samples/sec: 59.47 - lr: 0.000030
2021-07-18 23:21:52,058 epoch 5 - iter 3/13 - loss 1.43252134 - samples/sec: 59.76 - lr: 0.000030
2021-07-18 23:21:52,593 epoch 5 - iter 4/13 - loss 1.41393432 - samples/sec: 59.92 - lr: 0.000030
2021-07-18 23:21:53,120 epoch 5 - iter 5/13 - loss 1.38125751 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 23:21:53,642 epoch 5 - iter 6/13 - loss 1.38974847 - samples/sec: 61.37 - lr: 0.000030
2021-07-18 23:21:54,172 epoch 5 - iter 7/13 - loss 1.35569612 - samples/sec: 60.47 - lr: 0.000030
2021-07-18 23:21:54,710 epoch 5 - iter 8/13 - loss 1.35509731 - samples/sec: 59.53 - lr: 0.000030
2021-07-18 23:21:55,242 epoch 5 - iter 9/13 - loss 1.32812848 - samples/sec: 60.14 - lr: 0.000030
2021-07-18 23:21:55,783 epoch 5 - iter 10/13 - loss 1.30365433 - samples/sec: 59.19 - lr: 0.000030
2021-07-18 23:21:56,323 epoch 5 - iter 11/13 - loss 1.27006729 - samples/sec: 59.36 - lr: 0.000030
2021-07-18 23:21:56,861 epoch 5 - iter 12/13 - loss 1.24388653 - samples/sec: 59.58 - lr: 0.000030
2021-07-18 23:21:57,000 epoch 5 - iter 13/13 - loss 1.24389159 - samples/sec: 230.54 - lr: 0.000030
2021-07-18 23:21:57,000 ----------------------------------------------------------------------------------------------------
2021-07-18 23:21:57,000 EPOCH 5 done: loss 1.2439 - lr 0.0000300
2021-07-18 23:21:57,666 DEV : loss 0.6480419635772705 - score 0.8154
2021-07-18 23:21:57,676 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:22:01,698 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:02,232 epoch 6 - iter 1/13 - loss 0.93010855 - samples/sec: 60.08 - lr: 0.000030
2021-07-18 23:22:02,758 epoch 6 - iter 2/13 - loss 0.84536350 - samples/sec: 60.80 - lr: 0.000030
2021-07-18 23:22:03,301 epoch 6 - iter 3/13 - loss 0.87556418 - samples/sec: 59.04 - lr: 0.000030
2021-07-18 23:22:03,835 epoch 6 - iter 4/13 - loss 0.86370903 - samples/sec: 59.98 - lr: 0.000030
2021-07-18 23:22:04,367 epoch 6 - iter 5/13 - loss 0.92038560 - samples/sec: 60.20 - lr: 0.000030
2021-07-18 23:22:04,890 epoch 6 - iter 6/13 - loss 0.87499132 - samples/sec: 61.18 - lr: 0.000030
2021-07-18 23:22:05,432 epoch 6 - iter 7/13 - loss 0.89541859 - samples/sec: 59.17 - lr: 0.000030
2021-07-18 23:22:05,967 epoch 6 - iter 8/13 - loss 0.90175679 - samples/sec: 59.80 - lr: 0.000030
2021-07-18 23:22:06,502 epoch 6 - iter 9/13 - loss 0.86973733 - samples/sec: 59.90 - lr: 0.000030
2021-07-18 23:22:07,045 epoch 6 - iter 10/13 - loss 0.83651313 - samples/sec: 59.02 - lr: 0.000030
2021-07-18 23:22:07,580 epoch 6 - iter 11/13 - loss 0.81177802 - samples/sec: 59.79 - lr: 0.000030
2021-07-18 23:22:08,107 epoch 6 - iter 12/13 - loss 0.79276860 - samples/sec: 60.82 - lr: 0.000030
2021-07-18 23:22:08,253 epoch 6 - iter 13/13 - loss 0.76169627 - samples/sec: 220.16 - lr: 0.000030
2021-07-18 23:22:08,253 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:08,253 EPOCH 6 done: loss 0.7617 - lr 0.0000300
2021-07-18 23:22:08,917 DEV : loss 0.4255013167858124 - score 0.8591
2021-07-18 23:22:08,926 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:22:12,901 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:13,416 epoch 7 - iter 1/13 - loss 0.67271513 - samples/sec: 62.26 - lr: 0.000030
2021-07-18 23:22:13,946 epoch 7 - iter 2/13 - loss 0.64701590 - samples/sec: 60.38 - lr: 0.000030
2021-07-18 23:22:14,476 epoch 7 - iter 3/13 - loss 0.55161550 - samples/sec: 60.48 - lr: 0.000030
2021-07-18 23:22:15,094 epoch 7 - iter 4/13 - loss 0.57757179 - samples/sec: 51.84 - lr: 0.000030
2021-07-18 23:22:15,627 epoch 7 - iter 5/13 - loss 0.63490809 - samples/sec: 60.09 - lr: 0.000030
2021-07-18 23:22:16,169 epoch 7 - iter 6/13 - loss 0.60325733 - samples/sec: 59.09 - lr: 0.000030
2021-07-18 23:22:16,705 epoch 7 - iter 7/13 - loss 0.57305056 - samples/sec: 59.75 - lr: 0.000030
2021-07-18 23:22:17,244 epoch 7 - iter 8/13 - loss 0.58361264 - samples/sec: 59.33 - lr: 0.000030
2021-07-18 23:22:17,770 epoch 7 - iter 9/13 - loss 0.57382696 - samples/sec: 60.96 - lr: 0.000030
2021-07-18 23:22:18,286 epoch 7 - iter 10/13 - loss 0.55708184 - samples/sec: 62.06 - lr: 0.000030
2021-07-18 23:22:18,828 epoch 7 - iter 11/13 - loss 0.55818176 - samples/sec: 59.08 - lr: 0.000030
2021-07-18 23:22:19,367 epoch 7 - iter 12/13 - loss 0.55193484 - samples/sec: 59.46 - lr: 0.000030
2021-07-18 23:22:19,524 epoch 7 - iter 13/13 - loss 0.55887405 - samples/sec: 204.06 - lr: 0.000030
2021-07-18 23:22:19,524 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:19,524 EPOCH 7 done: loss 0.5589 - lr 0.0000300
2021-07-18 23:22:20,190 DEV : loss 0.3591068387031555 - score 0.8816
2021-07-18 23:22:20,199 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:22:24,083 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:24,612 epoch 8 - iter 1/13 - loss 0.42771101 - samples/sec: 60.58 - lr: 0.000030
2021-07-18 23:22:25,147 epoch 8 - iter 2/13 - loss 0.48590434 - samples/sec: 59.84 - lr: 0.000030
2021-07-18 23:22:25,660 epoch 8 - iter 3/13 - loss 0.45010371 - samples/sec: 62.45 - lr: 0.000030
2021-07-18 23:22:26,174 epoch 8 - iter 4/13 - loss 0.48352135 - samples/sec: 62.31 - lr: 0.000030
2021-07-18 23:22:26,708 epoch 8 - iter 5/13 - loss 0.48295990 - samples/sec: 59.94 - lr: 0.000030
2021-07-18 23:22:27,231 epoch 8 - iter 6/13 - loss 0.52302728 - samples/sec: 61.25 - lr: 0.000030
2021-07-18 23:22:27,759 epoch 8 - iter 7/13 - loss 0.50364154 - samples/sec: 60.66 - lr: 0.000030
2021-07-18 23:22:28,289 epoch 8 - iter 8/13 - loss 0.51813406 - samples/sec: 60.50 - lr: 0.000030
2021-07-18 23:22:28,827 epoch 8 - iter 9/13 - loss 0.50219661 - samples/sec: 59.52 - lr: 0.000030
2021-07-18 23:22:29,370 epoch 8 - iter 10/13 - loss 0.50138932 - samples/sec: 58.93 - lr: 0.000030
2021-07-18 23:22:29,906 epoch 8 - iter 11/13 - loss 0.48785123 - samples/sec: 59.72 - lr: 0.000030
2021-07-18 23:22:30,438 epoch 8 - iter 12/13 - loss 0.47275084 - samples/sec: 60.29 - lr: 0.000030
2021-07-18 23:22:30,595 epoch 8 - iter 13/13 - loss 0.45105359 - samples/sec: 204.03 - lr: 0.000030
2021-07-18 23:22:30,595 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:30,595 EPOCH 8 done: loss 0.4511 - lr 0.0000300
2021-07-18 23:22:31,257 DEV : loss 0.3291495144367218 - score 0.8974
2021-07-18 23:22:31,266 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:22:34,427 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:34,944 epoch 9 - iter 1/13 - loss 0.37923729 - samples/sec: 61.92 - lr: 0.000030
2021-07-18 23:22:35,484 epoch 9 - iter 2/13 - loss 0.35915536 - samples/sec: 59.36 - lr: 0.000030
2021-07-18 23:22:36,015 epoch 9 - iter 3/13 - loss 0.34286626 - samples/sec: 60.32 - lr: 0.000030
2021-07-18 23:22:36,544 epoch 9 - iter 4/13 - loss 0.37799197 - samples/sec: 60.48 - lr: 0.000030
2021-07-18 23:22:37,066 epoch 9 - iter 5/13 - loss 0.38405824 - samples/sec: 61.42 - lr: 0.000030
2021-07-18 23:22:37,604 epoch 9 - iter 6/13 - loss 0.35214739 - samples/sec: 59.46 - lr: 0.000030
2021-07-18 23:22:38,143 epoch 9 - iter 7/13 - loss 0.35594753 - samples/sec: 59.49 - lr: 0.000030
2021-07-18 23:22:38,672 epoch 9 - iter 8/13 - loss 0.36378073 - samples/sec: 60.52 - lr: 0.000030
2021-07-18 23:22:39,187 epoch 9 - iter 9/13 - loss 0.38438179 - samples/sec: 62.25 - lr: 0.000030
2021-07-18 23:22:39,705 epoch 9 - iter 10/13 - loss 0.38399194 - samples/sec: 61.72 - lr: 0.000030
2021-07-18 23:22:40,244 epoch 9 - iter 11/13 - loss 0.37562633 - samples/sec: 59.45 - lr: 0.000030
2021-07-18 23:22:40,786 epoch 9 - iter 12/13 - loss 0.38264665 - samples/sec: 59.11 - lr: 0.000030
2021-07-18 23:22:40,942 epoch 9 - iter 13/13 - loss 0.36969413 - samples/sec: 205.88 - lr: 0.000030
2021-07-18 23:22:40,942 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:40,942 EPOCH 9 done: loss 0.3697 - lr 0.0000300
2021-07-18 23:22:41,604 DEV : loss 0.3162083327770233 - score 0.8987
2021-07-18 23:22:41,613 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:22:45,561 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:46,095 epoch 10 - iter 1/13 - loss 0.62266612 - samples/sec: 60.03 - lr: 0.000030
2021-07-18 23:22:46,628 epoch 10 - iter 2/13 - loss 0.52342966 - samples/sec: 60.11 - lr: 0.000030
2021-07-18 23:22:47,174 epoch 10 - iter 3/13 - loss 0.45983571 - samples/sec: 58.63 - lr: 0.000030
2021-07-18 23:22:47,679 epoch 10 - iter 4/13 - loss 0.41275865 - samples/sec: 63.53 - lr: 0.000030
2021-07-18 23:22:48,198 epoch 10 - iter 5/13 - loss 0.41233954 - samples/sec: 61.63 - lr: 0.000030
2021-07-18 23:22:48,740 epoch 10 - iter 6/13 - loss 0.40278435 - samples/sec: 59.12 - lr: 0.000030
2021-07-18 23:22:49,271 epoch 10 - iter 7/13 - loss 0.38624722 - samples/sec: 60.33 - lr: 0.000030
2021-07-18 23:22:49,814 epoch 10 - iter 8/13 - loss 0.35973718 - samples/sec: 58.91 - lr: 0.000030
2021-07-18 23:22:50,352 epoch 10 - iter 9/13 - loss 0.34850401 - samples/sec: 59.56 - lr: 0.000030
2021-07-18 23:22:50,884 epoch 10 - iter 10/13 - loss 0.35570663 - samples/sec: 60.18 - lr: 0.000030
2021-07-18 23:22:51,411 epoch 10 - iter 11/13 - loss 0.34209135 - samples/sec: 60.82 - lr: 0.000030
2021-07-18 23:22:51,946 epoch 10 - iter 12/13 - loss 0.33993876 - samples/sec: 59.83 - lr: 0.000030
2021-07-18 23:22:52,104 epoch 10 - iter 13/13 - loss 0.37718462 - samples/sec: 203.76 - lr: 0.000030
2021-07-18 23:22:52,104 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:52,104 EPOCH 10 done: loss 0.3772 - lr 0.0000300
2021-07-18 23:22:52,766 DEV : loss 0.3162473738193512 - score 0.9068
2021-07-18 23:22:52,775 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:22:56,733 ----------------------------------------------------------------------------------------------------
2021-07-18 23:22:57,260 epoch 11 - iter 1/13 - loss 0.24758887 - samples/sec: 60.90 - lr: 0.000030
2021-07-18 23:22:57,802 epoch 11 - iter 2/13 - loss 0.21135509 - samples/sec: 59.04 - lr: 0.000030
2021-07-18 23:22:58,340 epoch 11 - iter 3/13 - loss 0.24593933 - samples/sec: 59.59 - lr: 0.000030
2021-07-18 23:22:58,873 epoch 11 - iter 4/13 - loss 0.29272431 - samples/sec: 60.03 - lr: 0.000030
2021-07-18 23:22:59,401 epoch 11 - iter 5/13 - loss 0.27262732 - samples/sec: 60.70 - lr: 0.000030
2021-07-18 23:22:59,928 epoch 11 - iter 6/13 - loss 0.28885813 - samples/sec: 60.73 - lr: 0.000030
2021-07-18 23:23:00,451 epoch 11 - iter 7/13 - loss 0.27958982 - samples/sec: 61.30 - lr: 0.000030
2021-07-18 23:23:00,972 epoch 11 - iter 8/13 - loss 0.30118535 - samples/sec: 61.36 - lr: 0.000030
2021-07-18 23:23:01,512 epoch 11 - iter 9/13 - loss 0.31695322 - samples/sec: 59.33 - lr: 0.000030
2021-07-18 23:23:02,051 epoch 11 - iter 10/13 - loss 0.30717717 - samples/sec: 59.45 - lr: 0.000030
2021-07-18 23:23:02,597 epoch 11 - iter 11/13 - loss 0.30183446 - samples/sec: 58.68 - lr: 0.000030
2021-07-18 23:23:03,123 epoch 11 - iter 12/13 - loss 0.30245660 - samples/sec: 60.81 - lr: 0.000030
2021-07-18 23:23:03,280 epoch 11 - iter 13/13 - loss 0.31630644 - samples/sec: 205.31 - lr: 0.000030
2021-07-18 23:23:03,280 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:03,280 EPOCH 11 done: loss 0.3163 - lr 0.0000300
2021-07-18 23:23:03,947 DEV : loss 0.29674017429351807 - score 0.8987
2021-07-18 23:23:03,956 BAD EPOCHS (no improvement): 1
2021-07-18 23:23:03,956 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:04,470 epoch 12 - iter 1/13 - loss 0.29686391 - samples/sec: 62.31 - lr: 0.000030
2021-07-18 23:23:04,995 epoch 12 - iter 2/13 - loss 0.22685663 - samples/sec: 61.02 - lr: 0.000030
2021-07-18 23:23:05,540 epoch 12 - iter 3/13 - loss 0.25452776 - samples/sec: 58.74 - lr: 0.000030
2021-07-18 23:23:06,075 epoch 12 - iter 4/13 - loss 0.22149902 - samples/sec: 59.94 - lr: 0.000030
2021-07-18 23:23:06,596 epoch 12 - iter 5/13 - loss 0.23370035 - samples/sec: 61.47 - lr: 0.000030
2021-07-18 23:23:07,139 epoch 12 - iter 6/13 - loss 0.26402428 - samples/sec: 58.93 - lr: 0.000030
2021-07-18 23:23:07,676 epoch 12 - iter 7/13 - loss 0.26587849 - samples/sec: 59.62 - lr: 0.000030
2021-07-18 23:23:08,211 epoch 12 - iter 8/13 - loss 0.31215939 - samples/sec: 59.96 - lr: 0.000030
2021-07-18 23:23:08,743 epoch 12 - iter 9/13 - loss 0.29267348 - samples/sec: 60.18 - lr: 0.000030
2021-07-18 23:23:09,275 epoch 12 - iter 10/13 - loss 0.28822533 - samples/sec: 60.23 - lr: 0.000030
2021-07-18 23:23:09,808 epoch 12 - iter 11/13 - loss 0.27850553 - samples/sec: 60.03 - lr: 0.000030
2021-07-18 23:23:10,339 epoch 12 - iter 12/13 - loss 0.28047713 - samples/sec: 60.32 - lr: 0.000030
2021-07-18 23:23:10,495 epoch 12 - iter 13/13 - loss 0.26837865 - samples/sec: 206.44 - lr: 0.000030
2021-07-18 23:23:10,495 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:10,495 EPOCH 12 done: loss 0.2684 - lr 0.0000300
2021-07-18 23:23:11,241 DEV : loss 0.29751670360565186 - score 0.9
2021-07-18 23:23:11,251 BAD EPOCHS (no improvement): 2
2021-07-18 23:23:11,251 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:11,771 epoch 13 - iter 1/13 - loss 0.37002730 - samples/sec: 61.61 - lr: 0.000030
2021-07-18 23:23:12,299 epoch 13 - iter 2/13 - loss 0.28558582 - samples/sec: 60.63 - lr: 0.000030
2021-07-18 23:23:12,827 epoch 13 - iter 3/13 - loss 0.26602352 - samples/sec: 60.60 - lr: 0.000030
2021-07-18 23:23:13,366 epoch 13 - iter 4/13 - loss 0.22775128 - samples/sec: 59.47 - lr: 0.000030
2021-07-18 23:23:13,907 epoch 13 - iter 5/13 - loss 0.26418154 - samples/sec: 59.19 - lr: 0.000030
2021-07-18 23:23:14,435 epoch 13 - iter 6/13 - loss 0.29470466 - samples/sec: 60.66 - lr: 0.000030
2021-07-18 23:23:14,954 epoch 13 - iter 7/13 - loss 0.29319378 - samples/sec: 61.76 - lr: 0.000030
2021-07-18 23:23:15,494 epoch 13 - iter 8/13 - loss 0.30041903 - samples/sec: 59.29 - lr: 0.000030
2021-07-18 23:23:16,008 epoch 13 - iter 9/13 - loss 0.28223051 - samples/sec: 62.34 - lr: 0.000030
2021-07-18 23:23:16,544 epoch 13 - iter 10/13 - loss 0.28686063 - samples/sec: 59.70 - lr: 0.000030
2021-07-18 23:23:17,079 epoch 13 - iter 11/13 - loss 0.28180598 - samples/sec: 59.88 - lr: 0.000030
2021-07-18 23:23:17,624 epoch 13 - iter 12/13 - loss 0.28796729 - samples/sec: 58.79 - lr: 0.000030
2021-07-18 23:23:17,780 epoch 13 - iter 13/13 - loss 0.27270257 - samples/sec: 205.43 - lr: 0.000030
2021-07-18 23:23:17,780 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:17,780 EPOCH 13 done: loss 0.2727 - lr 0.0000300
2021-07-18 23:23:18,442 DEV : loss 0.2862018644809723 - score 0.8917
2021-07-18 23:23:18,451 BAD EPOCHS (no improvement): 3
2021-07-18 23:23:18,452 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:18,976 epoch 14 - iter 1/13 - loss 0.23761296 - samples/sec: 61.04 - lr: 0.000030
2021-07-18 23:23:19,490 epoch 14 - iter 2/13 - loss 0.24060202 - samples/sec: 62.35 - lr: 0.000030
2021-07-18 23:23:20,019 epoch 14 - iter 3/13 - loss 0.19932791 - samples/sec: 60.55 - lr: 0.000030
2021-07-18 23:23:20,553 epoch 14 - iter 4/13 - loss 0.23052981 - samples/sec: 59.97 - lr: 0.000030
2021-07-18 23:23:21,088 epoch 14 - iter 5/13 - loss 0.24055285 - samples/sec: 59.91 - lr: 0.000030
2021-07-18 23:23:21,619 epoch 14 - iter 6/13 - loss 0.24809914 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 23:23:22,143 epoch 14 - iter 7/13 - loss 0.24919852 - samples/sec: 61.13 - lr: 0.000030
2021-07-18 23:23:22,670 epoch 14 - iter 8/13 - loss 0.24883063 - samples/sec: 60.74 - lr: 0.000030
2021-07-18 23:23:23,198 epoch 14 - iter 9/13 - loss 0.25090156 - samples/sec: 60.65 - lr: 0.000030
2021-07-18 23:23:23,736 epoch 14 - iter 10/13 - loss 0.26048605 - samples/sec: 59.56 - lr: 0.000030
2021-07-18 23:23:24,274 epoch 14 - iter 11/13 - loss 0.27949814 - samples/sec: 59.47 - lr: 0.000030
2021-07-18 23:23:24,811 epoch 14 - iter 12/13 - loss 0.29224783 - samples/sec: 59.61 - lr: 0.000030
2021-07-18 23:23:24,968 epoch 14 - iter 13/13 - loss 0.27630934 - samples/sec: 205.35 - lr: 0.000030
2021-07-18 23:23:24,968 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:24,968 EPOCH 14 done: loss 0.2763 - lr 0.0000300
2021-07-18 23:23:25,630 DEV : loss 0.2820349335670471 - score 0.9057
Epoch    14: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 23:23:25,639 BAD EPOCHS (no improvement): 4
2021-07-18 23:23:25,639 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:26,151 epoch 15 - iter 1/13 - loss 0.10140893 - samples/sec: 62.63 - lr: 0.000015
2021-07-18 23:23:26,687 epoch 15 - iter 2/13 - loss 0.16345772 - samples/sec: 59.77 - lr: 0.000015
2021-07-18 23:23:27,211 epoch 15 - iter 3/13 - loss 0.19942482 - samples/sec: 61.08 - lr: 0.000015
2021-07-18 23:23:27,746 epoch 15 - iter 4/13 - loss 0.21432644 - samples/sec: 59.86 - lr: 0.000015
2021-07-18 23:23:28,290 epoch 15 - iter 5/13 - loss 0.23852286 - samples/sec: 58.86 - lr: 0.000015
2021-07-18 23:23:28,823 epoch 15 - iter 6/13 - loss 0.24402938 - samples/sec: 60.09 - lr: 0.000015
2021-07-18 23:23:29,371 epoch 15 - iter 7/13 - loss 0.22718241 - samples/sec: 58.47 - lr: 0.000015
2021-07-18 23:23:29,907 epoch 15 - iter 8/13 - loss 0.26118691 - samples/sec: 59.69 - lr: 0.000015
2021-07-18 23:23:30,433 epoch 15 - iter 9/13 - loss 0.25908831 - samples/sec: 60.96 - lr: 0.000015
2021-07-18 23:23:30,966 epoch 15 - iter 10/13 - loss 0.26104489 - samples/sec: 60.10 - lr: 0.000015
2021-07-18 23:23:31,486 epoch 15 - iter 11/13 - loss 0.25470053 - samples/sec: 61.52 - lr: 0.000015
2021-07-18 23:23:32,026 epoch 15 - iter 12/13 - loss 0.24420140 - samples/sec: 59.28 - lr: 0.000015
2021-07-18 23:23:32,183 epoch 15 - iter 13/13 - loss 0.23995244 - samples/sec: 205.62 - lr: 0.000015
2021-07-18 23:23:32,183 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:32,183 EPOCH 15 done: loss 0.2400 - lr 0.0000150
2021-07-18 23:23:32,845 DEV : loss 0.2794695496559143 - score 0.9
2021-07-18 23:23:32,854 BAD EPOCHS (no improvement): 1
2021-07-18 23:23:32,854 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:33,383 epoch 16 - iter 1/13 - loss 0.15958166 - samples/sec: 60.53 - lr: 0.000015
2021-07-18 23:23:33,922 epoch 16 - iter 2/13 - loss 0.13885456 - samples/sec: 59.45 - lr: 0.000015
2021-07-18 23:23:34,450 epoch 16 - iter 3/13 - loss 0.14764415 - samples/sec: 60.62 - lr: 0.000015
2021-07-18 23:23:34,992 epoch 16 - iter 4/13 - loss 0.15677770 - samples/sec: 59.15 - lr: 0.000015
2021-07-18 23:23:35,534 epoch 16 - iter 5/13 - loss 0.15387103 - samples/sec: 59.06 - lr: 0.000015
2021-07-18 23:23:36,064 epoch 16 - iter 6/13 - loss 0.16184630 - samples/sec: 60.47 - lr: 0.000015
2021-07-18 23:23:36,588 epoch 16 - iter 7/13 - loss 0.17814849 - samples/sec: 61.13 - lr: 0.000015
2021-07-18 23:23:37,095 epoch 16 - iter 8/13 - loss 0.18074986 - samples/sec: 63.15 - lr: 0.000015
2021-07-18 23:23:37,634 epoch 16 - iter 9/13 - loss 0.20030848 - samples/sec: 59.39 - lr: 0.000015
2021-07-18 23:23:38,175 epoch 16 - iter 10/13 - loss 0.19322049 - samples/sec: 59.20 - lr: 0.000015
2021-07-18 23:23:38,718 epoch 16 - iter 11/13 - loss 0.19227305 - samples/sec: 58.99 - lr: 0.000015
2021-07-18 23:23:39,258 epoch 16 - iter 12/13 - loss 0.19947697 - samples/sec: 59.32 - lr: 0.000015
2021-07-18 23:23:39,404 epoch 16 - iter 13/13 - loss 0.23592345 - samples/sec: 219.88 - lr: 0.000015
2021-07-18 23:23:39,404 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:39,404 EPOCH 16 done: loss 0.2359 - lr 0.0000150
2021-07-18 23:23:40,068 DEV : loss 0.27577534317970276 - score 0.9
2021-07-18 23:23:40,077 BAD EPOCHS (no improvement): 2
2021-07-18 23:23:40,077 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:40,590 epoch 17 - iter 1/13 - loss 0.14378327 - samples/sec: 62.43 - lr: 0.000015
2021-07-18 23:23:41,126 epoch 17 - iter 2/13 - loss 0.32648918 - samples/sec: 59.83 - lr: 0.000015
2021-07-18 23:23:41,655 epoch 17 - iter 3/13 - loss 0.30763332 - samples/sec: 60.52 - lr: 0.000015
2021-07-18 23:23:42,187 epoch 17 - iter 4/13 - loss 0.34167662 - samples/sec: 60.16 - lr: 0.000015
2021-07-18 23:23:42,711 epoch 17 - iter 5/13 - loss 0.34025297 - samples/sec: 61.10 - lr: 0.000015
2021-07-18 23:23:43,244 epoch 17 - iter 6/13 - loss 0.30764157 - samples/sec: 60.18 - lr: 0.000015
2021-07-18 23:23:43,782 epoch 17 - iter 7/13 - loss 0.29132958 - samples/sec: 59.43 - lr: 0.000015
2021-07-18 23:23:44,326 epoch 17 - iter 8/13 - loss 0.28385540 - samples/sec: 58.92 - lr: 0.000015
2021-07-18 23:23:44,851 epoch 17 - iter 9/13 - loss 0.25970596 - samples/sec: 61.05 - lr: 0.000015
2021-07-18 23:23:45,390 epoch 17 - iter 10/13 - loss 0.27151281 - samples/sec: 59.32 - lr: 0.000015
2021-07-18 23:23:45,931 epoch 17 - iter 11/13 - loss 0.26286859 - samples/sec: 59.24 - lr: 0.000015
2021-07-18 23:23:46,458 epoch 17 - iter 12/13 - loss 0.25181286 - samples/sec: 60.82 - lr: 0.000015
2021-07-18 23:23:46,608 epoch 17 - iter 13/13 - loss 0.24358557 - samples/sec: 212.77 - lr: 0.000015
2021-07-18 23:23:46,609 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:46,609 EPOCH 17 done: loss 0.2436 - lr 0.0000150
2021-07-18 23:23:47,270 DEV : loss 0.27335262298583984 - score 0.9057
2021-07-18 23:23:47,279 BAD EPOCHS (no improvement): 3
2021-07-18 23:23:47,280 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:47,811 epoch 18 - iter 1/13 - loss 0.20010829 - samples/sec: 60.27 - lr: 0.000015
2021-07-18 23:23:48,334 epoch 18 - iter 2/13 - loss 0.29435262 - samples/sec: 61.20 - lr: 0.000015
2021-07-18 23:23:48,859 epoch 18 - iter 3/13 - loss 0.28542197 - samples/sec: 61.07 - lr: 0.000015
2021-07-18 23:23:49,393 epoch 18 - iter 4/13 - loss 0.28164402 - samples/sec: 59.96 - lr: 0.000015
2021-07-18 23:23:49,932 epoch 18 - iter 5/13 - loss 0.25875652 - samples/sec: 59.42 - lr: 0.000015
2021-07-18 23:23:50,462 epoch 18 - iter 6/13 - loss 0.25348042 - samples/sec: 60.37 - lr: 0.000015
2021-07-18 23:23:50,990 epoch 18 - iter 7/13 - loss 0.23591725 - samples/sec: 60.72 - lr: 0.000015
2021-07-18 23:23:51,522 epoch 18 - iter 8/13 - loss 0.22373296 - samples/sec: 60.21 - lr: 0.000015
2021-07-18 23:23:52,054 epoch 18 - iter 9/13 - loss 0.20754739 - samples/sec: 60.17 - lr: 0.000015
2021-07-18 23:23:52,594 epoch 18 - iter 10/13 - loss 0.21003453 - samples/sec: 59.30 - lr: 0.000015
2021-07-18 23:23:53,122 epoch 18 - iter 11/13 - loss 0.21778236 - samples/sec: 60.66 - lr: 0.000015
2021-07-18 23:23:53,651 epoch 18 - iter 12/13 - loss 0.21779022 - samples/sec: 60.54 - lr: 0.000015
2021-07-18 23:23:53,809 epoch 18 - iter 13/13 - loss 0.21551987 - samples/sec: 203.77 - lr: 0.000015
2021-07-18 23:23:53,809 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:53,809 EPOCH 18 done: loss 0.2155 - lr 0.0000150
2021-07-18 23:23:54,554 DEV : loss 0.27086392045021057 - score 0.9114
2021-07-18 23:23:54,564 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:23:58,380 ----------------------------------------------------------------------------------------------------
2021-07-18 23:23:58,919 epoch 19 - iter 1/13 - loss 0.24285650 - samples/sec: 59.52 - lr: 0.000015
2021-07-18 23:23:59,451 epoch 19 - iter 2/13 - loss 0.22657329 - samples/sec: 60.12 - lr: 0.000015
2021-07-18 23:23:59,978 epoch 19 - iter 3/13 - loss 0.22779105 - samples/sec: 60.78 - lr: 0.000015
2021-07-18 23:24:00,508 epoch 19 - iter 4/13 - loss 0.20726864 - samples/sec: 60.52 - lr: 0.000015
2021-07-18 23:24:01,040 epoch 19 - iter 5/13 - loss 0.21446819 - samples/sec: 60.15 - lr: 0.000015
2021-07-18 23:24:01,572 epoch 19 - iter 6/13 - loss 0.19018934 - samples/sec: 60.27 - lr: 0.000015
2021-07-18 23:24:02,117 epoch 19 - iter 7/13 - loss 0.21686975 - samples/sec: 58.76 - lr: 0.000015
2021-07-18 23:24:02,655 epoch 19 - iter 8/13 - loss 0.23075606 - samples/sec: 59.53 - lr: 0.000015
2021-07-18 23:24:03,176 epoch 19 - iter 9/13 - loss 0.22315845 - samples/sec: 61.40 - lr: 0.000015
2021-07-18 23:24:03,715 epoch 19 - iter 10/13 - loss 0.21142255 - samples/sec: 59.46 - lr: 0.000015
2021-07-18 23:24:04,244 epoch 19 - iter 11/13 - loss 0.20745878 - samples/sec: 60.51 - lr: 0.000015
2021-07-18 23:24:04,779 epoch 19 - iter 12/13 - loss 0.20137627 - samples/sec: 59.91 - lr: 0.000015
2021-07-18 23:24:04,934 epoch 19 - iter 13/13 - loss 0.19679700 - samples/sec: 206.71 - lr: 0.000015
2021-07-18 23:24:04,934 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:04,934 EPOCH 19 done: loss 0.1968 - lr 0.0000150
2021-07-18 23:24:05,594 DEV : loss 0.2632533013820648 - score 0.9045
2021-07-18 23:24:05,603 BAD EPOCHS (no improvement): 1
2021-07-18 23:24:05,603 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:06,111 epoch 20 - iter 1/13 - loss 0.11108950 - samples/sec: 63.07 - lr: 0.000015
2021-07-18 23:24:06,639 epoch 20 - iter 2/13 - loss 0.18089972 - samples/sec: 60.65 - lr: 0.000015
2021-07-18 23:24:07,175 epoch 20 - iter 3/13 - loss 0.17170897 - samples/sec: 59.80 - lr: 0.000015
2021-07-18 23:24:07,706 epoch 20 - iter 4/13 - loss 0.18126514 - samples/sec: 60.25 - lr: 0.000015
2021-07-18 23:24:08,236 epoch 20 - iter 5/13 - loss 0.17270500 - samples/sec: 60.49 - lr: 0.000015
2021-07-18 23:24:08,759 epoch 20 - iter 6/13 - loss 0.17860888 - samples/sec: 61.22 - lr: 0.000015
2021-07-18 23:24:09,306 epoch 20 - iter 7/13 - loss 0.17538686 - samples/sec: 58.51 - lr: 0.000015
2021-07-18 23:24:09,840 epoch 20 - iter 8/13 - loss 0.18075811 - samples/sec: 60.01 - lr: 0.000015
2021-07-18 23:24:10,371 epoch 20 - iter 9/13 - loss 0.18433791 - samples/sec: 60.34 - lr: 0.000015
2021-07-18 23:24:10,912 epoch 20 - iter 10/13 - loss 0.17551439 - samples/sec: 59.18 - lr: 0.000015
2021-07-18 23:24:11,451 epoch 20 - iter 11/13 - loss 0.17909824 - samples/sec: 59.42 - lr: 0.000015
2021-07-18 23:24:11,982 epoch 20 - iter 12/13 - loss 0.19288299 - samples/sec: 60.26 - lr: 0.000015
2021-07-18 23:24:12,139 epoch 20 - iter 13/13 - loss 0.18158372 - samples/sec: 204.74 - lr: 0.000015
2021-07-18 23:24:12,139 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:12,139 EPOCH 20 done: loss 0.1816 - lr 0.0000150
2021-07-18 23:24:12,799 DEV : loss 0.2644091248512268 - score 0.9114
2021-07-18 23:24:12,808 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:24:16,892 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:17,428 epoch 21 - iter 1/13 - loss 0.18778777 - samples/sec: 59.76 - lr: 0.000015
2021-07-18 23:24:17,962 epoch 21 - iter 2/13 - loss 0.14034379 - samples/sec: 60.02 - lr: 0.000015
2021-07-18 23:24:18,488 epoch 21 - iter 3/13 - loss 0.11528820 - samples/sec: 60.83 - lr: 0.000015
2021-07-18 23:24:19,024 epoch 21 - iter 4/13 - loss 0.15649955 - samples/sec: 59.85 - lr: 0.000015
2021-07-18 23:24:19,564 epoch 21 - iter 5/13 - loss 0.18319267 - samples/sec: 59.25 - lr: 0.000015
2021-07-18 23:24:20,096 epoch 21 - iter 6/13 - loss 0.16962575 - samples/sec: 60.21 - lr: 0.000015
2021-07-18 23:24:20,621 epoch 21 - iter 7/13 - loss 0.16016820 - samples/sec: 60.96 - lr: 0.000015
2021-07-18 23:24:21,155 epoch 21 - iter 8/13 - loss 0.16453921 - samples/sec: 60.02 - lr: 0.000015
2021-07-18 23:24:21,689 epoch 21 - iter 9/13 - loss 0.16021899 - samples/sec: 60.03 - lr: 0.000015
2021-07-18 23:24:22,223 epoch 21 - iter 10/13 - loss 0.16174303 - samples/sec: 59.94 - lr: 0.000015
2021-07-18 23:24:22,752 epoch 21 - iter 11/13 - loss 0.18607932 - samples/sec: 60.49 - lr: 0.000015
2021-07-18 23:24:23,286 epoch 21 - iter 12/13 - loss 0.18499499 - samples/sec: 59.97 - lr: 0.000015
2021-07-18 23:24:23,442 epoch 21 - iter 13/13 - loss 0.18103084 - samples/sec: 205.77 - lr: 0.000015
2021-07-18 23:24:23,443 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:23,443 EPOCH 21 done: loss 0.1810 - lr 0.0000150
2021-07-18 23:24:24,104 DEV : loss 0.2654823064804077 - score 0.9114
2021-07-18 23:24:24,113 BAD EPOCHS (no improvement): 1
2021-07-18 23:24:24,114 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:24,634 epoch 22 - iter 1/13 - loss 0.17093754 - samples/sec: 61.51 - lr: 0.000015
2021-07-18 23:24:25,176 epoch 22 - iter 2/13 - loss 0.26350260 - samples/sec: 59.06 - lr: 0.000015
2021-07-18 23:24:25,691 epoch 22 - iter 3/13 - loss 0.19648311 - samples/sec: 62.20 - lr: 0.000015
2021-07-18 23:24:26,229 epoch 22 - iter 4/13 - loss 0.18408922 - samples/sec: 59.52 - lr: 0.000015
2021-07-18 23:24:26,772 epoch 22 - iter 5/13 - loss 0.16982263 - samples/sec: 59.01 - lr: 0.000015
2021-07-18 23:24:27,310 epoch 22 - iter 6/13 - loss 0.20765267 - samples/sec: 59.50 - lr: 0.000015
2021-07-18 23:24:27,835 epoch 22 - iter 7/13 - loss 0.19518273 - samples/sec: 61.10 - lr: 0.000015
2021-07-18 23:24:28,376 epoch 22 - iter 8/13 - loss 0.19742939 - samples/sec: 59.14 - lr: 0.000015
2021-07-18 23:24:28,921 epoch 22 - iter 9/13 - loss 0.19826780 - samples/sec: 58.82 - lr: 0.000015
2021-07-18 23:24:29,456 epoch 22 - iter 10/13 - loss 0.19208660 - samples/sec: 59.79 - lr: 0.000015
2021-07-18 23:24:29,974 epoch 22 - iter 11/13 - loss 0.19171744 - samples/sec: 61.87 - lr: 0.000015
2021-07-18 23:24:30,500 epoch 22 - iter 12/13 - loss 0.18375400 - samples/sec: 60.87 - lr: 0.000015
2021-07-18 23:24:30,647 epoch 22 - iter 13/13 - loss 0.17296323 - samples/sec: 219.27 - lr: 0.000015
2021-07-18 23:24:30,647 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:30,647 EPOCH 22 done: loss 0.1730 - lr 0.0000150
2021-07-18 23:24:31,309 DEV : loss 0.2763341963291168 - score 0.9057
2021-07-18 23:24:31,318 BAD EPOCHS (no improvement): 2
2021-07-18 23:24:31,318 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:31,840 epoch 23 - iter 1/13 - loss 0.12052703 - samples/sec: 61.36 - lr: 0.000015
2021-07-18 23:24:32,380 epoch 23 - iter 2/13 - loss 0.10923493 - samples/sec: 59.33 - lr: 0.000015
2021-07-18 23:24:32,923 epoch 23 - iter 3/13 - loss 0.14575148 - samples/sec: 58.94 - lr: 0.000015
2021-07-18 23:24:33,462 epoch 23 - iter 4/13 - loss 0.14305890 - samples/sec: 59.39 - lr: 0.000015
2021-07-18 23:24:33,995 epoch 23 - iter 5/13 - loss 0.13823183 - samples/sec: 60.12 - lr: 0.000015
2021-07-18 23:24:34,523 epoch 23 - iter 6/13 - loss 0.12832669 - samples/sec: 60.69 - lr: 0.000015
2021-07-18 23:24:35,058 epoch 23 - iter 7/13 - loss 0.13648163 - samples/sec: 59.87 - lr: 0.000015
2021-07-18 23:24:35,582 epoch 23 - iter 8/13 - loss 0.13332997 - samples/sec: 61.12 - lr: 0.000015
2021-07-18 23:24:36,113 epoch 23 - iter 9/13 - loss 0.13169507 - samples/sec: 60.29 - lr: 0.000015
2021-07-18 23:24:36,640 epoch 23 - iter 10/13 - loss 0.13114180 - samples/sec: 60.84 - lr: 0.000015
2021-07-18 23:24:37,156 epoch 23 - iter 11/13 - loss 0.14127915 - samples/sec: 62.04 - lr: 0.000015
2021-07-18 23:24:37,684 epoch 23 - iter 12/13 - loss 0.14214236 - samples/sec: 60.68 - lr: 0.000015
2021-07-18 23:24:37,839 epoch 23 - iter 13/13 - loss 0.16268526 - samples/sec: 206.03 - lr: 0.000015
2021-07-18 23:24:37,840 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:37,840 EPOCH 23 done: loss 0.1627 - lr 0.0000150
2021-07-18 23:24:38,502 DEV : loss 0.2665417790412903 - score 0.9114
2021-07-18 23:24:38,511 BAD EPOCHS (no improvement): 3
2021-07-18 23:24:38,511 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:39,125 epoch 24 - iter 1/13 - loss 0.29941702 - samples/sec: 52.21 - lr: 0.000015
2021-07-18 23:24:39,651 epoch 24 - iter 2/13 - loss 0.26467425 - samples/sec: 60.83 - lr: 0.000015
2021-07-18 23:24:40,188 epoch 24 - iter 3/13 - loss 0.23317345 - samples/sec: 59.63 - lr: 0.000015
2021-07-18 23:24:40,724 epoch 24 - iter 4/13 - loss 0.22698206 - samples/sec: 59.81 - lr: 0.000015
2021-07-18 23:24:41,252 epoch 24 - iter 5/13 - loss 0.20709126 - samples/sec: 60.64 - lr: 0.000015
2021-07-18 23:24:41,770 epoch 24 - iter 6/13 - loss 0.19266036 - samples/sec: 61.83 - lr: 0.000015
2021-07-18 23:24:42,311 epoch 24 - iter 7/13 - loss 0.18295740 - samples/sec: 59.21 - lr: 0.000015
2021-07-18 23:24:42,840 epoch 24 - iter 8/13 - loss 0.19945825 - samples/sec: 60.48 - lr: 0.000015
2021-07-18 23:24:43,356 epoch 24 - iter 9/13 - loss 0.19396794 - samples/sec: 62.06 - lr: 0.000015
2021-07-18 23:24:43,899 epoch 24 - iter 10/13 - loss 0.18832327 - samples/sec: 58.97 - lr: 0.000015
2021-07-18 23:24:44,434 epoch 24 - iter 11/13 - loss 0.18401698 - samples/sec: 59.89 - lr: 0.000015
2021-07-18 23:24:44,975 epoch 24 - iter 12/13 - loss 0.17650966 - samples/sec: 59.24 - lr: 0.000015
2021-07-18 23:24:45,131 epoch 24 - iter 13/13 - loss 0.17058183 - samples/sec: 205.63 - lr: 0.000015
2021-07-18 23:24:45,131 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:45,131 EPOCH 24 done: loss 0.1706 - lr 0.0000150
2021-07-18 23:24:45,792 DEV : loss 0.266303151845932 - score 0.9114
Epoch    24: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 23:24:45,801 BAD EPOCHS (no improvement): 4
2021-07-18 23:24:45,802 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:46,323 epoch 25 - iter 1/13 - loss 0.24518210 - samples/sec: 61.37 - lr: 0.000008
2021-07-18 23:24:46,852 epoch 25 - iter 2/13 - loss 0.27509087 - samples/sec: 60.56 - lr: 0.000008
2021-07-18 23:24:47,377 epoch 25 - iter 3/13 - loss 0.28839368 - samples/sec: 60.97 - lr: 0.000008
2021-07-18 23:24:47,910 epoch 25 - iter 4/13 - loss 0.26687939 - samples/sec: 60.10 - lr: 0.000008
2021-07-18 23:24:48,450 epoch 25 - iter 5/13 - loss 0.23699857 - samples/sec: 59.32 - lr: 0.000008
2021-07-18 23:24:48,983 epoch 25 - iter 6/13 - loss 0.20458167 - samples/sec: 60.07 - lr: 0.000008
2021-07-18 23:24:49,523 epoch 25 - iter 7/13 - loss 0.20064144 - samples/sec: 59.33 - lr: 0.000008
2021-07-18 23:24:50,060 epoch 25 - iter 8/13 - loss 0.19045515 - samples/sec: 59.66 - lr: 0.000008
2021-07-18 23:24:50,583 epoch 25 - iter 9/13 - loss 0.19901131 - samples/sec: 61.23 - lr: 0.000008
2021-07-18 23:24:51,112 epoch 25 - iter 10/13 - loss 0.19666337 - samples/sec: 60.53 - lr: 0.000008
2021-07-18 23:24:51,638 epoch 25 - iter 11/13 - loss 0.18359800 - samples/sec: 60.95 - lr: 0.000008
2021-07-18 23:24:52,174 epoch 25 - iter 12/13 - loss 0.18587381 - samples/sec: 59.68 - lr: 0.000008
2021-07-18 23:24:52,325 epoch 25 - iter 13/13 - loss 0.18614807 - samples/sec: 212.90 - lr: 0.000008
2021-07-18 23:24:52,325 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:52,325 EPOCH 25 done: loss 0.1861 - lr 0.0000075
2021-07-18 23:24:52,987 DEV : loss 0.2680935263633728 - score 0.9114
2021-07-18 23:24:52,996 BAD EPOCHS (no improvement): 1
2021-07-18 23:24:52,996 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:53,515 epoch 26 - iter 1/13 - loss 0.22596240 - samples/sec: 61.71 - lr: 0.000008
2021-07-18 23:24:54,043 epoch 26 - iter 2/13 - loss 0.16456413 - samples/sec: 60.65 - lr: 0.000008
2021-07-18 23:24:54,570 epoch 26 - iter 3/13 - loss 0.20300446 - samples/sec: 60.79 - lr: 0.000008
2021-07-18 23:24:55,111 epoch 26 - iter 4/13 - loss 0.22718389 - samples/sec: 59.18 - lr: 0.000008
2021-07-18 23:24:55,638 epoch 26 - iter 5/13 - loss 0.22125460 - samples/sec: 60.76 - lr: 0.000008
2021-07-18 23:24:56,166 epoch 26 - iter 6/13 - loss 0.19859523 - samples/sec: 60.70 - lr: 0.000008
2021-07-18 23:24:56,706 epoch 26 - iter 7/13 - loss 0.18435514 - samples/sec: 59.29 - lr: 0.000008
2021-07-18 23:24:57,234 epoch 26 - iter 8/13 - loss 0.16828443 - samples/sec: 60.62 - lr: 0.000008
2021-07-18 23:24:57,767 epoch 26 - iter 9/13 - loss 0.16217021 - samples/sec: 60.13 - lr: 0.000008
2021-07-18 23:24:58,303 epoch 26 - iter 10/13 - loss 0.17407779 - samples/sec: 59.77 - lr: 0.000008
2021-07-18 23:24:58,831 epoch 26 - iter 11/13 - loss 0.17512317 - samples/sec: 60.62 - lr: 0.000008
2021-07-18 23:24:59,366 epoch 26 - iter 12/13 - loss 0.16946295 - samples/sec: 59.85 - lr: 0.000008
2021-07-18 23:24:59,522 epoch 26 - iter 13/13 - loss 0.16017846 - samples/sec: 205.63 - lr: 0.000008
2021-07-18 23:24:59,523 ----------------------------------------------------------------------------------------------------
2021-07-18 23:24:59,523 EPOCH 26 done: loss 0.1602 - lr 0.0000075
2021-07-18 23:25:00,184 DEV : loss 0.2719665467739105 - score 0.9114
2021-07-18 23:25:00,193 BAD EPOCHS (no improvement): 2
2021-07-18 23:25:00,193 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:00,720 epoch 27 - iter 1/13 - loss 0.20838070 - samples/sec: 60.81 - lr: 0.000008
2021-07-18 23:25:01,237 epoch 27 - iter 2/13 - loss 0.20617616 - samples/sec: 61.90 - lr: 0.000008
2021-07-18 23:25:01,765 epoch 27 - iter 3/13 - loss 0.20689797 - samples/sec: 60.65 - lr: 0.000008
2021-07-18 23:25:02,275 epoch 27 - iter 4/13 - loss 0.26968650 - samples/sec: 62.88 - lr: 0.000008
2021-07-18 23:25:02,820 epoch 27 - iter 5/13 - loss 0.23283475 - samples/sec: 58.70 - lr: 0.000008
2021-07-18 23:25:03,359 epoch 27 - iter 6/13 - loss 0.22556415 - samples/sec: 59.41 - lr: 0.000008
2021-07-18 23:25:03,898 epoch 27 - iter 7/13 - loss 0.20191529 - samples/sec: 59.48 - lr: 0.000008
2021-07-18 23:25:04,415 epoch 27 - iter 8/13 - loss 0.20524614 - samples/sec: 61.94 - lr: 0.000008
2021-07-18 23:25:04,951 epoch 27 - iter 9/13 - loss 0.20238516 - samples/sec: 59.71 - lr: 0.000008
2021-07-18 23:25:05,478 epoch 27 - iter 10/13 - loss 0.18722822 - samples/sec: 60.78 - lr: 0.000008
2021-07-18 23:25:06,015 epoch 27 - iter 11/13 - loss 0.18286059 - samples/sec: 59.73 - lr: 0.000008
2021-07-18 23:25:06,558 epoch 27 - iter 12/13 - loss 0.18172180 - samples/sec: 58.92 - lr: 0.000008
2021-07-18 23:25:06,712 epoch 27 - iter 13/13 - loss 0.17081355 - samples/sec: 208.28 - lr: 0.000008
2021-07-18 23:25:06,713 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:06,713 EPOCH 27 done: loss 0.1708 - lr 0.0000075
2021-07-18 23:25:07,374 DEV : loss 0.2753055989742279 - score 0.9182
2021-07-18 23:25:07,383 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:25:11,405 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:11,940 epoch 28 - iter 1/13 - loss 0.29150867 - samples/sec: 59.91 - lr: 0.000008
2021-07-18 23:25:12,467 epoch 28 - iter 2/13 - loss 0.21430260 - samples/sec: 60.85 - lr: 0.000008
2021-07-18 23:25:13,006 epoch 28 - iter 3/13 - loss 0.18638977 - samples/sec: 59.33 - lr: 0.000008
2021-07-18 23:25:13,547 epoch 28 - iter 4/13 - loss 0.17549241 - samples/sec: 59.29 - lr: 0.000008
2021-07-18 23:25:14,079 epoch 28 - iter 5/13 - loss 0.19145465 - samples/sec: 60.18 - lr: 0.000008
2021-07-18 23:25:14,610 epoch 28 - iter 6/13 - loss 0.19034720 - samples/sec: 60.34 - lr: 0.000008
2021-07-18 23:25:15,119 epoch 28 - iter 7/13 - loss 0.17153693 - samples/sec: 62.92 - lr: 0.000008
2021-07-18 23:25:15,655 epoch 28 - iter 8/13 - loss 0.18856690 - samples/sec: 59.68 - lr: 0.000008
2021-07-18 23:25:16,179 epoch 28 - iter 9/13 - loss 0.17526256 - samples/sec: 61.15 - lr: 0.000008
2021-07-18 23:25:16,707 epoch 28 - iter 10/13 - loss 0.17683174 - samples/sec: 60.64 - lr: 0.000008
2021-07-18 23:25:17,227 epoch 28 - iter 11/13 - loss 0.18487938 - samples/sec: 61.66 - lr: 0.000008
2021-07-18 23:25:17,764 epoch 28 - iter 12/13 - loss 0.17830914 - samples/sec: 59.58 - lr: 0.000008
2021-07-18 23:25:17,927 epoch 28 - iter 13/13 - loss 0.18615704 - samples/sec: 197.56 - lr: 0.000008
2021-07-18 23:25:17,927 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:17,927 EPOCH 28 done: loss 0.1862 - lr 0.0000075
2021-07-18 23:25:18,595 DEV : loss 0.27555906772613525 - score 0.9182
2021-07-18 23:25:18,605 BAD EPOCHS (no improvement): 1
2021-07-18 23:25:18,605 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:19,131 epoch 29 - iter 1/13 - loss 0.10800290 - samples/sec: 60.89 - lr: 0.000008
2021-07-18 23:25:19,661 epoch 29 - iter 2/13 - loss 0.07906082 - samples/sec: 60.42 - lr: 0.000008
2021-07-18 23:25:20,187 epoch 29 - iter 3/13 - loss 0.18120579 - samples/sec: 60.85 - lr: 0.000008
2021-07-18 23:25:20,735 epoch 29 - iter 4/13 - loss 0.15432027 - samples/sec: 58.46 - lr: 0.000008
2021-07-18 23:25:21,262 epoch 29 - iter 5/13 - loss 0.14856341 - samples/sec: 60.84 - lr: 0.000008
2021-07-18 23:25:21,795 epoch 29 - iter 6/13 - loss 0.13390865 - samples/sec: 60.02 - lr: 0.000008
2021-07-18 23:25:22,327 epoch 29 - iter 7/13 - loss 0.13419269 - samples/sec: 60.20 - lr: 0.000008
2021-07-18 23:25:22,842 epoch 29 - iter 8/13 - loss 0.13908285 - samples/sec: 62.19 - lr: 0.000008
2021-07-18 23:25:23,367 epoch 29 - iter 9/13 - loss 0.14077471 - samples/sec: 60.99 - lr: 0.000008
2021-07-18 23:25:23,894 epoch 29 - iter 10/13 - loss 0.13427051 - samples/sec: 60.77 - lr: 0.000008
2021-07-18 23:25:24,434 epoch 29 - iter 11/13 - loss 0.13846901 - samples/sec: 59.40 - lr: 0.000008
2021-07-18 23:25:24,966 epoch 29 - iter 12/13 - loss 0.14783922 - samples/sec: 60.17 - lr: 0.000008
2021-07-18 23:25:25,121 epoch 29 - iter 13/13 - loss 0.14123143 - samples/sec: 207.37 - lr: 0.000008
2021-07-18 23:25:25,121 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:25,121 EPOCH 29 done: loss 0.1412 - lr 0.0000075
2021-07-18 23:25:25,782 DEV : loss 0.2817571461200714 - score 0.9182
2021-07-18 23:25:25,791 BAD EPOCHS (no improvement): 2
2021-07-18 23:25:25,791 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:26,403 epoch 30 - iter 1/13 - loss 0.08217478 - samples/sec: 52.32 - lr: 0.000008
2021-07-18 23:25:26,909 epoch 30 - iter 2/13 - loss 0.13587527 - samples/sec: 63.32 - lr: 0.000008
2021-07-18 23:25:27,432 epoch 30 - iter 3/13 - loss 0.14191654 - samples/sec: 61.30 - lr: 0.000008
2021-07-18 23:25:27,970 epoch 30 - iter 4/13 - loss 0.15887680 - samples/sec: 59.50 - lr: 0.000008
2021-07-18 23:25:28,498 epoch 30 - iter 5/13 - loss 0.15378745 - samples/sec: 60.62 - lr: 0.000008
2021-07-18 23:25:29,038 epoch 30 - iter 6/13 - loss 0.16713395 - samples/sec: 59.37 - lr: 0.000008
2021-07-18 23:25:29,558 epoch 30 - iter 7/13 - loss 0.17648145 - samples/sec: 61.54 - lr: 0.000008
2021-07-18 23:25:30,095 epoch 30 - iter 8/13 - loss 0.16305768 - samples/sec: 59.68 - lr: 0.000008
2021-07-18 23:25:30,623 epoch 30 - iter 9/13 - loss 0.16857674 - samples/sec: 60.63 - lr: 0.000008
2021-07-18 23:25:31,157 epoch 30 - iter 10/13 - loss 0.16517234 - samples/sec: 60.03 - lr: 0.000008
2021-07-18 23:25:31,698 epoch 30 - iter 11/13 - loss 0.15693309 - samples/sec: 59.13 - lr: 0.000008
2021-07-18 23:25:32,222 epoch 30 - iter 12/13 - loss 0.15604718 - samples/sec: 61.14 - lr: 0.000008
2021-07-18 23:25:32,376 epoch 30 - iter 13/13 - loss 0.17924010 - samples/sec: 208.21 - lr: 0.000008
2021-07-18 23:25:32,377 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:32,377 EPOCH 30 done: loss 0.1792 - lr 0.0000075
2021-07-18 23:25:33,037 DEV : loss 0.28042399883270264 - score 0.9182
2021-07-18 23:25:33,047 BAD EPOCHS (no improvement): 3
2021-07-18 23:25:33,047 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:33,556 epoch 31 - iter 1/13 - loss 0.06511253 - samples/sec: 62.93 - lr: 0.000008
2021-07-18 23:25:34,092 epoch 31 - iter 2/13 - loss 0.15768501 - samples/sec: 59.68 - lr: 0.000008
2021-07-18 23:25:34,634 epoch 31 - iter 3/13 - loss 0.14418314 - samples/sec: 59.12 - lr: 0.000008
2021-07-18 23:25:35,166 epoch 31 - iter 4/13 - loss 0.12396024 - samples/sec: 60.22 - lr: 0.000008
2021-07-18 23:25:35,692 epoch 31 - iter 5/13 - loss 0.13129133 - samples/sec: 60.88 - lr: 0.000008
2021-07-18 23:25:36,217 epoch 31 - iter 6/13 - loss 0.14038224 - samples/sec: 60.94 - lr: 0.000008
2021-07-18 23:25:36,739 epoch 31 - iter 7/13 - loss 0.13941087 - samples/sec: 61.40 - lr: 0.000008
2021-07-18 23:25:37,259 epoch 31 - iter 8/13 - loss 0.15314363 - samples/sec: 61.57 - lr: 0.000008
2021-07-18 23:25:37,796 epoch 31 - iter 9/13 - loss 0.15298106 - samples/sec: 59.66 - lr: 0.000008
2021-07-18 23:25:38,337 epoch 31 - iter 10/13 - loss 0.14523524 - samples/sec: 59.25 - lr: 0.000008
2021-07-18 23:25:38,862 epoch 31 - iter 11/13 - loss 0.15637516 - samples/sec: 60.91 - lr: 0.000008
2021-07-18 23:25:39,393 epoch 31 - iter 12/13 - loss 0.15683545 - samples/sec: 60.32 - lr: 0.000008
2021-07-18 23:25:39,548 epoch 31 - iter 13/13 - loss 0.16048911 - samples/sec: 207.94 - lr: 0.000008
2021-07-18 23:25:39,548 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:39,548 EPOCH 31 done: loss 0.1605 - lr 0.0000075
2021-07-18 23:25:40,210 DEV : loss 0.27725455164909363 - score 0.9182
Epoch    31: reducing learning rate of group 0 to 3.7500e-06.
2021-07-18 23:25:40,219 BAD EPOCHS (no improvement): 4
2021-07-18 23:25:40,219 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:40,747 epoch 32 - iter 1/13 - loss 0.19571024 - samples/sec: 60.72 - lr: 0.000004
2021-07-18 23:25:41,285 epoch 32 - iter 2/13 - loss 0.16738716 - samples/sec: 59.53 - lr: 0.000004
2021-07-18 23:25:41,816 epoch 32 - iter 3/13 - loss 0.14799613 - samples/sec: 60.30 - lr: 0.000004
2021-07-18 23:25:42,347 epoch 32 - iter 4/13 - loss 0.14229621 - samples/sec: 60.29 - lr: 0.000004
2021-07-18 23:25:42,866 epoch 32 - iter 5/13 - loss 0.12413608 - samples/sec: 61.73 - lr: 0.000004
2021-07-18 23:25:43,386 epoch 32 - iter 6/13 - loss 0.13418052 - samples/sec: 61.58 - lr: 0.000004
2021-07-18 23:25:43,906 epoch 32 - iter 7/13 - loss 0.14475706 - samples/sec: 61.64 - lr: 0.000004
2021-07-18 23:25:44,438 epoch 32 - iter 8/13 - loss 0.14441277 - samples/sec: 60.18 - lr: 0.000004
2021-07-18 23:25:44,962 epoch 32 - iter 9/13 - loss 0.13988289 - samples/sec: 61.10 - lr: 0.000004
2021-07-18 23:25:45,502 epoch 32 - iter 10/13 - loss 0.15536734 - samples/sec: 59.35 - lr: 0.000004
2021-07-18 23:25:46,036 epoch 32 - iter 11/13 - loss 0.15394075 - samples/sec: 59.95 - lr: 0.000004
2021-07-18 23:25:46,576 epoch 32 - iter 12/13 - loss 0.14812989 - samples/sec: 59.33 - lr: 0.000004
2021-07-18 23:25:46,731 epoch 32 - iter 13/13 - loss 0.14159090 - samples/sec: 206.92 - lr: 0.000004
2021-07-18 23:25:46,731 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:46,731 EPOCH 32 done: loss 0.1416 - lr 0.0000038
2021-07-18 23:25:47,395 DEV : loss 0.27743449807167053 - score 0.9182
2021-07-18 23:25:47,405 BAD EPOCHS (no improvement): 1
2021-07-18 23:25:47,405 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:47,934 epoch 33 - iter 1/13 - loss 0.09414196 - samples/sec: 60.54 - lr: 0.000004
2021-07-18 23:25:48,460 epoch 33 - iter 2/13 - loss 0.11606568 - samples/sec: 60.86 - lr: 0.000004
2021-07-18 23:25:48,992 epoch 33 - iter 3/13 - loss 0.10667066 - samples/sec: 60.25 - lr: 0.000004
2021-07-18 23:25:49,528 epoch 33 - iter 4/13 - loss 0.12926814 - samples/sec: 59.69 - lr: 0.000004
2021-07-18 23:25:50,063 epoch 33 - iter 5/13 - loss 0.13740838 - samples/sec: 59.89 - lr: 0.000004
2021-07-18 23:25:50,582 epoch 33 - iter 6/13 - loss 0.14438964 - samples/sec: 61.66 - lr: 0.000004
2021-07-18 23:25:51,118 epoch 33 - iter 7/13 - loss 0.13796712 - samples/sec: 59.81 - lr: 0.000004
2021-07-18 23:25:51,648 epoch 33 - iter 8/13 - loss 0.14243605 - samples/sec: 60.37 - lr: 0.000004
2021-07-18 23:25:52,172 epoch 33 - iter 9/13 - loss 0.13345680 - samples/sec: 61.13 - lr: 0.000004
2021-07-18 23:25:52,706 epoch 33 - iter 10/13 - loss 0.13844976 - samples/sec: 60.00 - lr: 0.000004
2021-07-18 23:25:53,229 epoch 33 - iter 11/13 - loss 0.14264163 - samples/sec: 61.25 - lr: 0.000004
2021-07-18 23:25:53,746 epoch 33 - iter 12/13 - loss 0.14975094 - samples/sec: 61.98 - lr: 0.000004
2021-07-18 23:25:53,900 epoch 33 - iter 13/13 - loss 0.15633110 - samples/sec: 207.73 - lr: 0.000004
2021-07-18 23:25:53,900 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:53,900 EPOCH 33 done: loss 0.1563 - lr 0.0000038
2021-07-18 23:25:54,562 DEV : loss 0.27667415142059326 - score 0.9182
2021-07-18 23:25:54,571 BAD EPOCHS (no improvement): 2
2021-07-18 23:25:54,571 ----------------------------------------------------------------------------------------------------
2021-07-18 23:25:55,096 epoch 34 - iter 1/13 - loss 0.20484900 - samples/sec: 60.96 - lr: 0.000004
2021-07-18 23:25:55,636 epoch 34 - iter 2/13 - loss 0.13127851 - samples/sec: 59.38 - lr: 0.000004
2021-07-18 23:25:56,175 epoch 34 - iter 3/13 - loss 0.14648898 - samples/sec: 59.41 - lr: 0.000004
2021-07-18 23:25:56,692 epoch 34 - iter 4/13 - loss 0.16148344 - samples/sec: 61.96 - lr: 0.000004
2021-07-18 23:25:57,195 epoch 34 - iter 5/13 - loss 0.14294682 - samples/sec: 63.60 - lr: 0.000004
2021-07-18 23:25:57,726 epoch 34 - iter 6/13 - loss 0.12863651 - samples/sec: 60.31 - lr: 0.000004
2021-07-18 23:25:58,259 epoch 34 - iter 7/13 - loss 0.13487205 - samples/sec: 60.16 - lr: 0.000004
2021-07-18 23:25:58,781 epoch 34 - iter 8/13 - loss 0.13251688 - samples/sec: 61.28 - lr: 0.000004
2021-07-18 23:25:59,314 epoch 34 - iter 9/13 - loss 0.13161282 - samples/sec: 60.12 - lr: 0.000004
2021-07-18 23:25:59,851 epoch 34 - iter 10/13 - loss 0.13237218 - samples/sec: 59.68 - lr: 0.000004
2021-07-18 23:26:00,379 epoch 34 - iter 11/13 - loss 0.13145100 - samples/sec: 60.64 - lr: 0.000004
2021-07-18 23:26:00,923 epoch 34 - iter 12/13 - loss 0.14710939 - samples/sec: 58.88 - lr: 0.000004
2021-07-18 23:26:01,072 epoch 34 - iter 13/13 - loss 0.14244162 - samples/sec: 215.08 - lr: 0.000004
2021-07-18 23:26:01,072 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:01,073 EPOCH 34 done: loss 0.1424 - lr 0.0000038
2021-07-18 23:26:01,736 DEV : loss 0.2764865756034851 - score 0.9114
2021-07-18 23:26:01,745 BAD EPOCHS (no improvement): 3
2021-07-18 23:26:01,746 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:02,273 epoch 35 - iter 1/13 - loss 0.10762787 - samples/sec: 60.68 - lr: 0.000004
2021-07-18 23:26:02,798 epoch 35 - iter 2/13 - loss 0.09087235 - samples/sec: 61.00 - lr: 0.000004
2021-07-18 23:26:03,319 epoch 35 - iter 3/13 - loss 0.10955962 - samples/sec: 61.55 - lr: 0.000004
2021-07-18 23:26:03,855 epoch 35 - iter 4/13 - loss 0.10192668 - samples/sec: 59.71 - lr: 0.000004
2021-07-18 23:26:04,382 epoch 35 - iter 5/13 - loss 0.12213526 - samples/sec: 60.74 - lr: 0.000004
2021-07-18 23:26:04,907 epoch 35 - iter 6/13 - loss 0.12391114 - samples/sec: 61.03 - lr: 0.000004
2021-07-18 23:26:05,438 epoch 35 - iter 7/13 - loss 0.12033265 - samples/sec: 60.35 - lr: 0.000004
2021-07-18 23:26:05,972 epoch 35 - iter 8/13 - loss 0.12361464 - samples/sec: 59.98 - lr: 0.000004
2021-07-18 23:26:06,504 epoch 35 - iter 9/13 - loss 0.12465948 - samples/sec: 60.20 - lr: 0.000004
2021-07-18 23:26:07,027 epoch 35 - iter 10/13 - loss 0.11848366 - samples/sec: 61.21 - lr: 0.000004
2021-07-18 23:26:07,564 epoch 35 - iter 11/13 - loss 0.11788994 - samples/sec: 59.73 - lr: 0.000004
2021-07-18 23:26:08,103 epoch 35 - iter 12/13 - loss 0.13508898 - samples/sec: 59.36 - lr: 0.000004
2021-07-18 23:26:08,258 epoch 35 - iter 13/13 - loss 0.13446862 - samples/sec: 206.63 - lr: 0.000004
2021-07-18 23:26:08,259 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:08,259 EPOCH 35 done: loss 0.1345 - lr 0.0000038
2021-07-18 23:26:09,009 DEV : loss 0.2773456573486328 - score 0.9182
Epoch    35: reducing learning rate of group 0 to 1.8750e-06.
2021-07-18 23:26:09,019 BAD EPOCHS (no improvement): 4
2021-07-18 23:26:09,019 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:09,019 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:09,019 learning rate too small - quitting training!
2021-07-18 23:26:09,019 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:09,798 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:09,799 Testing using best model ...
2021-07-18 23:26:09,799 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/spa.rst.sctb/best-model.pt
2021-07-18 23:26:12,514 0.9157	0.9744	0.9441
2021-07-18 23:26:12,514 
Results:
- F1-score (micro) 0.9441
- F1-score (macro) 0.9441

By class:
SENT       tp: 76 - fp: 7 - fn: 2 - precision: 0.9157 - recall: 0.9744 - f1-score: 0.9441
2021-07-18 23:26:12,515 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.rstdt/
2021-07-18 23:26:12,522 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.rstdt
2021-07-18 23:26:12,525 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.rstdt/sent_train.txt
2021-07-18 23:26:12,525 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.rstdt/sent_dev.txt
2021-07-18 23:26:12,525 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.rstdt/sent_test.txt
Corpus: 6016 train + 840 dev + 2083 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-18 23:26:18,524 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:18,525 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-18 23:26:18,525 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:18,526 Corpus: "Corpus: 6016 train + 840 dev + 2083 test sentences"
2021-07-18 23:26:18,526 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:18,526 Parameters:
2021-07-18 23:26:18,526  - learning_rate: "3e-05"
2021-07-18 23:26:18,526  - mini_batch_size: "32"
2021-07-18 23:26:18,526  - patience: "3"
2021-07-18 23:26:18,526  - anneal_factor: "0.5"
2021-07-18 23:26:18,526  - max_epochs: "40"
2021-07-18 23:26:18,526  - shuffle: "True"
2021-07-18 23:26:18,526  - train_with_dev: "False"
2021-07-18 23:26:18,526  - batch_growth_annealing: "False"
2021-07-18 23:26:18,526 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:18,526 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.rstdt"
2021-07-18 23:26:18,526 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:18,526 Device: cuda:0
2021-07-18 23:26:18,526 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:18,526 Embeddings storage mode: cpu
2021-07-18 23:26:18,529 ----------------------------------------------------------------------------------------------------
2021-07-18 23:26:37,022 epoch 1 - iter 18/188 - loss 8.84631941 - samples/sec: 31.15 - lr: 0.000030
2021-07-18 23:26:55,487 epoch 1 - iter 36/188 - loss 6.12929395 - samples/sec: 31.20 - lr: 0.000030
2021-07-18 23:27:13,897 epoch 1 - iter 54/188 - loss 4.97017660 - samples/sec: 31.29 - lr: 0.000030
2021-07-18 23:27:32,358 epoch 1 - iter 72/188 - loss 4.22305969 - samples/sec: 31.20 - lr: 0.000030
2021-07-18 23:27:50,823 epoch 1 - iter 90/188 - loss 3.69124710 - samples/sec: 31.20 - lr: 0.000030
2021-07-18 23:28:09,226 epoch 1 - iter 108/188 - loss 3.29698306 - samples/sec: 31.30 - lr: 0.000030
2021-07-18 23:28:27,631 epoch 1 - iter 126/188 - loss 2.97732674 - samples/sec: 31.30 - lr: 0.000030
2021-07-18 23:28:46,028 epoch 1 - iter 144/188 - loss 2.72666819 - samples/sec: 31.31 - lr: 0.000030
2021-07-18 23:29:04,399 epoch 1 - iter 162/188 - loss 2.52253066 - samples/sec: 31.36 - lr: 0.000030
2021-07-18 23:29:22,756 epoch 1 - iter 180/188 - loss 2.35084143 - samples/sec: 31.38 - lr: 0.000030
2021-07-18 23:29:30,952 ----------------------------------------------------------------------------------------------------
2021-07-18 23:29:30,952 EPOCH 1 done: loss 2.2845 - lr 0.0000300
2021-07-18 23:29:46,597 DEV : loss 0.5964000821113586 - score 0.8811
2021-07-18 23:29:46,658 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:29:47,414 ----------------------------------------------------------------------------------------------------
2021-07-18 23:29:56,830 epoch 2 - iter 18/188 - loss 0.73951476 - samples/sec: 61.18 - lr: 0.000030
2021-07-18 23:30:06,337 epoch 2 - iter 36/188 - loss 0.73738435 - samples/sec: 60.60 - lr: 0.000030
2021-07-18 23:30:15,915 epoch 2 - iter 54/188 - loss 0.71420884 - samples/sec: 60.14 - lr: 0.000030
2021-07-18 23:30:25,395 epoch 2 - iter 72/188 - loss 0.70049486 - samples/sec: 60.76 - lr: 0.000030
2021-07-18 23:30:34,890 epoch 2 - iter 90/188 - loss 0.68255098 - samples/sec: 60.67 - lr: 0.000030
2021-07-18 23:30:44,406 epoch 2 - iter 108/188 - loss 0.65996891 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 23:30:53,940 epoch 2 - iter 126/188 - loss 0.63700828 - samples/sec: 60.43 - lr: 0.000030
2021-07-18 23:31:03,493 epoch 2 - iter 144/188 - loss 0.62309723 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 23:31:13,046 epoch 2 - iter 162/188 - loss 0.61274270 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 23:31:22,498 epoch 2 - iter 180/188 - loss 0.59501014 - samples/sec: 60.95 - lr: 0.000030
2021-07-18 23:31:26,744 ----------------------------------------------------------------------------------------------------
2021-07-18 23:31:26,744 EPOCH 2 done: loss 0.5880 - lr 0.0000300
2021-07-18 23:31:31,360 DEV : loss 0.35456031560897827 - score 0.9239
2021-07-18 23:31:31,422 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:31:35,279 ----------------------------------------------------------------------------------------------------
2021-07-18 23:31:44,801 epoch 3 - iter 18/188 - loss 0.48410539 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 23:31:54,340 epoch 3 - iter 36/188 - loss 0.43227496 - samples/sec: 60.39 - lr: 0.000030
2021-07-18 23:32:03,858 epoch 3 - iter 54/188 - loss 0.44184990 - samples/sec: 60.52 - lr: 0.000030
2021-07-18 23:32:13,386 epoch 3 - iter 72/188 - loss 0.43300102 - samples/sec: 60.46 - lr: 0.000030
2021-07-18 23:32:22,890 epoch 3 - iter 90/188 - loss 0.41929898 - samples/sec: 60.61 - lr: 0.000030
2021-07-18 23:32:32,403 epoch 3 - iter 108/188 - loss 0.41273188 - samples/sec: 60.56 - lr: 0.000030
2021-07-18 23:32:41,888 epoch 3 - iter 126/188 - loss 0.40856082 - samples/sec: 60.74 - lr: 0.000030
2021-07-18 23:32:51,390 epoch 3 - iter 144/188 - loss 0.40699692 - samples/sec: 60.63 - lr: 0.000030
2021-07-18 23:33:00,887 epoch 3 - iter 162/188 - loss 0.40204736 - samples/sec: 60.66 - lr: 0.000030
2021-07-18 23:33:10,388 epoch 3 - iter 180/188 - loss 0.39800482 - samples/sec: 60.63 - lr: 0.000030
2021-07-18 23:33:14,624 ----------------------------------------------------------------------------------------------------
2021-07-18 23:33:14,624 EPOCH 3 done: loss 0.3965 - lr 0.0000300
2021-07-18 23:33:19,202 DEV : loss 0.2806777358055115 - score 0.9343
2021-07-18 23:33:19,265 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:33:23,127 ----------------------------------------------------------------------------------------------------
2021-07-18 23:33:32,647 epoch 4 - iter 18/188 - loss 0.25752687 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 23:33:42,883 epoch 4 - iter 36/188 - loss 0.30289738 - samples/sec: 56.28 - lr: 0.000030
2021-07-18 23:33:52,406 epoch 4 - iter 54/188 - loss 0.31920575 - samples/sec: 60.50 - lr: 0.000030
2021-07-18 23:34:01,959 epoch 4 - iter 72/188 - loss 0.31801374 - samples/sec: 60.30 - lr: 0.000030
2021-07-18 23:34:11,434 epoch 4 - iter 90/188 - loss 0.32476604 - samples/sec: 60.80 - lr: 0.000030
2021-07-18 23:34:20,928 epoch 4 - iter 108/188 - loss 0.31767113 - samples/sec: 60.68 - lr: 0.000030
2021-07-18 23:34:30,452 epoch 4 - iter 126/188 - loss 0.32526154 - samples/sec: 60.49 - lr: 0.000030
2021-07-18 23:34:39,960 epoch 4 - iter 144/188 - loss 0.32368914 - samples/sec: 60.59 - lr: 0.000030
2021-07-18 23:34:49,467 epoch 4 - iter 162/188 - loss 0.32431718 - samples/sec: 60.60 - lr: 0.000030
2021-07-18 23:34:59,018 epoch 4 - iter 180/188 - loss 0.32360911 - samples/sec: 60.31 - lr: 0.000030
2021-07-18 23:35:03,222 ----------------------------------------------------------------------------------------------------
2021-07-18 23:35:03,223 EPOCH 4 done: loss 0.3258 - lr 0.0000300
2021-07-18 23:35:07,806 DEV : loss 0.24526993930339813 - score 0.9506
2021-07-18 23:35:07,868 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:35:11,474 ----------------------------------------------------------------------------------------------------
2021-07-18 23:35:21,030 epoch 5 - iter 18/188 - loss 0.26923124 - samples/sec: 60.28 - lr: 0.000030
2021-07-18 23:35:30,551 epoch 5 - iter 36/188 - loss 0.31722687 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 23:35:39,984 epoch 5 - iter 54/188 - loss 0.31003002 - samples/sec: 61.06 - lr: 0.000030
2021-07-18 23:35:49,550 epoch 5 - iter 72/188 - loss 0.31026972 - samples/sec: 60.23 - lr: 0.000030
2021-07-18 23:35:59,066 epoch 5 - iter 90/188 - loss 0.30038514 - samples/sec: 60.53 - lr: 0.000030
2021-07-18 23:36:08,551 epoch 5 - iter 108/188 - loss 0.29753203 - samples/sec: 60.73 - lr: 0.000030
2021-07-18 23:36:18,032 epoch 5 - iter 126/188 - loss 0.29055323 - samples/sec: 60.76 - lr: 0.000030
2021-07-18 23:36:27,487 epoch 5 - iter 144/188 - loss 0.28902095 - samples/sec: 60.93 - lr: 0.000030
2021-07-18 23:36:37,007 epoch 5 - iter 162/188 - loss 0.28268100 - samples/sec: 60.51 - lr: 0.000030
2021-07-18 23:36:46,571 epoch 5 - iter 180/188 - loss 0.28725653 - samples/sec: 60.23 - lr: 0.000030
2021-07-18 23:36:50,782 ----------------------------------------------------------------------------------------------------
2021-07-18 23:36:50,782 EPOCH 5 done: loss 0.2884 - lr 0.0000300
2021-07-18 23:36:55,359 DEV : loss 0.22142399847507477 - score 0.9583
2021-07-18 23:36:55,420 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:36:58,931 ----------------------------------------------------------------------------------------------------
2021-07-18 23:37:08,523 epoch 6 - iter 18/188 - loss 0.28677228 - samples/sec: 60.06 - lr: 0.000030
2021-07-18 23:37:18,038 epoch 6 - iter 36/188 - loss 0.26894042 - samples/sec: 60.54 - lr: 0.000030
2021-07-18 23:37:27,478 epoch 6 - iter 54/188 - loss 0.27045941 - samples/sec: 61.03 - lr: 0.000030
2021-07-18 23:37:36,927 epoch 6 - iter 72/188 - loss 0.26991624 - samples/sec: 60.96 - lr: 0.000030
2021-07-18 23:37:46,503 epoch 6 - iter 90/188 - loss 0.27105176 - samples/sec: 60.16 - lr: 0.000030
2021-07-18 23:37:55,992 epoch 6 - iter 108/188 - loss 0.27279240 - samples/sec: 60.71 - lr: 0.000030
2021-07-18 23:38:05,496 epoch 6 - iter 126/188 - loss 0.26825245 - samples/sec: 60.61 - lr: 0.000030
2021-07-18 23:38:15,035 epoch 6 - iter 144/188 - loss 0.26718357 - samples/sec: 60.40 - lr: 0.000030
2021-07-18 23:38:24,538 epoch 6 - iter 162/188 - loss 0.26579887 - samples/sec: 60.62 - lr: 0.000030
2021-07-18 23:38:34,041 epoch 6 - iter 180/188 - loss 0.26273481 - samples/sec: 60.62 - lr: 0.000030
2021-07-18 23:38:38,249 ----------------------------------------------------------------------------------------------------
2021-07-18 23:38:38,250 EPOCH 6 done: loss 0.2617 - lr 0.0000300
2021-07-18 23:38:42,824 DEV : loss 0.20826710760593414 - score 0.9572
2021-07-18 23:38:42,886 BAD EPOCHS (no improvement): 1
2021-07-18 23:38:42,887 ----------------------------------------------------------------------------------------------------
2021-07-18 23:38:52,315 epoch 7 - iter 18/188 - loss 0.26438310 - samples/sec: 61.10 - lr: 0.000030
2021-07-18 23:39:01,832 epoch 7 - iter 36/188 - loss 0.26732751 - samples/sec: 60.53 - lr: 0.000030
2021-07-18 23:39:11,324 epoch 7 - iter 54/188 - loss 0.23366924 - samples/sec: 60.69 - lr: 0.000030
2021-07-18 23:39:20,800 epoch 7 - iter 72/188 - loss 0.24017478 - samples/sec: 60.79 - lr: 0.000030
2021-07-18 23:39:30,311 epoch 7 - iter 90/188 - loss 0.23463722 - samples/sec: 60.57 - lr: 0.000030
2021-07-18 23:39:39,883 epoch 7 - iter 108/188 - loss 0.23729961 - samples/sec: 60.18 - lr: 0.000030
2021-07-18 23:39:49,365 epoch 7 - iter 126/188 - loss 0.23068349 - samples/sec: 60.76 - lr: 0.000030
2021-07-18 23:39:58,902 epoch 7 - iter 144/188 - loss 0.22877728 - samples/sec: 60.40 - lr: 0.000030
2021-07-18 23:40:08,388 epoch 7 - iter 162/188 - loss 0.23028226 - samples/sec: 60.73 - lr: 0.000030
2021-07-18 23:40:17,903 epoch 7 - iter 180/188 - loss 0.23103908 - samples/sec: 60.55 - lr: 0.000030
2021-07-18 23:40:22,109 ----------------------------------------------------------------------------------------------------
2021-07-18 23:40:22,109 EPOCH 7 done: loss 0.2292 - lr 0.0000300
2021-07-18 23:40:26,696 DEV : loss 0.20753604173660278 - score 0.9578
2021-07-18 23:40:26,758 BAD EPOCHS (no improvement): 2
2021-07-18 23:40:26,758 ----------------------------------------------------------------------------------------------------
2021-07-18 23:40:36,963 epoch 8 - iter 18/188 - loss 0.22007470 - samples/sec: 56.46 - lr: 0.000030
2021-07-18 23:40:46,458 epoch 8 - iter 36/188 - loss 0.20103147 - samples/sec: 60.67 - lr: 0.000030
2021-07-18 23:40:55,936 epoch 8 - iter 54/188 - loss 0.19519902 - samples/sec: 60.78 - lr: 0.000030
2021-07-18 23:41:05,442 epoch 8 - iter 72/188 - loss 0.20382548 - samples/sec: 60.60 - lr: 0.000030
2021-07-18 23:41:14,970 epoch 8 - iter 90/188 - loss 0.20851738 - samples/sec: 60.46 - lr: 0.000030
2021-07-18 23:41:24,528 epoch 8 - iter 108/188 - loss 0.21021772 - samples/sec: 60.27 - lr: 0.000030
2021-07-18 23:41:34,075 epoch 8 - iter 126/188 - loss 0.21825803 - samples/sec: 60.34 - lr: 0.000030
2021-07-18 23:41:43,532 epoch 8 - iter 144/188 - loss 0.21951489 - samples/sec: 60.92 - lr: 0.000030
2021-07-18 23:41:53,063 epoch 8 - iter 162/188 - loss 0.22580420 - samples/sec: 60.44 - lr: 0.000030
2021-07-18 23:42:02,590 epoch 8 - iter 180/188 - loss 0.22533893 - samples/sec: 60.47 - lr: 0.000030
2021-07-18 23:42:06,824 ----------------------------------------------------------------------------------------------------
2021-07-18 23:42:06,824 EPOCH 8 done: loss 0.2236 - lr 0.0000300
2021-07-18 23:42:11,406 DEV : loss 0.19540630280971527 - score 0.9573
2021-07-18 23:42:11,469 BAD EPOCHS (no improvement): 3
2021-07-18 23:42:11,470 ----------------------------------------------------------------------------------------------------
2021-07-18 23:42:21,022 epoch 9 - iter 18/188 - loss 0.26441905 - samples/sec: 60.31 - lr: 0.000030
2021-07-18 23:42:30,488 epoch 9 - iter 36/188 - loss 0.22620825 - samples/sec: 60.86 - lr: 0.000030
2021-07-18 23:42:39,991 epoch 9 - iter 54/188 - loss 0.23675771 - samples/sec: 60.62 - lr: 0.000030
2021-07-18 23:42:49,568 epoch 9 - iter 72/188 - loss 0.22804260 - samples/sec: 60.15 - lr: 0.000030
2021-07-18 23:42:59,108 epoch 9 - iter 90/188 - loss 0.21709200 - samples/sec: 60.39 - lr: 0.000030
2021-07-18 23:43:08,634 epoch 9 - iter 108/188 - loss 0.21228953 - samples/sec: 60.47 - lr: 0.000030
2021-07-18 23:43:18,185 epoch 9 - iter 126/188 - loss 0.20999521 - samples/sec: 60.32 - lr: 0.000030
2021-07-18 23:43:27,692 epoch 9 - iter 144/188 - loss 0.21329376 - samples/sec: 60.59 - lr: 0.000030
2021-07-18 23:43:37,155 epoch 9 - iter 162/188 - loss 0.21364826 - samples/sec: 60.88 - lr: 0.000030
2021-07-18 23:43:46,679 epoch 9 - iter 180/188 - loss 0.21462105 - samples/sec: 60.49 - lr: 0.000030
2021-07-18 23:43:50,910 ----------------------------------------------------------------------------------------------------
2021-07-18 23:43:50,911 EPOCH 9 done: loss 0.2126 - lr 0.0000300
2021-07-18 23:43:55,489 DEV : loss 0.20279332995414734 - score 0.9578
Epoch     9: reducing learning rate of group 0 to 1.5000e-05.
2021-07-18 23:43:55,551 BAD EPOCHS (no improvement): 4
2021-07-18 23:43:55,552 ----------------------------------------------------------------------------------------------------
2021-07-18 23:44:05,080 epoch 10 - iter 18/188 - loss 0.18077282 - samples/sec: 60.46 - lr: 0.000015
2021-07-18 23:44:14,574 epoch 10 - iter 36/188 - loss 0.18310148 - samples/sec: 60.68 - lr: 0.000015
2021-07-18 23:44:24,068 epoch 10 - iter 54/188 - loss 0.18497570 - samples/sec: 60.68 - lr: 0.000015
2021-07-18 23:44:33,663 epoch 10 - iter 72/188 - loss 0.19209122 - samples/sec: 60.04 - lr: 0.000015
2021-07-18 23:44:43,219 epoch 10 - iter 90/188 - loss 0.18839273 - samples/sec: 60.29 - lr: 0.000015
2021-07-18 23:44:52,747 epoch 10 - iter 108/188 - loss 0.19082251 - samples/sec: 60.46 - lr: 0.000015
2021-07-18 23:45:02,299 epoch 10 - iter 126/188 - loss 0.18907128 - samples/sec: 60.31 - lr: 0.000015
2021-07-18 23:45:11,772 epoch 10 - iter 144/188 - loss 0.19187901 - samples/sec: 60.82 - lr: 0.000015
2021-07-18 23:45:21,322 epoch 10 - iter 162/188 - loss 0.18849743 - samples/sec: 60.32 - lr: 0.000015
2021-07-18 23:45:30,775 epoch 10 - iter 180/188 - loss 0.18874017 - samples/sec: 60.94 - lr: 0.000015
2021-07-18 23:45:34,966 ----------------------------------------------------------------------------------------------------
2021-07-18 23:45:34,966 EPOCH 10 done: loss 0.1867 - lr 0.0000150
2021-07-18 23:45:39,563 DEV : loss 0.18344229459762573 - score 0.9577
2021-07-18 23:45:39,626 BAD EPOCHS (no improvement): 1
2021-07-18 23:45:39,626 ----------------------------------------------------------------------------------------------------
2021-07-18 23:45:49,128 epoch 11 - iter 18/188 - loss 0.18127165 - samples/sec: 60.63 - lr: 0.000015
2021-07-18 23:45:58,689 epoch 11 - iter 36/188 - loss 0.16618918 - samples/sec: 60.25 - lr: 0.000015
2021-07-18 23:46:08,227 epoch 11 - iter 54/188 - loss 0.16631729 - samples/sec: 60.40 - lr: 0.000015
2021-07-18 23:46:17,715 epoch 11 - iter 72/188 - loss 0.16379992 - samples/sec: 60.72 - lr: 0.000015
2021-07-18 23:46:27,212 epoch 11 - iter 90/188 - loss 0.16612723 - samples/sec: 60.66 - lr: 0.000015
2021-07-18 23:46:36,714 epoch 11 - iter 108/188 - loss 0.16506405 - samples/sec: 60.62 - lr: 0.000015
2021-07-18 23:46:46,239 epoch 11 - iter 126/188 - loss 0.16848693 - samples/sec: 60.48 - lr: 0.000015
2021-07-18 23:46:55,672 epoch 11 - iter 144/188 - loss 0.17107318 - samples/sec: 61.07 - lr: 0.000015
2021-07-18 23:47:05,215 epoch 11 - iter 162/188 - loss 0.17326209 - samples/sec: 60.37 - lr: 0.000015
2021-07-18 23:47:14,698 epoch 11 - iter 180/188 - loss 0.18061462 - samples/sec: 60.75 - lr: 0.000015
2021-07-18 23:47:18,930 ----------------------------------------------------------------------------------------------------
2021-07-18 23:47:18,931 EPOCH 11 done: loss 0.1832 - lr 0.0000150
2021-07-18 23:47:24,200 DEV : loss 0.1816488355398178 - score 0.9607
2021-07-18 23:47:24,262 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:47:28,154 ----------------------------------------------------------------------------------------------------
2021-07-18 23:47:37,675 epoch 12 - iter 18/188 - loss 0.19016443 - samples/sec: 60.51 - lr: 0.000015
2021-07-18 23:47:47,244 epoch 12 - iter 36/188 - loss 0.17035395 - samples/sec: 60.20 - lr: 0.000015
2021-07-18 23:47:56,735 epoch 12 - iter 54/188 - loss 0.17257426 - samples/sec: 60.70 - lr: 0.000015
2021-07-18 23:48:06,268 epoch 12 - iter 72/188 - loss 0.17903289 - samples/sec: 60.43 - lr: 0.000015
2021-07-18 23:48:15,834 epoch 12 - iter 90/188 - loss 0.17379776 - samples/sec: 60.22 - lr: 0.000015
2021-07-18 23:48:25,395 epoch 12 - iter 108/188 - loss 0.16859746 - samples/sec: 60.25 - lr: 0.000015
2021-07-18 23:48:34,903 epoch 12 - iter 126/188 - loss 0.17711560 - samples/sec: 60.59 - lr: 0.000015
2021-07-18 23:48:44,400 epoch 12 - iter 144/188 - loss 0.17582642 - samples/sec: 60.66 - lr: 0.000015
2021-07-18 23:48:53,938 epoch 12 - iter 162/188 - loss 0.17800702 - samples/sec: 60.40 - lr: 0.000015
2021-07-18 23:49:03,408 epoch 12 - iter 180/188 - loss 0.17498011 - samples/sec: 60.84 - lr: 0.000015
2021-07-18 23:49:07,623 ----------------------------------------------------------------------------------------------------
2021-07-18 23:49:07,624 EPOCH 12 done: loss 0.1744 - lr 0.0000150
2021-07-18 23:49:12,206 DEV : loss 0.17972332239151 - score 0.9589
2021-07-18 23:49:12,270 BAD EPOCHS (no improvement): 1
2021-07-18 23:49:12,270 ----------------------------------------------------------------------------------------------------
2021-07-18 23:49:21,769 epoch 13 - iter 18/188 - loss 0.15428629 - samples/sec: 60.65 - lr: 0.000015
2021-07-18 23:49:31,258 epoch 13 - iter 36/188 - loss 0.17504395 - samples/sec: 60.71 - lr: 0.000015
2021-07-18 23:49:40,830 epoch 13 - iter 54/188 - loss 0.17344227 - samples/sec: 60.18 - lr: 0.000015
2021-07-18 23:49:50,361 epoch 13 - iter 72/188 - loss 0.17064714 - samples/sec: 60.45 - lr: 0.000015
2021-07-18 23:49:59,871 epoch 13 - iter 90/188 - loss 0.16753862 - samples/sec: 60.58 - lr: 0.000015
2021-07-18 23:50:09,398 epoch 13 - iter 108/188 - loss 0.16908388 - samples/sec: 60.47 - lr: 0.000015
2021-07-18 23:50:18,942 epoch 13 - iter 126/188 - loss 0.17636476 - samples/sec: 60.36 - lr: 0.000015
2021-07-18 23:50:28,448 epoch 13 - iter 144/188 - loss 0.18020132 - samples/sec: 60.60 - lr: 0.000015
2021-07-18 23:50:37,942 epoch 13 - iter 162/188 - loss 0.17535995 - samples/sec: 60.68 - lr: 0.000015
2021-07-18 23:50:47,474 epoch 13 - iter 180/188 - loss 0.17225310 - samples/sec: 60.43 - lr: 0.000015
2021-07-18 23:50:51,710 ----------------------------------------------------------------------------------------------------
2021-07-18 23:50:51,710 EPOCH 13 done: loss 0.1696 - lr 0.0000150
2021-07-18 23:50:56,295 DEV : loss 0.1832939237356186 - score 0.9604
2021-07-18 23:50:56,358 BAD EPOCHS (no improvement): 2
2021-07-18 23:50:56,359 ----------------------------------------------------------------------------------------------------
2021-07-18 23:51:05,898 epoch 14 - iter 18/188 - loss 0.15349294 - samples/sec: 60.39 - lr: 0.000015
2021-07-18 23:51:15,448 epoch 14 - iter 36/188 - loss 0.18084152 - samples/sec: 60.32 - lr: 0.000015
2021-07-18 23:51:25,020 epoch 14 - iter 54/188 - loss 0.18569098 - samples/sec: 60.18 - lr: 0.000015
2021-07-18 23:51:34,495 epoch 14 - iter 72/188 - loss 0.17865489 - samples/sec: 60.80 - lr: 0.000015
2021-07-18 23:51:43,963 epoch 14 - iter 90/188 - loss 0.16974263 - samples/sec: 60.84 - lr: 0.000015
2021-07-18 23:51:53,399 epoch 14 - iter 108/188 - loss 0.16654611 - samples/sec: 61.05 - lr: 0.000015
2021-07-18 23:52:02,872 epoch 14 - iter 126/188 - loss 0.16919850 - samples/sec: 60.81 - lr: 0.000015
2021-07-18 23:52:12,358 epoch 14 - iter 144/188 - loss 0.16794164 - samples/sec: 60.73 - lr: 0.000015
2021-07-18 23:52:21,907 epoch 14 - iter 162/188 - loss 0.16969380 - samples/sec: 60.33 - lr: 0.000015
2021-07-18 23:52:31,411 epoch 14 - iter 180/188 - loss 0.16560338 - samples/sec: 60.62 - lr: 0.000015
2021-07-18 23:52:35,656 ----------------------------------------------------------------------------------------------------
2021-07-18 23:52:35,656 EPOCH 14 done: loss 0.1651 - lr 0.0000150
2021-07-18 23:52:40,232 DEV : loss 0.173225998878479 - score 0.9626
2021-07-18 23:52:40,295 BAD EPOCHS (no improvement): 0
saving best model
2021-07-18 23:52:44,263 ----------------------------------------------------------------------------------------------------
2021-07-18 23:52:53,821 epoch 15 - iter 18/188 - loss 0.15388959 - samples/sec: 60.28 - lr: 0.000015
2021-07-18 23:53:03,390 epoch 15 - iter 36/188 - loss 0.16425143 - samples/sec: 60.20 - lr: 0.000015
2021-07-18 23:53:12,937 epoch 15 - iter 54/188 - loss 0.14866232 - samples/sec: 60.34 - lr: 0.000015
2021-07-18 23:53:22,439 epoch 15 - iter 72/188 - loss 0.14798069 - samples/sec: 60.63 - lr: 0.000015
2021-07-18 23:53:31,872 epoch 15 - iter 90/188 - loss 0.15583003 - samples/sec: 61.07 - lr: 0.000015
2021-07-18 23:53:41,343 epoch 15 - iter 108/188 - loss 0.15624560 - samples/sec: 60.82 - lr: 0.000015
2021-07-18 23:53:50,763 epoch 15 - iter 126/188 - loss 0.15462237 - samples/sec: 61.16 - lr: 0.000015
2021-07-18 23:54:00,276 epoch 15 - iter 144/188 - loss 0.15993827 - samples/sec: 60.56 - lr: 0.000015
2021-07-18 23:54:09,783 epoch 15 - iter 162/188 - loss 0.15861385 - samples/sec: 60.59 - lr: 0.000015
2021-07-18 23:54:19,229 epoch 15 - iter 180/188 - loss 0.16086341 - samples/sec: 60.99 - lr: 0.000015
2021-07-18 23:54:23,409 ----------------------------------------------------------------------------------------------------
2021-07-18 23:54:23,409 EPOCH 15 done: loss 0.1608 - lr 0.0000150
2021-07-18 23:54:28,726 DEV : loss 0.1763579547405243 - score 0.9603
2021-07-18 23:54:28,790 BAD EPOCHS (no improvement): 1
2021-07-18 23:54:28,790 ----------------------------------------------------------------------------------------------------
2021-07-18 23:54:38,203 epoch 16 - iter 18/188 - loss 0.15553701 - samples/sec: 61.20 - lr: 0.000015
2021-07-18 23:54:47,663 epoch 16 - iter 36/188 - loss 0.15486795 - samples/sec: 60.90 - lr: 0.000015
2021-07-18 23:54:57,106 epoch 16 - iter 54/188 - loss 0.15500507 - samples/sec: 61.00 - lr: 0.000015
2021-07-18 23:55:06,563 epoch 16 - iter 72/188 - loss 0.15695527 - samples/sec: 60.92 - lr: 0.000015
2021-07-18 23:55:16,099 epoch 16 - iter 90/188 - loss 0.14797091 - samples/sec: 60.41 - lr: 0.000015
2021-07-18 23:55:25,574 epoch 16 - iter 108/188 - loss 0.14493321 - samples/sec: 60.80 - lr: 0.000015
2021-07-18 23:55:35,093 epoch 16 - iter 126/188 - loss 0.14947203 - samples/sec: 60.52 - lr: 0.000015
2021-07-18 23:55:44,624 epoch 16 - iter 144/188 - loss 0.14773392 - samples/sec: 60.44 - lr: 0.000015
2021-07-18 23:55:54,136 epoch 16 - iter 162/188 - loss 0.14957988 - samples/sec: 60.56 - lr: 0.000015
2021-07-18 23:56:03,666 epoch 16 - iter 180/188 - loss 0.15088410 - samples/sec: 60.44 - lr: 0.000015
2021-07-18 23:56:07,912 ----------------------------------------------------------------------------------------------------
2021-07-18 23:56:07,912 EPOCH 16 done: loss 0.1501 - lr 0.0000150
2021-07-18 23:56:12,490 DEV : loss 0.18426859378814697 - score 0.96
2021-07-18 23:56:12,553 BAD EPOCHS (no improvement): 2
2021-07-18 23:56:12,553 ----------------------------------------------------------------------------------------------------
2021-07-18 23:56:22,035 epoch 17 - iter 18/188 - loss 0.16128887 - samples/sec: 60.75 - lr: 0.000015
2021-07-18 23:56:31,600 epoch 17 - iter 36/188 - loss 0.14163580 - samples/sec: 60.23 - lr: 0.000015
2021-07-18 23:56:41,095 epoch 17 - iter 54/188 - loss 0.14386489 - samples/sec: 60.67 - lr: 0.000015
2021-07-18 23:56:50,619 epoch 17 - iter 72/188 - loss 0.15092189 - samples/sec: 60.49 - lr: 0.000015
2021-07-18 23:57:00,085 epoch 17 - iter 90/188 - loss 0.14409532 - samples/sec: 60.86 - lr: 0.000015
2021-07-18 23:57:09,638 epoch 17 - iter 108/188 - loss 0.13916581 - samples/sec: 60.30 - lr: 0.000015
2021-07-18 23:57:19,174 epoch 17 - iter 126/188 - loss 0.13913813 - samples/sec: 60.41 - lr: 0.000015
2021-07-18 23:57:28,638 epoch 17 - iter 144/188 - loss 0.14358200 - samples/sec: 60.87 - lr: 0.000015
2021-07-18 23:57:38,161 epoch 17 - iter 162/188 - loss 0.14723809 - samples/sec: 60.49 - lr: 0.000015
2021-07-18 23:57:47,688 epoch 17 - iter 180/188 - loss 0.14580779 - samples/sec: 60.47 - lr: 0.000015
2021-07-18 23:57:51,942 ----------------------------------------------------------------------------------------------------
2021-07-18 23:57:51,942 EPOCH 17 done: loss 0.1462 - lr 0.0000150
2021-07-18 23:57:56,532 DEV : loss 0.18302813172340393 - score 0.9601
2021-07-18 23:57:56,595 BAD EPOCHS (no improvement): 3
2021-07-18 23:57:56,596 ----------------------------------------------------------------------------------------------------
2021-07-18 23:58:06,146 epoch 18 - iter 18/188 - loss 0.16127640 - samples/sec: 60.32 - lr: 0.000015
2021-07-18 23:58:15,700 epoch 18 - iter 36/188 - loss 0.15244107 - samples/sec: 60.30 - lr: 0.000015
2021-07-18 23:58:25,224 epoch 18 - iter 54/188 - loss 0.14625080 - samples/sec: 60.48 - lr: 0.000015
2021-07-18 23:58:34,760 epoch 18 - iter 72/188 - loss 0.15198932 - samples/sec: 60.41 - lr: 0.000015
2021-07-18 23:58:44,240 epoch 18 - iter 90/188 - loss 0.14864992 - samples/sec: 60.76 - lr: 0.000015
2021-07-18 23:58:53,829 epoch 18 - iter 108/188 - loss 0.14378413 - samples/sec: 60.07 - lr: 0.000015
2021-07-18 23:59:03,304 epoch 18 - iter 126/188 - loss 0.14202449 - samples/sec: 60.80 - lr: 0.000015
2021-07-18 23:59:12,673 epoch 18 - iter 144/188 - loss 0.14156969 - samples/sec: 61.49 - lr: 0.000015
2021-07-18 23:59:22,075 epoch 18 - iter 162/188 - loss 0.14041978 - samples/sec: 61.27 - lr: 0.000015
2021-07-18 23:59:31,487 epoch 18 - iter 180/188 - loss 0.13950025 - samples/sec: 61.20 - lr: 0.000015
2021-07-18 23:59:35,677 ----------------------------------------------------------------------------------------------------
2021-07-18 23:59:35,677 EPOCH 18 done: loss 0.1403 - lr 0.0000150
2021-07-18 23:59:40,254 DEV : loss 0.17561380565166473 - score 0.9607
Epoch    18: reducing learning rate of group 0 to 7.5000e-06.
2021-07-18 23:59:40,316 BAD EPOCHS (no improvement): 4
2021-07-18 23:59:40,316 ----------------------------------------------------------------------------------------------------
2021-07-18 23:59:49,723 epoch 19 - iter 18/188 - loss 0.13008981 - samples/sec: 61.24 - lr: 0.000008
2021-07-18 23:59:59,148 epoch 19 - iter 36/188 - loss 0.13902386 - samples/sec: 61.12 - lr: 0.000008
2021-07-19 00:00:08,616 epoch 19 - iter 54/188 - loss 0.13020769 - samples/sec: 60.84 - lr: 0.000008
2021-07-19 00:00:18,130 epoch 19 - iter 72/188 - loss 0.12775567 - samples/sec: 60.55 - lr: 0.000008
2021-07-19 00:00:27,622 epoch 19 - iter 90/188 - loss 0.12777071 - samples/sec: 60.69 - lr: 0.000008
2021-07-19 00:00:37,152 epoch 19 - iter 108/188 - loss 0.13101442 - samples/sec: 60.45 - lr: 0.000008
2021-07-19 00:00:46,636 epoch 19 - iter 126/188 - loss 0.13509336 - samples/sec: 60.75 - lr: 0.000008
2021-07-19 00:00:56,191 epoch 19 - iter 144/188 - loss 0.13648293 - samples/sec: 60.29 - lr: 0.000008
2021-07-19 00:01:05,714 epoch 19 - iter 162/188 - loss 0.13630921 - samples/sec: 60.49 - lr: 0.000008
2021-07-19 00:01:15,191 epoch 19 - iter 180/188 - loss 0.13595674 - samples/sec: 60.79 - lr: 0.000008
2021-07-19 00:01:19,388 ----------------------------------------------------------------------------------------------------
2021-07-19 00:01:19,388 EPOCH 19 done: loss 0.1363 - lr 0.0000075
2021-07-19 00:01:24,660 DEV : loss 0.17748594284057617 - score 0.9598
2021-07-19 00:01:24,722 BAD EPOCHS (no improvement): 1
2021-07-19 00:01:24,723 ----------------------------------------------------------------------------------------------------
2021-07-19 00:01:34,195 epoch 20 - iter 18/188 - loss 0.11685242 - samples/sec: 60.82 - lr: 0.000008
2021-07-19 00:01:43,628 epoch 20 - iter 36/188 - loss 0.14337613 - samples/sec: 61.07 - lr: 0.000008
2021-07-19 00:01:53,159 epoch 20 - iter 54/188 - loss 0.14626863 - samples/sec: 60.44 - lr: 0.000008
2021-07-19 00:02:02,662 epoch 20 - iter 72/188 - loss 0.14058741 - samples/sec: 60.62 - lr: 0.000008
2021-07-19 00:02:12,183 epoch 20 - iter 90/188 - loss 0.14288136 - samples/sec: 60.51 - lr: 0.000008
2021-07-19 00:02:21,653 epoch 20 - iter 108/188 - loss 0.13870371 - samples/sec: 60.84 - lr: 0.000008
2021-07-19 00:02:31,106 epoch 20 - iter 126/188 - loss 0.13779906 - samples/sec: 60.94 - lr: 0.000008
2021-07-19 00:02:40,575 epoch 20 - iter 144/188 - loss 0.13471870 - samples/sec: 60.84 - lr: 0.000008
2021-07-19 00:02:50,095 epoch 20 - iter 162/188 - loss 0.13537572 - samples/sec: 60.51 - lr: 0.000008
2021-07-19 00:02:59,619 epoch 20 - iter 180/188 - loss 0.13404983 - samples/sec: 60.49 - lr: 0.000008
2021-07-19 00:03:03,822 ----------------------------------------------------------------------------------------------------
2021-07-19 00:03:03,823 EPOCH 20 done: loss 0.1334 - lr 0.0000075
2021-07-19 00:03:08,402 DEV : loss 0.169922336935997 - score 0.9614
2021-07-19 00:03:08,465 BAD EPOCHS (no improvement): 2
2021-07-19 00:03:08,465 ----------------------------------------------------------------------------------------------------
2021-07-19 00:03:17,978 epoch 21 - iter 18/188 - loss 0.14918288 - samples/sec: 60.56 - lr: 0.000008
2021-07-19 00:03:27,491 epoch 21 - iter 36/188 - loss 0.15068056 - samples/sec: 60.56 - lr: 0.000008
2021-07-19 00:03:36,991 epoch 21 - iter 54/188 - loss 0.14052602 - samples/sec: 60.63 - lr: 0.000008
2021-07-19 00:03:46,503 epoch 21 - iter 72/188 - loss 0.12890359 - samples/sec: 60.57 - lr: 0.000008
2021-07-19 00:03:56,003 epoch 21 - iter 90/188 - loss 0.13420213 - samples/sec: 60.64 - lr: 0.000008
2021-07-19 00:04:05,568 epoch 21 - iter 108/188 - loss 0.13480209 - samples/sec: 60.23 - lr: 0.000008
2021-07-19 00:04:15,058 epoch 21 - iter 126/188 - loss 0.13161549 - samples/sec: 60.70 - lr: 0.000008
2021-07-19 00:04:24,541 epoch 21 - iter 144/188 - loss 0.13039727 - samples/sec: 60.75 - lr: 0.000008
2021-07-19 00:04:34,046 epoch 21 - iter 162/188 - loss 0.13080513 - samples/sec: 60.61 - lr: 0.000008
2021-07-19 00:04:43,627 epoch 21 - iter 180/188 - loss 0.12824796 - samples/sec: 60.12 - lr: 0.000008
2021-07-19 00:04:47,835 ----------------------------------------------------------------------------------------------------
2021-07-19 00:04:47,836 EPOCH 21 done: loss 0.1281 - lr 0.0000075
2021-07-19 00:04:52,414 DEV : loss 0.1739456206560135 - score 0.9629
2021-07-19 00:04:52,477 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:04:56,330 ----------------------------------------------------------------------------------------------------
2021-07-19 00:05:05,847 epoch 22 - iter 18/188 - loss 0.12333801 - samples/sec: 60.54 - lr: 0.000008
2021-07-19 00:05:15,378 epoch 22 - iter 36/188 - loss 0.14430799 - samples/sec: 60.44 - lr: 0.000008
2021-07-19 00:05:24,862 epoch 22 - iter 54/188 - loss 0.14066807 - samples/sec: 60.74 - lr: 0.000008
2021-07-19 00:05:34,375 epoch 22 - iter 72/188 - loss 0.14259592 - samples/sec: 60.56 - lr: 0.000008
2021-07-19 00:05:43,881 epoch 22 - iter 90/188 - loss 0.14481059 - samples/sec: 60.60 - lr: 0.000008
2021-07-19 00:05:53,389 epoch 22 - iter 108/188 - loss 0.14411109 - samples/sec: 60.59 - lr: 0.000008
2021-07-19 00:06:02,832 epoch 22 - iter 126/188 - loss 0.14060256 - samples/sec: 61.01 - lr: 0.000008
2021-07-19 00:06:12,282 epoch 22 - iter 144/188 - loss 0.14077637 - samples/sec: 60.96 - lr: 0.000008
2021-07-19 00:06:21,680 epoch 22 - iter 162/188 - loss 0.14052929 - samples/sec: 61.30 - lr: 0.000008
2021-07-19 00:06:31,129 epoch 22 - iter 180/188 - loss 0.13684552 - samples/sec: 60.97 - lr: 0.000008
2021-07-19 00:06:35,360 ----------------------------------------------------------------------------------------------------
2021-07-19 00:06:35,360 EPOCH 22 done: loss 0.1356 - lr 0.0000075
2021-07-19 00:06:39,929 DEV : loss 0.17653828859329224 - score 0.9606
2021-07-19 00:06:39,992 BAD EPOCHS (no improvement): 1
2021-07-19 00:06:39,992 ----------------------------------------------------------------------------------------------------
2021-07-19 00:06:49,407 epoch 23 - iter 18/188 - loss 0.10656876 - samples/sec: 61.19 - lr: 0.000008
2021-07-19 00:06:58,872 epoch 23 - iter 36/188 - loss 0.10059551 - samples/sec: 60.86 - lr: 0.000008
2021-07-19 00:07:08,345 epoch 23 - iter 54/188 - loss 0.10966014 - samples/sec: 60.81 - lr: 0.000008
2021-07-19 00:07:17,793 epoch 23 - iter 72/188 - loss 0.11035366 - samples/sec: 60.98 - lr: 0.000008
2021-07-19 00:07:27,250 epoch 23 - iter 90/188 - loss 0.11592430 - samples/sec: 60.91 - lr: 0.000008
2021-07-19 00:07:36,713 epoch 23 - iter 108/188 - loss 0.11749633 - samples/sec: 60.88 - lr: 0.000008
2021-07-19 00:07:46,124 epoch 23 - iter 126/188 - loss 0.11728776 - samples/sec: 61.22 - lr: 0.000008
2021-07-19 00:07:55,560 epoch 23 - iter 144/188 - loss 0.12039728 - samples/sec: 61.05 - lr: 0.000008
2021-07-19 00:08:05,054 epoch 23 - iter 162/188 - loss 0.12075887 - samples/sec: 60.68 - lr: 0.000008
2021-07-19 00:08:14,512 epoch 23 - iter 180/188 - loss 0.12148108 - samples/sec: 60.90 - lr: 0.000008
2021-07-19 00:08:18,722 ----------------------------------------------------------------------------------------------------
2021-07-19 00:08:18,722 EPOCH 23 done: loss 0.1212 - lr 0.0000075
2021-07-19 00:08:23,984 DEV : loss 0.17183125019073486 - score 0.964
2021-07-19 00:08:24,048 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:08:28,115 ----------------------------------------------------------------------------------------------------
2021-07-19 00:08:37,602 epoch 24 - iter 18/188 - loss 0.10830119 - samples/sec: 60.72 - lr: 0.000008
2021-07-19 00:08:47,088 epoch 24 - iter 36/188 - loss 0.12723639 - samples/sec: 60.73 - lr: 0.000008
2021-07-19 00:08:56,564 epoch 24 - iter 54/188 - loss 0.12109734 - samples/sec: 60.79 - lr: 0.000008
2021-07-19 00:09:06,064 epoch 24 - iter 72/188 - loss 0.12316183 - samples/sec: 60.64 - lr: 0.000008
2021-07-19 00:09:15,532 epoch 24 - iter 90/188 - loss 0.12164825 - samples/sec: 60.84 - lr: 0.000008
2021-07-19 00:09:24,983 epoch 24 - iter 108/188 - loss 0.11986277 - samples/sec: 60.95 - lr: 0.000008
2021-07-19 00:09:34,418 epoch 24 - iter 126/188 - loss 0.11359994 - samples/sec: 61.06 - lr: 0.000008
2021-07-19 00:09:43,863 epoch 24 - iter 144/188 - loss 0.11628187 - samples/sec: 60.99 - lr: 0.000008
2021-07-19 00:09:53,258 epoch 24 - iter 162/188 - loss 0.11479217 - samples/sec: 61.32 - lr: 0.000008
2021-07-19 00:10:02,689 epoch 24 - iter 180/188 - loss 0.11753825 - samples/sec: 61.09 - lr: 0.000008
2021-07-19 00:10:06,908 ----------------------------------------------------------------------------------------------------
2021-07-19 00:10:06,908 EPOCH 24 done: loss 0.1181 - lr 0.0000075
2021-07-19 00:10:11,478 DEV : loss 0.1736142784357071 - score 0.9619
2021-07-19 00:10:11,540 BAD EPOCHS (no improvement): 1
2021-07-19 00:10:11,541 ----------------------------------------------------------------------------------------------------
2021-07-19 00:10:21,078 epoch 25 - iter 18/188 - loss 0.14148140 - samples/sec: 60.40 - lr: 0.000008
2021-07-19 00:10:30,610 epoch 25 - iter 36/188 - loss 0.13832942 - samples/sec: 60.43 - lr: 0.000008
2021-07-19 00:10:40,146 epoch 25 - iter 54/188 - loss 0.12840418 - samples/sec: 60.41 - lr: 0.000008
2021-07-19 00:10:49,616 epoch 25 - iter 72/188 - loss 0.12792560 - samples/sec: 60.84 - lr: 0.000008
2021-07-19 00:10:59,123 epoch 25 - iter 90/188 - loss 0.12273411 - samples/sec: 60.59 - lr: 0.000008
2021-07-19 00:11:08,660 epoch 25 - iter 108/188 - loss 0.12768696 - samples/sec: 60.40 - lr: 0.000008
2021-07-19 00:11:18,149 epoch 25 - iter 126/188 - loss 0.12294520 - samples/sec: 60.71 - lr: 0.000008
2021-07-19 00:11:27,664 epoch 25 - iter 144/188 - loss 0.12261828 - samples/sec: 60.55 - lr: 0.000008
2021-07-19 00:11:37,202 epoch 25 - iter 162/188 - loss 0.11840947 - samples/sec: 60.40 - lr: 0.000008
2021-07-19 00:11:46,732 epoch 25 - iter 180/188 - loss 0.11746720 - samples/sec: 60.45 - lr: 0.000008
2021-07-19 00:11:50,947 ----------------------------------------------------------------------------------------------------
2021-07-19 00:11:50,947 EPOCH 25 done: loss 0.1185 - lr 0.0000075
2021-07-19 00:11:55,518 DEV : loss 0.17417877912521362 - score 0.9613
2021-07-19 00:11:55,581 BAD EPOCHS (no improvement): 2
2021-07-19 00:11:55,581 ----------------------------------------------------------------------------------------------------
2021-07-19 00:12:05,048 epoch 26 - iter 18/188 - loss 0.08209203 - samples/sec: 60.85 - lr: 0.000008
2021-07-19 00:12:14,539 epoch 26 - iter 36/188 - loss 0.08881895 - samples/sec: 60.69 - lr: 0.000008
2021-07-19 00:12:24,052 epoch 26 - iter 54/188 - loss 0.09256521 - samples/sec: 60.56 - lr: 0.000008
2021-07-19 00:12:33,578 epoch 26 - iter 72/188 - loss 0.09624082 - samples/sec: 60.47 - lr: 0.000008
2021-07-19 00:12:43,104 epoch 26 - iter 90/188 - loss 0.10738759 - samples/sec: 60.48 - lr: 0.000008
2021-07-19 00:12:52,628 epoch 26 - iter 108/188 - loss 0.10933429 - samples/sec: 60.48 - lr: 0.000008
2021-07-19 00:13:02,150 epoch 26 - iter 126/188 - loss 0.11097604 - samples/sec: 60.50 - lr: 0.000008
2021-07-19 00:13:11,679 epoch 26 - iter 144/188 - loss 0.11554371 - samples/sec: 60.46 - lr: 0.000008
2021-07-19 00:13:21,195 epoch 26 - iter 162/188 - loss 0.11794847 - samples/sec: 60.54 - lr: 0.000008
2021-07-19 00:13:30,745 epoch 26 - iter 180/188 - loss 0.11602260 - samples/sec: 60.32 - lr: 0.000008
2021-07-19 00:13:34,988 ----------------------------------------------------------------------------------------------------
2021-07-19 00:13:34,988 EPOCH 26 done: loss 0.1153 - lr 0.0000075
2021-07-19 00:13:39,559 DEV : loss 0.16931158304214478 - score 0.9612
2021-07-19 00:13:39,622 BAD EPOCHS (no improvement): 3
2021-07-19 00:13:39,622 ----------------------------------------------------------------------------------------------------
2021-07-19 00:13:49,138 epoch 27 - iter 18/188 - loss 0.11206285 - samples/sec: 60.54 - lr: 0.000008
2021-07-19 00:13:59,323 epoch 27 - iter 36/188 - loss 0.11977856 - samples/sec: 56.56 - lr: 0.000008
2021-07-19 00:14:08,811 epoch 27 - iter 54/188 - loss 0.11157117 - samples/sec: 60.72 - lr: 0.000008
2021-07-19 00:14:18,339 epoch 27 - iter 72/188 - loss 0.11074480 - samples/sec: 60.46 - lr: 0.000008
2021-07-19 00:14:27,854 epoch 27 - iter 90/188 - loss 0.10569831 - samples/sec: 60.54 - lr: 0.000008
2021-07-19 00:14:37,358 epoch 27 - iter 108/188 - loss 0.10554018 - samples/sec: 60.61 - lr: 0.000008
2021-07-19 00:14:46,830 epoch 27 - iter 126/188 - loss 0.10641315 - samples/sec: 60.82 - lr: 0.000008
2021-07-19 00:14:56,364 epoch 27 - iter 144/188 - loss 0.10627827 - samples/sec: 60.42 - lr: 0.000008
2021-07-19 00:15:05,898 epoch 27 - iter 162/188 - loss 0.10712966 - samples/sec: 60.42 - lr: 0.000008
2021-07-19 00:15:15,430 epoch 27 - iter 180/188 - loss 0.10881401 - samples/sec: 60.44 - lr: 0.000008
2021-07-19 00:15:19,672 ----------------------------------------------------------------------------------------------------
2021-07-19 00:15:19,672 EPOCH 27 done: loss 0.1073 - lr 0.0000075
2021-07-19 00:15:24,252 DEV : loss 0.16847144067287445 - score 0.963
Epoch    27: reducing learning rate of group 0 to 3.7500e-06.
2021-07-19 00:15:24,315 BAD EPOCHS (no improvement): 4
2021-07-19 00:15:24,315 ----------------------------------------------------------------------------------------------------
2021-07-19 00:15:33,842 epoch 28 - iter 18/188 - loss 0.15717951 - samples/sec: 60.47 - lr: 0.000004
2021-07-19 00:15:43,388 epoch 28 - iter 36/188 - loss 0.13935083 - samples/sec: 60.35 - lr: 0.000004
2021-07-19 00:15:52,890 epoch 28 - iter 54/188 - loss 0.12416005 - samples/sec: 60.62 - lr: 0.000004
2021-07-19 00:16:02,422 epoch 28 - iter 72/188 - loss 0.12526520 - samples/sec: 60.44 - lr: 0.000004
2021-07-19 00:16:11,946 epoch 28 - iter 90/188 - loss 0.12143208 - samples/sec: 60.49 - lr: 0.000004
2021-07-19 00:16:21,382 epoch 28 - iter 108/188 - loss 0.11747136 - samples/sec: 61.05 - lr: 0.000004
2021-07-19 00:16:30,910 epoch 28 - iter 126/188 - loss 0.11517536 - samples/sec: 60.46 - lr: 0.000004
2021-07-19 00:16:40,338 epoch 28 - iter 144/188 - loss 0.11714385 - samples/sec: 61.11 - lr: 0.000004
2021-07-19 00:16:49,797 epoch 28 - iter 162/188 - loss 0.11495150 - samples/sec: 60.90 - lr: 0.000004
2021-07-19 00:16:59,232 epoch 28 - iter 180/188 - loss 0.11085581 - samples/sec: 61.06 - lr: 0.000004
2021-07-19 00:17:03,443 ----------------------------------------------------------------------------------------------------
2021-07-19 00:17:03,444 EPOCH 28 done: loss 0.1099 - lr 0.0000038
2021-07-19 00:17:08,014 DEV : loss 0.167146697640419 - score 0.9633
2021-07-19 00:17:08,077 BAD EPOCHS (no improvement): 1
2021-07-19 00:17:08,077 ----------------------------------------------------------------------------------------------------
2021-07-19 00:17:17,571 epoch 29 - iter 18/188 - loss 0.09398561 - samples/sec: 60.68 - lr: 0.000004
2021-07-19 00:17:27,004 epoch 29 - iter 36/188 - loss 0.10325864 - samples/sec: 61.07 - lr: 0.000004
2021-07-19 00:17:36,574 epoch 29 - iter 54/188 - loss 0.10658536 - samples/sec: 60.20 - lr: 0.000004
2021-07-19 00:17:46,095 epoch 29 - iter 72/188 - loss 0.10838185 - samples/sec: 60.51 - lr: 0.000004
2021-07-19 00:17:55,555 epoch 29 - iter 90/188 - loss 0.10141055 - samples/sec: 60.89 - lr: 0.000004
2021-07-19 00:18:05,095 epoch 29 - iter 108/188 - loss 0.10373515 - samples/sec: 60.39 - lr: 0.000004
2021-07-19 00:18:14,679 epoch 29 - iter 126/188 - loss 0.10463265 - samples/sec: 60.11 - lr: 0.000004
2021-07-19 00:18:24,158 epoch 29 - iter 144/188 - loss 0.10619305 - samples/sec: 60.77 - lr: 0.000004
2021-07-19 00:18:33,695 epoch 29 - iter 162/188 - loss 0.10740388 - samples/sec: 60.40 - lr: 0.000004
2021-07-19 00:18:43,235 epoch 29 - iter 180/188 - loss 0.10781460 - samples/sec: 60.38 - lr: 0.000004
2021-07-19 00:18:47,508 ----------------------------------------------------------------------------------------------------
2021-07-19 00:18:47,508 EPOCH 29 done: loss 0.1088 - lr 0.0000038
2021-07-19 00:18:52,078 DEV : loss 0.17090082168579102 - score 0.9641
2021-07-19 00:18:52,141 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:18:56,043 ----------------------------------------------------------------------------------------------------
2021-07-19 00:19:05,568 epoch 30 - iter 18/188 - loss 0.09970109 - samples/sec: 60.49 - lr: 0.000004
2021-07-19 00:19:15,115 epoch 30 - iter 36/188 - loss 0.10975709 - samples/sec: 60.34 - lr: 0.000004
2021-07-19 00:19:24,703 epoch 30 - iter 54/188 - loss 0.11077326 - samples/sec: 60.08 - lr: 0.000004
2021-07-19 00:19:34,216 epoch 30 - iter 72/188 - loss 0.11083237 - samples/sec: 60.56 - lr: 0.000004
2021-07-19 00:19:43,722 epoch 30 - iter 90/188 - loss 0.12002840 - samples/sec: 60.60 - lr: 0.000004
2021-07-19 00:19:53,218 epoch 30 - iter 108/188 - loss 0.11974110 - samples/sec: 60.67 - lr: 0.000004
2021-07-19 00:20:02,783 epoch 30 - iter 126/188 - loss 0.11849521 - samples/sec: 60.23 - lr: 0.000004
2021-07-19 00:20:12,278 epoch 30 - iter 144/188 - loss 0.11400251 - samples/sec: 60.67 - lr: 0.000004
2021-07-19 00:20:21,774 epoch 30 - iter 162/188 - loss 0.11135326 - samples/sec: 60.67 - lr: 0.000004
2021-07-19 00:20:31,286 epoch 30 - iter 180/188 - loss 0.11009750 - samples/sec: 60.57 - lr: 0.000004
2021-07-19 00:20:35,547 ----------------------------------------------------------------------------------------------------
2021-07-19 00:20:35,547 EPOCH 30 done: loss 0.1085 - lr 0.0000038
2021-07-19 00:20:40,119 DEV : loss 0.16713391244411469 - score 0.9647
2021-07-19 00:20:40,182 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:20:43,699 ----------------------------------------------------------------------------------------------------
2021-07-19 00:20:53,928 epoch 31 - iter 18/188 - loss 0.10842914 - samples/sec: 56.32 - lr: 0.000004
2021-07-19 00:21:03,445 epoch 31 - iter 36/188 - loss 0.10554981 - samples/sec: 60.53 - lr: 0.000004
2021-07-19 00:21:12,952 epoch 31 - iter 54/188 - loss 0.10850818 - samples/sec: 60.59 - lr: 0.000004
2021-07-19 00:21:22,476 epoch 31 - iter 72/188 - loss 0.12007649 - samples/sec: 60.49 - lr: 0.000004
2021-07-19 00:21:32,002 epoch 31 - iter 90/188 - loss 0.11206407 - samples/sec: 60.47 - lr: 0.000004
2021-07-19 00:21:41,568 epoch 31 - iter 108/188 - loss 0.11600144 - samples/sec: 60.22 - lr: 0.000004
2021-07-19 00:21:51,106 epoch 31 - iter 126/188 - loss 0.11981649 - samples/sec: 60.40 - lr: 0.000004
2021-07-19 00:22:00,644 epoch 31 - iter 144/188 - loss 0.12020962 - samples/sec: 60.40 - lr: 0.000004
2021-07-19 00:22:10,163 epoch 31 - iter 162/188 - loss 0.12010735 - samples/sec: 60.52 - lr: 0.000004
2021-07-19 00:22:19,616 epoch 31 - iter 180/188 - loss 0.11901957 - samples/sec: 60.94 - lr: 0.000004
2021-07-19 00:22:23,860 ----------------------------------------------------------------------------------------------------
2021-07-19 00:22:23,860 EPOCH 31 done: loss 0.1203 - lr 0.0000038
2021-07-19 00:22:28,435 DEV : loss 0.16783581674098969 - score 0.9626
2021-07-19 00:22:28,497 BAD EPOCHS (no improvement): 1
2021-07-19 00:22:28,497 ----------------------------------------------------------------------------------------------------
2021-07-19 00:22:38,008 epoch 32 - iter 18/188 - loss 0.14474563 - samples/sec: 60.57 - lr: 0.000004
2021-07-19 00:22:47,539 epoch 32 - iter 36/188 - loss 0.12704898 - samples/sec: 60.44 - lr: 0.000004
2021-07-19 00:22:57,030 epoch 32 - iter 54/188 - loss 0.11525085 - samples/sec: 60.70 - lr: 0.000004
2021-07-19 00:23:06,611 epoch 32 - iter 72/188 - loss 0.11282742 - samples/sec: 60.12 - lr: 0.000004
2021-07-19 00:23:16,122 epoch 32 - iter 90/188 - loss 0.10902238 - samples/sec: 60.57 - lr: 0.000004
2021-07-19 00:23:25,660 epoch 32 - iter 108/188 - loss 0.10861408 - samples/sec: 60.40 - lr: 0.000004
2021-07-19 00:23:35,226 epoch 32 - iter 126/188 - loss 0.10773747 - samples/sec: 60.22 - lr: 0.000004
2021-07-19 00:23:44,752 epoch 32 - iter 144/188 - loss 0.10913537 - samples/sec: 60.48 - lr: 0.000004
2021-07-19 00:23:54,254 epoch 32 - iter 162/188 - loss 0.10544809 - samples/sec: 60.63 - lr: 0.000004
2021-07-19 00:24:03,744 epoch 32 - iter 180/188 - loss 0.10523504 - samples/sec: 60.70 - lr: 0.000004
2021-07-19 00:24:07,952 ----------------------------------------------------------------------------------------------------
2021-07-19 00:24:07,953 EPOCH 32 done: loss 0.1058 - lr 0.0000038
2021-07-19 00:24:12,521 DEV : loss 0.16788409650325775 - score 0.967
2021-07-19 00:24:12,584 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:24:16,384 ----------------------------------------------------------------------------------------------------
2021-07-19 00:24:25,889 epoch 33 - iter 18/188 - loss 0.12374308 - samples/sec: 60.61 - lr: 0.000004
2021-07-19 00:24:35,359 epoch 33 - iter 36/188 - loss 0.11738478 - samples/sec: 60.83 - lr: 0.000004
2021-07-19 00:24:44,911 epoch 33 - iter 54/188 - loss 0.11251254 - samples/sec: 60.31 - lr: 0.000004
2021-07-19 00:24:54,499 epoch 33 - iter 72/188 - loss 0.10705306 - samples/sec: 60.08 - lr: 0.000004
2021-07-19 00:25:04,022 epoch 33 - iter 90/188 - loss 0.10200311 - samples/sec: 60.49 - lr: 0.000004
2021-07-19 00:25:13,564 epoch 33 - iter 108/188 - loss 0.09783481 - samples/sec: 60.37 - lr: 0.000004
2021-07-19 00:25:23,074 epoch 33 - iter 126/188 - loss 0.09693248 - samples/sec: 60.58 - lr: 0.000004
2021-07-19 00:25:32,547 epoch 33 - iter 144/188 - loss 0.09760910 - samples/sec: 60.82 - lr: 0.000004
2021-07-19 00:25:42,092 epoch 33 - iter 162/188 - loss 0.09669961 - samples/sec: 60.35 - lr: 0.000004
2021-07-19 00:25:51,618 epoch 33 - iter 180/188 - loss 0.10179918 - samples/sec: 60.48 - lr: 0.000004
2021-07-19 00:25:55,872 ----------------------------------------------------------------------------------------------------
2021-07-19 00:25:55,872 EPOCH 33 done: loss 0.1008 - lr 0.0000038
2021-07-19 00:26:00,451 DEV : loss 0.17215266823768616 - score 0.9606
2021-07-19 00:26:00,514 BAD EPOCHS (no improvement): 1
2021-07-19 00:26:00,514 ----------------------------------------------------------------------------------------------------
2021-07-19 00:26:10,054 epoch 34 - iter 18/188 - loss 0.11435998 - samples/sec: 60.38 - lr: 0.000004
2021-07-19 00:26:19,562 epoch 34 - iter 36/188 - loss 0.09877546 - samples/sec: 60.59 - lr: 0.000004
2021-07-19 00:26:28,995 epoch 34 - iter 54/188 - loss 0.10162947 - samples/sec: 61.07 - lr: 0.000004
2021-07-19 00:26:38,492 epoch 34 - iter 72/188 - loss 0.10921405 - samples/sec: 60.66 - lr: 0.000004
2021-07-19 00:26:48,020 epoch 34 - iter 90/188 - loss 0.10184740 - samples/sec: 60.46 - lr: 0.000004
2021-07-19 00:26:57,531 epoch 34 - iter 108/188 - loss 0.10327457 - samples/sec: 60.57 - lr: 0.000004
2021-07-19 00:27:07,007 epoch 34 - iter 126/188 - loss 0.10477895 - samples/sec: 60.79 - lr: 0.000004
2021-07-19 00:27:16,462 epoch 34 - iter 144/188 - loss 0.10393114 - samples/sec: 60.93 - lr: 0.000004
2021-07-19 00:27:25,983 epoch 34 - iter 162/188 - loss 0.10512043 - samples/sec: 60.50 - lr: 0.000004
2021-07-19 00:27:35,416 epoch 34 - iter 180/188 - loss 0.10364758 - samples/sec: 61.07 - lr: 0.000004
2021-07-19 00:27:39,644 ----------------------------------------------------------------------------------------------------
2021-07-19 00:27:39,644 EPOCH 34 done: loss 0.1062 - lr 0.0000038
2021-07-19 00:27:44,939 DEV : loss 0.17385223507881165 - score 0.9613
2021-07-19 00:27:45,002 BAD EPOCHS (no improvement): 2
2021-07-19 00:27:45,002 ----------------------------------------------------------------------------------------------------
2021-07-19 00:27:54,499 epoch 35 - iter 18/188 - loss 0.09730379 - samples/sec: 60.66 - lr: 0.000004
2021-07-19 00:28:03,980 epoch 35 - iter 36/188 - loss 0.10642982 - samples/sec: 60.76 - lr: 0.000004
2021-07-19 00:28:13,448 epoch 35 - iter 54/188 - loss 0.11201796 - samples/sec: 60.84 - lr: 0.000004
2021-07-19 00:28:22,942 epoch 35 - iter 72/188 - loss 0.10891436 - samples/sec: 60.68 - lr: 0.000004
2021-07-19 00:28:32,407 epoch 35 - iter 90/188 - loss 0.10814597 - samples/sec: 60.86 - lr: 0.000004
2021-07-19 00:28:41,881 epoch 35 - iter 108/188 - loss 0.10369433 - samples/sec: 60.81 - lr: 0.000004
2021-07-19 00:28:51,427 epoch 35 - iter 126/188 - loss 0.10142628 - samples/sec: 60.35 - lr: 0.000004
2021-07-19 00:29:00,927 epoch 35 - iter 144/188 - loss 0.10217009 - samples/sec: 60.64 - lr: 0.000004
2021-07-19 00:29:10,363 epoch 35 - iter 162/188 - loss 0.10071661 - samples/sec: 61.05 - lr: 0.000004
2021-07-19 00:29:19,872 epoch 35 - iter 180/188 - loss 0.10161651 - samples/sec: 60.58 - lr: 0.000004
2021-07-19 00:29:24,067 ----------------------------------------------------------------------------------------------------
2021-07-19 00:29:24,067 EPOCH 35 done: loss 0.1021 - lr 0.0000038
2021-07-19 00:29:28,640 DEV : loss 0.16610275208950043 - score 0.9618
2021-07-19 00:29:28,703 BAD EPOCHS (no improvement): 3
2021-07-19 00:29:28,703 ----------------------------------------------------------------------------------------------------
2021-07-19 00:29:38,157 epoch 36 - iter 18/188 - loss 0.09757977 - samples/sec: 60.93 - lr: 0.000004
2021-07-19 00:29:47,626 epoch 36 - iter 36/188 - loss 0.10119217 - samples/sec: 60.84 - lr: 0.000004
2021-07-19 00:29:57,123 epoch 36 - iter 54/188 - loss 0.10654745 - samples/sec: 60.66 - lr: 0.000004
2021-07-19 00:30:06,588 epoch 36 - iter 72/188 - loss 0.10690123 - samples/sec: 60.87 - lr: 0.000004
2021-07-19 00:30:16,055 epoch 36 - iter 90/188 - loss 0.10978111 - samples/sec: 60.85 - lr: 0.000004
2021-07-19 00:30:25,535 epoch 36 - iter 108/188 - loss 0.10853261 - samples/sec: 60.77 - lr: 0.000004
2021-07-19 00:30:35,006 epoch 36 - iter 126/188 - loss 0.10863114 - samples/sec: 60.82 - lr: 0.000004
2021-07-19 00:30:44,439 epoch 36 - iter 144/188 - loss 0.10701986 - samples/sec: 61.07 - lr: 0.000004
2021-07-19 00:30:53,951 epoch 36 - iter 162/188 - loss 0.10469029 - samples/sec: 60.57 - lr: 0.000004
2021-07-19 00:31:03,458 epoch 36 - iter 180/188 - loss 0.10332910 - samples/sec: 60.59 - lr: 0.000004
2021-07-19 00:31:07,636 ----------------------------------------------------------------------------------------------------
2021-07-19 00:31:07,636 EPOCH 36 done: loss 0.1024 - lr 0.0000038
2021-07-19 00:31:12,212 DEV : loss 0.16366617381572723 - score 0.9625
Epoch    36: reducing learning rate of group 0 to 1.8750e-06.
2021-07-19 00:31:12,275 BAD EPOCHS (no improvement): 4
2021-07-19 00:31:12,275 ----------------------------------------------------------------------------------------------------
2021-07-19 00:31:12,275 ----------------------------------------------------------------------------------------------------
2021-07-19 00:31:12,275 learning rate too small - quitting training!
2021-07-19 00:31:12,275 ----------------------------------------------------------------------------------------------------
2021-07-19 00:31:13,022 ----------------------------------------------------------------------------------------------------
2021-07-19 00:31:13,022 Testing using best model ...
2021-07-19 00:31:13,022 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/eng.rst.rstdt/best-model.pt
2021-07-19 00:31:48,515 0.9582	0.9756	0.9668
2021-07-19 00:31:48,515 
Results:
- F1-score (micro) 0.9668
- F1-score (macro) 0.9668

By class:
SENT       tp: 1718 - fp: 75 - fn: 43 - precision: 0.9582 - recall: 0.9756 - f1-score: 0.9668
2021-07-19 00:31:48,515 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/rus.rst.rrt/
2021-07-19 00:31:48,549 Reading data from /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/rus.rst.rrt
2021-07-19 00:31:48,551 Train: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/rus.rst.rrt/sent_train.txt
2021-07-19 00:31:48,553 Dev: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/rus.rst.rrt/sent_dev.txt
2021-07-19 00:31:48,555 Test: /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/rus.rst.rrt/sent_test.txt
Corpus: 14173 train + 1956 dev + 4548 test sentences
Dictionary with 5 tags: <unk>, O, B-SENT, <START>, <STOP>
2021-07-19 00:32:00,360 ----------------------------------------------------------------------------------------------------
2021-07-19 00:32:00,361 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50021, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3122, out_features=3122, bias=True)
  (rnn): LSTM(3122, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=5, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-19 00:32:00,362 ----------------------------------------------------------------------------------------------------
2021-07-19 00:32:00,362 Corpus: "Corpus: 14173 train + 1956 dev + 4548 test sentences"
2021-07-19 00:32:00,362 ----------------------------------------------------------------------------------------------------
2021-07-19 00:32:00,362 Parameters:
2021-07-19 00:32:00,362  - learning_rate: "3e-05"
2021-07-19 00:32:00,362  - mini_batch_size: "32"
2021-07-19 00:32:00,362  - patience: "3"
2021-07-19 00:32:00,362  - anneal_factor: "0.5"
2021-07-19 00:32:00,362  - max_epochs: "40"
2021-07-19 00:32:00,362  - shuffle: "True"
2021-07-19 00:32:00,362  - train_with_dev: "False"
2021-07-19 00:32:00,362  - batch_growth_annealing: "False"
2021-07-19 00:32:00,362 ----------------------------------------------------------------------------------------------------
2021-07-19 00:32:00,362 Model training base path: "/disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/rus.rst.rrt"
2021-07-19 00:32:00,362 ----------------------------------------------------------------------------------------------------
2021-07-19 00:32:00,362 Device: cuda:0
2021-07-19 00:32:00,362 ----------------------------------------------------------------------------------------------------
2021-07-19 00:32:00,362 Embeddings storage mode: cpu
2021-07-19 00:32:00,365 ----------------------------------------------------------------------------------------------------
2021-07-19 00:32:49,437 epoch 1 - iter 44/443 - loss 6.90466306 - samples/sec: 28.69 - lr: 0.000030
2021-07-19 00:33:37,588 epoch 1 - iter 88/443 - loss 3.95775778 - samples/sec: 29.24 - lr: 0.000030
2021-07-19 00:34:25,438 epoch 1 - iter 132/443 - loss 2.90183481 - samples/sec: 29.43 - lr: 0.000030
2021-07-19 00:35:13,060 epoch 1 - iter 176/443 - loss 2.33535413 - samples/sec: 29.57 - lr: 0.000030
2021-07-19 00:36:00,563 epoch 1 - iter 220/443 - loss 1.99091781 - samples/sec: 29.64 - lr: 0.000030
2021-07-19 00:36:47,952 epoch 1 - iter 264/443 - loss 1.75476925 - samples/sec: 29.71 - lr: 0.000030
2021-07-19 00:37:35,248 epoch 1 - iter 308/443 - loss 1.57540720 - samples/sec: 29.77 - lr: 0.000030
2021-07-19 00:38:23,456 epoch 1 - iter 352/443 - loss 1.43708652 - samples/sec: 29.21 - lr: 0.000030
2021-07-19 00:39:10,536 epoch 1 - iter 396/443 - loss 1.32106646 - samples/sec: 29.91 - lr: 0.000030
2021-07-19 00:39:57,723 epoch 1 - iter 440/443 - loss 1.23142831 - samples/sec: 29.84 - lr: 0.000030
2021-07-19 00:40:00,848 ----------------------------------------------------------------------------------------------------
2021-07-19 00:40:00,848 EPOCH 1 done: loss 1.2262 - lr 0.0000300
2021-07-19 00:40:37,791 DEV : loss 0.32971978187561035 - score 0.9423
2021-07-19 00:40:37,934 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:40:38,824 ----------------------------------------------------------------------------------------------------
2021-07-19 00:41:02,758 epoch 2 - iter 44/443 - loss 0.37976241 - samples/sec: 58.83 - lr: 0.000030
2021-07-19 00:41:26,695 epoch 2 - iter 88/443 - loss 0.36655218 - samples/sec: 58.83 - lr: 0.000030
2021-07-19 00:41:50,603 epoch 2 - iter 132/443 - loss 0.36519001 - samples/sec: 58.90 - lr: 0.000030
2021-07-19 00:42:14,468 epoch 2 - iter 176/443 - loss 0.35867329 - samples/sec: 59.00 - lr: 0.000030
2021-07-19 00:42:38,370 epoch 2 - iter 220/443 - loss 0.35163332 - samples/sec: 58.91 - lr: 0.000030
2021-07-19 00:43:02,267 epoch 2 - iter 264/443 - loss 0.34846544 - samples/sec: 58.93 - lr: 0.000030
2021-07-19 00:43:26,007 epoch 2 - iter 308/443 - loss 0.34971719 - samples/sec: 59.31 - lr: 0.000030
2021-07-19 00:43:49,778 epoch 2 - iter 352/443 - loss 0.34790433 - samples/sec: 59.24 - lr: 0.000030
2021-07-19 00:44:13,622 epoch 2 - iter 396/443 - loss 0.33929214 - samples/sec: 59.06 - lr: 0.000030
2021-07-19 00:44:37,448 epoch 2 - iter 440/443 - loss 0.33942765 - samples/sec: 59.10 - lr: 0.000030
2021-07-19 00:44:39,027 ----------------------------------------------------------------------------------------------------
2021-07-19 00:44:39,028 EPOCH 2 done: loss 0.3390 - lr 0.0000300
2021-07-19 00:44:50,106 DEV : loss 0.27741363644599915 - score 0.9571
2021-07-19 00:44:50,249 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:44:54,661 ----------------------------------------------------------------------------------------------------
2021-07-19 00:45:18,444 epoch 3 - iter 44/443 - loss 0.28241477 - samples/sec: 59.21 - lr: 0.000030
2021-07-19 00:45:42,199 epoch 3 - iter 88/443 - loss 0.28278548 - samples/sec: 59.28 - lr: 0.000030
2021-07-19 00:46:05,957 epoch 3 - iter 132/443 - loss 0.29246884 - samples/sec: 59.27 - lr: 0.000030
2021-07-19 00:46:29,756 epoch 3 - iter 176/443 - loss 0.28120742 - samples/sec: 59.17 - lr: 0.000030
2021-07-19 00:46:53,692 epoch 3 - iter 220/443 - loss 0.27869590 - samples/sec: 58.83 - lr: 0.000030
2021-07-19 00:47:17,494 epoch 3 - iter 264/443 - loss 0.27836343 - samples/sec: 59.16 - lr: 0.000030
2021-07-19 00:47:41,454 epoch 3 - iter 308/443 - loss 0.27643477 - samples/sec: 58.77 - lr: 0.000030
2021-07-19 00:48:06,559 epoch 3 - iter 352/443 - loss 0.27353501 - samples/sec: 56.09 - lr: 0.000030
2021-07-19 00:48:30,439 epoch 3 - iter 396/443 - loss 0.27163280 - samples/sec: 58.97 - lr: 0.000030
2021-07-19 00:48:54,372 epoch 3 - iter 440/443 - loss 0.27136255 - samples/sec: 58.84 - lr: 0.000030
2021-07-19 00:48:55,963 ----------------------------------------------------------------------------------------------------
2021-07-19 00:48:55,963 EPOCH 3 done: loss 0.2709 - lr 0.0000300
2021-07-19 00:49:07,004 DEV : loss 0.25265082716941833 - score 0.9605
2021-07-19 00:49:07,150 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:49:11,612 ----------------------------------------------------------------------------------------------------
2021-07-19 00:49:35,551 epoch 4 - iter 44/443 - loss 0.27173560 - samples/sec: 58.82 - lr: 0.000030
2021-07-19 00:49:59,401 epoch 4 - iter 88/443 - loss 0.25798528 - samples/sec: 59.04 - lr: 0.000030
2021-07-19 00:50:23,424 epoch 4 - iter 132/443 - loss 0.24852006 - samples/sec: 58.62 - lr: 0.000030
2021-07-19 00:50:47,294 epoch 4 - iter 176/443 - loss 0.24956274 - samples/sec: 58.99 - lr: 0.000030
2021-07-19 00:51:11,224 epoch 4 - iter 220/443 - loss 0.25105083 - samples/sec: 58.85 - lr: 0.000030
2021-07-19 00:51:35,122 epoch 4 - iter 264/443 - loss 0.24955922 - samples/sec: 58.92 - lr: 0.000030
2021-07-19 00:51:59,072 epoch 4 - iter 308/443 - loss 0.24827026 - samples/sec: 58.80 - lr: 0.000030
2021-07-19 00:52:22,938 epoch 4 - iter 352/443 - loss 0.24772400 - samples/sec: 59.00 - lr: 0.000030
2021-07-19 00:52:46,926 epoch 4 - iter 396/443 - loss 0.24837900 - samples/sec: 58.70 - lr: 0.000030
2021-07-19 00:53:10,828 epoch 4 - iter 440/443 - loss 0.24516113 - samples/sec: 58.91 - lr: 0.000030
2021-07-19 00:53:12,419 ----------------------------------------------------------------------------------------------------
2021-07-19 00:53:12,420 EPOCH 4 done: loss 0.2445 - lr 0.0000300
2021-07-19 00:53:23,460 DEV : loss 0.22400720417499542 - score 0.9651
2021-07-19 00:53:23,606 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:53:28,132 ----------------------------------------------------------------------------------------------------
2021-07-19 00:53:51,975 epoch 5 - iter 44/443 - loss 0.22676935 - samples/sec: 59.06 - lr: 0.000030
2021-07-19 00:54:15,842 epoch 5 - iter 88/443 - loss 0.24680246 - samples/sec: 59.00 - lr: 0.000030
2021-07-19 00:54:39,636 epoch 5 - iter 132/443 - loss 0.23295582 - samples/sec: 59.18 - lr: 0.000030
2021-07-19 00:55:03,433 epoch 5 - iter 176/443 - loss 0.22770746 - samples/sec: 59.17 - lr: 0.000030
2021-07-19 00:55:27,339 epoch 5 - iter 220/443 - loss 0.22104890 - samples/sec: 58.90 - lr: 0.000030
2021-07-19 00:55:51,060 epoch 5 - iter 264/443 - loss 0.21436172 - samples/sec: 59.36 - lr: 0.000030
2021-07-19 00:56:14,779 epoch 5 - iter 308/443 - loss 0.21993667 - samples/sec: 59.37 - lr: 0.000030
2021-07-19 00:56:38,624 epoch 5 - iter 352/443 - loss 0.22544799 - samples/sec: 59.05 - lr: 0.000030
2021-07-19 00:57:02,593 epoch 5 - iter 396/443 - loss 0.22501744 - samples/sec: 58.75 - lr: 0.000030
2021-07-19 00:57:26,399 epoch 5 - iter 440/443 - loss 0.22381608 - samples/sec: 59.15 - lr: 0.000030
2021-07-19 00:57:27,971 ----------------------------------------------------------------------------------------------------
2021-07-19 00:57:27,971 EPOCH 5 done: loss 0.2245 - lr 0.0000300
2021-07-19 00:57:38,974 DEV : loss 0.2102070450782776 - score 0.9678
2021-07-19 00:57:39,121 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 00:57:43,459 ----------------------------------------------------------------------------------------------------
2021-07-19 00:58:07,369 epoch 6 - iter 44/443 - loss 0.22581072 - samples/sec: 58.90 - lr: 0.000030
2021-07-19 00:58:31,203 epoch 6 - iter 88/443 - loss 0.21217779 - samples/sec: 59.08 - lr: 0.000030
2021-07-19 00:58:54,992 epoch 6 - iter 132/443 - loss 0.20203099 - samples/sec: 59.19 - lr: 0.000030
2021-07-19 00:59:18,874 epoch 6 - iter 176/443 - loss 0.20016577 - samples/sec: 58.96 - lr: 0.000030
2021-07-19 00:59:42,804 epoch 6 - iter 220/443 - loss 0.20644233 - samples/sec: 58.85 - lr: 0.000030
2021-07-19 01:00:06,611 epoch 6 - iter 264/443 - loss 0.20697559 - samples/sec: 59.15 - lr: 0.000030
2021-07-19 01:00:30,353 epoch 6 - iter 308/443 - loss 0.20536176 - samples/sec: 59.31 - lr: 0.000030
2021-07-19 01:00:54,122 epoch 6 - iter 352/443 - loss 0.20307963 - samples/sec: 59.24 - lr: 0.000030
2021-07-19 01:01:17,977 epoch 6 - iter 396/443 - loss 0.20644663 - samples/sec: 59.03 - lr: 0.000030
2021-07-19 01:01:41,943 epoch 6 - iter 440/443 - loss 0.20448553 - samples/sec: 58.76 - lr: 0.000030
2021-07-19 01:01:43,533 ----------------------------------------------------------------------------------------------------
2021-07-19 01:01:43,534 EPOCH 6 done: loss 0.2048 - lr 0.0000300
2021-07-19 01:01:54,535 DEV : loss 0.20356562733650208 - score 0.9692
2021-07-19 01:01:54,679 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 01:01:59,189 ----------------------------------------------------------------------------------------------------
2021-07-19 01:02:22,971 epoch 7 - iter 44/443 - loss 0.19293864 - samples/sec: 59.21 - lr: 0.000030
2021-07-19 01:02:46,761 epoch 7 - iter 88/443 - loss 0.19428160 - samples/sec: 59.19 - lr: 0.000030
2021-07-19 01:03:10,512 epoch 7 - iter 132/443 - loss 0.19253777 - samples/sec: 59.29 - lr: 0.000030
2021-07-19 01:03:34,385 epoch 7 - iter 176/443 - loss 0.19045740 - samples/sec: 58.99 - lr: 0.000030
2021-07-19 01:03:58,178 epoch 7 - iter 220/443 - loss 0.19300156 - samples/sec: 59.18 - lr: 0.000030
2021-07-19 01:04:22,028 epoch 7 - iter 264/443 - loss 0.19333216 - samples/sec: 59.04 - lr: 0.000030
2021-07-19 01:04:45,731 epoch 7 - iter 308/443 - loss 0.19118339 - samples/sec: 59.41 - lr: 0.000030
2021-07-19 01:05:09,532 epoch 7 - iter 352/443 - loss 0.19008661 - samples/sec: 59.16 - lr: 0.000030
2021-07-19 01:05:33,367 epoch 7 - iter 396/443 - loss 0.19214289 - samples/sec: 59.08 - lr: 0.000030
2021-07-19 01:05:58,284 epoch 7 - iter 440/443 - loss 0.19335716 - samples/sec: 56.51 - lr: 0.000030
2021-07-19 01:05:59,851 ----------------------------------------------------------------------------------------------------
2021-07-19 01:05:59,851 EPOCH 7 done: loss 0.1927 - lr 0.0000300
2021-07-19 01:06:10,845 DEV : loss 0.20147013664245605 - score 0.9714
2021-07-19 01:06:10,992 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 01:06:15,425 ----------------------------------------------------------------------------------------------------
2021-07-19 01:06:39,375 epoch 8 - iter 44/443 - loss 0.18750221 - samples/sec: 58.80 - lr: 0.000030
2021-07-19 01:07:03,324 epoch 8 - iter 88/443 - loss 0.18507524 - samples/sec: 58.80 - lr: 0.000030
2021-07-19 01:07:27,301 epoch 8 - iter 132/443 - loss 0.17807165 - samples/sec: 58.73 - lr: 0.000030
2021-07-19 01:07:51,203 epoch 8 - iter 176/443 - loss 0.18159736 - samples/sec: 58.91 - lr: 0.000030
2021-07-19 01:08:15,218 epoch 8 - iter 220/443 - loss 0.18314104 - samples/sec: 58.64 - lr: 0.000030
2021-07-19 01:08:39,084 epoch 8 - iter 264/443 - loss 0.18288007 - samples/sec: 59.00 - lr: 0.000030
2021-07-19 01:09:03,018 epoch 8 - iter 308/443 - loss 0.18409575 - samples/sec: 58.83 - lr: 0.000030
2021-07-19 01:09:26,930 epoch 8 - iter 352/443 - loss 0.18526444 - samples/sec: 58.89 - lr: 0.000030
2021-07-19 01:09:50,791 epoch 8 - iter 396/443 - loss 0.18218415 - samples/sec: 59.01 - lr: 0.000030
2021-07-19 01:10:14,697 epoch 8 - iter 440/443 - loss 0.18152318 - samples/sec: 58.90 - lr: 0.000030
2021-07-19 01:10:16,294 ----------------------------------------------------------------------------------------------------
2021-07-19 01:10:16,295 EPOCH 8 done: loss 0.1815 - lr 0.0000300
2021-07-19 01:10:27,294 DEV : loss 0.1989675611257553 - score 0.9709
2021-07-19 01:10:27,441 BAD EPOCHS (no improvement): 1
2021-07-19 01:10:27,441 ----------------------------------------------------------------------------------------------------
2021-07-19 01:10:51,430 epoch 9 - iter 44/443 - loss 0.16099588 - samples/sec: 58.70 - lr: 0.000030
2021-07-19 01:11:15,335 epoch 9 - iter 88/443 - loss 0.16400473 - samples/sec: 58.91 - lr: 0.000030
2021-07-19 01:11:39,280 epoch 9 - iter 132/443 - loss 0.16124125 - samples/sec: 58.81 - lr: 0.000030
2021-07-19 01:12:03,206 epoch 9 - iter 176/443 - loss 0.17273564 - samples/sec: 58.85 - lr: 0.000030
2021-07-19 01:12:27,050 epoch 9 - iter 220/443 - loss 0.17173959 - samples/sec: 59.06 - lr: 0.000030
2021-07-19 01:12:50,987 epoch 9 - iter 264/443 - loss 0.17258949 - samples/sec: 58.83 - lr: 0.000030
2021-07-19 01:13:14,944 epoch 9 - iter 308/443 - loss 0.17491737 - samples/sec: 58.78 - lr: 0.000030
2021-07-19 01:13:38,873 epoch 9 - iter 352/443 - loss 0.17333202 - samples/sec: 58.85 - lr: 0.000030
2021-07-19 01:14:02,806 epoch 9 - iter 396/443 - loss 0.17287937 - samples/sec: 58.84 - lr: 0.000030
2021-07-19 01:14:26,762 epoch 9 - iter 440/443 - loss 0.17455787 - samples/sec: 58.78 - lr: 0.000030
2021-07-19 01:14:28,339 ----------------------------------------------------------------------------------------------------
2021-07-19 01:14:28,340 EPOCH 9 done: loss 0.1746 - lr 0.0000300
2021-07-19 01:14:39,366 DEV : loss 0.1953713297843933 - score 0.9717
2021-07-19 01:14:39,512 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 01:14:44,187 ----------------------------------------------------------------------------------------------------
2021-07-19 01:15:08,115 epoch 10 - iter 44/443 - loss 0.16314540 - samples/sec: 58.85 - lr: 0.000030
2021-07-19 01:15:31,999 epoch 10 - iter 88/443 - loss 0.17124059 - samples/sec: 58.96 - lr: 0.000030
2021-07-19 01:15:55,890 epoch 10 - iter 132/443 - loss 0.17278225 - samples/sec: 58.94 - lr: 0.000030
2021-07-19 01:16:19,791 epoch 10 - iter 176/443 - loss 0.17062055 - samples/sec: 58.92 - lr: 0.000030
2021-07-19 01:16:43,578 epoch 10 - iter 220/443 - loss 0.16934422 - samples/sec: 59.20 - lr: 0.000030
2021-07-19 01:17:07,430 epoch 10 - iter 264/443 - loss 0.16792687 - samples/sec: 59.04 - lr: 0.000030
2021-07-19 01:17:31,302 epoch 10 - iter 308/443 - loss 0.16573732 - samples/sec: 58.99 - lr: 0.000030
2021-07-19 01:17:55,152 epoch 10 - iter 352/443 - loss 0.16709596 - samples/sec: 59.04 - lr: 0.000030
2021-07-19 01:18:19,164 epoch 10 - iter 396/443 - loss 0.16575657 - samples/sec: 58.64 - lr: 0.000030
2021-07-19 01:18:43,075 epoch 10 - iter 440/443 - loss 0.16982318 - samples/sec: 58.89 - lr: 0.000030
2021-07-19 01:18:44,655 ----------------------------------------------------------------------------------------------------
2021-07-19 01:18:44,655 EPOCH 10 done: loss 0.1697 - lr 0.0000300
2021-07-19 01:18:56,884 DEV : loss 0.1813647300004959 - score 0.9731
2021-07-19 01:18:57,029 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 01:19:01,396 ----------------------------------------------------------------------------------------------------
2021-07-19 01:19:25,227 epoch 11 - iter 44/443 - loss 0.12982408 - samples/sec: 59.09 - lr: 0.000030
2021-07-19 01:19:49,100 epoch 11 - iter 88/443 - loss 0.14294960 - samples/sec: 58.98 - lr: 0.000030
2021-07-19 01:20:13,001 epoch 11 - iter 132/443 - loss 0.15197963 - samples/sec: 58.92 - lr: 0.000030
2021-07-19 01:20:36,944 epoch 11 - iter 176/443 - loss 0.15061955 - samples/sec: 58.81 - lr: 0.000030
2021-07-19 01:21:00,782 epoch 11 - iter 220/443 - loss 0.15314626 - samples/sec: 59.07 - lr: 0.000030
2021-07-19 01:21:24,600 epoch 11 - iter 264/443 - loss 0.15322983 - samples/sec: 59.12 - lr: 0.000030
2021-07-19 01:21:48,476 epoch 11 - iter 308/443 - loss 0.15276808 - samples/sec: 58.98 - lr: 0.000030
2021-07-19 01:22:12,320 epoch 11 - iter 352/443 - loss 0.15321323 - samples/sec: 59.06 - lr: 0.000030
2021-07-19 01:22:36,070 epoch 11 - iter 396/443 - loss 0.15450811 - samples/sec: 59.29 - lr: 0.000030
2021-07-19 01:22:59,942 epoch 11 - iter 440/443 - loss 0.15735951 - samples/sec: 58.99 - lr: 0.000030
2021-07-19 01:23:01,521 ----------------------------------------------------------------------------------------------------
2021-07-19 01:23:01,522 EPOCH 11 done: loss 0.1572 - lr 0.0000300
2021-07-19 01:23:12,550 DEV : loss 0.1710207760334015 - score 0.9739
2021-07-19 01:23:12,698 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 01:23:17,304 ----------------------------------------------------------------------------------------------------
2021-07-19 01:23:41,153 epoch 12 - iter 44/443 - loss 0.15133759 - samples/sec: 59.05 - lr: 0.000030
2021-07-19 01:24:05,030 epoch 12 - iter 88/443 - loss 0.15145910 - samples/sec: 58.97 - lr: 0.000030
2021-07-19 01:24:28,960 epoch 12 - iter 132/443 - loss 0.15149293 - samples/sec: 58.85 - lr: 0.000030
2021-07-19 01:24:52,874 epoch 12 - iter 176/443 - loss 0.14902204 - samples/sec: 58.88 - lr: 0.000030
2021-07-19 01:25:16,721 epoch 12 - iter 220/443 - loss 0.15121612 - samples/sec: 59.05 - lr: 0.000030
2021-07-19 01:25:40,588 epoch 12 - iter 264/443 - loss 0.15222179 - samples/sec: 59.00 - lr: 0.000030
2021-07-19 01:26:04,411 epoch 12 - iter 308/443 - loss 0.15111732 - samples/sec: 59.11 - lr: 0.000030
2021-07-19 01:26:28,302 epoch 12 - iter 352/443 - loss 0.15075699 - samples/sec: 58.94 - lr: 0.000030
2021-07-19 01:26:52,120 epoch 12 - iter 396/443 - loss 0.15102426 - samples/sec: 59.12 - lr: 0.000030
2021-07-19 01:27:16,010 epoch 12 - iter 440/443 - loss 0.15237319 - samples/sec: 58.94 - lr: 0.000030
2021-07-19 01:27:17,590 ----------------------------------------------------------------------------------------------------
2021-07-19 01:27:17,590 EPOCH 12 done: loss 0.1527 - lr 0.0000300
2021-07-19 01:27:28,622 DEV : loss 0.19336605072021484 - score 0.9729
2021-07-19 01:27:28,770 BAD EPOCHS (no improvement): 1
2021-07-19 01:27:28,770 ----------------------------------------------------------------------------------------------------
2021-07-19 01:27:52,611 epoch 13 - iter 44/443 - loss 0.14172191 - samples/sec: 59.07 - lr: 0.000030
2021-07-19 01:28:16,380 epoch 13 - iter 88/443 - loss 0.14165190 - samples/sec: 59.24 - lr: 0.000030
2021-07-19 01:28:40,237 epoch 13 - iter 132/443 - loss 0.14264152 - samples/sec: 59.02 - lr: 0.000030
2021-07-19 01:29:04,034 epoch 13 - iter 176/443 - loss 0.14553753 - samples/sec: 59.17 - lr: 0.000030
2021-07-19 01:29:27,811 epoch 13 - iter 220/443 - loss 0.15244875 - samples/sec: 59.22 - lr: 0.000030
2021-07-19 01:29:51,685 epoch 13 - iter 264/443 - loss 0.14949907 - samples/sec: 58.98 - lr: 0.000030
2021-07-19 01:30:15,613 epoch 13 - iter 308/443 - loss 0.15245020 - samples/sec: 58.85 - lr: 0.000030
2021-07-19 01:30:39,551 epoch 13 - iter 352/443 - loss 0.15351334 - samples/sec: 58.82 - lr: 0.000030
2021-07-19 01:31:03,530 epoch 13 - iter 396/443 - loss 0.15493462 - samples/sec: 58.73 - lr: 0.000030
2021-07-19 01:31:27,426 epoch 13 - iter 440/443 - loss 0.15211197 - samples/sec: 58.93 - lr: 0.000030
2021-07-19 01:31:29,026 ----------------------------------------------------------------------------------------------------
2021-07-19 01:31:29,026 EPOCH 13 done: loss 0.1530 - lr 0.0000300
2021-07-19 01:31:40,046 DEV : loss 0.19037756323814392 - score 0.9721
2021-07-19 01:31:40,191 BAD EPOCHS (no improvement): 2
2021-07-19 01:31:40,191 ----------------------------------------------------------------------------------------------------
2021-07-19 01:32:04,200 epoch 14 - iter 44/443 - loss 0.14286620 - samples/sec: 58.65 - lr: 0.000030
2021-07-19 01:32:28,176 epoch 14 - iter 88/443 - loss 0.13930422 - samples/sec: 58.73 - lr: 0.000030
2021-07-19 01:32:52,131 epoch 14 - iter 132/443 - loss 0.14293014 - samples/sec: 58.78 - lr: 0.000030
2021-07-19 01:33:16,044 epoch 14 - iter 176/443 - loss 0.14478780 - samples/sec: 58.88 - lr: 0.000030
2021-07-19 01:33:39,895 epoch 14 - iter 220/443 - loss 0.14507731 - samples/sec: 59.04 - lr: 0.000030
2021-07-19 01:34:03,768 epoch 14 - iter 264/443 - loss 0.14393722 - samples/sec: 58.98 - lr: 0.000030
2021-07-19 01:34:27,530 epoch 14 - iter 308/443 - loss 0.14598063 - samples/sec: 59.26 - lr: 0.000030
2021-07-19 01:34:52,400 epoch 14 - iter 352/443 - loss 0.14794286 - samples/sec: 56.62 - lr: 0.000030
2021-07-19 01:35:16,032 epoch 14 - iter 396/443 - loss 0.14905204 - samples/sec: 59.59 - lr: 0.000030
2021-07-19 01:35:39,807 epoch 14 - iter 440/443 - loss 0.14988249 - samples/sec: 59.23 - lr: 0.000030
2021-07-19 01:35:41,376 ----------------------------------------------------------------------------------------------------
2021-07-19 01:35:41,377 EPOCH 14 done: loss 0.1493 - lr 0.0000300
2021-07-19 01:35:52,393 DEV : loss 0.17151856422424316 - score 0.9731
2021-07-19 01:35:52,540 BAD EPOCHS (no improvement): 3
2021-07-19 01:35:52,540 ----------------------------------------------------------------------------------------------------
2021-07-19 01:36:16,283 epoch 15 - iter 44/443 - loss 0.15207020 - samples/sec: 59.31 - lr: 0.000030
2021-07-19 01:36:40,055 epoch 15 - iter 88/443 - loss 0.14994416 - samples/sec: 59.24 - lr: 0.000030
2021-07-19 01:37:03,781 epoch 15 - iter 132/443 - loss 0.15071623 - samples/sec: 59.35 - lr: 0.000030
2021-07-19 01:37:27,542 epoch 15 - iter 176/443 - loss 0.14915051 - samples/sec: 59.26 - lr: 0.000030
2021-07-19 01:37:51,386 epoch 15 - iter 220/443 - loss 0.14226903 - samples/sec: 59.06 - lr: 0.000030
2021-07-19 01:38:15,234 epoch 15 - iter 264/443 - loss 0.14363435 - samples/sec: 59.05 - lr: 0.000030
2021-07-19 01:38:38,968 epoch 15 - iter 308/443 - loss 0.14403167 - samples/sec: 59.33 - lr: 0.000030
2021-07-19 01:39:02,740 epoch 15 - iter 352/443 - loss 0.14309593 - samples/sec: 59.24 - lr: 0.000030
2021-07-19 01:39:26,546 epoch 15 - iter 396/443 - loss 0.14290767 - samples/sec: 59.15 - lr: 0.000030
2021-07-19 01:39:50,334 epoch 15 - iter 440/443 - loss 0.14214341 - samples/sec: 59.20 - lr: 0.000030
2021-07-19 01:39:51,907 ----------------------------------------------------------------------------------------------------
2021-07-19 01:39:51,908 EPOCH 15 done: loss 0.1421 - lr 0.0000300
2021-07-19 01:40:02,957 DEV : loss 0.1700996458530426 - score 0.9754
2021-07-19 01:40:03,107 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 01:40:07,647 ----------------------------------------------------------------------------------------------------
2021-07-19 01:40:31,631 epoch 16 - iter 44/443 - loss 0.14201285 - samples/sec: 58.71 - lr: 0.000030
2021-07-19 01:40:55,571 epoch 16 - iter 88/443 - loss 0.13700782 - samples/sec: 58.82 - lr: 0.000030
2021-07-19 01:41:19,477 epoch 16 - iter 132/443 - loss 0.13646738 - samples/sec: 58.90 - lr: 0.000030
2021-07-19 01:41:43,427 epoch 16 - iter 176/443 - loss 0.13285529 - samples/sec: 58.80 - lr: 0.000030
2021-07-19 01:42:07,385 epoch 16 - iter 220/443 - loss 0.13270060 - samples/sec: 58.78 - lr: 0.000030
2021-07-19 01:42:31,360 epoch 16 - iter 264/443 - loss 0.13313574 - samples/sec: 58.73 - lr: 0.000030
2021-07-19 01:42:55,313 epoch 16 - iter 308/443 - loss 0.13180952 - samples/sec: 58.79 - lr: 0.000030
2021-07-19 01:43:19,214 epoch 16 - iter 352/443 - loss 0.13101700 - samples/sec: 58.91 - lr: 0.000030
2021-07-19 01:43:43,148 epoch 16 - iter 396/443 - loss 0.13375495 - samples/sec: 58.84 - lr: 0.000030
2021-07-19 01:44:07,156 epoch 16 - iter 440/443 - loss 0.13372616 - samples/sec: 58.65 - lr: 0.000030
2021-07-19 01:44:08,742 ----------------------------------------------------------------------------------------------------
2021-07-19 01:44:08,742 EPOCH 16 done: loss 0.1335 - lr 0.0000300
2021-07-19 01:44:19,776 DEV : loss 0.17773741483688354 - score 0.9753
2021-07-19 01:44:19,922 BAD EPOCHS (no improvement): 1
2021-07-19 01:44:19,922 ----------------------------------------------------------------------------------------------------
2021-07-19 01:44:43,859 epoch 17 - iter 44/443 - loss 0.12049767 - samples/sec: 58.83 - lr: 0.000030
2021-07-19 01:45:07,699 epoch 17 - iter 88/443 - loss 0.12197338 - samples/sec: 59.07 - lr: 0.000030
2021-07-19 01:45:31,480 epoch 17 - iter 132/443 - loss 0.11351353 - samples/sec: 59.21 - lr: 0.000030
2021-07-19 01:45:55,376 epoch 17 - iter 176/443 - loss 0.12042679 - samples/sec: 58.93 - lr: 0.000030
2021-07-19 01:46:19,282 epoch 17 - iter 220/443 - loss 0.12435340 - samples/sec: 58.90 - lr: 0.000030
2021-07-19 01:46:43,188 epoch 17 - iter 264/443 - loss 0.12806945 - samples/sec: 58.90 - lr: 0.000030
2021-07-19 01:47:07,164 epoch 17 - iter 308/443 - loss 0.13183386 - samples/sec: 58.73 - lr: 0.000030
2021-07-19 01:47:31,066 epoch 17 - iter 352/443 - loss 0.13338140 - samples/sec: 58.91 - lr: 0.000030
2021-07-19 01:47:54,981 epoch 17 - iter 396/443 - loss 0.13155709 - samples/sec: 58.88 - lr: 0.000030
2021-07-19 01:48:18,962 epoch 17 - iter 440/443 - loss 0.13261831 - samples/sec: 58.72 - lr: 0.000030
2021-07-19 01:48:20,546 ----------------------------------------------------------------------------------------------------
2021-07-19 01:48:20,546 EPOCH 17 done: loss 0.1327 - lr 0.0000300
2021-07-19 01:48:32,802 DEV : loss 0.18811658024787903 - score 0.9746
2021-07-19 01:48:32,950 BAD EPOCHS (no improvement): 2
2021-07-19 01:48:32,950 ----------------------------------------------------------------------------------------------------
2021-07-19 01:48:56,841 epoch 18 - iter 44/443 - loss 0.12614776 - samples/sec: 58.94 - lr: 0.000030
2021-07-19 01:49:20,816 epoch 18 - iter 88/443 - loss 0.13221220 - samples/sec: 58.73 - lr: 0.000030
2021-07-19 01:49:44,765 epoch 18 - iter 132/443 - loss 0.13233913 - samples/sec: 58.80 - lr: 0.000030
2021-07-19 01:50:08,743 epoch 18 - iter 176/443 - loss 0.12879209 - samples/sec: 58.72 - lr: 0.000030
2021-07-19 01:50:32,704 epoch 18 - iter 220/443 - loss 0.13333188 - samples/sec: 58.77 - lr: 0.000030
2021-07-19 01:50:56,635 epoch 18 - iter 264/443 - loss 0.13371851 - samples/sec: 58.84 - lr: 0.000030
2021-07-19 01:51:20,495 epoch 18 - iter 308/443 - loss 0.13680456 - samples/sec: 59.02 - lr: 0.000030
2021-07-19 01:51:44,371 epoch 18 - iter 352/443 - loss 0.13346490 - samples/sec: 58.98 - lr: 0.000030
2021-07-19 01:52:08,284 epoch 18 - iter 396/443 - loss 0.13249148 - samples/sec: 58.89 - lr: 0.000030
2021-07-19 01:52:32,179 epoch 18 - iter 440/443 - loss 0.13080239 - samples/sec: 58.93 - lr: 0.000030
2021-07-19 01:52:33,774 ----------------------------------------------------------------------------------------------------
2021-07-19 01:52:33,774 EPOCH 18 done: loss 0.1311 - lr 0.0000300
2021-07-19 01:52:44,848 DEV : loss 0.1697172224521637 - score 0.9735
2021-07-19 01:52:44,995 BAD EPOCHS (no improvement): 3
2021-07-19 01:52:44,996 ----------------------------------------------------------------------------------------------------
2021-07-19 01:53:08,854 epoch 19 - iter 44/443 - loss 0.10590375 - samples/sec: 59.02 - lr: 0.000030
2021-07-19 01:53:32,688 epoch 19 - iter 88/443 - loss 0.11855595 - samples/sec: 59.08 - lr: 0.000030
2021-07-19 01:53:56,567 epoch 19 - iter 132/443 - loss 0.12007847 - samples/sec: 58.97 - lr: 0.000030
2021-07-19 01:54:20,414 epoch 19 - iter 176/443 - loss 0.12345952 - samples/sec: 59.05 - lr: 0.000030
2021-07-19 01:54:44,289 epoch 19 - iter 220/443 - loss 0.12552681 - samples/sec: 58.98 - lr: 0.000030
2021-07-19 01:55:08,160 epoch 19 - iter 264/443 - loss 0.12541951 - samples/sec: 58.99 - lr: 0.000030
2021-07-19 01:55:31,983 epoch 19 - iter 308/443 - loss 0.12240580 - samples/sec: 59.11 - lr: 0.000030
2021-07-19 01:55:55,791 epoch 19 - iter 352/443 - loss 0.12250962 - samples/sec: 59.14 - lr: 0.000030
2021-07-19 01:56:19,611 epoch 19 - iter 396/443 - loss 0.12391539 - samples/sec: 59.12 - lr: 0.000030
2021-07-19 01:56:43,512 epoch 19 - iter 440/443 - loss 0.12377910 - samples/sec: 58.92 - lr: 0.000030
2021-07-19 01:56:45,094 ----------------------------------------------------------------------------------------------------
2021-07-19 01:56:45,095 EPOCH 19 done: loss 0.1243 - lr 0.0000300
2021-07-19 01:56:56,155 DEV : loss 0.17892679572105408 - score 0.9739
Epoch    19: reducing learning rate of group 0 to 1.5000e-05.
2021-07-19 01:56:56,303 BAD EPOCHS (no improvement): 4
2021-07-19 01:56:56,304 ----------------------------------------------------------------------------------------------------
2021-07-19 01:57:20,102 epoch 20 - iter 44/443 - loss 0.12385199 - samples/sec: 59.17 - lr: 0.000015
2021-07-19 01:57:43,966 epoch 20 - iter 88/443 - loss 0.11212988 - samples/sec: 59.01 - lr: 0.000015
2021-07-19 01:58:07,811 epoch 20 - iter 132/443 - loss 0.11969313 - samples/sec: 59.05 - lr: 0.000015
2021-07-19 01:58:31,592 epoch 20 - iter 176/443 - loss 0.11846346 - samples/sec: 59.21 - lr: 0.000015
2021-07-19 01:58:55,444 epoch 20 - iter 220/443 - loss 0.11564440 - samples/sec: 59.04 - lr: 0.000015
2021-07-19 01:59:19,236 epoch 20 - iter 264/443 - loss 0.11507243 - samples/sec: 59.18 - lr: 0.000015
2021-07-19 01:59:43,151 epoch 20 - iter 308/443 - loss 0.11619627 - samples/sec: 58.88 - lr: 0.000015
2021-07-19 02:00:06,967 epoch 20 - iter 352/443 - loss 0.11799876 - samples/sec: 59.13 - lr: 0.000015
2021-07-19 02:00:30,779 epoch 20 - iter 396/443 - loss 0.11864223 - samples/sec: 59.14 - lr: 0.000015
2021-07-19 02:00:54,699 epoch 20 - iter 440/443 - loss 0.11984355 - samples/sec: 58.87 - lr: 0.000015
2021-07-19 02:00:56,287 ----------------------------------------------------------------------------------------------------
2021-07-19 02:00:56,287 EPOCH 20 done: loss 0.1196 - lr 0.0000150
2021-07-19 02:01:07,345 DEV : loss 0.17869672179222107 - score 0.9747
2021-07-19 02:01:07,494 BAD EPOCHS (no improvement): 1
2021-07-19 02:01:07,494 ----------------------------------------------------------------------------------------------------
2021-07-19 02:01:31,486 epoch 21 - iter 44/443 - loss 0.09630440 - samples/sec: 58.69 - lr: 0.000015
2021-07-19 02:01:55,448 epoch 21 - iter 88/443 - loss 0.11038775 - samples/sec: 58.77 - lr: 0.000015
2021-07-19 02:02:19,471 epoch 21 - iter 132/443 - loss 0.11197538 - samples/sec: 58.62 - lr: 0.000015
2021-07-19 02:02:43,452 epoch 21 - iter 176/443 - loss 0.11169953 - samples/sec: 58.72 - lr: 0.000015
2021-07-19 02:03:07,416 epoch 21 - iter 220/443 - loss 0.11326079 - samples/sec: 58.76 - lr: 0.000015
2021-07-19 02:03:31,220 epoch 21 - iter 264/443 - loss 0.11362772 - samples/sec: 59.16 - lr: 0.000015
2021-07-19 02:03:55,130 epoch 21 - iter 308/443 - loss 0.11117135 - samples/sec: 58.89 - lr: 0.000015
2021-07-19 02:04:19,106 epoch 21 - iter 352/443 - loss 0.10851015 - samples/sec: 58.73 - lr: 0.000015
2021-07-19 02:04:43,042 epoch 21 - iter 396/443 - loss 0.11054159 - samples/sec: 58.83 - lr: 0.000015
2021-07-19 02:05:07,037 epoch 21 - iter 440/443 - loss 0.10980997 - samples/sec: 58.68 - lr: 0.000015
2021-07-19 02:05:08,599 ----------------------------------------------------------------------------------------------------
2021-07-19 02:05:08,599 EPOCH 21 done: loss 0.1099 - lr 0.0000150
2021-07-19 02:05:20,834 DEV : loss 0.17280399799346924 - score 0.9757
2021-07-19 02:05:20,983 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 02:05:25,399 ----------------------------------------------------------------------------------------------------
2021-07-19 02:05:49,280 epoch 22 - iter 44/443 - loss 0.09450567 - samples/sec: 58.97 - lr: 0.000015
2021-07-19 02:06:13,152 epoch 22 - iter 88/443 - loss 0.10668124 - samples/sec: 58.99 - lr: 0.000015
2021-07-19 02:06:37,028 epoch 22 - iter 132/443 - loss 0.10499229 - samples/sec: 58.98 - lr: 0.000015
2021-07-19 02:07:00,999 epoch 22 - iter 176/443 - loss 0.10689482 - samples/sec: 58.74 - lr: 0.000015
2021-07-19 02:07:24,963 epoch 22 - iter 220/443 - loss 0.10701994 - samples/sec: 58.76 - lr: 0.000015
2021-07-19 02:07:48,892 epoch 22 - iter 264/443 - loss 0.10740042 - samples/sec: 58.85 - lr: 0.000015
2021-07-19 02:08:12,856 epoch 22 - iter 308/443 - loss 0.10941539 - samples/sec: 58.76 - lr: 0.000015
2021-07-19 02:08:36,883 epoch 22 - iter 352/443 - loss 0.11000276 - samples/sec: 58.61 - lr: 0.000015
2021-07-19 02:09:00,808 epoch 22 - iter 396/443 - loss 0.11008219 - samples/sec: 58.86 - lr: 0.000015
2021-07-19 02:09:24,784 epoch 22 - iter 440/443 - loss 0.10910920 - samples/sec: 58.73 - lr: 0.000015
2021-07-19 02:09:26,376 ----------------------------------------------------------------------------------------------------
2021-07-19 02:09:26,376 EPOCH 22 done: loss 0.1088 - lr 0.0000150
2021-07-19 02:09:37,445 DEV : loss 0.17417681217193604 - score 0.9762
2021-07-19 02:09:37,592 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 02:09:42,004 ----------------------------------------------------------------------------------------------------
2021-07-19 02:10:06,031 epoch 23 - iter 44/443 - loss 0.10420629 - samples/sec: 58.61 - lr: 0.000015
2021-07-19 02:10:29,978 epoch 23 - iter 88/443 - loss 0.10272705 - samples/sec: 58.80 - lr: 0.000015
2021-07-19 02:10:53,900 epoch 23 - iter 132/443 - loss 0.10308381 - samples/sec: 58.86 - lr: 0.000015
2021-07-19 02:11:17,832 epoch 23 - iter 176/443 - loss 0.10228767 - samples/sec: 58.84 - lr: 0.000015
2021-07-19 02:11:41,679 epoch 23 - iter 220/443 - loss 0.10201701 - samples/sec: 59.05 - lr: 0.000015
2021-07-19 02:12:05,567 epoch 23 - iter 264/443 - loss 0.10136262 - samples/sec: 58.95 - lr: 0.000015
2021-07-19 02:12:29,475 epoch 23 - iter 308/443 - loss 0.10327743 - samples/sec: 58.90 - lr: 0.000015
2021-07-19 02:12:53,251 epoch 23 - iter 352/443 - loss 0.10484327 - samples/sec: 59.22 - lr: 0.000015
2021-07-19 02:13:17,086 epoch 23 - iter 396/443 - loss 0.10477908 - samples/sec: 59.08 - lr: 0.000015
2021-07-19 02:13:40,959 epoch 23 - iter 440/443 - loss 0.10613632 - samples/sec: 58.99 - lr: 0.000015
2021-07-19 02:13:42,513 ----------------------------------------------------------------------------------------------------
2021-07-19 02:13:42,514 EPOCH 23 done: loss 0.1061 - lr 0.0000150
2021-07-19 02:13:53,595 DEV : loss 0.16579633951187134 - score 0.9757
2021-07-19 02:13:53,742 BAD EPOCHS (no improvement): 1
2021-07-19 02:13:53,742 ----------------------------------------------------------------------------------------------------
2021-07-19 02:14:17,559 epoch 24 - iter 44/443 - loss 0.11766834 - samples/sec: 59.12 - lr: 0.000015
2021-07-19 02:14:41,398 epoch 24 - iter 88/443 - loss 0.11031036 - samples/sec: 59.07 - lr: 0.000015
2021-07-19 02:15:05,234 epoch 24 - iter 132/443 - loss 0.10922175 - samples/sec: 59.08 - lr: 0.000015
2021-07-19 02:15:29,143 epoch 24 - iter 176/443 - loss 0.10405406 - samples/sec: 58.90 - lr: 0.000015
2021-07-19 02:15:53,019 epoch 24 - iter 220/443 - loss 0.10163483 - samples/sec: 58.98 - lr: 0.000015
2021-07-19 02:16:16,866 epoch 24 - iter 264/443 - loss 0.10206613 - samples/sec: 59.05 - lr: 0.000015
2021-07-19 02:16:40,775 epoch 24 - iter 308/443 - loss 0.10412155 - samples/sec: 58.90 - lr: 0.000015
2021-07-19 02:17:04,711 epoch 24 - iter 352/443 - loss 0.10670109 - samples/sec: 58.83 - lr: 0.000015
2021-07-19 02:17:28,629 epoch 24 - iter 396/443 - loss 0.10615780 - samples/sec: 58.87 - lr: 0.000015
2021-07-19 02:17:52,436 epoch 24 - iter 440/443 - loss 0.10504889 - samples/sec: 59.15 - lr: 0.000015
2021-07-19 02:17:54,021 ----------------------------------------------------------------------------------------------------
2021-07-19 02:17:54,021 EPOCH 24 done: loss 0.1049 - lr 0.0000150
2021-07-19 02:18:05,095 DEV : loss 0.17540021240711212 - score 0.9755
2021-07-19 02:18:05,243 BAD EPOCHS (no improvement): 2
2021-07-19 02:18:05,243 ----------------------------------------------------------------------------------------------------
2021-07-19 02:18:29,100 epoch 25 - iter 44/443 - loss 0.09809060 - samples/sec: 59.03 - lr: 0.000015
2021-07-19 02:18:53,020 epoch 25 - iter 88/443 - loss 0.09841043 - samples/sec: 58.87 - lr: 0.000015
2021-07-19 02:19:16,982 epoch 25 - iter 132/443 - loss 0.09989683 - samples/sec: 58.76 - lr: 0.000015
2021-07-19 02:19:40,866 epoch 25 - iter 176/443 - loss 0.09999571 - samples/sec: 58.96 - lr: 0.000015
2021-07-19 02:20:04,679 epoch 25 - iter 220/443 - loss 0.10039089 - samples/sec: 59.13 - lr: 0.000015
2021-07-19 02:20:28,547 epoch 25 - iter 264/443 - loss 0.10207600 - samples/sec: 59.00 - lr: 0.000015
2021-07-19 02:20:52,415 epoch 25 - iter 308/443 - loss 0.10145625 - samples/sec: 59.00 - lr: 0.000015
2021-07-19 02:21:16,278 epoch 25 - iter 352/443 - loss 0.10104512 - samples/sec: 59.01 - lr: 0.000015
2021-07-19 02:21:40,123 epoch 25 - iter 396/443 - loss 0.10372455 - samples/sec: 59.05 - lr: 0.000015
2021-07-19 02:22:05,294 epoch 25 - iter 440/443 - loss 0.10479065 - samples/sec: 55.94 - lr: 0.000015
2021-07-19 02:22:06,886 ----------------------------------------------------------------------------------------------------
2021-07-19 02:22:06,886 EPOCH 25 done: loss 0.1050 - lr 0.0000150
2021-07-19 02:22:17,956 DEV : loss 0.1690203696489334 - score 0.9755
2021-07-19 02:22:18,104 BAD EPOCHS (no improvement): 3
2021-07-19 02:22:18,104 ----------------------------------------------------------------------------------------------------
2021-07-19 02:22:41,993 epoch 26 - iter 44/443 - loss 0.10032709 - samples/sec: 58.95 - lr: 0.000015
2021-07-19 02:23:05,813 epoch 26 - iter 88/443 - loss 0.09900960 - samples/sec: 59.12 - lr: 0.000015
2021-07-19 02:23:29,644 epoch 26 - iter 132/443 - loss 0.10184247 - samples/sec: 59.09 - lr: 0.000015
2021-07-19 02:23:53,596 epoch 26 - iter 176/443 - loss 0.10377766 - samples/sec: 58.79 - lr: 0.000015
2021-07-19 02:24:17,432 epoch 26 - iter 220/443 - loss 0.10343972 - samples/sec: 59.08 - lr: 0.000015
2021-07-19 02:24:41,340 epoch 26 - iter 264/443 - loss 0.10373058 - samples/sec: 58.90 - lr: 0.000015
2021-07-19 02:25:05,269 epoch 26 - iter 308/443 - loss 0.10448892 - samples/sec: 58.85 - lr: 0.000015
2021-07-19 02:25:29,159 epoch 26 - iter 352/443 - loss 0.10479060 - samples/sec: 58.94 - lr: 0.000015
2021-07-19 02:25:53,039 epoch 26 - iter 396/443 - loss 0.10268668 - samples/sec: 58.97 - lr: 0.000015
2021-07-19 02:26:16,923 epoch 26 - iter 440/443 - loss 0.10216410 - samples/sec: 58.96 - lr: 0.000015
2021-07-19 02:26:18,517 ----------------------------------------------------------------------------------------------------
2021-07-19 02:26:18,517 EPOCH 26 done: loss 0.1023 - lr 0.0000150
2021-07-19 02:26:29,594 DEV : loss 0.17577968537807465 - score 0.9762
2021-07-19 02:26:29,742 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 02:26:34,102 ----------------------------------------------------------------------------------------------------
2021-07-19 02:26:58,007 epoch 27 - iter 44/443 - loss 0.08435954 - samples/sec: 58.91 - lr: 0.000015
2021-07-19 02:27:21,959 epoch 27 - iter 88/443 - loss 0.08790658 - samples/sec: 58.79 - lr: 0.000015
2021-07-19 02:27:45,875 epoch 27 - iter 132/443 - loss 0.09193499 - samples/sec: 58.88 - lr: 0.000015
2021-07-19 02:28:09,795 epoch 27 - iter 176/443 - loss 0.09509981 - samples/sec: 58.87 - lr: 0.000015
2021-07-19 02:28:33,763 epoch 27 - iter 220/443 - loss 0.09510270 - samples/sec: 58.75 - lr: 0.000015
2021-07-19 02:28:57,744 epoch 27 - iter 264/443 - loss 0.09488577 - samples/sec: 58.72 - lr: 0.000015
2021-07-19 02:29:21,839 epoch 27 - iter 308/443 - loss 0.09474468 - samples/sec: 58.44 - lr: 0.000015
2021-07-19 02:29:45,792 epoch 27 - iter 352/443 - loss 0.09679243 - samples/sec: 58.79 - lr: 0.000015
2021-07-19 02:30:09,718 epoch 27 - iter 396/443 - loss 0.09630115 - samples/sec: 58.85 - lr: 0.000015
2021-07-19 02:30:33,618 epoch 27 - iter 440/443 - loss 0.09745828 - samples/sec: 58.92 - lr: 0.000015
2021-07-19 02:30:35,206 ----------------------------------------------------------------------------------------------------
2021-07-19 02:30:35,206 EPOCH 27 done: loss 0.0973 - lr 0.0000150
2021-07-19 02:30:46,253 DEV : loss 0.1703544706106186 - score 0.9762
2021-07-19 02:30:46,399 BAD EPOCHS (no improvement): 1
2021-07-19 02:30:46,400 ----------------------------------------------------------------------------------------------------
2021-07-19 02:31:10,367 epoch 28 - iter 44/443 - loss 0.11143557 - samples/sec: 58.75 - lr: 0.000015
2021-07-19 02:31:34,204 epoch 28 - iter 88/443 - loss 0.10713281 - samples/sec: 59.07 - lr: 0.000015
2021-07-19 02:31:58,210 epoch 28 - iter 132/443 - loss 0.10433421 - samples/sec: 58.66 - lr: 0.000015
2021-07-19 02:32:22,244 epoch 28 - iter 176/443 - loss 0.10446895 - samples/sec: 58.59 - lr: 0.000015
2021-07-19 02:32:46,250 epoch 28 - iter 220/443 - loss 0.10162311 - samples/sec: 58.66 - lr: 0.000015
2021-07-19 02:33:10,239 epoch 28 - iter 264/443 - loss 0.10176147 - samples/sec: 58.70 - lr: 0.000015
2021-07-19 02:33:34,188 epoch 28 - iter 308/443 - loss 0.10008863 - samples/sec: 58.80 - lr: 0.000015
2021-07-19 02:33:58,175 epoch 28 - iter 352/443 - loss 0.10015113 - samples/sec: 58.70 - lr: 0.000015
2021-07-19 02:34:22,083 epoch 28 - iter 396/443 - loss 0.10129800 - samples/sec: 58.90 - lr: 0.000015
2021-07-19 02:34:46,031 epoch 28 - iter 440/443 - loss 0.10111647 - samples/sec: 58.80 - lr: 0.000015
2021-07-19 02:34:47,626 ----------------------------------------------------------------------------------------------------
2021-07-19 02:34:47,626 EPOCH 28 done: loss 0.1011 - lr 0.0000150
2021-07-19 02:34:58,708 DEV : loss 0.17665870487689972 - score 0.9762
2021-07-19 02:34:58,854 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 02:35:03,239 ----------------------------------------------------------------------------------------------------
2021-07-19 02:35:28,340 epoch 29 - iter 44/443 - loss 0.09337117 - samples/sec: 56.10 - lr: 0.000015
2021-07-19 02:35:52,342 epoch 29 - iter 88/443 - loss 0.09118756 - samples/sec: 58.67 - lr: 0.000015
2021-07-19 02:36:16,310 epoch 29 - iter 132/443 - loss 0.08917402 - samples/sec: 58.75 - lr: 0.000015
2021-07-19 02:36:40,238 epoch 29 - iter 176/443 - loss 0.09534153 - samples/sec: 58.85 - lr: 0.000015
2021-07-19 02:37:04,144 epoch 29 - iter 220/443 - loss 0.09736592 - samples/sec: 58.90 - lr: 0.000015
2021-07-19 02:37:28,093 epoch 29 - iter 264/443 - loss 0.09670108 - samples/sec: 58.80 - lr: 0.000015
2021-07-19 02:37:52,096 epoch 29 - iter 308/443 - loss 0.09697822 - samples/sec: 58.67 - lr: 0.000015
2021-07-19 02:38:16,000 epoch 29 - iter 352/443 - loss 0.09630347 - samples/sec: 58.91 - lr: 0.000015
2021-07-19 02:38:40,015 epoch 29 - iter 396/443 - loss 0.09855756 - samples/sec: 58.64 - lr: 0.000015
2021-07-19 02:39:03,985 epoch 29 - iter 440/443 - loss 0.09719835 - samples/sec: 58.75 - lr: 0.000015
2021-07-19 02:39:05,564 ----------------------------------------------------------------------------------------------------
2021-07-19 02:39:05,564 EPOCH 29 done: loss 0.0973 - lr 0.0000150
2021-07-19 02:39:16,641 DEV : loss 0.16458001732826233 - score 0.9759
2021-07-19 02:39:16,789 BAD EPOCHS (no improvement): 1
2021-07-19 02:39:16,789 ----------------------------------------------------------------------------------------------------
2021-07-19 02:39:40,489 epoch 30 - iter 44/443 - loss 0.09122388 - samples/sec: 59.42 - lr: 0.000015
2021-07-19 02:40:04,366 epoch 30 - iter 88/443 - loss 0.09923405 - samples/sec: 58.97 - lr: 0.000015
2021-07-19 02:40:28,301 epoch 30 - iter 132/443 - loss 0.09384251 - samples/sec: 58.83 - lr: 0.000015
2021-07-19 02:40:52,283 epoch 30 - iter 176/443 - loss 0.09328649 - samples/sec: 58.72 - lr: 0.000015
2021-07-19 02:41:16,276 epoch 30 - iter 220/443 - loss 0.09463493 - samples/sec: 58.69 - lr: 0.000015
2021-07-19 02:41:40,020 epoch 30 - iter 264/443 - loss 0.09450559 - samples/sec: 59.31 - lr: 0.000015
2021-07-19 02:42:03,802 epoch 30 - iter 308/443 - loss 0.09534580 - samples/sec: 59.21 - lr: 0.000015
2021-07-19 02:42:27,652 epoch 30 - iter 352/443 - loss 0.09454679 - samples/sec: 59.04 - lr: 0.000015
2021-07-19 02:42:51,531 epoch 30 - iter 396/443 - loss 0.09411113 - samples/sec: 58.97 - lr: 0.000015
2021-07-19 02:43:15,285 epoch 30 - iter 440/443 - loss 0.09442163 - samples/sec: 59.28 - lr: 0.000015
2021-07-19 02:43:16,859 ----------------------------------------------------------------------------------------------------
2021-07-19 02:43:16,859 EPOCH 30 done: loss 0.0943 - lr 0.0000150
2021-07-19 02:43:27,898 DEV : loss 0.16419726610183716 - score 0.9755
2021-07-19 02:43:28,045 BAD EPOCHS (no improvement): 2
2021-07-19 02:43:28,045 ----------------------------------------------------------------------------------------------------
2021-07-19 02:43:51,806 epoch 31 - iter 44/443 - loss 0.10589343 - samples/sec: 59.26 - lr: 0.000015
2021-07-19 02:44:15,664 epoch 31 - iter 88/443 - loss 0.10399748 - samples/sec: 59.02 - lr: 0.000015
2021-07-19 02:44:39,562 epoch 31 - iter 132/443 - loss 0.09963584 - samples/sec: 58.92 - lr: 0.000015
2021-07-19 02:45:03,494 epoch 31 - iter 176/443 - loss 0.09627412 - samples/sec: 58.84 - lr: 0.000015
2021-07-19 02:45:27,444 epoch 31 - iter 220/443 - loss 0.09452305 - samples/sec: 58.79 - lr: 0.000015
2021-07-19 02:45:51,346 epoch 31 - iter 264/443 - loss 0.09440876 - samples/sec: 58.91 - lr: 0.000015
2021-07-19 02:46:15,332 epoch 31 - iter 308/443 - loss 0.09765475 - samples/sec: 58.71 - lr: 0.000015
2021-07-19 02:46:39,392 epoch 31 - iter 352/443 - loss 0.09509955 - samples/sec: 58.53 - lr: 0.000015
2021-07-19 02:47:03,340 epoch 31 - iter 396/443 - loss 0.09494864 - samples/sec: 58.80 - lr: 0.000015
2021-07-19 02:47:27,308 epoch 31 - iter 440/443 - loss 0.09319528 - samples/sec: 58.75 - lr: 0.000015
2021-07-19 02:47:28,914 ----------------------------------------------------------------------------------------------------
2021-07-19 02:47:28,915 EPOCH 31 done: loss 0.0937 - lr 0.0000150
2021-07-19 02:47:39,941 DEV : loss 0.1674453616142273 - score 0.9757
2021-07-19 02:47:40,088 BAD EPOCHS (no improvement): 3
2021-07-19 02:47:40,088 ----------------------------------------------------------------------------------------------------
2021-07-19 02:48:04,012 epoch 32 - iter 44/443 - loss 0.08433436 - samples/sec: 58.86 - lr: 0.000015
2021-07-19 02:48:28,023 epoch 32 - iter 88/443 - loss 0.08347771 - samples/sec: 58.65 - lr: 0.000015
2021-07-19 02:48:51,859 epoch 32 - iter 132/443 - loss 0.09419923 - samples/sec: 59.08 - lr: 0.000015
2021-07-19 02:49:15,806 epoch 32 - iter 176/443 - loss 0.09355527 - samples/sec: 58.80 - lr: 0.000015
2021-07-19 02:49:39,764 epoch 32 - iter 220/443 - loss 0.09397313 - samples/sec: 58.78 - lr: 0.000015
2021-07-19 02:50:03,769 epoch 32 - iter 264/443 - loss 0.09424542 - samples/sec: 58.66 - lr: 0.000015
2021-07-19 02:50:27,756 epoch 32 - iter 308/443 - loss 0.09366378 - samples/sec: 58.70 - lr: 0.000015
2021-07-19 02:50:51,686 epoch 32 - iter 352/443 - loss 0.09255101 - samples/sec: 58.84 - lr: 0.000015
2021-07-19 02:51:15,562 epoch 32 - iter 396/443 - loss 0.09119442 - samples/sec: 58.98 - lr: 0.000015
2021-07-19 02:51:39,463 epoch 32 - iter 440/443 - loss 0.09001510 - samples/sec: 58.91 - lr: 0.000015
2021-07-19 02:51:41,062 ----------------------------------------------------------------------------------------------------
2021-07-19 02:51:41,062 EPOCH 32 done: loss 0.0902 - lr 0.0000150
2021-07-19 02:51:53,294 DEV : loss 0.16613706946372986 - score 0.9751
Epoch    32: reducing learning rate of group 0 to 7.5000e-06.
2021-07-19 02:51:53,443 BAD EPOCHS (no improvement): 4
2021-07-19 02:51:53,444 ----------------------------------------------------------------------------------------------------
2021-07-19 02:52:17,395 epoch 33 - iter 44/443 - loss 0.10397681 - samples/sec: 58.79 - lr: 0.000008
2021-07-19 02:52:41,272 epoch 33 - iter 88/443 - loss 0.09859307 - samples/sec: 58.97 - lr: 0.000008
2021-07-19 02:53:04,999 epoch 33 - iter 132/443 - loss 0.09280174 - samples/sec: 59.35 - lr: 0.000008
2021-07-19 02:53:28,802 epoch 33 - iter 176/443 - loss 0.09524282 - samples/sec: 59.16 - lr: 0.000008
2021-07-19 02:53:52,798 epoch 33 - iter 220/443 - loss 0.09361327 - samples/sec: 58.68 - lr: 0.000008
2021-07-19 02:54:16,766 epoch 33 - iter 264/443 - loss 0.09114052 - samples/sec: 58.75 - lr: 0.000008
2021-07-19 02:54:40,691 epoch 33 - iter 308/443 - loss 0.09056410 - samples/sec: 58.86 - lr: 0.000008
2021-07-19 02:55:04,635 epoch 33 - iter 352/443 - loss 0.09004668 - samples/sec: 58.81 - lr: 0.000008
2021-07-19 02:55:28,549 epoch 33 - iter 396/443 - loss 0.08913950 - samples/sec: 58.88 - lr: 0.000008
2021-07-19 02:55:52,488 epoch 33 - iter 440/443 - loss 0.08788671 - samples/sec: 58.82 - lr: 0.000008
2021-07-19 02:55:54,078 ----------------------------------------------------------------------------------------------------
2021-07-19 02:55:54,079 EPOCH 33 done: loss 0.0879 - lr 0.0000075
2021-07-19 02:56:05,130 DEV : loss 0.17305386066436768 - score 0.9764
2021-07-19 02:56:05,276 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 02:56:09,781 ----------------------------------------------------------------------------------------------------
2021-07-19 02:56:33,495 epoch 34 - iter 44/443 - loss 0.06631416 - samples/sec: 59.38 - lr: 0.000008
2021-07-19 02:56:57,428 epoch 34 - iter 88/443 - loss 0.07204913 - samples/sec: 58.84 - lr: 0.000008
2021-07-19 02:57:21,361 epoch 34 - iter 132/443 - loss 0.07770076 - samples/sec: 58.84 - lr: 0.000008
2021-07-19 02:57:45,298 epoch 34 - iter 176/443 - loss 0.07990333 - samples/sec: 58.83 - lr: 0.000008
2021-07-19 02:58:09,206 epoch 34 - iter 220/443 - loss 0.08144612 - samples/sec: 58.90 - lr: 0.000008
2021-07-19 02:58:33,231 epoch 34 - iter 264/443 - loss 0.08254859 - samples/sec: 58.61 - lr: 0.000008
2021-07-19 02:58:57,260 epoch 34 - iter 308/443 - loss 0.08408888 - samples/sec: 58.60 - lr: 0.000008
2021-07-19 02:59:21,216 epoch 34 - iter 352/443 - loss 0.08314888 - samples/sec: 58.78 - lr: 0.000008
2021-07-19 02:59:45,168 epoch 34 - iter 396/443 - loss 0.08363867 - samples/sec: 58.79 - lr: 0.000008
2021-07-19 03:00:09,025 epoch 34 - iter 440/443 - loss 0.08405758 - samples/sec: 59.02 - lr: 0.000008
2021-07-19 03:00:10,612 ----------------------------------------------------------------------------------------------------
2021-07-19 03:00:10,613 EPOCH 34 done: loss 0.0843 - lr 0.0000075
2021-07-19 03:00:21,680 DEV : loss 0.17544220387935638 - score 0.977
2021-07-19 03:00:21,826 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 03:00:26,187 ----------------------------------------------------------------------------------------------------
2021-07-19 03:00:50,047 epoch 35 - iter 44/443 - loss 0.08339903 - samples/sec: 59.02 - lr: 0.000008
2021-07-19 03:01:13,895 epoch 35 - iter 88/443 - loss 0.08646467 - samples/sec: 59.05 - lr: 0.000008
2021-07-19 03:01:37,853 epoch 35 - iter 132/443 - loss 0.08187870 - samples/sec: 58.78 - lr: 0.000008
2021-07-19 03:02:01,780 epoch 35 - iter 176/443 - loss 0.08408183 - samples/sec: 58.85 - lr: 0.000008
2021-07-19 03:02:25,653 epoch 35 - iter 220/443 - loss 0.08597221 - samples/sec: 58.98 - lr: 0.000008
2021-07-19 03:02:49,405 epoch 35 - iter 264/443 - loss 0.08551601 - samples/sec: 59.29 - lr: 0.000008
2021-07-19 03:03:13,108 epoch 35 - iter 308/443 - loss 0.08569645 - samples/sec: 59.41 - lr: 0.000008
2021-07-19 03:03:36,841 epoch 35 - iter 352/443 - loss 0.08502811 - samples/sec: 59.33 - lr: 0.000008
2021-07-19 03:04:00,604 epoch 35 - iter 396/443 - loss 0.08573760 - samples/sec: 59.26 - lr: 0.000008
2021-07-19 03:04:24,656 epoch 35 - iter 440/443 - loss 0.08448835 - samples/sec: 58.55 - lr: 0.000008
2021-07-19 03:04:26,251 ----------------------------------------------------------------------------------------------------
2021-07-19 03:04:26,252 EPOCH 35 done: loss 0.0841 - lr 0.0000075
2021-07-19 03:04:37,308 DEV : loss 0.17196178436279297 - score 0.978
2021-07-19 03:04:37,457 BAD EPOCHS (no improvement): 0
saving best model
2021-07-19 03:04:42,091 ----------------------------------------------------------------------------------------------------
2021-07-19 03:05:06,085 epoch 36 - iter 44/443 - loss 0.08691585 - samples/sec: 58.69 - lr: 0.000008
2021-07-19 03:05:29,947 epoch 36 - iter 88/443 - loss 0.08902067 - samples/sec: 59.01 - lr: 0.000008
2021-07-19 03:05:55,192 epoch 36 - iter 132/443 - loss 0.08481228 - samples/sec: 55.78 - lr: 0.000008
2021-07-19 03:06:19,206 epoch 36 - iter 176/443 - loss 0.08756313 - samples/sec: 58.64 - lr: 0.000008
2021-07-19 03:06:43,151 epoch 36 - iter 220/443 - loss 0.08974583 - samples/sec: 58.81 - lr: 0.000008
2021-07-19 03:07:07,111 epoch 36 - iter 264/443 - loss 0.08954461 - samples/sec: 58.77 - lr: 0.000008
2021-07-19 03:07:31,012 epoch 36 - iter 308/443 - loss 0.08942986 - samples/sec: 58.92 - lr: 0.000008
2021-07-19 03:07:54,982 epoch 36 - iter 352/443 - loss 0.08818937 - samples/sec: 58.75 - lr: 0.000008
2021-07-19 03:08:18,907 epoch 36 - iter 396/443 - loss 0.08785159 - samples/sec: 58.86 - lr: 0.000008
2021-07-19 03:08:42,851 epoch 36 - iter 440/443 - loss 0.08634921 - samples/sec: 58.81 - lr: 0.000008
2021-07-19 03:08:44,450 ----------------------------------------------------------------------------------------------------
2021-07-19 03:08:44,450 EPOCH 36 done: loss 0.0865 - lr 0.0000075
2021-07-19 03:08:55,488 DEV : loss 0.17233045399188995 - score 0.9772
2021-07-19 03:08:55,635 BAD EPOCHS (no improvement): 1
2021-07-19 03:08:55,635 ----------------------------------------------------------------------------------------------------
2021-07-19 03:09:19,554 epoch 37 - iter 44/443 - loss 0.08597523 - samples/sec: 58.87 - lr: 0.000008
2021-07-19 03:09:43,489 epoch 37 - iter 88/443 - loss 0.08957326 - samples/sec: 58.83 - lr: 0.000008
2021-07-19 03:10:07,459 epoch 37 - iter 132/443 - loss 0.08905737 - samples/sec: 58.75 - lr: 0.000008
2021-07-19 03:10:31,432 epoch 37 - iter 176/443 - loss 0.08580379 - samples/sec: 58.74 - lr: 0.000008
2021-07-19 03:10:55,423 epoch 37 - iter 220/443 - loss 0.08414231 - samples/sec: 58.69 - lr: 0.000008
2021-07-19 03:11:19,419 epoch 37 - iter 264/443 - loss 0.08558938 - samples/sec: 58.68 - lr: 0.000008
2021-07-19 03:11:43,395 epoch 37 - iter 308/443 - loss 0.08537089 - samples/sec: 58.73 - lr: 0.000008
2021-07-19 03:12:07,364 epoch 37 - iter 352/443 - loss 0.08513831 - samples/sec: 58.75 - lr: 0.000008
2021-07-19 03:12:31,294 epoch 37 - iter 396/443 - loss 0.08462826 - samples/sec: 58.84 - lr: 0.000008
2021-07-19 03:12:55,249 epoch 37 - iter 440/443 - loss 0.08438532 - samples/sec: 58.78 - lr: 0.000008
2021-07-19 03:12:56,834 ----------------------------------------------------------------------------------------------------
2021-07-19 03:12:56,834 EPOCH 37 done: loss 0.0840 - lr 0.0000075
2021-07-19 03:13:07,872 DEV : loss 0.16860537230968475 - score 0.9775
2021-07-19 03:13:08,019 BAD EPOCHS (no improvement): 2
2021-07-19 03:13:08,019 ----------------------------------------------------------------------------------------------------
2021-07-19 03:13:31,920 epoch 38 - iter 44/443 - loss 0.08474656 - samples/sec: 58.92 - lr: 0.000008
2021-07-19 03:13:55,862 epoch 38 - iter 88/443 - loss 0.08293941 - samples/sec: 58.81 - lr: 0.000008
2021-07-19 03:14:19,790 epoch 38 - iter 132/443 - loss 0.08601561 - samples/sec: 58.85 - lr: 0.000008
2021-07-19 03:14:43,775 epoch 38 - iter 176/443 - loss 0.08240476 - samples/sec: 58.71 - lr: 0.000008
2021-07-19 03:15:07,736 epoch 38 - iter 220/443 - loss 0.08418245 - samples/sec: 58.77 - lr: 0.000008
2021-07-19 03:15:31,762 epoch 38 - iter 264/443 - loss 0.08178544 - samples/sec: 58.61 - lr: 0.000008
2021-07-19 03:15:55,720 epoch 38 - iter 308/443 - loss 0.08105168 - samples/sec: 58.78 - lr: 0.000008
2021-07-19 03:16:19,670 epoch 38 - iter 352/443 - loss 0.08120768 - samples/sec: 58.80 - lr: 0.000008
2021-07-19 03:16:43,571 epoch 38 - iter 396/443 - loss 0.08109485 - samples/sec: 58.92 - lr: 0.000008
2021-07-19 03:17:07,472 epoch 38 - iter 440/443 - loss 0.08043981 - samples/sec: 58.92 - lr: 0.000008
2021-07-19 03:17:09,038 ----------------------------------------------------------------------------------------------------
2021-07-19 03:17:09,039 EPOCH 38 done: loss 0.0804 - lr 0.0000075
2021-07-19 03:17:20,068 DEV : loss 0.17683342099189758 - score 0.9755
2021-07-19 03:17:20,217 BAD EPOCHS (no improvement): 3
2021-07-19 03:17:20,217 ----------------------------------------------------------------------------------------------------
2021-07-19 03:17:44,176 epoch 39 - iter 44/443 - loss 0.07545261 - samples/sec: 58.77 - lr: 0.000008
2021-07-19 03:18:08,027 epoch 39 - iter 88/443 - loss 0.07856203 - samples/sec: 59.04 - lr: 0.000008
2021-07-19 03:18:31,749 epoch 39 - iter 132/443 - loss 0.07986941 - samples/sec: 59.36 - lr: 0.000008
2021-07-19 03:18:55,616 epoch 39 - iter 176/443 - loss 0.07953472 - samples/sec: 59.00 - lr: 0.000008
2021-07-19 03:19:19,555 epoch 39 - iter 220/443 - loss 0.08001529 - samples/sec: 58.82 - lr: 0.000008
2021-07-19 03:19:43,518 epoch 39 - iter 264/443 - loss 0.07894087 - samples/sec: 58.76 - lr: 0.000008
2021-07-19 03:20:07,362 epoch 39 - iter 308/443 - loss 0.07883863 - samples/sec: 59.06 - lr: 0.000008
2021-07-19 03:20:31,226 epoch 39 - iter 352/443 - loss 0.07872602 - samples/sec: 59.01 - lr: 0.000008
2021-07-19 03:20:55,139 epoch 39 - iter 396/443 - loss 0.08012246 - samples/sec: 58.89 - lr: 0.000008
2021-07-19 03:21:19,023 epoch 39 - iter 440/443 - loss 0.07895187 - samples/sec: 58.96 - lr: 0.000008
2021-07-19 03:21:20,606 ----------------------------------------------------------------------------------------------------
2021-07-19 03:21:20,606 EPOCH 39 done: loss 0.0796 - lr 0.0000075
2021-07-19 03:21:32,893 DEV : loss 0.1702544242143631 - score 0.9769
Epoch    39: reducing learning rate of group 0 to 3.7500e-06.
2021-07-19 03:21:33,041 BAD EPOCHS (no improvement): 4
2021-07-19 03:21:33,041 ----------------------------------------------------------------------------------------------------
2021-07-19 03:21:56,935 epoch 40 - iter 44/443 - loss 0.07331305 - samples/sec: 58.93 - lr: 0.000004
2021-07-19 03:22:20,771 epoch 40 - iter 88/443 - loss 0.07950792 - samples/sec: 59.08 - lr: 0.000004
2021-07-19 03:22:44,690 epoch 40 - iter 132/443 - loss 0.08237934 - samples/sec: 58.87 - lr: 0.000004
2021-07-19 03:23:08,615 epoch 40 - iter 176/443 - loss 0.07952723 - samples/sec: 58.86 - lr: 0.000004
2021-07-19 03:23:32,462 epoch 40 - iter 220/443 - loss 0.08151510 - samples/sec: 59.05 - lr: 0.000004
2021-07-19 03:23:56,324 epoch 40 - iter 264/443 - loss 0.07938328 - samples/sec: 59.01 - lr: 0.000004
2021-07-19 03:24:20,195 epoch 40 - iter 308/443 - loss 0.07931917 - samples/sec: 58.99 - lr: 0.000004
2021-07-19 03:24:44,122 epoch 40 - iter 352/443 - loss 0.07862308 - samples/sec: 58.85 - lr: 0.000004
2021-07-19 03:25:08,033 epoch 40 - iter 396/443 - loss 0.07855360 - samples/sec: 58.89 - lr: 0.000004
2021-07-19 03:25:31,743 epoch 40 - iter 440/443 - loss 0.07836885 - samples/sec: 59.39 - lr: 0.000004
2021-07-19 03:25:33,296 ----------------------------------------------------------------------------------------------------
2021-07-19 03:25:33,296 EPOCH 40 done: loss 0.0783 - lr 0.0000038
2021-07-19 03:25:44,349 DEV : loss 0.1759546548128128 - score 0.9762
2021-07-19 03:25:44,497 BAD EPOCHS (no improvement): 1
2021-07-19 03:25:45,395 ----------------------------------------------------------------------------------------------------
2021-07-19 03:25:45,395 Testing using best model ...
2021-07-19 03:25:45,395 loading file /disk1/shabnam/codes/data/dstrpt/2021-folds/sentencer-2/rus.rst.rrt/best-model.pt
2021-07-19 03:27:08,548 0.9754	0.9770	0.9762
2021-07-19 03:27:08,548 
Results:
- F1-score (micro) 0.9762
- F1-score (macro) 0.9762

By class:
SENT       tp: 3733 - fp: 94 - fn: 88 - precision: 0.9754 - recall: 0.9770 - f1-score: 0.9762
2021-07-19 03:27:08,548 ----------------------------------------------------------------------------------------------------
