/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/por.rst.cstn/
2021-07-22 22:58:05,948 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/por.rst.cstn
2021-07-22 22:58:05,948 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/por.rst.cstn/sent_train.txt
2021-07-22 22:58:05,948 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/por.rst.cstn/sent_dev.txt
2021-07-22 22:58:05,948 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/por.rst.cstn/sent_test.txt
Corpus: 4755 train + 859 dev + 1592 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 22:58:12,285 ----------------------------------------------------------------------------------------------------
2021-07-22 22:58:12,286 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(119547, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 22:58:12,286 ----------------------------------------------------------------------------------------------------
2021-07-22 22:58:12,286 Corpus: "Corpus: 4755 train + 859 dev + 1592 test sentences"
2021-07-22 22:58:12,286 ----------------------------------------------------------------------------------------------------
2021-07-22 22:58:12,287 Parameters:
2021-07-22 22:58:12,287  - learning_rate: "3e-05"
2021-07-22 22:58:12,287  - mini_batch_size: "32"
2021-07-22 22:58:12,287  - patience: "3"
2021-07-22 22:58:12,287  - anneal_factor: "0.5"
2021-07-22 22:58:12,287  - max_epochs: "40"
2021-07-22 22:58:12,287  - shuffle: "True"
2021-07-22 22:58:12,287  - train_with_dev: "False"
2021-07-22 22:58:12,287  - batch_growth_annealing: "False"
2021-07-22 22:58:12,287 ----------------------------------------------------------------------------------------------------
2021-07-22 22:58:12,287 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/por.rst.cstn"
2021-07-22 22:58:12,287 ----------------------------------------------------------------------------------------------------
2021-07-22 22:58:12,287 Device: cuda:0
2021-07-22 22:58:12,287 ----------------------------------------------------------------------------------------------------
2021-07-22 22:58:12,287 Embeddings storage mode: cpu
2021-07-22 22:58:12,289 ----------------------------------------------------------------------------------------------------
2021-07-22 22:58:20,200 epoch 1 - iter 14/149 - loss 14.95526641 - samples/sec: 56.64 - lr: 0.000030
2021-07-22 22:58:28,039 epoch 1 - iter 28/149 - loss 13.07153307 - samples/sec: 57.15 - lr: 0.000030
2021-07-22 22:58:36,142 epoch 1 - iter 42/149 - loss 11.56972144 - samples/sec: 55.29 - lr: 0.000030
2021-07-22 22:58:44,171 epoch 1 - iter 56/149 - loss 10.01839263 - samples/sec: 55.81 - lr: 0.000030
2021-07-22 22:58:52,359 epoch 1 - iter 70/149 - loss 8.71884375 - samples/sec: 54.72 - lr: 0.000030
2021-07-22 22:59:00,658 epoch 1 - iter 84/149 - loss 7.66394819 - samples/sec: 53.98 - lr: 0.000030
2021-07-22 22:59:08,804 epoch 1 - iter 98/149 - loss 6.82646950 - samples/sec: 55.00 - lr: 0.000030
2021-07-22 22:59:16,962 epoch 1 - iter 112/149 - loss 6.15854622 - samples/sec: 54.92 - lr: 0.000030
2021-07-22 22:59:25,131 epoch 1 - iter 126/149 - loss 5.61704269 - samples/sec: 54.85 - lr: 0.000030
2021-07-22 22:59:33,355 epoch 1 - iter 140/149 - loss 5.15555684 - samples/sec: 54.47 - lr: 0.000030
2021-07-22 22:59:38,379 ----------------------------------------------------------------------------------------------------
2021-07-22 22:59:38,380 EPOCH 1 done: loss 4.9004 - lr 0.0000300
2021-07-22 22:59:49,659 DEV : loss 0.7414740920066833 - score 0.7085
2021-07-22 22:59:49,682 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 22:59:50,921 ----------------------------------------------------------------------------------------------------
2021-07-22 22:59:54,256 epoch 2 - iter 14/149 - loss 0.85407036 - samples/sec: 134.41 - lr: 0.000030
2021-07-22 22:59:57,578 epoch 2 - iter 28/149 - loss 0.81504836 - samples/sec: 134.87 - lr: 0.000030
2021-07-22 23:00:00,915 epoch 2 - iter 42/149 - loss 0.76339068 - samples/sec: 134.28 - lr: 0.000030
2021-07-22 23:00:04,144 epoch 2 - iter 56/149 - loss 0.73062429 - samples/sec: 138.79 - lr: 0.000030
2021-07-22 23:00:07,388 epoch 2 - iter 70/149 - loss 0.69473951 - samples/sec: 138.16 - lr: 0.000030
2021-07-22 23:00:10,740 epoch 2 - iter 84/149 - loss 0.65800896 - samples/sec: 133.68 - lr: 0.000030
2021-07-22 23:00:13,905 epoch 2 - iter 98/149 - loss 0.62525074 - samples/sec: 141.62 - lr: 0.000030
2021-07-22 23:00:17,173 epoch 2 - iter 112/149 - loss 0.59530973 - samples/sec: 137.12 - lr: 0.000030
2021-07-22 23:00:20,343 epoch 2 - iter 126/149 - loss 0.57332059 - samples/sec: 141.35 - lr: 0.000030
2021-07-22 23:00:23,556 epoch 2 - iter 140/149 - loss 0.55067183 - samples/sec: 139.49 - lr: 0.000030
2021-07-22 23:00:25,672 ----------------------------------------------------------------------------------------------------
2021-07-22 23:00:25,672 EPOCH 2 done: loss 0.5354 - lr 0.0000300
2021-07-22 23:00:27,739 DEV : loss 0.2204706370830536 - score 0.9612
2021-07-22 23:00:27,762 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:00:35,567 ----------------------------------------------------------------------------------------------------
2021-07-22 23:00:38,838 epoch 3 - iter 14/149 - loss 0.31899518 - samples/sec: 137.06 - lr: 0.000030
2021-07-22 23:00:42,066 epoch 3 - iter 28/149 - loss 0.30426107 - samples/sec: 138.81 - lr: 0.000030
2021-07-22 23:00:45,235 epoch 3 - iter 42/149 - loss 0.29800321 - samples/sec: 141.44 - lr: 0.000030
2021-07-22 23:00:48,532 epoch 3 - iter 56/149 - loss 0.29973831 - samples/sec: 135.90 - lr: 0.000030
2021-07-22 23:00:51,928 epoch 3 - iter 70/149 - loss 0.29380963 - samples/sec: 131.98 - lr: 0.000030
2021-07-22 23:00:55,191 epoch 3 - iter 84/149 - loss 0.28590575 - samples/sec: 137.30 - lr: 0.000030
2021-07-22 23:00:58,354 epoch 3 - iter 98/149 - loss 0.28115598 - samples/sec: 141.70 - lr: 0.000030
2021-07-22 23:01:01,619 epoch 3 - iter 112/149 - loss 0.27388347 - samples/sec: 137.22 - lr: 0.000030
2021-07-22 23:01:04,843 epoch 3 - iter 126/149 - loss 0.26398273 - samples/sec: 139.03 - lr: 0.000030
2021-07-22 23:01:08,116 epoch 3 - iter 140/149 - loss 0.26156578 - samples/sec: 136.89 - lr: 0.000030
2021-07-22 23:01:10,179 ----------------------------------------------------------------------------------------------------
2021-07-22 23:01:10,179 EPOCH 3 done: loss 0.2593 - lr 0.0000300
2021-07-22 23:01:12,384 DEV : loss 0.10282229632139206 - score 0.9806
2021-07-22 23:01:12,411 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:01:17,552 ----------------------------------------------------------------------------------------------------
2021-07-22 23:01:21,045 epoch 4 - iter 14/149 - loss 0.21901039 - samples/sec: 128.37 - lr: 0.000030
2021-07-22 23:01:24,396 epoch 4 - iter 28/149 - loss 0.19023526 - samples/sec: 133.72 - lr: 0.000030
2021-07-22 23:01:27,788 epoch 4 - iter 42/149 - loss 0.19998804 - samples/sec: 132.11 - lr: 0.000030
2021-07-22 23:01:31,115 epoch 4 - iter 56/149 - loss 0.20196178 - samples/sec: 134.68 - lr: 0.000030
2021-07-22 23:01:34,418 epoch 4 - iter 70/149 - loss 0.20182745 - samples/sec: 135.65 - lr: 0.000030
2021-07-22 23:01:37,716 epoch 4 - iter 84/149 - loss 0.19965258 - samples/sec: 135.88 - lr: 0.000030
2021-07-22 23:01:40,903 epoch 4 - iter 98/149 - loss 0.19459675 - samples/sec: 140.64 - lr: 0.000030
2021-07-22 23:01:44,211 epoch 4 - iter 112/149 - loss 0.19099382 - samples/sec: 135.44 - lr: 0.000030
2021-07-22 23:01:47,498 epoch 4 - iter 126/149 - loss 0.19042283 - samples/sec: 136.33 - lr: 0.000030
2021-07-22 23:01:50,852 epoch 4 - iter 140/149 - loss 0.18552392 - samples/sec: 133.62 - lr: 0.000030
2021-07-22 23:01:52,844 ----------------------------------------------------------------------------------------------------
2021-07-22 23:01:52,844 EPOCH 4 done: loss 0.1839 - lr 0.0000300
2021-07-22 23:01:54,894 DEV : loss 0.0701509490609169 - score 0.9868
2021-07-22 23:01:54,917 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:01:59,070 ----------------------------------------------------------------------------------------------------
2021-07-22 23:02:02,428 epoch 5 - iter 14/149 - loss 0.15143523 - samples/sec: 133.55 - lr: 0.000030
2021-07-22 23:02:05,602 epoch 5 - iter 28/149 - loss 0.15435143 - samples/sec: 141.17 - lr: 0.000030
2021-07-22 23:02:08,952 epoch 5 - iter 42/149 - loss 0.14871030 - samples/sec: 133.79 - lr: 0.000030
2021-07-22 23:02:12,198 epoch 5 - iter 56/149 - loss 0.14686181 - samples/sec: 138.05 - lr: 0.000030
2021-07-22 23:02:15,703 epoch 5 - iter 70/149 - loss 0.14876472 - samples/sec: 127.83 - lr: 0.000030
2021-07-22 23:02:19,028 epoch 5 - iter 84/149 - loss 0.14927005 - samples/sec: 134.79 - lr: 0.000030
2021-07-22 23:02:22,185 epoch 5 - iter 98/149 - loss 0.14848597 - samples/sec: 141.96 - lr: 0.000030
2021-07-22 23:02:25,592 epoch 5 - iter 112/149 - loss 0.14800852 - samples/sec: 131.52 - lr: 0.000030
2021-07-22 23:02:28,878 epoch 5 - iter 126/149 - loss 0.14918872 - samples/sec: 136.36 - lr: 0.000030
2021-07-22 23:02:32,136 epoch 5 - iter 140/149 - loss 0.14887273 - samples/sec: 137.55 - lr: 0.000030
2021-07-22 23:02:34,143 ----------------------------------------------------------------------------------------------------
2021-07-22 23:02:34,143 EPOCH 5 done: loss 0.1472 - lr 0.0000300
2021-07-22 23:02:36,193 DEV : loss 0.057355932891368866 - score 0.9886
2021-07-22 23:02:36,216 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:02:40,418 ----------------------------------------------------------------------------------------------------
2021-07-22 23:02:43,762 epoch 6 - iter 14/149 - loss 0.11340519 - samples/sec: 134.09 - lr: 0.000030
2021-07-22 23:02:47,124 epoch 6 - iter 28/149 - loss 0.14216434 - samples/sec: 133.29 - lr: 0.000030
2021-07-22 23:02:50,372 epoch 6 - iter 42/149 - loss 0.13873654 - samples/sec: 137.98 - lr: 0.000030
2021-07-22 23:02:53,676 epoch 6 - iter 56/149 - loss 0.14191267 - samples/sec: 135.63 - lr: 0.000030
2021-07-22 23:02:57,024 epoch 6 - iter 70/149 - loss 0.13985052 - samples/sec: 133.83 - lr: 0.000030
2021-07-22 23:03:00,308 epoch 6 - iter 84/149 - loss 0.13869544 - samples/sec: 136.47 - lr: 0.000030
2021-07-22 23:03:03,824 epoch 6 - iter 98/149 - loss 0.13897976 - samples/sec: 127.46 - lr: 0.000030
2021-07-22 23:03:07,092 epoch 6 - iter 112/149 - loss 0.13666629 - samples/sec: 137.08 - lr: 0.000030
2021-07-22 23:03:10,300 epoch 6 - iter 126/149 - loss 0.13420974 - samples/sec: 139.71 - lr: 0.000030
2021-07-22 23:03:13,542 epoch 6 - iter 140/149 - loss 0.13481147 - samples/sec: 138.23 - lr: 0.000030
2021-07-22 23:03:15,646 ----------------------------------------------------------------------------------------------------
2021-07-22 23:03:15,646 EPOCH 6 done: loss 0.1343 - lr 0.0000300
2021-07-22 23:03:17,690 DEV : loss 0.046136144548654556 - score 0.993
2021-07-22 23:03:17,713 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:03:21,866 ----------------------------------------------------------------------------------------------------
2021-07-22 23:03:25,131 epoch 7 - iter 14/149 - loss 0.10995966 - samples/sec: 137.33 - lr: 0.000030
2021-07-22 23:03:28,380 epoch 7 - iter 28/149 - loss 0.10577918 - samples/sec: 137.90 - lr: 0.000030
2021-07-22 23:03:31,672 epoch 7 - iter 42/149 - loss 0.10552528 - samples/sec: 136.14 - lr: 0.000030
2021-07-22 23:03:34,991 epoch 7 - iter 56/149 - loss 0.11290782 - samples/sec: 135.00 - lr: 0.000030
2021-07-22 23:03:38,392 epoch 7 - iter 70/149 - loss 0.11320612 - samples/sec: 131.78 - lr: 0.000030
2021-07-22 23:03:41,746 epoch 7 - iter 84/149 - loss 0.11111369 - samples/sec: 133.60 - lr: 0.000030
2021-07-22 23:03:44,959 epoch 7 - iter 98/149 - loss 0.11765696 - samples/sec: 139.48 - lr: 0.000030
2021-07-22 23:03:48,291 epoch 7 - iter 112/149 - loss 0.11776323 - samples/sec: 134.47 - lr: 0.000030
2021-07-22 23:03:51,607 epoch 7 - iter 126/149 - loss 0.11914303 - samples/sec: 135.18 - lr: 0.000030
2021-07-22 23:03:54,932 epoch 7 - iter 140/149 - loss 0.11804308 - samples/sec: 134.74 - lr: 0.000030
2021-07-22 23:03:57,052 ----------------------------------------------------------------------------------------------------
2021-07-22 23:03:57,052 EPOCH 7 done: loss 0.1167 - lr 0.0000300
2021-07-22 23:03:59,110 DEV : loss 0.044119685888290405 - score 0.9921
2021-07-22 23:03:59,133 BAD EPOCHS (no improvement): 1
2021-07-22 23:03:59,133 ----------------------------------------------------------------------------------------------------
2021-07-22 23:04:02,486 epoch 8 - iter 14/149 - loss 0.09934001 - samples/sec: 133.71 - lr: 0.000030
2021-07-22 23:04:05,668 epoch 8 - iter 28/149 - loss 0.10076910 - samples/sec: 140.80 - lr: 0.000030
2021-07-22 23:04:08,971 epoch 8 - iter 42/149 - loss 0.10015378 - samples/sec: 135.69 - lr: 0.000030
2021-07-22 23:04:12,305 epoch 8 - iter 56/149 - loss 0.10504387 - samples/sec: 134.41 - lr: 0.000030
2021-07-22 23:04:15,567 epoch 8 - iter 70/149 - loss 0.10752988 - samples/sec: 137.36 - lr: 0.000030
2021-07-22 23:04:18,984 epoch 8 - iter 84/149 - loss 0.10928996 - samples/sec: 131.15 - lr: 0.000030
2021-07-22 23:04:22,259 epoch 8 - iter 98/149 - loss 0.10961101 - samples/sec: 136.83 - lr: 0.000030
2021-07-22 23:04:25,615 epoch 8 - iter 112/149 - loss 0.10953478 - samples/sec: 133.52 - lr: 0.000030
2021-07-22 23:04:28,976 epoch 8 - iter 126/149 - loss 0.10764955 - samples/sec: 133.33 - lr: 0.000030
2021-07-22 23:04:32,308 epoch 8 - iter 140/149 - loss 0.10807251 - samples/sec: 134.51 - lr: 0.000030
2021-07-22 23:04:34,331 ----------------------------------------------------------------------------------------------------
2021-07-22 23:04:34,331 EPOCH 8 done: loss 0.1101 - lr 0.0000300
2021-07-22 23:04:36,377 DEV : loss 0.035511720925569534 - score 0.9912
2021-07-22 23:04:36,400 BAD EPOCHS (no improvement): 2
2021-07-22 23:04:36,400 ----------------------------------------------------------------------------------------------------
2021-07-22 23:04:39,892 epoch 9 - iter 14/149 - loss 0.10187696 - samples/sec: 128.35 - lr: 0.000030
2021-07-22 23:04:43,275 epoch 9 - iter 28/149 - loss 0.10937591 - samples/sec: 132.47 - lr: 0.000030
2021-07-22 23:04:46,603 epoch 9 - iter 42/149 - loss 0.11098353 - samples/sec: 134.68 - lr: 0.000030
2021-07-22 23:04:49,768 epoch 9 - iter 56/149 - loss 0.10240029 - samples/sec: 141.57 - lr: 0.000030
2021-07-22 23:04:53,030 epoch 9 - iter 70/149 - loss 0.10188635 - samples/sec: 137.40 - lr: 0.000030
2021-07-22 23:04:56,353 epoch 9 - iter 84/149 - loss 0.10381651 - samples/sec: 134.86 - lr: 0.000030
2021-07-22 23:04:59,550 epoch 9 - iter 98/149 - loss 0.10451337 - samples/sec: 140.15 - lr: 0.000030
2021-07-22 23:05:02,863 epoch 9 - iter 112/149 - loss 0.10260700 - samples/sec: 135.26 - lr: 0.000030
2021-07-22 23:05:06,176 epoch 9 - iter 126/149 - loss 0.10328868 - samples/sec: 135.26 - lr: 0.000030
2021-07-22 23:05:09,460 epoch 9 - iter 140/149 - loss 0.10662186 - samples/sec: 136.46 - lr: 0.000030
2021-07-22 23:05:11,504 ----------------------------------------------------------------------------------------------------
2021-07-22 23:05:11,504 EPOCH 9 done: loss 0.1050 - lr 0.0000300
2021-07-22 23:05:13,563 DEV : loss 0.03571832925081253 - score 0.993
2021-07-22 23:05:13,587 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:05:17,682 ----------------------------------------------------------------------------------------------------
2021-07-22 23:05:21,093 epoch 10 - iter 14/149 - loss 0.07905403 - samples/sec: 131.44 - lr: 0.000030
2021-07-22 23:05:24,407 epoch 10 - iter 28/149 - loss 0.08674666 - samples/sec: 135.21 - lr: 0.000030
2021-07-22 23:05:27,611 epoch 10 - iter 42/149 - loss 0.09333999 - samples/sec: 139.87 - lr: 0.000030
2021-07-22 23:05:30,851 epoch 10 - iter 56/149 - loss 0.09774865 - samples/sec: 138.32 - lr: 0.000030
2021-07-22 23:05:34,259 epoch 10 - iter 70/149 - loss 0.09747565 - samples/sec: 131.49 - lr: 0.000030
2021-07-22 23:05:37,563 epoch 10 - iter 84/149 - loss 0.09493392 - samples/sec: 135.63 - lr: 0.000030
2021-07-22 23:05:40,843 epoch 10 - iter 98/149 - loss 0.09499171 - samples/sec: 136.63 - lr: 0.000030
2021-07-22 23:05:44,028 epoch 10 - iter 112/149 - loss 0.09626188 - samples/sec: 140.69 - lr: 0.000030
2021-07-22 23:05:47,368 epoch 10 - iter 126/149 - loss 0.09490870 - samples/sec: 134.18 - lr: 0.000030
2021-07-22 23:05:50,640 epoch 10 - iter 140/149 - loss 0.09379979 - samples/sec: 136.94 - lr: 0.000030
2021-07-22 23:05:52,722 ----------------------------------------------------------------------------------------------------
2021-07-22 23:05:52,723 EPOCH 10 done: loss 0.0957 - lr 0.0000300
2021-07-22 23:05:54,785 DEV : loss 0.030530091375112534 - score 0.9904
2021-07-22 23:05:54,808 BAD EPOCHS (no improvement): 1
2021-07-22 23:05:54,808 ----------------------------------------------------------------------------------------------------
2021-07-22 23:05:58,142 epoch 11 - iter 14/149 - loss 0.11836084 - samples/sec: 134.45 - lr: 0.000030
2021-07-22 23:06:01,364 epoch 11 - iter 28/149 - loss 0.11664631 - samples/sec: 139.11 - lr: 0.000030
2021-07-22 23:06:04,680 epoch 11 - iter 42/149 - loss 0.10913399 - samples/sec: 135.14 - lr: 0.000030
2021-07-22 23:06:07,892 epoch 11 - iter 56/149 - loss 0.10300654 - samples/sec: 139.51 - lr: 0.000030
2021-07-22 23:06:11,177 epoch 11 - iter 70/149 - loss 0.10047933 - samples/sec: 136.42 - lr: 0.000030
2021-07-22 23:06:14,492 epoch 11 - iter 84/149 - loss 0.10046957 - samples/sec: 135.17 - lr: 0.000030
2021-07-22 23:06:17,766 epoch 11 - iter 98/149 - loss 0.09793659 - samples/sec: 136.85 - lr: 0.000030
2021-07-22 23:06:20,948 epoch 11 - iter 112/149 - loss 0.09754158 - samples/sec: 140.84 - lr: 0.000030
2021-07-22 23:06:24,424 epoch 11 - iter 126/149 - loss 0.09960581 - samples/sec: 128.92 - lr: 0.000030
2021-07-22 23:06:27,776 epoch 11 - iter 140/149 - loss 0.09905674 - samples/sec: 133.68 - lr: 0.000030
2021-07-22 23:06:29,860 ----------------------------------------------------------------------------------------------------
2021-07-22 23:06:29,860 EPOCH 11 done: loss 0.0996 - lr 0.0000300
2021-07-22 23:06:31,922 DEV : loss 0.03668232262134552 - score 0.9921
2021-07-22 23:06:31,946 BAD EPOCHS (no improvement): 2
2021-07-22 23:06:31,946 ----------------------------------------------------------------------------------------------------
2021-07-22 23:06:35,333 epoch 12 - iter 14/149 - loss 0.10373135 - samples/sec: 132.34 - lr: 0.000030
2021-07-22 23:06:38,575 epoch 12 - iter 28/149 - loss 0.10486900 - samples/sec: 138.23 - lr: 0.000030
2021-07-22 23:06:41,871 epoch 12 - iter 42/149 - loss 0.09922761 - samples/sec: 135.97 - lr: 0.000030
2021-07-22 23:06:45,172 epoch 12 - iter 56/149 - loss 0.10234680 - samples/sec: 135.74 - lr: 0.000030
2021-07-22 23:06:48,495 epoch 12 - iter 70/149 - loss 0.09532672 - samples/sec: 134.88 - lr: 0.000030
2021-07-22 23:06:51,823 epoch 12 - iter 84/149 - loss 0.09740083 - samples/sec: 134.65 - lr: 0.000030
2021-07-22 23:06:55,020 epoch 12 - iter 98/149 - loss 0.09661816 - samples/sec: 140.16 - lr: 0.000030
2021-07-22 23:06:58,280 epoch 12 - iter 112/149 - loss 0.09483570 - samples/sec: 137.46 - lr: 0.000030
2021-07-22 23:07:01,628 epoch 12 - iter 126/149 - loss 0.09647900 - samples/sec: 133.85 - lr: 0.000030
2021-07-22 23:07:05,043 epoch 12 - iter 140/149 - loss 0.09589420 - samples/sec: 131.21 - lr: 0.000030
2021-07-22 23:07:07,015 ----------------------------------------------------------------------------------------------------
2021-07-22 23:07:07,015 EPOCH 12 done: loss 0.0950 - lr 0.0000300
2021-07-22 23:07:09,077 DEV : loss 0.029124680906534195 - score 0.993
2021-07-22 23:07:09,100 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:07:13,510 ----------------------------------------------------------------------------------------------------
2021-07-22 23:07:16,704 epoch 13 - iter 14/149 - loss 0.09265027 - samples/sec: 140.35 - lr: 0.000030
2021-07-22 23:07:20,071 epoch 13 - iter 28/149 - loss 0.07899795 - samples/sec: 133.10 - lr: 0.000030
2021-07-22 23:07:23,372 epoch 13 - iter 42/149 - loss 0.08389762 - samples/sec: 135.77 - lr: 0.000030
2021-07-22 23:07:26,784 epoch 13 - iter 56/149 - loss 0.08496809 - samples/sec: 131.33 - lr: 0.000030
2021-07-22 23:07:30,040 epoch 13 - iter 70/149 - loss 0.08714178 - samples/sec: 137.63 - lr: 0.000030
2021-07-22 23:07:33,264 epoch 13 - iter 84/149 - loss 0.08565470 - samples/sec: 139.00 - lr: 0.000030
2021-07-22 23:07:36,610 epoch 13 - iter 98/149 - loss 0.08431859 - samples/sec: 133.90 - lr: 0.000030
2021-07-22 23:07:39,910 epoch 13 - iter 112/149 - loss 0.08284046 - samples/sec: 135.78 - lr: 0.000030
2021-07-22 23:07:43,136 epoch 13 - iter 126/149 - loss 0.08261167 - samples/sec: 138.93 - lr: 0.000030
2021-07-22 23:07:46,544 epoch 13 - iter 140/149 - loss 0.08429539 - samples/sec: 131.50 - lr: 0.000030
2021-07-22 23:07:48,632 ----------------------------------------------------------------------------------------------------
2021-07-22 23:07:48,633 EPOCH 13 done: loss 0.0846 - lr 0.0000300
2021-07-22 23:07:50,694 DEV : loss 0.03235961124300957 - score 0.993
2021-07-22 23:07:50,718 BAD EPOCHS (no improvement): 1
2021-07-22 23:07:50,718 ----------------------------------------------------------------------------------------------------
2021-07-22 23:07:54,144 epoch 14 - iter 14/149 - loss 0.07148714 - samples/sec: 130.85 - lr: 0.000030
2021-07-22 23:07:57,511 epoch 14 - iter 28/149 - loss 0.07196938 - samples/sec: 133.06 - lr: 0.000030
2021-07-22 23:08:00,822 epoch 14 - iter 42/149 - loss 0.07023928 - samples/sec: 135.33 - lr: 0.000030
2021-07-22 23:08:04,024 epoch 14 - iter 56/149 - loss 0.07601007 - samples/sec: 139.99 - lr: 0.000030
2021-07-22 23:08:07,341 epoch 14 - iter 70/149 - loss 0.07728955 - samples/sec: 135.09 - lr: 0.000030
2021-07-22 23:08:10,704 epoch 14 - iter 84/149 - loss 0.07839941 - samples/sec: 133.25 - lr: 0.000030
2021-07-22 23:08:14,087 epoch 14 - iter 98/149 - loss 0.08064363 - samples/sec: 132.43 - lr: 0.000030
2021-07-22 23:08:17,379 epoch 14 - iter 112/149 - loss 0.08542843 - samples/sec: 136.16 - lr: 0.000030
2021-07-22 23:08:20,768 epoch 14 - iter 126/149 - loss 0.08394068 - samples/sec: 132.23 - lr: 0.000030
2021-07-22 23:08:24,000 epoch 14 - iter 140/149 - loss 0.08168057 - samples/sec: 138.64 - lr: 0.000030
2021-07-22 23:08:26,006 ----------------------------------------------------------------------------------------------------
2021-07-22 23:08:26,006 EPOCH 14 done: loss 0.0806 - lr 0.0000300
2021-07-22 23:08:28,059 DEV : loss 0.02799888700246811 - score 0.993
2021-07-22 23:08:28,082 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:08:32,491 ----------------------------------------------------------------------------------------------------
2021-07-22 23:08:35,835 epoch 15 - iter 14/149 - loss 0.06792936 - samples/sec: 134.06 - lr: 0.000030
2021-07-22 23:08:39,140 epoch 15 - iter 28/149 - loss 0.08329128 - samples/sec: 135.59 - lr: 0.000030
2021-07-22 23:08:42,441 epoch 15 - iter 42/149 - loss 0.07305313 - samples/sec: 135.78 - lr: 0.000030
2021-07-22 23:08:45,771 epoch 15 - iter 56/149 - loss 0.07698630 - samples/sec: 134.56 - lr: 0.000030
2021-07-22 23:08:48,912 epoch 15 - iter 70/149 - loss 0.08093934 - samples/sec: 142.68 - lr: 0.000030
2021-07-22 23:08:52,212 epoch 15 - iter 84/149 - loss 0.07992226 - samples/sec: 135.80 - lr: 0.000030
2021-07-22 23:08:55,575 epoch 15 - iter 98/149 - loss 0.08221455 - samples/sec: 133.22 - lr: 0.000030
2021-07-22 23:08:58,955 epoch 15 - iter 112/149 - loss 0.08272006 - samples/sec: 132.59 - lr: 0.000030
2021-07-22 23:09:02,341 epoch 15 - iter 126/149 - loss 0.08373358 - samples/sec: 132.34 - lr: 0.000030
2021-07-22 23:09:05,732 epoch 15 - iter 140/149 - loss 0.08322205 - samples/sec: 132.14 - lr: 0.000030
2021-07-22 23:09:07,743 ----------------------------------------------------------------------------------------------------
2021-07-22 23:09:07,743 EPOCH 15 done: loss 0.0819 - lr 0.0000300
2021-07-22 23:09:09,793 DEV : loss 0.027661284431815147 - score 0.9939
2021-07-22 23:09:09,816 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:09:13,691 ----------------------------------------------------------------------------------------------------
2021-07-22 23:09:17,113 epoch 16 - iter 14/149 - loss 0.08080488 - samples/sec: 131.04 - lr: 0.000030
2021-07-22 23:09:20,423 epoch 16 - iter 28/149 - loss 0.07542615 - samples/sec: 135.38 - lr: 0.000030
2021-07-22 23:09:23,696 epoch 16 - iter 42/149 - loss 0.08465744 - samples/sec: 136.91 - lr: 0.000030
2021-07-22 23:09:26,992 epoch 16 - iter 56/149 - loss 0.08396055 - samples/sec: 135.96 - lr: 0.000030
2021-07-22 23:09:30,252 epoch 16 - iter 70/149 - loss 0.08015315 - samples/sec: 137.46 - lr: 0.000030
2021-07-22 23:09:33,604 epoch 16 - iter 84/149 - loss 0.07798343 - samples/sec: 133.68 - lr: 0.000030
2021-07-22 23:09:36,855 epoch 16 - iter 98/149 - loss 0.07864300 - samples/sec: 137.84 - lr: 0.000030
2021-07-22 23:09:40,223 epoch 16 - iter 112/149 - loss 0.08018651 - samples/sec: 133.04 - lr: 0.000030
2021-07-22 23:09:43,523 epoch 16 - iter 126/149 - loss 0.07799591 - samples/sec: 135.79 - lr: 0.000030
2021-07-22 23:09:46,855 epoch 16 - iter 140/149 - loss 0.07703603 - samples/sec: 134.50 - lr: 0.000030
2021-07-22 23:09:48,963 ----------------------------------------------------------------------------------------------------
2021-07-22 23:09:48,963 EPOCH 16 done: loss 0.0782 - lr 0.0000300
2021-07-22 23:09:51,013 DEV : loss 0.026256872341036797 - score 0.9939
2021-07-22 23:09:51,037 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:09:55,513 ----------------------------------------------------------------------------------------------------
2021-07-22 23:09:58,950 epoch 17 - iter 14/149 - loss 0.08164790 - samples/sec: 130.42 - lr: 0.000030
2021-07-22 23:10:02,257 epoch 17 - iter 28/149 - loss 0.07454362 - samples/sec: 135.51 - lr: 0.000030
2021-07-22 23:10:05,484 epoch 17 - iter 42/149 - loss 0.07371289 - samples/sec: 138.90 - lr: 0.000030
2021-07-22 23:10:08,791 epoch 17 - iter 56/149 - loss 0.07414758 - samples/sec: 135.49 - lr: 0.000030
2021-07-22 23:10:11,891 epoch 17 - iter 70/149 - loss 0.06976166 - samples/sec: 144.57 - lr: 0.000030
2021-07-22 23:10:15,048 epoch 17 - iter 84/149 - loss 0.07066995 - samples/sec: 141.94 - lr: 0.000030
2021-07-22 23:10:18,255 epoch 17 - iter 98/149 - loss 0.07194999 - samples/sec: 139.74 - lr: 0.000030
2021-07-22 23:10:21,415 epoch 17 - iter 112/149 - loss 0.07603402 - samples/sec: 141.78 - lr: 0.000030
2021-07-22 23:10:24,799 epoch 17 - iter 126/149 - loss 0.07513439 - samples/sec: 132.42 - lr: 0.000030
2021-07-22 23:10:28,243 epoch 17 - iter 140/149 - loss 0.07499974 - samples/sec: 130.12 - lr: 0.000030
2021-07-22 23:10:30,351 ----------------------------------------------------------------------------------------------------
2021-07-22 23:10:30,351 EPOCH 17 done: loss 0.0780 - lr 0.0000300
2021-07-22 23:10:32,421 DEV : loss 0.027984069660305977 - score 0.9921
2021-07-22 23:10:32,444 BAD EPOCHS (no improvement): 1
2021-07-22 23:10:32,444 ----------------------------------------------------------------------------------------------------
2021-07-22 23:10:35,691 epoch 18 - iter 14/149 - loss 0.08007718 - samples/sec: 138.04 - lr: 0.000030
2021-07-22 23:10:38,865 epoch 18 - iter 28/149 - loss 0.08466554 - samples/sec: 141.21 - lr: 0.000030
2021-07-22 23:10:42,143 epoch 18 - iter 42/149 - loss 0.08486785 - samples/sec: 136.73 - lr: 0.000030
2021-07-22 23:10:45,383 epoch 18 - iter 56/149 - loss 0.08427553 - samples/sec: 138.31 - lr: 0.000030
2021-07-22 23:10:48,656 epoch 18 - iter 70/149 - loss 0.08233110 - samples/sec: 136.88 - lr: 0.000030
2021-07-22 23:10:51,992 epoch 18 - iter 84/149 - loss 0.08157056 - samples/sec: 134.33 - lr: 0.000030
2021-07-22 23:10:55,311 epoch 18 - iter 98/149 - loss 0.07933615 - samples/sec: 135.04 - lr: 0.000030
2021-07-22 23:10:58,619 epoch 18 - iter 112/149 - loss 0.07693576 - samples/sec: 135.46 - lr: 0.000030
2021-07-22 23:11:02,049 epoch 18 - iter 126/149 - loss 0.07815047 - samples/sec: 130.63 - lr: 0.000030
2021-07-22 23:11:05,519 epoch 18 - iter 140/149 - loss 0.07730484 - samples/sec: 129.14 - lr: 0.000030
2021-07-22 23:11:07,547 ----------------------------------------------------------------------------------------------------
2021-07-22 23:11:07,547 EPOCH 18 done: loss 0.0771 - lr 0.0000300
2021-07-22 23:11:09,602 DEV : loss 0.024891706183552742 - score 0.993
2021-07-22 23:11:09,626 BAD EPOCHS (no improvement): 2
2021-07-22 23:11:09,626 ----------------------------------------------------------------------------------------------------
2021-07-22 23:11:13,090 epoch 19 - iter 14/149 - loss 0.08414024 - samples/sec: 129.39 - lr: 0.000030
2021-07-22 23:11:16,438 epoch 19 - iter 28/149 - loss 0.08393208 - samples/sec: 133.86 - lr: 0.000030
2021-07-22 23:11:19,680 epoch 19 - iter 42/149 - loss 0.07559854 - samples/sec: 138.24 - lr: 0.000030
2021-07-22 23:11:23,076 epoch 19 - iter 56/149 - loss 0.07117055 - samples/sec: 131.93 - lr: 0.000030
2021-07-22 23:11:26,247 epoch 19 - iter 70/149 - loss 0.06920240 - samples/sec: 141.35 - lr: 0.000030
2021-07-22 23:11:29,575 epoch 19 - iter 84/149 - loss 0.07040852 - samples/sec: 134.65 - lr: 0.000030
2021-07-22 23:11:32,784 epoch 19 - iter 98/149 - loss 0.06964872 - samples/sec: 139.64 - lr: 0.000030
2021-07-22 23:11:36,227 epoch 19 - iter 112/149 - loss 0.07009071 - samples/sec: 130.13 - lr: 0.000030
2021-07-22 23:11:39,490 epoch 19 - iter 126/149 - loss 0.07287498 - samples/sec: 137.33 - lr: 0.000030
2021-07-22 23:11:42,779 epoch 19 - iter 140/149 - loss 0.07132724 - samples/sec: 136.26 - lr: 0.000030
2021-07-22 23:11:45,040 ----------------------------------------------------------------------------------------------------
2021-07-22 23:11:45,040 EPOCH 19 done: loss 0.0710 - lr 0.0000300
2021-07-22 23:11:47,091 DEV : loss 0.02689356543123722 - score 0.9939
2021-07-22 23:11:47,114 BAD EPOCHS (no improvement): 3
2021-07-22 23:11:47,115 ----------------------------------------------------------------------------------------------------
2021-07-22 23:11:50,511 epoch 20 - iter 14/149 - loss 0.07193257 - samples/sec: 131.98 - lr: 0.000030
2021-07-22 23:11:53,908 epoch 20 - iter 28/149 - loss 0.07520443 - samples/sec: 131.90 - lr: 0.000030
2021-07-22 23:11:57,123 epoch 20 - iter 42/149 - loss 0.07723418 - samples/sec: 139.40 - lr: 0.000030
2021-07-22 23:12:00,544 epoch 20 - iter 56/149 - loss 0.08000355 - samples/sec: 131.01 - lr: 0.000030
2021-07-22 23:12:03,867 epoch 20 - iter 70/149 - loss 0.08027484 - samples/sec: 134.85 - lr: 0.000030
2021-07-22 23:12:07,164 epoch 20 - iter 84/149 - loss 0.07683936 - samples/sec: 135.90 - lr: 0.000030
2021-07-22 23:12:10,344 epoch 20 - iter 98/149 - loss 0.07633699 - samples/sec: 140.92 - lr: 0.000030
2021-07-22 23:12:13,683 epoch 20 - iter 112/149 - loss 0.07915540 - samples/sec: 134.20 - lr: 0.000030
2021-07-22 23:12:16,993 epoch 20 - iter 126/149 - loss 0.07853535 - samples/sec: 135.42 - lr: 0.000030
2021-07-22 23:12:20,330 epoch 20 - iter 140/149 - loss 0.07700325 - samples/sec: 134.25 - lr: 0.000030
2021-07-22 23:12:22,360 ----------------------------------------------------------------------------------------------------
2021-07-22 23:12:22,360 EPOCH 20 done: loss 0.0776 - lr 0.0000300
2021-07-22 23:12:24,406 DEV : loss 0.028592396527528763 - score 0.9921
Epoch    20: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 23:12:24,429 BAD EPOCHS (no improvement): 4
2021-07-22 23:12:24,429 ----------------------------------------------------------------------------------------------------
2021-07-22 23:12:27,753 epoch 21 - iter 14/149 - loss 0.07353159 - samples/sec: 134.88 - lr: 0.000015
2021-07-22 23:12:31,157 epoch 21 - iter 28/149 - loss 0.07440555 - samples/sec: 131.65 - lr: 0.000015
2021-07-22 23:12:34,528 epoch 21 - iter 42/149 - loss 0.06946720 - samples/sec: 132.93 - lr: 0.000015
2021-07-22 23:12:37,859 epoch 21 - iter 56/149 - loss 0.06909884 - samples/sec: 134.51 - lr: 0.000015
2021-07-22 23:12:41,192 epoch 21 - iter 70/149 - loss 0.06852378 - samples/sec: 134.45 - lr: 0.000015
2021-07-22 23:12:44,545 epoch 21 - iter 84/149 - loss 0.07341949 - samples/sec: 133.64 - lr: 0.000015
2021-07-22 23:12:47,771 epoch 21 - iter 98/149 - loss 0.06961254 - samples/sec: 138.93 - lr: 0.000015
2021-07-22 23:12:51,036 epoch 21 - iter 112/149 - loss 0.06934604 - samples/sec: 137.24 - lr: 0.000015
2021-07-22 23:12:54,333 epoch 21 - iter 126/149 - loss 0.06889331 - samples/sec: 135.94 - lr: 0.000015
2021-07-22 23:12:57,623 epoch 21 - iter 140/149 - loss 0.06942643 - samples/sec: 136.18 - lr: 0.000015
2021-07-22 23:12:59,672 ----------------------------------------------------------------------------------------------------
2021-07-22 23:12:59,673 EPOCH 21 done: loss 0.0693 - lr 0.0000150
2021-07-22 23:13:01,726 DEV : loss 0.027891753241419792 - score 0.9921
2021-07-22 23:13:01,749 BAD EPOCHS (no improvement): 1
2021-07-22 23:13:01,750 ----------------------------------------------------------------------------------------------------
2021-07-22 23:13:04,976 epoch 22 - iter 14/149 - loss 0.09066918 - samples/sec: 138.94 - lr: 0.000015
2021-07-22 23:13:08,254 epoch 22 - iter 28/149 - loss 0.08441606 - samples/sec: 136.70 - lr: 0.000015
2021-07-22 23:13:11,540 epoch 22 - iter 42/149 - loss 0.07217548 - samples/sec: 136.40 - lr: 0.000015
2021-07-22 23:13:14,752 epoch 22 - iter 56/149 - loss 0.07365826 - samples/sec: 139.48 - lr: 0.000015
2021-07-22 23:13:18,084 epoch 22 - iter 70/149 - loss 0.07760897 - samples/sec: 134.49 - lr: 0.000015
2021-07-22 23:13:21,347 epoch 22 - iter 84/149 - loss 0.07723984 - samples/sec: 137.33 - lr: 0.000015
2021-07-22 23:13:24,748 epoch 22 - iter 98/149 - loss 0.07873253 - samples/sec: 131.77 - lr: 0.000015
2021-07-22 23:13:28,238 epoch 22 - iter 112/149 - loss 0.07994309 - samples/sec: 128.39 - lr: 0.000015
2021-07-22 23:13:31,531 epoch 22 - iter 126/149 - loss 0.07707025 - samples/sec: 136.10 - lr: 0.000015
2021-07-22 23:13:34,899 epoch 22 - iter 140/149 - loss 0.07655562 - samples/sec: 133.02 - lr: 0.000015
2021-07-22 23:13:36,916 ----------------------------------------------------------------------------------------------------
2021-07-22 23:13:36,916 EPOCH 22 done: loss 0.0765 - lr 0.0000150
2021-07-22 23:13:38,979 DEV : loss 0.028005847707390785 - score 0.993
2021-07-22 23:13:39,003 BAD EPOCHS (no improvement): 2
2021-07-22 23:13:39,003 ----------------------------------------------------------------------------------------------------
2021-07-22 23:13:42,418 epoch 23 - iter 14/149 - loss 0.05707807 - samples/sec: 131.26 - lr: 0.000015
2021-07-22 23:13:45,695 epoch 23 - iter 28/149 - loss 0.05573542 - samples/sec: 136.74 - lr: 0.000015
2021-07-22 23:13:49,027 epoch 23 - iter 42/149 - loss 0.06784400 - samples/sec: 134.48 - lr: 0.000015
2021-07-22 23:13:52,222 epoch 23 - iter 56/149 - loss 0.06685937 - samples/sec: 140.27 - lr: 0.000015
2021-07-22 23:13:55,456 epoch 23 - iter 70/149 - loss 0.07363828 - samples/sec: 138.56 - lr: 0.000015
2021-07-22 23:13:58,751 epoch 23 - iter 84/149 - loss 0.07433710 - samples/sec: 136.02 - lr: 0.000015
2021-07-22 23:14:02,099 epoch 23 - iter 98/149 - loss 0.07359475 - samples/sec: 133.81 - lr: 0.000015
2021-07-22 23:14:05,380 epoch 23 - iter 112/149 - loss 0.06975932 - samples/sec: 136.59 - lr: 0.000015
2021-07-22 23:14:08,723 epoch 23 - iter 126/149 - loss 0.06997989 - samples/sec: 134.05 - lr: 0.000015
2021-07-22 23:14:12,076 epoch 23 - iter 140/149 - loss 0.06707466 - samples/sec: 133.64 - lr: 0.000015
2021-07-22 23:14:14,048 ----------------------------------------------------------------------------------------------------
2021-07-22 23:14:14,048 EPOCH 23 done: loss 0.0669 - lr 0.0000150
2021-07-22 23:14:16,106 DEV : loss 0.025699470192193985 - score 0.9939
2021-07-22 23:14:16,129 BAD EPOCHS (no improvement): 3
2021-07-22 23:14:16,129 ----------------------------------------------------------------------------------------------------
2021-07-22 23:14:19,522 epoch 24 - iter 14/149 - loss 0.08344910 - samples/sec: 132.12 - lr: 0.000015
2021-07-22 23:14:22,757 epoch 24 - iter 28/149 - loss 0.08742508 - samples/sec: 138.55 - lr: 0.000015
2021-07-22 23:14:26,040 epoch 24 - iter 42/149 - loss 0.08010226 - samples/sec: 136.48 - lr: 0.000015
2021-07-22 23:14:29,344 epoch 24 - iter 56/149 - loss 0.07503942 - samples/sec: 135.61 - lr: 0.000015
2021-07-22 23:14:32,696 epoch 24 - iter 70/149 - loss 0.07368243 - samples/sec: 133.68 - lr: 0.000015
2021-07-22 23:14:35,967 epoch 24 - iter 84/149 - loss 0.07327461 - samples/sec: 137.04 - lr: 0.000015
2021-07-22 23:14:39,179 epoch 24 - iter 98/149 - loss 0.07102032 - samples/sec: 139.48 - lr: 0.000015
2021-07-22 23:14:42,398 epoch 24 - iter 112/149 - loss 0.07091529 - samples/sec: 139.21 - lr: 0.000015
2021-07-22 23:14:45,804 epoch 24 - iter 126/149 - loss 0.07024602 - samples/sec: 131.57 - lr: 0.000015
2021-07-22 23:14:49,186 epoch 24 - iter 140/149 - loss 0.06963621 - samples/sec: 132.49 - lr: 0.000015
2021-07-22 23:14:51,228 ----------------------------------------------------------------------------------------------------
2021-07-22 23:14:51,228 EPOCH 24 done: loss 0.0697 - lr 0.0000150
2021-07-22 23:14:53,274 DEV : loss 0.0293593630194664 - score 0.9921
Epoch    24: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 23:14:53,297 BAD EPOCHS (no improvement): 4
2021-07-22 23:14:53,298 ----------------------------------------------------------------------------------------------------
2021-07-22 23:14:56,595 epoch 25 - iter 14/149 - loss 0.06597288 - samples/sec: 135.96 - lr: 0.000008
2021-07-22 23:14:59,935 epoch 25 - iter 28/149 - loss 0.06170368 - samples/sec: 134.15 - lr: 0.000008
2021-07-22 23:15:03,151 epoch 25 - iter 42/149 - loss 0.06563460 - samples/sec: 139.37 - lr: 0.000008
2021-07-22 23:15:06,548 epoch 25 - iter 56/149 - loss 0.06824769 - samples/sec: 131.91 - lr: 0.000008
2021-07-22 23:15:09,811 epoch 25 - iter 70/149 - loss 0.06913265 - samples/sec: 137.31 - lr: 0.000008
2021-07-22 23:15:13,049 epoch 25 - iter 84/149 - loss 0.06710648 - samples/sec: 138.41 - lr: 0.000008
2021-07-22 23:15:16,263 epoch 25 - iter 98/149 - loss 0.06632576 - samples/sec: 139.44 - lr: 0.000008
2021-07-22 23:15:19,437 epoch 25 - iter 112/149 - loss 0.06286338 - samples/sec: 141.16 - lr: 0.000008
2021-07-22 23:15:22,828 epoch 25 - iter 126/149 - loss 0.06079600 - samples/sec: 132.15 - lr: 0.000008
2021-07-22 23:15:26,027 epoch 25 - iter 140/149 - loss 0.05983265 - samples/sec: 140.08 - lr: 0.000008
2021-07-22 23:15:28,034 ----------------------------------------------------------------------------------------------------
2021-07-22 23:15:28,035 EPOCH 25 done: loss 0.0596 - lr 0.0000075
2021-07-22 23:15:30,083 DEV : loss 0.02498752623796463 - score 0.993
2021-07-22 23:15:30,106 BAD EPOCHS (no improvement): 1
2021-07-22 23:15:30,107 ----------------------------------------------------------------------------------------------------
2021-07-22 23:15:33,407 epoch 26 - iter 14/149 - loss 0.06041078 - samples/sec: 135.81 - lr: 0.000008
2021-07-22 23:15:36,646 epoch 26 - iter 28/149 - loss 0.06011443 - samples/sec: 138.35 - lr: 0.000008
2021-07-22 23:15:39,987 epoch 26 - iter 42/149 - loss 0.06021997 - samples/sec: 134.14 - lr: 0.000008
2021-07-22 23:15:43,251 epoch 26 - iter 56/149 - loss 0.06543079 - samples/sec: 137.30 - lr: 0.000008
2021-07-22 23:15:46,543 epoch 26 - iter 70/149 - loss 0.06910505 - samples/sec: 136.14 - lr: 0.000008
2021-07-22 23:15:49,716 epoch 26 - iter 84/149 - loss 0.06940767 - samples/sec: 141.21 - lr: 0.000008
2021-07-22 23:15:53,003 epoch 26 - iter 98/149 - loss 0.06896272 - samples/sec: 136.33 - lr: 0.000008
2021-07-22 23:15:56,367 epoch 26 - iter 112/149 - loss 0.06817784 - samples/sec: 133.22 - lr: 0.000008
2021-07-22 23:15:59,515 epoch 26 - iter 126/149 - loss 0.06813694 - samples/sec: 142.33 - lr: 0.000008
2021-07-22 23:16:02,871 epoch 26 - iter 140/149 - loss 0.06704355 - samples/sec: 133.53 - lr: 0.000008
2021-07-22 23:16:04,875 ----------------------------------------------------------------------------------------------------
2021-07-22 23:16:04,875 EPOCH 26 done: loss 0.0659 - lr 0.0000075
2021-07-22 23:16:06,924 DEV : loss 0.023666247725486755 - score 0.9948
2021-07-22 23:16:06,947 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:16:10,695 ----------------------------------------------------------------------------------------------------
2021-07-22 23:16:13,879 epoch 27 - iter 14/149 - loss 0.06569812 - samples/sec: 140.82 - lr: 0.000008
2021-07-22 23:16:17,311 epoch 27 - iter 28/149 - loss 0.06198362 - samples/sec: 130.56 - lr: 0.000008
2021-07-22 23:16:20,623 epoch 27 - iter 42/149 - loss 0.06739247 - samples/sec: 135.34 - lr: 0.000008
2021-07-22 23:16:23,896 epoch 27 - iter 56/149 - loss 0.06743063 - samples/sec: 136.89 - lr: 0.000008
2021-07-22 23:16:27,157 epoch 27 - iter 70/149 - loss 0.06613741 - samples/sec: 137.41 - lr: 0.000008
2021-07-22 23:16:30,352 epoch 27 - iter 84/149 - loss 0.06520072 - samples/sec: 140.27 - lr: 0.000008
2021-07-22 23:16:33,572 epoch 27 - iter 98/149 - loss 0.06263155 - samples/sec: 139.14 - lr: 0.000008
2021-07-22 23:16:36,863 epoch 27 - iter 112/149 - loss 0.06497914 - samples/sec: 136.18 - lr: 0.000008
2021-07-22 23:16:40,218 epoch 27 - iter 126/149 - loss 0.06272823 - samples/sec: 133.57 - lr: 0.000008
2021-07-22 23:16:43,423 epoch 27 - iter 140/149 - loss 0.06342069 - samples/sec: 139.79 - lr: 0.000008
2021-07-22 23:16:45,442 ----------------------------------------------------------------------------------------------------
2021-07-22 23:16:45,442 EPOCH 27 done: loss 0.0641 - lr 0.0000075
2021-07-22 23:16:47,489 DEV : loss 0.024294627830386162 - score 0.993
2021-07-22 23:16:47,513 BAD EPOCHS (no improvement): 1
2021-07-22 23:16:47,513 ----------------------------------------------------------------------------------------------------
2021-07-22 23:16:50,781 epoch 28 - iter 14/149 - loss 0.06406496 - samples/sec: 137.18 - lr: 0.000008
2021-07-22 23:16:53,987 epoch 28 - iter 28/149 - loss 0.05820214 - samples/sec: 139.76 - lr: 0.000008
2021-07-22 23:16:57,373 epoch 28 - iter 42/149 - loss 0.05977685 - samples/sec: 132.34 - lr: 0.000008
2021-07-22 23:17:00,725 epoch 28 - iter 56/149 - loss 0.06441263 - samples/sec: 133.71 - lr: 0.000008
2021-07-22 23:17:04,137 epoch 28 - iter 70/149 - loss 0.06602991 - samples/sec: 131.32 - lr: 0.000008
2021-07-22 23:17:07,367 epoch 28 - iter 84/149 - loss 0.06764699 - samples/sec: 138.74 - lr: 0.000008
2021-07-22 23:17:10,596 epoch 28 - iter 98/149 - loss 0.06804857 - samples/sec: 138.78 - lr: 0.000008
2021-07-22 23:17:13,782 epoch 28 - iter 112/149 - loss 0.06780060 - samples/sec: 140.66 - lr: 0.000008
2021-07-22 23:17:17,029 epoch 28 - iter 126/149 - loss 0.06722848 - samples/sec: 138.03 - lr: 0.000008
2021-07-22 23:17:20,361 epoch 28 - iter 140/149 - loss 0.06576531 - samples/sec: 134.49 - lr: 0.000008
2021-07-22 23:17:22,399 ----------------------------------------------------------------------------------------------------
2021-07-22 23:17:22,399 EPOCH 28 done: loss 0.0638 - lr 0.0000075
2021-07-22 23:17:24,460 DEV : loss 0.023927072063088417 - score 0.9948
2021-07-22 23:17:24,483 BAD EPOCHS (no improvement): 2
2021-07-22 23:17:24,484 ----------------------------------------------------------------------------------------------------
2021-07-22 23:17:27,991 epoch 29 - iter 14/149 - loss 0.06893784 - samples/sec: 127.79 - lr: 0.000008
2021-07-22 23:17:31,212 epoch 29 - iter 28/149 - loss 0.05530916 - samples/sec: 139.15 - lr: 0.000008
2021-07-22 23:17:34,548 epoch 29 - iter 42/149 - loss 0.05288865 - samples/sec: 134.31 - lr: 0.000008
2021-07-22 23:17:37,891 epoch 29 - iter 56/149 - loss 0.05553463 - samples/sec: 134.05 - lr: 0.000008
2021-07-22 23:17:41,201 epoch 29 - iter 70/149 - loss 0.05806260 - samples/sec: 135.39 - lr: 0.000008
2021-07-22 23:17:44,644 epoch 29 - iter 84/149 - loss 0.05960860 - samples/sec: 130.15 - lr: 0.000008
2021-07-22 23:17:48,012 epoch 29 - iter 98/149 - loss 0.06504844 - samples/sec: 133.03 - lr: 0.000008
2021-07-22 23:17:51,212 epoch 29 - iter 112/149 - loss 0.06356978 - samples/sec: 140.06 - lr: 0.000008
2021-07-22 23:17:54,544 epoch 29 - iter 126/149 - loss 0.06127441 - samples/sec: 134.47 - lr: 0.000008
2021-07-22 23:17:57,773 epoch 29 - iter 140/149 - loss 0.05918337 - samples/sec: 138.80 - lr: 0.000008
2021-07-22 23:17:59,822 ----------------------------------------------------------------------------------------------------
2021-07-22 23:17:59,822 EPOCH 29 done: loss 0.0597 - lr 0.0000075
2021-07-22 23:18:01,883 DEV : loss 0.02921753190457821 - score 0.9921
2021-07-22 23:18:01,907 BAD EPOCHS (no improvement): 3
2021-07-22 23:18:01,907 ----------------------------------------------------------------------------------------------------
2021-07-22 23:18:05,219 epoch 30 - iter 14/149 - loss 0.07346073 - samples/sec: 135.35 - lr: 0.000008
2021-07-22 23:18:08,596 epoch 30 - iter 28/149 - loss 0.06734030 - samples/sec: 132.68 - lr: 0.000008
2021-07-22 23:18:11,917 epoch 30 - iter 42/149 - loss 0.06037177 - samples/sec: 134.94 - lr: 0.000008
2021-07-22 23:18:15,156 epoch 30 - iter 56/149 - loss 0.06168735 - samples/sec: 138.35 - lr: 0.000008
2021-07-22 23:18:18,523 epoch 30 - iter 70/149 - loss 0.06052381 - samples/sec: 133.10 - lr: 0.000008
2021-07-22 23:18:21,800 epoch 30 - iter 84/149 - loss 0.06451173 - samples/sec: 136.74 - lr: 0.000008
2021-07-22 23:18:25,139 epoch 30 - iter 98/149 - loss 0.06649144 - samples/sec: 134.22 - lr: 0.000008
2021-07-22 23:18:28,299 epoch 30 - iter 112/149 - loss 0.06703697 - samples/sec: 141.77 - lr: 0.000008
2021-07-22 23:18:31,642 epoch 30 - iter 126/149 - loss 0.06537488 - samples/sec: 134.05 - lr: 0.000008
2021-07-22 23:18:34,880 epoch 30 - iter 140/149 - loss 0.06604871 - samples/sec: 138.39 - lr: 0.000008
2021-07-22 23:18:36,996 ----------------------------------------------------------------------------------------------------
2021-07-22 23:18:36,996 EPOCH 30 done: loss 0.0658 - lr 0.0000075
2021-07-22 23:18:39,059 DEV : loss 0.025546438992023468 - score 0.993
Epoch    30: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 23:18:39,082 BAD EPOCHS (no improvement): 4
2021-07-22 23:18:39,082 ----------------------------------------------------------------------------------------------------
2021-07-22 23:18:42,468 epoch 31 - iter 14/149 - loss 0.11540093 - samples/sec: 132.39 - lr: 0.000004
2021-07-22 23:18:45,867 epoch 31 - iter 28/149 - loss 0.08627211 - samples/sec: 131.83 - lr: 0.000004
2021-07-22 23:18:49,211 epoch 31 - iter 42/149 - loss 0.07877813 - samples/sec: 133.99 - lr: 0.000004
2021-07-22 23:18:52,539 epoch 31 - iter 56/149 - loss 0.07167539 - samples/sec: 134.67 - lr: 0.000004
2021-07-22 23:18:55,883 epoch 31 - iter 70/149 - loss 0.06857600 - samples/sec: 134.01 - lr: 0.000004
2021-07-22 23:18:59,080 epoch 31 - iter 84/149 - loss 0.06730370 - samples/sec: 140.16 - lr: 0.000004
2021-07-22 23:19:02,307 epoch 31 - iter 98/149 - loss 0.06537538 - samples/sec: 138.86 - lr: 0.000004
2021-07-22 23:19:05,500 epoch 31 - iter 112/149 - loss 0.06636077 - samples/sec: 140.34 - lr: 0.000004
2021-07-22 23:19:08,766 epoch 31 - iter 126/149 - loss 0.06636430 - samples/sec: 137.22 - lr: 0.000004
2021-07-22 23:19:12,024 epoch 31 - iter 140/149 - loss 0.06456505 - samples/sec: 137.53 - lr: 0.000004
2021-07-22 23:19:14,062 ----------------------------------------------------------------------------------------------------
2021-07-22 23:19:14,063 EPOCH 31 done: loss 0.0624 - lr 0.0000038
2021-07-22 23:19:16,109 DEV : loss 0.02576012909412384 - score 0.993
2021-07-22 23:19:16,132 BAD EPOCHS (no improvement): 1
2021-07-22 23:19:16,133 ----------------------------------------------------------------------------------------------------
2021-07-22 23:19:19,440 epoch 32 - iter 14/149 - loss 0.06600199 - samples/sec: 135.55 - lr: 0.000004
2021-07-22 23:19:22,744 epoch 32 - iter 28/149 - loss 0.06036599 - samples/sec: 135.61 - lr: 0.000004
2021-07-22 23:19:26,047 epoch 32 - iter 42/149 - loss 0.05857763 - samples/sec: 135.69 - lr: 0.000004
2021-07-22 23:19:29,364 epoch 32 - iter 56/149 - loss 0.06389966 - samples/sec: 135.09 - lr: 0.000004
2021-07-22 23:19:32,523 epoch 32 - iter 70/149 - loss 0.06407370 - samples/sec: 141.83 - lr: 0.000004
2021-07-22 23:19:35,707 epoch 32 - iter 84/149 - loss 0.06176321 - samples/sec: 140.76 - lr: 0.000004
2021-07-22 23:19:38,919 epoch 32 - iter 98/149 - loss 0.06026746 - samples/sec: 139.52 - lr: 0.000004
2021-07-22 23:19:42,264 epoch 32 - iter 112/149 - loss 0.06288127 - samples/sec: 133.96 - lr: 0.000004
2021-07-22 23:19:45,658 epoch 32 - iter 126/149 - loss 0.06205684 - samples/sec: 132.01 - lr: 0.000004
2021-07-22 23:19:48,876 epoch 32 - iter 140/149 - loss 0.06349379 - samples/sec: 139.27 - lr: 0.000004
2021-07-22 23:19:50,923 ----------------------------------------------------------------------------------------------------
2021-07-22 23:19:50,923 EPOCH 32 done: loss 0.0626 - lr 0.0000038
2021-07-22 23:19:52,973 DEV : loss 0.025576135143637657 - score 0.9947
2021-07-22 23:19:52,996 BAD EPOCHS (no improvement): 2
2021-07-22 23:19:52,996 ----------------------------------------------------------------------------------------------------
2021-07-22 23:19:56,359 epoch 33 - iter 14/149 - loss 0.06778652 - samples/sec: 133.28 - lr: 0.000004
2021-07-22 23:19:59,668 epoch 33 - iter 28/149 - loss 0.05818183 - samples/sec: 135.45 - lr: 0.000004
2021-07-22 23:20:02,887 epoch 33 - iter 42/149 - loss 0.06173151 - samples/sec: 139.21 - lr: 0.000004
2021-07-22 23:20:06,158 epoch 33 - iter 56/149 - loss 0.06140505 - samples/sec: 136.96 - lr: 0.000004
2021-07-22 23:20:09,376 epoch 33 - iter 70/149 - loss 0.06488307 - samples/sec: 139.26 - lr: 0.000004
2021-07-22 23:20:12,687 epoch 33 - iter 84/149 - loss 0.06183131 - samples/sec: 135.36 - lr: 0.000004
2021-07-22 23:20:15,843 epoch 33 - iter 98/149 - loss 0.06419926 - samples/sec: 141.97 - lr: 0.000004
2021-07-22 23:20:19,056 epoch 33 - iter 112/149 - loss 0.06385918 - samples/sec: 139.47 - lr: 0.000004
2021-07-22 23:20:22,372 epoch 33 - iter 126/149 - loss 0.06416484 - samples/sec: 135.13 - lr: 0.000004
2021-07-22 23:20:25,744 epoch 33 - iter 140/149 - loss 0.06544745 - samples/sec: 132.89 - lr: 0.000004
2021-07-22 23:20:27,687 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:27,687 EPOCH 33 done: loss 0.0642 - lr 0.0000038
2021-07-22 23:20:29,745 DEV : loss 0.02525280974805355 - score 0.9939
2021-07-22 23:20:29,768 BAD EPOCHS (no improvement): 3
2021-07-22 23:20:29,769 ----------------------------------------------------------------------------------------------------
2021-07-22 23:20:33,004 epoch 34 - iter 14/149 - loss 0.04400164 - samples/sec: 138.56 - lr: 0.000004
2021-07-22 23:20:36,483 epoch 34 - iter 28/149 - loss 0.05671898 - samples/sec: 128.78 - lr: 0.000004
2021-07-22 23:20:39,760 epoch 34 - iter 42/149 - loss 0.06347762 - samples/sec: 136.77 - lr: 0.000004
2021-07-22 23:20:43,076 epoch 34 - iter 56/149 - loss 0.05976819 - samples/sec: 135.13 - lr: 0.000004
2021-07-22 23:20:46,485 epoch 34 - iter 70/149 - loss 0.06057850 - samples/sec: 131.45 - lr: 0.000004
2021-07-22 23:20:49,755 epoch 34 - iter 84/149 - loss 0.06167324 - samples/sec: 137.03 - lr: 0.000004
2021-07-22 23:20:52,993 epoch 34 - iter 98/149 - loss 0.06037178 - samples/sec: 138.42 - lr: 0.000004
2021-07-22 23:20:56,372 epoch 34 - iter 112/149 - loss 0.06007031 - samples/sec: 132.61 - lr: 0.000004
2021-07-22 23:20:59,688 epoch 34 - iter 126/149 - loss 0.06164723 - samples/sec: 135.12 - lr: 0.000004
2021-07-22 23:21:03,076 epoch 34 - iter 140/149 - loss 0.06512097 - samples/sec: 132.26 - lr: 0.000004
2021-07-22 23:21:04,982 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:04,982 EPOCH 34 done: loss 0.0637 - lr 0.0000038
2021-07-22 23:21:07,036 DEV : loss 0.02548806369304657 - score 0.9939
Epoch    34: reducing learning rate of group 0 to 1.8750e-06.
2021-07-22 23:21:07,059 BAD EPOCHS (no improvement): 4
2021-07-22 23:21:07,060 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:07,060 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:07,060 learning rate too small - quitting training!
2021-07-22 23:21:07,060 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:08,300 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:08,300 Testing using best model ...
2021-07-22 23:21:08,301 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/por.rst.cstn/best-model.pt
2021-07-22 23:21:32,042 0.9915	0.9943	0.9929
2021-07-22 23:21:32,042 
Results:
- F1-score (micro) 0.9929
- F1-score (macro) 0.9918

By class:
SENT       tp: 450 - fp: 9 - fn: 6 - precision: 0.9804 - recall: 0.9868 - f1-score: 0.9836
X          tp: 594 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 23:21:32,042 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/deu.rst.pcc/
2021-07-22 23:21:32,087 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/deu.rst.pcc
2021-07-22 23:21:32,088 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/deu.rst.pcc/sent_train.txt
2021-07-22 23:21:32,090 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/deu.rst.pcc/sent_dev.txt
2021-07-22 23:21:32,091 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/deu.rst.pcc/sent_test.txt
Corpus: 3206 train + 506 dev + 1055 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 23:21:35,288 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:35,289 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30000, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 23:21:35,289 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:35,289 Corpus: "Corpus: 3206 train + 506 dev + 1055 test sentences"
2021-07-22 23:21:35,289 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:35,290 Parameters:
2021-07-22 23:21:35,290  - learning_rate: "3e-05"
2021-07-22 23:21:35,290  - mini_batch_size: "32"
2021-07-22 23:21:35,290  - patience: "3"
2021-07-22 23:21:35,290  - anneal_factor: "0.5"
2021-07-22 23:21:35,290  - max_epochs: "40"
2021-07-22 23:21:35,290  - shuffle: "True"
2021-07-22 23:21:35,290  - train_with_dev: "False"
2021-07-22 23:21:35,290  - batch_growth_annealing: "False"
2021-07-22 23:21:35,290 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:35,290 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/deu.rst.pcc"
2021-07-22 23:21:35,290 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:35,290 Device: cuda:0
2021-07-22 23:21:35,290 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:35,290 Embeddings storage mode: cpu
2021-07-22 23:21:35,292 ----------------------------------------------------------------------------------------------------
2021-07-22 23:21:40,786 epoch 1 - iter 10/101 - loss 12.96723833 - samples/sec: 58.26 - lr: 0.000030
2021-07-22 23:21:46,260 epoch 1 - iter 20/101 - loss 11.85590825 - samples/sec: 58.46 - lr: 0.000030
2021-07-22 23:21:51,714 epoch 1 - iter 30/101 - loss 11.03054655 - samples/sec: 58.68 - lr: 0.000030
2021-07-22 23:21:57,274 epoch 1 - iter 40/101 - loss 10.23328594 - samples/sec: 57.56 - lr: 0.000030
2021-07-22 23:22:02,904 epoch 1 - iter 50/101 - loss 9.56471658 - samples/sec: 56.84 - lr: 0.000030
2021-07-22 23:22:08,689 epoch 1 - iter 60/101 - loss 8.84618063 - samples/sec: 55.33 - lr: 0.000030
2021-07-22 23:22:14,327 epoch 1 - iter 70/101 - loss 8.16114213 - samples/sec: 56.76 - lr: 0.000030
2021-07-22 23:22:20,036 epoch 1 - iter 80/101 - loss 7.54653872 - samples/sec: 56.05 - lr: 0.000030
2021-07-22 23:22:25,783 epoch 1 - iter 90/101 - loss 7.00581342 - samples/sec: 55.69 - lr: 0.000030
2021-07-22 23:22:31,592 epoch 1 - iter 100/101 - loss 6.53600816 - samples/sec: 55.09 - lr: 0.000030
2021-07-22 23:22:31,729 ----------------------------------------------------------------------------------------------------
2021-07-22 23:22:31,729 EPOCH 1 done: loss 6.4909 - lr 0.0000300
2021-07-22 23:22:38,389 DEV : loss 1.8463554382324219 - score 0.0
2021-07-22 23:22:38,401 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:22:38,973 ----------------------------------------------------------------------------------------------------
2021-07-22 23:22:41,144 epoch 2 - iter 10/101 - loss 1.97305267 - samples/sec: 147.51 - lr: 0.000030
2021-07-22 23:22:43,408 epoch 2 - iter 20/101 - loss 1.86515133 - samples/sec: 141.41 - lr: 0.000030
2021-07-22 23:22:45,572 epoch 2 - iter 30/101 - loss 1.73623914 - samples/sec: 147.89 - lr: 0.000030
2021-07-22 23:22:47,787 epoch 2 - iter 40/101 - loss 1.66594153 - samples/sec: 144.54 - lr: 0.000030
2021-07-22 23:22:49,994 epoch 2 - iter 50/101 - loss 1.59348314 - samples/sec: 145.01 - lr: 0.000030
2021-07-22 23:22:52,091 epoch 2 - iter 60/101 - loss 1.50364305 - samples/sec: 152.67 - lr: 0.000030
2021-07-22 23:22:54,308 epoch 2 - iter 70/101 - loss 1.43885152 - samples/sec: 144.41 - lr: 0.000030
2021-07-22 23:22:56,436 epoch 2 - iter 80/101 - loss 1.37946337 - samples/sec: 150.39 - lr: 0.000030
2021-07-22 23:22:58,632 epoch 2 - iter 90/101 - loss 1.32426375 - samples/sec: 145.74 - lr: 0.000030
2021-07-22 23:23:00,824 epoch 2 - iter 100/101 - loss 1.27329320 - samples/sec: 146.06 - lr: 0.000030
2021-07-22 23:23:00,893 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:00,893 EPOCH 2 done: loss 1.2703 - lr 0.0000300
2021-07-22 23:23:02,016 DEV : loss 0.5847736597061157 - score 0.7081
2021-07-22 23:23:02,028 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:23:04,320 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:06,548 epoch 3 - iter 10/101 - loss 0.75043411 - samples/sec: 143.82 - lr: 0.000030
2021-07-22 23:23:08,817 epoch 3 - iter 20/101 - loss 0.71070636 - samples/sec: 141.08 - lr: 0.000030
2021-07-22 23:23:10,948 epoch 3 - iter 30/101 - loss 0.69458982 - samples/sec: 150.20 - lr: 0.000030
2021-07-22 23:23:13,054 epoch 3 - iter 40/101 - loss 0.66280188 - samples/sec: 151.98 - lr: 0.000030
2021-07-22 23:23:15,217 epoch 3 - iter 50/101 - loss 0.64826400 - samples/sec: 148.03 - lr: 0.000030
2021-07-22 23:23:17,444 epoch 3 - iter 60/101 - loss 0.63773043 - samples/sec: 143.75 - lr: 0.000030
2021-07-22 23:23:19,614 epoch 3 - iter 70/101 - loss 0.62837254 - samples/sec: 147.50 - lr: 0.000030
2021-07-22 23:23:21,731 epoch 3 - iter 80/101 - loss 0.61120858 - samples/sec: 151.20 - lr: 0.000030
2021-07-22 23:23:23,900 epoch 3 - iter 90/101 - loss 0.59154143 - samples/sec: 147.56 - lr: 0.000030
2021-07-22 23:23:26,120 epoch 3 - iter 100/101 - loss 0.57481396 - samples/sec: 144.18 - lr: 0.000030
2021-07-22 23:23:26,209 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:26,209 EPOCH 3 done: loss 0.5721 - lr 0.0000300
2021-07-22 23:23:27,333 DEV : loss 0.29134321212768555 - score 0.9375
2021-07-22 23:23:27,345 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:23:29,489 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:31,731 epoch 4 - iter 10/101 - loss 0.44610601 - samples/sec: 142.87 - lr: 0.000030
2021-07-22 23:23:33,862 epoch 4 - iter 20/101 - loss 0.42174539 - samples/sec: 150.23 - lr: 0.000030
2021-07-22 23:23:35,966 epoch 4 - iter 30/101 - loss 0.41972206 - samples/sec: 152.10 - lr: 0.000030
2021-07-22 23:23:38,068 epoch 4 - iter 40/101 - loss 0.41629790 - samples/sec: 152.30 - lr: 0.000030
2021-07-22 23:23:40,247 epoch 4 - iter 50/101 - loss 0.41351036 - samples/sec: 146.89 - lr: 0.000030
2021-07-22 23:23:42,395 epoch 4 - iter 60/101 - loss 0.40167143 - samples/sec: 149.03 - lr: 0.000030
2021-07-22 23:23:44,530 epoch 4 - iter 70/101 - loss 0.39315771 - samples/sec: 149.95 - lr: 0.000030
2021-07-22 23:23:46,831 epoch 4 - iter 80/101 - loss 0.38134856 - samples/sec: 139.14 - lr: 0.000030
2021-07-22 23:23:49,098 epoch 4 - iter 90/101 - loss 0.37830480 - samples/sec: 141.15 - lr: 0.000030
2021-07-22 23:23:51,235 epoch 4 - iter 100/101 - loss 0.37114130 - samples/sec: 149.80 - lr: 0.000030
2021-07-22 23:23:51,311 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:51,311 EPOCH 4 done: loss 0.3695 - lr 0.0000300
2021-07-22 23:23:52,434 DEV : loss 0.18116767704486847 - score 0.965
2021-07-22 23:23:52,445 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:23:54,594 ----------------------------------------------------------------------------------------------------
2021-07-22 23:23:56,812 epoch 5 - iter 10/101 - loss 0.28674645 - samples/sec: 144.43 - lr: 0.000030
2021-07-22 23:23:59,048 epoch 5 - iter 20/101 - loss 0.30199199 - samples/sec: 143.16 - lr: 0.000030
2021-07-22 23:24:01,296 epoch 5 - iter 30/101 - loss 0.30413454 - samples/sec: 142.40 - lr: 0.000030
2021-07-22 23:24:03,423 epoch 5 - iter 40/101 - loss 0.29749294 - samples/sec: 150.48 - lr: 0.000030
2021-07-22 23:24:05,640 epoch 5 - iter 50/101 - loss 0.29654106 - samples/sec: 144.44 - lr: 0.000030
2021-07-22 23:24:07,762 epoch 5 - iter 60/101 - loss 0.28941689 - samples/sec: 150.84 - lr: 0.000030
2021-07-22 23:24:09,902 epoch 5 - iter 70/101 - loss 0.29378980 - samples/sec: 149.54 - lr: 0.000030
2021-07-22 23:24:12,138 epoch 5 - iter 80/101 - loss 0.29388110 - samples/sec: 143.20 - lr: 0.000030
2021-07-22 23:24:14,207 epoch 5 - iter 90/101 - loss 0.29128288 - samples/sec: 154.71 - lr: 0.000030
2021-07-22 23:24:16,416 epoch 5 - iter 100/101 - loss 0.28711487 - samples/sec: 144.91 - lr: 0.000030
2021-07-22 23:24:16,495 ----------------------------------------------------------------------------------------------------
2021-07-22 23:24:16,495 EPOCH 5 done: loss 0.2865 - lr 0.0000300
2021-07-22 23:24:17,613 DEV : loss 0.13088130950927734 - score 0.9766
2021-07-22 23:24:17,624 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:24:19,797 ----------------------------------------------------------------------------------------------------
2021-07-22 23:24:22,134 epoch 6 - iter 10/101 - loss 0.25812747 - samples/sec: 137.05 - lr: 0.000030
2021-07-22 23:24:24,299 epoch 6 - iter 20/101 - loss 0.25700728 - samples/sec: 147.86 - lr: 0.000030
2021-07-22 23:24:26,446 epoch 6 - iter 30/101 - loss 0.25470305 - samples/sec: 149.07 - lr: 0.000030
2021-07-22 23:24:28,632 epoch 6 - iter 40/101 - loss 0.25224756 - samples/sec: 146.45 - lr: 0.000030
2021-07-22 23:24:30,832 epoch 6 - iter 50/101 - loss 0.24369699 - samples/sec: 145.51 - lr: 0.000030
2021-07-22 23:24:32,982 epoch 6 - iter 60/101 - loss 0.24513666 - samples/sec: 148.90 - lr: 0.000030
2021-07-22 23:24:35,287 epoch 6 - iter 70/101 - loss 0.24664478 - samples/sec: 138.83 - lr: 0.000030
2021-07-22 23:24:37,474 epoch 6 - iter 80/101 - loss 0.24270864 - samples/sec: 146.41 - lr: 0.000030
2021-07-22 23:24:39,603 epoch 6 - iter 90/101 - loss 0.23786683 - samples/sec: 150.31 - lr: 0.000030
2021-07-22 23:24:41,746 epoch 6 - iter 100/101 - loss 0.23985458 - samples/sec: 149.37 - lr: 0.000030
2021-07-22 23:24:41,839 ----------------------------------------------------------------------------------------------------
2021-07-22 23:24:41,839 EPOCH 6 done: loss 0.2383 - lr 0.0000300
2021-07-22 23:24:42,965 DEV : loss 0.10995009541511536 - score 0.9755
2021-07-22 23:24:42,977 BAD EPOCHS (no improvement): 1
2021-07-22 23:24:42,977 ----------------------------------------------------------------------------------------------------
2021-07-22 23:24:45,139 epoch 7 - iter 10/101 - loss 0.26624780 - samples/sec: 148.09 - lr: 0.000030
2021-07-22 23:24:47,328 epoch 7 - iter 20/101 - loss 0.23674178 - samples/sec: 146.24 - lr: 0.000030
2021-07-22 23:24:49,434 epoch 7 - iter 30/101 - loss 0.22518653 - samples/sec: 151.99 - lr: 0.000030
2021-07-22 23:24:51,579 epoch 7 - iter 40/101 - loss 0.21545441 - samples/sec: 149.25 - lr: 0.000030
2021-07-22 23:24:53,756 epoch 7 - iter 50/101 - loss 0.20160057 - samples/sec: 147.05 - lr: 0.000030
2021-07-22 23:24:55,994 epoch 7 - iter 60/101 - loss 0.20012148 - samples/sec: 143.04 - lr: 0.000030
2021-07-22 23:24:58,170 epoch 7 - iter 70/101 - loss 0.21229332 - samples/sec: 147.09 - lr: 0.000030
2021-07-22 23:25:00,323 epoch 7 - iter 80/101 - loss 0.20731439 - samples/sec: 148.66 - lr: 0.000030
2021-07-22 23:25:02,540 epoch 7 - iter 90/101 - loss 0.20722135 - samples/sec: 144.43 - lr: 0.000030
2021-07-22 23:25:04,730 epoch 7 - iter 100/101 - loss 0.20496148 - samples/sec: 146.12 - lr: 0.000030
2021-07-22 23:25:04,801 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:04,802 EPOCH 7 done: loss 0.2078 - lr 0.0000300
2021-07-22 23:25:05,919 DEV : loss 0.09442290663719177 - score 0.9741
2021-07-22 23:25:05,930 BAD EPOCHS (no improvement): 2
2021-07-22 23:25:05,931 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:08,115 epoch 8 - iter 10/101 - loss 0.26007381 - samples/sec: 146.60 - lr: 0.000030
2021-07-22 23:25:10,148 epoch 8 - iter 20/101 - loss 0.21299020 - samples/sec: 157.47 - lr: 0.000030
2021-07-22 23:25:12,359 epoch 8 - iter 30/101 - loss 0.20561328 - samples/sec: 144.78 - lr: 0.000030
2021-07-22 23:25:14,567 epoch 8 - iter 40/101 - loss 0.21230482 - samples/sec: 144.98 - lr: 0.000030
2021-07-22 23:25:16,732 epoch 8 - iter 50/101 - loss 0.21249240 - samples/sec: 147.82 - lr: 0.000030
2021-07-22 23:25:18,955 epoch 8 - iter 60/101 - loss 0.21144039 - samples/sec: 144.01 - lr: 0.000030
2021-07-22 23:25:21,196 epoch 8 - iter 70/101 - loss 0.20407516 - samples/sec: 142.87 - lr: 0.000030
2021-07-22 23:25:23,395 epoch 8 - iter 80/101 - loss 0.19707519 - samples/sec: 145.54 - lr: 0.000030
2021-07-22 23:25:25,620 epoch 8 - iter 90/101 - loss 0.19531124 - samples/sec: 143.87 - lr: 0.000030
2021-07-22 23:25:27,762 epoch 8 - iter 100/101 - loss 0.19449524 - samples/sec: 149.44 - lr: 0.000030
2021-07-22 23:25:27,810 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:27,810 EPOCH 8 done: loss 0.1942 - lr 0.0000300
2021-07-22 23:25:28,928 DEV : loss 0.09000609815120697 - score 0.9771
2021-07-22 23:25:28,940 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:25:31,112 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:33,239 epoch 9 - iter 10/101 - loss 0.14113187 - samples/sec: 150.59 - lr: 0.000030
2021-07-22 23:25:35,479 epoch 9 - iter 20/101 - loss 0.16518670 - samples/sec: 142.91 - lr: 0.000030
2021-07-22 23:25:37,671 epoch 9 - iter 30/101 - loss 0.15784195 - samples/sec: 146.02 - lr: 0.000030
2021-07-22 23:25:39,919 epoch 9 - iter 40/101 - loss 0.16293332 - samples/sec: 142.40 - lr: 0.000030
2021-07-22 23:25:41,971 epoch 9 - iter 50/101 - loss 0.16833965 - samples/sec: 156.00 - lr: 0.000030
2021-07-22 23:25:44,176 epoch 9 - iter 60/101 - loss 0.16776051 - samples/sec: 145.20 - lr: 0.000030
2021-07-22 23:25:46,339 epoch 9 - iter 70/101 - loss 0.17127274 - samples/sec: 147.98 - lr: 0.000030
2021-07-22 23:25:48,619 epoch 9 - iter 80/101 - loss 0.17492462 - samples/sec: 140.40 - lr: 0.000030
2021-07-22 23:25:50,775 epoch 9 - iter 90/101 - loss 0.17614203 - samples/sec: 148.42 - lr: 0.000030
2021-07-22 23:25:52,919 epoch 9 - iter 100/101 - loss 0.17616029 - samples/sec: 149.32 - lr: 0.000030
2021-07-22 23:25:53,002 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:53,003 EPOCH 9 done: loss 0.1750 - lr 0.0000300
2021-07-22 23:25:54,126 DEV : loss 0.07710865139961243 - score 0.9795
2021-07-22 23:25:54,138 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:25:56,297 ----------------------------------------------------------------------------------------------------
2021-07-22 23:25:58,486 epoch 10 - iter 10/101 - loss 0.18662850 - samples/sec: 146.37 - lr: 0.000030
2021-07-22 23:26:00,650 epoch 10 - iter 20/101 - loss 0.20119127 - samples/sec: 147.90 - lr: 0.000030
2021-07-22 23:26:02,916 epoch 10 - iter 30/101 - loss 0.18448282 - samples/sec: 141.28 - lr: 0.000030
2021-07-22 23:26:05,054 epoch 10 - iter 40/101 - loss 0.17805891 - samples/sec: 149.70 - lr: 0.000030
2021-07-22 23:26:07,210 epoch 10 - iter 50/101 - loss 0.17733241 - samples/sec: 148.52 - lr: 0.000030
2021-07-22 23:26:09,348 epoch 10 - iter 60/101 - loss 0.17543744 - samples/sec: 149.72 - lr: 0.000030
2021-07-22 23:26:11,460 epoch 10 - iter 70/101 - loss 0.17039805 - samples/sec: 151.54 - lr: 0.000030
2021-07-22 23:26:13,647 epoch 10 - iter 80/101 - loss 0.16909563 - samples/sec: 146.35 - lr: 0.000030
2021-07-22 23:26:15,865 epoch 10 - iter 90/101 - loss 0.17375087 - samples/sec: 144.33 - lr: 0.000030
2021-07-22 23:26:18,093 epoch 10 - iter 100/101 - loss 0.17121302 - samples/sec: 143.72 - lr: 0.000030
2021-07-22 23:26:18,146 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:18,146 EPOCH 10 done: loss 0.1697 - lr 0.0000300
2021-07-22 23:26:19,273 DEV : loss 0.07589416950941086 - score 0.9784
2021-07-22 23:26:19,284 BAD EPOCHS (no improvement): 1
2021-07-22 23:26:19,285 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:21,454 epoch 11 - iter 10/101 - loss 0.16232404 - samples/sec: 147.60 - lr: 0.000030
2021-07-22 23:26:23,591 epoch 11 - iter 20/101 - loss 0.16683547 - samples/sec: 149.80 - lr: 0.000030
2021-07-22 23:26:25,710 epoch 11 - iter 30/101 - loss 0.16039307 - samples/sec: 151.06 - lr: 0.000030
2021-07-22 23:26:27,936 epoch 11 - iter 40/101 - loss 0.15300901 - samples/sec: 143.82 - lr: 0.000030
2021-07-22 23:26:30,108 epoch 11 - iter 50/101 - loss 0.15431921 - samples/sec: 147.39 - lr: 0.000030
2021-07-22 23:26:32,286 epoch 11 - iter 60/101 - loss 0.14733339 - samples/sec: 146.97 - lr: 0.000030
2021-07-22 23:26:34,455 epoch 11 - iter 70/101 - loss 0.14857855 - samples/sec: 147.56 - lr: 0.000030
2021-07-22 23:26:36,563 epoch 11 - iter 80/101 - loss 0.15159240 - samples/sec: 151.90 - lr: 0.000030
2021-07-22 23:26:38,797 epoch 11 - iter 90/101 - loss 0.15057311 - samples/sec: 143.28 - lr: 0.000030
2021-07-22 23:26:41,047 epoch 11 - iter 100/101 - loss 0.15379381 - samples/sec: 142.32 - lr: 0.000030
2021-07-22 23:26:41,114 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:41,114 EPOCH 11 done: loss 0.1524 - lr 0.0000300
2021-07-22 23:26:42,240 DEV : loss 0.0694548636674881 - score 0.981
2021-07-22 23:26:42,252 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:26:44,598 ----------------------------------------------------------------------------------------------------
2021-07-22 23:26:46,772 epoch 12 - iter 10/101 - loss 0.15139420 - samples/sec: 147.37 - lr: 0.000030
2021-07-22 23:26:48,982 epoch 12 - iter 20/101 - loss 0.16541169 - samples/sec: 144.79 - lr: 0.000030
2021-07-22 23:26:51,107 epoch 12 - iter 30/101 - loss 0.14708219 - samples/sec: 150.68 - lr: 0.000030
2021-07-22 23:26:53,306 epoch 12 - iter 40/101 - loss 0.14876115 - samples/sec: 145.57 - lr: 0.000030
2021-07-22 23:26:55,363 epoch 12 - iter 50/101 - loss 0.14366574 - samples/sec: 155.61 - lr: 0.000030
2021-07-22 23:26:57,477 epoch 12 - iter 60/101 - loss 0.14342594 - samples/sec: 151.43 - lr: 0.000030
2021-07-22 23:26:59,664 epoch 12 - iter 70/101 - loss 0.14751346 - samples/sec: 146.38 - lr: 0.000030
2021-07-22 23:27:01,804 epoch 12 - iter 80/101 - loss 0.15727820 - samples/sec: 149.60 - lr: 0.000030
2021-07-22 23:27:04,027 epoch 12 - iter 90/101 - loss 0.15411231 - samples/sec: 143.98 - lr: 0.000030
2021-07-22 23:27:06,279 epoch 12 - iter 100/101 - loss 0.15366531 - samples/sec: 142.12 - lr: 0.000030
2021-07-22 23:27:06,369 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:06,369 EPOCH 12 done: loss 0.1524 - lr 0.0000300
2021-07-22 23:27:07,496 DEV : loss 0.07013466954231262 - score 0.9811
2021-07-22 23:27:07,508 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:27:09,615 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:11,762 epoch 13 - iter 10/101 - loss 0.16133508 - samples/sec: 149.24 - lr: 0.000030
2021-07-22 23:27:13,867 epoch 13 - iter 20/101 - loss 0.16622784 - samples/sec: 152.04 - lr: 0.000030
2021-07-22 23:27:15,990 epoch 13 - iter 30/101 - loss 0.15617609 - samples/sec: 150.78 - lr: 0.000030
2021-07-22 23:27:18,226 epoch 13 - iter 40/101 - loss 0.15556173 - samples/sec: 143.15 - lr: 0.000030
2021-07-22 23:27:20,412 epoch 13 - iter 50/101 - loss 0.14991992 - samples/sec: 146.42 - lr: 0.000030
2021-07-22 23:27:22,800 epoch 13 - iter 60/101 - loss 0.14637882 - samples/sec: 134.06 - lr: 0.000030
2021-07-22 23:27:24,962 epoch 13 - iter 70/101 - loss 0.14729560 - samples/sec: 148.03 - lr: 0.000030
2021-07-22 23:27:27,212 epoch 13 - iter 80/101 - loss 0.15017259 - samples/sec: 142.26 - lr: 0.000030
2021-07-22 23:27:29,351 epoch 13 - iter 90/101 - loss 0.14986795 - samples/sec: 149.65 - lr: 0.000030
2021-07-22 23:27:31,542 epoch 13 - iter 100/101 - loss 0.14857896 - samples/sec: 146.16 - lr: 0.000030
2021-07-22 23:27:31,621 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:31,621 EPOCH 13 done: loss 0.1489 - lr 0.0000300
2021-07-22 23:27:32,750 DEV : loss 0.06407436728477478 - score 0.9837
2021-07-22 23:27:32,762 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:27:34,942 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:37,044 epoch 14 - iter 10/101 - loss 0.16206996 - samples/sec: 152.43 - lr: 0.000030
2021-07-22 23:27:39,158 epoch 14 - iter 20/101 - loss 0.16595429 - samples/sec: 151.43 - lr: 0.000030
2021-07-22 23:27:41,363 epoch 14 - iter 30/101 - loss 0.14439500 - samples/sec: 145.17 - lr: 0.000030
2021-07-22 23:27:43,571 epoch 14 - iter 40/101 - loss 0.13464204 - samples/sec: 144.94 - lr: 0.000030
2021-07-22 23:27:45,806 epoch 14 - iter 50/101 - loss 0.13813776 - samples/sec: 143.21 - lr: 0.000030
2021-07-22 23:27:47,947 epoch 14 - iter 60/101 - loss 0.13665191 - samples/sec: 149.56 - lr: 0.000030
2021-07-22 23:27:50,224 epoch 14 - iter 70/101 - loss 0.13262915 - samples/sec: 140.60 - lr: 0.000030
2021-07-22 23:27:52,392 epoch 14 - iter 80/101 - loss 0.13893043 - samples/sec: 147.59 - lr: 0.000030
2021-07-22 23:27:54,535 epoch 14 - iter 90/101 - loss 0.13311569 - samples/sec: 149.44 - lr: 0.000030
2021-07-22 23:27:56,756 epoch 14 - iter 100/101 - loss 0.13210760 - samples/sec: 144.10 - lr: 0.000030
2021-07-22 23:27:56,833 ----------------------------------------------------------------------------------------------------
2021-07-22 23:27:56,834 EPOCH 14 done: loss 0.1309 - lr 0.0000300
2021-07-22 23:27:57,963 DEV : loss 0.06283967941999435 - score 0.9837
2021-07-22 23:27:57,975 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:28:00,180 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:02,351 epoch 15 - iter 10/101 - loss 0.18617974 - samples/sec: 147.61 - lr: 0.000030
2021-07-22 23:28:04,507 epoch 15 - iter 20/101 - loss 0.17539311 - samples/sec: 148.48 - lr: 0.000030
2021-07-22 23:28:06,719 epoch 15 - iter 30/101 - loss 0.15523837 - samples/sec: 144.67 - lr: 0.000030
2021-07-22 23:28:08,894 epoch 15 - iter 40/101 - loss 0.14795859 - samples/sec: 147.19 - lr: 0.000030
2021-07-22 23:28:11,174 epoch 15 - iter 50/101 - loss 0.14886970 - samples/sec: 140.41 - lr: 0.000030
2021-07-22 23:28:13,320 epoch 15 - iter 60/101 - loss 0.14754884 - samples/sec: 149.13 - lr: 0.000030
2021-07-22 23:28:15,467 epoch 15 - iter 70/101 - loss 0.14619561 - samples/sec: 149.13 - lr: 0.000030
2021-07-22 23:28:17,582 epoch 15 - iter 80/101 - loss 0.14710124 - samples/sec: 151.36 - lr: 0.000030
2021-07-22 23:28:19,744 epoch 15 - iter 90/101 - loss 0.14571134 - samples/sec: 148.06 - lr: 0.000030
2021-07-22 23:28:21,924 epoch 15 - iter 100/101 - loss 0.14394673 - samples/sec: 146.85 - lr: 0.000030
2021-07-22 23:28:22,014 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:22,015 EPOCH 15 done: loss 0.1432 - lr 0.0000300
2021-07-22 23:28:23,146 DEV : loss 0.06030692160129547 - score 0.985
2021-07-22 23:28:23,158 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:28:25,347 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:27,501 epoch 16 - iter 10/101 - loss 0.14835270 - samples/sec: 148.76 - lr: 0.000030
2021-07-22 23:28:29,655 epoch 16 - iter 20/101 - loss 0.14580727 - samples/sec: 148.65 - lr: 0.000030
2021-07-22 23:28:31,930 epoch 16 - iter 30/101 - loss 0.16067673 - samples/sec: 140.70 - lr: 0.000030
2021-07-22 23:28:34,114 epoch 16 - iter 40/101 - loss 0.14489385 - samples/sec: 146.51 - lr: 0.000030
2021-07-22 23:28:36,219 epoch 16 - iter 50/101 - loss 0.14338007 - samples/sec: 152.09 - lr: 0.000030
2021-07-22 23:28:38,374 epoch 16 - iter 60/101 - loss 0.13657359 - samples/sec: 148.52 - lr: 0.000030
2021-07-22 23:28:40,590 epoch 16 - iter 70/101 - loss 0.13498504 - samples/sec: 144.47 - lr: 0.000030
2021-07-22 23:28:42,772 epoch 16 - iter 80/101 - loss 0.13367436 - samples/sec: 146.68 - lr: 0.000030
2021-07-22 23:28:44,872 epoch 16 - iter 90/101 - loss 0.12739413 - samples/sec: 152.43 - lr: 0.000030
2021-07-22 23:28:47,047 epoch 16 - iter 100/101 - loss 0.12503829 - samples/sec: 147.21 - lr: 0.000030
2021-07-22 23:28:47,109 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:47,110 EPOCH 16 done: loss 0.1239 - lr 0.0000300
2021-07-22 23:28:48,238 DEV : loss 0.05985919013619423 - score 0.985
2021-07-22 23:28:48,250 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:28:50,395 ----------------------------------------------------------------------------------------------------
2021-07-22 23:28:52,547 epoch 17 - iter 10/101 - loss 0.14851419 - samples/sec: 148.86 - lr: 0.000030
2021-07-22 23:28:54,819 epoch 17 - iter 20/101 - loss 0.15620356 - samples/sec: 140.90 - lr: 0.000030
2021-07-22 23:28:56,899 epoch 17 - iter 30/101 - loss 0.14732176 - samples/sec: 153.92 - lr: 0.000030
2021-07-22 23:28:58,994 epoch 17 - iter 40/101 - loss 0.14382372 - samples/sec: 152.75 - lr: 0.000030
2021-07-22 23:29:01,208 epoch 17 - iter 50/101 - loss 0.13014695 - samples/sec: 144.61 - lr: 0.000030
2021-07-22 23:29:03,459 epoch 17 - iter 60/101 - loss 0.13064735 - samples/sec: 142.18 - lr: 0.000030
2021-07-22 23:29:05,678 epoch 17 - iter 70/101 - loss 0.12948113 - samples/sec: 144.29 - lr: 0.000030
2021-07-22 23:29:07,928 epoch 17 - iter 80/101 - loss 0.13185314 - samples/sec: 142.25 - lr: 0.000030
2021-07-22 23:29:10,044 epoch 17 - iter 90/101 - loss 0.12982853 - samples/sec: 151.25 - lr: 0.000030
2021-07-22 23:29:12,211 epoch 17 - iter 100/101 - loss 0.12774452 - samples/sec: 147.72 - lr: 0.000030
2021-07-22 23:29:12,281 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:12,281 EPOCH 17 done: loss 0.1265 - lr 0.0000300
2021-07-22 23:29:13,402 DEV : loss 0.05828346312046051 - score 0.985
2021-07-22 23:29:13,414 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:29:15,514 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:17,679 epoch 18 - iter 10/101 - loss 0.12794602 - samples/sec: 147.98 - lr: 0.000030
2021-07-22 23:29:19,895 epoch 18 - iter 20/101 - loss 0.11091266 - samples/sec: 144.46 - lr: 0.000030
2021-07-22 23:29:21,966 epoch 18 - iter 30/101 - loss 0.11442492 - samples/sec: 154.52 - lr: 0.000030
2021-07-22 23:29:24,187 epoch 18 - iter 40/101 - loss 0.11149363 - samples/sec: 144.15 - lr: 0.000030
2021-07-22 23:29:26,428 epoch 18 - iter 50/101 - loss 0.11056002 - samples/sec: 142.82 - lr: 0.000030
2021-07-22 23:29:28,557 epoch 18 - iter 60/101 - loss 0.10854531 - samples/sec: 150.35 - lr: 0.000030
2021-07-22 23:29:30,762 epoch 18 - iter 70/101 - loss 0.10969035 - samples/sec: 145.18 - lr: 0.000030
2021-07-22 23:29:33,015 epoch 18 - iter 80/101 - loss 0.10860641 - samples/sec: 142.12 - lr: 0.000030
2021-07-22 23:29:35,238 epoch 18 - iter 90/101 - loss 0.11147688 - samples/sec: 143.96 - lr: 0.000030
2021-07-22 23:29:37,354 epoch 18 - iter 100/101 - loss 0.10931241 - samples/sec: 151.26 - lr: 0.000030
2021-07-22 23:29:37,438 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:37,438 EPOCH 18 done: loss 0.1097 - lr 0.0000300
2021-07-22 23:29:38,556 DEV : loss 0.056884098798036575 - score 0.985
2021-07-22 23:29:38,567 BAD EPOCHS (no improvement): 1
2021-07-22 23:29:38,568 ----------------------------------------------------------------------------------------------------
2021-07-22 23:29:40,776 epoch 19 - iter 10/101 - loss 0.14541215 - samples/sec: 145.00 - lr: 0.000030
2021-07-22 23:29:42,959 epoch 19 - iter 20/101 - loss 0.12162690 - samples/sec: 146.65 - lr: 0.000030
2021-07-22 23:29:45,123 epoch 19 - iter 30/101 - loss 0.12780926 - samples/sec: 147.96 - lr: 0.000030
2021-07-22 23:29:47,290 epoch 19 - iter 40/101 - loss 0.12666645 - samples/sec: 147.67 - lr: 0.000030
2021-07-22 23:29:49,623 epoch 19 - iter 50/101 - loss 0.13037362 - samples/sec: 137.20 - lr: 0.000030
2021-07-22 23:29:51,776 epoch 19 - iter 60/101 - loss 0.13262854 - samples/sec: 148.72 - lr: 0.000030
2021-07-22 23:29:54,047 epoch 19 - iter 70/101 - loss 0.13427115 - samples/sec: 140.96 - lr: 0.000030
2021-07-22 23:29:56,139 epoch 19 - iter 80/101 - loss 0.13476607 - samples/sec: 153.03 - lr: 0.000030
2021-07-22 23:29:58,227 epoch 19 - iter 90/101 - loss 0.13741721 - samples/sec: 153.29 - lr: 0.000030
2021-07-22 23:30:00,344 epoch 19 - iter 100/101 - loss 0.13141483 - samples/sec: 151.21 - lr: 0.000030
2021-07-22 23:30:00,415 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:00,415 EPOCH 19 done: loss 0.1317 - lr 0.0000300
2021-07-22 23:30:01,543 DEV : loss 0.06380319595336914 - score 0.9825
2021-07-22 23:30:01,555 BAD EPOCHS (no improvement): 2
2021-07-22 23:30:01,555 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:03,800 epoch 20 - iter 10/101 - loss 0.14216612 - samples/sec: 142.69 - lr: 0.000030
2021-07-22 23:30:05,923 epoch 20 - iter 20/101 - loss 0.13077567 - samples/sec: 150.75 - lr: 0.000030
2021-07-22 23:30:08,148 epoch 20 - iter 30/101 - loss 0.12663320 - samples/sec: 143.89 - lr: 0.000030
2021-07-22 23:30:10,310 epoch 20 - iter 40/101 - loss 0.12354864 - samples/sec: 148.03 - lr: 0.000030
2021-07-22 23:30:12,411 epoch 20 - iter 50/101 - loss 0.12189375 - samples/sec: 152.33 - lr: 0.000030
2021-07-22 23:30:14,678 epoch 20 - iter 60/101 - loss 0.12541423 - samples/sec: 141.20 - lr: 0.000030
2021-07-22 23:30:16,890 epoch 20 - iter 70/101 - loss 0.12683889 - samples/sec: 144.70 - lr: 0.000030
2021-07-22 23:30:19,087 epoch 20 - iter 80/101 - loss 0.12569088 - samples/sec: 145.69 - lr: 0.000030
2021-07-22 23:30:21,315 epoch 20 - iter 90/101 - loss 0.12374486 - samples/sec: 143.70 - lr: 0.000030
2021-07-22 23:30:23,430 epoch 20 - iter 100/101 - loss 0.12590238 - samples/sec: 151.33 - lr: 0.000030
2021-07-22 23:30:23,519 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:23,519 EPOCH 20 done: loss 0.1247 - lr 0.0000300
2021-07-22 23:30:24,648 DEV : loss 0.056166402995586395 - score 0.985
2021-07-22 23:30:24,660 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:30:26,685 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:28,839 epoch 21 - iter 10/101 - loss 0.10331477 - samples/sec: 148.70 - lr: 0.000030
2021-07-22 23:30:31,012 epoch 21 - iter 20/101 - loss 0.09272303 - samples/sec: 147.36 - lr: 0.000030
2021-07-22 23:30:33,167 epoch 21 - iter 30/101 - loss 0.09648328 - samples/sec: 148.50 - lr: 0.000030
2021-07-22 23:30:35,328 epoch 21 - iter 40/101 - loss 0.10843929 - samples/sec: 148.14 - lr: 0.000030
2021-07-22 23:30:37,563 epoch 21 - iter 50/101 - loss 0.11524116 - samples/sec: 143.21 - lr: 0.000030
2021-07-22 23:30:39,733 epoch 21 - iter 60/101 - loss 0.11663195 - samples/sec: 147.55 - lr: 0.000030
2021-07-22 23:30:41,996 epoch 21 - iter 70/101 - loss 0.11921822 - samples/sec: 141.43 - lr: 0.000030
2021-07-22 23:30:44,259 epoch 21 - iter 80/101 - loss 0.11697088 - samples/sec: 141.49 - lr: 0.000030
2021-07-22 23:30:46,310 epoch 21 - iter 90/101 - loss 0.11989283 - samples/sec: 156.04 - lr: 0.000030
2021-07-22 23:30:48,510 epoch 21 - iter 100/101 - loss 0.11857903 - samples/sec: 145.49 - lr: 0.000030
2021-07-22 23:30:48,572 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:48,573 EPOCH 21 done: loss 0.1175 - lr 0.0000300
2021-07-22 23:30:49,717 DEV : loss 0.0550011582672596 - score 0.985
2021-07-22 23:30:49,728 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:30:51,869 ----------------------------------------------------------------------------------------------------
2021-07-22 23:30:53,946 epoch 22 - iter 10/101 - loss 0.08470607 - samples/sec: 154.23 - lr: 0.000030
2021-07-22 23:30:56,087 epoch 22 - iter 20/101 - loss 0.09026504 - samples/sec: 149.56 - lr: 0.000030
2021-07-22 23:30:58,266 epoch 22 - iter 30/101 - loss 0.11597309 - samples/sec: 146.87 - lr: 0.000030
2021-07-22 23:31:00,420 epoch 22 - iter 40/101 - loss 0.11998407 - samples/sec: 148.61 - lr: 0.000030
2021-07-22 23:31:02,671 epoch 22 - iter 50/101 - loss 0.11773140 - samples/sec: 142.19 - lr: 0.000030
2021-07-22 23:31:04,935 epoch 22 - iter 60/101 - loss 0.11492069 - samples/sec: 141.40 - lr: 0.000030
2021-07-22 23:31:07,132 epoch 22 - iter 70/101 - loss 0.11551836 - samples/sec: 145.67 - lr: 0.000030
2021-07-22 23:31:09,272 epoch 22 - iter 80/101 - loss 0.11826738 - samples/sec: 149.58 - lr: 0.000030
2021-07-22 23:31:11,504 epoch 22 - iter 90/101 - loss 0.11978302 - samples/sec: 143.46 - lr: 0.000030
2021-07-22 23:31:13,732 epoch 22 - iter 100/101 - loss 0.11909499 - samples/sec: 143.65 - lr: 0.000030
2021-07-22 23:31:13,820 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:13,820 EPOCH 22 done: loss 0.1196 - lr 0.0000300
2021-07-22 23:31:14,941 DEV : loss 0.060383934527635574 - score 0.9824
2021-07-22 23:31:14,953 BAD EPOCHS (no improvement): 1
2021-07-22 23:31:14,953 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:17,219 epoch 23 - iter 10/101 - loss 0.07103216 - samples/sec: 141.33 - lr: 0.000030
2021-07-22 23:31:19,331 epoch 23 - iter 20/101 - loss 0.08995184 - samples/sec: 151.55 - lr: 0.000030
2021-07-22 23:31:21,536 epoch 23 - iter 30/101 - loss 0.10128295 - samples/sec: 145.20 - lr: 0.000030
2021-07-22 23:31:23,730 epoch 23 - iter 40/101 - loss 0.11046911 - samples/sec: 145.90 - lr: 0.000030
2021-07-22 23:31:25,939 epoch 23 - iter 50/101 - loss 0.11270521 - samples/sec: 144.92 - lr: 0.000030
2021-07-22 23:31:28,213 epoch 23 - iter 60/101 - loss 0.11926053 - samples/sec: 140.77 - lr: 0.000030
2021-07-22 23:31:30,408 epoch 23 - iter 70/101 - loss 0.11525595 - samples/sec: 145.79 - lr: 0.000030
2021-07-22 23:31:32,431 epoch 23 - iter 80/101 - loss 0.11556752 - samples/sec: 158.27 - lr: 0.000030
2021-07-22 23:31:34,618 epoch 23 - iter 90/101 - loss 0.11755624 - samples/sec: 146.33 - lr: 0.000030
2021-07-22 23:31:36,819 epoch 23 - iter 100/101 - loss 0.11624359 - samples/sec: 145.45 - lr: 0.000030
2021-07-22 23:31:36,902 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:36,902 EPOCH 23 done: loss 0.1152 - lr 0.0000300
2021-07-22 23:31:38,024 DEV : loss 0.05888395383954048 - score 0.9824
2021-07-22 23:31:38,036 BAD EPOCHS (no improvement): 2
2021-07-22 23:31:38,036 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:40,200 epoch 24 - iter 10/101 - loss 0.12260660 - samples/sec: 147.99 - lr: 0.000030
2021-07-22 23:31:42,423 epoch 24 - iter 20/101 - loss 0.11084806 - samples/sec: 144.00 - lr: 0.000030
2021-07-22 23:31:44,590 epoch 24 - iter 30/101 - loss 0.10768011 - samples/sec: 147.66 - lr: 0.000030
2021-07-22 23:31:46,771 epoch 24 - iter 40/101 - loss 0.11714202 - samples/sec: 146.80 - lr: 0.000030
2021-07-22 23:31:49,054 epoch 24 - iter 50/101 - loss 0.11843195 - samples/sec: 140.19 - lr: 0.000030
2021-07-22 23:31:51,131 epoch 24 - iter 60/101 - loss 0.11785348 - samples/sec: 154.14 - lr: 0.000030
2021-07-22 23:31:53,309 epoch 24 - iter 70/101 - loss 0.11813301 - samples/sec: 147.01 - lr: 0.000030
2021-07-22 23:31:55,451 epoch 24 - iter 80/101 - loss 0.12157013 - samples/sec: 149.39 - lr: 0.000030
2021-07-22 23:31:57,648 epoch 24 - iter 90/101 - loss 0.11794649 - samples/sec: 145.74 - lr: 0.000030
2021-07-22 23:31:59,862 epoch 24 - iter 100/101 - loss 0.11380051 - samples/sec: 144.54 - lr: 0.000030
2021-07-22 23:31:59,914 ----------------------------------------------------------------------------------------------------
2021-07-22 23:31:59,914 EPOCH 24 done: loss 0.1128 - lr 0.0000300
2021-07-22 23:32:01,034 DEV : loss 0.05467106029391289 - score 0.9864
2021-07-22 23:32:01,046 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:32:03,266 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:05,443 epoch 25 - iter 10/101 - loss 0.13126974 - samples/sec: 147.19 - lr: 0.000030
2021-07-22 23:32:07,519 epoch 25 - iter 20/101 - loss 0.12351149 - samples/sec: 154.14 - lr: 0.000030
2021-07-22 23:32:09,776 epoch 25 - iter 30/101 - loss 0.13352570 - samples/sec: 141.85 - lr: 0.000030
2021-07-22 23:32:11,928 epoch 25 - iter 40/101 - loss 0.12334817 - samples/sec: 148.75 - lr: 0.000030
2021-07-22 23:32:14,259 epoch 25 - iter 50/101 - loss 0.12156944 - samples/sec: 137.33 - lr: 0.000030
2021-07-22 23:32:16,475 epoch 25 - iter 60/101 - loss 0.12021271 - samples/sec: 144.46 - lr: 0.000030
2021-07-22 23:32:18,677 epoch 25 - iter 70/101 - loss 0.11824397 - samples/sec: 145.35 - lr: 0.000030
2021-07-22 23:32:20,828 epoch 25 - iter 80/101 - loss 0.11282866 - samples/sec: 148.82 - lr: 0.000030
2021-07-22 23:32:23,039 epoch 25 - iter 90/101 - loss 0.11465987 - samples/sec: 144.78 - lr: 0.000030
2021-07-22 23:32:25,151 epoch 25 - iter 100/101 - loss 0.11317052 - samples/sec: 151.54 - lr: 0.000030
2021-07-22 23:32:25,217 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:25,217 EPOCH 25 done: loss 0.1138 - lr 0.0000300
2021-07-22 23:32:26,341 DEV : loss 0.05422379821538925 - score 0.9863
2021-07-22 23:32:26,353 BAD EPOCHS (no improvement): 1
2021-07-22 23:32:26,353 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:28,579 epoch 26 - iter 10/101 - loss 0.10638522 - samples/sec: 143.86 - lr: 0.000030
2021-07-22 23:32:30,856 epoch 26 - iter 20/101 - loss 0.10650023 - samples/sec: 140.59 - lr: 0.000030
2021-07-22 23:32:32,992 epoch 26 - iter 30/101 - loss 0.11334385 - samples/sec: 149.86 - lr: 0.000030
2021-07-22 23:32:35,223 epoch 26 - iter 40/101 - loss 0.11823796 - samples/sec: 143.49 - lr: 0.000030
2021-07-22 23:32:37,375 epoch 26 - iter 50/101 - loss 0.11294479 - samples/sec: 148.75 - lr: 0.000030
2021-07-22 23:32:39,446 epoch 26 - iter 60/101 - loss 0.11059815 - samples/sec: 154.53 - lr: 0.000030
2021-07-22 23:32:41,615 epoch 26 - iter 70/101 - loss 0.10434391 - samples/sec: 147.58 - lr: 0.000030
2021-07-22 23:32:43,821 epoch 26 - iter 80/101 - loss 0.11180545 - samples/sec: 145.15 - lr: 0.000030
2021-07-22 23:32:46,076 epoch 26 - iter 90/101 - loss 0.11479640 - samples/sec: 141.95 - lr: 0.000030
2021-07-22 23:32:48,228 epoch 26 - iter 100/101 - loss 0.11297500 - samples/sec: 148.73 - lr: 0.000030
2021-07-22 23:32:48,307 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:48,308 EPOCH 26 done: loss 0.1123 - lr 0.0000300
2021-07-22 23:32:49,427 DEV : loss 0.05983640253543854 - score 0.9851
2021-07-22 23:32:49,439 BAD EPOCHS (no improvement): 2
2021-07-22 23:32:49,439 ----------------------------------------------------------------------------------------------------
2021-07-22 23:32:51,623 epoch 27 - iter 10/101 - loss 0.10906959 - samples/sec: 146.64 - lr: 0.000030
2021-07-22 23:32:53,799 epoch 27 - iter 20/101 - loss 0.12778468 - samples/sec: 147.13 - lr: 0.000030
2021-07-22 23:32:56,008 epoch 27 - iter 30/101 - loss 0.11496455 - samples/sec: 144.89 - lr: 0.000030
2021-07-22 23:32:58,247 epoch 27 - iter 40/101 - loss 0.10830215 - samples/sec: 142.94 - lr: 0.000030
2021-07-22 23:33:00,458 epoch 27 - iter 50/101 - loss 0.10356418 - samples/sec: 144.76 - lr: 0.000030
2021-07-22 23:33:02,569 epoch 27 - iter 60/101 - loss 0.10343395 - samples/sec: 151.69 - lr: 0.000030
2021-07-22 23:33:04,888 epoch 27 - iter 70/101 - loss 0.10280968 - samples/sec: 138.03 - lr: 0.000030
2021-07-22 23:33:07,103 epoch 27 - iter 80/101 - loss 0.10647559 - samples/sec: 144.48 - lr: 0.000030
2021-07-22 23:33:09,336 epoch 27 - iter 90/101 - loss 0.10464969 - samples/sec: 143.36 - lr: 0.000030
2021-07-22 23:33:11,430 epoch 27 - iter 100/101 - loss 0.10382937 - samples/sec: 152.92 - lr: 0.000030
2021-07-22 23:33:11,498 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:11,499 EPOCH 27 done: loss 0.1110 - lr 0.0000300
2021-07-22 23:33:12,615 DEV : loss 0.06316204369068146 - score 0.9825
2021-07-22 23:33:12,627 BAD EPOCHS (no improvement): 3
2021-07-22 23:33:12,627 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:14,809 epoch 28 - iter 10/101 - loss 0.11919797 - samples/sec: 146.75 - lr: 0.000030
2021-07-22 23:33:17,027 epoch 28 - iter 20/101 - loss 0.08914484 - samples/sec: 144.33 - lr: 0.000030
2021-07-22 23:33:19,201 epoch 28 - iter 30/101 - loss 0.10760837 - samples/sec: 147.27 - lr: 0.000030
2021-07-22 23:33:21,395 epoch 28 - iter 40/101 - loss 0.11131459 - samples/sec: 145.86 - lr: 0.000030
2021-07-22 23:33:23,450 epoch 28 - iter 50/101 - loss 0.11609313 - samples/sec: 155.78 - lr: 0.000030
2021-07-22 23:33:25,560 epoch 28 - iter 60/101 - loss 0.11730080 - samples/sec: 151.74 - lr: 0.000030
2021-07-22 23:33:27,686 epoch 28 - iter 70/101 - loss 0.11395972 - samples/sec: 150.53 - lr: 0.000030
2021-07-22 23:33:29,891 epoch 28 - iter 80/101 - loss 0.11072135 - samples/sec: 145.23 - lr: 0.000030
2021-07-22 23:33:32,104 epoch 28 - iter 90/101 - loss 0.11395076 - samples/sec: 144.64 - lr: 0.000030
2021-07-22 23:33:34,318 epoch 28 - iter 100/101 - loss 0.11613787 - samples/sec: 144.57 - lr: 0.000030
2021-07-22 23:33:34,382 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:34,383 EPOCH 28 done: loss 0.1156 - lr 0.0000300
2021-07-22 23:33:35,511 DEV : loss 0.06109343469142914 - score 0.9824
Epoch    28: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 23:33:35,522 BAD EPOCHS (no improvement): 4
2021-07-22 23:33:35,523 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:37,726 epoch 29 - iter 10/101 - loss 0.08908764 - samples/sec: 145.32 - lr: 0.000015
2021-07-22 23:33:39,887 epoch 29 - iter 20/101 - loss 0.09903125 - samples/sec: 148.16 - lr: 0.000015
2021-07-22 23:33:42,060 epoch 29 - iter 30/101 - loss 0.09357344 - samples/sec: 147.32 - lr: 0.000015
2021-07-22 23:33:44,252 epoch 29 - iter 40/101 - loss 0.10142349 - samples/sec: 146.03 - lr: 0.000015
2021-07-22 23:33:46,510 epoch 29 - iter 50/101 - loss 0.10993178 - samples/sec: 141.75 - lr: 0.000015
2021-07-22 23:33:48,739 epoch 29 - iter 60/101 - loss 0.10968213 - samples/sec: 143.58 - lr: 0.000015
2021-07-22 23:33:50,847 epoch 29 - iter 70/101 - loss 0.10658582 - samples/sec: 151.89 - lr: 0.000015
2021-07-22 23:33:52,966 epoch 29 - iter 80/101 - loss 0.10081726 - samples/sec: 151.04 - lr: 0.000015
2021-07-22 23:33:55,160 epoch 29 - iter 90/101 - loss 0.09772679 - samples/sec: 145.92 - lr: 0.000015
2021-07-22 23:33:57,303 epoch 29 - iter 100/101 - loss 0.09907349 - samples/sec: 149.37 - lr: 0.000015
2021-07-22 23:33:57,371 ----------------------------------------------------------------------------------------------------
2021-07-22 23:33:57,371 EPOCH 29 done: loss 0.1008 - lr 0.0000150
2021-07-22 23:33:58,501 DEV : loss 0.057248540222644806 - score 0.9837
2021-07-22 23:33:58,512 BAD EPOCHS (no improvement): 1
2021-07-22 23:33:58,513 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:00,676 epoch 30 - iter 10/101 - loss 0.12808176 - samples/sec: 148.01 - lr: 0.000015
2021-07-22 23:34:02,835 epoch 30 - iter 20/101 - loss 0.12098368 - samples/sec: 148.31 - lr: 0.000015
2021-07-22 23:34:04,968 epoch 30 - iter 30/101 - loss 0.10729833 - samples/sec: 150.05 - lr: 0.000015
2021-07-22 23:34:07,114 epoch 30 - iter 40/101 - loss 0.10180085 - samples/sec: 149.16 - lr: 0.000015
2021-07-22 23:34:09,260 epoch 30 - iter 50/101 - loss 0.09790464 - samples/sec: 149.20 - lr: 0.000015
2021-07-22 23:34:11,526 epoch 30 - iter 60/101 - loss 0.09616581 - samples/sec: 141.23 - lr: 0.000015
2021-07-22 23:34:13,729 epoch 30 - iter 70/101 - loss 0.09572032 - samples/sec: 145.35 - lr: 0.000015
2021-07-22 23:34:15,971 epoch 30 - iter 80/101 - loss 0.10012283 - samples/sec: 142.72 - lr: 0.000015
2021-07-22 23:34:18,159 epoch 30 - iter 90/101 - loss 0.09936400 - samples/sec: 146.31 - lr: 0.000015
2021-07-22 23:34:20,320 epoch 30 - iter 100/101 - loss 0.10097865 - samples/sec: 148.14 - lr: 0.000015
2021-07-22 23:34:20,387 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:20,387 EPOCH 30 done: loss 0.1000 - lr 0.0000150
2021-07-22 23:34:21,509 DEV : loss 0.051839567720890045 - score 0.985
2021-07-22 23:34:21,520 BAD EPOCHS (no improvement): 2
2021-07-22 23:34:21,520 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:23,628 epoch 31 - iter 10/101 - loss 0.10283447 - samples/sec: 151.94 - lr: 0.000015
2021-07-22 23:34:25,902 epoch 31 - iter 20/101 - loss 0.10509949 - samples/sec: 140.76 - lr: 0.000015
2021-07-22 23:34:28,063 epoch 31 - iter 30/101 - loss 0.09926410 - samples/sec: 148.18 - lr: 0.000015
2021-07-22 23:34:30,275 epoch 31 - iter 40/101 - loss 0.09927009 - samples/sec: 144.67 - lr: 0.000015
2021-07-22 23:34:32,495 epoch 31 - iter 50/101 - loss 0.10101203 - samples/sec: 144.21 - lr: 0.000015
2021-07-22 23:34:34,591 epoch 31 - iter 60/101 - loss 0.10238275 - samples/sec: 152.69 - lr: 0.000015
2021-07-22 23:34:36,771 epoch 31 - iter 70/101 - loss 0.09919085 - samples/sec: 146.89 - lr: 0.000015
2021-07-22 23:34:38,858 epoch 31 - iter 80/101 - loss 0.09438405 - samples/sec: 153.35 - lr: 0.000015
2021-07-22 23:34:40,955 epoch 31 - iter 90/101 - loss 0.09905896 - samples/sec: 152.68 - lr: 0.000015
2021-07-22 23:34:43,143 epoch 31 - iter 100/101 - loss 0.09537200 - samples/sec: 146.27 - lr: 0.000015
2021-07-22 23:34:43,215 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:43,215 EPOCH 31 done: loss 0.0945 - lr 0.0000150
2021-07-22 23:34:44,333 DEV : loss 0.053176745772361755 - score 0.985
2021-07-22 23:34:44,345 BAD EPOCHS (no improvement): 3
2021-07-22 23:34:44,345 ----------------------------------------------------------------------------------------------------
2021-07-22 23:34:46,488 epoch 32 - iter 10/101 - loss 0.08433064 - samples/sec: 149.47 - lr: 0.000015
2021-07-22 23:34:48,695 epoch 32 - iter 20/101 - loss 0.09360857 - samples/sec: 145.03 - lr: 0.000015
2021-07-22 23:34:50,808 epoch 32 - iter 30/101 - loss 0.10599013 - samples/sec: 151.51 - lr: 0.000015
2021-07-22 23:34:53,016 epoch 32 - iter 40/101 - loss 0.11414906 - samples/sec: 144.97 - lr: 0.000015
2021-07-22 23:34:55,228 epoch 32 - iter 50/101 - loss 0.10859054 - samples/sec: 144.71 - lr: 0.000015
2021-07-22 23:34:57,347 epoch 32 - iter 60/101 - loss 0.10148644 - samples/sec: 151.09 - lr: 0.000015
2021-07-22 23:34:59,439 epoch 32 - iter 70/101 - loss 0.09703121 - samples/sec: 153.01 - lr: 0.000015
2021-07-22 23:35:01,624 epoch 32 - iter 80/101 - loss 0.09396427 - samples/sec: 146.47 - lr: 0.000015
2021-07-22 23:35:03,743 epoch 32 - iter 90/101 - loss 0.09716512 - samples/sec: 151.09 - lr: 0.000015
2021-07-22 23:35:05,938 epoch 32 - iter 100/101 - loss 0.09853638 - samples/sec: 145.83 - lr: 0.000015
2021-07-22 23:35:06,017 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:06,017 EPOCH 32 done: loss 0.0981 - lr 0.0000150
2021-07-22 23:35:07,137 DEV : loss 0.05371572822332382 - score 0.9837
Epoch    32: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 23:35:07,149 BAD EPOCHS (no improvement): 4
2021-07-22 23:35:07,149 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:09,350 epoch 33 - iter 10/101 - loss 0.10880506 - samples/sec: 145.47 - lr: 0.000008
2021-07-22 23:35:11,566 epoch 33 - iter 20/101 - loss 0.10965566 - samples/sec: 144.45 - lr: 0.000008
2021-07-22 23:35:13,746 epoch 33 - iter 30/101 - loss 0.10535789 - samples/sec: 146.85 - lr: 0.000008
2021-07-22 23:35:15,854 epoch 33 - iter 40/101 - loss 0.10640395 - samples/sec: 151.85 - lr: 0.000008
2021-07-22 23:35:18,083 epoch 33 - iter 50/101 - loss 0.10406042 - samples/sec: 143.66 - lr: 0.000008
2021-07-22 23:35:20,287 epoch 33 - iter 60/101 - loss 0.09935572 - samples/sec: 145.22 - lr: 0.000008
2021-07-22 23:35:22,438 epoch 33 - iter 70/101 - loss 0.09910159 - samples/sec: 148.78 - lr: 0.000008
2021-07-22 23:35:24,543 epoch 33 - iter 80/101 - loss 0.09858406 - samples/sec: 152.08 - lr: 0.000008
2021-07-22 23:35:26,674 epoch 33 - iter 90/101 - loss 0.09366541 - samples/sec: 150.20 - lr: 0.000008
2021-07-22 23:35:28,872 epoch 33 - iter 100/101 - loss 0.09587927 - samples/sec: 145.65 - lr: 0.000008
2021-07-22 23:35:28,953 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:28,954 EPOCH 33 done: loss 0.0953 - lr 0.0000075
2021-07-22 23:35:30,080 DEV : loss 0.05069215968251228 - score 0.9864
2021-07-22 23:35:30,092 BAD EPOCHS (no improvement): 1
2021-07-22 23:35:30,092 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:32,338 epoch 34 - iter 10/101 - loss 0.10164833 - samples/sec: 142.54 - lr: 0.000008
2021-07-22 23:35:34,402 epoch 34 - iter 20/101 - loss 0.09343983 - samples/sec: 155.12 - lr: 0.000008
2021-07-22 23:35:36,561 epoch 34 - iter 30/101 - loss 0.09707314 - samples/sec: 148.30 - lr: 0.000008
2021-07-22 23:35:38,828 epoch 34 - iter 40/101 - loss 0.09412323 - samples/sec: 141.19 - lr: 0.000008
2021-07-22 23:35:40,946 epoch 34 - iter 50/101 - loss 0.09198831 - samples/sec: 151.12 - lr: 0.000008
2021-07-22 23:35:43,152 epoch 34 - iter 60/101 - loss 0.09300099 - samples/sec: 145.11 - lr: 0.000008
2021-07-22 23:35:45,287 epoch 34 - iter 70/101 - loss 0.09521477 - samples/sec: 149.88 - lr: 0.000008
2021-07-22 23:35:47,532 epoch 34 - iter 80/101 - loss 0.09693462 - samples/sec: 142.59 - lr: 0.000008
2021-07-22 23:35:49,766 epoch 34 - iter 90/101 - loss 0.09722191 - samples/sec: 143.34 - lr: 0.000008
2021-07-22 23:35:51,844 epoch 34 - iter 100/101 - loss 0.09883163 - samples/sec: 154.06 - lr: 0.000008
2021-07-22 23:35:51,915 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:51,915 EPOCH 34 done: loss 0.0989 - lr 0.0000075
2021-07-22 23:35:53,043 DEV : loss 0.050758086144924164 - score 0.9864
2021-07-22 23:35:53,054 BAD EPOCHS (no improvement): 2
2021-07-22 23:35:53,055 ----------------------------------------------------------------------------------------------------
2021-07-22 23:35:55,113 epoch 35 - iter 10/101 - loss 0.09496266 - samples/sec: 155.61 - lr: 0.000008
2021-07-22 23:35:57,514 epoch 35 - iter 20/101 - loss 0.10150749 - samples/sec: 133.33 - lr: 0.000008
2021-07-22 23:35:59,635 epoch 35 - iter 30/101 - loss 0.09913038 - samples/sec: 150.87 - lr: 0.000008
2021-07-22 23:36:01,822 epoch 35 - iter 40/101 - loss 0.09824513 - samples/sec: 146.37 - lr: 0.000008
2021-07-22 23:36:03,992 epoch 35 - iter 50/101 - loss 0.09933366 - samples/sec: 147.56 - lr: 0.000008
2021-07-22 23:36:06,199 epoch 35 - iter 60/101 - loss 0.09848018 - samples/sec: 145.02 - lr: 0.000008
2021-07-22 23:36:08,310 epoch 35 - iter 70/101 - loss 0.09696489 - samples/sec: 151.62 - lr: 0.000008
2021-07-22 23:36:10,466 epoch 35 - iter 80/101 - loss 0.09986070 - samples/sec: 148.47 - lr: 0.000008
2021-07-22 23:36:12,670 epoch 35 - iter 90/101 - loss 0.09834897 - samples/sec: 145.27 - lr: 0.000008
2021-07-22 23:36:14,910 epoch 35 - iter 100/101 - loss 0.09939738 - samples/sec: 142.87 - lr: 0.000008
2021-07-22 23:36:14,973 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:14,974 EPOCH 35 done: loss 0.0984 - lr 0.0000075
2021-07-22 23:36:16,098 DEV : loss 0.05188123136758804 - score 0.985
2021-07-22 23:36:16,110 BAD EPOCHS (no improvement): 3
2021-07-22 23:36:16,110 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:18,259 epoch 36 - iter 10/101 - loss 0.14200952 - samples/sec: 149.02 - lr: 0.000008
2021-07-22 23:36:20,482 epoch 36 - iter 20/101 - loss 0.13473818 - samples/sec: 144.00 - lr: 0.000008
2021-07-22 23:36:22,739 epoch 36 - iter 30/101 - loss 0.11633209 - samples/sec: 141.82 - lr: 0.000008
2021-07-22 23:36:24,877 epoch 36 - iter 40/101 - loss 0.11033229 - samples/sec: 149.77 - lr: 0.000008
2021-07-22 23:36:26,980 epoch 36 - iter 50/101 - loss 0.10429695 - samples/sec: 152.17 - lr: 0.000008
2021-07-22 23:36:29,183 epoch 36 - iter 60/101 - loss 0.10770289 - samples/sec: 145.31 - lr: 0.000008
2021-07-22 23:36:31,362 epoch 36 - iter 70/101 - loss 0.10745886 - samples/sec: 146.91 - lr: 0.000008
2021-07-22 23:36:33,587 epoch 36 - iter 80/101 - loss 0.11049587 - samples/sec: 143.85 - lr: 0.000008
2021-07-22 23:36:35,735 epoch 36 - iter 90/101 - loss 0.10301026 - samples/sec: 149.03 - lr: 0.000008
2021-07-22 23:36:37,919 epoch 36 - iter 100/101 - loss 0.10075003 - samples/sec: 146.56 - lr: 0.000008
2021-07-22 23:36:37,993 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:37,993 EPOCH 36 done: loss 0.1013 - lr 0.0000075
2021-07-22 23:36:39,113 DEV : loss 0.05409499630331993 - score 0.9824
Epoch    36: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 23:36:39,125 BAD EPOCHS (no improvement): 4
2021-07-22 23:36:39,125 ----------------------------------------------------------------------------------------------------
2021-07-22 23:36:41,351 epoch 37 - iter 10/101 - loss 0.09573832 - samples/sec: 143.88 - lr: 0.000004
2021-07-22 23:36:43,558 epoch 37 - iter 20/101 - loss 0.09674858 - samples/sec: 145.05 - lr: 0.000004
2021-07-22 23:36:45,698 epoch 37 - iter 30/101 - loss 0.09793441 - samples/sec: 149.60 - lr: 0.000004
2021-07-22 23:36:47,944 epoch 37 - iter 40/101 - loss 0.10126671 - samples/sec: 142.46 - lr: 0.000004
2021-07-22 23:36:50,002 epoch 37 - iter 50/101 - loss 0.10269501 - samples/sec: 155.55 - lr: 0.000004
2021-07-22 23:36:52,147 epoch 37 - iter 60/101 - loss 0.10484531 - samples/sec: 149.29 - lr: 0.000004
2021-07-22 23:36:54,347 epoch 37 - iter 70/101 - loss 0.10526412 - samples/sec: 145.49 - lr: 0.000004
2021-07-22 23:36:56,584 epoch 37 - iter 80/101 - loss 0.10513418 - samples/sec: 143.09 - lr: 0.000004
2021-07-22 23:36:58,719 epoch 37 - iter 90/101 - loss 0.09970836 - samples/sec: 149.89 - lr: 0.000004
2021-07-22 23:37:00,923 epoch 37 - iter 100/101 - loss 0.09839599 - samples/sec: 145.25 - lr: 0.000004
2021-07-22 23:37:00,994 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:00,994 EPOCH 37 done: loss 0.0977 - lr 0.0000038
2021-07-22 23:37:02,117 DEV : loss 0.052722424268722534 - score 0.985
2021-07-22 23:37:02,129 BAD EPOCHS (no improvement): 1
2021-07-22 23:37:02,129 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:04,338 epoch 38 - iter 10/101 - loss 0.14545240 - samples/sec: 144.94 - lr: 0.000004
2021-07-22 23:37:06,447 epoch 38 - iter 20/101 - loss 0.12308987 - samples/sec: 151.77 - lr: 0.000004
2021-07-22 23:37:08,584 epoch 38 - iter 30/101 - loss 0.11503946 - samples/sec: 149.80 - lr: 0.000004
2021-07-22 23:37:10,671 epoch 38 - iter 40/101 - loss 0.11375006 - samples/sec: 153.42 - lr: 0.000004
2021-07-22 23:37:12,805 epoch 38 - iter 50/101 - loss 0.10909859 - samples/sec: 150.01 - lr: 0.000004
2021-07-22 23:37:14,914 epoch 38 - iter 60/101 - loss 0.10738568 - samples/sec: 151.73 - lr: 0.000004
2021-07-22 23:37:17,034 epoch 38 - iter 70/101 - loss 0.10215054 - samples/sec: 151.03 - lr: 0.000004
2021-07-22 23:37:19,202 epoch 38 - iter 80/101 - loss 0.09781792 - samples/sec: 147.61 - lr: 0.000004
2021-07-22 23:37:21,451 epoch 38 - iter 90/101 - loss 0.09942257 - samples/sec: 142.35 - lr: 0.000004
2021-07-22 23:37:23,671 epoch 38 - iter 100/101 - loss 0.09808252 - samples/sec: 144.22 - lr: 0.000004
2021-07-22 23:37:23,731 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:23,731 EPOCH 38 done: loss 0.0971 - lr 0.0000038
2021-07-22 23:37:24,851 DEV : loss 0.051705047488212585 - score 0.985
2021-07-22 23:37:24,863 BAD EPOCHS (no improvement): 2
2021-07-22 23:37:24,863 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:26,958 epoch 39 - iter 10/101 - loss 0.09715639 - samples/sec: 152.84 - lr: 0.000004
2021-07-22 23:37:29,168 epoch 39 - iter 20/101 - loss 0.08703842 - samples/sec: 144.86 - lr: 0.000004
2021-07-22 23:37:31,412 epoch 39 - iter 30/101 - loss 0.09048454 - samples/sec: 142.68 - lr: 0.000004
2021-07-22 23:37:33,472 epoch 39 - iter 40/101 - loss 0.08981521 - samples/sec: 155.36 - lr: 0.000004
2021-07-22 23:37:35,754 epoch 39 - iter 50/101 - loss 0.09073189 - samples/sec: 140.30 - lr: 0.000004
2021-07-22 23:37:38,004 epoch 39 - iter 60/101 - loss 0.09261833 - samples/sec: 142.22 - lr: 0.000004
2021-07-22 23:37:40,175 epoch 39 - iter 70/101 - loss 0.09176234 - samples/sec: 147.50 - lr: 0.000004
2021-07-22 23:37:42,254 epoch 39 - iter 80/101 - loss 0.09066715 - samples/sec: 157.81 - lr: 0.000004
2021-07-22 23:37:44,414 epoch 39 - iter 90/101 - loss 0.08876621 - samples/sec: 148.20 - lr: 0.000004
2021-07-22 23:37:46,570 epoch 39 - iter 100/101 - loss 0.09139003 - samples/sec: 148.47 - lr: 0.000004
2021-07-22 23:37:46,662 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:46,662 EPOCH 39 done: loss 0.0906 - lr 0.0000038
2021-07-22 23:37:47,795 DEV : loss 0.0521833635866642 - score 0.985
2021-07-22 23:37:47,807 BAD EPOCHS (no improvement): 3
2021-07-22 23:37:47,807 ----------------------------------------------------------------------------------------------------
2021-07-22 23:37:50,066 epoch 40 - iter 10/101 - loss 0.12336133 - samples/sec: 141.83 - lr: 0.000004
2021-07-22 23:37:52,180 epoch 40 - iter 20/101 - loss 0.11403417 - samples/sec: 151.37 - lr: 0.000004
2021-07-22 23:37:54,319 epoch 40 - iter 30/101 - loss 0.10626981 - samples/sec: 149.68 - lr: 0.000004
2021-07-22 23:37:56,511 epoch 40 - iter 40/101 - loss 0.10648825 - samples/sec: 146.05 - lr: 0.000004
2021-07-22 23:37:58,727 epoch 40 - iter 50/101 - loss 0.10147666 - samples/sec: 144.46 - lr: 0.000004
2021-07-22 23:38:00,855 epoch 40 - iter 60/101 - loss 0.09959080 - samples/sec: 150.36 - lr: 0.000004
2021-07-22 23:38:03,133 epoch 40 - iter 70/101 - loss 0.09757134 - samples/sec: 140.55 - lr: 0.000004
2021-07-22 23:38:05,328 epoch 40 - iter 80/101 - loss 0.09754314 - samples/sec: 145.85 - lr: 0.000004
2021-07-22 23:38:07,427 epoch 40 - iter 90/101 - loss 0.09861494 - samples/sec: 152.46 - lr: 0.000004
2021-07-22 23:38:09,627 epoch 40 - iter 100/101 - loss 0.10006744 - samples/sec: 145.53 - lr: 0.000004
2021-07-22 23:38:09,686 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:09,686 EPOCH 40 done: loss 0.0992 - lr 0.0000038
2021-07-22 23:38:10,806 DEV : loss 0.051609255373477936 - score 0.985
Epoch    40: reducing learning rate of group 0 to 1.8750e-06.
2021-07-22 23:38:10,817 BAD EPOCHS (no improvement): 4
2021-07-22 23:38:11,389 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:11,389 Testing using best model ...
2021-07-22 23:38:11,390 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/deu.rst.pcc/best-model.pt
2021-07-22 23:38:26,593 0.9821	0.9859	0.9840
2021-07-22 23:38:26,593 
Results:
- F1-score (micro) 0.9840
- F1-score (macro) 0.9861

By class:
SENT       tp: 436 - fp: 14 - fn: 11 - precision: 0.9689 - recall: 0.9754 - f1-score: 0.9721
X          tp: 331 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 23:38:26,593 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/spa.rst.sctb/
2021-07-22 23:38:26,617 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/spa.rst.sctb
2021-07-22 23:38:26,617 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/spa.rst.sctb/sent_train.txt
2021-07-22 23:38:26,618 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/spa.rst.sctb/sent_dev.txt
2021-07-22 23:38:26,619 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/spa.rst.sctb/sent_test.txt
Corpus: 1050 train + 302 dev + 233 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 23:38:28,808 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:28,810 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 23:38:28,810 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:28,810 Corpus: "Corpus: 1050 train + 302 dev + 233 test sentences"
2021-07-22 23:38:28,810 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:28,810 Parameters:
2021-07-22 23:38:28,810  - learning_rate: "3e-05"
2021-07-22 23:38:28,810  - mini_batch_size: "32"
2021-07-22 23:38:28,810  - patience: "3"
2021-07-22 23:38:28,810  - anneal_factor: "0.5"
2021-07-22 23:38:28,810  - max_epochs: "40"
2021-07-22 23:38:28,810  - shuffle: "True"
2021-07-22 23:38:28,810  - train_with_dev: "False"
2021-07-22 23:38:28,810  - batch_growth_annealing: "False"
2021-07-22 23:38:28,810 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:28,810 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/spa.rst.sctb"
2021-07-22 23:38:28,810 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:28,810 Device: cuda:0
2021-07-22 23:38:28,810 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:28,810 Embeddings storage mode: cpu
2021-07-22 23:38:28,813 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:30,528 epoch 1 - iter 3/33 - loss 16.46142387 - samples/sec: 55.99 - lr: 0.000030
2021-07-22 23:38:32,238 epoch 1 - iter 6/33 - loss 16.12283897 - samples/sec: 56.17 - lr: 0.000030
2021-07-22 23:38:33,970 epoch 1 - iter 9/33 - loss 15.69267273 - samples/sec: 55.41 - lr: 0.000030
2021-07-22 23:38:35,730 epoch 1 - iter 12/33 - loss 15.34853109 - samples/sec: 54.58 - lr: 0.000030
2021-07-22 23:38:37,525 epoch 1 - iter 15/33 - loss 15.14308033 - samples/sec: 53.49 - lr: 0.000030
2021-07-22 23:38:39,319 epoch 1 - iter 18/33 - loss 14.92218124 - samples/sec: 53.50 - lr: 0.000030
2021-07-22 23:38:41,104 epoch 1 - iter 21/33 - loss 14.59087926 - samples/sec: 53.80 - lr: 0.000030
2021-07-22 23:38:42,850 epoch 1 - iter 24/33 - loss 14.14180919 - samples/sec: 54.98 - lr: 0.000030
2021-07-22 23:38:44,936 epoch 1 - iter 27/33 - loss 13.63393784 - samples/sec: 46.02 - lr: 0.000030
2021-07-22 23:38:46,776 epoch 1 - iter 30/33 - loss 13.27898550 - samples/sec: 52.18 - lr: 0.000030
2021-07-22 23:38:48,455 epoch 1 - iter 33/33 - loss 12.83198490 - samples/sec: 57.18 - lr: 0.000030
2021-07-22 23:38:48,456 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:48,456 EPOCH 1 done: loss 12.8320 - lr 0.0000300
2021-07-22 23:38:52,497 DEV : loss 6.746377468109131 - score 0.0
2021-07-22 23:38:52,506 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:38:53,130 ----------------------------------------------------------------------------------------------------
2021-07-22 23:38:53,845 epoch 2 - iter 3/33 - loss 8.52587859 - samples/sec: 134.53 - lr: 0.000030
2021-07-22 23:38:54,543 epoch 2 - iter 6/33 - loss 7.48689747 - samples/sec: 137.65 - lr: 0.000030
2021-07-22 23:38:55,291 epoch 2 - iter 9/33 - loss 7.48401266 - samples/sec: 128.26 - lr: 0.000030
2021-07-22 23:38:55,931 epoch 2 - iter 12/33 - loss 7.12202104 - samples/sec: 150.15 - lr: 0.000030
2021-07-22 23:38:56,676 epoch 2 - iter 15/33 - loss 7.19541047 - samples/sec: 128.90 - lr: 0.000030
2021-07-22 23:38:57,428 epoch 2 - iter 18/33 - loss 6.96766297 - samples/sec: 127.85 - lr: 0.000030
2021-07-22 23:38:58,221 epoch 2 - iter 21/33 - loss 6.84212848 - samples/sec: 121.11 - lr: 0.000030
2021-07-22 23:38:59,016 epoch 2 - iter 24/33 - loss 6.63765005 - samples/sec: 120.73 - lr: 0.000030
2021-07-22 23:38:59,776 epoch 2 - iter 27/33 - loss 6.47782880 - samples/sec: 126.48 - lr: 0.000030
2021-07-22 23:39:00,500 epoch 2 - iter 30/33 - loss 6.34360288 - samples/sec: 132.66 - lr: 0.000030
2021-07-22 23:39:01,148 epoch 2 - iter 33/33 - loss 6.18447466 - samples/sec: 148.17 - lr: 0.000030
2021-07-22 23:39:01,149 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:01,149 EPOCH 2 done: loss 6.1845 - lr 0.0000300
2021-07-22 23:39:01,916 DEV : loss 2.865377187728882 - score 0.0
2021-07-22 23:39:01,925 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:04,149 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:04,876 epoch 3 - iter 3/33 - loss 3.93183128 - samples/sec: 132.29 - lr: 0.000030
2021-07-22 23:39:05,601 epoch 3 - iter 6/33 - loss 3.97570944 - samples/sec: 132.58 - lr: 0.000030
2021-07-22 23:39:06,315 epoch 3 - iter 9/33 - loss 3.81675013 - samples/sec: 134.54 - lr: 0.000030
2021-07-22 23:39:07,137 epoch 3 - iter 12/33 - loss 3.63093815 - samples/sec: 116.83 - lr: 0.000030
2021-07-22 23:39:07,812 epoch 3 - iter 15/33 - loss 3.48140445 - samples/sec: 142.24 - lr: 0.000030
2021-07-22 23:39:08,540 epoch 3 - iter 18/33 - loss 3.34058192 - samples/sec: 132.02 - lr: 0.000030
2021-07-22 23:39:09,248 epoch 3 - iter 21/33 - loss 3.25108073 - samples/sec: 135.59 - lr: 0.000030
2021-07-22 23:39:10,008 epoch 3 - iter 24/33 - loss 3.18833702 - samples/sec: 126.46 - lr: 0.000030
2021-07-22 23:39:10,708 epoch 3 - iter 27/33 - loss 3.13405349 - samples/sec: 137.08 - lr: 0.000030
2021-07-22 23:39:11,491 epoch 3 - iter 30/33 - loss 3.05515710 - samples/sec: 122.68 - lr: 0.000030
2021-07-22 23:39:12,160 epoch 3 - iter 33/33 - loss 2.99712529 - samples/sec: 143.59 - lr: 0.000030
2021-07-22 23:39:12,161 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:12,161 EPOCH 3 done: loss 2.9971 - lr 0.0000300
2021-07-22 23:39:12,921 DEV : loss 1.9758132696151733 - score 0.0
2021-07-22 23:39:12,930 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:15,211 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:15,929 epoch 4 - iter 3/33 - loss 2.18738763 - samples/sec: 134.05 - lr: 0.000030
2021-07-22 23:39:16,635 epoch 4 - iter 6/33 - loss 2.28922625 - samples/sec: 136.08 - lr: 0.000030
2021-07-22 23:39:17,359 epoch 4 - iter 9/33 - loss 2.25991164 - samples/sec: 132.56 - lr: 0.000030
2021-07-22 23:39:18,091 epoch 4 - iter 12/33 - loss 2.12536045 - samples/sec: 131.25 - lr: 0.000030
2021-07-22 23:39:18,811 epoch 4 - iter 15/33 - loss 2.06738221 - samples/sec: 133.31 - lr: 0.000030
2021-07-22 23:39:19,547 epoch 4 - iter 18/33 - loss 1.99159293 - samples/sec: 130.54 - lr: 0.000030
2021-07-22 23:39:20,307 epoch 4 - iter 21/33 - loss 1.94510173 - samples/sec: 126.47 - lr: 0.000030
2021-07-22 23:39:21,068 epoch 4 - iter 24/33 - loss 1.88295468 - samples/sec: 126.20 - lr: 0.000030
2021-07-22 23:39:21,764 epoch 4 - iter 27/33 - loss 1.83839084 - samples/sec: 137.96 - lr: 0.000030
2021-07-22 23:39:22,516 epoch 4 - iter 30/33 - loss 1.80691541 - samples/sec: 127.66 - lr: 0.000030
2021-07-22 23:39:23,220 epoch 4 - iter 33/33 - loss 1.77445045 - samples/sec: 136.63 - lr: 0.000030
2021-07-22 23:39:23,220 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:23,220 EPOCH 4 done: loss 1.7745 - lr 0.0000300
2021-07-22 23:39:23,994 DEV : loss 1.1253398656845093 - score 0.7595
2021-07-22 23:39:24,003 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:25,817 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:26,573 epoch 5 - iter 3/33 - loss 1.45862758 - samples/sec: 127.47 - lr: 0.000030
2021-07-22 23:39:27,323 epoch 5 - iter 6/33 - loss 1.35992970 - samples/sec: 127.91 - lr: 0.000030
2021-07-22 23:39:27,983 epoch 5 - iter 9/33 - loss 1.31774347 - samples/sec: 145.67 - lr: 0.000030
2021-07-22 23:39:28,699 epoch 5 - iter 12/33 - loss 1.31866725 - samples/sec: 134.13 - lr: 0.000030
2021-07-22 23:39:29,388 epoch 5 - iter 15/33 - loss 1.33300569 - samples/sec: 139.45 - lr: 0.000030
2021-07-22 23:39:30,140 epoch 5 - iter 18/33 - loss 1.32914504 - samples/sec: 127.74 - lr: 0.000030
2021-07-22 23:39:30,897 epoch 5 - iter 21/33 - loss 1.28388912 - samples/sec: 126.81 - lr: 0.000030
2021-07-22 23:39:31,629 epoch 5 - iter 24/33 - loss 1.23997889 - samples/sec: 131.26 - lr: 0.000030
2021-07-22 23:39:32,384 epoch 5 - iter 27/33 - loss 1.21209903 - samples/sec: 127.19 - lr: 0.000030
2021-07-22 23:39:33,171 epoch 5 - iter 30/33 - loss 1.19189349 - samples/sec: 122.00 - lr: 0.000030
2021-07-22 23:39:33,830 epoch 5 - iter 33/33 - loss 1.15733204 - samples/sec: 145.84 - lr: 0.000030
2021-07-22 23:39:33,831 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:33,831 EPOCH 5 done: loss 1.1573 - lr 0.0000300
2021-07-22 23:39:34,593 DEV : loss 0.7426103949546814 - score 0.7595
2021-07-22 23:39:34,602 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:36,932 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:37,664 epoch 6 - iter 3/33 - loss 0.85061169 - samples/sec: 131.53 - lr: 0.000030
2021-07-22 23:39:38,359 epoch 6 - iter 6/33 - loss 0.87461052 - samples/sec: 138.17 - lr: 0.000030
2021-07-22 23:39:39,095 epoch 6 - iter 9/33 - loss 0.85866553 - samples/sec: 130.37 - lr: 0.000030
2021-07-22 23:39:39,796 epoch 6 - iter 12/33 - loss 0.87262516 - samples/sec: 137.02 - lr: 0.000030
2021-07-22 23:39:40,472 epoch 6 - iter 15/33 - loss 0.86890104 - samples/sec: 142.18 - lr: 0.000030
2021-07-22 23:39:41,231 epoch 6 - iter 18/33 - loss 0.87126631 - samples/sec: 126.49 - lr: 0.000030
2021-07-22 23:39:42,005 epoch 6 - iter 21/33 - loss 0.86671066 - samples/sec: 124.18 - lr: 0.000030
2021-07-22 23:39:42,736 epoch 6 - iter 24/33 - loss 0.84609039 - samples/sec: 131.34 - lr: 0.000030
2021-07-22 23:39:43,497 epoch 6 - iter 27/33 - loss 0.86751257 - samples/sec: 126.24 - lr: 0.000030
2021-07-22 23:39:44,259 epoch 6 - iter 30/33 - loss 0.85103138 - samples/sec: 126.08 - lr: 0.000030
2021-07-22 23:39:44,955 epoch 6 - iter 33/33 - loss 0.83600878 - samples/sec: 137.93 - lr: 0.000030
2021-07-22 23:39:44,956 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:44,956 EPOCH 6 done: loss 0.8360 - lr 0.0000300
2021-07-22 23:39:45,719 DEV : loss 0.5263761878013611 - score 0.7595
2021-07-22 23:39:45,728 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:47,960 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:48,744 epoch 7 - iter 3/33 - loss 0.59388556 - samples/sec: 122.95 - lr: 0.000030
2021-07-22 23:39:49,467 epoch 7 - iter 6/33 - loss 0.65014103 - samples/sec: 132.84 - lr: 0.000030
2021-07-22 23:39:50,236 epoch 7 - iter 9/33 - loss 0.70047613 - samples/sec: 124.88 - lr: 0.000030
2021-07-22 23:39:50,959 epoch 7 - iter 12/33 - loss 0.71569024 - samples/sec: 132.87 - lr: 0.000030
2021-07-22 23:39:51,725 epoch 7 - iter 15/33 - loss 0.71288855 - samples/sec: 125.39 - lr: 0.000030
2021-07-22 23:39:52,473 epoch 7 - iter 18/33 - loss 0.69567770 - samples/sec: 128.39 - lr: 0.000030
2021-07-22 23:39:53,169 epoch 7 - iter 21/33 - loss 0.69095986 - samples/sec: 138.05 - lr: 0.000030
2021-07-22 23:39:53,951 epoch 7 - iter 24/33 - loss 0.67632231 - samples/sec: 122.82 - lr: 0.000030
2021-07-22 23:39:54,628 epoch 7 - iter 27/33 - loss 0.66494648 - samples/sec: 141.76 - lr: 0.000030
2021-07-22 23:39:55,331 epoch 7 - iter 30/33 - loss 0.67085006 - samples/sec: 136.59 - lr: 0.000030
2021-07-22 23:39:55,978 epoch 7 - iter 33/33 - loss 0.66207649 - samples/sec: 148.48 - lr: 0.000030
2021-07-22 23:39:55,979 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:55,979 EPOCH 7 done: loss 0.6621 - lr 0.0000300
2021-07-22 23:39:56,739 DEV : loss 0.39367231726646423 - score 0.8049
2021-07-22 23:39:56,748 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:39:59,165 ----------------------------------------------------------------------------------------------------
2021-07-22 23:39:59,908 epoch 8 - iter 3/33 - loss 0.64122985 - samples/sec: 129.44 - lr: 0.000030
2021-07-22 23:40:00,651 epoch 8 - iter 6/33 - loss 0.55182189 - samples/sec: 129.26 - lr: 0.000030
2021-07-22 23:40:01,368 epoch 8 - iter 9/33 - loss 0.58737272 - samples/sec: 134.04 - lr: 0.000030
2021-07-22 23:40:02,116 epoch 8 - iter 12/33 - loss 0.57370168 - samples/sec: 128.40 - lr: 0.000030
2021-07-22 23:40:02,855 epoch 8 - iter 15/33 - loss 0.56668607 - samples/sec: 129.91 - lr: 0.000030
2021-07-22 23:40:03,569 epoch 8 - iter 18/33 - loss 0.56706522 - samples/sec: 134.63 - lr: 0.000030
2021-07-22 23:40:04,348 epoch 8 - iter 21/33 - loss 0.56470409 - samples/sec: 123.20 - lr: 0.000030
2021-07-22 23:40:05,031 epoch 8 - iter 24/33 - loss 0.54672945 - samples/sec: 140.64 - lr: 0.000030
2021-07-22 23:40:05,778 epoch 8 - iter 27/33 - loss 0.53928851 - samples/sec: 128.62 - lr: 0.000030
2021-07-22 23:40:06,474 epoch 8 - iter 30/33 - loss 0.53538070 - samples/sec: 138.05 - lr: 0.000030
2021-07-22 23:40:07,146 epoch 8 - iter 33/33 - loss 0.54009724 - samples/sec: 142.84 - lr: 0.000030
2021-07-22 23:40:07,147 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:07,147 EPOCH 8 done: loss 0.5401 - lr 0.0000300
2021-07-22 23:40:07,908 DEV : loss 0.29451069235801697 - score 0.9377
2021-07-22 23:40:07,917 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:10,131 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:10,928 epoch 9 - iter 3/33 - loss 0.43766299 - samples/sec: 120.95 - lr: 0.000030
2021-07-22 23:40:11,628 epoch 9 - iter 6/33 - loss 0.44160301 - samples/sec: 137.14 - lr: 0.000030
2021-07-22 23:40:12,341 epoch 9 - iter 9/33 - loss 0.45701530 - samples/sec: 134.82 - lr: 0.000030
2021-07-22 23:40:13,080 epoch 9 - iter 12/33 - loss 0.43801453 - samples/sec: 129.81 - lr: 0.000030
2021-07-22 23:40:13,729 epoch 9 - iter 15/33 - loss 0.45396258 - samples/sec: 148.19 - lr: 0.000030
2021-07-22 23:40:14,496 epoch 9 - iter 18/33 - loss 0.44416465 - samples/sec: 125.24 - lr: 0.000030
2021-07-22 23:40:15,249 epoch 9 - iter 21/33 - loss 0.43974620 - samples/sec: 127.57 - lr: 0.000030
2021-07-22 23:40:15,980 epoch 9 - iter 24/33 - loss 0.43988551 - samples/sec: 131.28 - lr: 0.000030
2021-07-22 23:40:16,660 epoch 9 - iter 27/33 - loss 0.45486107 - samples/sec: 141.38 - lr: 0.000030
2021-07-22 23:40:17,428 epoch 9 - iter 30/33 - loss 0.46013242 - samples/sec: 124.91 - lr: 0.000030
2021-07-22 23:40:18,151 epoch 9 - iter 33/33 - loss 0.46149045 - samples/sec: 132.91 - lr: 0.000030
2021-07-22 23:40:18,152 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:18,152 EPOCH 9 done: loss 0.4615 - lr 0.0000300
2021-07-22 23:40:18,918 DEV : loss 0.2290959656238556 - score 0.9549
2021-07-22 23:40:18,927 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:21,107 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:21,841 epoch 10 - iter 3/33 - loss 0.40925886 - samples/sec: 131.21 - lr: 0.000030
2021-07-22 23:40:22,582 epoch 10 - iter 6/33 - loss 0.34816997 - samples/sec: 129.65 - lr: 0.000030
2021-07-22 23:40:23,250 epoch 10 - iter 9/33 - loss 0.43500559 - samples/sec: 143.73 - lr: 0.000030
2021-07-22 23:40:23,978 epoch 10 - iter 12/33 - loss 0.42967466 - samples/sec: 131.97 - lr: 0.000030
2021-07-22 23:40:24,787 epoch 10 - iter 15/33 - loss 0.40968890 - samples/sec: 118.66 - lr: 0.000030
2021-07-22 23:40:25,532 epoch 10 - iter 18/33 - loss 0.37765565 - samples/sec: 128.92 - lr: 0.000030
2021-07-22 23:40:26,301 epoch 10 - iter 21/33 - loss 0.38787359 - samples/sec: 124.98 - lr: 0.000030
2021-07-22 23:40:26,972 epoch 10 - iter 24/33 - loss 0.38369953 - samples/sec: 143.17 - lr: 0.000030
2021-07-22 23:40:27,651 epoch 10 - iter 27/33 - loss 0.37701656 - samples/sec: 141.48 - lr: 0.000030
2021-07-22 23:40:28,439 epoch 10 - iter 30/33 - loss 0.37848966 - samples/sec: 121.87 - lr: 0.000030
2021-07-22 23:40:29,043 epoch 10 - iter 33/33 - loss 0.36925532 - samples/sec: 158.98 - lr: 0.000030
2021-07-22 23:40:29,044 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:29,044 EPOCH 10 done: loss 0.3693 - lr 0.0000300
2021-07-22 23:40:29,808 DEV : loss 0.1826089769601822 - score 0.9634
2021-07-22 23:40:29,817 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:32,086 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:32,860 epoch 11 - iter 3/33 - loss 0.40015779 - samples/sec: 124.45 - lr: 0.000030
2021-07-22 23:40:33,615 epoch 11 - iter 6/33 - loss 0.32313896 - samples/sec: 127.26 - lr: 0.000030
2021-07-22 23:40:34,343 epoch 11 - iter 9/33 - loss 0.30805359 - samples/sec: 131.87 - lr: 0.000030
2021-07-22 23:40:35,075 epoch 11 - iter 12/33 - loss 0.31693887 - samples/sec: 131.28 - lr: 0.000030
2021-07-22 23:40:35,764 epoch 11 - iter 15/33 - loss 0.31607727 - samples/sec: 139.27 - lr: 0.000030
2021-07-22 23:40:36,491 epoch 11 - iter 18/33 - loss 0.30550524 - samples/sec: 132.16 - lr: 0.000030
2021-07-22 23:40:37,244 epoch 11 - iter 21/33 - loss 0.31162140 - samples/sec: 127.55 - lr: 0.000030
2021-07-22 23:40:38,008 epoch 11 - iter 24/33 - loss 0.31532833 - samples/sec: 125.70 - lr: 0.000030
2021-07-22 23:40:38,736 epoch 11 - iter 27/33 - loss 0.32814268 - samples/sec: 132.03 - lr: 0.000030
2021-07-22 23:40:39,388 epoch 11 - iter 30/33 - loss 0.32981312 - samples/sec: 147.43 - lr: 0.000030
2021-07-22 23:40:40,046 epoch 11 - iter 33/33 - loss 0.33298256 - samples/sec: 145.89 - lr: 0.000030
2021-07-22 23:40:40,048 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:40,048 EPOCH 11 done: loss 0.3330 - lr 0.0000300
2021-07-22 23:40:40,813 DEV : loss 0.1502017229795456 - score 0.9661
2021-07-22 23:40:40,822 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:43,086 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:43,797 epoch 12 - iter 3/33 - loss 0.34072446 - samples/sec: 135.34 - lr: 0.000030
2021-07-22 23:40:44,573 epoch 12 - iter 6/33 - loss 0.31671344 - samples/sec: 123.78 - lr: 0.000030
2021-07-22 23:40:45,323 epoch 12 - iter 9/33 - loss 0.31419837 - samples/sec: 128.08 - lr: 0.000030
2021-07-22 23:40:46,047 epoch 12 - iter 12/33 - loss 0.30382047 - samples/sec: 132.63 - lr: 0.000030
2021-07-22 23:40:46,810 epoch 12 - iter 15/33 - loss 0.30886013 - samples/sec: 125.81 - lr: 0.000030
2021-07-22 23:40:47,528 epoch 12 - iter 18/33 - loss 0.32471670 - samples/sec: 133.81 - lr: 0.000030
2021-07-22 23:40:48,247 epoch 12 - iter 21/33 - loss 0.30898590 - samples/sec: 133.72 - lr: 0.000030
2021-07-22 23:40:49,019 epoch 12 - iter 24/33 - loss 0.29649776 - samples/sec: 124.38 - lr: 0.000030
2021-07-22 23:40:49,742 epoch 12 - iter 27/33 - loss 0.28585962 - samples/sec: 132.78 - lr: 0.000030
2021-07-22 23:40:50,476 epoch 12 - iter 30/33 - loss 0.29182904 - samples/sec: 130.81 - lr: 0.000030
2021-07-22 23:40:51,139 epoch 12 - iter 33/33 - loss 0.29083978 - samples/sec: 145.02 - lr: 0.000030
2021-07-22 23:40:51,140 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:51,140 EPOCH 12 done: loss 0.2908 - lr 0.0000300
2021-07-22 23:40:51,904 DEV : loss 0.12882183492183685 - score 0.9688
2021-07-22 23:40:51,913 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:40:54,079 ----------------------------------------------------------------------------------------------------
2021-07-22 23:40:54,823 epoch 13 - iter 3/33 - loss 0.15970269 - samples/sec: 129.38 - lr: 0.000030
2021-07-22 23:40:55,528 epoch 13 - iter 6/33 - loss 0.20648815 - samples/sec: 136.28 - lr: 0.000030
2021-07-22 23:40:56,235 epoch 13 - iter 9/33 - loss 0.24888036 - samples/sec: 135.86 - lr: 0.000030
2021-07-22 23:40:57,016 epoch 13 - iter 12/33 - loss 0.25950687 - samples/sec: 122.98 - lr: 0.000030
2021-07-22 23:40:57,700 epoch 13 - iter 15/33 - loss 0.24842778 - samples/sec: 140.47 - lr: 0.000030
2021-07-22 23:40:58,414 epoch 13 - iter 18/33 - loss 0.25734496 - samples/sec: 134.44 - lr: 0.000030
2021-07-22 23:40:59,157 epoch 13 - iter 21/33 - loss 0.25685980 - samples/sec: 129.39 - lr: 0.000030
2021-07-22 23:40:59,843 epoch 13 - iter 24/33 - loss 0.25555752 - samples/sec: 139.87 - lr: 0.000030
2021-07-22 23:41:00,603 epoch 13 - iter 27/33 - loss 0.26282692 - samples/sec: 126.38 - lr: 0.000030
2021-07-22 23:41:01,363 epoch 13 - iter 30/33 - loss 0.25948917 - samples/sec: 126.37 - lr: 0.000030
2021-07-22 23:41:02,056 epoch 13 - iter 33/33 - loss 0.25493421 - samples/sec: 138.69 - lr: 0.000030
2021-07-22 23:41:02,058 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:02,058 EPOCH 13 done: loss 0.2549 - lr 0.0000300
2021-07-22 23:41:02,822 DEV : loss 0.10859868675470352 - score 0.9767
2021-07-22 23:41:02,831 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:41:05,021 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:05,774 epoch 14 - iter 3/33 - loss 0.41636928 - samples/sec: 127.87 - lr: 0.000030
2021-07-22 23:41:06,516 epoch 14 - iter 6/33 - loss 0.29050530 - samples/sec: 129.43 - lr: 0.000030
2021-07-22 23:41:07,265 epoch 14 - iter 9/33 - loss 0.25413649 - samples/sec: 128.26 - lr: 0.000030
2021-07-22 23:41:07,990 epoch 14 - iter 12/33 - loss 0.23649082 - samples/sec: 132.46 - lr: 0.000030
2021-07-22 23:41:08,724 epoch 14 - iter 15/33 - loss 0.23372422 - samples/sec: 130.87 - lr: 0.000030
2021-07-22 23:41:09,507 epoch 14 - iter 18/33 - loss 0.22526006 - samples/sec: 122.61 - lr: 0.000030
2021-07-22 23:41:10,188 epoch 14 - iter 21/33 - loss 0.21926747 - samples/sec: 141.08 - lr: 0.000030
2021-07-22 23:41:10,911 epoch 14 - iter 24/33 - loss 0.21598318 - samples/sec: 132.80 - lr: 0.000030
2021-07-22 23:41:11,616 epoch 14 - iter 27/33 - loss 0.22170409 - samples/sec: 136.29 - lr: 0.000030
2021-07-22 23:41:12,314 epoch 14 - iter 30/33 - loss 0.21854471 - samples/sec: 137.57 - lr: 0.000030
2021-07-22 23:41:13,010 epoch 14 - iter 33/33 - loss 0.22552512 - samples/sec: 138.00 - lr: 0.000030
2021-07-22 23:41:13,011 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:13,011 EPOCH 14 done: loss 0.2255 - lr 0.0000300
2021-07-22 23:41:13,771 DEV : loss 0.0962006226181984 - score 0.9767
2021-07-22 23:41:13,780 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:41:16,006 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:16,749 epoch 15 - iter 3/33 - loss 0.24168157 - samples/sec: 129.59 - lr: 0.000030
2021-07-22 23:41:17,488 epoch 15 - iter 6/33 - loss 0.18930868 - samples/sec: 129.99 - lr: 0.000030
2021-07-22 23:41:18,200 epoch 15 - iter 9/33 - loss 0.18759610 - samples/sec: 134.79 - lr: 0.000030
2021-07-22 23:41:18,855 epoch 15 - iter 12/33 - loss 0.21735514 - samples/sec: 146.84 - lr: 0.000030
2021-07-22 23:41:19,565 epoch 15 - iter 15/33 - loss 0.20013326 - samples/sec: 135.28 - lr: 0.000030
2021-07-22 23:41:20,328 epoch 15 - iter 18/33 - loss 0.21127381 - samples/sec: 125.75 - lr: 0.000030
2021-07-22 23:41:21,115 epoch 15 - iter 21/33 - loss 0.21849136 - samples/sec: 122.08 - lr: 0.000030
2021-07-22 23:41:21,848 epoch 15 - iter 24/33 - loss 0.22810769 - samples/sec: 131.06 - lr: 0.000030
2021-07-22 23:41:22,560 epoch 15 - iter 27/33 - loss 0.22466747 - samples/sec: 134.94 - lr: 0.000030
2021-07-22 23:41:23,277 epoch 15 - iter 30/33 - loss 0.22497477 - samples/sec: 134.00 - lr: 0.000030
2021-07-22 23:41:24,008 epoch 15 - iter 33/33 - loss 0.22291404 - samples/sec: 131.30 - lr: 0.000030
2021-07-22 23:41:24,009 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:24,009 EPOCH 15 done: loss 0.2229 - lr 0.0000300
2021-07-22 23:41:24,769 DEV : loss 0.0866871327161789 - score 0.9846
2021-07-22 23:41:24,778 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:41:28,073 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:28,813 epoch 16 - iter 3/33 - loss 0.28284508 - samples/sec: 129.97 - lr: 0.000030
2021-07-22 23:41:29,536 epoch 16 - iter 6/33 - loss 0.21354606 - samples/sec: 132.81 - lr: 0.000030
2021-07-22 23:41:30,284 epoch 16 - iter 9/33 - loss 0.21100399 - samples/sec: 128.55 - lr: 0.000030
2021-07-22 23:41:30,998 epoch 16 - iter 12/33 - loss 0.22571738 - samples/sec: 134.39 - lr: 0.000030
2021-07-22 23:41:31,680 epoch 16 - iter 15/33 - loss 0.23128523 - samples/sec: 140.83 - lr: 0.000030
2021-07-22 23:41:32,463 epoch 16 - iter 18/33 - loss 0.23619962 - samples/sec: 122.77 - lr: 0.000030
2021-07-22 23:41:33,122 epoch 16 - iter 21/33 - loss 0.21642499 - samples/sec: 145.66 - lr: 0.000030
2021-07-22 23:41:33,897 epoch 16 - iter 24/33 - loss 0.21124110 - samples/sec: 124.03 - lr: 0.000030
2021-07-22 23:41:34,615 epoch 16 - iter 27/33 - loss 0.20198825 - samples/sec: 133.75 - lr: 0.000030
2021-07-22 23:41:35,415 epoch 16 - iter 30/33 - loss 0.20693827 - samples/sec: 120.00 - lr: 0.000030
2021-07-22 23:41:36,083 epoch 16 - iter 33/33 - loss 0.20854005 - samples/sec: 143.74 - lr: 0.000030
2021-07-22 23:41:36,084 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:36,084 EPOCH 16 done: loss 0.2085 - lr 0.0000300
2021-07-22 23:41:36,844 DEV : loss 0.07954533398151398 - score 0.9846
2021-07-22 23:41:36,852 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:41:39,092 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:39,831 epoch 17 - iter 3/33 - loss 0.09520561 - samples/sec: 130.20 - lr: 0.000030
2021-07-22 23:41:40,633 epoch 17 - iter 6/33 - loss 0.14436790 - samples/sec: 119.82 - lr: 0.000030
2021-07-22 23:41:41,372 epoch 17 - iter 9/33 - loss 0.19099290 - samples/sec: 129.92 - lr: 0.000030
2021-07-22 23:41:42,002 epoch 17 - iter 12/33 - loss 0.16456755 - samples/sec: 152.45 - lr: 0.000030
2021-07-22 23:41:42,652 epoch 17 - iter 15/33 - loss 0.15900565 - samples/sec: 147.84 - lr: 0.000030
2021-07-22 23:41:43,424 epoch 17 - iter 18/33 - loss 0.17824026 - samples/sec: 124.30 - lr: 0.000030
2021-07-22 23:41:44,171 epoch 17 - iter 21/33 - loss 0.19198643 - samples/sec: 128.58 - lr: 0.000030
2021-07-22 23:41:44,905 epoch 17 - iter 24/33 - loss 0.20604525 - samples/sec: 131.01 - lr: 0.000030
2021-07-22 23:41:45,660 epoch 17 - iter 27/33 - loss 0.20299380 - samples/sec: 127.07 - lr: 0.000030
2021-07-22 23:41:46,366 epoch 17 - iter 30/33 - loss 0.19863201 - samples/sec: 136.18 - lr: 0.000030
2021-07-22 23:41:47,027 epoch 17 - iter 33/33 - loss 0.19847851 - samples/sec: 145.34 - lr: 0.000030
2021-07-22 23:41:47,028 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:47,028 EPOCH 17 done: loss 0.1985 - lr 0.0000300
2021-07-22 23:41:47,793 DEV : loss 0.07326264679431915 - score 0.9821
2021-07-22 23:41:47,802 BAD EPOCHS (no improvement): 1
2021-07-22 23:41:47,802 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:48,522 epoch 18 - iter 3/33 - loss 0.33230346 - samples/sec: 133.53 - lr: 0.000030
2021-07-22 23:41:49,389 epoch 18 - iter 6/33 - loss 0.20678890 - samples/sec: 110.83 - lr: 0.000030
2021-07-22 23:41:50,124 epoch 18 - iter 9/33 - loss 0.20890227 - samples/sec: 130.55 - lr: 0.000030
2021-07-22 23:41:50,795 epoch 18 - iter 12/33 - loss 0.21529823 - samples/sec: 143.25 - lr: 0.000030
2021-07-22 23:41:51,544 epoch 18 - iter 15/33 - loss 0.19975637 - samples/sec: 128.15 - lr: 0.000030
2021-07-22 23:41:52,250 epoch 18 - iter 18/33 - loss 0.19419385 - samples/sec: 136.03 - lr: 0.000030
2021-07-22 23:41:52,970 epoch 18 - iter 21/33 - loss 0.20829462 - samples/sec: 133.42 - lr: 0.000030
2021-07-22 23:41:53,706 epoch 18 - iter 24/33 - loss 0.19497216 - samples/sec: 130.61 - lr: 0.000030
2021-07-22 23:41:54,374 epoch 18 - iter 27/33 - loss 0.18675863 - samples/sec: 143.81 - lr: 0.000030
2021-07-22 23:41:55,092 epoch 18 - iter 30/33 - loss 0.18529240 - samples/sec: 133.74 - lr: 0.000030
2021-07-22 23:41:55,822 epoch 18 - iter 33/33 - loss 0.18725582 - samples/sec: 131.46 - lr: 0.000030
2021-07-22 23:41:55,823 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:55,823 EPOCH 18 done: loss 0.1873 - lr 0.0000300
2021-07-22 23:41:56,587 DEV : loss 0.06871403753757477 - score 0.9821
2021-07-22 23:41:56,596 BAD EPOCHS (no improvement): 2
2021-07-22 23:41:56,596 ----------------------------------------------------------------------------------------------------
2021-07-22 23:41:57,380 epoch 19 - iter 3/33 - loss 0.16760650 - samples/sec: 122.68 - lr: 0.000030
2021-07-22 23:41:58,095 epoch 19 - iter 6/33 - loss 0.20564298 - samples/sec: 134.23 - lr: 0.000030
2021-07-22 23:41:58,875 epoch 19 - iter 9/33 - loss 0.18839056 - samples/sec: 123.15 - lr: 0.000030
2021-07-22 23:41:59,616 epoch 19 - iter 12/33 - loss 0.17940022 - samples/sec: 129.60 - lr: 0.000030
2021-07-22 23:42:00,323 epoch 19 - iter 15/33 - loss 0.17534210 - samples/sec: 135.88 - lr: 0.000030
2021-07-22 23:42:01,011 epoch 19 - iter 18/33 - loss 0.17205663 - samples/sec: 139.70 - lr: 0.000030
2021-07-22 23:42:01,708 epoch 19 - iter 21/33 - loss 0.17884073 - samples/sec: 137.70 - lr: 0.000030
2021-07-22 23:42:02,447 epoch 19 - iter 24/33 - loss 0.16808142 - samples/sec: 130.14 - lr: 0.000030
2021-07-22 23:42:03,119 epoch 19 - iter 27/33 - loss 0.16852585 - samples/sec: 142.98 - lr: 0.000030
2021-07-22 23:42:03,809 epoch 19 - iter 30/33 - loss 0.17219270 - samples/sec: 139.03 - lr: 0.000030
2021-07-22 23:42:04,534 epoch 19 - iter 33/33 - loss 0.17094184 - samples/sec: 132.60 - lr: 0.000030
2021-07-22 23:42:04,535 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:04,535 EPOCH 19 done: loss 0.1709 - lr 0.0000300
2021-07-22 23:42:05,299 DEV : loss 0.06493481993675232 - score 0.9821
2021-07-22 23:42:05,308 BAD EPOCHS (no improvement): 3
2021-07-22 23:42:05,308 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:05,961 epoch 20 - iter 3/33 - loss 0.12056185 - samples/sec: 147.39 - lr: 0.000030
2021-07-22 23:42:06,689 epoch 20 - iter 6/33 - loss 0.13331840 - samples/sec: 131.96 - lr: 0.000030
2021-07-22 23:42:07,450 epoch 20 - iter 9/33 - loss 0.11665871 - samples/sec: 126.10 - lr: 0.000030
2021-07-22 23:42:08,176 epoch 20 - iter 12/33 - loss 0.15099265 - samples/sec: 132.31 - lr: 0.000030
2021-07-22 23:42:08,863 epoch 20 - iter 15/33 - loss 0.16160529 - samples/sec: 139.94 - lr: 0.000030
2021-07-22 23:42:09,530 epoch 20 - iter 18/33 - loss 0.16113666 - samples/sec: 144.11 - lr: 0.000030
2021-07-22 23:42:10,253 epoch 20 - iter 21/33 - loss 0.15495377 - samples/sec: 132.78 - lr: 0.000030
2021-07-22 23:42:10,973 epoch 20 - iter 24/33 - loss 0.16866641 - samples/sec: 133.46 - lr: 0.000030
2021-07-22 23:42:11,719 epoch 20 - iter 27/33 - loss 0.16450738 - samples/sec: 128.80 - lr: 0.000030
2021-07-22 23:42:12,523 epoch 20 - iter 30/33 - loss 0.16930770 - samples/sec: 119.41 - lr: 0.000030
2021-07-22 23:42:13,231 epoch 20 - iter 33/33 - loss 0.16647911 - samples/sec: 135.81 - lr: 0.000030
2021-07-22 23:42:13,231 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:13,232 EPOCH 20 done: loss 0.1665 - lr 0.0000300
2021-07-22 23:42:13,995 DEV : loss 0.06199014186859131 - score 0.9821
Epoch    20: reducing learning rate of group 0 to 1.5000e-05.
2021-07-22 23:42:14,008 BAD EPOCHS (no improvement): 4
2021-07-22 23:42:14,008 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:14,759 epoch 21 - iter 3/33 - loss 0.14484929 - samples/sec: 128.08 - lr: 0.000015
2021-07-22 23:42:15,375 epoch 21 - iter 6/33 - loss 0.16893268 - samples/sec: 155.82 - lr: 0.000015
2021-07-22 23:42:16,116 epoch 21 - iter 9/33 - loss 0.17057620 - samples/sec: 129.61 - lr: 0.000015
2021-07-22 23:42:16,859 epoch 21 - iter 12/33 - loss 0.15445466 - samples/sec: 129.39 - lr: 0.000015
2021-07-22 23:42:17,540 epoch 21 - iter 15/33 - loss 0.15351213 - samples/sec: 141.02 - lr: 0.000015
2021-07-22 23:42:18,275 epoch 21 - iter 18/33 - loss 0.15123044 - samples/sec: 130.77 - lr: 0.000015
2021-07-22 23:42:19,068 epoch 21 - iter 21/33 - loss 0.15048591 - samples/sec: 121.12 - lr: 0.000015
2021-07-22 23:42:19,797 epoch 21 - iter 24/33 - loss 0.14641710 - samples/sec: 131.75 - lr: 0.000015
2021-07-22 23:42:20,491 epoch 21 - iter 27/33 - loss 0.15866778 - samples/sec: 138.26 - lr: 0.000015
2021-07-22 23:42:21,272 epoch 21 - iter 30/33 - loss 0.17131015 - samples/sec: 123.05 - lr: 0.000015
2021-07-22 23:42:21,976 epoch 21 - iter 33/33 - loss 0.16813445 - samples/sec: 136.46 - lr: 0.000015
2021-07-22 23:42:21,977 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:21,977 EPOCH 21 done: loss 0.1681 - lr 0.0000150
2021-07-22 23:42:22,737 DEV : loss 0.060779739171266556 - score 0.9847
2021-07-22 23:42:22,745 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:42:25,109 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:25,848 epoch 22 - iter 3/33 - loss 0.14867743 - samples/sec: 130.25 - lr: 0.000015
2021-07-22 23:42:26,544 epoch 22 - iter 6/33 - loss 0.20831854 - samples/sec: 138.03 - lr: 0.000015
2021-07-22 23:42:27,313 epoch 22 - iter 9/33 - loss 0.16935399 - samples/sec: 124.89 - lr: 0.000015
2021-07-22 23:42:27,997 epoch 22 - iter 12/33 - loss 0.16889613 - samples/sec: 140.39 - lr: 0.000015
2021-07-22 23:42:28,772 epoch 22 - iter 15/33 - loss 0.15969338 - samples/sec: 123.86 - lr: 0.000015
2021-07-22 23:42:29,500 epoch 22 - iter 18/33 - loss 0.14944348 - samples/sec: 132.07 - lr: 0.000015
2021-07-22 23:42:30,242 epoch 22 - iter 21/33 - loss 0.14507305 - samples/sec: 129.31 - lr: 0.000015
2021-07-22 23:42:30,948 epoch 22 - iter 24/33 - loss 0.16907963 - samples/sec: 136.10 - lr: 0.000015
2021-07-22 23:42:31,656 epoch 22 - iter 27/33 - loss 0.16349585 - samples/sec: 135.68 - lr: 0.000015
2021-07-22 23:42:32,359 epoch 22 - iter 30/33 - loss 0.16485983 - samples/sec: 136.54 - lr: 0.000015
2021-07-22 23:42:33,087 epoch 22 - iter 33/33 - loss 0.17079633 - samples/sec: 131.95 - lr: 0.000015
2021-07-22 23:42:33,088 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:33,088 EPOCH 22 done: loss 0.1708 - lr 0.0000150
2021-07-22 23:42:33,855 DEV : loss 0.059432175010442734 - score 0.9821
2021-07-22 23:42:33,863 BAD EPOCHS (no improvement): 1
2021-07-22 23:42:33,864 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:34,594 epoch 23 - iter 3/33 - loss 0.17399772 - samples/sec: 131.56 - lr: 0.000015
2021-07-22 23:42:35,303 epoch 23 - iter 6/33 - loss 0.20290014 - samples/sec: 135.55 - lr: 0.000015
2021-07-22 23:42:36,020 epoch 23 - iter 9/33 - loss 0.17060224 - samples/sec: 133.95 - lr: 0.000015
2021-07-22 23:42:36,747 epoch 23 - iter 12/33 - loss 0.16147874 - samples/sec: 132.17 - lr: 0.000015
2021-07-22 23:42:37,488 epoch 23 - iter 15/33 - loss 0.14765354 - samples/sec: 129.65 - lr: 0.000015
2021-07-22 23:42:38,211 epoch 23 - iter 18/33 - loss 0.14655277 - samples/sec: 132.87 - lr: 0.000015
2021-07-22 23:42:38,969 epoch 23 - iter 21/33 - loss 0.13618536 - samples/sec: 126.59 - lr: 0.000015
2021-07-22 23:42:39,671 epoch 23 - iter 24/33 - loss 0.14614696 - samples/sec: 136.85 - lr: 0.000015
2021-07-22 23:42:40,379 epoch 23 - iter 27/33 - loss 0.14352042 - samples/sec: 135.74 - lr: 0.000015
2021-07-22 23:42:41,104 epoch 23 - iter 30/33 - loss 0.14884991 - samples/sec: 132.38 - lr: 0.000015
2021-07-22 23:42:41,845 epoch 23 - iter 33/33 - loss 0.15070740 - samples/sec: 129.77 - lr: 0.000015
2021-07-22 23:42:41,845 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:41,846 EPOCH 23 done: loss 0.1507 - lr 0.0000150
2021-07-22 23:42:42,610 DEV : loss 0.05917009338736534 - score 0.9847
2021-07-22 23:42:42,619 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:42:44,885 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:45,531 epoch 24 - iter 3/33 - loss 0.20120031 - samples/sec: 149.15 - lr: 0.000015
2021-07-22 23:42:46,335 epoch 24 - iter 6/33 - loss 0.16701684 - samples/sec: 119.40 - lr: 0.000015
2021-07-22 23:42:47,044 epoch 24 - iter 9/33 - loss 0.14603517 - samples/sec: 135.49 - lr: 0.000015
2021-07-22 23:42:47,760 epoch 24 - iter 12/33 - loss 0.14436086 - samples/sec: 134.15 - lr: 0.000015
2021-07-22 23:42:48,499 epoch 24 - iter 15/33 - loss 0.13881697 - samples/sec: 129.95 - lr: 0.000015
2021-07-22 23:42:49,252 epoch 24 - iter 18/33 - loss 0.13012108 - samples/sec: 127.54 - lr: 0.000015
2021-07-22 23:42:50,007 epoch 24 - iter 21/33 - loss 0.14370756 - samples/sec: 127.30 - lr: 0.000015
2021-07-22 23:42:50,693 epoch 24 - iter 24/33 - loss 0.14541647 - samples/sec: 139.97 - lr: 0.000015
2021-07-22 23:42:51,412 epoch 24 - iter 27/33 - loss 0.15063395 - samples/sec: 133.59 - lr: 0.000015
2021-07-22 23:42:52,200 epoch 24 - iter 30/33 - loss 0.14094830 - samples/sec: 121.81 - lr: 0.000015
2021-07-22 23:42:52,896 epoch 24 - iter 33/33 - loss 0.15109604 - samples/sec: 138.15 - lr: 0.000015
2021-07-22 23:42:52,897 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:52,897 EPOCH 24 done: loss 0.1511 - lr 0.0000150
2021-07-22 23:42:53,759 DEV : loss 0.0586840882897377 - score 0.9847
2021-07-22 23:42:53,768 BAD EPOCHS (no improvement): 0
saving best model
2021-07-22 23:42:56,012 ----------------------------------------------------------------------------------------------------
2021-07-22 23:42:56,763 epoch 25 - iter 3/33 - loss 0.14639985 - samples/sec: 128.21 - lr: 0.000015
2021-07-22 23:42:57,465 epoch 25 - iter 6/33 - loss 0.14429004 - samples/sec: 136.87 - lr: 0.000015
2021-07-22 23:42:58,233 epoch 25 - iter 9/33 - loss 0.10967209 - samples/sec: 124.95 - lr: 0.000015
2021-07-22 23:42:58,975 epoch 25 - iter 12/33 - loss 0.12684904 - samples/sec: 129.46 - lr: 0.000015
2021-07-22 23:42:59,707 epoch 25 - iter 15/33 - loss 0.14358722 - samples/sec: 131.24 - lr: 0.000015
2021-07-22 23:43:00,395 epoch 25 - iter 18/33 - loss 0.15689822 - samples/sec: 139.60 - lr: 0.000015
2021-07-22 23:43:01,100 epoch 25 - iter 21/33 - loss 0.14938149 - samples/sec: 136.36 - lr: 0.000015
2021-07-22 23:43:01,820 epoch 25 - iter 24/33 - loss 0.14318601 - samples/sec: 133.40 - lr: 0.000015
2021-07-22 23:43:02,579 epoch 25 - iter 27/33 - loss 0.14584355 - samples/sec: 126.48 - lr: 0.000015
2021-07-22 23:43:03,312 epoch 25 - iter 30/33 - loss 0.14568443 - samples/sec: 131.12 - lr: 0.000015
2021-07-22 23:43:03,999 epoch 25 - iter 33/33 - loss 0.14641843 - samples/sec: 139.71 - lr: 0.000015
2021-07-22 23:43:04,000 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:04,000 EPOCH 25 done: loss 0.1464 - lr 0.0000150
2021-07-22 23:43:04,765 DEV : loss 0.058226872235536575 - score 0.9822
2021-07-22 23:43:04,773 BAD EPOCHS (no improvement): 1
2021-07-22 23:43:04,774 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:05,495 epoch 26 - iter 3/33 - loss 0.26119111 - samples/sec: 133.33 - lr: 0.000015
2021-07-22 23:43:06,212 epoch 26 - iter 6/33 - loss 0.17799433 - samples/sec: 134.00 - lr: 0.000015
2021-07-22 23:43:06,933 epoch 26 - iter 9/33 - loss 0.15861185 - samples/sec: 133.07 - lr: 0.000015
2021-07-22 23:43:07,663 epoch 26 - iter 12/33 - loss 0.16110839 - samples/sec: 131.63 - lr: 0.000015
2021-07-22 23:43:08,410 epoch 26 - iter 15/33 - loss 0.15429966 - samples/sec: 128.59 - lr: 0.000015
2021-07-22 23:43:09,119 epoch 26 - iter 18/33 - loss 0.15062670 - samples/sec: 135.49 - lr: 0.000015
2021-07-22 23:43:09,816 epoch 26 - iter 21/33 - loss 0.16106895 - samples/sec: 137.85 - lr: 0.000015
2021-07-22 23:43:10,561 epoch 26 - iter 24/33 - loss 0.15888819 - samples/sec: 128.96 - lr: 0.000015
2021-07-22 23:43:11,339 epoch 26 - iter 27/33 - loss 0.14601425 - samples/sec: 123.34 - lr: 0.000015
2021-07-22 23:43:12,040 epoch 26 - iter 30/33 - loss 0.14167977 - samples/sec: 137.04 - lr: 0.000015
2021-07-22 23:43:12,747 epoch 26 - iter 33/33 - loss 0.13765101 - samples/sec: 135.88 - lr: 0.000015
2021-07-22 23:43:12,748 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:12,748 EPOCH 26 done: loss 0.1377 - lr 0.0000150
2021-07-22 23:43:13,511 DEV : loss 0.05663711577653885 - score 0.9822
2021-07-22 23:43:13,520 BAD EPOCHS (no improvement): 2
2021-07-22 23:43:13,520 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:14,223 epoch 27 - iter 3/33 - loss 0.09574592 - samples/sec: 136.77 - lr: 0.000015
2021-07-22 23:43:15,039 epoch 27 - iter 6/33 - loss 0.09284165 - samples/sec: 117.71 - lr: 0.000015
2021-07-22 23:43:15,776 epoch 27 - iter 9/33 - loss 0.10030256 - samples/sec: 130.36 - lr: 0.000015
2021-07-22 23:43:16,536 epoch 27 - iter 12/33 - loss 0.11044592 - samples/sec: 126.31 - lr: 0.000015
2021-07-22 23:43:17,264 epoch 27 - iter 15/33 - loss 0.12625338 - samples/sec: 132.03 - lr: 0.000015
2021-07-22 23:43:17,944 epoch 27 - iter 18/33 - loss 0.12490325 - samples/sec: 141.20 - lr: 0.000015
2021-07-22 23:43:18,675 epoch 27 - iter 21/33 - loss 0.12134747 - samples/sec: 131.43 - lr: 0.000015
2021-07-22 23:43:19,415 epoch 27 - iter 24/33 - loss 0.13254973 - samples/sec: 129.78 - lr: 0.000015
2021-07-22 23:43:20,195 epoch 27 - iter 27/33 - loss 0.12971652 - samples/sec: 123.09 - lr: 0.000015
2021-07-22 23:43:20,826 epoch 27 - iter 30/33 - loss 0.13424779 - samples/sec: 152.41 - lr: 0.000015
2021-07-22 23:43:21,499 epoch 27 - iter 33/33 - loss 0.13748334 - samples/sec: 142.67 - lr: 0.000015
2021-07-22 23:43:21,500 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:21,500 EPOCH 27 done: loss 0.1375 - lr 0.0000150
2021-07-22 23:43:22,258 DEV : loss 0.056472647935152054 - score 0.9822
2021-07-22 23:43:22,267 BAD EPOCHS (no improvement): 3
2021-07-22 23:43:22,267 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:22,975 epoch 28 - iter 3/33 - loss 0.11190464 - samples/sec: 135.87 - lr: 0.000015
2021-07-22 23:43:23,696 epoch 28 - iter 6/33 - loss 0.18635616 - samples/sec: 133.32 - lr: 0.000015
2021-07-22 23:43:24,461 epoch 28 - iter 9/33 - loss 0.18412015 - samples/sec: 125.55 - lr: 0.000015
2021-07-22 23:43:25,148 epoch 28 - iter 12/33 - loss 0.17747334 - samples/sec: 139.68 - lr: 0.000015
2021-07-22 23:43:25,836 epoch 28 - iter 15/33 - loss 0.17011078 - samples/sec: 139.76 - lr: 0.000015
2021-07-22 23:43:26,588 epoch 28 - iter 18/33 - loss 0.16933913 - samples/sec: 127.58 - lr: 0.000015
2021-07-22 23:43:27,348 epoch 28 - iter 21/33 - loss 0.17132136 - samples/sec: 126.37 - lr: 0.000015
2021-07-22 23:43:28,101 epoch 28 - iter 24/33 - loss 0.16806456 - samples/sec: 127.68 - lr: 0.000015
2021-07-22 23:43:28,911 epoch 28 - iter 27/33 - loss 0.16321707 - samples/sec: 118.46 - lr: 0.000015
2021-07-22 23:43:29,523 epoch 28 - iter 30/33 - loss 0.15784445 - samples/sec: 157.04 - lr: 0.000015
2021-07-22 23:43:30,268 epoch 28 - iter 33/33 - loss 0.14969447 - samples/sec: 128.95 - lr: 0.000015
2021-07-22 23:43:30,269 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:30,269 EPOCH 28 done: loss 0.1497 - lr 0.0000150
2021-07-22 23:43:31,039 DEV : loss 0.05559803172945976 - score 0.9822
Epoch    28: reducing learning rate of group 0 to 7.5000e-06.
2021-07-22 23:43:31,048 BAD EPOCHS (no improvement): 4
2021-07-22 23:43:31,048 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:31,786 epoch 29 - iter 3/33 - loss 0.22081265 - samples/sec: 130.21 - lr: 0.000008
2021-07-22 23:43:32,499 epoch 29 - iter 6/33 - loss 0.18782776 - samples/sec: 134.75 - lr: 0.000008
2021-07-22 23:43:33,192 epoch 29 - iter 9/33 - loss 0.18553483 - samples/sec: 138.55 - lr: 0.000008
2021-07-22 23:43:33,884 epoch 29 - iter 12/33 - loss 0.18170203 - samples/sec: 138.93 - lr: 0.000008
2021-07-22 23:43:34,615 epoch 29 - iter 15/33 - loss 0.17216695 - samples/sec: 131.40 - lr: 0.000008
2021-07-22 23:43:35,356 epoch 29 - iter 18/33 - loss 0.16614524 - samples/sec: 129.60 - lr: 0.000008
2021-07-22 23:43:36,096 epoch 29 - iter 21/33 - loss 0.15100788 - samples/sec: 129.82 - lr: 0.000008
2021-07-22 23:43:36,855 epoch 29 - iter 24/33 - loss 0.14076977 - samples/sec: 126.50 - lr: 0.000008
2021-07-22 23:43:37,549 epoch 29 - iter 27/33 - loss 0.14198846 - samples/sec: 138.50 - lr: 0.000008
2021-07-22 23:43:38,243 epoch 29 - iter 30/33 - loss 0.14543505 - samples/sec: 138.35 - lr: 0.000008
2021-07-22 23:43:38,949 epoch 29 - iter 33/33 - loss 0.14842750 - samples/sec: 136.11 - lr: 0.000008
2021-07-22 23:43:39,021 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:39,021 EPOCH 29 done: loss 0.1484 - lr 0.0000075
2021-07-22 23:43:39,786 DEV : loss 0.05576471611857414 - score 0.9822
2021-07-22 23:43:39,795 BAD EPOCHS (no improvement): 1
2021-07-22 23:43:39,795 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:40,556 epoch 30 - iter 3/33 - loss 0.20491906 - samples/sec: 126.39 - lr: 0.000008
2021-07-22 23:43:41,360 epoch 30 - iter 6/33 - loss 0.17127090 - samples/sec: 119.50 - lr: 0.000008
2021-07-22 23:43:42,057 epoch 30 - iter 9/33 - loss 0.17619322 - samples/sec: 137.84 - lr: 0.000008
2021-07-22 23:43:42,767 epoch 30 - iter 12/33 - loss 0.17885030 - samples/sec: 135.19 - lr: 0.000008
2021-07-22 23:43:43,447 epoch 30 - iter 15/33 - loss 0.19308532 - samples/sec: 141.39 - lr: 0.000008
2021-07-22 23:43:44,184 epoch 30 - iter 18/33 - loss 0.17485653 - samples/sec: 130.18 - lr: 0.000008
2021-07-22 23:43:44,899 epoch 30 - iter 21/33 - loss 0.16952903 - samples/sec: 134.40 - lr: 0.000008
2021-07-22 23:43:45,648 epoch 30 - iter 24/33 - loss 0.16861491 - samples/sec: 128.19 - lr: 0.000008
2021-07-22 23:43:46,417 epoch 30 - iter 27/33 - loss 0.15729931 - samples/sec: 124.98 - lr: 0.000008
2021-07-22 23:43:47,123 epoch 30 - iter 30/33 - loss 0.14890015 - samples/sec: 136.07 - lr: 0.000008
2021-07-22 23:43:47,787 epoch 30 - iter 33/33 - loss 0.13910890 - samples/sec: 144.60 - lr: 0.000008
2021-07-22 23:43:47,788 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:47,788 EPOCH 30 done: loss 0.1391 - lr 0.0000075
2021-07-22 23:43:48,548 DEV : loss 0.05522648245096207 - score 0.9822
2021-07-22 23:43:48,561 BAD EPOCHS (no improvement): 2
2021-07-22 23:43:48,561 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:49,319 epoch 31 - iter 3/33 - loss 0.19114298 - samples/sec: 126.91 - lr: 0.000008
2021-07-22 23:43:50,039 epoch 31 - iter 6/33 - loss 0.17719656 - samples/sec: 133.32 - lr: 0.000008
2021-07-22 23:43:50,896 epoch 31 - iter 9/33 - loss 0.17015376 - samples/sec: 112.09 - lr: 0.000008
2021-07-22 23:43:51,554 epoch 31 - iter 12/33 - loss 0.14566803 - samples/sec: 146.02 - lr: 0.000008
2021-07-22 23:43:52,299 epoch 31 - iter 15/33 - loss 0.13625279 - samples/sec: 128.84 - lr: 0.000008
2021-07-22 23:43:52,996 epoch 31 - iter 18/33 - loss 0.14185261 - samples/sec: 137.80 - lr: 0.000008
2021-07-22 23:43:53,736 epoch 31 - iter 21/33 - loss 0.14012607 - samples/sec: 129.81 - lr: 0.000008
2021-07-22 23:43:54,496 epoch 31 - iter 24/33 - loss 0.14648928 - samples/sec: 126.48 - lr: 0.000008
2021-07-22 23:43:55,240 epoch 31 - iter 27/33 - loss 0.15319517 - samples/sec: 129.05 - lr: 0.000008
2021-07-22 23:43:55,973 epoch 31 - iter 30/33 - loss 0.14524027 - samples/sec: 131.09 - lr: 0.000008
2021-07-22 23:43:56,642 epoch 31 - iter 33/33 - loss 0.14413552 - samples/sec: 143.41 - lr: 0.000008
2021-07-22 23:43:56,644 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:56,644 EPOCH 31 done: loss 0.1441 - lr 0.0000075
2021-07-22 23:43:57,411 DEV : loss 0.054397474974393845 - score 0.9822
2021-07-22 23:43:57,419 BAD EPOCHS (no improvement): 3
2021-07-22 23:43:57,420 ----------------------------------------------------------------------------------------------------
2021-07-22 23:43:58,109 epoch 32 - iter 3/33 - loss 0.14276484 - samples/sec: 139.52 - lr: 0.000008
2021-07-22 23:43:58,835 epoch 32 - iter 6/33 - loss 0.15779130 - samples/sec: 132.38 - lr: 0.000008
2021-07-22 23:43:59,595 epoch 32 - iter 9/33 - loss 0.15578094 - samples/sec: 126.38 - lr: 0.000008
2021-07-22 23:44:00,284 epoch 32 - iter 12/33 - loss 0.16793426 - samples/sec: 139.42 - lr: 0.000008
2021-07-22 23:44:01,083 epoch 32 - iter 15/33 - loss 0.16257604 - samples/sec: 120.11 - lr: 0.000008
2021-07-22 23:44:01,791 epoch 32 - iter 18/33 - loss 0.16356884 - samples/sec: 135.62 - lr: 0.000008
2021-07-22 23:44:02,528 epoch 32 - iter 21/33 - loss 0.14935086 - samples/sec: 130.32 - lr: 0.000008
2021-07-22 23:44:03,266 epoch 32 - iter 24/33 - loss 0.14312398 - samples/sec: 130.21 - lr: 0.000008
2021-07-22 23:44:03,983 epoch 32 - iter 27/33 - loss 0.13763023 - samples/sec: 133.92 - lr: 0.000008
2021-07-22 23:44:04,712 epoch 32 - iter 30/33 - loss 0.14023870 - samples/sec: 131.83 - lr: 0.000008
2021-07-22 23:44:05,375 epoch 32 - iter 33/33 - loss 0.13256182 - samples/sec: 144.97 - lr: 0.000008
2021-07-22 23:44:05,376 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:05,376 EPOCH 32 done: loss 0.1326 - lr 0.0000075
2021-07-22 23:44:06,141 DEV : loss 0.05434628948569298 - score 0.9822
Epoch    32: reducing learning rate of group 0 to 3.7500e-06.
2021-07-22 23:44:06,150 BAD EPOCHS (no improvement): 4
2021-07-22 23:44:06,150 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:06,827 epoch 33 - iter 3/33 - loss 0.21832230 - samples/sec: 142.06 - lr: 0.000004
2021-07-22 23:44:07,566 epoch 33 - iter 6/33 - loss 0.19169163 - samples/sec: 129.89 - lr: 0.000004
2021-07-22 23:44:08,348 epoch 33 - iter 9/33 - loss 0.16609159 - samples/sec: 122.88 - lr: 0.000004
2021-07-22 23:44:09,069 epoch 33 - iter 12/33 - loss 0.15880276 - samples/sec: 133.27 - lr: 0.000004
2021-07-22 23:44:09,838 epoch 33 - iter 15/33 - loss 0.13877293 - samples/sec: 124.84 - lr: 0.000004
2021-07-22 23:44:10,530 epoch 33 - iter 18/33 - loss 0.14334535 - samples/sec: 138.82 - lr: 0.000004
2021-07-22 23:44:11,230 epoch 33 - iter 21/33 - loss 0.17011613 - samples/sec: 137.22 - lr: 0.000004
2021-07-22 23:44:11,962 epoch 33 - iter 24/33 - loss 0.16018912 - samples/sec: 131.16 - lr: 0.000004
2021-07-22 23:44:12,688 epoch 33 - iter 27/33 - loss 0.15903215 - samples/sec: 132.34 - lr: 0.000004
2021-07-22 23:44:13,399 epoch 33 - iter 30/33 - loss 0.15672117 - samples/sec: 135.05 - lr: 0.000004
2021-07-22 23:44:14,131 epoch 33 - iter 33/33 - loss 0.16031507 - samples/sec: 131.30 - lr: 0.000004
2021-07-22 23:44:14,132 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:14,132 EPOCH 33 done: loss 0.1603 - lr 0.0000038
2021-07-22 23:44:14,890 DEV : loss 0.05423334985971451 - score 0.9822
2021-07-22 23:44:14,898 BAD EPOCHS (no improvement): 1
2021-07-22 23:44:14,899 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:15,676 epoch 34 - iter 3/33 - loss 0.08493375 - samples/sec: 123.74 - lr: 0.000004
2021-07-22 23:44:16,392 epoch 34 - iter 6/33 - loss 0.12356483 - samples/sec: 134.02 - lr: 0.000004
2021-07-22 23:44:17,163 epoch 34 - iter 9/33 - loss 0.13985740 - samples/sec: 124.63 - lr: 0.000004
2021-07-22 23:44:17,940 epoch 34 - iter 12/33 - loss 0.12288797 - samples/sec: 123.69 - lr: 0.000004
2021-07-22 23:44:18,656 epoch 34 - iter 15/33 - loss 0.11597248 - samples/sec: 134.07 - lr: 0.000004
2021-07-22 23:44:19,400 epoch 34 - iter 18/33 - loss 0.12539686 - samples/sec: 129.18 - lr: 0.000004
2021-07-22 23:44:20,147 epoch 34 - iter 21/33 - loss 0.12159648 - samples/sec: 128.55 - lr: 0.000004
2021-07-22 23:44:20,852 epoch 34 - iter 24/33 - loss 0.12415972 - samples/sec: 136.15 - lr: 0.000004
2021-07-22 23:44:21,560 epoch 34 - iter 27/33 - loss 0.11584561 - samples/sec: 135.75 - lr: 0.000004
2021-07-22 23:44:22,244 epoch 34 - iter 30/33 - loss 0.12020655 - samples/sec: 140.43 - lr: 0.000004
2021-07-22 23:44:22,895 epoch 34 - iter 33/33 - loss 0.12264029 - samples/sec: 147.43 - lr: 0.000004
2021-07-22 23:44:22,896 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:22,896 EPOCH 34 done: loss 0.1226 - lr 0.0000038
2021-07-22 23:44:23,655 DEV : loss 0.05434490367770195 - score 0.9822
2021-07-22 23:44:23,664 BAD EPOCHS (no improvement): 2
2021-07-22 23:44:23,664 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:24,400 epoch 35 - iter 3/33 - loss 0.12479777 - samples/sec: 130.74 - lr: 0.000004
2021-07-22 23:44:25,156 epoch 35 - iter 6/33 - loss 0.12036710 - samples/sec: 127.03 - lr: 0.000004
2021-07-22 23:44:25,875 epoch 35 - iter 9/33 - loss 0.13086605 - samples/sec: 133.52 - lr: 0.000004
2021-07-22 23:44:26,637 epoch 35 - iter 12/33 - loss 0.13374256 - samples/sec: 126.13 - lr: 0.000004
2021-07-22 23:44:27,361 epoch 35 - iter 15/33 - loss 0.14338706 - samples/sec: 132.72 - lr: 0.000004
2021-07-22 23:44:28,044 epoch 35 - iter 18/33 - loss 0.14698999 - samples/sec: 140.54 - lr: 0.000004
2021-07-22 23:44:28,776 epoch 35 - iter 21/33 - loss 0.15181532 - samples/sec: 131.20 - lr: 0.000004
2021-07-22 23:44:29,512 epoch 35 - iter 24/33 - loss 0.13928745 - samples/sec: 130.60 - lr: 0.000004
2021-07-22 23:44:30,276 epoch 35 - iter 27/33 - loss 0.14500538 - samples/sec: 125.59 - lr: 0.000004
2021-07-22 23:44:30,973 epoch 35 - iter 30/33 - loss 0.15032874 - samples/sec: 137.79 - lr: 0.000004
2021-07-22 23:44:31,648 epoch 35 - iter 33/33 - loss 0.14493148 - samples/sec: 142.47 - lr: 0.000004
2021-07-22 23:44:31,649 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:31,649 EPOCH 35 done: loss 0.1449 - lr 0.0000038
2021-07-22 23:44:32,408 DEV : loss 0.054711610078811646 - score 0.9822
2021-07-22 23:44:32,417 BAD EPOCHS (no improvement): 3
2021-07-22 23:44:32,417 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:33,119 epoch 36 - iter 3/33 - loss 0.08933199 - samples/sec: 137.09 - lr: 0.000004
2021-07-22 23:44:33,875 epoch 36 - iter 6/33 - loss 0.10381870 - samples/sec: 127.11 - lr: 0.000004
2021-07-22 23:44:34,537 epoch 36 - iter 9/33 - loss 0.11054701 - samples/sec: 144.90 - lr: 0.000004
2021-07-22 23:44:35,333 epoch 36 - iter 12/33 - loss 0.11949801 - samples/sec: 120.76 - lr: 0.000004
2021-07-22 23:44:36,046 epoch 36 - iter 15/33 - loss 0.11976175 - samples/sec: 134.72 - lr: 0.000004
2021-07-22 23:44:36,751 epoch 36 - iter 18/33 - loss 0.10795873 - samples/sec: 136.18 - lr: 0.000004
2021-07-22 23:44:37,472 epoch 36 - iter 21/33 - loss 0.11235342 - samples/sec: 133.21 - lr: 0.000004
2021-07-22 23:44:38,239 epoch 36 - iter 24/33 - loss 0.11894536 - samples/sec: 125.25 - lr: 0.000004
2021-07-22 23:44:38,938 epoch 36 - iter 27/33 - loss 0.11888745 - samples/sec: 137.39 - lr: 0.000004
2021-07-22 23:44:39,675 epoch 36 - iter 30/33 - loss 0.12612893 - samples/sec: 130.37 - lr: 0.000004
2021-07-22 23:44:40,364 epoch 36 - iter 33/33 - loss 0.12541564 - samples/sec: 139.49 - lr: 0.000004
2021-07-22 23:44:40,365 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:40,365 EPOCH 36 done: loss 0.1254 - lr 0.0000038
2021-07-22 23:44:41,129 DEV : loss 0.054376255720853806 - score 0.9822
Epoch    36: reducing learning rate of group 0 to 1.8750e-06.
2021-07-22 23:44:41,138 BAD EPOCHS (no improvement): 4
2021-07-22 23:44:41,138 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:41,138 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:41,138 learning rate too small - quitting training!
2021-07-22 23:44:41,138 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:41,899 ----------------------------------------------------------------------------------------------------
2021-07-22 23:44:41,899 Testing using best model ...
2021-07-22 23:44:41,900 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/spa.rst.sctb/best-model.pt
2021-07-22 23:44:47,290 0.9801	0.9867	0.9834
2021-07-22 23:44:47,290 
Results:
- F1-score (micro) 0.9834
- F1-score (macro) 0.9779

By class:
SENT       tp: 54 - fp: 3 - fn: 2 - precision: 0.9474 - recall: 0.9643 - f1-score: 0.9558
X          tp: 94 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-22 23:44:47,290 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.pdtb.pdtb/
2021-07-22 23:44:47,313 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.pdtb.pdtb
2021-07-22 23:44:47,314 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.pdtb.pdtb/sent_train.txt
2021-07-22 23:44:47,315 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.pdtb.pdtb/sent_dev.txt
2021-07-22 23:44:47,316 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.pdtb.pdtb/sent_test.txt
Corpus: 107526 train + 5406 dev + 36158 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-22 23:45:09,854 ----------------------------------------------------------------------------------------------------
2021-07-22 23:45:09,856 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-22 23:45:09,856 ----------------------------------------------------------------------------------------------------
2021-07-22 23:45:09,856 Corpus: "Corpus: 107526 train + 5406 dev + 36158 test sentences"
2021-07-22 23:45:09,856 ----------------------------------------------------------------------------------------------------
2021-07-22 23:45:09,856 Parameters:
2021-07-22 23:45:09,856  - learning_rate: "3e-05"
2021-07-22 23:45:09,856  - mini_batch_size: "32"
2021-07-22 23:45:09,856  - patience: "3"
2021-07-22 23:45:09,856  - anneal_factor: "0.5"
2021-07-22 23:45:09,856  - max_epochs: "40"
2021-07-22 23:45:09,856  - shuffle: "True"
2021-07-22 23:45:09,856  - train_with_dev: "False"
2021-07-22 23:45:09,856  - batch_growth_annealing: "False"
2021-07-22 23:45:09,856 ----------------------------------------------------------------------------------------------------
2021-07-22 23:45:09,856 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.pdtb.pdtb"
2021-07-22 23:45:09,856 ----------------------------------------------------------------------------------------------------
2021-07-22 23:45:09,856 Device: cuda:0
2021-07-22 23:45:09,857 ----------------------------------------------------------------------------------------------------
2021-07-22 23:45:09,857 Embeddings storage mode: cpu
2021-07-22 23:45:09,859 ----------------------------------------------------------------------------------------------------
2021-07-22 23:48:26,953 epoch 1 - iter 336/3361 - loss 3.56368419 - samples/sec: 54.56 - lr: 0.000030
2021-07-22 23:51:43,515 epoch 1 - iter 672/3361 - loss 1.92047374 - samples/sec: 54.70 - lr: 0.000030
2021-07-22 23:55:00,847 epoch 1 - iter 1008/3361 - loss 1.34809158 - samples/sec: 54.49 - lr: 0.000030
2021-07-22 23:58:18,301 epoch 1 - iter 1344/3361 - loss 1.05819528 - samples/sec: 54.46 - lr: 0.000030
2021-07-23 00:01:36,189 epoch 1 - iter 1680/3361 - loss 0.88074587 - samples/sec: 54.34 - lr: 0.000030
2021-07-23 00:04:57,494 epoch 1 - iter 2016/3361 - loss 0.75983196 - samples/sec: 53.42 - lr: 0.000030
2021-07-23 00:08:16,950 epoch 1 - iter 2352/3361 - loss 0.67383924 - samples/sec: 53.91 - lr: 0.000030
2021-07-23 00:11:36,579 epoch 1 - iter 2688/3361 - loss 0.61015825 - samples/sec: 53.86 - lr: 0.000030
2021-07-23 00:14:57,795 epoch 1 - iter 3024/3361 - loss 0.55887259 - samples/sec: 53.44 - lr: 0.000030
2021-07-23 00:18:19,999 epoch 1 - iter 3360/3361 - loss 0.51782364 - samples/sec: 53.18 - lr: 0.000030
2021-07-23 00:18:20,149 ----------------------------------------------------------------------------------------------------
2021-07-23 00:18:20,149 EPOCH 1 done: loss 0.5177 - lr 0.0000300
2021-07-23 00:19:31,959 DEV : loss 0.06873765587806702 - score 0.9814
2021-07-23 00:19:32,097 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 00:19:32,751 ----------------------------------------------------------------------------------------------------
2021-07-23 00:20:53,546 epoch 2 - iter 336/3361 - loss 0.13480974 - samples/sec: 133.11 - lr: 0.000030
2021-07-23 00:22:15,152 epoch 2 - iter 672/3361 - loss 0.13200201 - samples/sec: 131.78 - lr: 0.000030
2021-07-23 00:23:36,443 epoch 2 - iter 1008/3361 - loss 0.12691346 - samples/sec: 132.29 - lr: 0.000030
2021-07-23 00:24:58,120 epoch 2 - iter 1344/3361 - loss 0.12574915 - samples/sec: 131.67 - lr: 0.000030
2021-07-23 00:26:19,327 epoch 2 - iter 1680/3361 - loss 0.12298392 - samples/sec: 132.43 - lr: 0.000030
2021-07-23 00:27:40,148 epoch 2 - iter 2016/3361 - loss 0.11966945 - samples/sec: 133.06 - lr: 0.000030
2021-07-23 00:29:01,224 epoch 2 - iter 2352/3361 - loss 0.11628197 - samples/sec: 132.64 - lr: 0.000030
2021-07-23 00:30:21,319 epoch 2 - iter 2688/3361 - loss 0.11373381 - samples/sec: 134.27 - lr: 0.000030
2021-07-23 00:31:41,884 epoch 2 - iter 3024/3361 - loss 0.11200435 - samples/sec: 133.49 - lr: 0.000030
2021-07-23 00:33:02,805 epoch 2 - iter 3360/3361 - loss 0.10972333 - samples/sec: 132.90 - lr: 0.000030
2021-07-23 00:33:02,882 ----------------------------------------------------------------------------------------------------
2021-07-23 00:33:02,882 EPOCH 2 done: loss 0.1097 - lr 0.0000300
2021-07-23 00:33:15,850 DEV : loss 0.058139368891716 - score 0.9849
2021-07-23 00:33:15,991 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 00:33:18,211 ----------------------------------------------------------------------------------------------------
2021-07-23 00:34:39,844 epoch 3 - iter 336/3361 - loss 0.08375160 - samples/sec: 131.75 - lr: 0.000030
2021-07-23 00:36:00,593 epoch 3 - iter 672/3361 - loss 0.08589920 - samples/sec: 133.18 - lr: 0.000030
2021-07-23 00:37:22,547 epoch 3 - iter 1008/3361 - loss 0.08610529 - samples/sec: 131.22 - lr: 0.000030
2021-07-23 00:38:44,336 epoch 3 - iter 1344/3361 - loss 0.08453085 - samples/sec: 131.49 - lr: 0.000030
2021-07-23 00:40:05,829 epoch 3 - iter 1680/3361 - loss 0.08487625 - samples/sec: 131.97 - lr: 0.000030
2021-07-23 00:41:27,610 epoch 3 - iter 2016/3361 - loss 0.08457770 - samples/sec: 131.50 - lr: 0.000030
2021-07-23 00:42:48,782 epoch 3 - iter 2352/3361 - loss 0.08417952 - samples/sec: 132.49 - lr: 0.000030
2021-07-23 00:44:10,344 epoch 3 - iter 2688/3361 - loss 0.08393733 - samples/sec: 131.85 - lr: 0.000030
2021-07-23 00:45:31,355 epoch 3 - iter 3024/3361 - loss 0.08395148 - samples/sec: 132.75 - lr: 0.000030
2021-07-23 00:46:52,915 epoch 3 - iter 3360/3361 - loss 0.08386541 - samples/sec: 131.86 - lr: 0.000030
2021-07-23 00:46:53,002 ----------------------------------------------------------------------------------------------------
2021-07-23 00:46:53,003 EPOCH 3 done: loss 0.0838 - lr 0.0000300
2021-07-23 00:47:06,062 DEV : loss 0.055728986859321594 - score 0.9844
2021-07-23 00:47:06,202 BAD EPOCHS (no improvement): 1
2021-07-23 00:47:06,202 ----------------------------------------------------------------------------------------------------
2021-07-23 00:48:28,015 epoch 4 - iter 336/3361 - loss 0.07958000 - samples/sec: 131.46 - lr: 0.000030
2021-07-23 00:49:49,706 epoch 4 - iter 672/3361 - loss 0.08071462 - samples/sec: 131.65 - lr: 0.000030
2021-07-23 00:51:11,688 epoch 4 - iter 1008/3361 - loss 0.08131795 - samples/sec: 131.18 - lr: 0.000030
2021-07-23 00:52:33,388 epoch 4 - iter 1344/3361 - loss 0.08007340 - samples/sec: 131.63 - lr: 0.000030
2021-07-23 00:53:55,142 epoch 4 - iter 1680/3361 - loss 0.07868889 - samples/sec: 131.54 - lr: 0.000030
2021-07-23 00:55:17,072 epoch 4 - iter 2016/3361 - loss 0.07814404 - samples/sec: 131.26 - lr: 0.000030
2021-07-23 00:56:39,548 epoch 4 - iter 2352/3361 - loss 0.07783980 - samples/sec: 130.39 - lr: 0.000030
2021-07-23 00:58:01,336 epoch 4 - iter 2688/3361 - loss 0.07786284 - samples/sec: 131.49 - lr: 0.000030
2021-07-23 00:59:23,294 epoch 4 - iter 3024/3361 - loss 0.07729091 - samples/sec: 131.22 - lr: 0.000030
2021-07-23 01:00:45,016 epoch 4 - iter 3360/3361 - loss 0.07723245 - samples/sec: 131.60 - lr: 0.000030
2021-07-23 01:00:45,112 ----------------------------------------------------------------------------------------------------
2021-07-23 01:00:45,112 EPOCH 4 done: loss 0.0774 - lr 0.0000300
2021-07-23 01:01:01,281 DEV : loss 0.05202045291662216 - score 0.985
2021-07-23 01:01:01,424 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 01:01:03,700 ----------------------------------------------------------------------------------------------------
2021-07-23 01:02:25,538 epoch 5 - iter 336/3361 - loss 0.07049786 - samples/sec: 131.42 - lr: 0.000030
2021-07-23 01:03:48,021 epoch 5 - iter 672/3361 - loss 0.06730539 - samples/sec: 130.38 - lr: 0.000030
2021-07-23 01:05:09,779 epoch 5 - iter 1008/3361 - loss 0.06732574 - samples/sec: 131.54 - lr: 0.000030
2021-07-23 01:06:31,631 epoch 5 - iter 1344/3361 - loss 0.06888799 - samples/sec: 131.39 - lr: 0.000030
2021-07-23 01:07:53,638 epoch 5 - iter 1680/3361 - loss 0.06952097 - samples/sec: 131.14 - lr: 0.000030
2021-07-23 01:09:16,225 epoch 5 - iter 2016/3361 - loss 0.06993142 - samples/sec: 130.22 - lr: 0.000030
2021-07-23 01:10:38,464 epoch 5 - iter 2352/3361 - loss 0.07010256 - samples/sec: 130.77 - lr: 0.000030
2021-07-23 01:12:01,096 epoch 5 - iter 2688/3361 - loss 0.07043080 - samples/sec: 130.15 - lr: 0.000030
2021-07-23 01:13:24,025 epoch 5 - iter 3024/3361 - loss 0.07059968 - samples/sec: 129.68 - lr: 0.000030
2021-07-23 01:14:45,332 epoch 5 - iter 3360/3361 - loss 0.07025967 - samples/sec: 132.27 - lr: 0.000030
2021-07-23 01:14:45,426 ----------------------------------------------------------------------------------------------------
2021-07-23 01:14:45,426 EPOCH 5 done: loss 0.0703 - lr 0.0000300
2021-07-23 01:14:58,740 DEV : loss 0.0465615838766098 - score 0.987
2021-07-23 01:14:58,879 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 01:15:01,080 ----------------------------------------------------------------------------------------------------
2021-07-23 01:16:22,588 epoch 6 - iter 336/3361 - loss 0.07257248 - samples/sec: 131.96 - lr: 0.000030
2021-07-23 01:17:45,235 epoch 6 - iter 672/3361 - loss 0.07036403 - samples/sec: 130.12 - lr: 0.000030
2021-07-23 01:19:07,336 epoch 6 - iter 1008/3361 - loss 0.06967225 - samples/sec: 130.99 - lr: 0.000030
2021-07-23 01:20:28,897 epoch 6 - iter 1344/3361 - loss 0.06850649 - samples/sec: 131.86 - lr: 0.000030
2021-07-23 01:21:50,020 epoch 6 - iter 1680/3361 - loss 0.06744658 - samples/sec: 132.57 - lr: 0.000030
2021-07-23 01:23:11,361 epoch 6 - iter 2016/3361 - loss 0.06678945 - samples/sec: 132.21 - lr: 0.000030
2021-07-23 01:24:32,383 epoch 6 - iter 2352/3361 - loss 0.06729534 - samples/sec: 132.73 - lr: 0.000030
2021-07-23 01:25:54,421 epoch 6 - iter 2688/3361 - loss 0.06773024 - samples/sec: 131.09 - lr: 0.000030
2021-07-23 01:27:16,836 epoch 6 - iter 3024/3361 - loss 0.06790398 - samples/sec: 130.49 - lr: 0.000030
2021-07-23 01:28:38,620 epoch 6 - iter 3360/3361 - loss 0.06763144 - samples/sec: 131.50 - lr: 0.000030
2021-07-23 01:28:38,714 ----------------------------------------------------------------------------------------------------
2021-07-23 01:28:38,714 EPOCH 6 done: loss 0.0676 - lr 0.0000300
2021-07-23 01:28:51,935 DEV : loss 0.0462050586938858 - score 0.988
2021-07-23 01:28:52,077 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 01:28:54,380 ----------------------------------------------------------------------------------------------------
2021-07-23 01:30:16,668 epoch 7 - iter 336/3361 - loss 0.05700891 - samples/sec: 130.71 - lr: 0.000030
2021-07-23 01:31:39,193 epoch 7 - iter 672/3361 - loss 0.06135018 - samples/sec: 130.32 - lr: 0.000030
2021-07-23 01:33:01,039 epoch 7 - iter 1008/3361 - loss 0.06213361 - samples/sec: 131.39 - lr: 0.000030
2021-07-23 01:34:23,479 epoch 7 - iter 1344/3361 - loss 0.06330313 - samples/sec: 130.45 - lr: 0.000030
2021-07-23 01:35:45,603 epoch 7 - iter 1680/3361 - loss 0.06401100 - samples/sec: 130.95 - lr: 0.000030
2021-07-23 01:37:07,430 epoch 7 - iter 2016/3361 - loss 0.06446005 - samples/sec: 131.43 - lr: 0.000030
2021-07-23 01:38:30,160 epoch 7 - iter 2352/3361 - loss 0.06419726 - samples/sec: 129.99 - lr: 0.000030
2021-07-23 01:39:52,239 epoch 7 - iter 2688/3361 - loss 0.06426342 - samples/sec: 131.02 - lr: 0.000030
2021-07-23 01:41:13,881 epoch 7 - iter 3024/3361 - loss 0.06433555 - samples/sec: 131.72 - lr: 0.000030
2021-07-23 01:42:36,752 epoch 7 - iter 3360/3361 - loss 0.06441605 - samples/sec: 129.77 - lr: 0.000030
2021-07-23 01:42:36,846 ----------------------------------------------------------------------------------------------------
2021-07-23 01:42:36,846 EPOCH 7 done: loss 0.0644 - lr 0.0000300
2021-07-23 01:42:50,051 DEV : loss 0.044726014137268066 - score 0.9879
2021-07-23 01:42:50,195 BAD EPOCHS (no improvement): 1
2021-07-23 01:42:50,195 ----------------------------------------------------------------------------------------------------
2021-07-23 01:44:12,393 epoch 8 - iter 336/3361 - loss 0.06651185 - samples/sec: 130.84 - lr: 0.000030
2021-07-23 01:45:35,145 epoch 8 - iter 672/3361 - loss 0.06334596 - samples/sec: 129.96 - lr: 0.000030
2021-07-23 01:46:57,316 epoch 8 - iter 1008/3361 - loss 0.06167563 - samples/sec: 130.88 - lr: 0.000030
2021-07-23 01:48:19,863 epoch 8 - iter 1344/3361 - loss 0.06306634 - samples/sec: 130.28 - lr: 0.000030
2021-07-23 01:49:42,208 epoch 8 - iter 1680/3361 - loss 0.06204169 - samples/sec: 130.60 - lr: 0.000030
2021-07-23 01:51:04,112 epoch 8 - iter 2016/3361 - loss 0.06222922 - samples/sec: 131.30 - lr: 0.000030
2021-07-23 01:52:26,252 epoch 8 - iter 2352/3361 - loss 0.06225363 - samples/sec: 130.92 - lr: 0.000030
2021-07-23 01:53:49,004 epoch 8 - iter 2688/3361 - loss 0.06282354 - samples/sec: 129.96 - lr: 0.000030
2021-07-23 01:55:10,885 epoch 8 - iter 3024/3361 - loss 0.06229013 - samples/sec: 131.34 - lr: 0.000030
2021-07-23 01:56:32,996 epoch 8 - iter 3360/3361 - loss 0.06183731 - samples/sec: 130.97 - lr: 0.000030
2021-07-23 01:56:33,091 ----------------------------------------------------------------------------------------------------
2021-07-23 01:56:33,091 EPOCH 8 done: loss 0.0618 - lr 0.0000300
2021-07-23 01:56:46,248 DEV : loss 0.043279144912958145 - score 0.9883
2021-07-23 01:56:46,390 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 01:56:48,603 ----------------------------------------------------------------------------------------------------
2021-07-23 01:58:10,704 epoch 9 - iter 336/3361 - loss 0.05418503 - samples/sec: 131.00 - lr: 0.000030
2021-07-23 01:59:33,557 epoch 9 - iter 672/3361 - loss 0.05610188 - samples/sec: 129.80 - lr: 0.000030
2021-07-23 02:00:56,314 epoch 9 - iter 1008/3361 - loss 0.05898671 - samples/sec: 129.95 - lr: 0.000030
2021-07-23 02:02:18,292 epoch 9 - iter 1344/3361 - loss 0.05954284 - samples/sec: 131.18 - lr: 0.000030
2021-07-23 02:03:40,572 epoch 9 - iter 1680/3361 - loss 0.06015467 - samples/sec: 130.70 - lr: 0.000030
2021-07-23 02:05:02,496 epoch 9 - iter 2016/3361 - loss 0.06002018 - samples/sec: 131.27 - lr: 0.000030
2021-07-23 02:06:25,006 epoch 9 - iter 2352/3361 - loss 0.05960471 - samples/sec: 130.34 - lr: 0.000030
2021-07-23 02:07:47,477 epoch 9 - iter 2688/3361 - loss 0.06024087 - samples/sec: 130.40 - lr: 0.000030
2021-07-23 02:09:09,046 epoch 9 - iter 3024/3361 - loss 0.05975211 - samples/sec: 131.84 - lr: 0.000030
2021-07-23 02:10:31,096 epoch 9 - iter 3360/3361 - loss 0.05940784 - samples/sec: 131.07 - lr: 0.000030
2021-07-23 02:10:31,183 ----------------------------------------------------------------------------------------------------
2021-07-23 02:10:31,184 EPOCH 9 done: loss 0.0594 - lr 0.0000300
2021-07-23 02:10:44,392 DEV : loss 0.04222976043820381 - score 0.9894
2021-07-23 02:10:44,535 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 02:10:46,891 ----------------------------------------------------------------------------------------------------
2021-07-23 02:12:08,900 epoch 10 - iter 336/3361 - loss 0.05115977 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 02:13:30,989 epoch 10 - iter 672/3361 - loss 0.05483134 - samples/sec: 131.01 - lr: 0.000030
2021-07-23 02:14:53,568 epoch 10 - iter 1008/3361 - loss 0.05662514 - samples/sec: 130.23 - lr: 0.000030
2021-07-23 02:16:15,957 epoch 10 - iter 1344/3361 - loss 0.05580124 - samples/sec: 130.53 - lr: 0.000030
2021-07-23 02:17:38,319 epoch 10 - iter 1680/3361 - loss 0.05672251 - samples/sec: 130.57 - lr: 0.000030
2021-07-23 02:19:00,388 epoch 10 - iter 2016/3361 - loss 0.05700573 - samples/sec: 131.04 - lr: 0.000030
2021-07-23 02:20:22,520 epoch 10 - iter 2352/3361 - loss 0.05743755 - samples/sec: 130.94 - lr: 0.000030
2021-07-23 02:21:45,339 epoch 10 - iter 2688/3361 - loss 0.05724675 - samples/sec: 129.85 - lr: 0.000030
2021-07-23 02:23:07,932 epoch 10 - iter 3024/3361 - loss 0.05756957 - samples/sec: 130.21 - lr: 0.000030
2021-07-23 02:24:30,125 epoch 10 - iter 3360/3361 - loss 0.05759532 - samples/sec: 130.84 - lr: 0.000030
2021-07-23 02:24:30,195 ----------------------------------------------------------------------------------------------------
2021-07-23 02:24:30,195 EPOCH 10 done: loss 0.0576 - lr 0.0000300
2021-07-23 02:24:43,412 DEV : loss 0.040890902280807495 - score 0.9895
2021-07-23 02:24:43,552 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 02:24:45,791 ----------------------------------------------------------------------------------------------------
2021-07-23 02:26:08,065 epoch 11 - iter 336/3361 - loss 0.05513953 - samples/sec: 130.72 - lr: 0.000030
2021-07-23 02:27:29,868 epoch 11 - iter 672/3361 - loss 0.05498354 - samples/sec: 131.46 - lr: 0.000030
2021-07-23 02:28:52,203 epoch 11 - iter 1008/3361 - loss 0.05426638 - samples/sec: 130.62 - lr: 0.000030
2021-07-23 02:30:13,981 epoch 11 - iter 1344/3361 - loss 0.05431989 - samples/sec: 131.50 - lr: 0.000030
2021-07-23 02:31:35,964 epoch 11 - iter 1680/3361 - loss 0.05447299 - samples/sec: 131.18 - lr: 0.000030
2021-07-23 02:32:58,725 epoch 11 - iter 2016/3361 - loss 0.05412134 - samples/sec: 129.94 - lr: 0.000030
2021-07-23 02:34:19,932 epoch 11 - iter 2352/3361 - loss 0.05395801 - samples/sec: 132.43 - lr: 0.000030
2021-07-23 02:35:41,876 epoch 11 - iter 2688/3361 - loss 0.05445761 - samples/sec: 131.24 - lr: 0.000030
2021-07-23 02:37:04,524 epoch 11 - iter 3024/3361 - loss 0.05547796 - samples/sec: 130.12 - lr: 0.000030
2021-07-23 02:38:26,630 epoch 11 - iter 3360/3361 - loss 0.05595784 - samples/sec: 130.98 - lr: 0.000030
2021-07-23 02:38:26,695 ----------------------------------------------------------------------------------------------------
2021-07-23 02:38:26,695 EPOCH 11 done: loss 0.0559 - lr 0.0000300
2021-07-23 02:38:42,844 DEV : loss 0.041069503873586655 - score 0.9897
2021-07-23 02:38:42,984 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 02:38:45,316 ----------------------------------------------------------------------------------------------------
2021-07-23 02:40:07,767 epoch 12 - iter 336/3361 - loss 0.05510288 - samples/sec: 130.44 - lr: 0.000030
2021-07-23 02:41:29,289 epoch 12 - iter 672/3361 - loss 0.05285489 - samples/sec: 131.92 - lr: 0.000030
2021-07-23 02:42:50,655 epoch 12 - iter 1008/3361 - loss 0.05336791 - samples/sec: 132.17 - lr: 0.000030
2021-07-23 02:44:13,068 epoch 12 - iter 1344/3361 - loss 0.05487054 - samples/sec: 130.49 - lr: 0.000030
2021-07-23 02:45:35,209 epoch 12 - iter 1680/3361 - loss 0.05415337 - samples/sec: 130.92 - lr: 0.000030
2021-07-23 02:46:57,052 epoch 12 - iter 2016/3361 - loss 0.05438390 - samples/sec: 131.40 - lr: 0.000030
2021-07-23 02:48:19,635 epoch 12 - iter 2352/3361 - loss 0.05497623 - samples/sec: 130.22 - lr: 0.000030
2021-07-23 02:49:41,823 epoch 12 - iter 2688/3361 - loss 0.05508484 - samples/sec: 130.85 - lr: 0.000030
2021-07-23 02:51:03,178 epoch 12 - iter 3024/3361 - loss 0.05481952 - samples/sec: 132.19 - lr: 0.000030
2021-07-23 02:52:25,168 epoch 12 - iter 3360/3361 - loss 0.05494674 - samples/sec: 131.16 - lr: 0.000030
2021-07-23 02:52:25,260 ----------------------------------------------------------------------------------------------------
2021-07-23 02:52:25,260 EPOCH 12 done: loss 0.0549 - lr 0.0000300
2021-07-23 02:52:38,430 DEV : loss 0.038587864488363266 - score 0.9899
2021-07-23 02:52:38,575 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 02:52:40,798 ----------------------------------------------------------------------------------------------------
2021-07-23 02:54:03,714 epoch 13 - iter 336/3361 - loss 0.05557061 - samples/sec: 129.71 - lr: 0.000030
2021-07-23 02:55:26,072 epoch 13 - iter 672/3361 - loss 0.05237821 - samples/sec: 130.58 - lr: 0.000030
2021-07-23 02:56:46,587 epoch 13 - iter 1008/3361 - loss 0.05379280 - samples/sec: 133.57 - lr: 0.000030
2021-07-23 02:58:08,377 epoch 13 - iter 1344/3361 - loss 0.05385916 - samples/sec: 131.49 - lr: 0.000030
2021-07-23 02:59:30,331 epoch 13 - iter 1680/3361 - loss 0.05384253 - samples/sec: 131.22 - lr: 0.000030
2021-07-23 03:00:51,764 epoch 13 - iter 2016/3361 - loss 0.05446357 - samples/sec: 132.06 - lr: 0.000030
2021-07-23 03:02:13,227 epoch 13 - iter 2352/3361 - loss 0.05431074 - samples/sec: 132.01 - lr: 0.000030
2021-07-23 03:03:34,984 epoch 13 - iter 2688/3361 - loss 0.05455268 - samples/sec: 131.54 - lr: 0.000030
2021-07-23 03:04:56,315 epoch 13 - iter 3024/3361 - loss 0.05415905 - samples/sec: 132.23 - lr: 0.000030
2021-07-23 03:06:18,028 epoch 13 - iter 3360/3361 - loss 0.05411374 - samples/sec: 131.61 - lr: 0.000030
2021-07-23 03:06:18,114 ----------------------------------------------------------------------------------------------------
2021-07-23 03:06:18,115 EPOCH 13 done: loss 0.0541 - lr 0.0000300
2021-07-23 03:06:31,355 DEV : loss 0.040004413574934006 - score 0.9897
2021-07-23 03:06:31,495 BAD EPOCHS (no improvement): 1
2021-07-23 03:06:31,496 ----------------------------------------------------------------------------------------------------
2021-07-23 03:07:53,800 epoch 14 - iter 336/3361 - loss 0.05332149 - samples/sec: 130.67 - lr: 0.000030
2021-07-23 03:09:16,289 epoch 14 - iter 672/3361 - loss 0.05435172 - samples/sec: 130.37 - lr: 0.000030
2021-07-23 03:10:38,396 epoch 14 - iter 1008/3361 - loss 0.05453702 - samples/sec: 130.98 - lr: 0.000030
2021-07-23 03:12:00,733 epoch 14 - iter 1344/3361 - loss 0.05371521 - samples/sec: 130.61 - lr: 0.000030
2021-07-23 03:13:22,979 epoch 14 - iter 1680/3361 - loss 0.05343004 - samples/sec: 130.76 - lr: 0.000030
2021-07-23 03:14:45,152 epoch 14 - iter 2016/3361 - loss 0.05211805 - samples/sec: 130.87 - lr: 0.000030
2021-07-23 03:16:06,662 epoch 14 - iter 2352/3361 - loss 0.05166587 - samples/sec: 131.94 - lr: 0.000030
2021-07-23 03:17:28,549 epoch 14 - iter 2688/3361 - loss 0.05228424 - samples/sec: 131.33 - lr: 0.000030
2021-07-23 03:18:50,741 epoch 14 - iter 3024/3361 - loss 0.05226255 - samples/sec: 130.84 - lr: 0.000030
2021-07-23 03:20:11,984 epoch 14 - iter 3360/3361 - loss 0.05258526 - samples/sec: 132.37 - lr: 0.000030
2021-07-23 03:20:12,079 ----------------------------------------------------------------------------------------------------
2021-07-23 03:20:12,079 EPOCH 14 done: loss 0.0526 - lr 0.0000300
2021-07-23 03:20:25,248 DEV : loss 0.040433287620544434 - score 0.9897
2021-07-23 03:20:25,390 BAD EPOCHS (no improvement): 2
2021-07-23 03:20:25,390 ----------------------------------------------------------------------------------------------------
2021-07-23 03:21:46,796 epoch 15 - iter 336/3361 - loss 0.05328762 - samples/sec: 132.12 - lr: 0.000030
2021-07-23 03:23:08,275 epoch 15 - iter 672/3361 - loss 0.05198869 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 03:24:30,688 epoch 15 - iter 1008/3361 - loss 0.05057580 - samples/sec: 130.49 - lr: 0.000030
2021-07-23 03:25:53,227 epoch 15 - iter 1344/3361 - loss 0.05029332 - samples/sec: 130.29 - lr: 0.000030
2021-07-23 03:27:15,477 epoch 15 - iter 1680/3361 - loss 0.05056728 - samples/sec: 130.75 - lr: 0.000030
2021-07-23 03:28:37,816 epoch 15 - iter 2016/3361 - loss 0.05063923 - samples/sec: 130.61 - lr: 0.000030
2021-07-23 03:29:59,971 epoch 15 - iter 2352/3361 - loss 0.05090036 - samples/sec: 130.90 - lr: 0.000030
2021-07-23 03:31:22,357 epoch 15 - iter 2688/3361 - loss 0.05033713 - samples/sec: 130.53 - lr: 0.000030
2021-07-23 03:32:44,145 epoch 15 - iter 3024/3361 - loss 0.05045736 - samples/sec: 131.49 - lr: 0.000030
2021-07-23 03:34:05,549 epoch 15 - iter 3360/3361 - loss 0.05096185 - samples/sec: 132.11 - lr: 0.000030
2021-07-23 03:34:05,610 ----------------------------------------------------------------------------------------------------
2021-07-23 03:34:05,611 EPOCH 15 done: loss 0.0509 - lr 0.0000300
2021-07-23 03:34:18,797 DEV : loss 0.03924252465367317 - score 0.9901
2021-07-23 03:34:18,941 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 03:34:21,309 ----------------------------------------------------------------------------------------------------
2021-07-23 03:35:43,155 epoch 16 - iter 336/3361 - loss 0.04885162 - samples/sec: 131.40 - lr: 0.000030
2021-07-23 03:37:05,415 epoch 16 - iter 672/3361 - loss 0.05120680 - samples/sec: 130.73 - lr: 0.000030
2021-07-23 03:38:27,436 epoch 16 - iter 1008/3361 - loss 0.05167693 - samples/sec: 131.12 - lr: 0.000030
2021-07-23 03:39:48,612 epoch 16 - iter 1344/3361 - loss 0.05051465 - samples/sec: 132.48 - lr: 0.000030
2021-07-23 03:41:09,989 epoch 16 - iter 1680/3361 - loss 0.05008136 - samples/sec: 132.15 - lr: 0.000030
2021-07-23 03:42:31,813 epoch 16 - iter 2016/3361 - loss 0.05051795 - samples/sec: 131.43 - lr: 0.000030
2021-07-23 03:43:52,875 epoch 16 - iter 2352/3361 - loss 0.05062501 - samples/sec: 132.67 - lr: 0.000030
2021-07-23 03:45:14,709 epoch 16 - iter 2688/3361 - loss 0.05052263 - samples/sec: 131.42 - lr: 0.000030
2021-07-23 03:46:35,347 epoch 16 - iter 3024/3361 - loss 0.05039941 - samples/sec: 133.36 - lr: 0.000030
2021-07-23 03:47:57,797 epoch 16 - iter 3360/3361 - loss 0.05028933 - samples/sec: 130.43 - lr: 0.000030
2021-07-23 03:47:57,883 ----------------------------------------------------------------------------------------------------
2021-07-23 03:47:57,883 EPOCH 16 done: loss 0.0503 - lr 0.0000300
2021-07-23 03:48:11,063 DEV : loss 0.03959066420793533 - score 0.9904
2021-07-23 03:48:11,206 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 03:48:13,515 ----------------------------------------------------------------------------------------------------
2021-07-23 03:49:34,953 epoch 17 - iter 336/3361 - loss 0.04696632 - samples/sec: 132.07 - lr: 0.000030
2021-07-23 03:50:56,691 epoch 17 - iter 672/3361 - loss 0.04854655 - samples/sec: 131.57 - lr: 0.000030
2021-07-23 03:52:19,396 epoch 17 - iter 1008/3361 - loss 0.05104465 - samples/sec: 130.03 - lr: 0.000030
2021-07-23 03:53:41,633 epoch 17 - iter 1344/3361 - loss 0.05007327 - samples/sec: 130.77 - lr: 0.000030
2021-07-23 03:55:03,555 epoch 17 - iter 1680/3361 - loss 0.05027099 - samples/sec: 131.28 - lr: 0.000030
2021-07-23 03:56:25,507 epoch 17 - iter 2016/3361 - loss 0.05006676 - samples/sec: 131.22 - lr: 0.000030
2021-07-23 03:57:48,359 epoch 17 - iter 2352/3361 - loss 0.05008993 - samples/sec: 129.80 - lr: 0.000030
2021-07-23 03:59:10,147 epoch 17 - iter 2688/3361 - loss 0.04938859 - samples/sec: 131.49 - lr: 0.000030
2021-07-23 04:00:32,772 epoch 17 - iter 3024/3361 - loss 0.04918259 - samples/sec: 130.16 - lr: 0.000030
2021-07-23 04:01:54,514 epoch 17 - iter 3360/3361 - loss 0.04929682 - samples/sec: 131.56 - lr: 0.000030
2021-07-23 04:01:54,591 ----------------------------------------------------------------------------------------------------
2021-07-23 04:01:54,591 EPOCH 17 done: loss 0.0493 - lr 0.0000300
2021-07-23 04:02:07,789 DEV : loss 0.0383438803255558 - score 0.9904
2021-07-23 04:02:07,934 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 04:02:10,147 ----------------------------------------------------------------------------------------------------
2021-07-23 04:03:32,327 epoch 18 - iter 336/3361 - loss 0.04590425 - samples/sec: 130.87 - lr: 0.000030
2021-07-23 04:04:55,098 epoch 18 - iter 672/3361 - loss 0.04715012 - samples/sec: 129.93 - lr: 0.000030
2021-07-23 04:06:15,913 epoch 18 - iter 1008/3361 - loss 0.04595091 - samples/sec: 133.07 - lr: 0.000030
2021-07-23 04:07:38,609 epoch 18 - iter 1344/3361 - loss 0.04786275 - samples/sec: 130.04 - lr: 0.000030
2021-07-23 04:09:01,055 epoch 18 - iter 1680/3361 - loss 0.04795047 - samples/sec: 130.44 - lr: 0.000030
2021-07-23 04:10:23,187 epoch 18 - iter 2016/3361 - loss 0.04823328 - samples/sec: 130.94 - lr: 0.000030
2021-07-23 04:11:45,863 epoch 18 - iter 2352/3361 - loss 0.04864300 - samples/sec: 130.08 - lr: 0.000030
2021-07-23 04:13:08,136 epoch 18 - iter 2688/3361 - loss 0.04841453 - samples/sec: 130.71 - lr: 0.000030
2021-07-23 04:14:29,681 epoch 18 - iter 3024/3361 - loss 0.04880005 - samples/sec: 131.88 - lr: 0.000030
2021-07-23 04:15:51,452 epoch 18 - iter 3360/3361 - loss 0.04808657 - samples/sec: 131.52 - lr: 0.000030
2021-07-23 04:15:51,535 ----------------------------------------------------------------------------------------------------
2021-07-23 04:15:51,535 EPOCH 18 done: loss 0.0481 - lr 0.0000300
2021-07-23 04:16:07,787 DEV : loss 0.0396246574819088 - score 0.9905
2021-07-23 04:16:07,931 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 04:16:10,391 ----------------------------------------------------------------------------------------------------
2021-07-23 04:17:32,126 epoch 19 - iter 336/3361 - loss 0.04475271 - samples/sec: 131.59 - lr: 0.000030
2021-07-23 04:18:54,077 epoch 19 - iter 672/3361 - loss 0.04616663 - samples/sec: 131.23 - lr: 0.000030
2021-07-23 04:20:16,583 epoch 19 - iter 1008/3361 - loss 0.04735557 - samples/sec: 130.34 - lr: 0.000030
2021-07-23 04:21:38,579 epoch 19 - iter 1344/3361 - loss 0.04723793 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 04:23:00,057 epoch 19 - iter 1680/3361 - loss 0.04669625 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 04:24:21,829 epoch 19 - iter 2016/3361 - loss 0.04631436 - samples/sec: 131.51 - lr: 0.000030
2021-07-23 04:25:43,791 epoch 19 - iter 2352/3361 - loss 0.04615751 - samples/sec: 131.21 - lr: 0.000030
2021-07-23 04:27:05,720 epoch 19 - iter 2688/3361 - loss 0.04640942 - samples/sec: 131.26 - lr: 0.000030
2021-07-23 04:28:27,788 epoch 19 - iter 3024/3361 - loss 0.04708871 - samples/sec: 131.04 - lr: 0.000030
2021-07-23 04:29:50,699 epoch 19 - iter 3360/3361 - loss 0.04706936 - samples/sec: 129.71 - lr: 0.000030
2021-07-23 04:29:50,774 ----------------------------------------------------------------------------------------------------
2021-07-23 04:29:50,774 EPOCH 19 done: loss 0.0471 - lr 0.0000300
2021-07-23 04:30:03,964 DEV : loss 0.04007392004132271 - score 0.9898
2021-07-23 04:30:04,107 BAD EPOCHS (no improvement): 1
2021-07-23 04:30:04,108 ----------------------------------------------------------------------------------------------------
2021-07-23 04:31:25,295 epoch 20 - iter 336/3361 - loss 0.04557002 - samples/sec: 132.47 - lr: 0.000030
2021-07-23 04:32:47,013 epoch 20 - iter 672/3361 - loss 0.04463935 - samples/sec: 131.60 - lr: 0.000030
2021-07-23 04:34:08,467 epoch 20 - iter 1008/3361 - loss 0.04596350 - samples/sec: 132.03 - lr: 0.000030
2021-07-23 04:35:29,947 epoch 20 - iter 1344/3361 - loss 0.04561003 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 04:36:51,976 epoch 20 - iter 1680/3361 - loss 0.04568020 - samples/sec: 131.10 - lr: 0.000030
2021-07-23 04:38:13,803 epoch 20 - iter 2016/3361 - loss 0.04605435 - samples/sec: 131.43 - lr: 0.000030
2021-07-23 04:39:36,521 epoch 20 - iter 2352/3361 - loss 0.04530677 - samples/sec: 130.01 - lr: 0.000030
2021-07-23 04:40:58,620 epoch 20 - iter 2688/3361 - loss 0.04547136 - samples/sec: 130.99 - lr: 0.000030
2021-07-23 04:42:20,696 epoch 20 - iter 3024/3361 - loss 0.04571155 - samples/sec: 131.03 - lr: 0.000030
2021-07-23 04:43:42,870 epoch 20 - iter 3360/3361 - loss 0.04579192 - samples/sec: 130.87 - lr: 0.000030
2021-07-23 04:43:42,951 ----------------------------------------------------------------------------------------------------
2021-07-23 04:43:42,951 EPOCH 20 done: loss 0.0458 - lr 0.0000300
2021-07-23 04:43:56,227 DEV : loss 0.04079195484519005 - score 0.9902
2021-07-23 04:43:56,367 BAD EPOCHS (no improvement): 2
2021-07-23 04:43:56,368 ----------------------------------------------------------------------------------------------------
2021-07-23 04:45:18,256 epoch 21 - iter 336/3361 - loss 0.04489575 - samples/sec: 131.34 - lr: 0.000030
2021-07-23 04:46:40,639 epoch 21 - iter 672/3361 - loss 0.04733137 - samples/sec: 130.54 - lr: 0.000030
2021-07-23 04:48:02,838 epoch 21 - iter 1008/3361 - loss 0.04651348 - samples/sec: 130.83 - lr: 0.000030
2021-07-23 04:49:24,149 epoch 21 - iter 1344/3361 - loss 0.04725374 - samples/sec: 132.26 - lr: 0.000030
2021-07-23 04:50:45,628 epoch 21 - iter 1680/3361 - loss 0.04701316 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 04:52:07,514 epoch 21 - iter 2016/3361 - loss 0.04627750 - samples/sec: 131.33 - lr: 0.000030
2021-07-23 04:53:30,194 epoch 21 - iter 2352/3361 - loss 0.04593526 - samples/sec: 130.07 - lr: 0.000030
2021-07-23 04:54:52,152 epoch 21 - iter 2688/3361 - loss 0.04562351 - samples/sec: 131.22 - lr: 0.000030
2021-07-23 04:56:14,909 epoch 21 - iter 3024/3361 - loss 0.04588069 - samples/sec: 129.95 - lr: 0.000030
2021-07-23 04:57:36,669 epoch 21 - iter 3360/3361 - loss 0.04618276 - samples/sec: 131.53 - lr: 0.000030
2021-07-23 04:57:36,758 ----------------------------------------------------------------------------------------------------
2021-07-23 04:57:36,758 EPOCH 21 done: loss 0.0462 - lr 0.0000300
2021-07-23 04:57:50,047 DEV : loss 0.03975381702184677 - score 0.9908
2021-07-23 04:57:50,190 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 04:57:52,398 ----------------------------------------------------------------------------------------------------
2021-07-23 04:59:13,547 epoch 22 - iter 336/3361 - loss 0.04614733 - samples/sec: 132.54 - lr: 0.000030
2021-07-23 05:00:34,615 epoch 22 - iter 672/3361 - loss 0.04256741 - samples/sec: 132.66 - lr: 0.000030
2021-07-23 05:01:56,943 epoch 22 - iter 1008/3361 - loss 0.04328890 - samples/sec: 130.63 - lr: 0.000030
2021-07-23 05:03:18,911 epoch 22 - iter 1344/3361 - loss 0.04359458 - samples/sec: 131.20 - lr: 0.000030
2021-07-23 05:04:41,059 epoch 22 - iter 1680/3361 - loss 0.04324748 - samples/sec: 130.91 - lr: 0.000030
2021-07-23 05:06:03,380 epoch 22 - iter 2016/3361 - loss 0.04286786 - samples/sec: 130.64 - lr: 0.000030
2021-07-23 05:07:26,132 epoch 22 - iter 2352/3361 - loss 0.04311228 - samples/sec: 129.96 - lr: 0.000030
2021-07-23 05:08:48,956 epoch 22 - iter 2688/3361 - loss 0.04311119 - samples/sec: 129.84 - lr: 0.000030
2021-07-23 05:10:11,195 epoch 22 - iter 3024/3361 - loss 0.04344502 - samples/sec: 130.77 - lr: 0.000030
2021-07-23 05:11:33,788 epoch 22 - iter 3360/3361 - loss 0.04396107 - samples/sec: 130.21 - lr: 0.000030
2021-07-23 05:11:33,859 ----------------------------------------------------------------------------------------------------
2021-07-23 05:11:33,859 EPOCH 22 done: loss 0.0439 - lr 0.0000300
2021-07-23 05:11:47,137 DEV : loss 0.041246604174375534 - score 0.9901
2021-07-23 05:11:47,280 BAD EPOCHS (no improvement): 1
2021-07-23 05:11:47,280 ----------------------------------------------------------------------------------------------------
2021-07-23 05:13:08,984 epoch 23 - iter 336/3361 - loss 0.03931906 - samples/sec: 131.63 - lr: 0.000030
2021-07-23 05:14:30,419 epoch 23 - iter 672/3361 - loss 0.04092024 - samples/sec: 132.06 - lr: 0.000030
2021-07-23 05:15:52,329 epoch 23 - iter 1008/3361 - loss 0.04155906 - samples/sec: 131.29 - lr: 0.000030
2021-07-23 05:17:14,260 epoch 23 - iter 1344/3361 - loss 0.04181995 - samples/sec: 131.26 - lr: 0.000030
2021-07-23 05:18:36,036 epoch 23 - iter 1680/3361 - loss 0.04266809 - samples/sec: 131.51 - lr: 0.000030
2021-07-23 05:19:58,365 epoch 23 - iter 2016/3361 - loss 0.04284178 - samples/sec: 130.62 - lr: 0.000030
2021-07-23 05:21:20,203 epoch 23 - iter 2352/3361 - loss 0.04282060 - samples/sec: 131.41 - lr: 0.000030
2021-07-23 05:22:42,595 epoch 23 - iter 2688/3361 - loss 0.04320673 - samples/sec: 130.52 - lr: 0.000030
2021-07-23 05:24:05,184 epoch 23 - iter 3024/3361 - loss 0.04324192 - samples/sec: 130.21 - lr: 0.000030
2021-07-23 05:25:27,393 epoch 23 - iter 3360/3361 - loss 0.04315459 - samples/sec: 130.82 - lr: 0.000030
2021-07-23 05:25:27,475 ----------------------------------------------------------------------------------------------------
2021-07-23 05:25:27,475 EPOCH 23 done: loss 0.0431 - lr 0.0000300
2021-07-23 05:25:40,664 DEV : loss 0.040276575833559036 - score 0.9901
2021-07-23 05:25:40,807 BAD EPOCHS (no improvement): 2
2021-07-23 05:25:40,808 ----------------------------------------------------------------------------------------------------
2021-07-23 05:27:03,434 epoch 24 - iter 336/3361 - loss 0.04164392 - samples/sec: 130.16 - lr: 0.000030
2021-07-23 05:28:25,303 epoch 24 - iter 672/3361 - loss 0.04072607 - samples/sec: 131.36 - lr: 0.000030
2021-07-23 05:29:47,895 epoch 24 - iter 1008/3361 - loss 0.04160362 - samples/sec: 130.21 - lr: 0.000030
2021-07-23 05:31:10,260 epoch 24 - iter 1344/3361 - loss 0.04234962 - samples/sec: 130.57 - lr: 0.000030
2021-07-23 05:32:32,415 epoch 24 - iter 1680/3361 - loss 0.04288473 - samples/sec: 130.90 - lr: 0.000030
2021-07-23 05:33:54,751 epoch 24 - iter 2016/3361 - loss 0.04301369 - samples/sec: 130.61 - lr: 0.000030
2021-07-23 05:35:16,252 epoch 24 - iter 2352/3361 - loss 0.04311886 - samples/sec: 131.95 - lr: 0.000030
2021-07-23 05:36:38,232 epoch 24 - iter 2688/3361 - loss 0.04318799 - samples/sec: 131.18 - lr: 0.000030
2021-07-23 05:38:00,563 epoch 24 - iter 3024/3361 - loss 0.04382555 - samples/sec: 130.62 - lr: 0.000030
2021-07-23 05:39:22,773 epoch 24 - iter 3360/3361 - loss 0.04308011 - samples/sec: 130.81 - lr: 0.000030
2021-07-23 05:39:22,841 ----------------------------------------------------------------------------------------------------
2021-07-23 05:39:22,841 EPOCH 24 done: loss 0.0431 - lr 0.0000300
2021-07-23 05:39:36,110 DEV : loss 0.04250197112560272 - score 0.9902
2021-07-23 05:39:36,253 BAD EPOCHS (no improvement): 3
2021-07-23 05:39:36,253 ----------------------------------------------------------------------------------------------------
2021-07-23 05:40:58,444 epoch 25 - iter 336/3361 - loss 0.04358962 - samples/sec: 130.85 - lr: 0.000030
2021-07-23 05:42:20,766 epoch 25 - iter 672/3361 - loss 0.04099260 - samples/sec: 130.63 - lr: 0.000030
2021-07-23 05:43:43,585 epoch 25 - iter 1008/3361 - loss 0.04246023 - samples/sec: 129.85 - lr: 0.000030
2021-07-23 05:45:05,903 epoch 25 - iter 1344/3361 - loss 0.04309073 - samples/sec: 130.64 - lr: 0.000030
2021-07-23 05:46:28,131 epoch 25 - iter 1680/3361 - loss 0.04265136 - samples/sec: 130.78 - lr: 0.000030
2021-07-23 05:47:50,141 epoch 25 - iter 2016/3361 - loss 0.04300902 - samples/sec: 131.13 - lr: 0.000030
2021-07-23 05:49:12,161 epoch 25 - iter 2352/3361 - loss 0.04364865 - samples/sec: 131.12 - lr: 0.000030
2021-07-23 05:50:33,973 epoch 25 - iter 2688/3361 - loss 0.04379301 - samples/sec: 131.45 - lr: 0.000030
2021-07-23 05:51:55,486 epoch 25 - iter 3024/3361 - loss 0.04418036 - samples/sec: 131.93 - lr: 0.000030
2021-07-23 05:53:17,827 epoch 25 - iter 3360/3361 - loss 0.04421704 - samples/sec: 130.61 - lr: 0.000030
2021-07-23 05:53:17,898 ----------------------------------------------------------------------------------------------------
2021-07-23 05:53:17,898 EPOCH 25 done: loss 0.0442 - lr 0.0000300
2021-07-23 05:53:34,180 DEV : loss 0.04036004841327667 - score 0.9899
Epoch    25: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 05:53:34,325 BAD EPOCHS (no improvement): 4
2021-07-23 05:53:34,326 ----------------------------------------------------------------------------------------------------
2021-07-23 05:54:57,149 epoch 26 - iter 336/3361 - loss 0.04375861 - samples/sec: 129.85 - lr: 0.000015
2021-07-23 05:56:18,769 epoch 26 - iter 672/3361 - loss 0.04167882 - samples/sec: 131.76 - lr: 0.000015
2021-07-23 05:57:40,643 epoch 26 - iter 1008/3361 - loss 0.04124345 - samples/sec: 131.35 - lr: 0.000015
2021-07-23 05:59:02,474 epoch 26 - iter 1344/3361 - loss 0.04169153 - samples/sec: 131.42 - lr: 0.000015
2021-07-23 06:00:24,449 epoch 26 - iter 1680/3361 - loss 0.04162357 - samples/sec: 131.19 - lr: 0.000015
2021-07-23 06:01:46,838 epoch 26 - iter 2016/3361 - loss 0.04134436 - samples/sec: 130.53 - lr: 0.000015
2021-07-23 06:03:08,946 epoch 26 - iter 2352/3361 - loss 0.04129159 - samples/sec: 130.98 - lr: 0.000015
2021-07-23 06:04:31,294 epoch 26 - iter 2688/3361 - loss 0.04153529 - samples/sec: 130.59 - lr: 0.000015
2021-07-23 06:05:53,351 epoch 26 - iter 3024/3361 - loss 0.04149779 - samples/sec: 131.06 - lr: 0.000015
2021-07-23 06:07:15,136 epoch 26 - iter 3360/3361 - loss 0.04099188 - samples/sec: 131.49 - lr: 0.000015
2021-07-23 06:07:15,219 ----------------------------------------------------------------------------------------------------
2021-07-23 06:07:15,219 EPOCH 26 done: loss 0.0410 - lr 0.0000150
2021-07-23 06:07:28,484 DEV : loss 0.04303646832704544 - score 0.9896
2021-07-23 06:07:28,627 BAD EPOCHS (no improvement): 1
2021-07-23 06:07:28,628 ----------------------------------------------------------------------------------------------------
2021-07-23 06:08:50,951 epoch 27 - iter 336/3361 - loss 0.03716397 - samples/sec: 130.64 - lr: 0.000015
2021-07-23 06:10:12,833 epoch 27 - iter 672/3361 - loss 0.03817744 - samples/sec: 131.34 - lr: 0.000015
2021-07-23 06:11:35,018 epoch 27 - iter 1008/3361 - loss 0.04010449 - samples/sec: 130.85 - lr: 0.000015
2021-07-23 06:12:57,711 epoch 27 - iter 1344/3361 - loss 0.04020514 - samples/sec: 130.05 - lr: 0.000015
2021-07-23 06:14:20,440 epoch 27 - iter 1680/3361 - loss 0.03979238 - samples/sec: 129.99 - lr: 0.000015
2021-07-23 06:15:42,719 epoch 27 - iter 2016/3361 - loss 0.03936254 - samples/sec: 130.70 - lr: 0.000015
2021-07-23 06:17:04,163 epoch 27 - iter 2352/3361 - loss 0.03950251 - samples/sec: 132.04 - lr: 0.000015
2021-07-23 06:18:25,649 epoch 27 - iter 2688/3361 - loss 0.03987918 - samples/sec: 131.98 - lr: 0.000015
2021-07-23 06:19:48,336 epoch 27 - iter 3024/3361 - loss 0.03971223 - samples/sec: 130.06 - lr: 0.000015
2021-07-23 06:21:10,613 epoch 27 - iter 3360/3361 - loss 0.03988044 - samples/sec: 130.71 - lr: 0.000015
2021-07-23 06:21:10,699 ----------------------------------------------------------------------------------------------------
2021-07-23 06:21:10,699 EPOCH 27 done: loss 0.0399 - lr 0.0000150
2021-07-23 06:21:24,006 DEV : loss 0.03925344720482826 - score 0.9902
2021-07-23 06:21:24,149 BAD EPOCHS (no improvement): 2
2021-07-23 06:21:24,150 ----------------------------------------------------------------------------------------------------
2021-07-23 06:22:46,619 epoch 28 - iter 336/3361 - loss 0.03864093 - samples/sec: 130.41 - lr: 0.000015
2021-07-23 06:24:08,032 epoch 28 - iter 672/3361 - loss 0.03772312 - samples/sec: 132.09 - lr: 0.000015
2021-07-23 06:25:30,444 epoch 28 - iter 1008/3361 - loss 0.03632202 - samples/sec: 130.49 - lr: 0.000015
2021-07-23 06:26:51,960 epoch 28 - iter 1344/3361 - loss 0.03601113 - samples/sec: 131.93 - lr: 0.000015
2021-07-23 06:28:12,991 epoch 28 - iter 1680/3361 - loss 0.03607754 - samples/sec: 132.72 - lr: 0.000015
2021-07-23 06:29:34,569 epoch 28 - iter 2016/3361 - loss 0.03728076 - samples/sec: 131.83 - lr: 0.000015
2021-07-23 06:30:55,945 epoch 28 - iter 2352/3361 - loss 0.03816637 - samples/sec: 132.15 - lr: 0.000015
2021-07-23 06:32:18,329 epoch 28 - iter 2688/3361 - loss 0.03877328 - samples/sec: 130.54 - lr: 0.000015
2021-07-23 06:33:40,192 epoch 28 - iter 3024/3361 - loss 0.03885807 - samples/sec: 131.37 - lr: 0.000015
2021-07-23 06:35:02,912 epoch 28 - iter 3360/3361 - loss 0.03893403 - samples/sec: 130.01 - lr: 0.000015
2021-07-23 06:35:02,971 ----------------------------------------------------------------------------------------------------
2021-07-23 06:35:02,971 EPOCH 28 done: loss 0.0389 - lr 0.0000150
2021-07-23 06:35:16,180 DEV : loss 0.04049801826477051 - score 0.9906
2021-07-23 06:35:16,324 BAD EPOCHS (no improvement): 3
2021-07-23 06:35:16,324 ----------------------------------------------------------------------------------------------------
2021-07-23 06:36:39,200 epoch 29 - iter 336/3361 - loss 0.03663886 - samples/sec: 129.77 - lr: 0.000015
2021-07-23 06:38:01,414 epoch 29 - iter 672/3361 - loss 0.03861152 - samples/sec: 130.81 - lr: 0.000015
2021-07-23 06:39:23,333 epoch 29 - iter 1008/3361 - loss 0.03792807 - samples/sec: 131.28 - lr: 0.000015
2021-07-23 06:40:45,523 epoch 29 - iter 1344/3361 - loss 0.03736209 - samples/sec: 130.84 - lr: 0.000015
2021-07-23 06:42:07,424 epoch 29 - iter 1680/3361 - loss 0.03727070 - samples/sec: 131.31 - lr: 0.000015
2021-07-23 06:43:30,353 epoch 29 - iter 2016/3361 - loss 0.03788875 - samples/sec: 129.68 - lr: 0.000015
2021-07-23 06:44:52,784 epoch 29 - iter 2352/3361 - loss 0.03808660 - samples/sec: 130.46 - lr: 0.000015
2021-07-23 06:46:14,108 epoch 29 - iter 2688/3361 - loss 0.03821787 - samples/sec: 132.24 - lr: 0.000015
2021-07-23 06:47:36,287 epoch 29 - iter 3024/3361 - loss 0.03803601 - samples/sec: 130.86 - lr: 0.000015
2021-07-23 06:48:58,101 epoch 29 - iter 3360/3361 - loss 0.03819533 - samples/sec: 131.45 - lr: 0.000015
2021-07-23 06:48:58,174 ----------------------------------------------------------------------------------------------------
2021-07-23 06:48:58,175 EPOCH 29 done: loss 0.0383 - lr 0.0000150
2021-07-23 06:49:11,473 DEV : loss 0.0404544398188591 - score 0.99
Epoch    29: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 06:49:11,617 BAD EPOCHS (no improvement): 4
2021-07-23 06:49:11,618 ----------------------------------------------------------------------------------------------------
2021-07-23 06:50:33,299 epoch 30 - iter 336/3361 - loss 0.03893260 - samples/sec: 131.67 - lr: 0.000008
2021-07-23 06:51:55,977 epoch 30 - iter 672/3361 - loss 0.03865764 - samples/sec: 130.07 - lr: 0.000008
2021-07-23 06:53:18,671 epoch 30 - iter 1008/3361 - loss 0.03751776 - samples/sec: 130.05 - lr: 0.000008
2021-07-23 06:54:41,270 epoch 30 - iter 1344/3361 - loss 0.03811030 - samples/sec: 130.20 - lr: 0.000008
2021-07-23 06:56:04,048 epoch 30 - iter 1680/3361 - loss 0.03802804 - samples/sec: 129.92 - lr: 0.000008
2021-07-23 06:57:25,075 epoch 30 - iter 2016/3361 - loss 0.03818439 - samples/sec: 132.72 - lr: 0.000008
2021-07-23 06:58:47,382 epoch 30 - iter 2352/3361 - loss 0.03787175 - samples/sec: 130.66 - lr: 0.000008
2021-07-23 07:00:09,396 epoch 30 - iter 2688/3361 - loss 0.03777119 - samples/sec: 131.13 - lr: 0.000008
2021-07-23 07:01:31,380 epoch 30 - iter 3024/3361 - loss 0.03749099 - samples/sec: 131.17 - lr: 0.000008
2021-07-23 07:02:54,003 epoch 30 - iter 3360/3361 - loss 0.03744708 - samples/sec: 130.16 - lr: 0.000008
2021-07-23 07:02:54,066 ----------------------------------------------------------------------------------------------------
2021-07-23 07:02:54,066 EPOCH 30 done: loss 0.0374 - lr 0.0000075
2021-07-23 07:03:07,366 DEV : loss 0.04166698083281517 - score 0.9892
2021-07-23 07:03:07,510 BAD EPOCHS (no improvement): 1
2021-07-23 07:03:07,510 ----------------------------------------------------------------------------------------------------
2021-07-23 07:04:29,456 epoch 31 - iter 336/3361 - loss 0.03675827 - samples/sec: 131.25 - lr: 0.000008
2021-07-23 07:05:51,097 epoch 31 - iter 672/3361 - loss 0.03697907 - samples/sec: 131.72 - lr: 0.000008
2021-07-23 07:07:13,727 epoch 31 - iter 1008/3361 - loss 0.03725412 - samples/sec: 130.15 - lr: 0.000008
2021-07-23 07:08:35,881 epoch 31 - iter 1344/3361 - loss 0.03749369 - samples/sec: 130.90 - lr: 0.000008
2021-07-23 07:09:58,116 epoch 31 - iter 1680/3361 - loss 0.03704529 - samples/sec: 130.77 - lr: 0.000008
2021-07-23 07:11:20,093 epoch 31 - iter 2016/3361 - loss 0.03647633 - samples/sec: 131.19 - lr: 0.000008
2021-07-23 07:12:42,659 epoch 31 - iter 2352/3361 - loss 0.03665679 - samples/sec: 130.25 - lr: 0.000008
2021-07-23 07:14:04,608 epoch 31 - iter 2688/3361 - loss 0.03692747 - samples/sec: 131.23 - lr: 0.000008
2021-07-23 07:15:26,969 epoch 31 - iter 3024/3361 - loss 0.03707135 - samples/sec: 130.57 - lr: 0.000008
2021-07-23 07:16:49,666 epoch 31 - iter 3360/3361 - loss 0.03675866 - samples/sec: 130.04 - lr: 0.000008
2021-07-23 07:16:49,754 ----------------------------------------------------------------------------------------------------
2021-07-23 07:16:49,754 EPOCH 31 done: loss 0.0368 - lr 0.0000075
2021-07-23 07:17:02,961 DEV : loss 0.04140663519501686 - score 0.9898
2021-07-23 07:17:03,108 BAD EPOCHS (no improvement): 2
2021-07-23 07:17:03,108 ----------------------------------------------------------------------------------------------------
2021-07-23 07:18:25,773 epoch 32 - iter 336/3361 - loss 0.03711937 - samples/sec: 130.10 - lr: 0.000008
2021-07-23 07:19:47,976 epoch 32 - iter 672/3361 - loss 0.03647161 - samples/sec: 130.82 - lr: 0.000008
2021-07-23 07:21:09,663 epoch 32 - iter 1008/3361 - loss 0.03700327 - samples/sec: 131.65 - lr: 0.000008
2021-07-23 07:22:30,859 epoch 32 - iter 1344/3361 - loss 0.03575672 - samples/sec: 132.45 - lr: 0.000008
2021-07-23 07:23:52,234 epoch 32 - iter 1680/3361 - loss 0.03643513 - samples/sec: 132.15 - lr: 0.000008
2021-07-23 07:25:13,914 epoch 32 - iter 2016/3361 - loss 0.03707084 - samples/sec: 131.66 - lr: 0.000008
2021-07-23 07:26:35,357 epoch 32 - iter 2352/3361 - loss 0.03616153 - samples/sec: 132.05 - lr: 0.000008
2021-07-23 07:27:57,083 epoch 32 - iter 2688/3361 - loss 0.03601612 - samples/sec: 131.59 - lr: 0.000008
2021-07-23 07:29:19,890 epoch 32 - iter 3024/3361 - loss 0.03601533 - samples/sec: 129.87 - lr: 0.000008
2021-07-23 07:30:42,701 epoch 32 - iter 3360/3361 - loss 0.03676306 - samples/sec: 129.86 - lr: 0.000008
2021-07-23 07:30:42,787 ----------------------------------------------------------------------------------------------------
2021-07-23 07:30:42,787 EPOCH 32 done: loss 0.0368 - lr 0.0000075
2021-07-23 07:30:55,972 DEV : loss 0.040710728615522385 - score 0.99
2021-07-23 07:30:56,115 BAD EPOCHS (no improvement): 3
2021-07-23 07:30:56,116 ----------------------------------------------------------------------------------------------------
2021-07-23 07:32:21,269 epoch 33 - iter 336/3361 - loss 0.03527642 - samples/sec: 126.30 - lr: 0.000008
2021-07-23 07:33:44,084 epoch 33 - iter 672/3361 - loss 0.03660696 - samples/sec: 129.86 - lr: 0.000008
2021-07-23 07:35:05,465 epoch 33 - iter 1008/3361 - loss 0.03683999 - samples/sec: 132.15 - lr: 0.000008
2021-07-23 07:36:27,413 epoch 33 - iter 1344/3361 - loss 0.03680501 - samples/sec: 131.23 - lr: 0.000008
2021-07-23 07:37:49,079 epoch 33 - iter 1680/3361 - loss 0.03662155 - samples/sec: 131.68 - lr: 0.000008
2021-07-23 07:39:11,428 epoch 33 - iter 2016/3361 - loss 0.03610171 - samples/sec: 130.59 - lr: 0.000008
2021-07-23 07:40:33,695 epoch 33 - iter 2352/3361 - loss 0.03672427 - samples/sec: 130.72 - lr: 0.000008
2021-07-23 07:41:55,929 epoch 33 - iter 2688/3361 - loss 0.03625708 - samples/sec: 130.78 - lr: 0.000008
2021-07-23 07:43:17,652 epoch 33 - iter 3024/3361 - loss 0.03635596 - samples/sec: 131.59 - lr: 0.000008
2021-07-23 07:44:39,371 epoch 33 - iter 3360/3361 - loss 0.03642022 - samples/sec: 131.60 - lr: 0.000008
2021-07-23 07:44:39,465 ----------------------------------------------------------------------------------------------------
2021-07-23 07:44:39,466 EPOCH 33 done: loss 0.0364 - lr 0.0000075
2021-07-23 07:44:52,782 DEV : loss 0.03953792527318001 - score 0.9907
Epoch    33: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 07:44:52,924 BAD EPOCHS (no improvement): 4
2021-07-23 07:44:52,925 ----------------------------------------------------------------------------------------------------
2021-07-23 07:46:14,855 epoch 34 - iter 336/3361 - loss 0.03624688 - samples/sec: 131.27 - lr: 0.000004
2021-07-23 07:47:36,977 epoch 34 - iter 672/3361 - loss 0.03567677 - samples/sec: 130.95 - lr: 0.000004
2021-07-23 07:48:58,520 epoch 34 - iter 1008/3361 - loss 0.03443535 - samples/sec: 131.88 - lr: 0.000004
2021-07-23 07:50:21,384 epoch 34 - iter 1344/3361 - loss 0.03523957 - samples/sec: 129.78 - lr: 0.000004
2021-07-23 07:51:43,803 epoch 34 - iter 1680/3361 - loss 0.03521682 - samples/sec: 130.48 - lr: 0.000004
2021-07-23 07:53:05,858 epoch 34 - iter 2016/3361 - loss 0.03590059 - samples/sec: 131.06 - lr: 0.000004
2021-07-23 07:54:28,621 epoch 34 - iter 2352/3361 - loss 0.03559822 - samples/sec: 129.94 - lr: 0.000004
2021-07-23 07:55:50,657 epoch 34 - iter 2688/3361 - loss 0.03542941 - samples/sec: 131.09 - lr: 0.000004
2021-07-23 07:57:12,587 epoch 34 - iter 3024/3361 - loss 0.03566969 - samples/sec: 131.26 - lr: 0.000004
2021-07-23 07:58:34,845 epoch 34 - iter 3360/3361 - loss 0.03588891 - samples/sec: 130.74 - lr: 0.000004
2021-07-23 07:58:34,935 ----------------------------------------------------------------------------------------------------
2021-07-23 07:58:34,935 EPOCH 34 done: loss 0.0359 - lr 0.0000038
2021-07-23 07:58:48,178 DEV : loss 0.04289866238832474 - score 0.9894
2021-07-23 07:58:48,323 BAD EPOCHS (no improvement): 1
2021-07-23 07:58:48,323 ----------------------------------------------------------------------------------------------------
2021-07-23 08:00:10,921 epoch 35 - iter 336/3361 - loss 0.03428347 - samples/sec: 130.21 - lr: 0.000004
2021-07-23 08:01:33,437 epoch 35 - iter 672/3361 - loss 0.03500323 - samples/sec: 130.33 - lr: 0.000004
2021-07-23 08:02:55,160 epoch 35 - iter 1008/3361 - loss 0.03546395 - samples/sec: 131.59 - lr: 0.000004
2021-07-23 08:04:17,489 epoch 35 - iter 1344/3361 - loss 0.03456863 - samples/sec: 130.63 - lr: 0.000004
2021-07-23 08:05:39,222 epoch 35 - iter 1680/3361 - loss 0.03527749 - samples/sec: 131.58 - lr: 0.000004
2021-07-23 08:07:00,727 epoch 35 - iter 2016/3361 - loss 0.03591354 - samples/sec: 131.94 - lr: 0.000004
2021-07-23 08:08:22,724 epoch 35 - iter 2352/3361 - loss 0.03575196 - samples/sec: 131.15 - lr: 0.000004
2021-07-23 08:09:45,530 epoch 35 - iter 2688/3361 - loss 0.03590296 - samples/sec: 129.87 - lr: 0.000004
2021-07-23 08:11:08,211 epoch 35 - iter 3024/3361 - loss 0.03554330 - samples/sec: 130.07 - lr: 0.000004
2021-07-23 08:12:30,399 epoch 35 - iter 3360/3361 - loss 0.03561414 - samples/sec: 130.85 - lr: 0.000004
2021-07-23 08:12:30,482 ----------------------------------------------------------------------------------------------------
2021-07-23 08:12:30,483 EPOCH 35 done: loss 0.0356 - lr 0.0000038
2021-07-23 08:12:43,704 DEV : loss 0.04086398705840111 - score 0.9902
2021-07-23 08:12:43,846 BAD EPOCHS (no improvement): 2
2021-07-23 08:12:43,846 ----------------------------------------------------------------------------------------------------
2021-07-23 08:14:06,456 epoch 36 - iter 336/3361 - loss 0.03820329 - samples/sec: 130.19 - lr: 0.000004
2021-07-23 08:15:28,253 epoch 36 - iter 672/3361 - loss 0.03676570 - samples/sec: 131.47 - lr: 0.000004
2021-07-23 08:16:50,956 epoch 36 - iter 1008/3361 - loss 0.03562829 - samples/sec: 130.03 - lr: 0.000004
2021-07-23 08:18:13,771 epoch 36 - iter 1344/3361 - loss 0.03565009 - samples/sec: 129.86 - lr: 0.000004
2021-07-23 08:19:35,833 epoch 36 - iter 1680/3361 - loss 0.03592214 - samples/sec: 131.05 - lr: 0.000004
2021-07-23 08:20:57,547 epoch 36 - iter 2016/3361 - loss 0.03550366 - samples/sec: 131.61 - lr: 0.000004
2021-07-23 08:22:19,246 epoch 36 - iter 2352/3361 - loss 0.03529313 - samples/sec: 131.63 - lr: 0.000004
2021-07-23 08:23:41,828 epoch 36 - iter 2688/3361 - loss 0.03516166 - samples/sec: 130.22 - lr: 0.000004
2021-07-23 08:25:04,604 epoch 36 - iter 3024/3361 - loss 0.03503859 - samples/sec: 129.92 - lr: 0.000004
2021-07-23 08:26:26,949 epoch 36 - iter 3360/3361 - loss 0.03527400 - samples/sec: 130.60 - lr: 0.000004
2021-07-23 08:26:27,022 ----------------------------------------------------------------------------------------------------
2021-07-23 08:26:27,023 EPOCH 36 done: loss 0.0353 - lr 0.0000038
2021-07-23 08:26:40,270 DEV : loss 0.04062800109386444 - score 0.9901
2021-07-23 08:26:40,413 BAD EPOCHS (no improvement): 3
2021-07-23 08:26:40,414 ----------------------------------------------------------------------------------------------------
2021-07-23 08:28:02,353 epoch 37 - iter 336/3361 - loss 0.03725307 - samples/sec: 131.25 - lr: 0.000004
2021-07-23 08:29:24,317 epoch 37 - iter 672/3361 - loss 0.03520695 - samples/sec: 131.21 - lr: 0.000004
2021-07-23 08:30:46,356 epoch 37 - iter 1008/3361 - loss 0.03502601 - samples/sec: 131.09 - lr: 0.000004
2021-07-23 08:32:09,138 epoch 37 - iter 1344/3361 - loss 0.03538411 - samples/sec: 129.91 - lr: 0.000004
2021-07-23 08:33:30,789 epoch 37 - iter 1680/3361 - loss 0.03549013 - samples/sec: 131.71 - lr: 0.000004
2021-07-23 08:34:53,041 epoch 37 - iter 2016/3361 - loss 0.03579639 - samples/sec: 130.75 - lr: 0.000004
2021-07-23 08:36:15,489 epoch 37 - iter 2352/3361 - loss 0.03513478 - samples/sec: 130.44 - lr: 0.000004
2021-07-23 08:37:38,252 epoch 37 - iter 2688/3361 - loss 0.03489547 - samples/sec: 129.94 - lr: 0.000004
2021-07-23 08:39:00,964 epoch 37 - iter 3024/3361 - loss 0.03500510 - samples/sec: 130.02 - lr: 0.000004
2021-07-23 08:40:22,772 epoch 37 - iter 3360/3361 - loss 0.03478892 - samples/sec: 131.46 - lr: 0.000004
2021-07-23 08:40:22,858 ----------------------------------------------------------------------------------------------------
2021-07-23 08:40:22,858 EPOCH 37 done: loss 0.0348 - lr 0.0000038
2021-07-23 08:40:36,074 DEV : loss 0.04302405193448067 - score 0.9895
Epoch    37: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 08:40:36,218 BAD EPOCHS (no improvement): 4
2021-07-23 08:40:36,218 ----------------------------------------------------------------------------------------------------
2021-07-23 08:40:36,218 ----------------------------------------------------------------------------------------------------
2021-07-23 08:40:36,218 learning rate too small - quitting training!
2021-07-23 08:40:36,218 ----------------------------------------------------------------------------------------------------
2021-07-23 08:40:36,866 ----------------------------------------------------------------------------------------------------
2021-07-23 08:40:36,866 Testing using best model ...
2021-07-23 08:40:36,867 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.pdtb.pdtb/best-model.pt
2021-07-23 08:48:22,312 0.9896	0.9892	0.9894
2021-07-23 08:48:22,312 
Results:
- F1-score (micro) 0.9894
- F1-score (macro) 0.9885

By class:
SENT       tp: 10955 - fp: 252 - fn: 262 - precision: 0.9775 - recall: 0.9766 - f1-score: 0.9771
X          tp: 12957 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 08:48:22,312 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/rus.rst.rrt/
2021-07-23 08:48:22,358 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/rus.rst.rrt
2021-07-23 08:48:22,359 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/rus.rst.rrt/sent_train.txt
2021-07-23 08:48:22,360 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/rus.rst.rrt/sent_dev.txt
2021-07-23 08:48:22,362 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/rus.rst.rrt/sent_test.txt
Corpus: 45166 train + 5825 dev + 10064 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 08:48:39,530 ----------------------------------------------------------------------------------------------------
2021-07-23 08:48:39,531 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): RobertaModel(
        (embeddings): RobertaEmbeddings(
          (word_embeddings): Embedding(50021, 768, padding_idx=1)
          (position_embeddings): Embedding(514, 768, padding_idx=1)
          (token_type_embeddings): Embedding(1, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): RobertaEncoder(
          (layer): ModuleList(
            (0): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): RobertaLayer(
              (attention): RobertaAttention(
                (self): RobertaSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): RobertaSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): RobertaIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): RobertaOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): RobertaPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 08:48:39,532 ----------------------------------------------------------------------------------------------------
2021-07-23 08:48:39,532 Corpus: "Corpus: 45166 train + 5825 dev + 10064 test sentences"
2021-07-23 08:48:39,532 ----------------------------------------------------------------------------------------------------
2021-07-23 08:48:39,532 Parameters:
2021-07-23 08:48:39,532  - learning_rate: "3e-05"
2021-07-23 08:48:39,532  - mini_batch_size: "32"
2021-07-23 08:48:39,532  - patience: "3"
2021-07-23 08:48:39,532  - anneal_factor: "0.5"
2021-07-23 08:48:39,532  - max_epochs: "40"
2021-07-23 08:48:39,532  - shuffle: "True"
2021-07-23 08:48:39,532  - train_with_dev: "False"
2021-07-23 08:48:39,532  - batch_growth_annealing: "False"
2021-07-23 08:48:39,532 ----------------------------------------------------------------------------------------------------
2021-07-23 08:48:39,532 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/rus.rst.rrt"
2021-07-23 08:48:39,532 ----------------------------------------------------------------------------------------------------
2021-07-23 08:48:39,532 Device: cuda:0
2021-07-23 08:48:39,532 ----------------------------------------------------------------------------------------------------
2021-07-23 08:48:39,532 Embeddings storage mode: cpu
2021-07-23 08:48:39,535 ----------------------------------------------------------------------------------------------------
2021-07-23 08:50:01,794 epoch 1 - iter 141/1412 - loss 7.57894353 - samples/sec: 54.86 - lr: 0.000030
2021-07-23 08:51:25,408 epoch 1 - iter 282/1412 - loss 3.96956468 - samples/sec: 53.97 - lr: 0.000030
2021-07-23 08:52:49,194 epoch 1 - iter 423/1412 - loss 2.73794256 - samples/sec: 53.86 - lr: 0.000030
2021-07-23 08:54:16,579 epoch 1 - iter 564/1412 - loss 2.12238605 - samples/sec: 51.64 - lr: 0.000030
2021-07-23 08:55:43,804 epoch 1 - iter 705/1412 - loss 1.74354626 - samples/sec: 51.73 - lr: 0.000030
2021-07-23 08:57:09,474 epoch 1 - iter 846/1412 - loss 1.49873179 - samples/sec: 52.67 - lr: 0.000030
2021-07-23 08:58:34,875 epoch 1 - iter 987/1412 - loss 1.32092519 - samples/sec: 52.84 - lr: 0.000030
2021-07-23 09:00:00,225 epoch 1 - iter 1128/1412 - loss 1.18762056 - samples/sec: 52.87 - lr: 0.000030
2021-07-23 09:01:28,176 epoch 1 - iter 1269/1412 - loss 1.07916467 - samples/sec: 51.30 - lr: 0.000030
2021-07-23 09:02:59,041 epoch 1 - iter 1410/1412 - loss 0.99240961 - samples/sec: 49.66 - lr: 0.000030
2021-07-23 09:02:59,890 ----------------------------------------------------------------------------------------------------
2021-07-23 09:02:59,890 EPOCH 1 done: loss 0.9915 - lr 0.0000300
2021-07-23 09:04:23,071 DEV : loss 0.11467144638299942 - score 0.9686
2021-07-23 09:04:23,221 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:04:24,008 ----------------------------------------------------------------------------------------------------
2021-07-23 09:04:58,277 epoch 2 - iter 141/1412 - loss 0.18063609 - samples/sec: 131.70 - lr: 0.000030
2021-07-23 09:05:32,468 epoch 2 - iter 282/1412 - loss 0.19322608 - samples/sec: 131.99 - lr: 0.000030
2021-07-23 09:06:06,355 epoch 2 - iter 423/1412 - loss 0.18506109 - samples/sec: 133.18 - lr: 0.000030
2021-07-23 09:06:41,007 epoch 2 - iter 564/1412 - loss 0.18842681 - samples/sec: 130.23 - lr: 0.000030
2021-07-23 09:07:15,237 epoch 2 - iter 705/1412 - loss 0.18756883 - samples/sec: 131.84 - lr: 0.000030
2021-07-23 09:07:49,978 epoch 2 - iter 846/1412 - loss 0.18480420 - samples/sec: 129.90 - lr: 0.000030
2021-07-23 09:08:24,615 epoch 2 - iter 987/1412 - loss 0.18382253 - samples/sec: 130.29 - lr: 0.000030
2021-07-23 09:08:59,187 epoch 2 - iter 1128/1412 - loss 0.18299014 - samples/sec: 130.54 - lr: 0.000030
2021-07-23 09:09:33,668 epoch 2 - iter 1269/1412 - loss 0.18208136 - samples/sec: 130.88 - lr: 0.000030
2021-07-23 09:10:07,947 epoch 2 - iter 1410/1412 - loss 0.18115059 - samples/sec: 131.65 - lr: 0.000030
2021-07-23 09:10:08,340 ----------------------------------------------------------------------------------------------------
2021-07-23 09:10:08,340 EPOCH 2 done: loss 0.1811 - lr 0.0000300
2021-07-23 09:10:22,695 DEV : loss 0.08623243868350983 - score 0.9776
2021-07-23 09:10:22,844 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:10:25,728 ----------------------------------------------------------------------------------------------------
2021-07-23 09:11:00,139 epoch 3 - iter 141/1412 - loss 0.15961917 - samples/sec: 131.17 - lr: 0.000030
2021-07-23 09:11:34,637 epoch 3 - iter 282/1412 - loss 0.15920909 - samples/sec: 130.82 - lr: 0.000030
2021-07-23 09:12:09,165 epoch 3 - iter 423/1412 - loss 0.15999515 - samples/sec: 130.70 - lr: 0.000030
2021-07-23 09:12:43,909 epoch 3 - iter 564/1412 - loss 0.16235683 - samples/sec: 129.89 - lr: 0.000030
2021-07-23 09:13:18,845 epoch 3 - iter 705/1412 - loss 0.16437896 - samples/sec: 129.17 - lr: 0.000030
2021-07-23 09:13:53,564 epoch 3 - iter 846/1412 - loss 0.16373890 - samples/sec: 129.99 - lr: 0.000030
2021-07-23 09:14:28,269 epoch 3 - iter 987/1412 - loss 0.16317107 - samples/sec: 130.04 - lr: 0.000030
2021-07-23 09:15:02,617 epoch 3 - iter 1128/1412 - loss 0.16055545 - samples/sec: 131.39 - lr: 0.000030
2021-07-23 09:15:37,311 epoch 3 - iter 1269/1412 - loss 0.15854382 - samples/sec: 130.08 - lr: 0.000030
2021-07-23 09:16:11,564 epoch 3 - iter 1410/1412 - loss 0.15648289 - samples/sec: 131.75 - lr: 0.000030
2021-07-23 09:16:11,979 ----------------------------------------------------------------------------------------------------
2021-07-23 09:16:11,979 EPOCH 3 done: loss 0.1565 - lr 0.0000300
2021-07-23 09:16:26,256 DEV : loss 0.07803887873888016 - score 0.979
2021-07-23 09:16:26,405 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:16:29,119 ----------------------------------------------------------------------------------------------------
2021-07-23 09:17:03,600 epoch 4 - iter 141/1412 - loss 0.13971932 - samples/sec: 130.90 - lr: 0.000030
2021-07-23 09:17:38,149 epoch 4 - iter 282/1412 - loss 0.13948828 - samples/sec: 130.62 - lr: 0.000030
2021-07-23 09:18:12,616 epoch 4 - iter 423/1412 - loss 0.13813570 - samples/sec: 130.93 - lr: 0.000030
2021-07-23 09:18:46,917 epoch 4 - iter 564/1412 - loss 0.13650319 - samples/sec: 131.57 - lr: 0.000030
2021-07-23 09:19:21,322 epoch 4 - iter 705/1412 - loss 0.13581399 - samples/sec: 131.17 - lr: 0.000030
2021-07-23 09:19:55,928 epoch 4 - iter 846/1412 - loss 0.13208748 - samples/sec: 130.41 - lr: 0.000030
2021-07-23 09:20:30,859 epoch 4 - iter 987/1412 - loss 0.13125015 - samples/sec: 129.20 - lr: 0.000030
2021-07-23 09:21:04,989 epoch 4 - iter 1128/1412 - loss 0.13060980 - samples/sec: 132.23 - lr: 0.000030
2021-07-23 09:21:40,095 epoch 4 - iter 1269/1412 - loss 0.12830543 - samples/sec: 128.55 - lr: 0.000030
2021-07-23 09:22:14,855 epoch 4 - iter 1410/1412 - loss 0.12742302 - samples/sec: 129.83 - lr: 0.000030
2021-07-23 09:22:15,236 ----------------------------------------------------------------------------------------------------
2021-07-23 09:22:15,236 EPOCH 4 done: loss 0.1273 - lr 0.0000300
2021-07-23 09:22:29,641 DEV : loss 0.07334864884614944 - score 0.9804
2021-07-23 09:22:29,790 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:22:33,951 ----------------------------------------------------------------------------------------------------
2021-07-23 09:23:08,825 epoch 5 - iter 141/1412 - loss 0.11116362 - samples/sec: 129.42 - lr: 0.000030
2021-07-23 09:23:42,759 epoch 5 - iter 282/1412 - loss 0.10901710 - samples/sec: 132.99 - lr: 0.000030
2021-07-23 09:24:17,682 epoch 5 - iter 423/1412 - loss 0.11070337 - samples/sec: 129.23 - lr: 0.000030
2021-07-23 09:24:52,304 epoch 5 - iter 564/1412 - loss 0.10973130 - samples/sec: 130.35 - lr: 0.000030
2021-07-23 09:25:27,143 epoch 5 - iter 705/1412 - loss 0.10995507 - samples/sec: 129.53 - lr: 0.000030
2021-07-23 09:26:02,075 epoch 5 - iter 846/1412 - loss 0.10954517 - samples/sec: 129.19 - lr: 0.000030
2021-07-23 09:26:36,304 epoch 5 - iter 987/1412 - loss 0.10776212 - samples/sec: 131.84 - lr: 0.000030
2021-07-23 09:27:11,028 epoch 5 - iter 1128/1412 - loss 0.10631422 - samples/sec: 129.97 - lr: 0.000030
2021-07-23 09:27:45,463 epoch 5 - iter 1269/1412 - loss 0.10548845 - samples/sec: 131.06 - lr: 0.000030
2021-07-23 09:28:20,342 epoch 5 - iter 1410/1412 - loss 0.10536084 - samples/sec: 129.39 - lr: 0.000030
2021-07-23 09:28:20,788 ----------------------------------------------------------------------------------------------------
2021-07-23 09:28:20,788 EPOCH 5 done: loss 0.1053 - lr 0.0000300
2021-07-23 09:28:35,232 DEV : loss 0.0707382932305336 - score 0.9801
2021-07-23 09:28:35,381 BAD EPOCHS (no improvement): 1
2021-07-23 09:28:35,381 ----------------------------------------------------------------------------------------------------
2021-07-23 09:29:10,040 epoch 6 - iter 141/1412 - loss 0.09435276 - samples/sec: 130.22 - lr: 0.000030
2021-07-23 09:29:44,555 epoch 6 - iter 282/1412 - loss 0.10075715 - samples/sec: 130.75 - lr: 0.000030
2021-07-23 09:30:19,116 epoch 6 - iter 423/1412 - loss 0.10198447 - samples/sec: 130.58 - lr: 0.000030
2021-07-23 09:30:53,327 epoch 6 - iter 564/1412 - loss 0.10037420 - samples/sec: 131.92 - lr: 0.000030
2021-07-23 09:31:28,263 epoch 6 - iter 705/1412 - loss 0.09981727 - samples/sec: 129.18 - lr: 0.000030
2021-07-23 09:32:03,322 epoch 6 - iter 846/1412 - loss 0.09698566 - samples/sec: 128.72 - lr: 0.000030
2021-07-23 09:32:38,376 epoch 6 - iter 987/1412 - loss 0.09719300 - samples/sec: 128.74 - lr: 0.000030
2021-07-23 09:33:12,858 epoch 6 - iter 1128/1412 - loss 0.09616168 - samples/sec: 130.88 - lr: 0.000030
2021-07-23 09:33:47,356 epoch 6 - iter 1269/1412 - loss 0.09590503 - samples/sec: 130.82 - lr: 0.000030
2021-07-23 09:34:22,419 epoch 6 - iter 1410/1412 - loss 0.09671941 - samples/sec: 128.71 - lr: 0.000030
2021-07-23 09:34:22,807 ----------------------------------------------------------------------------------------------------
2021-07-23 09:34:22,808 EPOCH 6 done: loss 0.0967 - lr 0.0000300
2021-07-23 09:34:37,158 DEV : loss 0.0696301981806755 - score 0.9801
2021-07-23 09:34:37,308 BAD EPOCHS (no improvement): 2
2021-07-23 09:34:37,308 ----------------------------------------------------------------------------------------------------
2021-07-23 09:35:11,799 epoch 7 - iter 141/1412 - loss 0.08673304 - samples/sec: 130.86 - lr: 0.000030
2021-07-23 09:35:46,564 epoch 7 - iter 282/1412 - loss 0.08722297 - samples/sec: 129.81 - lr: 0.000030
2021-07-23 09:36:21,242 epoch 7 - iter 423/1412 - loss 0.09209263 - samples/sec: 130.14 - lr: 0.000030
2021-07-23 09:36:55,869 epoch 7 - iter 564/1412 - loss 0.09305805 - samples/sec: 130.33 - lr: 0.000030
2021-07-23 09:37:30,347 epoch 7 - iter 705/1412 - loss 0.09256837 - samples/sec: 130.89 - lr: 0.000030
2021-07-23 09:38:04,357 epoch 7 - iter 846/1412 - loss 0.09306488 - samples/sec: 132.69 - lr: 0.000030
2021-07-23 09:38:38,737 epoch 7 - iter 987/1412 - loss 0.09403139 - samples/sec: 131.27 - lr: 0.000030
2021-07-23 09:39:12,937 epoch 7 - iter 1128/1412 - loss 0.09408351 - samples/sec: 131.96 - lr: 0.000030
2021-07-23 09:39:47,598 epoch 7 - iter 1269/1412 - loss 0.09387969 - samples/sec: 130.20 - lr: 0.000030
2021-07-23 09:40:22,572 epoch 7 - iter 1410/1412 - loss 0.09478418 - samples/sec: 129.04 - lr: 0.000030
2021-07-23 09:40:22,930 ----------------------------------------------------------------------------------------------------
2021-07-23 09:40:22,930 EPOCH 7 done: loss 0.0947 - lr 0.0000300
2021-07-23 09:40:37,322 DEV : loss 0.06812631338834763 - score 0.9814
2021-07-23 09:40:37,472 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:40:40,326 ----------------------------------------------------------------------------------------------------
2021-07-23 09:41:15,181 epoch 8 - iter 141/1412 - loss 0.09442904 - samples/sec: 129.50 - lr: 0.000030
2021-07-23 09:41:49,748 epoch 8 - iter 282/1412 - loss 0.09282265 - samples/sec: 130.55 - lr: 0.000030
2021-07-23 09:42:24,483 epoch 8 - iter 423/1412 - loss 0.09176952 - samples/sec: 129.93 - lr: 0.000030
2021-07-23 09:42:59,136 epoch 8 - iter 564/1412 - loss 0.09225676 - samples/sec: 130.23 - lr: 0.000030
2021-07-23 09:43:33,680 epoch 8 - iter 705/1412 - loss 0.09132694 - samples/sec: 130.64 - lr: 0.000030
2021-07-23 09:44:08,572 epoch 8 - iter 846/1412 - loss 0.09087230 - samples/sec: 129.34 - lr: 0.000030
2021-07-23 09:44:43,189 epoch 8 - iter 987/1412 - loss 0.09030827 - samples/sec: 130.37 - lr: 0.000030
2021-07-23 09:45:18,174 epoch 8 - iter 1128/1412 - loss 0.09117995 - samples/sec: 129.00 - lr: 0.000030
2021-07-23 09:45:53,173 epoch 8 - iter 1269/1412 - loss 0.08989761 - samples/sec: 128.94 - lr: 0.000030
2021-07-23 09:46:27,540 epoch 8 - iter 1410/1412 - loss 0.08890994 - samples/sec: 131.32 - lr: 0.000030
2021-07-23 09:46:27,943 ----------------------------------------------------------------------------------------------------
2021-07-23 09:46:27,943 EPOCH 8 done: loss 0.0889 - lr 0.0000300
2021-07-23 09:46:42,400 DEV : loss 0.07010246813297272 - score 0.9786
2021-07-23 09:46:42,550 BAD EPOCHS (no improvement): 1
2021-07-23 09:46:42,550 ----------------------------------------------------------------------------------------------------
2021-07-23 09:47:17,007 epoch 9 - iter 141/1412 - loss 0.08949426 - samples/sec: 130.98 - lr: 0.000030
2021-07-23 09:47:51,459 epoch 9 - iter 282/1412 - loss 0.09092980 - samples/sec: 130.99 - lr: 0.000030
2021-07-23 09:48:25,452 epoch 9 - iter 423/1412 - loss 0.08608310 - samples/sec: 132.76 - lr: 0.000030
2021-07-23 09:49:00,255 epoch 9 - iter 564/1412 - loss 0.08634781 - samples/sec: 129.67 - lr: 0.000030
2021-07-23 09:49:35,041 epoch 9 - iter 705/1412 - loss 0.08582314 - samples/sec: 129.73 - lr: 0.000030
2021-07-23 09:50:10,023 epoch 9 - iter 846/1412 - loss 0.08567493 - samples/sec: 129.01 - lr: 0.000030
2021-07-23 09:50:44,531 epoch 9 - iter 987/1412 - loss 0.08454911 - samples/sec: 130.78 - lr: 0.000030
2021-07-23 09:51:19,271 epoch 9 - iter 1128/1412 - loss 0.08416368 - samples/sec: 129.91 - lr: 0.000030
2021-07-23 09:51:54,212 epoch 9 - iter 1269/1412 - loss 0.08479987 - samples/sec: 129.16 - lr: 0.000030
2021-07-23 09:52:28,872 epoch 9 - iter 1410/1412 - loss 0.08577220 - samples/sec: 130.20 - lr: 0.000030
2021-07-23 09:52:29,248 ----------------------------------------------------------------------------------------------------
2021-07-23 09:52:29,248 EPOCH 9 done: loss 0.0857 - lr 0.0000300
2021-07-23 09:52:45,098 DEV : loss 0.06754252314567566 - score 0.9808
2021-07-23 09:52:45,250 BAD EPOCHS (no improvement): 2
2021-07-23 09:52:45,250 ----------------------------------------------------------------------------------------------------
2021-07-23 09:53:20,209 epoch 10 - iter 141/1412 - loss 0.09087129 - samples/sec: 129.10 - lr: 0.000030
2021-07-23 09:53:54,837 epoch 10 - iter 282/1412 - loss 0.08323593 - samples/sec: 130.32 - lr: 0.000030
2021-07-23 09:54:30,064 epoch 10 - iter 423/1412 - loss 0.08315915 - samples/sec: 128.11 - lr: 0.000030
2021-07-23 09:55:05,449 epoch 10 - iter 564/1412 - loss 0.08357633 - samples/sec: 127.54 - lr: 0.000030
2021-07-23 09:55:40,279 epoch 10 - iter 705/1412 - loss 0.08420738 - samples/sec: 129.57 - lr: 0.000030
2021-07-23 09:56:14,838 epoch 10 - iter 846/1412 - loss 0.08427868 - samples/sec: 130.58 - lr: 0.000030
2021-07-23 09:56:49,141 epoch 10 - iter 987/1412 - loss 0.08416404 - samples/sec: 131.56 - lr: 0.000030
2021-07-23 09:57:23,555 epoch 10 - iter 1128/1412 - loss 0.08364609 - samples/sec: 131.14 - lr: 0.000030
2021-07-23 09:57:58,020 epoch 10 - iter 1269/1412 - loss 0.08430962 - samples/sec: 130.94 - lr: 0.000030
2021-07-23 09:58:32,380 epoch 10 - iter 1410/1412 - loss 0.08431658 - samples/sec: 131.34 - lr: 0.000030
2021-07-23 09:58:32,747 ----------------------------------------------------------------------------------------------------
2021-07-23 09:58:32,748 EPOCH 10 done: loss 0.0843 - lr 0.0000300
2021-07-23 09:58:47,181 DEV : loss 0.06380017846822739 - score 0.9814
2021-07-23 09:58:47,332 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 09:58:50,082 ----------------------------------------------------------------------------------------------------
2021-07-23 09:59:24,848 epoch 11 - iter 141/1412 - loss 0.08882233 - samples/sec: 129.83 - lr: 0.000030
2021-07-23 09:59:59,357 epoch 11 - iter 282/1412 - loss 0.08365643 - samples/sec: 130.77 - lr: 0.000030
2021-07-23 10:00:34,167 epoch 11 - iter 423/1412 - loss 0.08229410 - samples/sec: 129.64 - lr: 0.000030
2021-07-23 10:01:08,584 epoch 11 - iter 564/1412 - loss 0.08085214 - samples/sec: 131.13 - lr: 0.000030
2021-07-23 10:01:43,320 epoch 11 - iter 705/1412 - loss 0.07976981 - samples/sec: 129.92 - lr: 0.000030
2021-07-23 10:02:17,951 epoch 11 - iter 846/1412 - loss 0.07984086 - samples/sec: 130.31 - lr: 0.000030
2021-07-23 10:02:52,372 epoch 11 - iter 987/1412 - loss 0.07926009 - samples/sec: 131.11 - lr: 0.000030
2021-07-23 10:03:26,917 epoch 11 - iter 1128/1412 - loss 0.07976404 - samples/sec: 130.64 - lr: 0.000030
2021-07-23 10:04:01,769 epoch 11 - iter 1269/1412 - loss 0.08072851 - samples/sec: 129.49 - lr: 0.000030
2021-07-23 10:04:36,509 epoch 11 - iter 1410/1412 - loss 0.07982666 - samples/sec: 129.90 - lr: 0.000030
2021-07-23 10:04:36,872 ----------------------------------------------------------------------------------------------------
2021-07-23 10:04:36,872 EPOCH 11 done: loss 0.0798 - lr 0.0000300
2021-07-23 10:04:51,325 DEV : loss 0.06329021602869034 - score 0.9817
2021-07-23 10:04:51,478 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 10:04:54,290 ----------------------------------------------------------------------------------------------------
2021-07-23 10:05:29,007 epoch 12 - iter 141/1412 - loss 0.07743172 - samples/sec: 130.01 - lr: 0.000030
2021-07-23 10:06:03,436 epoch 12 - iter 282/1412 - loss 0.08223332 - samples/sec: 131.08 - lr: 0.000030
2021-07-23 10:06:38,246 epoch 12 - iter 423/1412 - loss 0.07755950 - samples/sec: 129.64 - lr: 0.000030
2021-07-23 10:07:12,935 epoch 12 - iter 564/1412 - loss 0.07577881 - samples/sec: 130.09 - lr: 0.000030
2021-07-23 10:07:47,705 epoch 12 - iter 705/1412 - loss 0.07749445 - samples/sec: 129.79 - lr: 0.000030
2021-07-23 10:08:22,236 epoch 12 - iter 846/1412 - loss 0.07586430 - samples/sec: 130.69 - lr: 0.000030
2021-07-23 10:08:57,053 epoch 12 - iter 987/1412 - loss 0.07603447 - samples/sec: 129.62 - lr: 0.000030
2021-07-23 10:09:31,760 epoch 12 - iter 1128/1412 - loss 0.07646577 - samples/sec: 130.03 - lr: 0.000030
2021-07-23 10:10:06,053 epoch 12 - iter 1269/1412 - loss 0.07671023 - samples/sec: 131.60 - lr: 0.000030
2021-07-23 10:10:40,998 epoch 12 - iter 1410/1412 - loss 0.07695721 - samples/sec: 129.14 - lr: 0.000030
2021-07-23 10:10:41,367 ----------------------------------------------------------------------------------------------------
2021-07-23 10:10:41,367 EPOCH 12 done: loss 0.0769 - lr 0.0000300
2021-07-23 10:10:55,856 DEV : loss 0.06416162848472595 - score 0.982
2021-07-23 10:10:56,006 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 10:10:58,685 ----------------------------------------------------------------------------------------------------
2021-07-23 10:11:33,104 epoch 13 - iter 141/1412 - loss 0.07427561 - samples/sec: 131.13 - lr: 0.000030
2021-07-23 10:12:08,119 epoch 13 - iter 282/1412 - loss 0.07765064 - samples/sec: 128.89 - lr: 0.000030
2021-07-23 10:12:42,472 epoch 13 - iter 423/1412 - loss 0.07727425 - samples/sec: 131.37 - lr: 0.000030
2021-07-23 10:13:17,405 epoch 13 - iter 564/1412 - loss 0.07499806 - samples/sec: 129.19 - lr: 0.000030
2021-07-23 10:13:52,244 epoch 13 - iter 705/1412 - loss 0.07682755 - samples/sec: 129.54 - lr: 0.000030
2021-07-23 10:14:27,360 epoch 13 - iter 846/1412 - loss 0.07639847 - samples/sec: 128.51 - lr: 0.000030
2021-07-23 10:15:01,844 epoch 13 - iter 987/1412 - loss 0.07594446 - samples/sec: 130.87 - lr: 0.000030
2021-07-23 10:15:36,325 epoch 13 - iter 1128/1412 - loss 0.07597654 - samples/sec: 130.88 - lr: 0.000030
2021-07-23 10:16:10,509 epoch 13 - iter 1269/1412 - loss 0.07560328 - samples/sec: 132.02 - lr: 0.000030
2021-07-23 10:16:45,320 epoch 13 - iter 1410/1412 - loss 0.07503451 - samples/sec: 129.64 - lr: 0.000030
2021-07-23 10:16:45,744 ----------------------------------------------------------------------------------------------------
2021-07-23 10:16:45,744 EPOCH 13 done: loss 0.0750 - lr 0.0000300
2021-07-23 10:17:01,589 DEV : loss 0.06599060446023941 - score 0.9806
2021-07-23 10:17:01,742 BAD EPOCHS (no improvement): 1
2021-07-23 10:17:01,742 ----------------------------------------------------------------------------------------------------
2021-07-23 10:17:36,000 epoch 14 - iter 141/1412 - loss 0.06399720 - samples/sec: 131.75 - lr: 0.000030
2021-07-23 10:18:10,303 epoch 14 - iter 282/1412 - loss 0.07028082 - samples/sec: 131.56 - lr: 0.000030
2021-07-23 10:18:45,193 epoch 14 - iter 423/1412 - loss 0.07010449 - samples/sec: 129.35 - lr: 0.000030
2021-07-23 10:19:19,864 epoch 14 - iter 564/1412 - loss 0.07191671 - samples/sec: 130.16 - lr: 0.000030
2021-07-23 10:19:54,349 epoch 14 - iter 705/1412 - loss 0.07199828 - samples/sec: 130.87 - lr: 0.000030
2021-07-23 10:20:28,712 epoch 14 - iter 846/1412 - loss 0.07277200 - samples/sec: 131.33 - lr: 0.000030
2021-07-23 10:21:02,998 epoch 14 - iter 987/1412 - loss 0.07265306 - samples/sec: 131.62 - lr: 0.000030
2021-07-23 10:21:38,268 epoch 14 - iter 1128/1412 - loss 0.07320787 - samples/sec: 127.95 - lr: 0.000030
2021-07-23 10:22:13,116 epoch 14 - iter 1269/1412 - loss 0.07395221 - samples/sec: 129.50 - lr: 0.000030
2021-07-23 10:22:47,812 epoch 14 - iter 1410/1412 - loss 0.07355131 - samples/sec: 130.07 - lr: 0.000030
2021-07-23 10:22:48,191 ----------------------------------------------------------------------------------------------------
2021-07-23 10:22:48,192 EPOCH 14 done: loss 0.0736 - lr 0.0000300
2021-07-23 10:23:02,581 DEV : loss 0.06366389989852905 - score 0.9819
2021-07-23 10:23:02,735 BAD EPOCHS (no improvement): 2
2021-07-23 10:23:02,735 ----------------------------------------------------------------------------------------------------
2021-07-23 10:23:37,572 epoch 15 - iter 141/1412 - loss 0.06953231 - samples/sec: 129.56 - lr: 0.000030
2021-07-23 10:24:12,700 epoch 15 - iter 282/1412 - loss 0.07299517 - samples/sec: 128.47 - lr: 0.000030
2021-07-23 10:24:47,581 epoch 15 - iter 423/1412 - loss 0.06984823 - samples/sec: 129.38 - lr: 0.000030
2021-07-23 10:25:22,088 epoch 15 - iter 564/1412 - loss 0.06968627 - samples/sec: 130.79 - lr: 0.000030
2021-07-23 10:25:56,574 epoch 15 - iter 705/1412 - loss 0.07059755 - samples/sec: 130.86 - lr: 0.000030
2021-07-23 10:26:31,516 epoch 15 - iter 846/1412 - loss 0.07089161 - samples/sec: 129.16 - lr: 0.000030
2021-07-23 10:27:06,371 epoch 15 - iter 987/1412 - loss 0.07023039 - samples/sec: 129.48 - lr: 0.000030
2021-07-23 10:27:40,224 epoch 15 - iter 1128/1412 - loss 0.06961691 - samples/sec: 133.31 - lr: 0.000030
2021-07-23 10:28:14,666 epoch 15 - iter 1269/1412 - loss 0.06939673 - samples/sec: 131.03 - lr: 0.000030
2021-07-23 10:28:49,369 epoch 15 - iter 1410/1412 - loss 0.07017763 - samples/sec: 130.04 - lr: 0.000030
2021-07-23 10:28:49,759 ----------------------------------------------------------------------------------------------------
2021-07-23 10:28:49,759 EPOCH 15 done: loss 0.0701 - lr 0.0000300
2021-07-23 10:29:04,111 DEV : loss 0.06308410316705704 - score 0.982
2021-07-23 10:29:04,265 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 10:29:07,095 ----------------------------------------------------------------------------------------------------
2021-07-23 10:29:41,828 epoch 16 - iter 141/1412 - loss 0.07617926 - samples/sec: 129.95 - lr: 0.000030
2021-07-23 10:30:17,023 epoch 16 - iter 282/1412 - loss 0.07584563 - samples/sec: 128.22 - lr: 0.000030
2021-07-23 10:30:51,394 epoch 16 - iter 423/1412 - loss 0.07413813 - samples/sec: 131.30 - lr: 0.000030
2021-07-23 10:31:26,169 epoch 16 - iter 564/1412 - loss 0.07247283 - samples/sec: 129.77 - lr: 0.000030
2021-07-23 10:32:01,183 epoch 16 - iter 705/1412 - loss 0.07310484 - samples/sec: 128.89 - lr: 0.000030
2021-07-23 10:32:35,595 epoch 16 - iter 846/1412 - loss 0.07178459 - samples/sec: 131.14 - lr: 0.000030
2021-07-23 10:33:10,393 epoch 16 - iter 987/1412 - loss 0.07108943 - samples/sec: 129.69 - lr: 0.000030
2021-07-23 10:33:44,780 epoch 16 - iter 1128/1412 - loss 0.07099605 - samples/sec: 131.24 - lr: 0.000030
2021-07-23 10:34:19,639 epoch 16 - iter 1269/1412 - loss 0.07060782 - samples/sec: 129.46 - lr: 0.000030
2021-07-23 10:34:54,444 epoch 16 - iter 1410/1412 - loss 0.07036368 - samples/sec: 129.66 - lr: 0.000030
2021-07-23 10:34:54,850 ----------------------------------------------------------------------------------------------------
2021-07-23 10:34:54,850 EPOCH 16 done: loss 0.0705 - lr 0.0000300
2021-07-23 10:35:09,267 DEV : loss 0.061284635215997696 - score 0.9818
2021-07-23 10:35:09,419 BAD EPOCHS (no improvement): 1
2021-07-23 10:35:09,419 ----------------------------------------------------------------------------------------------------
2021-07-23 10:35:44,440 epoch 17 - iter 141/1412 - loss 0.06492099 - samples/sec: 128.88 - lr: 0.000030
2021-07-23 10:36:18,768 epoch 17 - iter 282/1412 - loss 0.06602691 - samples/sec: 131.47 - lr: 0.000030
2021-07-23 10:36:53,548 epoch 17 - iter 423/1412 - loss 0.06636615 - samples/sec: 129.75 - lr: 0.000030
2021-07-23 10:37:27,867 epoch 17 - iter 564/1412 - loss 0.06768617 - samples/sec: 131.50 - lr: 0.000030
2021-07-23 10:38:02,017 epoch 17 - iter 705/1412 - loss 0.06748653 - samples/sec: 132.15 - lr: 0.000030
2021-07-23 10:38:36,596 epoch 17 - iter 846/1412 - loss 0.06650008 - samples/sec: 130.51 - lr: 0.000030
2021-07-23 10:39:11,547 epoch 17 - iter 987/1412 - loss 0.06765792 - samples/sec: 129.12 - lr: 0.000030
2021-07-23 10:39:46,349 epoch 17 - iter 1128/1412 - loss 0.06713501 - samples/sec: 129.68 - lr: 0.000030
2021-07-23 10:40:21,564 epoch 17 - iter 1269/1412 - loss 0.06772465 - samples/sec: 128.15 - lr: 0.000030
2021-07-23 10:40:56,103 epoch 17 - iter 1410/1412 - loss 0.06786423 - samples/sec: 130.66 - lr: 0.000030
2021-07-23 10:40:56,487 ----------------------------------------------------------------------------------------------------
2021-07-23 10:40:56,487 EPOCH 17 done: loss 0.0679 - lr 0.0000300
2021-07-23 10:41:10,989 DEV : loss 0.0618574395775795 - score 0.9819
2021-07-23 10:41:11,140 BAD EPOCHS (no improvement): 2
2021-07-23 10:41:11,140 ----------------------------------------------------------------------------------------------------
2021-07-23 10:41:45,713 epoch 18 - iter 141/1412 - loss 0.06836228 - samples/sec: 130.55 - lr: 0.000030
2021-07-23 10:42:20,628 epoch 18 - iter 282/1412 - loss 0.07288687 - samples/sec: 129.25 - lr: 0.000030
2021-07-23 10:42:56,456 epoch 18 - iter 423/1412 - loss 0.06846342 - samples/sec: 125.96 - lr: 0.000030
2021-07-23 10:43:30,934 epoch 18 - iter 564/1412 - loss 0.06750315 - samples/sec: 130.90 - lr: 0.000030
2021-07-23 10:44:06,041 epoch 18 - iter 705/1412 - loss 0.06653451 - samples/sec: 128.54 - lr: 0.000030
2021-07-23 10:44:40,474 epoch 18 - iter 846/1412 - loss 0.06701257 - samples/sec: 131.06 - lr: 0.000030
2021-07-23 10:45:15,015 epoch 18 - iter 987/1412 - loss 0.06651336 - samples/sec: 130.65 - lr: 0.000030
2021-07-23 10:45:49,739 epoch 18 - iter 1128/1412 - loss 0.06650893 - samples/sec: 129.97 - lr: 0.000030
2021-07-23 10:46:24,629 epoch 18 - iter 1269/1412 - loss 0.06676172 - samples/sec: 129.35 - lr: 0.000030
2021-07-23 10:46:59,400 epoch 18 - iter 1410/1412 - loss 0.06736977 - samples/sec: 129.79 - lr: 0.000030
2021-07-23 10:46:59,784 ----------------------------------------------------------------------------------------------------
2021-07-23 10:46:59,784 EPOCH 18 done: loss 0.0673 - lr 0.0000300
2021-07-23 10:47:14,297 DEV : loss 0.060552407056093216 - score 0.9829
2021-07-23 10:47:14,448 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 10:47:17,287 ----------------------------------------------------------------------------------------------------
2021-07-23 10:47:52,161 epoch 19 - iter 141/1412 - loss 0.06118339 - samples/sec: 129.42 - lr: 0.000030
2021-07-23 10:48:26,336 epoch 19 - iter 282/1412 - loss 0.06532599 - samples/sec: 132.05 - lr: 0.000030
2021-07-23 10:49:01,679 epoch 19 - iter 423/1412 - loss 0.06576890 - samples/sec: 127.69 - lr: 0.000030
2021-07-23 10:49:35,687 epoch 19 - iter 564/1412 - loss 0.06936797 - samples/sec: 132.70 - lr: 0.000030
2021-07-23 10:50:10,476 epoch 19 - iter 705/1412 - loss 0.06790894 - samples/sec: 129.72 - lr: 0.000030
2021-07-23 10:50:44,988 epoch 19 - iter 846/1412 - loss 0.06674703 - samples/sec: 130.77 - lr: 0.000030
2021-07-23 10:51:19,496 epoch 19 - iter 987/1412 - loss 0.06654035 - samples/sec: 130.78 - lr: 0.000030
2021-07-23 10:51:54,494 epoch 19 - iter 1128/1412 - loss 0.06529653 - samples/sec: 128.95 - lr: 0.000030
2021-07-23 10:52:29,228 epoch 19 - iter 1269/1412 - loss 0.06494523 - samples/sec: 129.93 - lr: 0.000030
2021-07-23 10:53:04,310 epoch 19 - iter 1410/1412 - loss 0.06494050 - samples/sec: 128.64 - lr: 0.000030
2021-07-23 10:53:04,646 ----------------------------------------------------------------------------------------------------
2021-07-23 10:53:04,646 EPOCH 19 done: loss 0.0649 - lr 0.0000300
2021-07-23 10:53:19,178 DEV : loss 0.0607636421918869 - score 0.9823
2021-07-23 10:53:19,330 BAD EPOCHS (no improvement): 1
2021-07-23 10:53:19,330 ----------------------------------------------------------------------------------------------------
2021-07-23 10:53:54,228 epoch 20 - iter 141/1412 - loss 0.06404455 - samples/sec: 129.33 - lr: 0.000030
2021-07-23 10:54:29,397 epoch 20 - iter 282/1412 - loss 0.06082653 - samples/sec: 128.32 - lr: 0.000030
2021-07-23 10:55:04,034 epoch 20 - iter 423/1412 - loss 0.06125793 - samples/sec: 130.29 - lr: 0.000030
2021-07-23 10:55:39,216 epoch 20 - iter 564/1412 - loss 0.06050525 - samples/sec: 128.27 - lr: 0.000030
2021-07-23 10:56:14,232 epoch 20 - iter 705/1412 - loss 0.06141294 - samples/sec: 128.88 - lr: 0.000030
2021-07-23 10:56:48,676 epoch 20 - iter 846/1412 - loss 0.06213572 - samples/sec: 131.02 - lr: 0.000030
2021-07-23 10:57:23,711 epoch 20 - iter 987/1412 - loss 0.06338852 - samples/sec: 128.81 - lr: 0.000030
2021-07-23 10:57:57,853 epoch 20 - iter 1128/1412 - loss 0.06338052 - samples/sec: 132.18 - lr: 0.000030
2021-07-23 10:58:32,392 epoch 20 - iter 1269/1412 - loss 0.06335382 - samples/sec: 130.66 - lr: 0.000030
2021-07-23 10:59:06,523 epoch 20 - iter 1410/1412 - loss 0.06337616 - samples/sec: 132.22 - lr: 0.000030
2021-07-23 10:59:06,928 ----------------------------------------------------------------------------------------------------
2021-07-23 10:59:06,928 EPOCH 20 done: loss 0.0635 - lr 0.0000300
2021-07-23 10:59:21,453 DEV : loss 0.06114833801984787 - score 0.9825
2021-07-23 10:59:21,604 BAD EPOCHS (no improvement): 2
2021-07-23 10:59:21,604 ----------------------------------------------------------------------------------------------------
2021-07-23 10:59:56,333 epoch 21 - iter 141/1412 - loss 0.06432108 - samples/sec: 129.96 - lr: 0.000030
2021-07-23 11:00:31,076 epoch 21 - iter 282/1412 - loss 0.06419325 - samples/sec: 129.89 - lr: 0.000030
2021-07-23 11:01:05,799 epoch 21 - iter 423/1412 - loss 0.06213810 - samples/sec: 129.97 - lr: 0.000030
2021-07-23 11:01:40,805 epoch 21 - iter 564/1412 - loss 0.06091943 - samples/sec: 128.92 - lr: 0.000030
2021-07-23 11:02:15,540 epoch 21 - iter 705/1412 - loss 0.06011942 - samples/sec: 129.92 - lr: 0.000030
2021-07-23 11:02:49,720 epoch 21 - iter 846/1412 - loss 0.05919123 - samples/sec: 132.03 - lr: 0.000030
2021-07-23 11:03:24,449 epoch 21 - iter 987/1412 - loss 0.05907881 - samples/sec: 129.95 - lr: 0.000030
2021-07-23 11:03:59,512 epoch 21 - iter 1128/1412 - loss 0.06008869 - samples/sec: 128.71 - lr: 0.000030
2021-07-23 11:04:33,772 epoch 21 - iter 1269/1412 - loss 0.06019825 - samples/sec: 131.73 - lr: 0.000030
2021-07-23 11:05:08,438 epoch 21 - iter 1410/1412 - loss 0.06069227 - samples/sec: 130.18 - lr: 0.000030
2021-07-23 11:05:08,800 ----------------------------------------------------------------------------------------------------
2021-07-23 11:05:08,800 EPOCH 21 done: loss 0.0607 - lr 0.0000300
2021-07-23 11:05:23,202 DEV : loss 0.060850027948617935 - score 0.9833
2021-07-23 11:05:23,355 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:05:25,633 ----------------------------------------------------------------------------------------------------
2021-07-23 11:06:00,115 epoch 22 - iter 141/1412 - loss 0.05535625 - samples/sec: 130.90 - lr: 0.000030
2021-07-23 11:06:35,049 epoch 22 - iter 282/1412 - loss 0.06221058 - samples/sec: 129.19 - lr: 0.000030
2021-07-23 11:07:09,392 epoch 22 - iter 423/1412 - loss 0.06100352 - samples/sec: 131.40 - lr: 0.000030
2021-07-23 11:07:44,227 epoch 22 - iter 564/1412 - loss 0.06349247 - samples/sec: 129.55 - lr: 0.000030
2021-07-23 11:08:19,133 epoch 22 - iter 705/1412 - loss 0.06258070 - samples/sec: 129.29 - lr: 0.000030
2021-07-23 11:08:53,732 epoch 22 - iter 846/1412 - loss 0.06278324 - samples/sec: 130.43 - lr: 0.000030
2021-07-23 11:09:28,592 epoch 22 - iter 987/1412 - loss 0.06249119 - samples/sec: 129.46 - lr: 0.000030
2021-07-23 11:10:03,504 epoch 22 - iter 1128/1412 - loss 0.06128216 - samples/sec: 129.26 - lr: 0.000030
2021-07-23 11:10:37,524 epoch 22 - iter 1269/1412 - loss 0.06235421 - samples/sec: 132.66 - lr: 0.000030
2021-07-23 11:11:11,743 epoch 22 - iter 1410/1412 - loss 0.06258327 - samples/sec: 131.88 - lr: 0.000030
2021-07-23 11:11:12,138 ----------------------------------------------------------------------------------------------------
2021-07-23 11:11:12,138 EPOCH 22 done: loss 0.0625 - lr 0.0000300
2021-07-23 11:11:27,927 DEV : loss 0.06302472203969955 - score 0.9813
2021-07-23 11:11:28,078 BAD EPOCHS (no improvement): 1
2021-07-23 11:11:28,078 ----------------------------------------------------------------------------------------------------
2021-07-23 11:12:03,169 epoch 23 - iter 141/1412 - loss 0.05977533 - samples/sec: 128.62 - lr: 0.000030
2021-07-23 11:12:37,741 epoch 23 - iter 282/1412 - loss 0.05997109 - samples/sec: 130.54 - lr: 0.000030
2021-07-23 11:13:12,155 epoch 23 - iter 423/1412 - loss 0.06105600 - samples/sec: 131.13 - lr: 0.000030
2021-07-23 11:13:47,343 epoch 23 - iter 564/1412 - loss 0.06057419 - samples/sec: 128.25 - lr: 0.000030
2021-07-23 11:14:21,989 epoch 23 - iter 705/1412 - loss 0.06007622 - samples/sec: 130.26 - lr: 0.000030
2021-07-23 11:14:56,811 epoch 23 - iter 846/1412 - loss 0.06091367 - samples/sec: 129.60 - lr: 0.000030
2021-07-23 11:15:31,339 epoch 23 - iter 987/1412 - loss 0.06039441 - samples/sec: 130.70 - lr: 0.000030
2021-07-23 11:16:06,027 epoch 23 - iter 1128/1412 - loss 0.06007451 - samples/sec: 130.10 - lr: 0.000030
2021-07-23 11:16:40,866 epoch 23 - iter 1269/1412 - loss 0.05972702 - samples/sec: 129.54 - lr: 0.000030
2021-07-23 11:17:15,213 epoch 23 - iter 1410/1412 - loss 0.06004308 - samples/sec: 131.39 - lr: 0.000030
2021-07-23 11:17:15,604 ----------------------------------------------------------------------------------------------------
2021-07-23 11:17:15,604 EPOCH 23 done: loss 0.0600 - lr 0.0000300
2021-07-23 11:17:30,145 DEV : loss 0.06041005626320839 - score 0.9836
2021-07-23 11:17:30,296 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:17:33,331 ----------------------------------------------------------------------------------------------------
2021-07-23 11:18:08,356 epoch 24 - iter 141/1412 - loss 0.05911537 - samples/sec: 128.87 - lr: 0.000030
2021-07-23 11:18:42,850 epoch 24 - iter 282/1412 - loss 0.06112593 - samples/sec: 130.83 - lr: 0.000030
2021-07-23 11:19:17,521 epoch 24 - iter 423/1412 - loss 0.06297564 - samples/sec: 130.16 - lr: 0.000030
2021-07-23 11:19:52,121 epoch 24 - iter 564/1412 - loss 0.06307915 - samples/sec: 130.43 - lr: 0.000030
2021-07-23 11:20:26,764 epoch 24 - iter 705/1412 - loss 0.06256934 - samples/sec: 130.27 - lr: 0.000030
2021-07-23 11:21:01,697 epoch 24 - iter 846/1412 - loss 0.06102879 - samples/sec: 129.19 - lr: 0.000030
2021-07-23 11:21:35,879 epoch 24 - iter 987/1412 - loss 0.05946818 - samples/sec: 132.02 - lr: 0.000030
2021-07-23 11:22:10,300 epoch 24 - iter 1128/1412 - loss 0.06144867 - samples/sec: 131.11 - lr: 0.000030
2021-07-23 11:22:45,014 epoch 24 - iter 1269/1412 - loss 0.06148315 - samples/sec: 130.01 - lr: 0.000030
2021-07-23 11:23:19,337 epoch 24 - iter 1410/1412 - loss 0.06107302 - samples/sec: 131.48 - lr: 0.000030
2021-07-23 11:23:19,680 ----------------------------------------------------------------------------------------------------
2021-07-23 11:23:19,680 EPOCH 24 done: loss 0.0611 - lr 0.0000300
2021-07-23 11:23:34,225 DEV : loss 0.059884585440158844 - score 0.984
2021-07-23 11:23:34,378 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 11:23:37,128 ----------------------------------------------------------------------------------------------------
2021-07-23 11:24:12,030 epoch 25 - iter 141/1412 - loss 0.06354061 - samples/sec: 129.32 - lr: 0.000030
2021-07-23 11:24:46,640 epoch 25 - iter 282/1412 - loss 0.06249110 - samples/sec: 130.39 - lr: 0.000030
2021-07-23 11:25:21,016 epoch 25 - iter 423/1412 - loss 0.05973757 - samples/sec: 131.28 - lr: 0.000030
2021-07-23 11:25:55,804 epoch 25 - iter 564/1412 - loss 0.06006209 - samples/sec: 129.72 - lr: 0.000030
2021-07-23 11:26:29,935 epoch 25 - iter 705/1412 - loss 0.06017928 - samples/sec: 132.23 - lr: 0.000030
2021-07-23 11:27:04,489 epoch 25 - iter 846/1412 - loss 0.05935312 - samples/sec: 130.60 - lr: 0.000030
2021-07-23 11:27:39,340 epoch 25 - iter 987/1412 - loss 0.05777986 - samples/sec: 129.49 - lr: 0.000030
2021-07-23 11:28:14,233 epoch 25 - iter 1128/1412 - loss 0.05727153 - samples/sec: 129.33 - lr: 0.000030
2021-07-23 11:28:49,241 epoch 25 - iter 1269/1412 - loss 0.05711557 - samples/sec: 128.91 - lr: 0.000030
2021-07-23 11:29:23,651 epoch 25 - iter 1410/1412 - loss 0.05794699 - samples/sec: 131.15 - lr: 0.000030
2021-07-23 11:29:24,057 ----------------------------------------------------------------------------------------------------
2021-07-23 11:29:24,057 EPOCH 25 done: loss 0.0580 - lr 0.0000300
2021-07-23 11:29:38,554 DEV : loss 0.06243148446083069 - score 0.9824
2021-07-23 11:29:38,706 BAD EPOCHS (no improvement): 1
2021-07-23 11:29:38,706 ----------------------------------------------------------------------------------------------------
2021-07-23 11:30:13,159 epoch 26 - iter 141/1412 - loss 0.05739517 - samples/sec: 131.00 - lr: 0.000030
2021-07-23 11:30:47,804 epoch 26 - iter 282/1412 - loss 0.05785488 - samples/sec: 130.26 - lr: 0.000030
2021-07-23 11:31:22,193 epoch 26 - iter 423/1412 - loss 0.05323504 - samples/sec: 131.23 - lr: 0.000030
2021-07-23 11:31:56,882 epoch 26 - iter 564/1412 - loss 0.05474957 - samples/sec: 130.10 - lr: 0.000030
2021-07-23 11:32:31,549 epoch 26 - iter 705/1412 - loss 0.05583184 - samples/sec: 130.18 - lr: 0.000030
2021-07-23 11:33:05,936 epoch 26 - iter 846/1412 - loss 0.05560175 - samples/sec: 131.24 - lr: 0.000030
2021-07-23 11:33:40,933 epoch 26 - iter 987/1412 - loss 0.05548477 - samples/sec: 128.95 - lr: 0.000030
2021-07-23 11:34:16,329 epoch 26 - iter 1128/1412 - loss 0.05598143 - samples/sec: 127.50 - lr: 0.000030
2021-07-23 11:34:51,361 epoch 26 - iter 1269/1412 - loss 0.05609128 - samples/sec: 128.82 - lr: 0.000030
2021-07-23 11:35:26,397 epoch 26 - iter 1410/1412 - loss 0.05692439 - samples/sec: 128.81 - lr: 0.000030
2021-07-23 11:35:26,820 ----------------------------------------------------------------------------------------------------
2021-07-23 11:35:26,820 EPOCH 26 done: loss 0.0570 - lr 0.0000300
2021-07-23 11:35:42,619 DEV : loss 0.06061787158250809 - score 0.9836
2021-07-23 11:35:42,772 BAD EPOCHS (no improvement): 2
2021-07-23 11:35:42,772 ----------------------------------------------------------------------------------------------------
2021-07-23 11:36:17,720 epoch 27 - iter 141/1412 - loss 0.04772664 - samples/sec: 129.14 - lr: 0.000030
2021-07-23 11:36:52,588 epoch 27 - iter 282/1412 - loss 0.04991443 - samples/sec: 129.43 - lr: 0.000030
2021-07-23 11:37:27,479 epoch 27 - iter 423/1412 - loss 0.05030860 - samples/sec: 129.34 - lr: 0.000030
2021-07-23 11:38:02,741 epoch 27 - iter 564/1412 - loss 0.05379682 - samples/sec: 127.98 - lr: 0.000030
2021-07-23 11:38:37,593 epoch 27 - iter 705/1412 - loss 0.05357788 - samples/sec: 129.49 - lr: 0.000030
2021-07-23 11:39:11,966 epoch 27 - iter 846/1412 - loss 0.05365074 - samples/sec: 131.29 - lr: 0.000030
2021-07-23 11:39:46,500 epoch 27 - iter 987/1412 - loss 0.05453138 - samples/sec: 130.68 - lr: 0.000030
2021-07-23 11:40:21,240 epoch 27 - iter 1128/1412 - loss 0.05433313 - samples/sec: 129.91 - lr: 0.000030
2021-07-23 11:40:55,917 epoch 27 - iter 1269/1412 - loss 0.05486161 - samples/sec: 130.14 - lr: 0.000030
2021-07-23 11:41:30,609 epoch 27 - iter 1410/1412 - loss 0.05541715 - samples/sec: 130.09 - lr: 0.000030
2021-07-23 11:41:30,962 ----------------------------------------------------------------------------------------------------
2021-07-23 11:41:30,962 EPOCH 27 done: loss 0.0554 - lr 0.0000300
2021-07-23 11:41:45,467 DEV : loss 0.06107727810740471 - score 0.9832
2021-07-23 11:41:45,619 BAD EPOCHS (no improvement): 3
2021-07-23 11:41:45,619 ----------------------------------------------------------------------------------------------------
2021-07-23 11:42:20,129 epoch 28 - iter 141/1412 - loss 0.04536691 - samples/sec: 130.78 - lr: 0.000030
2021-07-23 11:42:55,075 epoch 28 - iter 282/1412 - loss 0.04960543 - samples/sec: 129.14 - lr: 0.000030
2021-07-23 11:43:29,981 epoch 28 - iter 423/1412 - loss 0.05156987 - samples/sec: 129.29 - lr: 0.000030
2021-07-23 11:44:04,973 epoch 28 - iter 564/1412 - loss 0.05016401 - samples/sec: 128.97 - lr: 0.000030
2021-07-23 11:44:39,667 epoch 28 - iter 705/1412 - loss 0.05071022 - samples/sec: 130.08 - lr: 0.000030
2021-07-23 11:45:14,283 epoch 28 - iter 846/1412 - loss 0.05344277 - samples/sec: 130.37 - lr: 0.000030
2021-07-23 11:45:48,729 epoch 28 - iter 987/1412 - loss 0.05422616 - samples/sec: 131.02 - lr: 0.000030
2021-07-23 11:46:23,076 epoch 28 - iter 1128/1412 - loss 0.05446409 - samples/sec: 131.39 - lr: 0.000030
2021-07-23 11:46:57,613 epoch 28 - iter 1269/1412 - loss 0.05484108 - samples/sec: 130.67 - lr: 0.000030
2021-07-23 11:47:31,624 epoch 28 - iter 1410/1412 - loss 0.05532767 - samples/sec: 132.69 - lr: 0.000030
2021-07-23 11:47:31,975 ----------------------------------------------------------------------------------------------------
2021-07-23 11:47:31,975 EPOCH 28 done: loss 0.0553 - lr 0.0000300
2021-07-23 11:47:46,459 DEV : loss 0.06073560565710068 - score 0.9838
Epoch    28: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 11:47:46,611 BAD EPOCHS (no improvement): 4
2021-07-23 11:47:46,611 ----------------------------------------------------------------------------------------------------
2021-07-23 11:48:20,977 epoch 29 - iter 141/1412 - loss 0.04950831 - samples/sec: 131.33 - lr: 0.000015
2021-07-23 11:48:55,617 epoch 29 - iter 282/1412 - loss 0.04964205 - samples/sec: 130.28 - lr: 0.000015
2021-07-23 11:49:29,860 epoch 29 - iter 423/1412 - loss 0.05071632 - samples/sec: 131.79 - lr: 0.000015
2021-07-23 11:50:04,607 epoch 29 - iter 564/1412 - loss 0.05164789 - samples/sec: 129.88 - lr: 0.000015
2021-07-23 11:50:39,184 epoch 29 - iter 705/1412 - loss 0.05144704 - samples/sec: 130.52 - lr: 0.000015
2021-07-23 11:51:13,686 epoch 29 - iter 846/1412 - loss 0.05221602 - samples/sec: 130.80 - lr: 0.000015
2021-07-23 11:51:48,648 epoch 29 - iter 987/1412 - loss 0.05229073 - samples/sec: 129.08 - lr: 0.000015
2021-07-23 11:52:23,273 epoch 29 - iter 1128/1412 - loss 0.05191587 - samples/sec: 130.34 - lr: 0.000015
2021-07-23 11:52:57,928 epoch 29 - iter 1269/1412 - loss 0.05172905 - samples/sec: 130.22 - lr: 0.000015
2021-07-23 11:53:33,112 epoch 29 - iter 1410/1412 - loss 0.05137346 - samples/sec: 128.27 - lr: 0.000015
2021-07-23 11:53:33,519 ----------------------------------------------------------------------------------------------------
2021-07-23 11:53:33,519 EPOCH 29 done: loss 0.0513 - lr 0.0000150
2021-07-23 11:53:48,081 DEV : loss 0.06153475120663643 - score 0.9827
2021-07-23 11:53:48,231 BAD EPOCHS (no improvement): 1
2021-07-23 11:53:48,232 ----------------------------------------------------------------------------------------------------
2021-07-23 11:54:23,080 epoch 30 - iter 141/1412 - loss 0.05739517 - samples/sec: 129.51 - lr: 0.000015
2021-07-23 11:54:57,588 epoch 30 - iter 282/1412 - loss 0.05260774 - samples/sec: 130.78 - lr: 0.000015
2021-07-23 11:55:32,749 epoch 30 - iter 423/1412 - loss 0.05127636 - samples/sec: 128.35 - lr: 0.000015
2021-07-23 11:56:07,497 epoch 30 - iter 564/1412 - loss 0.05052069 - samples/sec: 129.88 - lr: 0.000015
2021-07-23 11:56:42,265 epoch 30 - iter 705/1412 - loss 0.05076316 - samples/sec: 129.80 - lr: 0.000015
2021-07-23 11:57:16,960 epoch 30 - iter 846/1412 - loss 0.05144393 - samples/sec: 130.07 - lr: 0.000015
2021-07-23 11:57:51,533 epoch 30 - iter 987/1412 - loss 0.05067659 - samples/sec: 130.53 - lr: 0.000015
2021-07-23 11:58:26,308 epoch 30 - iter 1128/1412 - loss 0.04967642 - samples/sec: 129.77 - lr: 0.000015
2021-07-23 11:59:00,772 epoch 30 - iter 1269/1412 - loss 0.04990361 - samples/sec: 130.94 - lr: 0.000015
2021-07-23 11:59:35,132 epoch 30 - iter 1410/1412 - loss 0.04964578 - samples/sec: 131.34 - lr: 0.000015
2021-07-23 11:59:35,504 ----------------------------------------------------------------------------------------------------
2021-07-23 11:59:35,504 EPOCH 30 done: loss 0.0496 - lr 0.0000150
2021-07-23 11:59:49,969 DEV : loss 0.06265551596879959 - score 0.9829
2021-07-23 11:59:50,122 BAD EPOCHS (no improvement): 2
2021-07-23 11:59:50,123 ----------------------------------------------------------------------------------------------------
2021-07-23 12:00:24,605 epoch 31 - iter 141/1412 - loss 0.04578638 - samples/sec: 130.89 - lr: 0.000015
2021-07-23 12:00:59,323 epoch 31 - iter 282/1412 - loss 0.04946293 - samples/sec: 129.99 - lr: 0.000015
2021-07-23 12:01:33,756 epoch 31 - iter 423/1412 - loss 0.05447667 - samples/sec: 131.06 - lr: 0.000015
2021-07-23 12:02:08,184 epoch 31 - iter 564/1412 - loss 0.05285177 - samples/sec: 131.09 - lr: 0.000015
2021-07-23 12:02:43,106 epoch 31 - iter 705/1412 - loss 0.05182946 - samples/sec: 129.23 - lr: 0.000015
2021-07-23 12:03:17,948 epoch 31 - iter 846/1412 - loss 0.05193369 - samples/sec: 129.52 - lr: 0.000015
2021-07-23 12:03:53,668 epoch 31 - iter 987/1412 - loss 0.05100966 - samples/sec: 126.34 - lr: 0.000015
2021-07-23 12:04:28,489 epoch 31 - iter 1128/1412 - loss 0.05086340 - samples/sec: 129.60 - lr: 0.000015
2021-07-23 12:05:02,694 epoch 31 - iter 1269/1412 - loss 0.05071986 - samples/sec: 131.94 - lr: 0.000015
2021-07-23 12:05:37,369 epoch 31 - iter 1410/1412 - loss 0.05051287 - samples/sec: 130.15 - lr: 0.000015
2021-07-23 12:05:37,772 ----------------------------------------------------------------------------------------------------
2021-07-23 12:05:37,772 EPOCH 31 done: loss 0.0505 - lr 0.0000150
2021-07-23 12:05:52,320 DEV : loss 0.06082860380411148 - score 0.9837
2021-07-23 12:05:52,469 BAD EPOCHS (no improvement): 3
2021-07-23 12:05:52,469 ----------------------------------------------------------------------------------------------------
2021-07-23 12:06:27,208 epoch 32 - iter 141/1412 - loss 0.04472014 - samples/sec: 129.92 - lr: 0.000015
2021-07-23 12:07:01,323 epoch 32 - iter 282/1412 - loss 0.04686693 - samples/sec: 132.28 - lr: 0.000015
2021-07-23 12:07:36,349 epoch 32 - iter 423/1412 - loss 0.04629507 - samples/sec: 128.85 - lr: 0.000015
2021-07-23 12:08:10,731 epoch 32 - iter 564/1412 - loss 0.04526398 - samples/sec: 131.26 - lr: 0.000015
2021-07-23 12:08:45,382 epoch 32 - iter 705/1412 - loss 0.04596203 - samples/sec: 130.24 - lr: 0.000015
2021-07-23 12:09:20,252 epoch 32 - iter 846/1412 - loss 0.04629445 - samples/sec: 129.42 - lr: 0.000015
2021-07-23 12:09:55,339 epoch 32 - iter 987/1412 - loss 0.04694065 - samples/sec: 128.62 - lr: 0.000015
2021-07-23 12:10:29,772 epoch 32 - iter 1128/1412 - loss 0.04791635 - samples/sec: 131.06 - lr: 0.000015
2021-07-23 12:11:04,700 epoch 32 - iter 1269/1412 - loss 0.04794938 - samples/sec: 129.21 - lr: 0.000015
2021-07-23 12:11:39,440 epoch 32 - iter 1410/1412 - loss 0.04792703 - samples/sec: 129.90 - lr: 0.000015
2021-07-23 12:11:39,826 ----------------------------------------------------------------------------------------------------
2021-07-23 12:11:39,826 EPOCH 32 done: loss 0.0479 - lr 0.0000150
2021-07-23 12:11:54,289 DEV : loss 0.0653497502207756 - score 0.9824
Epoch    32: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 12:11:54,441 BAD EPOCHS (no improvement): 4
2021-07-23 12:11:54,442 ----------------------------------------------------------------------------------------------------
2021-07-23 12:12:29,124 epoch 33 - iter 141/1412 - loss 0.04492835 - samples/sec: 130.13 - lr: 0.000008
2021-07-23 12:13:03,622 epoch 33 - iter 282/1412 - loss 0.04912371 - samples/sec: 130.82 - lr: 0.000008
2021-07-23 12:13:38,647 epoch 33 - iter 423/1412 - loss 0.04782652 - samples/sec: 128.85 - lr: 0.000008
2021-07-23 12:14:13,505 epoch 33 - iter 564/1412 - loss 0.05041682 - samples/sec: 129.47 - lr: 0.000008
2021-07-23 12:14:48,280 epoch 33 - iter 705/1412 - loss 0.04974961 - samples/sec: 129.77 - lr: 0.000008
2021-07-23 12:15:22,923 epoch 33 - iter 846/1412 - loss 0.04892067 - samples/sec: 130.27 - lr: 0.000008
2021-07-23 12:15:57,400 epoch 33 - iter 987/1412 - loss 0.04948304 - samples/sec: 130.90 - lr: 0.000008
2021-07-23 12:16:32,028 epoch 33 - iter 1128/1412 - loss 0.04980273 - samples/sec: 130.32 - lr: 0.000008
2021-07-23 12:17:06,748 epoch 33 - iter 1269/1412 - loss 0.04901834 - samples/sec: 129.98 - lr: 0.000008
2021-07-23 12:17:41,600 epoch 33 - iter 1410/1412 - loss 0.04937403 - samples/sec: 129.49 - lr: 0.000008
2021-07-23 12:17:41,944 ----------------------------------------------------------------------------------------------------
2021-07-23 12:17:41,945 EPOCH 33 done: loss 0.0493 - lr 0.0000075
2021-07-23 12:17:56,453 DEV : loss 0.06299150735139847 - score 0.9836
2021-07-23 12:17:56,607 BAD EPOCHS (no improvement): 1
2021-07-23 12:17:56,608 ----------------------------------------------------------------------------------------------------
2021-07-23 12:18:30,885 epoch 34 - iter 141/1412 - loss 0.04535968 - samples/sec: 131.67 - lr: 0.000008
2021-07-23 12:19:05,545 epoch 34 - iter 282/1412 - loss 0.04242319 - samples/sec: 130.20 - lr: 0.000008
2021-07-23 12:19:39,773 epoch 34 - iter 423/1412 - loss 0.04530963 - samples/sec: 131.85 - lr: 0.000008
2021-07-23 12:20:14,459 epoch 34 - iter 564/1412 - loss 0.04597031 - samples/sec: 130.11 - lr: 0.000008
2021-07-23 12:20:49,429 epoch 34 - iter 705/1412 - loss 0.04594635 - samples/sec: 129.05 - lr: 0.000008
2021-07-23 12:21:24,592 epoch 34 - iter 846/1412 - loss 0.04519039 - samples/sec: 128.34 - lr: 0.000008
2021-07-23 12:21:59,305 epoch 34 - iter 987/1412 - loss 0.04495353 - samples/sec: 130.01 - lr: 0.000008
2021-07-23 12:22:34,300 epoch 34 - iter 1128/1412 - loss 0.04619936 - samples/sec: 128.96 - lr: 0.000008
2021-07-23 12:23:09,060 epoch 34 - iter 1269/1412 - loss 0.04600419 - samples/sec: 129.83 - lr: 0.000008
2021-07-23 12:23:43,229 epoch 34 - iter 1410/1412 - loss 0.04656057 - samples/sec: 132.07 - lr: 0.000008
2021-07-23 12:23:43,647 ----------------------------------------------------------------------------------------------------
2021-07-23 12:23:43,648 EPOCH 34 done: loss 0.0465 - lr 0.0000075
2021-07-23 12:23:58,262 DEV : loss 0.06338313966989517 - score 0.983
2021-07-23 12:23:58,413 BAD EPOCHS (no improvement): 2
2021-07-23 12:23:58,413 ----------------------------------------------------------------------------------------------------
2021-07-23 12:24:32,512 epoch 35 - iter 141/1412 - loss 0.03875745 - samples/sec: 132.36 - lr: 0.000008
2021-07-23 12:25:07,425 epoch 35 - iter 282/1412 - loss 0.04453453 - samples/sec: 129.26 - lr: 0.000008
2021-07-23 12:25:41,600 epoch 35 - iter 423/1412 - loss 0.04724912 - samples/sec: 132.05 - lr: 0.000008
2021-07-23 12:26:16,345 epoch 35 - iter 564/1412 - loss 0.04736250 - samples/sec: 129.89 - lr: 0.000008
2021-07-23 12:26:50,909 epoch 35 - iter 705/1412 - loss 0.04690117 - samples/sec: 130.57 - lr: 0.000008
2021-07-23 12:27:25,223 epoch 35 - iter 846/1412 - loss 0.04714633 - samples/sec: 131.52 - lr: 0.000008
2021-07-23 12:27:59,677 epoch 35 - iter 987/1412 - loss 0.04774022 - samples/sec: 130.99 - lr: 0.000008
2021-07-23 12:28:34,087 epoch 35 - iter 1128/1412 - loss 0.04750854 - samples/sec: 131.15 - lr: 0.000008
2021-07-23 12:29:08,484 epoch 35 - iter 1269/1412 - loss 0.04674000 - samples/sec: 131.20 - lr: 0.000008
2021-07-23 12:29:42,949 epoch 35 - iter 1410/1412 - loss 0.04684256 - samples/sec: 130.94 - lr: 0.000008
2021-07-23 12:29:43,359 ----------------------------------------------------------------------------------------------------
2021-07-23 12:29:43,359 EPOCH 35 done: loss 0.0470 - lr 0.0000075
2021-07-23 12:29:59,258 DEV : loss 0.06380167603492737 - score 0.9838
2021-07-23 12:29:59,411 BAD EPOCHS (no improvement): 3
2021-07-23 12:29:59,411 ----------------------------------------------------------------------------------------------------
2021-07-23 12:30:34,521 epoch 36 - iter 141/1412 - loss 0.04761479 - samples/sec: 128.55 - lr: 0.000008
2021-07-23 12:31:09,403 epoch 36 - iter 282/1412 - loss 0.04389239 - samples/sec: 129.38 - lr: 0.000008
2021-07-23 12:31:44,504 epoch 36 - iter 423/1412 - loss 0.04464716 - samples/sec: 128.57 - lr: 0.000008
2021-07-23 12:32:19,112 epoch 36 - iter 564/1412 - loss 0.04649379 - samples/sec: 130.40 - lr: 0.000008
2021-07-23 12:32:53,873 epoch 36 - iter 705/1412 - loss 0.04612443 - samples/sec: 129.82 - lr: 0.000008
2021-07-23 12:33:28,542 epoch 36 - iter 846/1412 - loss 0.04630357 - samples/sec: 130.17 - lr: 0.000008
2021-07-23 12:34:02,938 epoch 36 - iter 987/1412 - loss 0.04599134 - samples/sec: 131.21 - lr: 0.000008
2021-07-23 12:34:37,493 epoch 36 - iter 1128/1412 - loss 0.04610548 - samples/sec: 130.60 - lr: 0.000008
2021-07-23 12:35:12,102 epoch 36 - iter 1269/1412 - loss 0.04658744 - samples/sec: 130.40 - lr: 0.000008
2021-07-23 12:35:46,725 epoch 36 - iter 1410/1412 - loss 0.04788158 - samples/sec: 130.34 - lr: 0.000008
2021-07-23 12:35:47,104 ----------------------------------------------------------------------------------------------------
2021-07-23 12:35:47,104 EPOCH 36 done: loss 0.0479 - lr 0.0000075
2021-07-23 12:36:01,599 DEV : loss 0.06297457218170166 - score 0.9832
Epoch    36: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 12:36:01,753 BAD EPOCHS (no improvement): 4
2021-07-23 12:36:01,753 ----------------------------------------------------------------------------------------------------
2021-07-23 12:36:36,800 epoch 37 - iter 141/1412 - loss 0.04705660 - samples/sec: 128.78 - lr: 0.000004
2021-07-23 12:37:11,869 epoch 37 - iter 282/1412 - loss 0.04518132 - samples/sec: 128.69 - lr: 0.000004
2021-07-23 12:37:46,681 epoch 37 - iter 423/1412 - loss 0.04574849 - samples/sec: 129.64 - lr: 0.000004
2021-07-23 12:38:20,873 epoch 37 - iter 564/1412 - loss 0.04675652 - samples/sec: 131.99 - lr: 0.000004
2021-07-23 12:38:55,649 epoch 37 - iter 705/1412 - loss 0.04702157 - samples/sec: 129.77 - lr: 0.000004
2021-07-23 12:39:30,239 epoch 37 - iter 846/1412 - loss 0.04752012 - samples/sec: 130.47 - lr: 0.000004
2021-07-23 12:40:04,749 epoch 37 - iter 987/1412 - loss 0.04721027 - samples/sec: 130.77 - lr: 0.000004
2021-07-23 12:40:39,461 epoch 37 - iter 1128/1412 - loss 0.04709263 - samples/sec: 130.01 - lr: 0.000004
2021-07-23 12:41:14,190 epoch 37 - iter 1269/1412 - loss 0.04719362 - samples/sec: 129.95 - lr: 0.000004
2021-07-23 12:41:49,223 epoch 37 - iter 1410/1412 - loss 0.04809641 - samples/sec: 128.82 - lr: 0.000004
2021-07-23 12:41:49,610 ----------------------------------------------------------------------------------------------------
2021-07-23 12:41:49,610 EPOCH 37 done: loss 0.0480 - lr 0.0000038
2021-07-23 12:42:04,108 DEV : loss 0.06254871934652328 - score 0.9837
2021-07-23 12:42:04,261 BAD EPOCHS (no improvement): 1
2021-07-23 12:42:04,261 ----------------------------------------------------------------------------------------------------
2021-07-23 12:42:39,154 epoch 38 - iter 141/1412 - loss 0.04647166 - samples/sec: 129.35 - lr: 0.000004
2021-07-23 12:43:14,570 epoch 38 - iter 282/1412 - loss 0.04616677 - samples/sec: 127.43 - lr: 0.000004
2021-07-23 12:43:49,370 epoch 38 - iter 423/1412 - loss 0.04436822 - samples/sec: 129.68 - lr: 0.000004
2021-07-23 12:44:24,667 epoch 38 - iter 564/1412 - loss 0.04419048 - samples/sec: 127.86 - lr: 0.000004
2021-07-23 12:44:59,089 epoch 38 - iter 705/1412 - loss 0.04499870 - samples/sec: 131.11 - lr: 0.000004
2021-07-23 12:45:33,436 epoch 38 - iter 846/1412 - loss 0.04465217 - samples/sec: 131.39 - lr: 0.000004
2021-07-23 12:46:07,689 epoch 38 - iter 987/1412 - loss 0.04484057 - samples/sec: 131.75 - lr: 0.000004
2021-07-23 12:46:42,435 epoch 38 - iter 1128/1412 - loss 0.04523753 - samples/sec: 129.88 - lr: 0.000004
2021-07-23 12:47:17,356 epoch 38 - iter 1269/1412 - loss 0.04550680 - samples/sec: 129.23 - lr: 0.000004
2021-07-23 12:47:51,868 epoch 38 - iter 1410/1412 - loss 0.04634131 - samples/sec: 130.76 - lr: 0.000004
2021-07-23 12:47:52,257 ----------------------------------------------------------------------------------------------------
2021-07-23 12:47:52,257 EPOCH 38 done: loss 0.0463 - lr 0.0000038
2021-07-23 12:48:06,835 DEV : loss 0.0640907734632492 - score 0.9837
2021-07-23 12:48:06,987 BAD EPOCHS (no improvement): 2
2021-07-23 12:48:06,987 ----------------------------------------------------------------------------------------------------
2021-07-23 12:48:41,632 epoch 39 - iter 141/1412 - loss 0.04972623 - samples/sec: 130.27 - lr: 0.000004
2021-07-23 12:49:16,614 epoch 39 - iter 282/1412 - loss 0.04659113 - samples/sec: 129.01 - lr: 0.000004
2021-07-23 12:49:51,284 epoch 39 - iter 423/1412 - loss 0.04580996 - samples/sec: 130.17 - lr: 0.000004
2021-07-23 12:50:26,069 epoch 39 - iter 564/1412 - loss 0.04443471 - samples/sec: 129.74 - lr: 0.000004
2021-07-23 12:51:00,393 epoch 39 - iter 705/1412 - loss 0.04393080 - samples/sec: 131.48 - lr: 0.000004
2021-07-23 12:51:35,480 epoch 39 - iter 846/1412 - loss 0.04488502 - samples/sec: 128.62 - lr: 0.000004
2021-07-23 12:52:09,956 epoch 39 - iter 987/1412 - loss 0.04480077 - samples/sec: 130.90 - lr: 0.000004
2021-07-23 12:52:44,614 epoch 39 - iter 1128/1412 - loss 0.04442421 - samples/sec: 130.21 - lr: 0.000004
2021-07-23 12:53:19,325 epoch 39 - iter 1269/1412 - loss 0.04421370 - samples/sec: 130.01 - lr: 0.000004
2021-07-23 12:53:54,388 epoch 39 - iter 1410/1412 - loss 0.04406415 - samples/sec: 128.71 - lr: 0.000004
2021-07-23 12:53:54,754 ----------------------------------------------------------------------------------------------------
2021-07-23 12:53:54,754 EPOCH 39 done: loss 0.0442 - lr 0.0000038
2021-07-23 12:54:09,355 DEV : loss 0.06427484005689621 - score 0.9837
2021-07-23 12:54:09,507 BAD EPOCHS (no improvement): 3
2021-07-23 12:54:09,507 ----------------------------------------------------------------------------------------------------
2021-07-23 12:54:45,564 epoch 40 - iter 141/1412 - loss 0.04991785 - samples/sec: 125.17 - lr: 0.000004
2021-07-23 12:55:20,536 epoch 40 - iter 282/1412 - loss 0.04804684 - samples/sec: 129.05 - lr: 0.000004
2021-07-23 12:55:55,119 epoch 40 - iter 423/1412 - loss 0.04656142 - samples/sec: 130.49 - lr: 0.000004
2021-07-23 12:56:29,914 epoch 40 - iter 564/1412 - loss 0.04591286 - samples/sec: 129.70 - lr: 0.000004
2021-07-23 12:57:04,975 epoch 40 - iter 705/1412 - loss 0.04615245 - samples/sec: 128.72 - lr: 0.000004
2021-07-23 12:57:39,378 epoch 40 - iter 846/1412 - loss 0.04692137 - samples/sec: 131.18 - lr: 0.000004
2021-07-23 12:58:14,037 epoch 40 - iter 987/1412 - loss 0.04522153 - samples/sec: 130.21 - lr: 0.000004
2021-07-23 12:58:48,724 epoch 40 - iter 1128/1412 - loss 0.04560753 - samples/sec: 130.10 - lr: 0.000004
2021-07-23 12:59:23,220 epoch 40 - iter 1269/1412 - loss 0.04627194 - samples/sec: 130.83 - lr: 0.000004
2021-07-23 12:59:57,871 epoch 40 - iter 1410/1412 - loss 0.04541326 - samples/sec: 130.24 - lr: 0.000004
2021-07-23 12:59:58,243 ----------------------------------------------------------------------------------------------------
2021-07-23 12:59:58,243 EPOCH 40 done: loss 0.0454 - lr 0.0000038
2021-07-23 13:00:12,860 DEV : loss 0.0633465051651001 - score 0.9841
2021-07-23 13:00:13,011 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:00:16,737 ----------------------------------------------------------------------------------------------------
2021-07-23 13:00:16,738 Testing using best model ...
2021-07-23 13:00:16,739 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/rus.rst.rrt/best-model.pt
2021-07-23 13:02:38,908 0.9838	0.9928	0.9883
2021-07-23 13:02:38,908 
Results:
- F1-score (micro) 0.9883
- F1-score (macro) 0.9889

By class:
SENT       tp: 3618 - fp: 114 - fn: 50 - precision: 0.9695 - recall: 0.9864 - f1-score: 0.9778
X          tp: 3320 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 13:02:38,909 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.gum/
2021-07-23 13:02:38,978 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.gum
2021-07-23 13:02:38,980 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.gum/sent_train.txt
2021-07-23 13:02:38,981 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.gum/sent_dev.txt
2021-07-23 13:02:38,983 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.gum/sent_test.txt
Corpus: 12303 train + 2617 dev + 4704 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 13:02:52,359 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:52,360 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 13:02:52,360 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:52,360 Corpus: "Corpus: 12303 train + 2617 dev + 4704 test sentences"
2021-07-23 13:02:52,360 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:52,360 Parameters:
2021-07-23 13:02:52,360  - learning_rate: "3e-05"
2021-07-23 13:02:52,361  - mini_batch_size: "32"
2021-07-23 13:02:52,361  - patience: "3"
2021-07-23 13:02:52,361  - anneal_factor: "0.5"
2021-07-23 13:02:52,361  - max_epochs: "40"
2021-07-23 13:02:52,361  - shuffle: "True"
2021-07-23 13:02:52,361  - train_with_dev: "False"
2021-07-23 13:02:52,361  - batch_growth_annealing: "False"
2021-07-23 13:02:52,361 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:52,361 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.gum"
2021-07-23 13:02:52,361 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:52,361 Device: cuda:0
2021-07-23 13:02:52,361 ----------------------------------------------------------------------------------------------------
2021-07-23 13:02:52,361 Embeddings storage mode: cpu
2021-07-23 13:02:52,364 ----------------------------------------------------------------------------------------------------
2021-07-23 13:03:14,325 epoch 1 - iter 38/385 - loss 6.36450805 - samples/sec: 55.38 - lr: 0.000030
2021-07-23 13:03:37,075 epoch 1 - iter 76/385 - loss 4.82180043 - samples/sec: 53.46 - lr: 0.000030
2021-07-23 13:03:59,831 epoch 1 - iter 114/385 - loss 3.83846417 - samples/sec: 53.44 - lr: 0.000030
2021-07-23 13:04:21,743 epoch 1 - iter 152/385 - loss 3.21962784 - samples/sec: 55.50 - lr: 0.000030
2021-07-23 13:04:43,668 epoch 1 - iter 190/385 - loss 2.76990119 - samples/sec: 55.47 - lr: 0.000030
2021-07-23 13:05:06,162 epoch 1 - iter 228/385 - loss 2.42444807 - samples/sec: 54.06 - lr: 0.000030
2021-07-23 13:05:28,161 epoch 1 - iter 266/385 - loss 2.16379589 - samples/sec: 55.28 - lr: 0.000030
2021-07-23 13:05:50,235 epoch 1 - iter 304/385 - loss 1.95760994 - samples/sec: 55.09 - lr: 0.000030
2021-07-23 13:06:12,070 epoch 1 - iter 342/385 - loss 1.79370176 - samples/sec: 55.69 - lr: 0.000030
2021-07-23 13:06:33,645 epoch 1 - iter 380/385 - loss 1.65468585 - samples/sec: 56.36 - lr: 0.000030
2021-07-23 13:06:36,179 ----------------------------------------------------------------------------------------------------
2021-07-23 13:06:36,179 EPOCH 1 done: loss 1.6372 - lr 0.0000300
2021-07-23 13:07:10,401 DEV : loss 0.18314668536186218 - score 0.9749
2021-07-23 13:07:10,469 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:07:11,099 ----------------------------------------------------------------------------------------------------
2021-07-23 13:07:20,056 epoch 2 - iter 38/385 - loss 0.33495874 - samples/sec: 135.80 - lr: 0.000030
2021-07-23 13:07:29,015 epoch 2 - iter 76/385 - loss 0.31967312 - samples/sec: 135.77 - lr: 0.000030
2021-07-23 13:07:37,903 epoch 2 - iter 114/385 - loss 0.30740519 - samples/sec: 136.84 - lr: 0.000030
2021-07-23 13:07:46,853 epoch 2 - iter 152/385 - loss 0.29983191 - samples/sec: 135.90 - lr: 0.000030
2021-07-23 13:07:56,061 epoch 2 - iter 190/385 - loss 0.28713170 - samples/sec: 132.08 - lr: 0.000030
2021-07-23 13:08:05,070 epoch 2 - iter 228/385 - loss 0.27531451 - samples/sec: 135.01 - lr: 0.000030
2021-07-23 13:08:14,231 epoch 2 - iter 266/385 - loss 0.26528903 - samples/sec: 132.76 - lr: 0.000030
2021-07-23 13:08:22,997 epoch 2 - iter 304/385 - loss 0.25952342 - samples/sec: 138.75 - lr: 0.000030
2021-07-23 13:08:32,036 epoch 2 - iter 342/385 - loss 0.25497364 - samples/sec: 134.56 - lr: 0.000030
2021-07-23 13:08:40,963 epoch 2 - iter 380/385 - loss 0.25214558 - samples/sec: 136.25 - lr: 0.000030
2021-07-23 13:08:42,003 ----------------------------------------------------------------------------------------------------
2021-07-23 13:08:42,003 EPOCH 2 done: loss 0.2519 - lr 0.0000300
2021-07-23 13:08:48,170 DEV : loss 0.08777700364589691 - score 0.9827
2021-07-23 13:08:48,238 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:08:50,545 ----------------------------------------------------------------------------------------------------
2021-07-23 13:08:59,551 epoch 3 - iter 38/385 - loss 0.17316985 - samples/sec: 135.09 - lr: 0.000030
2021-07-23 13:09:08,703 epoch 3 - iter 76/385 - loss 0.18515306 - samples/sec: 132.90 - lr: 0.000030
2021-07-23 13:09:17,998 epoch 3 - iter 114/385 - loss 0.18982136 - samples/sec: 130.86 - lr: 0.000030
2021-07-23 13:09:27,418 epoch 3 - iter 152/385 - loss 0.19024470 - samples/sec: 129.11 - lr: 0.000030
2021-07-23 13:09:36,456 epoch 3 - iter 190/385 - loss 0.18844773 - samples/sec: 134.57 - lr: 0.000030
2021-07-23 13:09:45,341 epoch 3 - iter 228/385 - loss 0.18887059 - samples/sec: 136.90 - lr: 0.000030
2021-07-23 13:09:54,245 epoch 3 - iter 266/385 - loss 0.18798518 - samples/sec: 136.60 - lr: 0.000030
2021-07-23 13:10:03,096 epoch 3 - iter 304/385 - loss 0.18933080 - samples/sec: 137.41 - lr: 0.000030
2021-07-23 13:10:11,881 epoch 3 - iter 342/385 - loss 0.18783140 - samples/sec: 138.46 - lr: 0.000030
2021-07-23 13:10:20,620 epoch 3 - iter 380/385 - loss 0.18640908 - samples/sec: 139.17 - lr: 0.000030
2021-07-23 13:10:21,635 ----------------------------------------------------------------------------------------------------
2021-07-23 13:10:21,635 EPOCH 3 done: loss 0.1867 - lr 0.0000300
2021-07-23 13:10:27,839 DEV : loss 0.07725907117128372 - score 0.9849
2021-07-23 13:10:27,909 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:10:30,316 ----------------------------------------------------------------------------------------------------
2021-07-23 13:10:39,262 epoch 4 - iter 38/385 - loss 0.16851858 - samples/sec: 135.99 - lr: 0.000030
2021-07-23 13:10:48,389 epoch 4 - iter 76/385 - loss 0.17382543 - samples/sec: 133.25 - lr: 0.000030
2021-07-23 13:10:57,251 epoch 4 - iter 114/385 - loss 0.17235428 - samples/sec: 137.25 - lr: 0.000030
2021-07-23 13:11:06,219 epoch 4 - iter 152/385 - loss 0.17043956 - samples/sec: 135.63 - lr: 0.000030
2021-07-23 13:11:15,380 epoch 4 - iter 190/385 - loss 0.17068916 - samples/sec: 132.76 - lr: 0.000030
2021-07-23 13:11:24,680 epoch 4 - iter 228/385 - loss 0.16882134 - samples/sec: 130.78 - lr: 0.000030
2021-07-23 13:11:33,768 epoch 4 - iter 266/385 - loss 0.16849375 - samples/sec: 133.84 - lr: 0.000030
2021-07-23 13:11:42,787 epoch 4 - iter 304/385 - loss 0.17072787 - samples/sec: 134.85 - lr: 0.000030
2021-07-23 13:11:51,534 epoch 4 - iter 342/385 - loss 0.16958565 - samples/sec: 139.06 - lr: 0.000030
2021-07-23 13:12:00,427 epoch 4 - iter 380/385 - loss 0.17086208 - samples/sec: 136.76 - lr: 0.000030
2021-07-23 13:12:01,544 ----------------------------------------------------------------------------------------------------
2021-07-23 13:12:01,544 EPOCH 4 done: loss 0.1711 - lr 0.0000300
2021-07-23 13:12:07,731 DEV : loss 0.07468052208423615 - score 0.9851
2021-07-23 13:12:07,800 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:12:10,057 ----------------------------------------------------------------------------------------------------
2021-07-23 13:12:18,967 epoch 5 - iter 38/385 - loss 0.17588878 - samples/sec: 136.54 - lr: 0.000030
2021-07-23 13:12:27,965 epoch 5 - iter 76/385 - loss 0.16586425 - samples/sec: 135.18 - lr: 0.000030
2021-07-23 13:12:37,044 epoch 5 - iter 114/385 - loss 0.16689201 - samples/sec: 133.96 - lr: 0.000030
2021-07-23 13:12:46,005 epoch 5 - iter 152/385 - loss 0.17262218 - samples/sec: 135.73 - lr: 0.000030
2021-07-23 13:12:55,096 epoch 5 - iter 190/385 - loss 0.16964895 - samples/sec: 133.78 - lr: 0.000030
2021-07-23 13:13:04,080 epoch 5 - iter 228/385 - loss 0.17087868 - samples/sec: 135.39 - lr: 0.000030
2021-07-23 13:13:12,812 epoch 5 - iter 266/385 - loss 0.17128011 - samples/sec: 139.29 - lr: 0.000030
2021-07-23 13:13:21,667 epoch 5 - iter 304/385 - loss 0.17078187 - samples/sec: 137.35 - lr: 0.000030
2021-07-23 13:13:30,423 epoch 5 - iter 342/385 - loss 0.16834164 - samples/sec: 138.91 - lr: 0.000030
2021-07-23 13:13:39,274 epoch 5 - iter 380/385 - loss 0.16890221 - samples/sec: 137.42 - lr: 0.000030
2021-07-23 13:13:40,313 ----------------------------------------------------------------------------------------------------
2021-07-23 13:13:40,313 EPOCH 5 done: loss 0.1692 - lr 0.0000300
2021-07-23 13:13:46,974 DEV : loss 0.06773967295885086 - score 0.9857
2021-07-23 13:13:47,044 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:13:49,319 ----------------------------------------------------------------------------------------------------
2021-07-23 13:13:58,339 epoch 6 - iter 38/385 - loss 0.13590663 - samples/sec: 134.89 - lr: 0.000030
2021-07-23 13:14:07,237 epoch 6 - iter 76/385 - loss 0.13887333 - samples/sec: 136.68 - lr: 0.000030
2021-07-23 13:14:16,275 epoch 6 - iter 114/385 - loss 0.14734622 - samples/sec: 134.58 - lr: 0.000030
2021-07-23 13:14:25,344 epoch 6 - iter 152/385 - loss 0.15107455 - samples/sec: 134.11 - lr: 0.000030
2021-07-23 13:14:34,374 epoch 6 - iter 190/385 - loss 0.15360208 - samples/sec: 134.68 - lr: 0.000030
2021-07-23 13:14:43,329 epoch 6 - iter 228/385 - loss 0.15276712 - samples/sec: 135.83 - lr: 0.000030
2021-07-23 13:14:52,333 epoch 6 - iter 266/385 - loss 0.15167927 - samples/sec: 135.08 - lr: 0.000030
2021-07-23 13:15:01,364 epoch 6 - iter 304/385 - loss 0.15131727 - samples/sec: 134.68 - lr: 0.000030
2021-07-23 13:15:10,327 epoch 6 - iter 342/385 - loss 0.15125678 - samples/sec: 135.70 - lr: 0.000030
2021-07-23 13:15:19,244 epoch 6 - iter 380/385 - loss 0.15250757 - samples/sec: 136.40 - lr: 0.000030
2021-07-23 13:15:20,342 ----------------------------------------------------------------------------------------------------
2021-07-23 13:15:20,342 EPOCH 6 done: loss 0.1517 - lr 0.0000300
2021-07-23 13:15:26,543 DEV : loss 0.06620562076568604 - score 0.9862
2021-07-23 13:15:26,613 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:15:29,033 ----------------------------------------------------------------------------------------------------
2021-07-23 13:15:38,041 epoch 7 - iter 38/385 - loss 0.14467400 - samples/sec: 135.06 - lr: 0.000030
2021-07-23 13:15:47,055 epoch 7 - iter 76/385 - loss 0.14307931 - samples/sec: 134.93 - lr: 0.000030
2021-07-23 13:15:56,018 epoch 7 - iter 114/385 - loss 0.14151305 - samples/sec: 135.71 - lr: 0.000030
2021-07-23 13:16:05,149 epoch 7 - iter 152/385 - loss 0.13907834 - samples/sec: 133.20 - lr: 0.000030
2021-07-23 13:16:14,103 epoch 7 - iter 190/385 - loss 0.13621708 - samples/sec: 135.83 - lr: 0.000030
2021-07-23 13:16:23,154 epoch 7 - iter 228/385 - loss 0.14105712 - samples/sec: 134.39 - lr: 0.000030
2021-07-23 13:16:31,936 epoch 7 - iter 266/385 - loss 0.14276261 - samples/sec: 138.49 - lr: 0.000030
2021-07-23 13:16:41,013 epoch 7 - iter 304/385 - loss 0.14274399 - samples/sec: 134.00 - lr: 0.000030
2021-07-23 13:16:50,103 epoch 7 - iter 342/385 - loss 0.14298673 - samples/sec: 133.80 - lr: 0.000030
2021-07-23 13:16:59,135 epoch 7 - iter 380/385 - loss 0.14212122 - samples/sec: 134.66 - lr: 0.000030
2021-07-23 13:17:00,196 ----------------------------------------------------------------------------------------------------
2021-07-23 13:17:00,196 EPOCH 7 done: loss 0.1427 - lr 0.0000300
2021-07-23 13:17:06,417 DEV : loss 0.06297065317630768 - score 0.9868
2021-07-23 13:17:06,486 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:17:08,858 ----------------------------------------------------------------------------------------------------
2021-07-23 13:17:17,761 epoch 8 - iter 38/385 - loss 0.15329596 - samples/sec: 136.64 - lr: 0.000030
2021-07-23 13:17:26,778 epoch 8 - iter 76/385 - loss 0.14045216 - samples/sec: 134.89 - lr: 0.000030
2021-07-23 13:17:35,639 epoch 8 - iter 114/385 - loss 0.13690333 - samples/sec: 137.25 - lr: 0.000030
2021-07-23 13:17:44,478 epoch 8 - iter 152/385 - loss 0.13892936 - samples/sec: 137.61 - lr: 0.000030
2021-07-23 13:17:53,408 epoch 8 - iter 190/385 - loss 0.13907289 - samples/sec: 136.20 - lr: 0.000030
2021-07-23 13:18:02,670 epoch 8 - iter 228/385 - loss 0.13795260 - samples/sec: 131.32 - lr: 0.000030
2021-07-23 13:18:11,632 epoch 8 - iter 266/385 - loss 0.13821240 - samples/sec: 135.71 - lr: 0.000030
2021-07-23 13:18:20,756 epoch 8 - iter 304/385 - loss 0.13950689 - samples/sec: 133.29 - lr: 0.000030
2021-07-23 13:18:29,889 epoch 8 - iter 342/385 - loss 0.13840638 - samples/sec: 133.17 - lr: 0.000030
2021-07-23 13:18:38,912 epoch 8 - iter 380/385 - loss 0.13731273 - samples/sec: 134.80 - lr: 0.000030
2021-07-23 13:18:39,998 ----------------------------------------------------------------------------------------------------
2021-07-23 13:18:39,998 EPOCH 8 done: loss 0.1372 - lr 0.0000300
2021-07-23 13:18:46,198 DEV : loss 0.06269878149032593 - score 0.9865
2021-07-23 13:18:46,267 BAD EPOCHS (no improvement): 1
2021-07-23 13:18:46,267 ----------------------------------------------------------------------------------------------------
2021-07-23 13:18:55,120 epoch 9 - iter 38/385 - loss 0.11413438 - samples/sec: 137.41 - lr: 0.000030
2021-07-23 13:19:04,159 epoch 9 - iter 76/385 - loss 0.12332430 - samples/sec: 134.57 - lr: 0.000030
2021-07-23 13:19:13,352 epoch 9 - iter 114/385 - loss 0.12275849 - samples/sec: 132.31 - lr: 0.000030
2021-07-23 13:19:22,220 epoch 9 - iter 152/385 - loss 0.12848886 - samples/sec: 137.15 - lr: 0.000030
2021-07-23 13:19:31,094 epoch 9 - iter 190/385 - loss 0.12974439 - samples/sec: 137.05 - lr: 0.000030
2021-07-23 13:19:40,376 epoch 9 - iter 228/385 - loss 0.13361675 - samples/sec: 131.04 - lr: 0.000030
2021-07-23 13:19:49,446 epoch 9 - iter 266/385 - loss 0.13497636 - samples/sec: 134.09 - lr: 0.000030
2021-07-23 13:19:58,376 epoch 9 - iter 304/385 - loss 0.13414625 - samples/sec: 136.21 - lr: 0.000030
2021-07-23 13:20:07,427 epoch 9 - iter 342/385 - loss 0.13602604 - samples/sec: 134.38 - lr: 0.000030
2021-07-23 13:20:16,361 epoch 9 - iter 380/385 - loss 0.13634934 - samples/sec: 136.14 - lr: 0.000030
2021-07-23 13:20:17,435 ----------------------------------------------------------------------------------------------------
2021-07-23 13:20:17,435 EPOCH 9 done: loss 0.1365 - lr 0.0000300
2021-07-23 13:20:24,078 DEV : loss 0.060181017965078354 - score 0.9873
2021-07-23 13:20:24,147 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:20:26,433 ----------------------------------------------------------------------------------------------------
2021-07-23 13:20:35,424 epoch 10 - iter 38/385 - loss 0.11447226 - samples/sec: 135.32 - lr: 0.000030
2021-07-23 13:20:44,595 epoch 10 - iter 76/385 - loss 0.12479712 - samples/sec: 132.62 - lr: 0.000030
2021-07-23 13:20:53,558 epoch 10 - iter 114/385 - loss 0.13576922 - samples/sec: 135.70 - lr: 0.000030
2021-07-23 13:21:02,568 epoch 10 - iter 152/385 - loss 0.13259462 - samples/sec: 134.98 - lr: 0.000030
2021-07-23 13:21:11,471 epoch 10 - iter 190/385 - loss 0.13287922 - samples/sec: 136.62 - lr: 0.000030
2021-07-23 13:21:20,527 epoch 10 - iter 228/385 - loss 0.13306734 - samples/sec: 134.30 - lr: 0.000030
2021-07-23 13:21:29,549 epoch 10 - iter 266/385 - loss 0.13454310 - samples/sec: 134.81 - lr: 0.000030
2021-07-23 13:21:38,839 epoch 10 - iter 304/385 - loss 0.13280517 - samples/sec: 130.92 - lr: 0.000030
2021-07-23 13:21:47,811 epoch 10 - iter 342/385 - loss 0.13355197 - samples/sec: 135.56 - lr: 0.000030
2021-07-23 13:21:56,696 epoch 10 - iter 380/385 - loss 0.13477665 - samples/sec: 136.90 - lr: 0.000030
2021-07-23 13:21:57,835 ----------------------------------------------------------------------------------------------------
2021-07-23 13:21:57,836 EPOCH 10 done: loss 0.1334 - lr 0.0000300
2021-07-23 13:22:04,013 DEV : loss 0.05868587642908096 - score 0.9873
2021-07-23 13:22:04,082 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:22:06,309 ----------------------------------------------------------------------------------------------------
2021-07-23 13:22:15,425 epoch 11 - iter 38/385 - loss 0.12601506 - samples/sec: 133.45 - lr: 0.000030
2021-07-23 13:22:24,551 epoch 11 - iter 76/385 - loss 0.14023638 - samples/sec: 133.28 - lr: 0.000030
2021-07-23 13:22:33,665 epoch 11 - iter 114/385 - loss 0.13787166 - samples/sec: 133.45 - lr: 0.000030
2021-07-23 13:22:42,671 epoch 11 - iter 152/385 - loss 0.13154533 - samples/sec: 135.06 - lr: 0.000030
2021-07-23 13:22:51,652 epoch 11 - iter 190/385 - loss 0.13395436 - samples/sec: 135.42 - lr: 0.000030
2021-07-23 13:23:00,468 epoch 11 - iter 228/385 - loss 0.13117216 - samples/sec: 137.97 - lr: 0.000030
2021-07-23 13:23:09,452 epoch 11 - iter 266/385 - loss 0.13054786 - samples/sec: 135.39 - lr: 0.000030
2021-07-23 13:23:18,351 epoch 11 - iter 304/385 - loss 0.13236424 - samples/sec: 136.68 - lr: 0.000030
2021-07-23 13:23:27,225 epoch 11 - iter 342/385 - loss 0.13265345 - samples/sec: 137.06 - lr: 0.000030
2021-07-23 13:23:36,340 epoch 11 - iter 380/385 - loss 0.13145846 - samples/sec: 133.42 - lr: 0.000030
2021-07-23 13:23:37,458 ----------------------------------------------------------------------------------------------------
2021-07-23 13:23:37,458 EPOCH 11 done: loss 0.1313 - lr 0.0000300
2021-07-23 13:23:43,633 DEV : loss 0.05995776504278183 - score 0.9882
2021-07-23 13:23:43,703 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:23:46,027 ----------------------------------------------------------------------------------------------------
2021-07-23 13:23:55,168 epoch 12 - iter 38/385 - loss 0.14167462 - samples/sec: 133.08 - lr: 0.000030
2021-07-23 13:24:04,180 epoch 12 - iter 76/385 - loss 0.13820376 - samples/sec: 134.97 - lr: 0.000030
2021-07-23 13:24:13,039 epoch 12 - iter 114/385 - loss 0.13356308 - samples/sec: 137.29 - lr: 0.000030
2021-07-23 13:24:22,097 epoch 12 - iter 152/385 - loss 0.13310697 - samples/sec: 134.28 - lr: 0.000030
2021-07-23 13:24:31,208 epoch 12 - iter 190/385 - loss 0.13106144 - samples/sec: 133.49 - lr: 0.000030
2021-07-23 13:24:40,405 epoch 12 - iter 228/385 - loss 0.12892884 - samples/sec: 132.26 - lr: 0.000030
2021-07-23 13:24:49,352 epoch 12 - iter 266/385 - loss 0.12661726 - samples/sec: 135.94 - lr: 0.000030
2021-07-23 13:24:58,396 epoch 12 - iter 304/385 - loss 0.12900144 - samples/sec: 134.48 - lr: 0.000030
2021-07-23 13:25:07,220 epoch 12 - iter 342/385 - loss 0.12692817 - samples/sec: 137.84 - lr: 0.000030
2021-07-23 13:25:16,117 epoch 12 - iter 380/385 - loss 0.12709631 - samples/sec: 136.71 - lr: 0.000030
2021-07-23 13:25:17,227 ----------------------------------------------------------------------------------------------------
2021-07-23 13:25:17,227 EPOCH 12 done: loss 0.1272 - lr 0.0000300
2021-07-23 13:25:23,383 DEV : loss 0.063162662088871 - score 0.9876
2021-07-23 13:25:23,453 BAD EPOCHS (no improvement): 1
2021-07-23 13:25:23,453 ----------------------------------------------------------------------------------------------------
2021-07-23 13:25:32,397 epoch 13 - iter 38/385 - loss 0.13247060 - samples/sec: 136.02 - lr: 0.000030
2021-07-23 13:25:41,409 epoch 13 - iter 76/385 - loss 0.12185891 - samples/sec: 134.96 - lr: 0.000030
2021-07-23 13:25:50,604 epoch 13 - iter 114/385 - loss 0.11616924 - samples/sec: 132.28 - lr: 0.000030
2021-07-23 13:25:59,589 epoch 13 - iter 152/385 - loss 0.11775418 - samples/sec: 135.37 - lr: 0.000030
2021-07-23 13:26:08,639 epoch 13 - iter 190/385 - loss 0.11817600 - samples/sec: 134.38 - lr: 0.000030
2021-07-23 13:26:17,345 epoch 13 - iter 228/385 - loss 0.12044519 - samples/sec: 139.71 - lr: 0.000030
2021-07-23 13:26:26,440 epoch 13 - iter 266/385 - loss 0.11945512 - samples/sec: 133.73 - lr: 0.000030
2021-07-23 13:26:35,495 epoch 13 - iter 304/385 - loss 0.11833573 - samples/sec: 134.32 - lr: 0.000030
2021-07-23 13:26:44,317 epoch 13 - iter 342/385 - loss 0.11846120 - samples/sec: 137.88 - lr: 0.000030
2021-07-23 13:26:53,911 epoch 13 - iter 380/385 - loss 0.11844623 - samples/sec: 126.77 - lr: 0.000030
2021-07-23 13:26:55,028 ----------------------------------------------------------------------------------------------------
2021-07-23 13:26:55,029 EPOCH 13 done: loss 0.1181 - lr 0.0000300
2021-07-23 13:27:01,188 DEV : loss 0.05693330243229866 - score 0.9884
2021-07-23 13:27:01,257 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:27:03,544 ----------------------------------------------------------------------------------------------------
2021-07-23 13:27:12,752 epoch 14 - iter 38/385 - loss 0.12052388 - samples/sec: 132.12 - lr: 0.000030
2021-07-23 13:27:21,860 epoch 14 - iter 76/385 - loss 0.11218500 - samples/sec: 133.55 - lr: 0.000030
2021-07-23 13:27:30,757 epoch 14 - iter 114/385 - loss 0.11216303 - samples/sec: 136.70 - lr: 0.000030
2021-07-23 13:27:39,873 epoch 14 - iter 152/385 - loss 0.11072367 - samples/sec: 133.42 - lr: 0.000030
2021-07-23 13:27:48,773 epoch 14 - iter 190/385 - loss 0.10678736 - samples/sec: 136.67 - lr: 0.000030
2021-07-23 13:27:57,873 epoch 14 - iter 228/385 - loss 0.11082041 - samples/sec: 133.65 - lr: 0.000030
2021-07-23 13:28:06,723 epoch 14 - iter 266/385 - loss 0.11052931 - samples/sec: 137.43 - lr: 0.000030
2021-07-23 13:28:15,508 epoch 14 - iter 304/385 - loss 0.11059815 - samples/sec: 138.45 - lr: 0.000030
2021-07-23 13:28:24,588 epoch 14 - iter 342/385 - loss 0.11146580 - samples/sec: 133.95 - lr: 0.000030
2021-07-23 13:28:33,568 epoch 14 - iter 380/385 - loss 0.11136181 - samples/sec: 135.45 - lr: 0.000030
2021-07-23 13:28:34,699 ----------------------------------------------------------------------------------------------------
2021-07-23 13:28:34,700 EPOCH 14 done: loss 0.1116 - lr 0.0000300
2021-07-23 13:28:40,904 DEV : loss 0.056013140827417374 - score 0.9892
2021-07-23 13:28:40,974 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:28:43,198 ----------------------------------------------------------------------------------------------------
2021-07-23 13:28:52,170 epoch 15 - iter 38/385 - loss 0.09932729 - samples/sec: 135.60 - lr: 0.000030
2021-07-23 13:29:00,917 epoch 15 - iter 76/385 - loss 0.10912919 - samples/sec: 139.06 - lr: 0.000030
2021-07-23 13:29:09,876 epoch 15 - iter 114/385 - loss 0.10669471 - samples/sec: 135.76 - lr: 0.000030
2021-07-23 13:29:18,625 epoch 15 - iter 152/385 - loss 0.10563435 - samples/sec: 139.02 - lr: 0.000030
2021-07-23 13:29:27,836 epoch 15 - iter 190/385 - loss 0.10435543 - samples/sec: 132.04 - lr: 0.000030
2021-07-23 13:29:36,623 epoch 15 - iter 228/385 - loss 0.10596842 - samples/sec: 138.41 - lr: 0.000030
2021-07-23 13:29:45,524 epoch 15 - iter 266/385 - loss 0.10558964 - samples/sec: 136.66 - lr: 0.000030
2021-07-23 13:29:54,547 epoch 15 - iter 304/385 - loss 0.10689772 - samples/sec: 134.79 - lr: 0.000030
2021-07-23 13:30:03,645 epoch 15 - iter 342/385 - loss 0.10473595 - samples/sec: 133.69 - lr: 0.000030
2021-07-23 13:30:12,576 epoch 15 - iter 380/385 - loss 0.10472268 - samples/sec: 136.18 - lr: 0.000030
2021-07-23 13:30:13,554 ----------------------------------------------------------------------------------------------------
2021-07-23 13:30:13,554 EPOCH 15 done: loss 0.1039 - lr 0.0000300
2021-07-23 13:30:19,747 DEV : loss 0.05599121004343033 - score 0.9898
2021-07-23 13:30:19,816 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:30:22,022 ----------------------------------------------------------------------------------------------------
2021-07-23 13:30:31,065 epoch 16 - iter 38/385 - loss 0.10231259 - samples/sec: 134.53 - lr: 0.000030
2021-07-23 13:30:40,060 epoch 16 - iter 76/385 - loss 0.10562904 - samples/sec: 135.22 - lr: 0.000030
2021-07-23 13:30:49,036 epoch 16 - iter 114/385 - loss 0.10274024 - samples/sec: 135.51 - lr: 0.000030
2021-07-23 13:30:58,018 epoch 16 - iter 152/385 - loss 0.10220955 - samples/sec: 135.41 - lr: 0.000030
2021-07-23 13:31:07,212 epoch 16 - iter 190/385 - loss 0.10397794 - samples/sec: 132.28 - lr: 0.000030
2021-07-23 13:31:16,256 epoch 16 - iter 228/385 - loss 0.09944146 - samples/sec: 134.49 - lr: 0.000030
2021-07-23 13:31:25,324 epoch 16 - iter 266/385 - loss 0.09787872 - samples/sec: 134.12 - lr: 0.000030
2021-07-23 13:31:34,289 epoch 16 - iter 304/385 - loss 0.09700252 - samples/sec: 135.68 - lr: 0.000030
2021-07-23 13:31:42,991 epoch 16 - iter 342/385 - loss 0.09847762 - samples/sec: 139.76 - lr: 0.000030
2021-07-23 13:31:52,096 epoch 16 - iter 380/385 - loss 0.09752294 - samples/sec: 133.59 - lr: 0.000030
2021-07-23 13:31:53,172 ----------------------------------------------------------------------------------------------------
2021-07-23 13:31:53,172 EPOCH 16 done: loss 0.0971 - lr 0.0000300
2021-07-23 13:31:59,887 DEV : loss 0.05667709931731224 - score 0.9901
2021-07-23 13:31:59,957 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:32:02,086 ----------------------------------------------------------------------------------------------------
2021-07-23 13:32:11,088 epoch 17 - iter 38/385 - loss 0.08782756 - samples/sec: 135.15 - lr: 0.000030
2021-07-23 13:32:19,968 epoch 17 - iter 76/385 - loss 0.08303798 - samples/sec: 136.97 - lr: 0.000030
2021-07-23 13:32:28,887 epoch 17 - iter 114/385 - loss 0.08135683 - samples/sec: 136.37 - lr: 0.000030
2021-07-23 13:32:37,856 epoch 17 - iter 152/385 - loss 0.08320352 - samples/sec: 135.61 - lr: 0.000030
2021-07-23 13:32:46,861 epoch 17 - iter 190/385 - loss 0.07927053 - samples/sec: 135.06 - lr: 0.000030
2021-07-23 13:32:55,840 epoch 17 - iter 228/385 - loss 0.08384246 - samples/sec: 135.45 - lr: 0.000030
2021-07-23 13:33:04,700 epoch 17 - iter 266/385 - loss 0.08370873 - samples/sec: 137.28 - lr: 0.000030
2021-07-23 13:33:13,720 epoch 17 - iter 304/385 - loss 0.08428392 - samples/sec: 134.85 - lr: 0.000030
2021-07-23 13:33:22,651 epoch 17 - iter 342/385 - loss 0.08281442 - samples/sec: 136.18 - lr: 0.000030
2021-07-23 13:33:31,561 epoch 17 - iter 380/385 - loss 0.08493178 - samples/sec: 136.50 - lr: 0.000030
2021-07-23 13:33:32,672 ----------------------------------------------------------------------------------------------------
2021-07-23 13:33:32,672 EPOCH 17 done: loss 0.0858 - lr 0.0000300
2021-07-23 13:33:38,876 DEV : loss 0.05569838732481003 - score 0.9893
2021-07-23 13:33:38,946 BAD EPOCHS (no improvement): 1
2021-07-23 13:33:38,946 ----------------------------------------------------------------------------------------------------
2021-07-23 13:33:47,767 epoch 18 - iter 38/385 - loss 0.08446096 - samples/sec: 137.90 - lr: 0.000030
2021-07-23 13:33:56,849 epoch 18 - iter 76/385 - loss 0.08303062 - samples/sec: 133.93 - lr: 0.000030
2021-07-23 13:34:05,958 epoch 18 - iter 114/385 - loss 0.08258860 - samples/sec: 133.52 - lr: 0.000030
2021-07-23 13:34:14,980 epoch 18 - iter 152/385 - loss 0.08251546 - samples/sec: 134.82 - lr: 0.000030
2021-07-23 13:34:23,904 epoch 18 - iter 190/385 - loss 0.08378849 - samples/sec: 136.30 - lr: 0.000030
2021-07-23 13:34:32,907 epoch 18 - iter 228/385 - loss 0.08422731 - samples/sec: 135.09 - lr: 0.000030
2021-07-23 13:34:41,943 epoch 18 - iter 266/385 - loss 0.08654043 - samples/sec: 134.61 - lr: 0.000030
2021-07-23 13:34:50,979 epoch 18 - iter 304/385 - loss 0.08520353 - samples/sec: 134.60 - lr: 0.000030
2021-07-23 13:35:00,129 epoch 18 - iter 342/385 - loss 0.08658372 - samples/sec: 132.94 - lr: 0.000030
2021-07-23 13:35:08,939 epoch 18 - iter 380/385 - loss 0.08801246 - samples/sec: 138.04 - lr: 0.000030
2021-07-23 13:35:10,010 ----------------------------------------------------------------------------------------------------
2021-07-23 13:35:10,010 EPOCH 18 done: loss 0.0879 - lr 0.0000300
2021-07-23 13:35:16,225 DEV : loss 0.05341668054461479 - score 0.9903
2021-07-23 13:35:16,295 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:35:18,849 ----------------------------------------------------------------------------------------------------
2021-07-23 13:35:27,660 epoch 19 - iter 38/385 - loss 0.06672197 - samples/sec: 138.07 - lr: 0.000030
2021-07-23 13:35:36,701 epoch 19 - iter 76/385 - loss 0.07453331 - samples/sec: 134.54 - lr: 0.000030
2021-07-23 13:35:45,646 epoch 19 - iter 114/385 - loss 0.07271611 - samples/sec: 135.97 - lr: 0.000030
2021-07-23 13:35:54,528 epoch 19 - iter 152/385 - loss 0.07563213 - samples/sec: 136.95 - lr: 0.000030
2021-07-23 13:36:03,698 epoch 19 - iter 190/385 - loss 0.07967931 - samples/sec: 132.64 - lr: 0.000030
2021-07-23 13:36:12,825 epoch 19 - iter 228/385 - loss 0.08031806 - samples/sec: 133.26 - lr: 0.000030
2021-07-23 13:36:21,943 epoch 19 - iter 266/385 - loss 0.07889660 - samples/sec: 133.39 - lr: 0.000030
2021-07-23 13:36:30,753 epoch 19 - iter 304/385 - loss 0.08140769 - samples/sec: 138.06 - lr: 0.000030
2021-07-23 13:36:39,831 epoch 19 - iter 342/385 - loss 0.08274592 - samples/sec: 133.97 - lr: 0.000030
2021-07-23 13:36:48,760 epoch 19 - iter 380/385 - loss 0.08359522 - samples/sec: 136.22 - lr: 0.000030
2021-07-23 13:36:49,836 ----------------------------------------------------------------------------------------------------
2021-07-23 13:36:49,837 EPOCH 19 done: loss 0.0832 - lr 0.0000300
2021-07-23 13:36:56,041 DEV : loss 0.053186170756816864 - score 0.9904
2021-07-23 13:36:56,111 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:36:58,438 ----------------------------------------------------------------------------------------------------
2021-07-23 13:37:07,660 epoch 20 - iter 38/385 - loss 0.07449235 - samples/sec: 131.92 - lr: 0.000030
2021-07-23 13:37:16,641 epoch 20 - iter 76/385 - loss 0.07713777 - samples/sec: 135.44 - lr: 0.000030
2021-07-23 13:37:25,628 epoch 20 - iter 114/385 - loss 0.07698379 - samples/sec: 135.34 - lr: 0.000030
2021-07-23 13:37:34,521 epoch 20 - iter 152/385 - loss 0.07801716 - samples/sec: 136.77 - lr: 0.000030
2021-07-23 13:37:43,333 epoch 20 - iter 190/385 - loss 0.07500877 - samples/sec: 138.02 - lr: 0.000030
2021-07-23 13:37:52,337 epoch 20 - iter 228/385 - loss 0.07517927 - samples/sec: 135.09 - lr: 0.000030
2021-07-23 13:38:01,473 epoch 20 - iter 266/385 - loss 0.07629892 - samples/sec: 133.13 - lr: 0.000030
2021-07-23 13:38:10,316 epoch 20 - iter 304/385 - loss 0.07719994 - samples/sec: 137.53 - lr: 0.000030
2021-07-23 13:38:19,384 epoch 20 - iter 342/385 - loss 0.07865963 - samples/sec: 134.14 - lr: 0.000030
2021-07-23 13:38:28,277 epoch 20 - iter 380/385 - loss 0.07754641 - samples/sec: 136.77 - lr: 0.000030
2021-07-23 13:38:29,347 ----------------------------------------------------------------------------------------------------
2021-07-23 13:38:29,347 EPOCH 20 done: loss 0.0780 - lr 0.0000300
2021-07-23 13:38:36,000 DEV : loss 0.05403595417737961 - score 0.9901
2021-07-23 13:38:36,069 BAD EPOCHS (no improvement): 1
2021-07-23 13:38:36,069 ----------------------------------------------------------------------------------------------------
2021-07-23 13:38:45,169 epoch 21 - iter 38/385 - loss 0.06914574 - samples/sec: 133.69 - lr: 0.000030
2021-07-23 13:38:53,842 epoch 21 - iter 76/385 - loss 0.06808035 - samples/sec: 140.24 - lr: 0.000030
2021-07-23 13:39:02,900 epoch 21 - iter 114/385 - loss 0.08187541 - samples/sec: 134.28 - lr: 0.000030
2021-07-23 13:39:11,715 epoch 21 - iter 152/385 - loss 0.07737664 - samples/sec: 137.97 - lr: 0.000030
2021-07-23 13:39:20,657 epoch 21 - iter 190/385 - loss 0.07747317 - samples/sec: 136.03 - lr: 0.000030
2021-07-23 13:39:29,881 epoch 21 - iter 228/385 - loss 0.08012783 - samples/sec: 131.85 - lr: 0.000030
2021-07-23 13:39:38,923 epoch 21 - iter 266/385 - loss 0.08016296 - samples/sec: 134.51 - lr: 0.000030
2021-07-23 13:39:47,993 epoch 21 - iter 304/385 - loss 0.08234205 - samples/sec: 134.10 - lr: 0.000030
2021-07-23 13:39:57,032 epoch 21 - iter 342/385 - loss 0.08058660 - samples/sec: 134.56 - lr: 0.000030
2021-07-23 13:40:06,259 epoch 21 - iter 380/385 - loss 0.07913385 - samples/sec: 131.81 - lr: 0.000030
2021-07-23 13:40:07,401 ----------------------------------------------------------------------------------------------------
2021-07-23 13:40:07,401 EPOCH 21 done: loss 0.0789 - lr 0.0000300
2021-07-23 13:40:13,573 DEV : loss 0.05430208146572113 - score 0.9895
2021-07-23 13:40:13,643 BAD EPOCHS (no improvement): 2
2021-07-23 13:40:13,643 ----------------------------------------------------------------------------------------------------
2021-07-23 13:40:22,611 epoch 22 - iter 38/385 - loss 0.08310813 - samples/sec: 135.64 - lr: 0.000030
2021-07-23 13:40:31,485 epoch 22 - iter 76/385 - loss 0.08569694 - samples/sec: 137.07 - lr: 0.000030
2021-07-23 13:40:40,288 epoch 22 - iter 114/385 - loss 0.08420485 - samples/sec: 138.16 - lr: 0.000030
2021-07-23 13:40:49,294 epoch 22 - iter 152/385 - loss 0.08402802 - samples/sec: 135.06 - lr: 0.000030
2021-07-23 13:40:58,161 epoch 22 - iter 190/385 - loss 0.08619637 - samples/sec: 137.17 - lr: 0.000030
2021-07-23 13:41:07,352 epoch 22 - iter 228/385 - loss 0.08371070 - samples/sec: 132.33 - lr: 0.000030
2021-07-23 13:41:16,486 epoch 22 - iter 266/385 - loss 0.07996818 - samples/sec: 133.16 - lr: 0.000030
2021-07-23 13:41:25,618 epoch 22 - iter 304/385 - loss 0.07951942 - samples/sec: 133.19 - lr: 0.000030
2021-07-23 13:41:34,859 epoch 22 - iter 342/385 - loss 0.07971467 - samples/sec: 131.60 - lr: 0.000030
2021-07-23 13:41:43,864 epoch 22 - iter 380/385 - loss 0.07742020 - samples/sec: 135.07 - lr: 0.000030
2021-07-23 13:41:44,962 ----------------------------------------------------------------------------------------------------
2021-07-23 13:41:44,962 EPOCH 22 done: loss 0.0773 - lr 0.0000300
2021-07-23 13:41:51,136 DEV : loss 0.05323152244091034 - score 0.9893
2021-07-23 13:41:51,206 BAD EPOCHS (no improvement): 3
2021-07-23 13:41:51,206 ----------------------------------------------------------------------------------------------------
2021-07-23 13:42:00,072 epoch 23 - iter 38/385 - loss 0.05563748 - samples/sec: 137.21 - lr: 0.000030
2021-07-23 13:42:09,077 epoch 23 - iter 76/385 - loss 0.07375388 - samples/sec: 135.07 - lr: 0.000030
2021-07-23 13:42:18,048 epoch 23 - iter 114/385 - loss 0.07848607 - samples/sec: 135.57 - lr: 0.000030
2021-07-23 13:42:27,111 epoch 23 - iter 152/385 - loss 0.07385188 - samples/sec: 134.21 - lr: 0.000030
2021-07-23 13:42:36,174 epoch 23 - iter 190/385 - loss 0.07374536 - samples/sec: 134.19 - lr: 0.000030
2021-07-23 13:42:45,334 epoch 23 - iter 228/385 - loss 0.07097053 - samples/sec: 132.78 - lr: 0.000030
2021-07-23 13:42:54,353 epoch 23 - iter 266/385 - loss 0.07162875 - samples/sec: 134.86 - lr: 0.000030
2021-07-23 13:43:03,553 epoch 23 - iter 304/385 - loss 0.07260667 - samples/sec: 132.21 - lr: 0.000030
2021-07-23 13:43:12,421 epoch 23 - iter 342/385 - loss 0.07259804 - samples/sec: 137.15 - lr: 0.000030
2021-07-23 13:43:21,367 epoch 23 - iter 380/385 - loss 0.07347432 - samples/sec: 135.95 - lr: 0.000030
2021-07-23 13:43:22,471 ----------------------------------------------------------------------------------------------------
2021-07-23 13:43:22,471 EPOCH 23 done: loss 0.0732 - lr 0.0000300
2021-07-23 13:43:28,613 DEV : loss 0.053000908344984055 - score 0.9904
2021-07-23 13:43:28,682 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 13:43:31,089 ----------------------------------------------------------------------------------------------------
2021-07-23 13:43:40,084 epoch 24 - iter 38/385 - loss 0.06635673 - samples/sec: 135.25 - lr: 0.000030
2021-07-23 13:43:49,007 epoch 24 - iter 76/385 - loss 0.06260953 - samples/sec: 136.30 - lr: 0.000030
2021-07-23 13:43:57,938 epoch 24 - iter 114/385 - loss 0.06648500 - samples/sec: 136.18 - lr: 0.000030
2021-07-23 13:44:07,016 epoch 24 - iter 152/385 - loss 0.06611894 - samples/sec: 133.99 - lr: 0.000030
2021-07-23 13:44:16,013 epoch 24 - iter 190/385 - loss 0.06531403 - samples/sec: 135.19 - lr: 0.000030
2021-07-23 13:44:25,067 epoch 24 - iter 228/385 - loss 0.06554120 - samples/sec: 134.32 - lr: 0.000030
2021-07-23 13:44:34,037 epoch 24 - iter 266/385 - loss 0.06820586 - samples/sec: 135.60 - lr: 0.000030
2021-07-23 13:44:43,101 epoch 24 - iter 304/385 - loss 0.06874608 - samples/sec: 134.20 - lr: 0.000030
2021-07-23 13:44:52,059 epoch 24 - iter 342/385 - loss 0.07012649 - samples/sec: 135.76 - lr: 0.000030
2021-07-23 13:45:01,249 epoch 24 - iter 380/385 - loss 0.07159930 - samples/sec: 132.35 - lr: 0.000030
2021-07-23 13:45:02,329 ----------------------------------------------------------------------------------------------------
2021-07-23 13:45:02,329 EPOCH 24 done: loss 0.0714 - lr 0.0000300
2021-07-23 13:45:08,979 DEV : loss 0.0528724305331707 - score 0.9901
2021-07-23 13:45:09,049 BAD EPOCHS (no improvement): 1
2021-07-23 13:45:09,049 ----------------------------------------------------------------------------------------------------
2021-07-23 13:45:17,975 epoch 25 - iter 38/385 - loss 0.07531496 - samples/sec: 136.29 - lr: 0.000030
2021-07-23 13:45:26,995 epoch 25 - iter 76/385 - loss 0.06888976 - samples/sec: 134.84 - lr: 0.000030
2021-07-23 13:45:36,096 epoch 25 - iter 114/385 - loss 0.06617791 - samples/sec: 133.63 - lr: 0.000030
2021-07-23 13:45:45,163 epoch 25 - iter 152/385 - loss 0.06583247 - samples/sec: 134.15 - lr: 0.000030
2021-07-23 13:45:54,293 epoch 25 - iter 190/385 - loss 0.06866981 - samples/sec: 133.22 - lr: 0.000030
2021-07-23 13:46:03,309 epoch 25 - iter 228/385 - loss 0.06824971 - samples/sec: 134.90 - lr: 0.000030
2021-07-23 13:46:12,327 epoch 25 - iter 266/385 - loss 0.07371282 - samples/sec: 134.87 - lr: 0.000030
2021-07-23 13:46:21,132 epoch 25 - iter 304/385 - loss 0.07317499 - samples/sec: 138.14 - lr: 0.000030
2021-07-23 13:46:30,245 epoch 25 - iter 342/385 - loss 0.07464000 - samples/sec: 133.46 - lr: 0.000030
2021-07-23 13:46:39,292 epoch 25 - iter 380/385 - loss 0.07431258 - samples/sec: 134.44 - lr: 0.000030
2021-07-23 13:46:40,419 ----------------------------------------------------------------------------------------------------
2021-07-23 13:46:40,419 EPOCH 25 done: loss 0.0736 - lr 0.0000300
2021-07-23 13:46:46,589 DEV : loss 0.0531630665063858 - score 0.9895
2021-07-23 13:46:46,658 BAD EPOCHS (no improvement): 2
2021-07-23 13:46:46,658 ----------------------------------------------------------------------------------------------------
2021-07-23 13:46:55,592 epoch 26 - iter 38/385 - loss 0.07617416 - samples/sec: 136.17 - lr: 0.000030
2021-07-23 13:47:04,688 epoch 26 - iter 76/385 - loss 0.07195921 - samples/sec: 133.71 - lr: 0.000030
2021-07-23 13:47:13,564 epoch 26 - iter 114/385 - loss 0.07046051 - samples/sec: 137.04 - lr: 0.000030
2021-07-23 13:47:22,355 epoch 26 - iter 152/385 - loss 0.06811542 - samples/sec: 138.35 - lr: 0.000030
2021-07-23 13:47:31,208 epoch 26 - iter 190/385 - loss 0.06904885 - samples/sec: 137.39 - lr: 0.000030
2021-07-23 13:47:40,108 epoch 26 - iter 228/385 - loss 0.06844992 - samples/sec: 136.65 - lr: 0.000030
2021-07-23 13:47:49,048 epoch 26 - iter 266/385 - loss 0.06941780 - samples/sec: 136.05 - lr: 0.000030
2021-07-23 13:47:57,965 epoch 26 - iter 304/385 - loss 0.06973284 - samples/sec: 136.40 - lr: 0.000030
2021-07-23 13:48:07,072 epoch 26 - iter 342/385 - loss 0.06825052 - samples/sec: 133.56 - lr: 0.000030
2021-07-23 13:48:15,919 epoch 26 - iter 380/385 - loss 0.06831755 - samples/sec: 137.48 - lr: 0.000030
2021-07-23 13:48:17,024 ----------------------------------------------------------------------------------------------------
2021-07-23 13:48:17,024 EPOCH 26 done: loss 0.0689 - lr 0.0000300
2021-07-23 13:48:23,166 DEV : loss 0.05447639897465706 - score 0.9901
2021-07-23 13:48:23,236 BAD EPOCHS (no improvement): 3
2021-07-23 13:48:23,236 ----------------------------------------------------------------------------------------------------
2021-07-23 13:48:31,985 epoch 27 - iter 38/385 - loss 0.06307193 - samples/sec: 139.06 - lr: 0.000030
2021-07-23 13:48:40,816 epoch 27 - iter 76/385 - loss 0.05734051 - samples/sec: 137.72 - lr: 0.000030
2021-07-23 13:48:49,856 epoch 27 - iter 114/385 - loss 0.05967854 - samples/sec: 134.55 - lr: 0.000030
2021-07-23 13:48:58,571 epoch 27 - iter 152/385 - loss 0.05987357 - samples/sec: 139.56 - lr: 0.000030
2021-07-23 13:49:07,687 epoch 27 - iter 190/385 - loss 0.06010551 - samples/sec: 133.42 - lr: 0.000030
2021-07-23 13:49:16,849 epoch 27 - iter 228/385 - loss 0.06282695 - samples/sec: 132.75 - lr: 0.000030
2021-07-23 13:49:25,864 epoch 27 - iter 266/385 - loss 0.06324726 - samples/sec: 134.92 - lr: 0.000030
2021-07-23 13:49:34,697 epoch 27 - iter 304/385 - loss 0.06469249 - samples/sec: 137.70 - lr: 0.000030
2021-07-23 13:49:43,620 epoch 27 - iter 342/385 - loss 0.06491145 - samples/sec: 136.31 - lr: 0.000030
2021-07-23 13:49:52,843 epoch 27 - iter 380/385 - loss 0.06679440 - samples/sec: 131.87 - lr: 0.000030
2021-07-23 13:49:53,939 ----------------------------------------------------------------------------------------------------
2021-07-23 13:49:53,939 EPOCH 27 done: loss 0.0665 - lr 0.0000300
2021-07-23 13:50:00,133 DEV : loss 0.05426022782921791 - score 0.9895
Epoch    27: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 13:50:00,203 BAD EPOCHS (no improvement): 4
2021-07-23 13:50:00,203 ----------------------------------------------------------------------------------------------------
2021-07-23 13:50:09,373 epoch 28 - iter 38/385 - loss 0.07280893 - samples/sec: 132.67 - lr: 0.000015
2021-07-23 13:50:18,249 epoch 28 - iter 76/385 - loss 0.06558543 - samples/sec: 137.03 - lr: 0.000015
2021-07-23 13:50:27,329 epoch 28 - iter 114/385 - loss 0.06844279 - samples/sec: 133.96 - lr: 0.000015
2021-07-23 13:50:36,371 epoch 28 - iter 152/385 - loss 0.07088842 - samples/sec: 134.51 - lr: 0.000015
2021-07-23 13:50:45,315 epoch 28 - iter 190/385 - loss 0.07034380 - samples/sec: 135.98 - lr: 0.000015
2021-07-23 13:50:54,424 epoch 28 - iter 228/385 - loss 0.06862974 - samples/sec: 133.53 - lr: 0.000015
2021-07-23 13:51:03,257 epoch 28 - iter 266/385 - loss 0.06529461 - samples/sec: 137.70 - lr: 0.000015
2021-07-23 13:51:12,207 epoch 28 - iter 304/385 - loss 0.06739033 - samples/sec: 135.90 - lr: 0.000015
2021-07-23 13:51:21,110 epoch 28 - iter 342/385 - loss 0.06715680 - samples/sec: 136.62 - lr: 0.000015
2021-07-23 13:51:30,053 epoch 28 - iter 380/385 - loss 0.06682668 - samples/sec: 135.99 - lr: 0.000015
2021-07-23 13:51:31,160 ----------------------------------------------------------------------------------------------------
2021-07-23 13:51:31,160 EPOCH 28 done: loss 0.0670 - lr 0.0000150
2021-07-23 13:51:37,856 DEV : loss 0.053021933883428574 - score 0.9892
2021-07-23 13:51:37,927 BAD EPOCHS (no improvement): 1
2021-07-23 13:51:37,927 ----------------------------------------------------------------------------------------------------
2021-07-23 13:51:46,836 epoch 29 - iter 38/385 - loss 0.07081696 - samples/sec: 136.54 - lr: 0.000015
2021-07-23 13:51:55,916 epoch 29 - iter 76/385 - loss 0.07107428 - samples/sec: 133.95 - lr: 0.000015
2021-07-23 13:52:04,919 epoch 29 - iter 114/385 - loss 0.06842829 - samples/sec: 135.11 - lr: 0.000015
2021-07-23 13:52:14,085 epoch 29 - iter 152/385 - loss 0.06865885 - samples/sec: 132.69 - lr: 0.000015
2021-07-23 13:52:23,048 epoch 29 - iter 190/385 - loss 0.06898945 - samples/sec: 135.69 - lr: 0.000015
2021-07-23 13:52:32,185 epoch 29 - iter 228/385 - loss 0.06955401 - samples/sec: 133.12 - lr: 0.000015
2021-07-23 13:52:41,172 epoch 29 - iter 266/385 - loss 0.06804874 - samples/sec: 135.34 - lr: 0.000015
2021-07-23 13:52:50,013 epoch 29 - iter 304/385 - loss 0.06848904 - samples/sec: 137.57 - lr: 0.000015
2021-07-23 13:52:58,896 epoch 29 - iter 342/385 - loss 0.06808014 - samples/sec: 136.92 - lr: 0.000015
2021-07-23 13:53:07,859 epoch 29 - iter 380/385 - loss 0.06712286 - samples/sec: 135.70 - lr: 0.000015
2021-07-23 13:53:08,971 ----------------------------------------------------------------------------------------------------
2021-07-23 13:53:08,971 EPOCH 29 done: loss 0.0676 - lr 0.0000150
2021-07-23 13:53:15,158 DEV : loss 0.05235300213098526 - score 0.9892
2021-07-23 13:53:15,228 BAD EPOCHS (no improvement): 2
2021-07-23 13:53:15,228 ----------------------------------------------------------------------------------------------------
2021-07-23 13:53:24,147 epoch 30 - iter 38/385 - loss 0.04988793 - samples/sec: 136.39 - lr: 0.000015
2021-07-23 13:53:33,209 epoch 30 - iter 76/385 - loss 0.05807498 - samples/sec: 134.22 - lr: 0.000015
2021-07-23 13:53:42,179 epoch 30 - iter 114/385 - loss 0.06168034 - samples/sec: 135.60 - lr: 0.000015
2021-07-23 13:53:50,919 epoch 30 - iter 152/385 - loss 0.05965277 - samples/sec: 139.16 - lr: 0.000015
2021-07-23 13:53:59,871 epoch 30 - iter 190/385 - loss 0.06034019 - samples/sec: 135.86 - lr: 0.000015
2021-07-23 13:54:08,792 epoch 30 - iter 228/385 - loss 0.06117639 - samples/sec: 136.34 - lr: 0.000015
2021-07-23 13:54:18,088 epoch 30 - iter 266/385 - loss 0.06084452 - samples/sec: 130.83 - lr: 0.000015
2021-07-23 13:54:27,095 epoch 30 - iter 304/385 - loss 0.06228476 - samples/sec: 135.03 - lr: 0.000015
2021-07-23 13:54:36,127 epoch 30 - iter 342/385 - loss 0.06137919 - samples/sec: 134.66 - lr: 0.000015
2021-07-23 13:54:45,165 epoch 30 - iter 380/385 - loss 0.06061655 - samples/sec: 134.57 - lr: 0.000015
2021-07-23 13:54:46,264 ----------------------------------------------------------------------------------------------------
2021-07-23 13:54:46,265 EPOCH 30 done: loss 0.0610 - lr 0.0000150
2021-07-23 13:54:52,452 DEV : loss 0.05268528684973717 - score 0.9901
2021-07-23 13:54:52,522 BAD EPOCHS (no improvement): 3
2021-07-23 13:54:52,522 ----------------------------------------------------------------------------------------------------
2021-07-23 13:55:01,562 epoch 31 - iter 38/385 - loss 0.06977767 - samples/sec: 134.57 - lr: 0.000015
2021-07-23 13:55:10,500 epoch 31 - iter 76/385 - loss 0.05886989 - samples/sec: 136.09 - lr: 0.000015
2021-07-23 13:55:19,451 epoch 31 - iter 114/385 - loss 0.06188438 - samples/sec: 135.87 - lr: 0.000015
2021-07-23 13:55:28,415 epoch 31 - iter 152/385 - loss 0.06070079 - samples/sec: 135.69 - lr: 0.000015
2021-07-23 13:55:37,444 epoch 31 - iter 190/385 - loss 0.06625051 - samples/sec: 134.71 - lr: 0.000015
2021-07-23 13:55:46,491 epoch 31 - iter 228/385 - loss 0.06384089 - samples/sec: 134.44 - lr: 0.000015
2021-07-23 13:55:55,623 epoch 31 - iter 266/385 - loss 0.06227336 - samples/sec: 133.18 - lr: 0.000015
2021-07-23 13:56:04,680 epoch 31 - iter 304/385 - loss 0.06122336 - samples/sec: 134.29 - lr: 0.000015
2021-07-23 13:56:13,955 epoch 31 - iter 342/385 - loss 0.06201769 - samples/sec: 131.14 - lr: 0.000015
2021-07-23 13:56:22,811 epoch 31 - iter 380/385 - loss 0.06165263 - samples/sec: 137.34 - lr: 0.000015
2021-07-23 13:56:23,939 ----------------------------------------------------------------------------------------------------
2021-07-23 13:56:23,940 EPOCH 31 done: loss 0.0615 - lr 0.0000150
2021-07-23 13:56:30,087 DEV : loss 0.05256267637014389 - score 0.9901
Epoch    31: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 13:56:30,156 BAD EPOCHS (no improvement): 4
2021-07-23 13:56:30,156 ----------------------------------------------------------------------------------------------------
2021-07-23 13:56:39,137 epoch 32 - iter 38/385 - loss 0.06140609 - samples/sec: 135.47 - lr: 0.000008
2021-07-23 13:56:48,131 epoch 32 - iter 76/385 - loss 0.06294294 - samples/sec: 135.22 - lr: 0.000008
2021-07-23 13:56:57,153 epoch 32 - iter 114/385 - loss 0.05963732 - samples/sec: 134.81 - lr: 0.000008
2021-07-23 13:57:06,415 epoch 32 - iter 152/385 - loss 0.05999220 - samples/sec: 131.32 - lr: 0.000008
2021-07-23 13:57:15,367 epoch 32 - iter 190/385 - loss 0.06150949 - samples/sec: 135.85 - lr: 0.000008
2021-07-23 13:57:24,437 epoch 32 - iter 228/385 - loss 0.05800678 - samples/sec: 134.10 - lr: 0.000008
2021-07-23 13:57:33,701 epoch 32 - iter 266/385 - loss 0.05813493 - samples/sec: 131.29 - lr: 0.000008
2021-07-23 13:57:42,456 epoch 32 - iter 304/385 - loss 0.05907399 - samples/sec: 138.93 - lr: 0.000008
2021-07-23 13:57:51,369 epoch 32 - iter 342/385 - loss 0.06002435 - samples/sec: 136.46 - lr: 0.000008
2021-07-23 13:58:00,412 epoch 32 - iter 380/385 - loss 0.06002431 - samples/sec: 134.50 - lr: 0.000008
2021-07-23 13:58:01,475 ----------------------------------------------------------------------------------------------------
2021-07-23 13:58:01,475 EPOCH 32 done: loss 0.0604 - lr 0.0000075
2021-07-23 13:58:07,628 DEV : loss 0.0532466284930706 - score 0.9901
2021-07-23 13:58:07,699 BAD EPOCHS (no improvement): 1
2021-07-23 13:58:07,699 ----------------------------------------------------------------------------------------------------
2021-07-23 13:58:17,177 epoch 33 - iter 38/385 - loss 0.06826151 - samples/sec: 128.35 - lr: 0.000008
2021-07-23 13:58:26,159 epoch 33 - iter 76/385 - loss 0.06282663 - samples/sec: 135.41 - lr: 0.000008
2021-07-23 13:58:34,992 epoch 33 - iter 114/385 - loss 0.06142680 - samples/sec: 137.70 - lr: 0.000008
2021-07-23 13:58:44,025 epoch 33 - iter 152/385 - loss 0.06346749 - samples/sec: 134.66 - lr: 0.000008
2021-07-23 13:58:53,104 epoch 33 - iter 190/385 - loss 0.06392593 - samples/sec: 133.96 - lr: 0.000008
2021-07-23 13:59:02,176 epoch 33 - iter 228/385 - loss 0.06224339 - samples/sec: 134.08 - lr: 0.000008
2021-07-23 13:59:11,128 epoch 33 - iter 266/385 - loss 0.06091621 - samples/sec: 135.86 - lr: 0.000008
2021-07-23 13:59:20,128 epoch 33 - iter 304/385 - loss 0.06117879 - samples/sec: 135.15 - lr: 0.000008
2021-07-23 13:59:29,229 epoch 33 - iter 342/385 - loss 0.06104459 - samples/sec: 133.63 - lr: 0.000008
2021-07-23 13:59:38,384 epoch 33 - iter 380/385 - loss 0.06175602 - samples/sec: 132.86 - lr: 0.000008
2021-07-23 13:59:39,486 ----------------------------------------------------------------------------------------------------
2021-07-23 13:59:39,486 EPOCH 33 done: loss 0.0616 - lr 0.0000075
2021-07-23 13:59:45,627 DEV : loss 0.05320024862885475 - score 0.9898
2021-07-23 13:59:45,697 BAD EPOCHS (no improvement): 2
2021-07-23 13:59:45,697 ----------------------------------------------------------------------------------------------------
2021-07-23 13:59:54,792 epoch 34 - iter 38/385 - loss 0.05766108 - samples/sec: 133.75 - lr: 0.000008
2021-07-23 14:00:03,780 epoch 34 - iter 76/385 - loss 0.06267501 - samples/sec: 135.33 - lr: 0.000008
2021-07-23 14:00:12,836 epoch 34 - iter 114/385 - loss 0.06165428 - samples/sec: 134.30 - lr: 0.000008
2021-07-23 14:00:21,936 epoch 34 - iter 152/385 - loss 0.06068179 - samples/sec: 133.66 - lr: 0.000008
2021-07-23 14:00:30,893 epoch 34 - iter 190/385 - loss 0.06092415 - samples/sec: 135.79 - lr: 0.000008
2021-07-23 14:00:39,864 epoch 34 - iter 228/385 - loss 0.05993207 - samples/sec: 135.57 - lr: 0.000008
2021-07-23 14:00:49,116 epoch 34 - iter 266/385 - loss 0.05907494 - samples/sec: 131.45 - lr: 0.000008
2021-07-23 14:00:58,449 epoch 34 - iter 304/385 - loss 0.05987831 - samples/sec: 130.33 - lr: 0.000008
2021-07-23 14:01:07,245 epoch 34 - iter 342/385 - loss 0.05958114 - samples/sec: 138.27 - lr: 0.000008
2021-07-23 14:01:16,194 epoch 34 - iter 380/385 - loss 0.05938817 - samples/sec: 135.91 - lr: 0.000008
2021-07-23 14:01:17,273 ----------------------------------------------------------------------------------------------------
2021-07-23 14:01:17,273 EPOCH 34 done: loss 0.0591 - lr 0.0000075
2021-07-23 14:01:23,434 DEV : loss 0.05470593273639679 - score 0.9889
2021-07-23 14:01:23,504 BAD EPOCHS (no improvement): 3
2021-07-23 14:01:23,504 ----------------------------------------------------------------------------------------------------
2021-07-23 14:01:32,555 epoch 35 - iter 38/385 - loss 0.08131069 - samples/sec: 134.40 - lr: 0.000008
2021-07-23 14:01:41,733 epoch 35 - iter 76/385 - loss 0.07620651 - samples/sec: 132.53 - lr: 0.000008
2021-07-23 14:01:50,783 epoch 35 - iter 114/385 - loss 0.06754611 - samples/sec: 134.39 - lr: 0.000008
2021-07-23 14:01:59,707 epoch 35 - iter 152/385 - loss 0.06981741 - samples/sec: 136.29 - lr: 0.000008
2021-07-23 14:02:08,741 epoch 35 - iter 190/385 - loss 0.06799380 - samples/sec: 134.63 - lr: 0.000008
2021-07-23 14:02:17,920 epoch 35 - iter 228/385 - loss 0.06342501 - samples/sec: 132.51 - lr: 0.000008
2021-07-23 14:02:26,796 epoch 35 - iter 266/385 - loss 0.06199194 - samples/sec: 137.03 - lr: 0.000008
2021-07-23 14:02:35,836 epoch 35 - iter 304/385 - loss 0.06095105 - samples/sec: 134.53 - lr: 0.000008
2021-07-23 14:02:44,776 epoch 35 - iter 342/385 - loss 0.06087964 - samples/sec: 136.06 - lr: 0.000008
2021-07-23 14:02:53,669 epoch 35 - iter 380/385 - loss 0.06065427 - samples/sec: 136.77 - lr: 0.000008
2021-07-23 14:02:54,791 ----------------------------------------------------------------------------------------------------
2021-07-23 14:02:54,791 EPOCH 35 done: loss 0.0603 - lr 0.0000075
2021-07-23 14:03:00,944 DEV : loss 0.054221268743276596 - score 0.9895
Epoch    35: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 14:03:01,013 BAD EPOCHS (no improvement): 4
2021-07-23 14:03:01,013 ----------------------------------------------------------------------------------------------------
2021-07-23 14:03:10,168 epoch 36 - iter 38/385 - loss 0.05684796 - samples/sec: 132.88 - lr: 0.000004
2021-07-23 14:03:19,220 epoch 36 - iter 76/385 - loss 0.05817496 - samples/sec: 134.37 - lr: 0.000004
2021-07-23 14:03:28,372 epoch 36 - iter 114/385 - loss 0.05675553 - samples/sec: 132.90 - lr: 0.000004
2021-07-23 14:03:37,435 epoch 36 - iter 152/385 - loss 0.05655090 - samples/sec: 134.21 - lr: 0.000004
2021-07-23 14:03:46,487 epoch 36 - iter 190/385 - loss 0.05497403 - samples/sec: 134.35 - lr: 0.000004
2021-07-23 14:03:55,396 epoch 36 - iter 228/385 - loss 0.05933570 - samples/sec: 136.54 - lr: 0.000004
2021-07-23 14:04:04,407 epoch 36 - iter 266/385 - loss 0.05843525 - samples/sec: 134.97 - lr: 0.000004
2021-07-23 14:04:13,228 epoch 36 - iter 304/385 - loss 0.05686166 - samples/sec: 137.89 - lr: 0.000004
2021-07-23 14:04:22,208 epoch 36 - iter 342/385 - loss 0.05692565 - samples/sec: 135.45 - lr: 0.000004
2021-07-23 14:04:31,268 epoch 36 - iter 380/385 - loss 0.05827185 - samples/sec: 134.25 - lr: 0.000004
2021-07-23 14:04:32,315 ----------------------------------------------------------------------------------------------------
2021-07-23 14:04:32,315 EPOCH 36 done: loss 0.0584 - lr 0.0000038
2021-07-23 14:04:38,446 DEV : loss 0.05426428094506264 - score 0.9892
2021-07-23 14:04:38,516 BAD EPOCHS (no improvement): 1
2021-07-23 14:04:38,516 ----------------------------------------------------------------------------------------------------
2021-07-23 14:04:47,862 epoch 37 - iter 38/385 - loss 0.05008112 - samples/sec: 130.16 - lr: 0.000004
2021-07-23 14:04:57,224 epoch 37 - iter 76/385 - loss 0.05663221 - samples/sec: 129.91 - lr: 0.000004
2021-07-23 14:05:06,296 epoch 37 - iter 114/385 - loss 0.05544421 - samples/sec: 134.07 - lr: 0.000004
2021-07-23 14:05:15,401 epoch 37 - iter 152/385 - loss 0.05541043 - samples/sec: 133.59 - lr: 0.000004
2021-07-23 14:05:24,345 epoch 37 - iter 190/385 - loss 0.05611594 - samples/sec: 136.00 - lr: 0.000004
2021-07-23 14:05:33,220 epoch 37 - iter 228/385 - loss 0.05562687 - samples/sec: 137.03 - lr: 0.000004
2021-07-23 14:05:42,339 epoch 37 - iter 266/385 - loss 0.05560497 - samples/sec: 133.39 - lr: 0.000004
2021-07-23 14:05:51,399 epoch 37 - iter 304/385 - loss 0.05635385 - samples/sec: 134.24 - lr: 0.000004
2021-07-23 14:06:00,205 epoch 37 - iter 342/385 - loss 0.05608553 - samples/sec: 138.12 - lr: 0.000004
2021-07-23 14:06:09,137 epoch 37 - iter 380/385 - loss 0.05657818 - samples/sec: 136.18 - lr: 0.000004
2021-07-23 14:06:10,184 ----------------------------------------------------------------------------------------------------
2021-07-23 14:06:10,184 EPOCH 37 done: loss 0.0566 - lr 0.0000038
2021-07-23 14:06:16,366 DEV : loss 0.053243909031152725 - score 0.9898
2021-07-23 14:06:16,436 BAD EPOCHS (no improvement): 2
2021-07-23 14:06:16,436 ----------------------------------------------------------------------------------------------------
2021-07-23 14:06:25,646 epoch 38 - iter 38/385 - loss 0.05404474 - samples/sec: 132.09 - lr: 0.000004
2021-07-23 14:06:34,706 epoch 38 - iter 76/385 - loss 0.05678191 - samples/sec: 134.24 - lr: 0.000004
2021-07-23 14:06:43,724 epoch 38 - iter 114/385 - loss 0.05723650 - samples/sec: 134.88 - lr: 0.000004
2021-07-23 14:06:52,652 epoch 38 - iter 152/385 - loss 0.05662770 - samples/sec: 136.23 - lr: 0.000004
2021-07-23 14:07:01,568 epoch 38 - iter 190/385 - loss 0.05712714 - samples/sec: 136.41 - lr: 0.000004
2021-07-23 14:07:10,488 epoch 38 - iter 228/385 - loss 0.05799881 - samples/sec: 136.36 - lr: 0.000004
2021-07-23 14:07:19,535 epoch 38 - iter 266/385 - loss 0.05560941 - samples/sec: 134.43 - lr: 0.000004
2021-07-23 14:07:28,357 epoch 38 - iter 304/385 - loss 0.05311060 - samples/sec: 137.88 - lr: 0.000004
2021-07-23 14:07:37,468 epoch 38 - iter 342/385 - loss 0.05374637 - samples/sec: 133.49 - lr: 0.000004
2021-07-23 14:07:46,466 epoch 38 - iter 380/385 - loss 0.05334223 - samples/sec: 135.17 - lr: 0.000004
2021-07-23 14:07:47,568 ----------------------------------------------------------------------------------------------------
2021-07-23 14:07:47,569 EPOCH 38 done: loss 0.0532 - lr 0.0000038
2021-07-23 14:07:53,713 DEV : loss 0.05382406339049339 - score 0.9898
2021-07-23 14:07:53,783 BAD EPOCHS (no improvement): 3
2021-07-23 14:07:53,783 ----------------------------------------------------------------------------------------------------
2021-07-23 14:08:02,741 epoch 39 - iter 38/385 - loss 0.05613225 - samples/sec: 135.80 - lr: 0.000004
2021-07-23 14:08:11,703 epoch 39 - iter 76/385 - loss 0.05419839 - samples/sec: 135.71 - lr: 0.000004
2021-07-23 14:08:20,768 epoch 39 - iter 114/385 - loss 0.05373631 - samples/sec: 134.17 - lr: 0.000004
2021-07-23 14:08:29,900 epoch 39 - iter 152/385 - loss 0.05416577 - samples/sec: 133.19 - lr: 0.000004
2021-07-23 14:08:38,936 epoch 39 - iter 190/385 - loss 0.05726369 - samples/sec: 134.60 - lr: 0.000004
2021-07-23 14:08:48,041 epoch 39 - iter 228/385 - loss 0.05560721 - samples/sec: 133.59 - lr: 0.000004
2021-07-23 14:08:57,151 epoch 39 - iter 266/385 - loss 0.05627696 - samples/sec: 133.50 - lr: 0.000004
2021-07-23 14:09:06,352 epoch 39 - iter 304/385 - loss 0.05572210 - samples/sec: 132.19 - lr: 0.000004
2021-07-23 14:09:15,140 epoch 39 - iter 342/385 - loss 0.05674228 - samples/sec: 138.40 - lr: 0.000004
2021-07-23 14:09:23,933 epoch 39 - iter 380/385 - loss 0.05859480 - samples/sec: 138.33 - lr: 0.000004
2021-07-23 14:09:24,970 ----------------------------------------------------------------------------------------------------
2021-07-23 14:09:24,970 EPOCH 39 done: loss 0.0587 - lr 0.0000038
2021-07-23 14:09:31,105 DEV : loss 0.05394221842288971 - score 0.989
Epoch    39: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 14:09:31,174 BAD EPOCHS (no improvement): 4
2021-07-23 14:09:31,175 ----------------------------------------------------------------------------------------------------
2021-07-23 14:09:31,175 ----------------------------------------------------------------------------------------------------
2021-07-23 14:09:31,175 learning rate too small - quitting training!
2021-07-23 14:09:31,175 ----------------------------------------------------------------------------------------------------
2021-07-23 14:09:31,804 ----------------------------------------------------------------------------------------------------
2021-07-23 14:09:31,804 Testing using best model ...
2021-07-23 14:09:31,805 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.rst.gum/best-model.pt
2021-07-23 14:10:32,222 0.9816	0.9828	0.9822
2021-07-23 14:10:32,222 
Results:
- F1-score (micro) 0.9822
- F1-score (macro) 0.9843

By class:
SENT       tp: 1850 - fp: 62 - fn: 58 - precision: 0.9676 - recall: 0.9696 - f1-score: 0.9686
X          tp: 1459 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 14:10:32,222 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/nld.rst.nldt/
2021-07-23 14:10:32,282 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/nld.rst.nldt
2021-07-23 14:10:32,285 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/nld.rst.nldt/sent_train.txt
2021-07-23 14:10:32,287 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/nld.rst.nldt/sent_dev.txt
2021-07-23 14:10:32,289 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/nld.rst.nldt/sent_test.txt
Corpus: 2047 train + 599 dev + 750 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 14:10:34,651 ----------------------------------------------------------------------------------------------------
2021-07-23 14:10:34,653 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30073, 768, padding_idx=3)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 14:10:34,653 ----------------------------------------------------------------------------------------------------
2021-07-23 14:10:34,653 Corpus: "Corpus: 2047 train + 599 dev + 750 test sentences"
2021-07-23 14:10:34,653 ----------------------------------------------------------------------------------------------------
2021-07-23 14:10:34,653 Parameters:
2021-07-23 14:10:34,653  - learning_rate: "3e-05"
2021-07-23 14:10:34,653  - mini_batch_size: "32"
2021-07-23 14:10:34,653  - patience: "3"
2021-07-23 14:10:34,653  - anneal_factor: "0.5"
2021-07-23 14:10:34,653  - max_epochs: "40"
2021-07-23 14:10:34,653  - shuffle: "True"
2021-07-23 14:10:34,653  - train_with_dev: "False"
2021-07-23 14:10:34,653  - batch_growth_annealing: "False"
2021-07-23 14:10:34,653 ----------------------------------------------------------------------------------------------------
2021-07-23 14:10:34,653 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/nld.rst.nldt"
2021-07-23 14:10:34,653 ----------------------------------------------------------------------------------------------------
2021-07-23 14:10:34,653 Device: cuda:0
2021-07-23 14:10:34,653 ----------------------------------------------------------------------------------------------------
2021-07-23 14:10:34,653 Embeddings storage mode: cpu
2021-07-23 14:10:34,656 ----------------------------------------------------------------------------------------------------
2021-07-23 14:10:38,024 epoch 1 - iter 6/64 - loss 13.58997742 - samples/sec: 57.03 - lr: 0.000030
2021-07-23 14:10:41,361 epoch 1 - iter 12/64 - loss 12.68854276 - samples/sec: 57.54 - lr: 0.000030
2021-07-23 14:10:44,772 epoch 1 - iter 18/64 - loss 12.47267066 - samples/sec: 56.29 - lr: 0.000030
2021-07-23 14:10:48,146 epoch 1 - iter 24/64 - loss 11.95399809 - samples/sec: 56.92 - lr: 0.000030
2021-07-23 14:10:51,496 epoch 1 - iter 30/64 - loss 11.34435067 - samples/sec: 57.32 - lr: 0.000030
2021-07-23 14:10:54,828 epoch 1 - iter 36/64 - loss 10.79742326 - samples/sec: 57.64 - lr: 0.000030
2021-07-23 14:10:58,196 epoch 1 - iter 42/64 - loss 10.37206685 - samples/sec: 57.00 - lr: 0.000030
2021-07-23 14:11:01,617 epoch 1 - iter 48/64 - loss 10.05505764 - samples/sec: 56.14 - lr: 0.000030
2021-07-23 14:11:05,002 epoch 1 - iter 54/64 - loss 9.72181425 - samples/sec: 56.72 - lr: 0.000030
2021-07-23 14:11:08,437 epoch 1 - iter 60/64 - loss 9.38566144 - samples/sec: 55.91 - lr: 0.000030
2021-07-23 14:11:10,735 ----------------------------------------------------------------------------------------------------
2021-07-23 14:11:10,735 EPOCH 1 done: loss 9.1836 - lr 0.0000300
2021-07-23 14:11:18,339 DEV : loss 1.9775617122650146 - score 0.5828
2021-07-23 14:11:18,353 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:11:18,927 ----------------------------------------------------------------------------------------------------
2021-07-23 14:11:20,265 epoch 2 - iter 6/64 - loss 4.70164927 - samples/sec: 143.68 - lr: 0.000030
2021-07-23 14:11:21,684 epoch 2 - iter 12/64 - loss 4.68170124 - samples/sec: 135.39 - lr: 0.000030
2021-07-23 14:11:23,078 epoch 2 - iter 18/64 - loss 4.23399455 - samples/sec: 137.77 - lr: 0.000030
2021-07-23 14:11:24,476 epoch 2 - iter 24/64 - loss 3.92203380 - samples/sec: 137.32 - lr: 0.000030
2021-07-23 14:11:25,837 epoch 2 - iter 30/64 - loss 3.61872284 - samples/sec: 141.15 - lr: 0.000030
2021-07-23 14:11:27,223 epoch 2 - iter 36/64 - loss 3.32279990 - samples/sec: 138.54 - lr: 0.000030
2021-07-23 14:11:28,559 epoch 2 - iter 42/64 - loss 3.10104597 - samples/sec: 143.85 - lr: 0.000030
2021-07-23 14:11:29,828 epoch 2 - iter 48/64 - loss 2.90331236 - samples/sec: 151.29 - lr: 0.000030
2021-07-23 14:11:31,135 epoch 2 - iter 54/64 - loss 2.72322880 - samples/sec: 146.98 - lr: 0.000030
2021-07-23 14:11:32,479 epoch 2 - iter 60/64 - loss 2.56707344 - samples/sec: 142.87 - lr: 0.000030
2021-07-23 14:11:33,372 ----------------------------------------------------------------------------------------------------
2021-07-23 14:11:33,372 EPOCH 2 done: loss 2.4755 - lr 0.0000300
2021-07-23 14:11:34,731 DEV : loss 0.807998538017273 - score 0.6022
2021-07-23 14:11:34,746 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:11:37,256 ----------------------------------------------------------------------------------------------------
2021-07-23 14:11:38,664 epoch 3 - iter 6/64 - loss 0.96136202 - samples/sec: 136.60 - lr: 0.000030
2021-07-23 14:11:40,041 epoch 3 - iter 12/64 - loss 0.96789698 - samples/sec: 139.54 - lr: 0.000030
2021-07-23 14:11:41,417 epoch 3 - iter 18/64 - loss 0.93116852 - samples/sec: 139.60 - lr: 0.000030
2021-07-23 14:11:42,684 epoch 3 - iter 24/64 - loss 0.89370072 - samples/sec: 151.51 - lr: 0.000030
2021-07-23 14:11:44,051 epoch 3 - iter 30/64 - loss 0.87564509 - samples/sec: 140.52 - lr: 0.000030
2021-07-23 14:11:45,343 epoch 3 - iter 36/64 - loss 0.84619478 - samples/sec: 148.63 - lr: 0.000030
2021-07-23 14:11:46,733 epoch 3 - iter 42/64 - loss 0.82821208 - samples/sec: 138.24 - lr: 0.000030
2021-07-23 14:11:48,049 epoch 3 - iter 48/64 - loss 0.80676535 - samples/sec: 145.96 - lr: 0.000030
2021-07-23 14:11:49,456 epoch 3 - iter 54/64 - loss 0.79391564 - samples/sec: 136.48 - lr: 0.000030
2021-07-23 14:11:50,849 epoch 3 - iter 60/64 - loss 0.78022480 - samples/sec: 137.87 - lr: 0.000030
2021-07-23 14:11:51,734 ----------------------------------------------------------------------------------------------------
2021-07-23 14:11:51,734 EPOCH 3 done: loss 0.7702 - lr 0.0000300
2021-07-23 14:11:53,095 DEV : loss 0.5026167035102844 - score 0.8987
2021-07-23 14:11:53,109 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:11:55,335 ----------------------------------------------------------------------------------------------------
2021-07-23 14:11:56,728 epoch 4 - iter 6/64 - loss 0.58826460 - samples/sec: 138.07 - lr: 0.000030
2021-07-23 14:11:58,051 epoch 4 - iter 12/64 - loss 0.57975712 - samples/sec: 145.20 - lr: 0.000030
2021-07-23 14:11:59,391 epoch 4 - iter 18/64 - loss 0.59097044 - samples/sec: 143.35 - lr: 0.000030
2021-07-23 14:12:00,682 epoch 4 - iter 24/64 - loss 0.58229439 - samples/sec: 148.72 - lr: 0.000030
2021-07-23 14:12:02,035 epoch 4 - iter 30/64 - loss 0.58213691 - samples/sec: 141.98 - lr: 0.000030
2021-07-23 14:12:03,384 epoch 4 - iter 36/64 - loss 0.57786824 - samples/sec: 142.36 - lr: 0.000030
2021-07-23 14:12:04,737 epoch 4 - iter 42/64 - loss 0.56883504 - samples/sec: 142.04 - lr: 0.000030
2021-07-23 14:12:06,101 epoch 4 - iter 48/64 - loss 0.55941777 - samples/sec: 140.82 - lr: 0.000030
2021-07-23 14:12:07,467 epoch 4 - iter 54/64 - loss 0.55394781 - samples/sec: 140.56 - lr: 0.000030
2021-07-23 14:12:08,885 epoch 4 - iter 60/64 - loss 0.54911386 - samples/sec: 135.47 - lr: 0.000030
2021-07-23 14:12:09,768 ----------------------------------------------------------------------------------------------------
2021-07-23 14:12:09,768 EPOCH 4 done: loss 0.5447 - lr 0.0000300
2021-07-23 14:12:11,140 DEV : loss 0.35971030592918396 - score 0.9546
2021-07-23 14:12:11,154 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:12:13,473 ----------------------------------------------------------------------------------------------------
2021-07-23 14:12:14,795 epoch 5 - iter 6/64 - loss 0.41722419 - samples/sec: 145.42 - lr: 0.000030
2021-07-23 14:12:16,224 epoch 5 - iter 12/64 - loss 0.43585617 - samples/sec: 134.48 - lr: 0.000030
2021-07-23 14:12:17,608 epoch 5 - iter 18/64 - loss 0.41843201 - samples/sec: 138.79 - lr: 0.000030
2021-07-23 14:12:18,935 epoch 5 - iter 24/64 - loss 0.41055933 - samples/sec: 144.65 - lr: 0.000030
2021-07-23 14:12:20,299 epoch 5 - iter 30/64 - loss 0.41307183 - samples/sec: 140.86 - lr: 0.000030
2021-07-23 14:12:21,664 epoch 5 - iter 36/64 - loss 0.41129915 - samples/sec: 140.75 - lr: 0.000030
2021-07-23 14:12:23,011 epoch 5 - iter 42/64 - loss 0.41306141 - samples/sec: 142.53 - lr: 0.000030
2021-07-23 14:12:24,288 epoch 5 - iter 48/64 - loss 0.41301575 - samples/sec: 150.48 - lr: 0.000030
2021-07-23 14:12:25,580 epoch 5 - iter 54/64 - loss 0.40802924 - samples/sec: 148.63 - lr: 0.000030
2021-07-23 14:12:26,971 epoch 5 - iter 60/64 - loss 0.40723837 - samples/sec: 138.06 - lr: 0.000030
2021-07-23 14:12:27,877 ----------------------------------------------------------------------------------------------------
2021-07-23 14:12:27,878 EPOCH 5 done: loss 0.4060 - lr 0.0000300
2021-07-23 14:12:29,246 DEV : loss 0.2606683075428009 - score 0.9594
2021-07-23 14:12:29,261 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:12:31,664 ----------------------------------------------------------------------------------------------------
2021-07-23 14:12:32,979 epoch 6 - iter 6/64 - loss 0.38232238 - samples/sec: 146.28 - lr: 0.000030
2021-07-23 14:12:34,364 epoch 6 - iter 12/64 - loss 0.37613285 - samples/sec: 138.68 - lr: 0.000030
2021-07-23 14:12:35,644 epoch 6 - iter 18/64 - loss 0.36205802 - samples/sec: 150.02 - lr: 0.000030
2021-07-23 14:12:36,966 epoch 6 - iter 24/64 - loss 0.36279273 - samples/sec: 145.26 - lr: 0.000030
2021-07-23 14:12:38,327 epoch 6 - iter 30/64 - loss 0.34743153 - samples/sec: 141.15 - lr: 0.000030
2021-07-23 14:12:39,663 epoch 6 - iter 36/64 - loss 0.33875479 - samples/sec: 143.78 - lr: 0.000030
2021-07-23 14:12:41,073 epoch 6 - iter 42/64 - loss 0.33838608 - samples/sec: 136.26 - lr: 0.000030
2021-07-23 14:12:42,405 epoch 6 - iter 48/64 - loss 0.33633886 - samples/sec: 144.15 - lr: 0.000030
2021-07-23 14:12:43,729 epoch 6 - iter 54/64 - loss 0.32982054 - samples/sec: 145.05 - lr: 0.000030
2021-07-23 14:12:45,181 epoch 6 - iter 60/64 - loss 0.32588594 - samples/sec: 132.34 - lr: 0.000030
2021-07-23 14:12:46,065 ----------------------------------------------------------------------------------------------------
2021-07-23 14:12:46,065 EPOCH 6 done: loss 0.3239 - lr 0.0000300
2021-07-23 14:12:47,433 DEV : loss 0.19811831414699554 - score 0.9675
2021-07-23 14:12:47,451 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:12:49,982 ----------------------------------------------------------------------------------------------------
2021-07-23 14:12:51,379 epoch 7 - iter 6/64 - loss 0.28818530 - samples/sec: 137.60 - lr: 0.000030
2021-07-23 14:12:52,696 epoch 7 - iter 12/64 - loss 0.28498349 - samples/sec: 145.92 - lr: 0.000030
2021-07-23 14:12:54,041 epoch 7 - iter 18/64 - loss 0.27828393 - samples/sec: 142.76 - lr: 0.000030
2021-07-23 14:12:55,484 epoch 7 - iter 24/64 - loss 0.27752778 - samples/sec: 133.07 - lr: 0.000030
2021-07-23 14:12:56,828 epoch 7 - iter 30/64 - loss 0.27639714 - samples/sec: 142.93 - lr: 0.000030
2021-07-23 14:12:58,152 epoch 7 - iter 36/64 - loss 0.28200858 - samples/sec: 145.11 - lr: 0.000030
2021-07-23 14:12:59,471 epoch 7 - iter 42/64 - loss 0.27373408 - samples/sec: 145.56 - lr: 0.000030
2021-07-23 14:13:00,750 epoch 7 - iter 48/64 - loss 0.27477002 - samples/sec: 150.17 - lr: 0.000030
2021-07-23 14:13:02,100 epoch 7 - iter 54/64 - loss 0.27371314 - samples/sec: 142.30 - lr: 0.000030
2021-07-23 14:13:03,384 epoch 7 - iter 60/64 - loss 0.27176147 - samples/sec: 149.55 - lr: 0.000030
2021-07-23 14:13:04,321 ----------------------------------------------------------------------------------------------------
2021-07-23 14:13:04,322 EPOCH 7 done: loss 0.2720 - lr 0.0000300
2021-07-23 14:13:05,680 DEV : loss 0.1550070196390152 - score 0.9747
2021-07-23 14:13:05,695 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:13:07,864 ----------------------------------------------------------------------------------------------------
2021-07-23 14:13:09,107 epoch 8 - iter 6/64 - loss 0.25905719 - samples/sec: 154.74 - lr: 0.000030
2021-07-23 14:13:10,469 epoch 8 - iter 12/64 - loss 0.26361922 - samples/sec: 141.08 - lr: 0.000030
2021-07-23 14:13:11,795 epoch 8 - iter 18/64 - loss 0.24937916 - samples/sec: 144.77 - lr: 0.000030
2021-07-23 14:13:13,171 epoch 8 - iter 24/64 - loss 0.24703361 - samples/sec: 139.61 - lr: 0.000030
2021-07-23 14:13:14,568 epoch 8 - iter 30/64 - loss 0.23921424 - samples/sec: 137.52 - lr: 0.000030
2021-07-23 14:13:15,880 epoch 8 - iter 36/64 - loss 0.23718288 - samples/sec: 146.43 - lr: 0.000030
2021-07-23 14:13:17,265 epoch 8 - iter 42/64 - loss 0.24145927 - samples/sec: 138.61 - lr: 0.000030
2021-07-23 14:13:18,643 epoch 8 - iter 48/64 - loss 0.23834446 - samples/sec: 139.45 - lr: 0.000030
2021-07-23 14:13:20,031 epoch 8 - iter 54/64 - loss 0.23166100 - samples/sec: 138.31 - lr: 0.000030
2021-07-23 14:13:21,271 epoch 8 - iter 60/64 - loss 0.23044241 - samples/sec: 154.92 - lr: 0.000030
2021-07-23 14:13:22,175 ----------------------------------------------------------------------------------------------------
2021-07-23 14:13:22,176 EPOCH 8 done: loss 0.2320 - lr 0.0000300
2021-07-23 14:13:23,534 DEV : loss 0.13692915439605713 - score 0.9793
2021-07-23 14:13:23,548 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:13:27,329 ----------------------------------------------------------------------------------------------------
2021-07-23 14:13:28,632 epoch 9 - iter 6/64 - loss 0.23561628 - samples/sec: 147.62 - lr: 0.000030
2021-07-23 14:13:29,880 epoch 9 - iter 12/64 - loss 0.23703003 - samples/sec: 153.92 - lr: 0.000030
2021-07-23 14:13:31,235 epoch 9 - iter 18/64 - loss 0.21697496 - samples/sec: 141.76 - lr: 0.000030
2021-07-23 14:13:32,597 epoch 9 - iter 24/64 - loss 0.20393553 - samples/sec: 141.00 - lr: 0.000030
2021-07-23 14:13:33,947 epoch 9 - iter 30/64 - loss 0.20428111 - samples/sec: 142.29 - lr: 0.000030
2021-07-23 14:13:35,248 epoch 9 - iter 36/64 - loss 0.21006182 - samples/sec: 147.67 - lr: 0.000030
2021-07-23 14:13:36,623 epoch 9 - iter 42/64 - loss 0.21165347 - samples/sec: 139.67 - lr: 0.000030
2021-07-23 14:13:37,959 epoch 9 - iter 48/64 - loss 0.20986822 - samples/sec: 143.72 - lr: 0.000030
2021-07-23 14:13:39,307 epoch 9 - iter 54/64 - loss 0.20826252 - samples/sec: 142.53 - lr: 0.000030
2021-07-23 14:13:40,680 epoch 9 - iter 60/64 - loss 0.20568428 - samples/sec: 139.87 - lr: 0.000030
2021-07-23 14:13:41,620 ----------------------------------------------------------------------------------------------------
2021-07-23 14:13:41,621 EPOCH 9 done: loss 0.2032 - lr 0.0000300
2021-07-23 14:13:42,996 DEV : loss 0.1213810071349144 - score 0.9828
2021-07-23 14:13:43,010 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:13:45,249 ----------------------------------------------------------------------------------------------------
2021-07-23 14:13:46,531 epoch 10 - iter 6/64 - loss 0.17229324 - samples/sec: 150.11 - lr: 0.000030
2021-07-23 14:13:47,877 epoch 10 - iter 12/64 - loss 0.17560125 - samples/sec: 142.73 - lr: 0.000030
2021-07-23 14:13:49,248 epoch 10 - iter 18/64 - loss 0.18715661 - samples/sec: 140.03 - lr: 0.000030
2021-07-23 14:13:50,539 epoch 10 - iter 24/64 - loss 0.17451530 - samples/sec: 148.76 - lr: 0.000030
2021-07-23 14:13:51,924 epoch 10 - iter 30/64 - loss 0.17975623 - samples/sec: 138.74 - lr: 0.000030
2021-07-23 14:13:53,284 epoch 10 - iter 36/64 - loss 0.17975576 - samples/sec: 141.23 - lr: 0.000030
2021-07-23 14:13:54,675 epoch 10 - iter 42/64 - loss 0.17882190 - samples/sec: 138.05 - lr: 0.000030
2021-07-23 14:13:56,040 epoch 10 - iter 48/64 - loss 0.17314841 - samples/sec: 140.76 - lr: 0.000030
2021-07-23 14:13:57,394 epoch 10 - iter 54/64 - loss 0.17496735 - samples/sec: 141.81 - lr: 0.000030
2021-07-23 14:13:58,686 epoch 10 - iter 60/64 - loss 0.17503834 - samples/sec: 148.65 - lr: 0.000030
2021-07-23 14:13:59,587 ----------------------------------------------------------------------------------------------------
2021-07-23 14:13:59,587 EPOCH 10 done: loss 0.1760 - lr 0.0000300
2021-07-23 14:14:00,958 DEV : loss 0.09963095188140869 - score 0.9818
2021-07-23 14:14:00,973 BAD EPOCHS (no improvement): 1
2021-07-23 14:14:00,973 ----------------------------------------------------------------------------------------------------
2021-07-23 14:14:02,301 epoch 11 - iter 6/64 - loss 0.14384708 - samples/sec: 144.69 - lr: 0.000030
2021-07-23 14:14:03,652 epoch 11 - iter 12/64 - loss 0.16549725 - samples/sec: 142.26 - lr: 0.000030
2021-07-23 14:14:04,962 epoch 11 - iter 18/64 - loss 0.16520058 - samples/sec: 146.52 - lr: 0.000030
2021-07-23 14:14:06,311 epoch 11 - iter 24/64 - loss 0.16739125 - samples/sec: 142.38 - lr: 0.000030
2021-07-23 14:14:07,676 epoch 11 - iter 30/64 - loss 0.16251455 - samples/sec: 140.77 - lr: 0.000030
2021-07-23 14:14:08,988 epoch 11 - iter 36/64 - loss 0.16458781 - samples/sec: 146.40 - lr: 0.000030
2021-07-23 14:14:10,268 epoch 11 - iter 42/64 - loss 0.17007736 - samples/sec: 150.00 - lr: 0.000030
2021-07-23 14:14:11,721 epoch 11 - iter 48/64 - loss 0.17881934 - samples/sec: 132.24 - lr: 0.000030
2021-07-23 14:14:13,052 epoch 11 - iter 54/64 - loss 0.17536058 - samples/sec: 144.26 - lr: 0.000030
2021-07-23 14:14:14,407 epoch 11 - iter 60/64 - loss 0.17646601 - samples/sec: 141.77 - lr: 0.000030
2021-07-23 14:14:15,289 ----------------------------------------------------------------------------------------------------
2021-07-23 14:14:15,290 EPOCH 11 done: loss 0.1733 - lr 0.0000300
2021-07-23 14:14:16,661 DEV : loss 0.0990530252456665 - score 0.9817
2021-07-23 14:14:16,676 BAD EPOCHS (no improvement): 2
2021-07-23 14:14:16,676 ----------------------------------------------------------------------------------------------------
2021-07-23 14:14:18,096 epoch 12 - iter 6/64 - loss 0.19490696 - samples/sec: 135.40 - lr: 0.000030
2021-07-23 14:14:19,484 epoch 12 - iter 12/64 - loss 0.17457715 - samples/sec: 138.34 - lr: 0.000030
2021-07-23 14:14:20,768 epoch 12 - iter 18/64 - loss 0.17425568 - samples/sec: 149.57 - lr: 0.000030
2021-07-23 14:14:22,132 epoch 12 - iter 24/64 - loss 0.17383516 - samples/sec: 140.89 - lr: 0.000030
2021-07-23 14:14:23,549 epoch 12 - iter 30/64 - loss 0.17165453 - samples/sec: 135.51 - lr: 0.000030
2021-07-23 14:14:24,847 epoch 12 - iter 36/64 - loss 0.17322860 - samples/sec: 148.05 - lr: 0.000030
2021-07-23 14:14:26,229 epoch 12 - iter 42/64 - loss 0.17425710 - samples/sec: 138.95 - lr: 0.000030
2021-07-23 14:14:27,567 epoch 12 - iter 48/64 - loss 0.16991535 - samples/sec: 143.50 - lr: 0.000030
2021-07-23 14:14:28,900 epoch 12 - iter 54/64 - loss 0.17288799 - samples/sec: 144.09 - lr: 0.000030
2021-07-23 14:14:30,166 epoch 12 - iter 60/64 - loss 0.16680074 - samples/sec: 151.73 - lr: 0.000030
2021-07-23 14:14:30,993 ----------------------------------------------------------------------------------------------------
2021-07-23 14:14:30,994 EPOCH 12 done: loss 0.1665 - lr 0.0000300
2021-07-23 14:14:32,362 DEV : loss 0.09353989362716675 - score 0.9817
2021-07-23 14:14:32,376 BAD EPOCHS (no improvement): 3
2021-07-23 14:14:32,376 ----------------------------------------------------------------------------------------------------
2021-07-23 14:14:33,683 epoch 13 - iter 6/64 - loss 0.14011825 - samples/sec: 147.07 - lr: 0.000030
2021-07-23 14:14:34,984 epoch 13 - iter 12/64 - loss 0.16073285 - samples/sec: 147.64 - lr: 0.000030
2021-07-23 14:14:36,319 epoch 13 - iter 18/64 - loss 0.16151362 - samples/sec: 143.89 - lr: 0.000030
2021-07-23 14:14:37,733 epoch 13 - iter 24/64 - loss 0.16194056 - samples/sec: 135.90 - lr: 0.000030
2021-07-23 14:14:39,085 epoch 13 - iter 30/64 - loss 0.15816802 - samples/sec: 142.02 - lr: 0.000030
2021-07-23 14:14:40,424 epoch 13 - iter 36/64 - loss 0.15823641 - samples/sec: 143.46 - lr: 0.000030
2021-07-23 14:14:41,759 epoch 13 - iter 42/64 - loss 0.15770051 - samples/sec: 143.83 - lr: 0.000030
2021-07-23 14:14:43,075 epoch 13 - iter 48/64 - loss 0.15592515 - samples/sec: 145.97 - lr: 0.000030
2021-07-23 14:14:44,407 epoch 13 - iter 54/64 - loss 0.15885034 - samples/sec: 144.22 - lr: 0.000030
2021-07-23 14:14:45,832 epoch 13 - iter 60/64 - loss 0.15609222 - samples/sec: 134.80 - lr: 0.000030
2021-07-23 14:14:46,710 ----------------------------------------------------------------------------------------------------
2021-07-23 14:14:46,711 EPOCH 13 done: loss 0.1575 - lr 0.0000300
2021-07-23 14:14:48,076 DEV : loss 0.0915651023387909 - score 0.9851
2021-07-23 14:14:48,094 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:14:50,372 ----------------------------------------------------------------------------------------------------
2021-07-23 14:14:51,801 epoch 14 - iter 6/64 - loss 0.16699535 - samples/sec: 134.64 - lr: 0.000030
2021-07-23 14:14:53,132 epoch 14 - iter 12/64 - loss 0.14795455 - samples/sec: 144.31 - lr: 0.000030
2021-07-23 14:14:54,475 epoch 14 - iter 18/64 - loss 0.14475180 - samples/sec: 143.03 - lr: 0.000030
2021-07-23 14:14:55,827 epoch 14 - iter 24/64 - loss 0.14186767 - samples/sec: 142.04 - lr: 0.000030
2021-07-23 14:14:57,155 epoch 14 - iter 30/64 - loss 0.14715996 - samples/sec: 144.60 - lr: 0.000030
2021-07-23 14:14:58,475 epoch 14 - iter 36/64 - loss 0.14569135 - samples/sec: 145.52 - lr: 0.000030
2021-07-23 14:14:59,805 epoch 14 - iter 42/64 - loss 0.15344304 - samples/sec: 144.44 - lr: 0.000030
2021-07-23 14:15:01,090 epoch 14 - iter 48/64 - loss 0.15887246 - samples/sec: 149.41 - lr: 0.000030
2021-07-23 14:15:02,466 epoch 14 - iter 54/64 - loss 0.15100968 - samples/sec: 139.62 - lr: 0.000030
2021-07-23 14:15:03,819 epoch 14 - iter 60/64 - loss 0.14779979 - samples/sec: 141.92 - lr: 0.000030
2021-07-23 14:15:04,709 ----------------------------------------------------------------------------------------------------
2021-07-23 14:15:04,709 EPOCH 14 done: loss 0.1453 - lr 0.0000300
2021-07-23 14:15:06,075 DEV : loss 0.08247916400432587 - score 0.9841
2021-07-23 14:15:06,089 BAD EPOCHS (no improvement): 1
2021-07-23 14:15:06,089 ----------------------------------------------------------------------------------------------------
2021-07-23 14:15:07,399 epoch 15 - iter 6/64 - loss 0.13308553 - samples/sec: 146.77 - lr: 0.000030
2021-07-23 14:15:08,669 epoch 15 - iter 12/64 - loss 0.14332772 - samples/sec: 151.31 - lr: 0.000030
2021-07-23 14:15:09,947 epoch 15 - iter 18/64 - loss 0.13312236 - samples/sec: 150.20 - lr: 0.000030
2021-07-23 14:15:11,311 epoch 15 - iter 24/64 - loss 0.12942167 - samples/sec: 140.83 - lr: 0.000030
2021-07-23 14:15:12,790 epoch 15 - iter 30/64 - loss 0.13203615 - samples/sec: 129.84 - lr: 0.000030
2021-07-23 14:15:14,092 epoch 15 - iter 36/64 - loss 0.13103021 - samples/sec: 147.58 - lr: 0.000030
2021-07-23 14:15:15,516 epoch 15 - iter 42/64 - loss 0.13285651 - samples/sec: 134.89 - lr: 0.000030
2021-07-23 14:15:16,919 epoch 15 - iter 48/64 - loss 0.13471863 - samples/sec: 136.87 - lr: 0.000030
2021-07-23 14:15:18,267 epoch 15 - iter 54/64 - loss 0.13404368 - samples/sec: 142.53 - lr: 0.000030
2021-07-23 14:15:19,592 epoch 15 - iter 60/64 - loss 0.13162127 - samples/sec: 144.92 - lr: 0.000030
2021-07-23 14:15:20,517 ----------------------------------------------------------------------------------------------------
2021-07-23 14:15:20,517 EPOCH 15 done: loss 0.1315 - lr 0.0000300
2021-07-23 14:15:21,881 DEV : loss 0.08364775031805038 - score 0.9852
2021-07-23 14:15:21,895 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:15:24,221 ----------------------------------------------------------------------------------------------------
2021-07-23 14:15:25,547 epoch 16 - iter 6/64 - loss 0.10377351 - samples/sec: 145.02 - lr: 0.000030
2021-07-23 14:15:26,823 epoch 16 - iter 12/64 - loss 0.13075744 - samples/sec: 150.51 - lr: 0.000030
2021-07-23 14:15:28,151 epoch 16 - iter 18/64 - loss 0.13698038 - samples/sec: 144.66 - lr: 0.000030
2021-07-23 14:15:29,471 epoch 16 - iter 24/64 - loss 0.15162658 - samples/sec: 145.49 - lr: 0.000030
2021-07-23 14:15:30,867 epoch 16 - iter 30/64 - loss 0.14299232 - samples/sec: 137.65 - lr: 0.000030
2021-07-23 14:15:32,242 epoch 16 - iter 36/64 - loss 0.14345280 - samples/sec: 139.62 - lr: 0.000030
2021-07-23 14:15:33,553 epoch 16 - iter 42/64 - loss 0.13642913 - samples/sec: 146.60 - lr: 0.000030
2021-07-23 14:15:34,889 epoch 16 - iter 48/64 - loss 0.14046796 - samples/sec: 143.74 - lr: 0.000030
2021-07-23 14:15:36,283 epoch 16 - iter 54/64 - loss 0.13978848 - samples/sec: 137.82 - lr: 0.000030
2021-07-23 14:15:37,654 epoch 16 - iter 60/64 - loss 0.13452940 - samples/sec: 140.02 - lr: 0.000030
2021-07-23 14:15:38,523 ----------------------------------------------------------------------------------------------------
2021-07-23 14:15:38,523 EPOCH 16 done: loss 0.1331 - lr 0.0000300
2021-07-23 14:15:39,891 DEV : loss 0.07718244194984436 - score 0.9841
2021-07-23 14:15:39,905 BAD EPOCHS (no improvement): 1
2021-07-23 14:15:39,905 ----------------------------------------------------------------------------------------------------
2021-07-23 14:15:41,191 epoch 17 - iter 6/64 - loss 0.14685305 - samples/sec: 149.46 - lr: 0.000030
2021-07-23 14:15:42,560 epoch 17 - iter 12/64 - loss 0.15337136 - samples/sec: 140.34 - lr: 0.000030
2021-07-23 14:15:43,847 epoch 17 - iter 18/64 - loss 0.13415835 - samples/sec: 149.23 - lr: 0.000030
2021-07-23 14:15:45,211 epoch 17 - iter 24/64 - loss 0.13523401 - samples/sec: 140.83 - lr: 0.000030
2021-07-23 14:15:46,491 epoch 17 - iter 30/64 - loss 0.13684149 - samples/sec: 150.04 - lr: 0.000030
2021-07-23 14:15:47,879 epoch 17 - iter 36/64 - loss 0.13793328 - samples/sec: 138.37 - lr: 0.000030
2021-07-23 14:15:49,256 epoch 17 - iter 42/64 - loss 0.13558087 - samples/sec: 139.55 - lr: 0.000030
2021-07-23 14:15:50,592 epoch 17 - iter 48/64 - loss 0.13509211 - samples/sec: 143.69 - lr: 0.000030
2021-07-23 14:15:51,963 epoch 17 - iter 54/64 - loss 0.13698538 - samples/sec: 140.16 - lr: 0.000030
2021-07-23 14:15:53,296 epoch 17 - iter 60/64 - loss 0.13340864 - samples/sec: 144.12 - lr: 0.000030
2021-07-23 14:15:54,212 ----------------------------------------------------------------------------------------------------
2021-07-23 14:15:54,213 EPOCH 17 done: loss 0.1292 - lr 0.0000300
2021-07-23 14:15:55,579 DEV : loss 0.07148879021406174 - score 0.9852
2021-07-23 14:15:55,594 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:15:57,928 ----------------------------------------------------------------------------------------------------
2021-07-23 14:15:59,325 epoch 18 - iter 6/64 - loss 0.11699231 - samples/sec: 137.66 - lr: 0.000030
2021-07-23 14:16:00,682 epoch 18 - iter 12/64 - loss 0.11259955 - samples/sec: 141.50 - lr: 0.000030
2021-07-23 14:16:02,107 epoch 18 - iter 18/64 - loss 0.13329268 - samples/sec: 134.81 - lr: 0.000030
2021-07-23 14:16:03,521 epoch 18 - iter 24/64 - loss 0.12717556 - samples/sec: 135.90 - lr: 0.000030
2021-07-23 14:16:04,872 epoch 18 - iter 30/64 - loss 0.11969212 - samples/sec: 142.12 - lr: 0.000030
2021-07-23 14:16:06,119 epoch 18 - iter 36/64 - loss 0.12262802 - samples/sec: 154.02 - lr: 0.000030
2021-07-23 14:16:07,428 epoch 18 - iter 42/64 - loss 0.12456575 - samples/sec: 146.75 - lr: 0.000030
2021-07-23 14:16:08,662 epoch 18 - iter 48/64 - loss 0.12198054 - samples/sec: 155.70 - lr: 0.000030
2021-07-23 14:16:10,036 epoch 18 - iter 54/64 - loss 0.11980744 - samples/sec: 139.78 - lr: 0.000030
2021-07-23 14:16:11,415 epoch 18 - iter 60/64 - loss 0.12125558 - samples/sec: 139.28 - lr: 0.000030
2021-07-23 14:16:12,300 ----------------------------------------------------------------------------------------------------
2021-07-23 14:16:12,301 EPOCH 18 done: loss 0.1230 - lr 0.0000300
2021-07-23 14:16:13,664 DEV : loss 0.06925906240940094 - score 0.9841
2021-07-23 14:16:13,678 BAD EPOCHS (no improvement): 1
2021-07-23 14:16:13,678 ----------------------------------------------------------------------------------------------------
2021-07-23 14:16:15,002 epoch 19 - iter 6/64 - loss 0.11900778 - samples/sec: 145.28 - lr: 0.000030
2021-07-23 14:16:16,369 epoch 19 - iter 12/64 - loss 0.10184203 - samples/sec: 140.49 - lr: 0.000030
2021-07-23 14:16:17,687 epoch 19 - iter 18/64 - loss 0.10378526 - samples/sec: 145.66 - lr: 0.000030
2021-07-23 14:16:19,108 epoch 19 - iter 24/64 - loss 0.10285035 - samples/sec: 135.18 - lr: 0.000030
2021-07-23 14:16:20,528 epoch 19 - iter 30/64 - loss 0.11130722 - samples/sec: 135.26 - lr: 0.000030
2021-07-23 14:16:21,775 epoch 19 - iter 36/64 - loss 0.11501821 - samples/sec: 154.02 - lr: 0.000030
2021-07-23 14:16:23,060 epoch 19 - iter 42/64 - loss 0.11321281 - samples/sec: 149.55 - lr: 0.000030
2021-07-23 14:16:24,364 epoch 19 - iter 48/64 - loss 0.11082058 - samples/sec: 147.30 - lr: 0.000030
2021-07-23 14:16:25,652 epoch 19 - iter 54/64 - loss 0.10895414 - samples/sec: 149.13 - lr: 0.000030
2021-07-23 14:16:27,041 epoch 19 - iter 60/64 - loss 0.10989823 - samples/sec: 138.29 - lr: 0.000030
2021-07-23 14:16:27,996 ----------------------------------------------------------------------------------------------------
2021-07-23 14:16:27,996 EPOCH 19 done: loss 0.1114 - lr 0.0000300
2021-07-23 14:16:29,359 DEV : loss 0.06754433363676071 - score 0.9841
2021-07-23 14:16:29,374 BAD EPOCHS (no improvement): 2
2021-07-23 14:16:29,374 ----------------------------------------------------------------------------------------------------
2021-07-23 14:16:30,635 epoch 20 - iter 6/64 - loss 0.12225350 - samples/sec: 152.42 - lr: 0.000030
2021-07-23 14:16:32,056 epoch 20 - iter 12/64 - loss 0.11757787 - samples/sec: 135.19 - lr: 0.000030
2021-07-23 14:16:33,376 epoch 20 - iter 18/64 - loss 0.10644964 - samples/sec: 145.53 - lr: 0.000030
2021-07-23 14:16:34,784 epoch 20 - iter 24/64 - loss 0.10625736 - samples/sec: 136.41 - lr: 0.000030
2021-07-23 14:16:36,193 epoch 20 - iter 30/64 - loss 0.11000132 - samples/sec: 136.28 - lr: 0.000030
2021-07-23 14:16:37,520 epoch 20 - iter 36/64 - loss 0.10916173 - samples/sec: 144.74 - lr: 0.000030
2021-07-23 14:16:38,812 epoch 20 - iter 42/64 - loss 0.10906481 - samples/sec: 148.71 - lr: 0.000030
2021-07-23 14:16:40,151 epoch 20 - iter 48/64 - loss 0.11251616 - samples/sec: 143.44 - lr: 0.000030
2021-07-23 14:16:41,571 epoch 20 - iter 54/64 - loss 0.11143854 - samples/sec: 135.20 - lr: 0.000030
2021-07-23 14:16:42,907 epoch 20 - iter 60/64 - loss 0.10863756 - samples/sec: 143.78 - lr: 0.000030
2021-07-23 14:16:43,809 ----------------------------------------------------------------------------------------------------
2021-07-23 14:16:43,809 EPOCH 20 done: loss 0.1080 - lr 0.0000300
2021-07-23 14:16:45,181 DEV : loss 0.06809497624635696 - score 0.9852
2021-07-23 14:16:45,196 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:16:47,509 ----------------------------------------------------------------------------------------------------
2021-07-23 14:16:48,867 epoch 21 - iter 6/64 - loss 0.14680184 - samples/sec: 141.63 - lr: 0.000030
2021-07-23 14:16:50,364 epoch 21 - iter 12/64 - loss 0.12313265 - samples/sec: 128.33 - lr: 0.000030
2021-07-23 14:16:51,680 epoch 21 - iter 18/64 - loss 0.11900260 - samples/sec: 145.92 - lr: 0.000030
2021-07-23 14:16:53,052 epoch 21 - iter 24/64 - loss 0.12589800 - samples/sec: 140.00 - lr: 0.000030
2021-07-23 14:16:54,368 epoch 21 - iter 30/64 - loss 0.12153610 - samples/sec: 145.94 - lr: 0.000030
2021-07-23 14:16:55,712 epoch 21 - iter 36/64 - loss 0.11815155 - samples/sec: 142.97 - lr: 0.000030
2021-07-23 14:16:57,063 epoch 21 - iter 42/64 - loss 0.11653969 - samples/sec: 142.17 - lr: 0.000030
2021-07-23 14:16:58,367 epoch 21 - iter 48/64 - loss 0.11834259 - samples/sec: 147.31 - lr: 0.000030
2021-07-23 14:16:59,756 epoch 21 - iter 54/64 - loss 0.12010134 - samples/sec: 138.20 - lr: 0.000030
2021-07-23 14:17:01,080 epoch 21 - iter 60/64 - loss 0.12202683 - samples/sec: 145.18 - lr: 0.000030
2021-07-23 14:17:01,940 ----------------------------------------------------------------------------------------------------
2021-07-23 14:17:01,940 EPOCH 21 done: loss 0.1202 - lr 0.0000300
2021-07-23 14:17:03,303 DEV : loss 0.06297142058610916 - score 0.9852
2021-07-23 14:17:03,318 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:17:05,591 ----------------------------------------------------------------------------------------------------
2021-07-23 14:17:06,947 epoch 22 - iter 6/64 - loss 0.12445637 - samples/sec: 141.86 - lr: 0.000030
2021-07-23 14:17:08,255 epoch 22 - iter 12/64 - loss 0.12358931 - samples/sec: 146.88 - lr: 0.000030
2021-07-23 14:17:09,624 epoch 22 - iter 18/64 - loss 0.12245842 - samples/sec: 140.29 - lr: 0.000030
2021-07-23 14:17:10,969 epoch 22 - iter 24/64 - loss 0.11899996 - samples/sec: 142.81 - lr: 0.000030
2021-07-23 14:17:12,260 epoch 22 - iter 30/64 - loss 0.11581336 - samples/sec: 148.76 - lr: 0.000030
2021-07-23 14:17:13,519 epoch 22 - iter 36/64 - loss 0.10631786 - samples/sec: 152.61 - lr: 0.000030
2021-07-23 14:17:14,923 epoch 22 - iter 42/64 - loss 0.10105796 - samples/sec: 136.76 - lr: 0.000030
2021-07-23 14:17:16,255 epoch 22 - iter 48/64 - loss 0.10226685 - samples/sec: 144.22 - lr: 0.000030
2021-07-23 14:17:17,553 epoch 22 - iter 54/64 - loss 0.10252173 - samples/sec: 148.00 - lr: 0.000030
2021-07-23 14:17:18,965 epoch 22 - iter 60/64 - loss 0.10212188 - samples/sec: 136.02 - lr: 0.000030
2021-07-23 14:17:19,864 ----------------------------------------------------------------------------------------------------
2021-07-23 14:17:19,865 EPOCH 22 done: loss 0.1031 - lr 0.0000300
2021-07-23 14:17:21,226 DEV : loss 0.061569277197122574 - score 0.9864
2021-07-23 14:17:21,241 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:17:23,559 ----------------------------------------------------------------------------------------------------
2021-07-23 14:17:25,025 epoch 23 - iter 6/64 - loss 0.12906606 - samples/sec: 131.21 - lr: 0.000030
2021-07-23 14:17:26,409 epoch 23 - iter 12/64 - loss 0.14582807 - samples/sec: 138.80 - lr: 0.000030
2021-07-23 14:17:27,808 epoch 23 - iter 18/64 - loss 0.14824930 - samples/sec: 137.22 - lr: 0.000030
2021-07-23 14:17:29,124 epoch 23 - iter 24/64 - loss 0.13570871 - samples/sec: 146.03 - lr: 0.000030
2021-07-23 14:17:30,479 epoch 23 - iter 30/64 - loss 0.14441654 - samples/sec: 141.71 - lr: 0.000030
2021-07-23 14:17:31,756 epoch 23 - iter 36/64 - loss 0.13575554 - samples/sec: 150.43 - lr: 0.000030
2021-07-23 14:17:33,044 epoch 23 - iter 42/64 - loss 0.12676123 - samples/sec: 149.18 - lr: 0.000030
2021-07-23 14:17:34,360 epoch 23 - iter 48/64 - loss 0.12315050 - samples/sec: 145.89 - lr: 0.000030
2021-07-23 14:17:35,603 epoch 23 - iter 54/64 - loss 0.12194365 - samples/sec: 154.50 - lr: 0.000030
2021-07-23 14:17:36,952 epoch 23 - iter 60/64 - loss 0.11714020 - samples/sec: 142.43 - lr: 0.000030
2021-07-23 14:17:37,861 ----------------------------------------------------------------------------------------------------
2021-07-23 14:17:37,862 EPOCH 23 done: loss 0.1156 - lr 0.0000300
2021-07-23 14:17:39,225 DEV : loss 0.06322796642780304 - score 0.9864
2021-07-23 14:17:39,239 BAD EPOCHS (no improvement): 1
2021-07-23 14:17:39,239 ----------------------------------------------------------------------------------------------------
2021-07-23 14:17:40,491 epoch 24 - iter 6/64 - loss 0.13168049 - samples/sec: 153.58 - lr: 0.000030
2021-07-23 14:17:41,852 epoch 24 - iter 12/64 - loss 0.13109903 - samples/sec: 141.13 - lr: 0.000030
2021-07-23 14:17:43,187 epoch 24 - iter 18/64 - loss 0.12961473 - samples/sec: 143.91 - lr: 0.000030
2021-07-23 14:17:44,513 epoch 24 - iter 24/64 - loss 0.11902024 - samples/sec: 144.80 - lr: 0.000030
2021-07-23 14:17:45,788 epoch 24 - iter 30/64 - loss 0.10866480 - samples/sec: 150.61 - lr: 0.000030
2021-07-23 14:17:47,175 epoch 24 - iter 36/64 - loss 0.11037545 - samples/sec: 138.53 - lr: 0.000030
2021-07-23 14:17:48,617 epoch 24 - iter 42/64 - loss 0.11004813 - samples/sec: 133.17 - lr: 0.000030
2021-07-23 14:17:49,891 epoch 24 - iter 48/64 - loss 0.10667583 - samples/sec: 150.78 - lr: 0.000030
2021-07-23 14:17:51,281 epoch 24 - iter 54/64 - loss 0.10511107 - samples/sec: 138.16 - lr: 0.000030
2021-07-23 14:17:52,637 epoch 24 - iter 60/64 - loss 0.10425198 - samples/sec: 141.71 - lr: 0.000030
2021-07-23 14:17:53,499 ----------------------------------------------------------------------------------------------------
2021-07-23 14:17:53,500 EPOCH 24 done: loss 0.1038 - lr 0.0000300
2021-07-23 14:17:54,862 DEV : loss 0.06405662000179291 - score 0.9863
2021-07-23 14:17:54,877 BAD EPOCHS (no improvement): 2
2021-07-23 14:17:54,877 ----------------------------------------------------------------------------------------------------
2021-07-23 14:17:56,167 epoch 25 - iter 6/64 - loss 0.16471118 - samples/sec: 149.04 - lr: 0.000030
2021-07-23 14:17:57,468 epoch 25 - iter 12/64 - loss 0.13310713 - samples/sec: 147.63 - lr: 0.000030
2021-07-23 14:17:58,925 epoch 25 - iter 18/64 - loss 0.11978052 - samples/sec: 131.83 - lr: 0.000030
2021-07-23 14:18:00,252 epoch 25 - iter 24/64 - loss 0.11484415 - samples/sec: 144.66 - lr: 0.000030
2021-07-23 14:18:01,580 epoch 25 - iter 30/64 - loss 0.11086715 - samples/sec: 144.68 - lr: 0.000030
2021-07-23 14:18:03,028 epoch 25 - iter 36/64 - loss 0.11587679 - samples/sec: 132.64 - lr: 0.000030
2021-07-23 14:18:04,330 epoch 25 - iter 42/64 - loss 0.11260287 - samples/sec: 147.53 - lr: 0.000030
2021-07-23 14:18:05,648 epoch 25 - iter 48/64 - loss 0.11240305 - samples/sec: 145.71 - lr: 0.000030
2021-07-23 14:18:06,957 epoch 25 - iter 54/64 - loss 0.11614576 - samples/sec: 146.82 - lr: 0.000030
2021-07-23 14:18:08,288 epoch 25 - iter 60/64 - loss 0.11617039 - samples/sec: 144.21 - lr: 0.000030
2021-07-23 14:18:09,208 ----------------------------------------------------------------------------------------------------
2021-07-23 14:18:09,208 EPOCH 25 done: loss 0.1151 - lr 0.0000300
2021-07-23 14:18:10,573 DEV : loss 0.061709925532341 - score 0.9864
2021-07-23 14:18:10,588 BAD EPOCHS (no improvement): 3
2021-07-23 14:18:10,588 ----------------------------------------------------------------------------------------------------
2021-07-23 14:18:11,904 epoch 26 - iter 6/64 - loss 0.08260071 - samples/sec: 146.08 - lr: 0.000030
2021-07-23 14:18:13,366 epoch 26 - iter 12/64 - loss 0.09152278 - samples/sec: 131.38 - lr: 0.000030
2021-07-23 14:18:14,689 epoch 26 - iter 18/64 - loss 0.08695377 - samples/sec: 145.12 - lr: 0.000030
2021-07-23 14:18:16,049 epoch 26 - iter 24/64 - loss 0.08816672 - samples/sec: 141.31 - lr: 0.000030
2021-07-23 14:18:17,413 epoch 26 - iter 30/64 - loss 0.09464056 - samples/sec: 140.82 - lr: 0.000030
2021-07-23 14:18:18,736 epoch 26 - iter 36/64 - loss 0.09161309 - samples/sec: 145.16 - lr: 0.000030
2021-07-23 14:18:20,031 epoch 26 - iter 42/64 - loss 0.09062869 - samples/sec: 148.28 - lr: 0.000030
2021-07-23 14:18:21,323 epoch 26 - iter 48/64 - loss 0.09161172 - samples/sec: 148.72 - lr: 0.000030
2021-07-23 14:18:22,668 epoch 26 - iter 54/64 - loss 0.09242207 - samples/sec: 142.82 - lr: 0.000030
2021-07-23 14:18:24,007 epoch 26 - iter 60/64 - loss 0.09574814 - samples/sec: 143.39 - lr: 0.000030
2021-07-23 14:18:24,916 ----------------------------------------------------------------------------------------------------
2021-07-23 14:18:24,916 EPOCH 26 done: loss 0.0990 - lr 0.0000300
2021-07-23 14:18:26,399 DEV : loss 0.05770527571439743 - score 0.9864
2021-07-23 14:18:26,417 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:18:28,726 ----------------------------------------------------------------------------------------------------
2021-07-23 14:18:30,204 epoch 27 - iter 6/64 - loss 0.09727796 - samples/sec: 130.12 - lr: 0.000030
2021-07-23 14:18:31,475 epoch 27 - iter 12/64 - loss 0.08864309 - samples/sec: 151.13 - lr: 0.000030
2021-07-23 14:18:32,892 epoch 27 - iter 18/64 - loss 0.10785816 - samples/sec: 135.50 - lr: 0.000030
2021-07-23 14:18:34,231 epoch 27 - iter 24/64 - loss 0.10397551 - samples/sec: 143.41 - lr: 0.000030
2021-07-23 14:18:35,553 epoch 27 - iter 30/64 - loss 0.09893185 - samples/sec: 145.37 - lr: 0.000030
2021-07-23 14:18:36,855 epoch 27 - iter 36/64 - loss 0.10159923 - samples/sec: 147.50 - lr: 0.000030
2021-07-23 14:18:38,185 epoch 27 - iter 42/64 - loss 0.09621746 - samples/sec: 144.44 - lr: 0.000030
2021-07-23 14:18:39,471 epoch 27 - iter 48/64 - loss 0.09513733 - samples/sec: 149.35 - lr: 0.000030
2021-07-23 14:18:40,860 epoch 27 - iter 54/64 - loss 0.09528709 - samples/sec: 138.28 - lr: 0.000030
2021-07-23 14:18:42,264 epoch 27 - iter 60/64 - loss 0.09810158 - samples/sec: 136.76 - lr: 0.000030
2021-07-23 14:18:43,172 ----------------------------------------------------------------------------------------------------
2021-07-23 14:18:43,172 EPOCH 27 done: loss 0.0951 - lr 0.0000300
2021-07-23 14:18:44,541 DEV : loss 0.05822329968214035 - score 0.9864
2021-07-23 14:18:44,556 BAD EPOCHS (no improvement): 1
2021-07-23 14:18:44,556 ----------------------------------------------------------------------------------------------------
2021-07-23 14:18:45,884 epoch 28 - iter 6/64 - loss 0.14307355 - samples/sec: 144.73 - lr: 0.000030
2021-07-23 14:18:47,243 epoch 28 - iter 12/64 - loss 0.11923082 - samples/sec: 141.33 - lr: 0.000030
2021-07-23 14:18:48,631 epoch 28 - iter 18/64 - loss 0.10897083 - samples/sec: 138.35 - lr: 0.000030
2021-07-23 14:18:49,987 epoch 28 - iter 24/64 - loss 0.09886125 - samples/sec: 141.72 - lr: 0.000030
2021-07-23 14:18:51,336 epoch 28 - iter 30/64 - loss 0.09570830 - samples/sec: 142.34 - lr: 0.000030
2021-07-23 14:18:52,648 epoch 28 - iter 36/64 - loss 0.10150962 - samples/sec: 146.40 - lr: 0.000030
2021-07-23 14:18:54,067 epoch 28 - iter 42/64 - loss 0.10379445 - samples/sec: 135.34 - lr: 0.000030
2021-07-23 14:18:55,383 epoch 28 - iter 48/64 - loss 0.09803638 - samples/sec: 145.93 - lr: 0.000030
2021-07-23 14:18:56,700 epoch 28 - iter 54/64 - loss 0.09291492 - samples/sec: 145.93 - lr: 0.000030
2021-07-23 14:18:58,020 epoch 28 - iter 60/64 - loss 0.09027224 - samples/sec: 145.42 - lr: 0.000030
2021-07-23 14:18:58,952 ----------------------------------------------------------------------------------------------------
2021-07-23 14:18:58,952 EPOCH 28 done: loss 0.0886 - lr 0.0000300
2021-07-23 14:19:00,322 DEV : loss 0.05806853994727135 - score 0.9864
2021-07-23 14:19:00,336 BAD EPOCHS (no improvement): 2
2021-07-23 14:19:00,336 ----------------------------------------------------------------------------------------------------
2021-07-23 14:19:01,667 epoch 29 - iter 6/64 - loss 0.05754340 - samples/sec: 144.41 - lr: 0.000030
2021-07-23 14:19:03,095 epoch 29 - iter 12/64 - loss 0.07549490 - samples/sec: 134.51 - lr: 0.000030
2021-07-23 14:19:04,429 epoch 29 - iter 18/64 - loss 0.07056526 - samples/sec: 144.02 - lr: 0.000030
2021-07-23 14:19:05,648 epoch 29 - iter 24/64 - loss 0.07490745 - samples/sec: 157.58 - lr: 0.000030
2021-07-23 14:19:07,039 epoch 29 - iter 30/64 - loss 0.08244095 - samples/sec: 138.07 - lr: 0.000030
2021-07-23 14:19:08,392 epoch 29 - iter 36/64 - loss 0.08446034 - samples/sec: 141.91 - lr: 0.000030
2021-07-23 14:19:09,788 epoch 29 - iter 42/64 - loss 0.08386261 - samples/sec: 137.67 - lr: 0.000030
2021-07-23 14:19:11,156 epoch 29 - iter 48/64 - loss 0.08313098 - samples/sec: 140.42 - lr: 0.000030
2021-07-23 14:19:12,565 epoch 29 - iter 54/64 - loss 0.08349962 - samples/sec: 136.25 - lr: 0.000030
2021-07-23 14:19:13,888 epoch 29 - iter 60/64 - loss 0.08574540 - samples/sec: 145.22 - lr: 0.000030
2021-07-23 14:19:14,777 ----------------------------------------------------------------------------------------------------
2021-07-23 14:19:14,777 EPOCH 29 done: loss 0.0852 - lr 0.0000300
2021-07-23 14:19:16,147 DEV : loss 0.061708394438028336 - score 0.9875
2021-07-23 14:19:16,162 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:19:18,526 ----------------------------------------------------------------------------------------------------
2021-07-23 14:19:19,838 epoch 30 - iter 6/64 - loss 0.08373970 - samples/sec: 146.53 - lr: 0.000030
2021-07-23 14:19:21,156 epoch 30 - iter 12/64 - loss 0.07887729 - samples/sec: 145.70 - lr: 0.000030
2021-07-23 14:19:22,531 epoch 30 - iter 18/64 - loss 0.08873554 - samples/sec: 139.73 - lr: 0.000030
2021-07-23 14:19:23,928 epoch 30 - iter 24/64 - loss 0.08208557 - samples/sec: 137.50 - lr: 0.000030
2021-07-23 14:19:25,296 epoch 30 - iter 30/64 - loss 0.08313565 - samples/sec: 140.38 - lr: 0.000030
2021-07-23 14:19:26,652 epoch 30 - iter 36/64 - loss 0.08684057 - samples/sec: 141.60 - lr: 0.000030
2021-07-23 14:19:28,008 epoch 30 - iter 42/64 - loss 0.08767820 - samples/sec: 141.71 - lr: 0.000030
2021-07-23 14:19:29,307 epoch 30 - iter 48/64 - loss 0.09154133 - samples/sec: 147.90 - lr: 0.000030
2021-07-23 14:19:30,663 epoch 30 - iter 54/64 - loss 0.09214660 - samples/sec: 141.57 - lr: 0.000030
2021-07-23 14:19:32,056 epoch 30 - iter 60/64 - loss 0.09023457 - samples/sec: 137.88 - lr: 0.000030
2021-07-23 14:19:32,965 ----------------------------------------------------------------------------------------------------
2021-07-23 14:19:32,965 EPOCH 30 done: loss 0.0897 - lr 0.0000300
2021-07-23 14:19:34,336 DEV : loss 0.06249523162841797 - score 0.9864
2021-07-23 14:19:34,351 BAD EPOCHS (no improvement): 1
2021-07-23 14:19:34,351 ----------------------------------------------------------------------------------------------------
2021-07-23 14:19:35,691 epoch 31 - iter 6/64 - loss 0.09252053 - samples/sec: 143.43 - lr: 0.000030
2021-07-23 14:19:37,067 epoch 31 - iter 12/64 - loss 0.09456464 - samples/sec: 139.62 - lr: 0.000030
2021-07-23 14:19:38,404 epoch 31 - iter 18/64 - loss 0.08801548 - samples/sec: 143.68 - lr: 0.000030
2021-07-23 14:19:39,744 epoch 31 - iter 24/64 - loss 0.08916876 - samples/sec: 143.28 - lr: 0.000030
2021-07-23 14:19:41,032 epoch 31 - iter 30/64 - loss 0.08137492 - samples/sec: 149.10 - lr: 0.000030
2021-07-23 14:19:42,357 epoch 31 - iter 36/64 - loss 0.08260470 - samples/sec: 145.06 - lr: 0.000030
2021-07-23 14:19:43,701 epoch 31 - iter 42/64 - loss 0.08206806 - samples/sec: 142.85 - lr: 0.000030
2021-07-23 14:19:45,030 epoch 31 - iter 48/64 - loss 0.08492002 - samples/sec: 144.48 - lr: 0.000030
2021-07-23 14:19:46,384 epoch 31 - iter 54/64 - loss 0.08386206 - samples/sec: 141.92 - lr: 0.000030
2021-07-23 14:19:47,826 epoch 31 - iter 60/64 - loss 0.08303017 - samples/sec: 133.22 - lr: 0.000030
2021-07-23 14:19:48,788 ----------------------------------------------------------------------------------------------------
2021-07-23 14:19:48,788 EPOCH 31 done: loss 0.0893 - lr 0.0000300
2021-07-23 14:19:50,160 DEV : loss 0.06012768670916557 - score 0.9864
2021-07-23 14:19:50,175 BAD EPOCHS (no improvement): 2
2021-07-23 14:19:50,175 ----------------------------------------------------------------------------------------------------
2021-07-23 14:19:51,548 epoch 32 - iter 6/64 - loss 0.11194231 - samples/sec: 139.95 - lr: 0.000030
2021-07-23 14:19:52,892 epoch 32 - iter 12/64 - loss 0.10305824 - samples/sec: 142.92 - lr: 0.000030
2021-07-23 14:19:54,312 epoch 32 - iter 18/64 - loss 0.09886152 - samples/sec: 135.31 - lr: 0.000030
2021-07-23 14:19:55,601 epoch 32 - iter 24/64 - loss 0.09966987 - samples/sec: 149.02 - lr: 0.000030
2021-07-23 14:19:56,941 epoch 32 - iter 30/64 - loss 0.09530292 - samples/sec: 143.34 - lr: 0.000030
2021-07-23 14:19:58,319 epoch 32 - iter 36/64 - loss 0.09728416 - samples/sec: 139.30 - lr: 0.000030
2021-07-23 14:19:59,701 epoch 32 - iter 42/64 - loss 0.09500358 - samples/sec: 139.00 - lr: 0.000030
2021-07-23 14:20:01,057 epoch 32 - iter 48/64 - loss 0.09317090 - samples/sec: 141.70 - lr: 0.000030
2021-07-23 14:20:02,420 epoch 32 - iter 54/64 - loss 0.09144916 - samples/sec: 140.85 - lr: 0.000030
2021-07-23 14:20:03,735 epoch 32 - iter 60/64 - loss 0.09055860 - samples/sec: 146.09 - lr: 0.000030
2021-07-23 14:20:04,614 ----------------------------------------------------------------------------------------------------
2021-07-23 14:20:04,614 EPOCH 32 done: loss 0.0893 - lr 0.0000300
2021-07-23 14:20:05,987 DEV : loss 0.05734042823314667 - score 0.9853
2021-07-23 14:20:06,001 BAD EPOCHS (no improvement): 3
2021-07-23 14:20:06,001 ----------------------------------------------------------------------------------------------------
2021-07-23 14:20:07,471 epoch 33 - iter 6/64 - loss 0.10414341 - samples/sec: 130.73 - lr: 0.000030
2021-07-23 14:20:08,804 epoch 33 - iter 12/64 - loss 0.08636101 - samples/sec: 144.15 - lr: 0.000030
2021-07-23 14:20:10,112 epoch 33 - iter 18/64 - loss 0.08683817 - samples/sec: 146.83 - lr: 0.000030
2021-07-23 14:20:11,409 epoch 33 - iter 24/64 - loss 0.08666003 - samples/sec: 148.13 - lr: 0.000030
2021-07-23 14:20:12,855 epoch 33 - iter 30/64 - loss 0.08723500 - samples/sec: 132.79 - lr: 0.000030
2021-07-23 14:20:14,173 epoch 33 - iter 36/64 - loss 0.08609377 - samples/sec: 145.75 - lr: 0.000030
2021-07-23 14:20:15,461 epoch 33 - iter 42/64 - loss 0.08849627 - samples/sec: 149.16 - lr: 0.000030
2021-07-23 14:20:16,839 epoch 33 - iter 48/64 - loss 0.09017520 - samples/sec: 139.34 - lr: 0.000030
2021-07-23 14:20:18,249 epoch 33 - iter 54/64 - loss 0.09225265 - samples/sec: 136.29 - lr: 0.000030
2021-07-23 14:20:19,648 epoch 33 - iter 60/64 - loss 0.09258906 - samples/sec: 137.23 - lr: 0.000030
2021-07-23 14:20:20,551 ----------------------------------------------------------------------------------------------------
2021-07-23 14:20:20,552 EPOCH 33 done: loss 0.0923 - lr 0.0000300
2021-07-23 14:20:21,922 DEV : loss 0.05646602809429169 - score 0.9853
Epoch    33: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 14:20:21,936 BAD EPOCHS (no improvement): 4
2021-07-23 14:20:21,937 ----------------------------------------------------------------------------------------------------
2021-07-23 14:20:23,271 epoch 34 - iter 6/64 - loss 0.12145325 - samples/sec: 144.01 - lr: 0.000015
2021-07-23 14:20:24,713 epoch 34 - iter 12/64 - loss 0.11731149 - samples/sec: 133.23 - lr: 0.000015
2021-07-23 14:20:26,007 epoch 34 - iter 18/64 - loss 0.10210499 - samples/sec: 148.43 - lr: 0.000015
2021-07-23 14:20:27,323 epoch 34 - iter 24/64 - loss 0.08901057 - samples/sec: 145.91 - lr: 0.000015
2021-07-23 14:20:28,619 epoch 34 - iter 30/64 - loss 0.08559967 - samples/sec: 148.19 - lr: 0.000015
2021-07-23 14:20:30,027 epoch 34 - iter 36/64 - loss 0.08543243 - samples/sec: 136.42 - lr: 0.000015
2021-07-23 14:20:31,393 epoch 34 - iter 42/64 - loss 0.08326870 - samples/sec: 140.71 - lr: 0.000015
2021-07-23 14:20:32,760 epoch 34 - iter 48/64 - loss 0.08159688 - samples/sec: 140.45 - lr: 0.000015
2021-07-23 14:20:34,121 epoch 34 - iter 54/64 - loss 0.08044377 - samples/sec: 141.17 - lr: 0.000015
2021-07-23 14:20:35,480 epoch 34 - iter 60/64 - loss 0.08107736 - samples/sec: 141.29 - lr: 0.000015
2021-07-23 14:20:36,355 ----------------------------------------------------------------------------------------------------
2021-07-23 14:20:36,356 EPOCH 34 done: loss 0.0832 - lr 0.0000150
2021-07-23 14:20:37,728 DEV : loss 0.057352449744939804 - score 0.9864
2021-07-23 14:20:37,742 BAD EPOCHS (no improvement): 1
2021-07-23 14:20:37,743 ----------------------------------------------------------------------------------------------------
2021-07-23 14:20:39,056 epoch 35 - iter 6/64 - loss 0.05287328 - samples/sec: 146.36 - lr: 0.000015
2021-07-23 14:20:40,356 epoch 35 - iter 12/64 - loss 0.07875451 - samples/sec: 147.72 - lr: 0.000015
2021-07-23 14:20:41,791 epoch 35 - iter 18/64 - loss 0.08211897 - samples/sec: 133.89 - lr: 0.000015
2021-07-23 14:20:43,135 epoch 35 - iter 24/64 - loss 0.07737152 - samples/sec: 142.91 - lr: 0.000015
2021-07-23 14:20:44,481 epoch 35 - iter 30/64 - loss 0.07466976 - samples/sec: 142.68 - lr: 0.000015
2021-07-23 14:20:45,847 epoch 35 - iter 36/64 - loss 0.07839051 - samples/sec: 140.58 - lr: 0.000015
2021-07-23 14:20:47,199 epoch 35 - iter 42/64 - loss 0.07900036 - samples/sec: 142.12 - lr: 0.000015
2021-07-23 14:20:48,596 epoch 35 - iter 48/64 - loss 0.08105375 - samples/sec: 137.43 - lr: 0.000015
2021-07-23 14:20:49,936 epoch 35 - iter 54/64 - loss 0.08414081 - samples/sec: 143.36 - lr: 0.000015
2021-07-23 14:20:51,240 epoch 35 - iter 60/64 - loss 0.08485596 - samples/sec: 147.24 - lr: 0.000015
2021-07-23 14:20:52,173 ----------------------------------------------------------------------------------------------------
2021-07-23 14:20:52,173 EPOCH 35 done: loss 0.0849 - lr 0.0000150
2021-07-23 14:20:53,543 DEV : loss 0.05792761594057083 - score 0.9841
2021-07-23 14:20:53,558 BAD EPOCHS (no improvement): 2
2021-07-23 14:20:53,558 ----------------------------------------------------------------------------------------------------
2021-07-23 14:20:54,924 epoch 36 - iter 6/64 - loss 0.09868799 - samples/sec: 140.65 - lr: 0.000015
2021-07-23 14:20:56,287 epoch 36 - iter 12/64 - loss 0.07700831 - samples/sec: 140.97 - lr: 0.000015
2021-07-23 14:20:57,612 epoch 36 - iter 18/64 - loss 0.08513654 - samples/sec: 144.95 - lr: 0.000015
2021-07-23 14:20:58,956 epoch 36 - iter 24/64 - loss 0.09118214 - samples/sec: 142.92 - lr: 0.000015
2021-07-23 14:21:00,324 epoch 36 - iter 30/64 - loss 0.09173653 - samples/sec: 140.42 - lr: 0.000015
2021-07-23 14:21:01,757 epoch 36 - iter 36/64 - loss 0.08734823 - samples/sec: 133.98 - lr: 0.000015
2021-07-23 14:21:03,115 epoch 36 - iter 42/64 - loss 0.08395870 - samples/sec: 141.47 - lr: 0.000015
2021-07-23 14:21:04,447 epoch 36 - iter 48/64 - loss 0.08392805 - samples/sec: 144.16 - lr: 0.000015
2021-07-23 14:21:05,762 epoch 36 - iter 54/64 - loss 0.08528495 - samples/sec: 146.08 - lr: 0.000015
2021-07-23 14:21:07,104 epoch 36 - iter 60/64 - loss 0.08558359 - samples/sec: 143.15 - lr: 0.000015
2021-07-23 14:21:07,928 ----------------------------------------------------------------------------------------------------
2021-07-23 14:21:07,928 EPOCH 36 done: loss 0.0875 - lr 0.0000150
2021-07-23 14:21:09,287 DEV : loss 0.05769180506467819 - score 0.9853
2021-07-23 14:21:09,302 BAD EPOCHS (no improvement): 3
2021-07-23 14:21:09,302 ----------------------------------------------------------------------------------------------------
2021-07-23 14:21:10,579 epoch 37 - iter 6/64 - loss 0.07597257 - samples/sec: 150.55 - lr: 0.000015
2021-07-23 14:21:11,865 epoch 37 - iter 12/64 - loss 0.08225648 - samples/sec: 149.43 - lr: 0.000015
2021-07-23 14:21:13,216 epoch 37 - iter 18/64 - loss 0.07786598 - samples/sec: 142.16 - lr: 0.000015
2021-07-23 14:21:14,599 epoch 37 - iter 24/64 - loss 0.08073055 - samples/sec: 138.85 - lr: 0.000015
2021-07-23 14:21:16,016 epoch 37 - iter 30/64 - loss 0.07620475 - samples/sec: 135.52 - lr: 0.000015
2021-07-23 14:21:17,364 epoch 37 - iter 36/64 - loss 0.07339947 - samples/sec: 142.55 - lr: 0.000015
2021-07-23 14:21:18,645 epoch 37 - iter 42/64 - loss 0.07295636 - samples/sec: 149.88 - lr: 0.000015
2021-07-23 14:21:19,988 epoch 37 - iter 48/64 - loss 0.07385189 - samples/sec: 142.99 - lr: 0.000015
2021-07-23 14:21:21,383 epoch 37 - iter 54/64 - loss 0.07557780 - samples/sec: 137.69 - lr: 0.000015
2021-07-23 14:21:22,691 epoch 37 - iter 60/64 - loss 0.07612257 - samples/sec: 146.92 - lr: 0.000015
2021-07-23 14:21:23,608 ----------------------------------------------------------------------------------------------------
2021-07-23 14:21:23,608 EPOCH 37 done: loss 0.0786 - lr 0.0000150
2021-07-23 14:21:24,972 DEV : loss 0.05723440647125244 - score 0.9875
2021-07-23 14:21:24,986 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:21:27,407 ----------------------------------------------------------------------------------------------------
2021-07-23 14:21:28,699 epoch 38 - iter 6/64 - loss 0.07730347 - samples/sec: 148.97 - lr: 0.000015
2021-07-23 14:21:30,007 epoch 38 - iter 12/64 - loss 0.08817955 - samples/sec: 146.78 - lr: 0.000015
2021-07-23 14:21:31,381 epoch 38 - iter 18/64 - loss 0.09213879 - samples/sec: 139.85 - lr: 0.000015
2021-07-23 14:21:32,686 epoch 38 - iter 24/64 - loss 0.08766405 - samples/sec: 147.14 - lr: 0.000015
2021-07-23 14:21:34,017 epoch 38 - iter 30/64 - loss 0.08734398 - samples/sec: 144.37 - lr: 0.000015
2021-07-23 14:21:35,401 epoch 38 - iter 36/64 - loss 0.08447142 - samples/sec: 138.78 - lr: 0.000015
2021-07-23 14:21:36,751 epoch 38 - iter 42/64 - loss 0.08380012 - samples/sec: 142.27 - lr: 0.000015
2021-07-23 14:21:38,153 epoch 38 - iter 48/64 - loss 0.08485901 - samples/sec: 137.01 - lr: 0.000015
2021-07-23 14:21:39,492 epoch 38 - iter 54/64 - loss 0.08217321 - samples/sec: 143.44 - lr: 0.000015
2021-07-23 14:21:40,912 epoch 38 - iter 60/64 - loss 0.07987702 - samples/sec: 135.18 - lr: 0.000015
2021-07-23 14:21:41,821 ----------------------------------------------------------------------------------------------------
2021-07-23 14:21:41,821 EPOCH 38 done: loss 0.0791 - lr 0.0000150
2021-07-23 14:21:43,191 DEV : loss 0.05623399466276169 - score 0.9853
2021-07-23 14:21:43,209 BAD EPOCHS (no improvement): 1
2021-07-23 14:21:43,209 ----------------------------------------------------------------------------------------------------
2021-07-23 14:21:44,525 epoch 39 - iter 6/64 - loss 0.07068843 - samples/sec: 146.14 - lr: 0.000015
2021-07-23 14:21:45,816 epoch 39 - iter 12/64 - loss 0.07332440 - samples/sec: 148.74 - lr: 0.000015
2021-07-23 14:21:47,256 epoch 39 - iter 18/64 - loss 0.06475286 - samples/sec: 133.40 - lr: 0.000015
2021-07-23 14:21:48,663 epoch 39 - iter 24/64 - loss 0.06807618 - samples/sec: 136.46 - lr: 0.000015
2021-07-23 14:21:49,933 epoch 39 - iter 30/64 - loss 0.06650015 - samples/sec: 151.32 - lr: 0.000015
2021-07-23 14:21:51,272 epoch 39 - iter 36/64 - loss 0.07006909 - samples/sec: 143.39 - lr: 0.000015
2021-07-23 14:21:52,671 epoch 39 - iter 42/64 - loss 0.07829522 - samples/sec: 137.29 - lr: 0.000015
2021-07-23 14:21:54,072 epoch 39 - iter 48/64 - loss 0.07483915 - samples/sec: 137.07 - lr: 0.000015
2021-07-23 14:21:55,407 epoch 39 - iter 54/64 - loss 0.07674299 - samples/sec: 143.91 - lr: 0.000015
2021-07-23 14:21:56,756 epoch 39 - iter 60/64 - loss 0.07789703 - samples/sec: 142.44 - lr: 0.000015
2021-07-23 14:21:57,629 ----------------------------------------------------------------------------------------------------
2021-07-23 14:21:57,629 EPOCH 39 done: loss 0.0790 - lr 0.0000150
2021-07-23 14:21:58,993 DEV : loss 0.05703296139836311 - score 0.9841
2021-07-23 14:21:59,007 BAD EPOCHS (no improvement): 2
2021-07-23 14:21:59,008 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:00,392 epoch 40 - iter 6/64 - loss 0.06397375 - samples/sec: 138.83 - lr: 0.000015
2021-07-23 14:22:01,648 epoch 40 - iter 12/64 - loss 0.07092377 - samples/sec: 152.95 - lr: 0.000015
2021-07-23 14:22:03,039 epoch 40 - iter 18/64 - loss 0.07130180 - samples/sec: 138.06 - lr: 0.000015
2021-07-23 14:22:04,345 epoch 40 - iter 24/64 - loss 0.07396115 - samples/sec: 147.16 - lr: 0.000015
2021-07-23 14:22:05,669 epoch 40 - iter 30/64 - loss 0.08051472 - samples/sec: 145.04 - lr: 0.000015
2021-07-23 14:22:07,004 epoch 40 - iter 36/64 - loss 0.07739816 - samples/sec: 143.87 - lr: 0.000015
2021-07-23 14:22:08,351 epoch 40 - iter 42/64 - loss 0.07798297 - samples/sec: 142.60 - lr: 0.000015
2021-07-23 14:22:09,712 epoch 40 - iter 48/64 - loss 0.07703980 - samples/sec: 141.15 - lr: 0.000015
2021-07-23 14:22:11,071 epoch 40 - iter 54/64 - loss 0.07694338 - samples/sec: 141.26 - lr: 0.000015
2021-07-23 14:22:12,466 epoch 40 - iter 60/64 - loss 0.07611079 - samples/sec: 137.69 - lr: 0.000015
2021-07-23 14:22:13,420 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:13,420 EPOCH 40 done: loss 0.0755 - lr 0.0000150
2021-07-23 14:22:14,786 DEV : loss 0.05725884437561035 - score 0.9853
2021-07-23 14:22:14,800 BAD EPOCHS (no improvement): 3
2021-07-23 14:22:15,366 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:15,366 Testing using best model ...
2021-07-23 14:22:15,367 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/nld.rst.nldt/best-model.pt
2021-07-23 14:22:27,173 0.9867	0.9848	0.9857
2021-07-23 14:22:27,173 
Results:
- F1-score (micro) 0.9857
- F1-score (macro) 0.9865

By class:
SENT       tp: 270 - fp: 7 - fn: 8 - precision: 0.9747 - recall: 0.9712 - f1-score: 0.9730
X          tp: 248 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 14:22:27,173 ----------------------------------------------------------------------------------------------------
/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.sdrt.stac/
2021-07-23 14:22:27,211 Reading data from /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.sdrt.stac
2021-07-23 14:22:27,212 Train: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.sdrt.stac/sent_train.txt
2021-07-23 14:22:27,214 Dev: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.sdrt.stac/sent_dev.txt
2021-07-23 14:22:27,216 Test: /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.sdrt.stac/sent_test.txt
Corpus: 9526 train + 1406 dev + 2706 test sentences
Dictionary with 6 tags: <unk>, O, X, B-SENT, <START>, <STOP>
2021-07-23 14:22:30,711 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:30,714 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=818, out_features=818, bias=True)
  (rnn): LSTM(818, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2021-07-23 14:22:30,714 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:30,714 Corpus: "Corpus: 9526 train + 1406 dev + 2706 test sentences"
2021-07-23 14:22:30,714 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:30,715 Parameters:
2021-07-23 14:22:30,715  - learning_rate: "3e-05"
2021-07-23 14:22:30,715  - mini_batch_size: "32"
2021-07-23 14:22:30,715  - patience: "3"
2021-07-23 14:22:30,715  - anneal_factor: "0.5"
2021-07-23 14:22:30,715  - max_epochs: "40"
2021-07-23 14:22:30,715  - shuffle: "True"
2021-07-23 14:22:30,715  - train_with_dev: "False"
2021-07-23 14:22:30,715  - batch_growth_annealing: "False"
2021-07-23 14:22:30,715 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:30,715 Model training base path: "/disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.sdrt.stac"
2021-07-23 14:22:30,715 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:30,715 Device: cuda:0
2021-07-23 14:22:30,715 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:30,716 Embeddings storage mode: cpu
2021-07-23 14:22:30,720 ----------------------------------------------------------------------------------------------------
2021-07-23 14:22:45,278 epoch 1 - iter 29/298 - loss 2.66042934 - samples/sec: 63.76 - lr: 0.000030
2021-07-23 14:22:59,034 epoch 1 - iter 58/298 - loss 2.26311038 - samples/sec: 67.47 - lr: 0.000030
2021-07-23 14:23:12,922 epoch 1 - iter 87/298 - loss 1.99484639 - samples/sec: 66.83 - lr: 0.000030
2021-07-23 14:23:26,892 epoch 1 - iter 116/298 - loss 1.76334620 - samples/sec: 66.44 - lr: 0.000030
2021-07-23 14:23:40,722 epoch 1 - iter 145/298 - loss 1.57634828 - samples/sec: 67.10 - lr: 0.000030
2021-07-23 14:23:54,483 epoch 1 - iter 174/298 - loss 1.41784595 - samples/sec: 67.44 - lr: 0.000030
2021-07-23 14:24:08,215 epoch 1 - iter 203/298 - loss 1.28885337 - samples/sec: 67.58 - lr: 0.000030
2021-07-23 14:24:21,975 epoch 1 - iter 232/298 - loss 1.19135641 - samples/sec: 67.45 - lr: 0.000030
2021-07-23 14:24:35,985 epoch 1 - iter 261/298 - loss 1.10601707 - samples/sec: 66.25 - lr: 0.000030
2021-07-23 14:24:49,926 epoch 1 - iter 290/298 - loss 1.03850227 - samples/sec: 66.57 - lr: 0.000030
2021-07-23 14:24:53,806 ----------------------------------------------------------------------------------------------------
2021-07-23 14:24:53,806 EPOCH 1 done: loss 1.0236 - lr 0.0000300
2021-07-23 14:25:09,673 DEV : loss 0.32686060667037964 - score 0.9336
2021-07-23 14:25:09,692 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:25:10,263 ----------------------------------------------------------------------------------------------------
2021-07-23 14:25:14,955 epoch 2 - iter 29/298 - loss 0.39352490 - samples/sec: 197.89 - lr: 0.000030
2021-07-23 14:25:19,579 epoch 2 - iter 58/298 - loss 0.38126522 - samples/sec: 200.75 - lr: 0.000030
2021-07-23 14:25:24,299 epoch 2 - iter 87/298 - loss 0.38536692 - samples/sec: 196.68 - lr: 0.000030
2021-07-23 14:25:28,987 epoch 2 - iter 116/298 - loss 0.38474864 - samples/sec: 198.01 - lr: 0.000030
2021-07-23 14:25:33,682 epoch 2 - iter 145/298 - loss 0.38361699 - samples/sec: 197.75 - lr: 0.000030
2021-07-23 14:25:38,254 epoch 2 - iter 174/298 - loss 0.38045430 - samples/sec: 203.01 - lr: 0.000030
2021-07-23 14:25:42,971 epoch 2 - iter 203/298 - loss 0.37138499 - samples/sec: 196.80 - lr: 0.000030
2021-07-23 14:25:47,636 epoch 2 - iter 232/298 - loss 0.36586114 - samples/sec: 199.03 - lr: 0.000030
2021-07-23 14:25:52,282 epoch 2 - iter 261/298 - loss 0.36030133 - samples/sec: 199.80 - lr: 0.000030
2021-07-23 14:25:56,957 epoch 2 - iter 290/298 - loss 0.35585290 - samples/sec: 198.56 - lr: 0.000030
2021-07-23 14:25:58,206 ----------------------------------------------------------------------------------------------------
2021-07-23 14:25:58,207 EPOCH 2 done: loss 0.3556 - lr 0.0000300
2021-07-23 14:26:00,465 DEV : loss 0.2684960961341858 - score 0.9351
2021-07-23 14:26:00,485 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:26:02,685 ----------------------------------------------------------------------------------------------------
2021-07-23 14:26:07,369 epoch 3 - iter 29/298 - loss 0.32244394 - samples/sec: 198.27 - lr: 0.000030
2021-07-23 14:26:12,031 epoch 3 - iter 58/298 - loss 0.32670983 - samples/sec: 199.13 - lr: 0.000030
2021-07-23 14:26:16,668 epoch 3 - iter 87/298 - loss 0.31485981 - samples/sec: 200.22 - lr: 0.000030
2021-07-23 14:26:21,318 epoch 3 - iter 116/298 - loss 0.31680820 - samples/sec: 199.63 - lr: 0.000030
2021-07-23 14:26:25,948 epoch 3 - iter 145/298 - loss 0.31586544 - samples/sec: 200.51 - lr: 0.000030
2021-07-23 14:26:30,679 epoch 3 - iter 174/298 - loss 0.31804716 - samples/sec: 196.21 - lr: 0.000030
2021-07-23 14:26:35,506 epoch 3 - iter 203/298 - loss 0.31786135 - samples/sec: 192.29 - lr: 0.000030
2021-07-23 14:26:40,288 epoch 3 - iter 232/298 - loss 0.31636211 - samples/sec: 194.15 - lr: 0.000030
2021-07-23 14:26:44,845 epoch 3 - iter 261/298 - loss 0.31602519 - samples/sec: 203.72 - lr: 0.000030
2021-07-23 14:26:49,456 epoch 3 - iter 290/298 - loss 0.31619834 - samples/sec: 201.35 - lr: 0.000030
2021-07-23 14:26:50,662 ----------------------------------------------------------------------------------------------------
2021-07-23 14:26:50,662 EPOCH 3 done: loss 0.3158 - lr 0.0000300
2021-07-23 14:26:52,910 DEV : loss 0.24780194461345673 - score 0.9404
2021-07-23 14:26:52,930 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:26:55,062 ----------------------------------------------------------------------------------------------------
2021-07-23 14:26:59,683 epoch 4 - iter 29/298 - loss 0.28638941 - samples/sec: 200.99 - lr: 0.000030
2021-07-23 14:27:04,367 epoch 4 - iter 58/298 - loss 0.29831079 - samples/sec: 198.18 - lr: 0.000030
2021-07-23 14:27:09,053 epoch 4 - iter 87/298 - loss 0.31014275 - samples/sec: 198.09 - lr: 0.000030
2021-07-23 14:27:13,691 epoch 4 - iter 116/298 - loss 0.30859536 - samples/sec: 200.17 - lr: 0.000030
2021-07-23 14:27:18,414 epoch 4 - iter 145/298 - loss 0.30802668 - samples/sec: 196.57 - lr: 0.000030
2021-07-23 14:27:23,124 epoch 4 - iter 174/298 - loss 0.31206123 - samples/sec: 197.11 - lr: 0.000030
2021-07-23 14:27:27,703 epoch 4 - iter 203/298 - loss 0.30784250 - samples/sec: 202.71 - lr: 0.000030
2021-07-23 14:27:32,365 epoch 4 - iter 232/298 - loss 0.30624952 - samples/sec: 199.16 - lr: 0.000030
2021-07-23 14:27:36,983 epoch 4 - iter 261/298 - loss 0.30557406 - samples/sec: 201.02 - lr: 0.000030
2021-07-23 14:27:41,751 epoch 4 - iter 290/298 - loss 0.30621191 - samples/sec: 194.69 - lr: 0.000030
2021-07-23 14:27:42,950 ----------------------------------------------------------------------------------------------------
2021-07-23 14:27:42,950 EPOCH 4 done: loss 0.3044 - lr 0.0000300
2021-07-23 14:27:45,190 DEV : loss 0.25157007575035095 - score 0.9428
2021-07-23 14:27:45,210 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:27:47,421 ----------------------------------------------------------------------------------------------------
2021-07-23 14:27:52,015 epoch 5 - iter 29/298 - loss 0.27608779 - samples/sec: 202.17 - lr: 0.000030
2021-07-23 14:27:56,691 epoch 5 - iter 58/298 - loss 0.28141518 - samples/sec: 198.52 - lr: 0.000030
2021-07-23 14:28:01,339 epoch 5 - iter 87/298 - loss 0.28845059 - samples/sec: 199.73 - lr: 0.000030
2021-07-23 14:28:06,027 epoch 5 - iter 116/298 - loss 0.29348983 - samples/sec: 198.04 - lr: 0.000030
2021-07-23 14:28:10,681 epoch 5 - iter 145/298 - loss 0.29231406 - samples/sec: 199.45 - lr: 0.000030
2021-07-23 14:28:15,318 epoch 5 - iter 174/298 - loss 0.29273316 - samples/sec: 200.19 - lr: 0.000030
2021-07-23 14:28:20,109 epoch 5 - iter 203/298 - loss 0.28980459 - samples/sec: 193.76 - lr: 0.000030
2021-07-23 14:28:24,735 epoch 5 - iter 232/298 - loss 0.28791849 - samples/sec: 200.68 - lr: 0.000030
2021-07-23 14:28:29,410 epoch 5 - iter 261/298 - loss 0.29105644 - samples/sec: 198.60 - lr: 0.000030
2021-07-23 14:28:34,144 epoch 5 - iter 290/298 - loss 0.29279070 - samples/sec: 196.09 - lr: 0.000030
2021-07-23 14:28:35,395 ----------------------------------------------------------------------------------------------------
2021-07-23 14:28:35,395 EPOCH 5 done: loss 0.2920 - lr 0.0000300
2021-07-23 14:28:37,636 DEV : loss 0.23559072613716125 - score 0.9451
2021-07-23 14:28:37,656 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:28:39,844 ----------------------------------------------------------------------------------------------------
2021-07-23 14:28:44,463 epoch 6 - iter 29/298 - loss 0.26890306 - samples/sec: 201.07 - lr: 0.000030
2021-07-23 14:28:49,148 epoch 6 - iter 58/298 - loss 0.26770053 - samples/sec: 198.18 - lr: 0.000030
2021-07-23 14:28:53,770 epoch 6 - iter 87/298 - loss 0.27028304 - samples/sec: 200.85 - lr: 0.000030
2021-07-23 14:28:58,391 epoch 6 - iter 116/298 - loss 0.28727667 - samples/sec: 200.85 - lr: 0.000030
2021-07-23 14:29:03,075 epoch 6 - iter 145/298 - loss 0.28790587 - samples/sec: 198.22 - lr: 0.000030
2021-07-23 14:29:07,684 epoch 6 - iter 174/298 - loss 0.28737339 - samples/sec: 201.42 - lr: 0.000030
2021-07-23 14:29:12,331 epoch 6 - iter 203/298 - loss 0.28647778 - samples/sec: 199.76 - lr: 0.000030
2021-07-23 14:29:17,090 epoch 6 - iter 232/298 - loss 0.28860859 - samples/sec: 195.04 - lr: 0.000030
2021-07-23 14:29:21,806 epoch 6 - iter 261/298 - loss 0.28649861 - samples/sec: 196.86 - lr: 0.000030
2021-07-23 14:29:26,441 epoch 6 - iter 290/298 - loss 0.28866733 - samples/sec: 200.26 - lr: 0.000030
2021-07-23 14:29:27,784 ----------------------------------------------------------------------------------------------------
2021-07-23 14:29:27,784 EPOCH 6 done: loss 0.2893 - lr 0.0000300
2021-07-23 14:29:30,027 DEV : loss 0.24246065318584442 - score 0.9432
2021-07-23 14:29:30,047 BAD EPOCHS (no improvement): 1
2021-07-23 14:29:30,047 ----------------------------------------------------------------------------------------------------
2021-07-23 14:29:34,664 epoch 7 - iter 29/298 - loss 0.27291276 - samples/sec: 201.12 - lr: 0.000030
2021-07-23 14:29:39,307 epoch 7 - iter 58/298 - loss 0.27083494 - samples/sec: 199.93 - lr: 0.000030
2021-07-23 14:29:44,010 epoch 7 - iter 87/298 - loss 0.27749479 - samples/sec: 197.40 - lr: 0.000030
2021-07-23 14:29:48,660 epoch 7 - iter 116/298 - loss 0.27971530 - samples/sec: 199.65 - lr: 0.000030
2021-07-23 14:29:53,363 epoch 7 - iter 145/298 - loss 0.28477349 - samples/sec: 197.36 - lr: 0.000030
2021-07-23 14:29:58,026 epoch 7 - iter 174/298 - loss 0.28268485 - samples/sec: 199.08 - lr: 0.000030
2021-07-23 14:30:02,726 epoch 7 - iter 203/298 - loss 0.27880562 - samples/sec: 197.53 - lr: 0.000030
2021-07-23 14:30:07,399 epoch 7 - iter 232/298 - loss 0.28381688 - samples/sec: 198.65 - lr: 0.000030
2021-07-23 14:30:12,004 epoch 7 - iter 261/298 - loss 0.28922817 - samples/sec: 201.59 - lr: 0.000030
2021-07-23 14:30:16,708 epoch 7 - iter 290/298 - loss 0.28858425 - samples/sec: 197.34 - lr: 0.000030
2021-07-23 14:30:17,926 ----------------------------------------------------------------------------------------------------
2021-07-23 14:30:17,926 EPOCH 7 done: loss 0.2886 - lr 0.0000300
2021-07-23 14:30:20,395 DEV : loss 0.25408342480659485 - score 0.9429
2021-07-23 14:30:20,415 BAD EPOCHS (no improvement): 2
2021-07-23 14:30:20,415 ----------------------------------------------------------------------------------------------------
2021-07-23 14:30:25,073 epoch 8 - iter 29/298 - loss 0.25202032 - samples/sec: 199.33 - lr: 0.000030
2021-07-23 14:30:29,782 epoch 8 - iter 58/298 - loss 0.26095604 - samples/sec: 197.17 - lr: 0.000030
2021-07-23 14:30:34,335 epoch 8 - iter 87/298 - loss 0.26025519 - samples/sec: 203.89 - lr: 0.000030
2021-07-23 14:30:38,992 epoch 8 - iter 116/298 - loss 0.26988349 - samples/sec: 199.34 - lr: 0.000030
2021-07-23 14:30:43,604 epoch 8 - iter 145/298 - loss 0.26994279 - samples/sec: 201.28 - lr: 0.000030
2021-07-23 14:30:48,292 epoch 8 - iter 174/298 - loss 0.27408315 - samples/sec: 198.02 - lr: 0.000030
2021-07-23 14:30:52,983 epoch 8 - iter 203/298 - loss 0.27670905 - samples/sec: 197.87 - lr: 0.000030
2021-07-23 14:30:57,559 epoch 8 - iter 232/298 - loss 0.27518003 - samples/sec: 202.86 - lr: 0.000030
2021-07-23 14:31:02,258 epoch 8 - iter 261/298 - loss 0.27425251 - samples/sec: 197.57 - lr: 0.000030
2021-07-23 14:31:06,947 epoch 8 - iter 290/298 - loss 0.27618511 - samples/sec: 197.96 - lr: 0.000030
2021-07-23 14:31:08,215 ----------------------------------------------------------------------------------------------------
2021-07-23 14:31:08,215 EPOCH 8 done: loss 0.2772 - lr 0.0000300
2021-07-23 14:31:10,457 DEV : loss 0.23335731029510498 - score 0.9462
2021-07-23 14:31:10,477 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:31:12,672 ----------------------------------------------------------------------------------------------------
2021-07-23 14:31:17,387 epoch 9 - iter 29/298 - loss 0.25992102 - samples/sec: 196.99 - lr: 0.000030
2021-07-23 14:31:22,119 epoch 9 - iter 58/298 - loss 0.26685171 - samples/sec: 196.19 - lr: 0.000030
2021-07-23 14:31:26,775 epoch 9 - iter 87/298 - loss 0.27980592 - samples/sec: 199.36 - lr: 0.000030
2021-07-23 14:31:31,563 epoch 9 - iter 116/298 - loss 0.27818394 - samples/sec: 193.88 - lr: 0.000030
2021-07-23 14:31:36,209 epoch 9 - iter 145/298 - loss 0.27838489 - samples/sec: 199.83 - lr: 0.000030
2021-07-23 14:31:40,811 epoch 9 - iter 174/298 - loss 0.28149324 - samples/sec: 201.73 - lr: 0.000030
2021-07-23 14:31:45,430 epoch 9 - iter 203/298 - loss 0.27586276 - samples/sec: 200.99 - lr: 0.000030
2021-07-23 14:31:49,955 epoch 9 - iter 232/298 - loss 0.27375156 - samples/sec: 205.14 - lr: 0.000030
2021-07-23 14:31:54,596 epoch 9 - iter 261/298 - loss 0.27732737 - samples/sec: 200.05 - lr: 0.000030
2021-07-23 14:31:59,375 epoch 9 - iter 290/298 - loss 0.27685475 - samples/sec: 194.24 - lr: 0.000030
2021-07-23 14:32:00,644 ----------------------------------------------------------------------------------------------------
2021-07-23 14:32:00,644 EPOCH 9 done: loss 0.2764 - lr 0.0000300
2021-07-23 14:32:02,896 DEV : loss 0.23266427218914032 - score 0.9463
2021-07-23 14:32:02,916 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:32:05,016 ----------------------------------------------------------------------------------------------------
2021-07-23 14:32:09,609 epoch 10 - iter 29/298 - loss 0.27656930 - samples/sec: 202.21 - lr: 0.000030
2021-07-23 14:32:14,157 epoch 10 - iter 58/298 - loss 0.28238582 - samples/sec: 204.11 - lr: 0.000030
2021-07-23 14:32:18,819 epoch 10 - iter 87/298 - loss 0.27534519 - samples/sec: 199.16 - lr: 0.000030
2021-07-23 14:32:23,506 epoch 10 - iter 116/298 - loss 0.27495914 - samples/sec: 198.02 - lr: 0.000030
2021-07-23 14:32:28,199 epoch 10 - iter 145/298 - loss 0.27325859 - samples/sec: 197.84 - lr: 0.000030
2021-07-23 14:32:32,795 epoch 10 - iter 174/298 - loss 0.27891613 - samples/sec: 201.97 - lr: 0.000030
2021-07-23 14:32:37,448 epoch 10 - iter 203/298 - loss 0.27171315 - samples/sec: 199.52 - lr: 0.000030
2021-07-23 14:32:42,011 epoch 10 - iter 232/298 - loss 0.26993761 - samples/sec: 203.41 - lr: 0.000030
2021-07-23 14:32:46,612 epoch 10 - iter 261/298 - loss 0.27258705 - samples/sec: 201.80 - lr: 0.000030
2021-07-23 14:32:51,222 epoch 10 - iter 290/298 - loss 0.27480594 - samples/sec: 201.34 - lr: 0.000030
2021-07-23 14:32:52,394 ----------------------------------------------------------------------------------------------------
2021-07-23 14:32:52,394 EPOCH 10 done: loss 0.2749 - lr 0.0000300
2021-07-23 14:32:54,637 DEV : loss 0.23684291541576385 - score 0.9442
2021-07-23 14:32:54,657 BAD EPOCHS (no improvement): 1
2021-07-23 14:32:54,658 ----------------------------------------------------------------------------------------------------
2021-07-23 14:32:59,298 epoch 11 - iter 29/298 - loss 0.28854641 - samples/sec: 200.10 - lr: 0.000030
2021-07-23 14:33:03,894 epoch 11 - iter 58/298 - loss 0.27843291 - samples/sec: 202.01 - lr: 0.000030
2021-07-23 14:33:08,642 epoch 11 - iter 87/298 - loss 0.26695614 - samples/sec: 195.51 - lr: 0.000030
2021-07-23 14:33:13,176 epoch 11 - iter 116/298 - loss 0.27523840 - samples/sec: 204.75 - lr: 0.000030
2021-07-23 14:33:17,711 epoch 11 - iter 145/298 - loss 0.27525323 - samples/sec: 204.70 - lr: 0.000030
2021-07-23 14:33:22,330 epoch 11 - iter 174/298 - loss 0.27715456 - samples/sec: 200.96 - lr: 0.000030
2021-07-23 14:33:27,047 epoch 11 - iter 203/298 - loss 0.27834420 - samples/sec: 196.80 - lr: 0.000030
2021-07-23 14:33:31,649 epoch 11 - iter 232/298 - loss 0.27948249 - samples/sec: 201.76 - lr: 0.000030
2021-07-23 14:33:36,311 epoch 11 - iter 261/298 - loss 0.27817957 - samples/sec: 199.10 - lr: 0.000030
2021-07-23 14:33:40,923 epoch 11 - iter 290/298 - loss 0.27694102 - samples/sec: 201.30 - lr: 0.000030
2021-07-23 14:33:42,154 ----------------------------------------------------------------------------------------------------
2021-07-23 14:33:42,154 EPOCH 11 done: loss 0.2770 - lr 0.0000300
2021-07-23 14:33:44,394 DEV : loss 0.22438693046569824 - score 0.9499
2021-07-23 14:33:44,414 BAD EPOCHS (no improvement): 0
saving best model
2021-07-23 14:33:46,559 ----------------------------------------------------------------------------------------------------
2021-07-23 14:33:51,191 epoch 12 - iter 29/298 - loss 0.28163366 - samples/sec: 200.53 - lr: 0.000030
2021-07-23 14:33:55,737 epoch 12 - iter 58/298 - loss 0.28615023 - samples/sec: 204.17 - lr: 0.000030
2021-07-23 14:34:00,387 epoch 12 - iter 87/298 - loss 0.27629474 - samples/sec: 199.66 - lr: 0.000030
2021-07-23 14:34:04,981 epoch 12 - iter 116/298 - loss 0.27715907 - samples/sec: 202.04 - lr: 0.000030
2021-07-23 14:34:09,635 epoch 12 - iter 145/298 - loss 0.27176310 - samples/sec: 199.47 - lr: 0.000030
2021-07-23 14:34:14,251 epoch 12 - iter 174/298 - loss 0.27179136 - samples/sec: 201.14 - lr: 0.000030
2021-07-23 14:34:18,782 epoch 12 - iter 203/298 - loss 0.27098253 - samples/sec: 204.87 - lr: 0.000030
2021-07-23 14:34:23,448 epoch 12 - iter 232/298 - loss 0.27264418 - samples/sec: 198.95 - lr: 0.000030
2021-07-23 14:34:28,098 epoch 12 - iter 261/298 - loss 0.27400346 - samples/sec: 199.62 - lr: 0.000030
2021-07-23 14:34:32,795 epoch 12 - iter 290/298 - loss 0.27370419 - samples/sec: 197.63 - lr: 0.000030
2021-07-23 14:34:34,027 ----------------------------------------------------------------------------------------------------
2021-07-23 14:34:34,027 EPOCH 12 done: loss 0.2734 - lr 0.0000300
2021-07-23 14:34:36,282 DEV : loss 0.23327773809432983 - score 0.948
2021-07-23 14:34:36,301 BAD EPOCHS (no improvement): 1
2021-07-23 14:34:36,302 ----------------------------------------------------------------------------------------------------
2021-07-23 14:34:41,083 epoch 13 - iter 29/298 - loss 0.28726867 - samples/sec: 194.19 - lr: 0.000030
2021-07-23 14:34:45,684 epoch 13 - iter 58/298 - loss 0.27548488 - samples/sec: 201.80 - lr: 0.000030
2021-07-23 14:34:50,327 epoch 13 - iter 87/298 - loss 0.26616799 - samples/sec: 199.91 - lr: 0.000030
2021-07-23 14:34:54,908 epoch 13 - iter 116/298 - loss 0.26697664 - samples/sec: 202.67 - lr: 0.000030
2021-07-23 14:34:59,435 epoch 13 - iter 145/298 - loss 0.26347898 - samples/sec: 205.07 - lr: 0.000030
2021-07-23 14:35:04,140 epoch 13 - iter 174/298 - loss 0.26985387 - samples/sec: 197.31 - lr: 0.000030
2021-07-23 14:35:08,827 epoch 13 - iter 203/298 - loss 0.27081867 - samples/sec: 198.04 - lr: 0.000030
2021-07-23 14:35:13,448 epoch 13 - iter 232/298 - loss 0.27020545 - samples/sec: 200.90 - lr: 0.000030
2021-07-23 14:35:18,146 epoch 13 - iter 261/298 - loss 0.27183702 - samples/sec: 197.59 - lr: 0.000030
2021-07-23 14:35:22,883 epoch 13 - iter 290/298 - loss 0.27543413 - samples/sec: 195.98 - lr: 0.000030
2021-07-23 14:35:24,150 ----------------------------------------------------------------------------------------------------
2021-07-23 14:35:24,150 EPOCH 13 done: loss 0.2763 - lr 0.0000300
2021-07-23 14:35:26,409 DEV : loss 0.23330402374267578 - score 0.9469
2021-07-23 14:35:26,429 BAD EPOCHS (no improvement): 2
2021-07-23 14:35:26,429 ----------------------------------------------------------------------------------------------------
2021-07-23 14:35:31,066 epoch 14 - iter 29/298 - loss 0.26411309 - samples/sec: 200.26 - lr: 0.000030
2021-07-23 14:35:35,784 epoch 14 - iter 58/298 - loss 0.26315209 - samples/sec: 196.77 - lr: 0.000030
2021-07-23 14:35:40,455 epoch 14 - iter 87/298 - loss 0.25857269 - samples/sec: 198.71 - lr: 0.000030
2021-07-23 14:35:45,118 epoch 14 - iter 116/298 - loss 0.26539586 - samples/sec: 199.11 - lr: 0.000030
2021-07-23 14:35:49,806 epoch 14 - iter 145/298 - loss 0.26925319 - samples/sec: 197.99 - lr: 0.000030
2021-07-23 14:35:54,459 epoch 14 - iter 174/298 - loss 0.27170962 - samples/sec: 199.50 - lr: 0.000030
2021-07-23 14:35:58,986 epoch 14 - iter 203/298 - loss 0.26748841 - samples/sec: 205.08 - lr: 0.000030
2021-07-23 14:36:03,588 epoch 14 - iter 232/298 - loss 0.26980976 - samples/sec: 201.74 - lr: 0.000030
2021-07-23 14:36:08,362 epoch 14 - iter 261/298 - loss 0.26975394 - samples/sec: 194.42 - lr: 0.000030
2021-07-23 14:36:13,084 epoch 14 - iter 290/298 - loss 0.27029432 - samples/sec: 196.62 - lr: 0.000030
2021-07-23 14:36:14,223 ----------------------------------------------------------------------------------------------------
2021-07-23 14:36:14,223 EPOCH 14 done: loss 0.2695 - lr 0.0000300
2021-07-23 14:36:16,466 DEV : loss 0.22620715200901031 - score 0.9494
2021-07-23 14:36:16,486 BAD EPOCHS (no improvement): 3
2021-07-23 14:36:16,486 ----------------------------------------------------------------------------------------------------
2021-07-23 14:36:21,074 epoch 15 - iter 29/298 - loss 0.22571364 - samples/sec: 202.39 - lr: 0.000030
2021-07-23 14:36:25,627 epoch 15 - iter 58/298 - loss 0.25267622 - samples/sec: 203.90 - lr: 0.000030
2021-07-23 14:36:30,283 epoch 15 - iter 87/298 - loss 0.25663947 - samples/sec: 199.39 - lr: 0.000030
2021-07-23 14:36:34,808 epoch 15 - iter 116/298 - loss 0.26368085 - samples/sec: 205.16 - lr: 0.000030
2021-07-23 14:36:39,503 epoch 15 - iter 145/298 - loss 0.25968434 - samples/sec: 197.71 - lr: 0.000030
2021-07-23 14:36:44,223 epoch 15 - iter 174/298 - loss 0.25929920 - samples/sec: 196.67 - lr: 0.000030
2021-07-23 14:36:48,809 epoch 15 - iter 203/298 - loss 0.26234510 - samples/sec: 202.41 - lr: 0.000030
2021-07-23 14:36:53,390 epoch 15 - iter 232/298 - loss 0.26156554 - samples/sec: 202.65 - lr: 0.000030
2021-07-23 14:36:58,047 epoch 15 - iter 261/298 - loss 0.26909404 - samples/sec: 199.35 - lr: 0.000030
2021-07-23 14:37:02,675 epoch 15 - iter 290/298 - loss 0.26788497 - samples/sec: 200.61 - lr: 0.000030
2021-07-23 14:37:03,915 ----------------------------------------------------------------------------------------------------
2021-07-23 14:37:03,916 EPOCH 15 done: loss 0.2677 - lr 0.0000300
2021-07-23 14:37:06,158 DEV : loss 0.2266337275505066 - score 0.9494
Epoch    15: reducing learning rate of group 0 to 1.5000e-05.
2021-07-23 14:37:06,178 BAD EPOCHS (no improvement): 4
2021-07-23 14:37:06,178 ----------------------------------------------------------------------------------------------------
2021-07-23 14:37:10,795 epoch 16 - iter 29/298 - loss 0.23866113 - samples/sec: 201.13 - lr: 0.000015
2021-07-23 14:37:15,467 epoch 16 - iter 58/298 - loss 0.24988297 - samples/sec: 198.71 - lr: 0.000015
2021-07-23 14:37:19,995 epoch 16 - iter 87/298 - loss 0.25905266 - samples/sec: 205.00 - lr: 0.000015
2021-07-23 14:37:24,586 epoch 16 - iter 116/298 - loss 0.26082960 - samples/sec: 202.19 - lr: 0.000015
2021-07-23 14:37:29,135 epoch 16 - iter 145/298 - loss 0.25896041 - samples/sec: 204.11 - lr: 0.000015
2021-07-23 14:37:33,691 epoch 16 - iter 174/298 - loss 0.25678179 - samples/sec: 203.72 - lr: 0.000015
2021-07-23 14:37:38,370 epoch 16 - iter 203/298 - loss 0.25936643 - samples/sec: 198.39 - lr: 0.000015
2021-07-23 14:37:42,934 epoch 16 - iter 232/298 - loss 0.26092204 - samples/sec: 203.41 - lr: 0.000015
2021-07-23 14:37:47,535 epoch 16 - iter 261/298 - loss 0.26221855 - samples/sec: 201.75 - lr: 0.000015
2021-07-23 14:37:52,259 epoch 16 - iter 290/298 - loss 0.26405241 - samples/sec: 196.54 - lr: 0.000015
2021-07-23 14:37:53,561 ----------------------------------------------------------------------------------------------------
2021-07-23 14:37:53,561 EPOCH 16 done: loss 0.2615 - lr 0.0000150
2021-07-23 14:37:55,815 DEV : loss 0.22964085638523102 - score 0.9476
2021-07-23 14:37:55,834 BAD EPOCHS (no improvement): 1
2021-07-23 14:37:55,835 ----------------------------------------------------------------------------------------------------
2021-07-23 14:38:00,462 epoch 17 - iter 29/298 - loss 0.25305950 - samples/sec: 200.66 - lr: 0.000015
2021-07-23 14:38:05,164 epoch 17 - iter 58/298 - loss 0.25496312 - samples/sec: 197.46 - lr: 0.000015
2021-07-23 14:38:09,879 epoch 17 - iter 87/298 - loss 0.25077244 - samples/sec: 196.88 - lr: 0.000015
2021-07-23 14:38:14,390 epoch 17 - iter 116/298 - loss 0.24853874 - samples/sec: 205.77 - lr: 0.000015
2021-07-23 14:38:19,058 epoch 17 - iter 145/298 - loss 0.25690439 - samples/sec: 198.88 - lr: 0.000015
2021-07-23 14:38:23,662 epoch 17 - iter 174/298 - loss 0.25735138 - samples/sec: 201.64 - lr: 0.000015
2021-07-23 14:38:28,210 epoch 17 - iter 203/298 - loss 0.25914477 - samples/sec: 204.11 - lr: 0.000015
2021-07-23 14:38:32,818 epoch 17 - iter 232/298 - loss 0.25776357 - samples/sec: 201.47 - lr: 0.000015
2021-07-23 14:38:37,540 epoch 17 - iter 261/298 - loss 0.25892594 - samples/sec: 196.59 - lr: 0.000015
2021-07-23 14:38:42,149 epoch 17 - iter 290/298 - loss 0.25958172 - samples/sec: 201.40 - lr: 0.000015
2021-07-23 14:38:43,367 ----------------------------------------------------------------------------------------------------
2021-07-23 14:38:43,367 EPOCH 17 done: loss 0.2580 - lr 0.0000150
2021-07-23 14:38:45,618 DEV : loss 0.22585324943065643 - score 0.9485
2021-07-23 14:38:45,638 BAD EPOCHS (no improvement): 2
2021-07-23 14:38:45,638 ----------------------------------------------------------------------------------------------------
2021-07-23 14:38:50,192 epoch 18 - iter 29/298 - loss 0.24504429 - samples/sec: 203.93 - lr: 0.000015
2021-07-23 14:38:54,895 epoch 18 - iter 58/298 - loss 0.26078816 - samples/sec: 197.38 - lr: 0.000015
2021-07-23 14:38:59,499 epoch 18 - iter 87/298 - loss 0.25444379 - samples/sec: 201.61 - lr: 0.000015
2021-07-23 14:39:04,166 epoch 18 - iter 116/298 - loss 0.25611405 - samples/sec: 198.92 - lr: 0.000015
2021-07-23 14:39:08,871 epoch 18 - iter 145/298 - loss 0.25287375 - samples/sec: 197.28 - lr: 0.000015
2021-07-23 14:39:13,486 epoch 18 - iter 174/298 - loss 0.26106232 - samples/sec: 201.16 - lr: 0.000015
2021-07-23 14:39:18,122 epoch 18 - iter 203/298 - loss 0.26533510 - samples/sec: 200.26 - lr: 0.000015
2021-07-23 14:39:22,766 epoch 18 - iter 232/298 - loss 0.26707720 - samples/sec: 199.90 - lr: 0.000015
2021-07-23 14:39:27,438 epoch 18 - iter 261/298 - loss 0.26785131 - samples/sec: 198.66 - lr: 0.000015
2021-07-23 14:39:32,154 epoch 18 - iter 290/298 - loss 0.26504776 - samples/sec: 196.84 - lr: 0.000015
2021-07-23 14:39:33,392 ----------------------------------------------------------------------------------------------------
2021-07-23 14:39:33,392 EPOCH 18 done: loss 0.2653 - lr 0.0000150
2021-07-23 14:39:35,631 DEV : loss 0.22802941501140594 - score 0.9489
2021-07-23 14:39:35,651 BAD EPOCHS (no improvement): 3
2021-07-23 14:39:35,651 ----------------------------------------------------------------------------------------------------
2021-07-23 14:39:40,342 epoch 19 - iter 29/298 - loss 0.26329701 - samples/sec: 197.93 - lr: 0.000015
2021-07-23 14:39:44,983 epoch 19 - iter 58/298 - loss 0.25959647 - samples/sec: 200.05 - lr: 0.000015
2021-07-23 14:39:49,651 epoch 19 - iter 87/298 - loss 0.25603061 - samples/sec: 198.84 - lr: 0.000015
2021-07-23 14:39:54,272 epoch 19 - iter 116/298 - loss 0.25534177 - samples/sec: 200.92 - lr: 0.000015
2021-07-23 14:39:58,923 epoch 19 - iter 145/298 - loss 0.25736269 - samples/sec: 199.57 - lr: 0.000015
2021-07-23 14:40:03,546 epoch 19 - iter 174/298 - loss 0.26111794 - samples/sec: 200.81 - lr: 0.000015
2021-07-23 14:40:08,295 epoch 19 - iter 203/298 - loss 0.25896152 - samples/sec: 195.49 - lr: 0.000015
2021-07-23 14:40:13,052 epoch 19 - iter 232/298 - loss 0.26042746 - samples/sec: 195.14 - lr: 0.000015
2021-07-23 14:40:17,766 epoch 19 - iter 261/298 - loss 0.26009863 - samples/sec: 196.91 - lr: 0.000015
2021-07-23 14:40:22,411 epoch 19 - iter 290/298 - loss 0.26002887 - samples/sec: 199.87 - lr: 0.000015
2021-07-23 14:40:23,671 ----------------------------------------------------------------------------------------------------
2021-07-23 14:40:23,671 EPOCH 19 done: loss 0.2590 - lr 0.0000150
2021-07-23 14:40:25,921 DEV : loss 0.23212175071239471 - score 0.9476
Epoch    19: reducing learning rate of group 0 to 7.5000e-06.
2021-07-23 14:40:25,941 BAD EPOCHS (no improvement): 4
2021-07-23 14:40:25,941 ----------------------------------------------------------------------------------------------------
2021-07-23 14:40:30,603 epoch 20 - iter 29/298 - loss 0.21913798 - samples/sec: 199.21 - lr: 0.000008
2021-07-23 14:40:35,247 epoch 20 - iter 58/298 - loss 0.24052891 - samples/sec: 199.87 - lr: 0.000008
2021-07-23 14:40:39,818 epoch 20 - iter 87/298 - loss 0.25296860 - samples/sec: 203.09 - lr: 0.000008
2021-07-23 14:40:44,522 epoch 20 - iter 116/298 - loss 0.25609857 - samples/sec: 197.34 - lr: 0.000008
2021-07-23 14:40:49,285 epoch 20 - iter 145/298 - loss 0.25290489 - samples/sec: 194.90 - lr: 0.000008
2021-07-23 14:40:53,947 epoch 20 - iter 174/298 - loss 0.25760619 - samples/sec: 199.13 - lr: 0.000008
2021-07-23 14:40:58,643 epoch 20 - iter 203/298 - loss 0.25851128 - samples/sec: 197.68 - lr: 0.000008
2021-07-23 14:41:03,286 epoch 20 - iter 232/298 - loss 0.26133024 - samples/sec: 199.94 - lr: 0.000008
2021-07-23 14:41:07,930 epoch 20 - iter 261/298 - loss 0.26025806 - samples/sec: 199.91 - lr: 0.000008
2021-07-23 14:41:12,559 epoch 20 - iter 290/298 - loss 0.26082802 - samples/sec: 200.51 - lr: 0.000008
2021-07-23 14:41:13,791 ----------------------------------------------------------------------------------------------------
2021-07-23 14:41:13,792 EPOCH 20 done: loss 0.2597 - lr 0.0000075
2021-07-23 14:41:16,035 DEV : loss 0.23167426884174347 - score 0.9487
2021-07-23 14:41:16,055 BAD EPOCHS (no improvement): 1
2021-07-23 14:41:16,055 ----------------------------------------------------------------------------------------------------
2021-07-23 14:41:20,711 epoch 21 - iter 29/298 - loss 0.27613637 - samples/sec: 199.43 - lr: 0.000008
2021-07-23 14:41:25,207 epoch 21 - iter 58/298 - loss 0.25578978 - samples/sec: 206.48 - lr: 0.000008
2021-07-23 14:41:29,983 epoch 21 - iter 87/298 - loss 0.25103513 - samples/sec: 194.37 - lr: 0.000008
2021-07-23 14:41:34,695 epoch 21 - iter 116/298 - loss 0.25115358 - samples/sec: 197.00 - lr: 0.000008
2021-07-23 14:41:39,362 epoch 21 - iter 145/298 - loss 0.25043936 - samples/sec: 198.90 - lr: 0.000008
2021-07-23 14:41:44,107 epoch 21 - iter 174/298 - loss 0.25257155 - samples/sec: 195.66 - lr: 0.000008
2021-07-23 14:41:48,665 epoch 21 - iter 203/298 - loss 0.24972436 - samples/sec: 203.66 - lr: 0.000008
2021-07-23 14:41:53,398 epoch 21 - iter 232/298 - loss 0.24861457 - samples/sec: 196.14 - lr: 0.000008
2021-07-23 14:41:58,068 epoch 21 - iter 261/298 - loss 0.24919379 - samples/sec: 198.80 - lr: 0.000008
2021-07-23 14:42:02,739 epoch 21 - iter 290/298 - loss 0.25101963 - samples/sec: 198.72 - lr: 0.000008
2021-07-23 14:42:03,981 ----------------------------------------------------------------------------------------------------
2021-07-23 14:42:03,982 EPOCH 21 done: loss 0.2513 - lr 0.0000075
2021-07-23 14:42:06,228 DEV : loss 0.2290484756231308 - score 0.9491
2021-07-23 14:42:06,248 BAD EPOCHS (no improvement): 2
2021-07-23 14:42:06,248 ----------------------------------------------------------------------------------------------------
2021-07-23 14:42:10,837 epoch 22 - iter 29/298 - loss 0.23893749 - samples/sec: 202.34 - lr: 0.000008
2021-07-23 14:42:15,443 epoch 22 - iter 58/298 - loss 0.23461079 - samples/sec: 201.57 - lr: 0.000008
2021-07-23 14:42:20,014 epoch 22 - iter 87/298 - loss 0.23785205 - samples/sec: 203.06 - lr: 0.000008
2021-07-23 14:42:24,718 epoch 22 - iter 116/298 - loss 0.24711157 - samples/sec: 197.36 - lr: 0.000008
2021-07-23 14:42:29,439 epoch 22 - iter 145/298 - loss 0.24849046 - samples/sec: 196.65 - lr: 0.000008
2021-07-23 14:42:34,171 epoch 22 - iter 174/298 - loss 0.24875147 - samples/sec: 196.19 - lr: 0.000008
2021-07-23 14:42:38,792 epoch 22 - iter 203/298 - loss 0.24829625 - samples/sec: 200.90 - lr: 0.000008
2021-07-23 14:42:43,384 epoch 22 - iter 232/298 - loss 0.25152306 - samples/sec: 202.16 - lr: 0.000008
2021-07-23 14:42:48,175 epoch 22 - iter 261/298 - loss 0.25235945 - samples/sec: 193.76 - lr: 0.000008
2021-07-23 14:42:52,794 epoch 22 - iter 290/298 - loss 0.25479989 - samples/sec: 200.97 - lr: 0.000008
2021-07-23 14:42:54,059 ----------------------------------------------------------------------------------------------------
2021-07-23 14:42:54,059 EPOCH 22 done: loss 0.2551 - lr 0.0000075
2021-07-23 14:42:56,299 DEV : loss 0.23247253894805908 - score 0.9476
2021-07-23 14:42:56,319 BAD EPOCHS (no improvement): 3
2021-07-23 14:42:56,319 ----------------------------------------------------------------------------------------------------
2021-07-23 14:43:00,926 epoch 23 - iter 29/298 - loss 0.25976224 - samples/sec: 201.59 - lr: 0.000008
2021-07-23 14:43:05,675 epoch 23 - iter 58/298 - loss 0.26307962 - samples/sec: 195.46 - lr: 0.000008
2021-07-23 14:43:10,328 epoch 23 - iter 87/298 - loss 0.26330421 - samples/sec: 199.52 - lr: 0.000008
2021-07-23 14:43:14,987 epoch 23 - iter 116/298 - loss 0.25671822 - samples/sec: 199.25 - lr: 0.000008
2021-07-23 14:43:19,692 epoch 23 - iter 145/298 - loss 0.25548799 - samples/sec: 197.31 - lr: 0.000008
2021-07-23 14:43:24,418 epoch 23 - iter 174/298 - loss 0.25409603 - samples/sec: 196.40 - lr: 0.000008
2021-07-23 14:43:29,083 epoch 23 - iter 203/298 - loss 0.25054801 - samples/sec: 199.02 - lr: 0.000008
2021-07-23 14:43:33,654 epoch 23 - iter 232/298 - loss 0.25054073 - samples/sec: 203.08 - lr: 0.000008
2021-07-23 14:43:38,302 epoch 23 - iter 261/298 - loss 0.25095999 - samples/sec: 199.74 - lr: 0.000008
2021-07-23 14:43:43,098 epoch 23 - iter 290/298 - loss 0.25172719 - samples/sec: 193.53 - lr: 0.000008
2021-07-23 14:43:44,339 ----------------------------------------------------------------------------------------------------
2021-07-23 14:43:44,339 EPOCH 23 done: loss 0.2530 - lr 0.0000075
2021-07-23 14:43:46,580 DEV : loss 0.23056839406490326 - score 0.9479
Epoch    23: reducing learning rate of group 0 to 3.7500e-06.
2021-07-23 14:43:46,600 BAD EPOCHS (no improvement): 4
2021-07-23 14:43:46,601 ----------------------------------------------------------------------------------------------------
2021-07-23 14:43:51,267 epoch 24 - iter 29/298 - loss 0.21439926 - samples/sec: 198.99 - lr: 0.000004
2021-07-23 14:43:55,974 epoch 24 - iter 58/298 - loss 0.22835328 - samples/sec: 197.21 - lr: 0.000004
2021-07-23 14:44:00,671 epoch 24 - iter 87/298 - loss 0.23540585 - samples/sec: 197.65 - lr: 0.000004
2021-07-23 14:44:05,189 epoch 24 - iter 116/298 - loss 0.23281967 - samples/sec: 205.45 - lr: 0.000004
2021-07-23 14:44:09,844 epoch 24 - iter 145/298 - loss 0.23767692 - samples/sec: 199.45 - lr: 0.000004
2021-07-23 14:44:14,536 epoch 24 - iter 174/298 - loss 0.23786082 - samples/sec: 197.83 - lr: 0.000004
2021-07-23 14:44:19,162 epoch 24 - iter 203/298 - loss 0.24268701 - samples/sec: 200.69 - lr: 0.000004
2021-07-23 14:44:23,805 epoch 24 - iter 232/298 - loss 0.24729927 - samples/sec: 199.92 - lr: 0.000004
2021-07-23 14:44:28,515 epoch 24 - iter 261/298 - loss 0.24802055 - samples/sec: 197.09 - lr: 0.000004
2021-07-23 14:44:33,238 epoch 24 - iter 290/298 - loss 0.24738365 - samples/sec: 196.56 - lr: 0.000004
2021-07-23 14:44:34,458 ----------------------------------------------------------------------------------------------------
2021-07-23 14:44:34,458 EPOCH 24 done: loss 0.2465 - lr 0.0000038
2021-07-23 14:44:36,702 DEV : loss 0.22978495061397552 - score 0.9487
2021-07-23 14:44:36,722 BAD EPOCHS (no improvement): 1
2021-07-23 14:44:36,722 ----------------------------------------------------------------------------------------------------
2021-07-23 14:44:41,442 epoch 25 - iter 29/298 - loss 0.24432971 - samples/sec: 196.72 - lr: 0.000004
2021-07-23 14:44:46,082 epoch 25 - iter 58/298 - loss 0.25278113 - samples/sec: 200.07 - lr: 0.000004
2021-07-23 14:44:50,802 epoch 25 - iter 87/298 - loss 0.25262278 - samples/sec: 196.69 - lr: 0.000004
2021-07-23 14:44:55,498 epoch 25 - iter 116/298 - loss 0.25471895 - samples/sec: 197.66 - lr: 0.000004
2021-07-23 14:45:00,134 epoch 25 - iter 145/298 - loss 0.24687620 - samples/sec: 200.27 - lr: 0.000004
2021-07-23 14:45:04,812 epoch 25 - iter 174/298 - loss 0.24496627 - samples/sec: 198.46 - lr: 0.000004
2021-07-23 14:45:09,439 epoch 25 - iter 203/298 - loss 0.24328653 - samples/sec: 200.62 - lr: 0.000004
2021-07-23 14:45:14,162 epoch 25 - iter 232/298 - loss 0.24702781 - samples/sec: 196.56 - lr: 0.000004
2021-07-23 14:45:18,778 epoch 25 - iter 261/298 - loss 0.24573548 - samples/sec: 201.11 - lr: 0.000004
2021-07-23 14:45:23,383 epoch 25 - iter 290/298 - loss 0.25287290 - samples/sec: 201.60 - lr: 0.000004
2021-07-23 14:45:24,610 ----------------------------------------------------------------------------------------------------
2021-07-23 14:45:24,610 EPOCH 25 done: loss 0.2526 - lr 0.0000038
2021-07-23 14:45:26,857 DEV : loss 0.2299678772687912 - score 0.9483
2021-07-23 14:45:26,877 BAD EPOCHS (no improvement): 2
2021-07-23 14:45:26,877 ----------------------------------------------------------------------------------------------------
2021-07-23 14:45:31,490 epoch 26 - iter 29/298 - loss 0.27616926 - samples/sec: 201.28 - lr: 0.000004
2021-07-23 14:45:36,122 epoch 26 - iter 58/298 - loss 0.27064190 - samples/sec: 200.45 - lr: 0.000004
2021-07-23 14:45:40,872 epoch 26 - iter 87/298 - loss 0.26861793 - samples/sec: 195.44 - lr: 0.000004
2021-07-23 14:45:45,532 epoch 26 - iter 116/298 - loss 0.26027107 - samples/sec: 199.21 - lr: 0.000004
2021-07-23 14:45:50,099 epoch 26 - iter 145/298 - loss 0.25475452 - samples/sec: 203.26 - lr: 0.000004
2021-07-23 14:45:54,735 epoch 26 - iter 174/298 - loss 0.25230763 - samples/sec: 200.21 - lr: 0.000004
2021-07-23 14:45:59,452 epoch 26 - iter 203/298 - loss 0.25388431 - samples/sec: 196.82 - lr: 0.000004
2021-07-23 14:46:04,178 epoch 26 - iter 232/298 - loss 0.25852255 - samples/sec: 196.39 - lr: 0.000004
2021-07-23 14:46:08,871 epoch 26 - iter 261/298 - loss 0.25919858 - samples/sec: 197.82 - lr: 0.000004
2021-07-23 14:46:13,398 epoch 26 - iter 290/298 - loss 0.25807002 - samples/sec: 205.05 - lr: 0.000004
2021-07-23 14:46:14,626 ----------------------------------------------------------------------------------------------------
2021-07-23 14:46:14,626 EPOCH 26 done: loss 0.2583 - lr 0.0000038
2021-07-23 14:46:16,870 DEV : loss 0.23087051510810852 - score 0.9479
2021-07-23 14:46:16,890 BAD EPOCHS (no improvement): 3
2021-07-23 14:46:16,890 ----------------------------------------------------------------------------------------------------
2021-07-23 14:46:21,469 epoch 27 - iter 29/298 - loss 0.24762557 - samples/sec: 202.79 - lr: 0.000004
2021-07-23 14:46:26,174 epoch 27 - iter 58/298 - loss 0.24476984 - samples/sec: 197.33 - lr: 0.000004
2021-07-23 14:46:30,802 epoch 27 - iter 87/298 - loss 0.24023342 - samples/sec: 200.56 - lr: 0.000004
2021-07-23 14:46:35,499 epoch 27 - iter 116/298 - loss 0.24828057 - samples/sec: 197.66 - lr: 0.000004
2021-07-23 14:46:40,187 epoch 27 - iter 145/298 - loss 0.25699748 - samples/sec: 198.00 - lr: 0.000004
2021-07-23 14:46:44,823 epoch 27 - iter 174/298 - loss 0.25525125 - samples/sec: 200.22 - lr: 0.000004
2021-07-23 14:46:49,494 epoch 27 - iter 203/298 - loss 0.25466212 - samples/sec: 198.75 - lr: 0.000004
2021-07-23 14:46:54,075 epoch 27 - iter 232/298 - loss 0.25542470 - samples/sec: 202.65 - lr: 0.000004
2021-07-23 14:46:58,799 epoch 27 - iter 261/298 - loss 0.25459170 - samples/sec: 196.51 - lr: 0.000004
2021-07-23 14:47:03,525 epoch 27 - iter 290/298 - loss 0.25124125 - samples/sec: 196.44 - lr: 0.000004
2021-07-23 14:47:04,800 ----------------------------------------------------------------------------------------------------
2021-07-23 14:47:04,800 EPOCH 27 done: loss 0.2519 - lr 0.0000038
2021-07-23 14:47:07,054 DEV : loss 0.23153774440288544 - score 0.9479
Epoch    27: reducing learning rate of group 0 to 1.8750e-06.
2021-07-23 14:47:07,073 BAD EPOCHS (no improvement): 4
2021-07-23 14:47:07,074 ----------------------------------------------------------------------------------------------------
2021-07-23 14:47:07,074 ----------------------------------------------------------------------------------------------------
2021-07-23 14:47:07,074 learning rate too small - quitting training!
2021-07-23 14:47:07,074 ----------------------------------------------------------------------------------------------------
2021-07-23 14:47:07,637 ----------------------------------------------------------------------------------------------------
2021-07-23 14:47:07,637 Testing using best model ...
2021-07-23 14:47:07,638 loading file /disk1/shabnam/codes/disrpt-data/2021-folds/sentencer-1/eng.sdrt.stac/best-model.pt
2021-07-23 14:47:39,787 0.9141	0.9668	0.9397
2021-07-23 14:47:39,788 
Results:
- F1-score (micro) 0.9397
- F1-score (macro) 0.9635

By class:
SENT       tp: 1872 - fp: 216 - fn: 79 - precision: 0.8966 - recall: 0.9595 - f1-score: 0.9270
X          tp: 426 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000
2021-07-23 14:47:39,788 ----------------------------------------------------------------------------------------------------
